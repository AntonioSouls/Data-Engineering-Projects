<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2011.13427] Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation</title><meta property="og:description" content="Human pose and shape estimation from RGB images is a highly sought after alternative to marker-based motion capture, which is laborious, requires expensive equipment, and constrains capture to laboratory environments. â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2011.13427">

<!--Generated on Tue Mar 19 05:24:12 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Soyong Shin Â Â Â Â Â Â Â Â Â  Eni Halilaj
<br class="ltx_break">Carnegie Mellon University
<br class="ltx_break">Pittsburgh, PA, USA
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{soyongs, ehalilaj}@andrew.cmu.edu</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Human pose and shape estimation from RGB images is a highly sought after alternative to marker-based motion capture, which is laborious, requires expensive equipment, and constrains capture to laboratory environments. Monocular vision-based algorithms, however, still suffer from rotational ambiguities and are not ready for translation in healthcare applications, where high accuracy is paramount. While fusion of data from multiple viewpoints could overcome these challenges, current algorithms require further improvement to obtain clinically acceptable accuracies. In this paper, we propose a learnable volumetric aggregation approach to reconstruct 3D human body pose and shape from calibrated multi-view images. We use a parametric representation of the human body, which makes our approach directly applicable to medical applications. Compared to previous approaches, our framework shows higher accuracy and greater promise for real-time prediction, given its cost efficiency.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Accurate 3D human pose estimation could revolutionize the study and treatment of mobility-limiting medical conditions. In the field of biomechanics, accurate assessment of 3D pose is key in the early diagnoses of neuromusculoskeletal diseases and monitoring of rehabilitation. Conventionally, marker-based motion tracking systems or inertial measurement units (IMU) have been the dominant methods for human motion analysis. Although highly accurate, marker-based techniques have limitations, including intrusiveness, required expertise for data collection and analysis, and a need for expensive equipment, which make the approach not scalable across clinics. IMU-based approaches are portable, but relevant pose-estimation algorithms are susceptible to heading drift and a need for careful sensor-to-body calibration. Computer vision could address some of these limitations, but current algorithms lack the accuracy that is required for clinical applications.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2011.13427/assets/Figure1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="608" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Erroneous predictions due to self-occlusion when using single-view pose estimation approaches. Predictions from single-view algorithms fit well on the input images, as shown in the example image (a) and predicted human body from this view (b), but may contain errors if there are occlusions, as shown in an image from another view (c) and the prediction from the second view (d), where it is clear the left hand position is not predicted correctly.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Attempts at vision-based motion tracking are evolving from skeletal models based on joint locations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> to statistical models that capture both body shape and 3D pose simultaneously <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Although skeletal-based approaches have improved in recent years, allowing both 2D and 3D joint center detection, they are not directly applicable in many medical applications. One of their major limitations is inability to capture 3D body pose, which bears significance in terms of disease progression or recovery. Deformable parametric body models are therefore more appropriate for biomechanics applications. Estimating human pose and shape from a single image using parametric body models has been a large area of focus in computer vision in recent years. The problem remains challenging and highly unconstrained, however, due to occlusions and lack of 3D information in 2D images (Figure <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). Optimization-based multi-view approaches have been explored as a potential solution, but these methods still do not meet the accuracy and computational efficiency requirements of clinical applications.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Inspired by a recently published multi-view aggregation algorithm that generates 3D keypoints using learnable triangulation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, we propose a model-based volumetric aggregation method for 3D human pose and shape estimation. Our approach aggregates visual information from calibrated cameras in 3D global coordinate space using a back-project operation. It then estimates a single pose and shape of the human body from aggregated information using a 3D regression network. Unlike the previous method that depends on voxel-wise representations, our approach uses a human kinematics embedding that enables reconstruction of the human body from sparse information. This way, our approach does not require a large number of network parameters and can aggregate multiple images in a cost-efficient manner, which makes it convenient real-time pose estimation.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We evaluated our model on two multi-view image datasets, Human3.6M <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and MPI-INF-3DHP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, and compared it with current state-of-the-art approaches. Our model outperforms existing single- and multi-view methods in 3D human pose and shape estimation. Our contributions are as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix1.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix1.1.1.m1.1b"><mo id="S1.I1.ix1.1.1.m1.1.1" xref="S1.I1.ix1.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix1.1.1.m1.1c"><ci id="S1.I1.ix1.1.1.m1.1.1.cmml" xref="S1.I1.ix1.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix1.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix1.p1" class="ltx_para">
<p id="S1.I1.ix1.p1.1" class="ltx_p"><span id="S1.I1.ix1.p1.1.1" class="ltx_text ltx_font_bold">Novelty:</span> We propose a 3D human pose and shape estimation model from multi-view RGB images using volumetric aggregation. Our model predicts body shape and joint angles, which are relevant for medical applications.</p>
</div>
</li>
<li id="S1.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix2.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix2.1.1.m1.1b"><mo id="S1.I1.ix2.1.1.m1.1.1" xref="S1.I1.ix2.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix2.1.1.m1.1c"><ci id="S1.I1.ix2.1.1.m1.1.1.cmml" xref="S1.I1.ix2.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix2.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix2.p1" class="ltx_para">
<p id="S1.I1.ix2.p1.1" class="ltx_p"><span id="S1.I1.ix2.p1.1.1" class="ltx_text ltx_font_bold">Speed:</span> Our framework uses rich information from a parametric human body model, allowing aggregation in a computationally efficient way compared to the recently suggested voxel-wise 3D keypoint estimation.</p>
</div>
</li>
<li id="S1.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.ix3.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.ix3.1.1.m1.1b"><mo id="S1.I1.ix3.1.1.m1.1.1" xref="S1.I1.ix3.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.ix3.1.1.m1.1c"><ci id="S1.I1.ix3.1.1.m1.1.1.cmml" xref="S1.I1.ix3.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.ix3.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.ix3.p1" class="ltx_para">
<p id="S1.I1.ix3.p1.1" class="ltx_p"><span id="S1.I1.ix3.p1.1.1" class="ltx_text ltx_font_bold">Accuracy:</span> Our aggregation method shows state-of-the-art performance in reconstructing 3D human body from multi-view images. Furthermore, the learnable aggregation method could enable utilization of the intermediate aggregated features for even better performance in the future.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we discuss related methods for predicting 3D human pose and shape from RGB images. We categorize these methods into two parts: 1) multi-view aggregation methods for 3D human pose estimation and 2) model-based approaches for reconstructing 3D body shape and pose.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Pose estimation from multi-view images</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Multi-view approaches for human pose estimation have been generally used to generate ground truth 3D pose in the development of less accurate single-view algorithms. In the early stages, 3D pose was estimated by a simple triangulation of 2D pose from each view, generated with pretrained detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. The work of Kadkhodamohammadi <em id="S2.SS1.p1.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS1.p1.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> reconstructs human pose in global 3D coordinates using a fully connected network, after concatenating 2D keypoints from all views into a single batch. To aggregate information from multiple views more efficiently, later studies then proposed deep learning architectures based on geometric information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2011.13427/assets/Figure2.png" id="S2.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="187" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overall pipeline of the approach. Figures from all views are encoded via a 2D backbone network, and then extracted feature maps are back-projected to a 3D global coordinate and aggregated into a single volume. SMPL parameters are the estimated through a regression network to finally reconstruct the full body pose.</figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">One major approach for 3D keypoint detection is to aggregate information from multiple viewpoints into volumetric 3D space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Joo <em id="S2.SS1.p2.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS1.p2.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> back-project multi-view 2D joint heatmaps from pretrained detectors into a common 3D space and estimates the probability of 3D joint locations in a global coordinate system. Iskakov <em id="S2.SS1.p2.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS1.p2.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> use end-to-end learnable triangulation to aggregate images from multiple views. Instead of 2D heatmaps, they back-project the intermediate feature maps of all views into a 3D grid and predict per-voxel heatmaps of 3D keypoints with a volumetric convolutional regressor. In addition to state-of-the-art performance, this geometry-based 3D approach shows promise for future applications since the triangulation is learnable, enabling incorporation of motion or pose priors. However, volumetric regression methods require high computational power to generate dense intermediate feature maps and 3D grid volumes for their voxel-wise representation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. In this work, we fuse information from multiple images using volumetric aggregation, but do so in a cost-efficient manner by employing a 3D kinematics embedding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. By estimating 3D kinematics, this approach also opens the door to the translation of vision-based approaches in biomechanics and rehabilitation.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Pose estimation with parametric body models</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Parametric 3D human body models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> enable reconstruction of 3D body shape and pose from 2D images. One such model, Skinned Multi-Person Linear (SMPL), which learned salient information about 3D human shape and pose from a large 3D body-scan dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, is widely used to solve 3D positional ambiguity from single or multiple images. Early-stage model-based approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> use optimization algorithms to fit the 3D body model to 2D keypoints predicted from a pretrained detector <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Since the optimization fitting is highly dependent on an initialization step and not translatable to real-time applications, learning-based regression models have been recently proposed. Pavlakos <em id="S2.SS2.p1.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS2.p1.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> use a two-stage approach, first estimating 2D keypoints and a silhouette from a convolutional encoder and then separately regressing pose and shape parameters from two intermediate representations, respectively. Kanazawa <em id="S2.SS2.p1.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS2.p1.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> used a direct regression method to estimate a full set of SMPL parameters directly from the image and penalize infeasible human body predictions using an adversarial discriminator. Kolotouros <em id="S2.SS2.p1.1.5" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS2.p1.1.6" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, based on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, use direct supervision on SMPL parameters by incorporating an optimization fitting loop to generate semi-ground-truth labels. They can weakly penalize infeasible pose and shape, since the objective function of the fitting loop includes prior terms. These approaches have ushered progress in human pose and shape estimation from single-view images, but accuracies are still not optimal, especially when occlusion is present.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">To address this challenge, multi-view approaches have also been explored. Kanazawa <em id="S2.SS2.p2.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS2.p2.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> used optimization fitting to find 3D human body parameters that minimize the reprojection error of joint locations and 2D silhouettes from each view. Liang <em id="S2.SS2.p2.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS2.p2.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> proposed a stage-by-stage and view-by-view regression method. Following a structure similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, their iterative algorithm transfers information on camera calibration to the next stage, while pose and shape prediction is transferred along each view. This method was the first to solve the multi-view aggregation for 3D pose and shape estimation in an end-to-end manner, but rather than aggregating the information from different views, their method simply expands the iteration loop and estimates SMPL parameters from all views. This approach not only requires longer inference time, as it takes larger iteration steps, but it also shows relatively low performance compared to the current state-of-the-art approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. By comparison, our approach aggregates the multiple images using geometric information from calibrated cameras and shows greater accuracy and shorter inference time.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Figure <a href="#S2.F2" title="Figure 2 â€£ 2.1 Pose estimation from multi-view images â€£ 2 Related work â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the overall flow of our approach for reconstructing 3D human body pose and shape in a calibrated multi-view setting. The following sub-sections will describe (<a href="#S3.SS1" title="3.1 SMPL body model â€£ 3 Method â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>) the parametric 3D human body model, SMPL, (<a href="#S3.SS2" title="3.2 Aggregation method â€£ 3 Method â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>) the aggregation method, which uses volumetric back-projection, and (<a href="#S3.SS3" title="3.3 Regression network â€£ 3 Method â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>) the regression network.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>SMPL body model</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.10" class="ltx_p">Instead of estimating the full set of the human body mesh vertices directly, we estimate the parameters of SMPL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, a generative model learned from a large scale 3D human body scan data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. SMPL is a differentiable function, <math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="\mathcal{M}(\theta,\beta)" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.3" xref="S3.SS1.p1.1.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.2.3.2" xref="S3.SS1.p1.1.m1.2.3.2.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.2.3.1" xref="S3.SS1.p1.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p1.1.m1.2.3.3.2" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.2.3.3.2.1" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">Î¸</mi><mo id="S3.SS1.p1.1.m1.2.3.3.2.2" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">Î²</mi><mo stretchy="false" id="S3.SS1.p1.1.m1.2.3.3.2.3" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.3"><times id="S3.SS1.p1.1.m1.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.1"></times><ci id="S3.SS1.p1.1.m1.2.3.2.cmml" xref="S3.SS1.p1.1.m1.2.3.2">â„³</ci><interval closure="open" id="S3.SS1.p1.1.m1.2.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.3.2"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğœƒ</ci><ci id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2">ğ›½</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">\mathcal{M}(\theta,\beta)</annotation></semantics></math>, which maps a triangulated body mesh <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="M\in R^{N\times 3}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">M</mi><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">R</mi><mrow id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.3.2" xref="S3.SS1.p1.2.m2.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.2.m2.1.1.3.3.1" xref="S3.SS1.p1.2.m2.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p1.2.m2.1.1.3.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><in id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></in><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ‘€</ci><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">ğ‘…</ci><apply id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3"><times id="S3.SS1.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.1"></times><ci id="S3.SS1.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.2">ğ‘</ci><cn type="integer" id="S3.SS1.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">M\in R^{N\times 3}</annotation></semantics></math> to given pose <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\theta\in R^{J\times 3}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">Î¸</mi><mo id="S3.SS1.p1.3.m3.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">R</mi><mrow id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.3.2" xref="S3.SS1.p1.3.m3.1.1.3.3.2.cmml">J</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.3.m3.1.1.3.3.1" xref="S3.SS1.p1.3.m3.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p1.3.m3.1.1.3.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><in id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1"></in><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ğœƒ</ci><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">ğ‘…</ci><apply id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3"><times id="S3.SS1.p1.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.1"></times><ci id="S3.SS1.p1.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.2">ğ½</ci><cn type="integer" id="S3.SS1.p1.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\theta\in R^{J\times 3}</annotation></semantics></math> and shape <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="\beta\in R^{10}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">Î²</mi><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">R</mi><mn id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">10</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><in id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1"></in><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">ğ›½</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">ğ‘…</ci><cn type="integer" id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\beta\in R^{10}</annotation></semantics></math> parameters. Pose parameters are a set of 3D rotation vectors representing body segments relative to their parent segments and the global orientation of the body (i.e., root joint rotation), for a total of <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="J=24" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">J</mi><mo id="S3.SS1.p1.5.m5.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">24</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><eq id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1"></eq><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">ğ½</ci><cn type="integer" id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">24</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">J=24</annotation></semantics></math> vectors. The shape parameter vector represents the 10 directions of greatest shape variability, retrieved from Principle Component Analysis. The reconstructed 3D human body mesh consist of <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="N=6890" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mrow id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">N</mi><mo id="S3.SS1.p1.6.m6.1.1.1" xref="S3.SS1.p1.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">6890</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><eq id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1"></eq><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">ğ‘</ci><cn type="integer" id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">6890</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">N=6890</annotation></semantics></math> vertices that can be linearly regressed to the 3D keypoints location <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="X\in R^{J^{\prime}\times 3}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">X</mi><mo id="S3.SS1.p1.7.m7.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml"><mi id="S3.SS1.p1.7.m7.1.1.3.2" xref="S3.SS1.p1.7.m7.1.1.3.2.cmml">R</mi><mrow id="S3.SS1.p1.7.m7.1.1.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.cmml"><msup id="S3.SS1.p1.7.m7.1.1.3.3.2" xref="S3.SS1.p1.7.m7.1.1.3.3.2.cmml"><mi id="S3.SS1.p1.7.m7.1.1.3.3.2.2" xref="S3.SS1.p1.7.m7.1.1.3.3.2.2.cmml">J</mi><mo id="S3.SS1.p1.7.m7.1.1.3.3.2.3" xref="S3.SS1.p1.7.m7.1.1.3.3.2.3.cmml">â€²</mo></msup><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.7.m7.1.1.3.3.1" xref="S3.SS1.p1.7.m7.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p1.7.m7.1.1.3.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><in id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1"></in><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">ğ‘‹</ci><apply id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.2">ğ‘…</ci><apply id="S3.SS1.p1.7.m7.1.1.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3"><times id="S3.SS1.p1.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.1"></times><apply id="S3.SS1.p1.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.3.3.2.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.2">superscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.3.3.2.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.2.2">ğ½</ci><ci id="S3.SS1.p1.7.m7.1.1.3.3.2.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.2.3">â€²</ci></apply><cn type="integer" id="S3.SS1.p1.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">X\in R^{J^{\prime}\times 3}</annotation></semantics></math> from a pretrained regressor <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">W</annotation></semantics></math> by <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="X=WM" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mrow id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">X</mi><mo id="S3.SS1.p1.9.m9.1.1.1" xref="S3.SS1.p1.9.m9.1.1.1.cmml">=</mo><mrow id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.3.2" xref="S3.SS1.p1.9.m9.1.1.3.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.9.m9.1.1.3.1" xref="S3.SS1.p1.9.m9.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p1.9.m9.1.1.3.3" xref="S3.SS1.p1.9.m9.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><eq id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1"></eq><ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">ğ‘‹</ci><apply id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3"><times id="S3.SS1.p1.9.m9.1.1.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.3.1"></times><ci id="S3.SS1.p1.9.m9.1.1.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.3.2">ğ‘Š</ci><ci id="S3.SS1.p1.9.m9.1.1.3.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">X=WM</annotation></semantics></math>. We use the linear regressor provided by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, which outputs <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="J^{\prime}=49" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mrow id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml"><msup id="S3.SS1.p1.10.m10.1.1.2" xref="S3.SS1.p1.10.m10.1.1.2.cmml"><mi id="S3.SS1.p1.10.m10.1.1.2.2" xref="S3.SS1.p1.10.m10.1.1.2.2.cmml">J</mi><mo id="S3.SS1.p1.10.m10.1.1.2.3" xref="S3.SS1.p1.10.m10.1.1.2.3.cmml">â€²</mo></msup><mo id="S3.SS1.p1.10.m10.1.1.1" xref="S3.SS1.p1.10.m10.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.10.m10.1.1.3" xref="S3.SS1.p1.10.m10.1.1.3.cmml">49</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1"><eq id="S3.SS1.p1.10.m10.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1.1"></eq><apply id="S3.SS1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.1.2.1.cmml" xref="S3.SS1.p1.10.m10.1.1.2">superscript</csymbol><ci id="S3.SS1.p1.10.m10.1.1.2.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2.2">ğ½</ci><ci id="S3.SS1.p1.10.m10.1.1.2.3.cmml" xref="S3.SS1.p1.10.m10.1.1.2.3">â€²</ci></apply><cn type="integer" id="S3.SS1.p1.10.m10.1.1.3.cmml" xref="S3.SS1.p1.10.m10.1.1.3">49</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">J^{\prime}=49</annotation></semantics></math> keypoints. Unlike previous model-based approaches, we do not estimate camera translation since our approach directly estimates the 3D human body in a global coordinate system using the given camera calibration.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2011.13427/assets/Figure3.png" id="S3.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="268" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Back-project operation. Using the camera projection matrix, we back-project the feature maps into 3D space and fill the empty volume within the projection line.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Aggregation method</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.7" class="ltx_p">In order to fuse a subjectâ€™s pose and shape information captured from surrounding cameras, we aggregate 2D feature maps from each image into a 3D coordinate system through a back-projecting operation. The feature map <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="m_{c}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">m</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ‘š</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">m_{c}</annotation></semantics></math> of a 2D image (<math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="I_{c}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">I</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ¼</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">I_{c}</annotation></semantics></math>) from camera view <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">c</annotation></semantics></math> is extracted by a 2D convolutional encoder <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="e_{2D}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><msub id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">e</mi><mrow id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml"><mn id="S3.SS2.p1.4.m4.1.1.3.2" xref="S3.SS2.p1.4.m4.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p1.4.m4.1.1.3.1" xref="S3.SS2.p1.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.4.m4.1.1.3.3" xref="S3.SS2.p1.4.m4.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">ğ‘’</ci><apply id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3"><times id="S3.SS2.p1.4.m4.1.1.3.1.cmml" xref="S3.SS2.p1.4.m4.1.1.3.1"></times><cn type="integer" id="S3.SS2.p1.4.m4.1.1.3.2.cmml" xref="S3.SS2.p1.4.m4.1.1.3.2">2</cn><ci id="S3.SS2.p1.4.m4.1.1.3.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">e_{2D}</annotation></semantics></math>. We retrieve feature maps from a single 2D convolutional layer <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">g</annotation></semantics></math> with a <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mrow id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mn id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.6.m6.1.1.1" xref="S3.SS2.p1.6.m6.1.1.1.cmml">Ã—</mo><mn id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><times id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1.1"></times><cn type="integer" id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">1</cn><cn type="integer" id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">1\times 1</annotation></semantics></math> kernel to downsize the channel before the aggregation. Down-sampled feature map <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="m_{c}^{in}" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><msubsup id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><mi id="S3.SS2.p1.7.m7.1.1.2.2" xref="S3.SS2.p1.7.m7.1.1.2.2.cmml">m</mi><mi id="S3.SS2.p1.7.m7.1.1.2.3" xref="S3.SS2.p1.7.m7.1.1.2.3.cmml">c</mi><mrow id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml"><mi id="S3.SS2.p1.7.m7.1.1.3.2" xref="S3.SS2.p1.7.m7.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.7.m7.1.1.3.1" xref="S3.SS2.p1.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.7.m7.1.1.3.3" xref="S3.SS2.p1.7.m7.1.1.3.3.cmml">n</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">superscript</csymbol><apply id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.2.1.cmml" xref="S3.SS2.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.2.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2.2">ğ‘š</ci><ci id="S3.SS2.p1.7.m7.1.1.2.3.cmml" xref="S3.SS2.p1.7.m7.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.p1.7.m7.1.1.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3"><times id="S3.SS2.p1.7.m7.1.1.3.1.cmml" xref="S3.SS2.p1.7.m7.1.1.3.1"></times><ci id="S3.SS2.p1.7.m7.1.1.3.2.cmml" xref="S3.SS2.p1.7.m7.1.1.3.2">ğ‘–</ci><ci id="S3.SS2.p1.7.m7.1.1.3.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">m_{c}^{in}</annotation></semantics></math> is computed as</p>
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.1" class="ltx_Math" alttext="m_{c}^{in}=g(e_{2D}(I_{c}))." display="block"><semantics id="S3.Ex1.m1.1a"><mrow id="S3.Ex1.m1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.cmml"><mrow id="S3.Ex1.m1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.cmml"><msubsup id="S3.Ex1.m1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.3.cmml"><mi id="S3.Ex1.m1.1.1.1.1.3.2.2" xref="S3.Ex1.m1.1.1.1.1.3.2.2.cmml">m</mi><mi id="S3.Ex1.m1.1.1.1.1.3.2.3" xref="S3.Ex1.m1.1.1.1.1.3.2.3.cmml">c</mi><mrow id="S3.Ex1.m1.1.1.1.1.3.3" xref="S3.Ex1.m1.1.1.1.1.3.3.cmml"><mi id="S3.Ex1.m1.1.1.1.1.3.3.2" xref="S3.Ex1.m1.1.1.1.1.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.1.1.1.3.3.1" xref="S3.Ex1.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex1.m1.1.1.1.1.3.3.3" xref="S3.Ex1.m1.1.1.1.1.3.3.3.cmml">n</mi></mrow></msubsup><mo id="S3.Ex1.m1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.Ex1.m1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.cmml">e</mi><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.cmml"><mn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.3.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">c</mi></msub><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.Ex1.m1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.Ex1.m1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.1b"><apply id="S3.Ex1.m1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1"><eq id="S3.Ex1.m1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.2"></eq><apply id="S3.Ex1.m1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.3">superscript</csymbol><apply id="S3.Ex1.m1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.3.2.2">ğ‘š</ci><ci id="S3.Ex1.m1.1.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.3.2.3">ğ‘</ci></apply><apply id="S3.Ex1.m1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.3.3"><times id="S3.Ex1.m1.1.1.1.1.3.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.3.3.1"></times><ci id="S3.Ex1.m1.1.1.1.1.3.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.3.3.2">ğ‘–</ci><ci id="S3.Ex1.m1.1.1.1.1.3.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.3.3.3">ğ‘›</ci></apply></apply><apply id="S3.Ex1.m1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1"><times id="S3.Ex1.m1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.2"></times><ci id="S3.Ex1.m1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.3">ğ‘”</ci><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1"><times id="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2">ğ‘’</ci><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3"><times id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.1"></times><cn type="integer" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.2">2</cn><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.3">ğ·</ci></apply></apply><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.2">ğ¼</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.1c">m_{c}^{in}=g(e_{2D}(I_{c})).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.17" class="ltx_p">We then build a <math id="S3.SS2.p1.8.m1.1" class="ltx_Math" alttext="K\times L\times L\times L" display="inline"><semantics id="S3.SS2.p1.8.m1.1a"><mrow id="S3.SS2.p1.8.m1.1.1" xref="S3.SS2.p1.8.m1.1.1.cmml"><mi id="S3.SS2.p1.8.m1.1.1.2" xref="S3.SS2.p1.8.m1.1.1.2.cmml">K</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.8.m1.1.1.1" xref="S3.SS2.p1.8.m1.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.p1.8.m1.1.1.3" xref="S3.SS2.p1.8.m1.1.1.3.cmml">L</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.8.m1.1.1.1a" xref="S3.SS2.p1.8.m1.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.p1.8.m1.1.1.4" xref="S3.SS2.p1.8.m1.1.1.4.cmml">L</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.8.m1.1.1.1b" xref="S3.SS2.p1.8.m1.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.p1.8.m1.1.1.5" xref="S3.SS2.p1.8.m1.1.1.5.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m1.1b"><apply id="S3.SS2.p1.8.m1.1.1.cmml" xref="S3.SS2.p1.8.m1.1.1"><times id="S3.SS2.p1.8.m1.1.1.1.cmml" xref="S3.SS2.p1.8.m1.1.1.1"></times><ci id="S3.SS2.p1.8.m1.1.1.2.cmml" xref="S3.SS2.p1.8.m1.1.1.2">ğ¾</ci><ci id="S3.SS2.p1.8.m1.1.1.3.cmml" xref="S3.SS2.p1.8.m1.1.1.3">ğ¿</ci><ci id="S3.SS2.p1.8.m1.1.1.4.cmml" xref="S3.SS2.p1.8.m1.1.1.4">ğ¿</ci><ci id="S3.SS2.p1.8.m1.1.1.5.cmml" xref="S3.SS2.p1.8.m1.1.1.5">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m1.1c">K\times L\times L\times L</annotation></semantics></math> cuboid <math id="S3.SS2.p1.9.m2.1" class="ltx_Math" alttext="V^{coord}" display="inline"><semantics id="S3.SS2.p1.9.m2.1a"><msup id="S3.SS2.p1.9.m2.1.1" xref="S3.SS2.p1.9.m2.1.1.cmml"><mi id="S3.SS2.p1.9.m2.1.1.2" xref="S3.SS2.p1.9.m2.1.1.2.cmml">V</mi><mrow id="S3.SS2.p1.9.m2.1.1.3" xref="S3.SS2.p1.9.m2.1.1.3.cmml"><mi id="S3.SS2.p1.9.m2.1.1.3.2" xref="S3.SS2.p1.9.m2.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m2.1.1.3.1" xref="S3.SS2.p1.9.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.9.m2.1.1.3.3" xref="S3.SS2.p1.9.m2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m2.1.1.3.1a" xref="S3.SS2.p1.9.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.9.m2.1.1.3.4" xref="S3.SS2.p1.9.m2.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m2.1.1.3.1b" xref="S3.SS2.p1.9.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.9.m2.1.1.3.5" xref="S3.SS2.p1.9.m2.1.1.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m2.1.1.3.1c" xref="S3.SS2.p1.9.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.9.m2.1.1.3.6" xref="S3.SS2.p1.9.m2.1.1.3.6.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m2.1b"><apply id="S3.SS2.p1.9.m2.1.1.cmml" xref="S3.SS2.p1.9.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.9.m2.1.1.1.cmml" xref="S3.SS2.p1.9.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.9.m2.1.1.2.cmml" xref="S3.SS2.p1.9.m2.1.1.2">ğ‘‰</ci><apply id="S3.SS2.p1.9.m2.1.1.3.cmml" xref="S3.SS2.p1.9.m2.1.1.3"><times id="S3.SS2.p1.9.m2.1.1.3.1.cmml" xref="S3.SS2.p1.9.m2.1.1.3.1"></times><ci id="S3.SS2.p1.9.m2.1.1.3.2.cmml" xref="S3.SS2.p1.9.m2.1.1.3.2">ğ‘</ci><ci id="S3.SS2.p1.9.m2.1.1.3.3.cmml" xref="S3.SS2.p1.9.m2.1.1.3.3">ğ‘œ</ci><ci id="S3.SS2.p1.9.m2.1.1.3.4.cmml" xref="S3.SS2.p1.9.m2.1.1.3.4">ğ‘œ</ci><ci id="S3.SS2.p1.9.m2.1.1.3.5.cmml" xref="S3.SS2.p1.9.m2.1.1.3.5">ğ‘Ÿ</ci><ci id="S3.SS2.p1.9.m2.1.1.3.6.cmml" xref="S3.SS2.p1.9.m2.1.1.3.6">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m2.1c">V^{coord}</annotation></semantics></math> in a global coordinate system, where <math id="S3.SS2.p1.10.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p1.10.m3.1a"><mi id="S3.SS2.p1.10.m3.1.1" xref="S3.SS2.p1.10.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m3.1b"><ci id="S3.SS2.p1.10.m3.1.1.cmml" xref="S3.SS2.p1.10.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m3.1c">K</annotation></semantics></math> is channel size of <math id="S3.SS2.p1.11.m4.1" class="ltx_Math" alttext="m_{c}^{in}" display="inline"><semantics id="S3.SS2.p1.11.m4.1a"><msubsup id="S3.SS2.p1.11.m4.1.1" xref="S3.SS2.p1.11.m4.1.1.cmml"><mi id="S3.SS2.p1.11.m4.1.1.2.2" xref="S3.SS2.p1.11.m4.1.1.2.2.cmml">m</mi><mi id="S3.SS2.p1.11.m4.1.1.2.3" xref="S3.SS2.p1.11.m4.1.1.2.3.cmml">c</mi><mrow id="S3.SS2.p1.11.m4.1.1.3" xref="S3.SS2.p1.11.m4.1.1.3.cmml"><mi id="S3.SS2.p1.11.m4.1.1.3.2" xref="S3.SS2.p1.11.m4.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.11.m4.1.1.3.1" xref="S3.SS2.p1.11.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.11.m4.1.1.3.3" xref="S3.SS2.p1.11.m4.1.1.3.3.cmml">n</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m4.1b"><apply id="S3.SS2.p1.11.m4.1.1.cmml" xref="S3.SS2.p1.11.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.11.m4.1.1.1.cmml" xref="S3.SS2.p1.11.m4.1.1">superscript</csymbol><apply id="S3.SS2.p1.11.m4.1.1.2.cmml" xref="S3.SS2.p1.11.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.11.m4.1.1.2.1.cmml" xref="S3.SS2.p1.11.m4.1.1">subscript</csymbol><ci id="S3.SS2.p1.11.m4.1.1.2.2.cmml" xref="S3.SS2.p1.11.m4.1.1.2.2">ğ‘š</ci><ci id="S3.SS2.p1.11.m4.1.1.2.3.cmml" xref="S3.SS2.p1.11.m4.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.p1.11.m4.1.1.3.cmml" xref="S3.SS2.p1.11.m4.1.1.3"><times id="S3.SS2.p1.11.m4.1.1.3.1.cmml" xref="S3.SS2.p1.11.m4.1.1.3.1"></times><ci id="S3.SS2.p1.11.m4.1.1.3.2.cmml" xref="S3.SS2.p1.11.m4.1.1.3.2">ğ‘–</ci><ci id="S3.SS2.p1.11.m4.1.1.3.3.cmml" xref="S3.SS2.p1.11.m4.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m4.1c">m_{c}^{in}</annotation></semantics></math> and <math id="S3.SS2.p1.12.m5.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.p1.12.m5.1a"><mi id="S3.SS2.p1.12.m5.1.1" xref="S3.SS2.p1.12.m5.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m5.1b"><ci id="S3.SS2.p1.12.m5.1.1.cmml" xref="S3.SS2.p1.12.m5.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m5.1c">L</annotation></semantics></math> is the side length of the cuboid. The center point of the cuboid is set at the subjectâ€™s pelvis, which is obtained by algebraic triangulation of the 2D pelvis detection from each view. Following the back-project operation described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, we back-project <math id="S3.SS2.p1.13.m6.1" class="ltx_Math" alttext="m^{in}_{c}" display="inline"><semantics id="S3.SS2.p1.13.m6.1a"><msubsup id="S3.SS2.p1.13.m6.1.1" xref="S3.SS2.p1.13.m6.1.1.cmml"><mi id="S3.SS2.p1.13.m6.1.1.2.2" xref="S3.SS2.p1.13.m6.1.1.2.2.cmml">m</mi><mi id="S3.SS2.p1.13.m6.1.1.3" xref="S3.SS2.p1.13.m6.1.1.3.cmml">c</mi><mrow id="S3.SS2.p1.13.m6.1.1.2.3" xref="S3.SS2.p1.13.m6.1.1.2.3.cmml"><mi id="S3.SS2.p1.13.m6.1.1.2.3.2" xref="S3.SS2.p1.13.m6.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.13.m6.1.1.2.3.1" xref="S3.SS2.p1.13.m6.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.13.m6.1.1.2.3.3" xref="S3.SS2.p1.13.m6.1.1.2.3.3.cmml">n</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.13.m6.1b"><apply id="S3.SS2.p1.13.m6.1.1.cmml" xref="S3.SS2.p1.13.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.13.m6.1.1.1.cmml" xref="S3.SS2.p1.13.m6.1.1">subscript</csymbol><apply id="S3.SS2.p1.13.m6.1.1.2.cmml" xref="S3.SS2.p1.13.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.13.m6.1.1.2.1.cmml" xref="S3.SS2.p1.13.m6.1.1">superscript</csymbol><ci id="S3.SS2.p1.13.m6.1.1.2.2.cmml" xref="S3.SS2.p1.13.m6.1.1.2.2">ğ‘š</ci><apply id="S3.SS2.p1.13.m6.1.1.2.3.cmml" xref="S3.SS2.p1.13.m6.1.1.2.3"><times id="S3.SS2.p1.13.m6.1.1.2.3.1.cmml" xref="S3.SS2.p1.13.m6.1.1.2.3.1"></times><ci id="S3.SS2.p1.13.m6.1.1.2.3.2.cmml" xref="S3.SS2.p1.13.m6.1.1.2.3.2">ğ‘–</ci><ci id="S3.SS2.p1.13.m6.1.1.2.3.3.cmml" xref="S3.SS2.p1.13.m6.1.1.2.3.3">ğ‘›</ci></apply></apply><ci id="S3.SS2.p1.13.m6.1.1.3.cmml" xref="S3.SS2.p1.13.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.13.m6.1c">m^{in}_{c}</annotation></semantics></math>, the feature map from view <math id="S3.SS2.p1.14.m7.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p1.14.m7.1a"><mi id="S3.SS2.p1.14.m7.1.1" xref="S3.SS2.p1.14.m7.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.14.m7.1b"><ci id="S3.SS2.p1.14.m7.1.1.cmml" xref="S3.SS2.p1.14.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.14.m7.1c">c</annotation></semantics></math>, into the established global coordinate volume and obtain the filled cube <math id="S3.SS2.p1.15.m8.1" class="ltx_Math" alttext="V_{c}=B_{c}(m^{in}_{c})" display="inline"><semantics id="S3.SS2.p1.15.m8.1a"><mrow id="S3.SS2.p1.15.m8.1.1" xref="S3.SS2.p1.15.m8.1.1.cmml"><msub id="S3.SS2.p1.15.m8.1.1.3" xref="S3.SS2.p1.15.m8.1.1.3.cmml"><mi id="S3.SS2.p1.15.m8.1.1.3.2" xref="S3.SS2.p1.15.m8.1.1.3.2.cmml">V</mi><mi id="S3.SS2.p1.15.m8.1.1.3.3" xref="S3.SS2.p1.15.m8.1.1.3.3.cmml">c</mi></msub><mo id="S3.SS2.p1.15.m8.1.1.2" xref="S3.SS2.p1.15.m8.1.1.2.cmml">=</mo><mrow id="S3.SS2.p1.15.m8.1.1.1" xref="S3.SS2.p1.15.m8.1.1.1.cmml"><msub id="S3.SS2.p1.15.m8.1.1.1.3" xref="S3.SS2.p1.15.m8.1.1.1.3.cmml"><mi id="S3.SS2.p1.15.m8.1.1.1.3.2" xref="S3.SS2.p1.15.m8.1.1.1.3.2.cmml">B</mi><mi id="S3.SS2.p1.15.m8.1.1.1.3.3" xref="S3.SS2.p1.15.m8.1.1.1.3.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p1.15.m8.1.1.1.2" xref="S3.SS2.p1.15.m8.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS2.p1.15.m8.1.1.1.1.1" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p1.15.m8.1.1.1.1.1.2" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.SS2.p1.15.m8.1.1.1.1.1.1" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.2" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.2.cmml">m</mi><mi id="S3.SS2.p1.15.m8.1.1.1.1.1.1.3" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.3.cmml">c</mi><mrow id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.cmml"><mi id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.2" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.1" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.3" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.3.cmml">n</mi></mrow></msubsup><mo stretchy="false" id="S3.SS2.p1.15.m8.1.1.1.1.1.3" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.15.m8.1b"><apply id="S3.SS2.p1.15.m8.1.1.cmml" xref="S3.SS2.p1.15.m8.1.1"><eq id="S3.SS2.p1.15.m8.1.1.2.cmml" xref="S3.SS2.p1.15.m8.1.1.2"></eq><apply id="S3.SS2.p1.15.m8.1.1.3.cmml" xref="S3.SS2.p1.15.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.15.m8.1.1.3.1.cmml" xref="S3.SS2.p1.15.m8.1.1.3">subscript</csymbol><ci id="S3.SS2.p1.15.m8.1.1.3.2.cmml" xref="S3.SS2.p1.15.m8.1.1.3.2">ğ‘‰</ci><ci id="S3.SS2.p1.15.m8.1.1.3.3.cmml" xref="S3.SS2.p1.15.m8.1.1.3.3">ğ‘</ci></apply><apply id="S3.SS2.p1.15.m8.1.1.1.cmml" xref="S3.SS2.p1.15.m8.1.1.1"><times id="S3.SS2.p1.15.m8.1.1.1.2.cmml" xref="S3.SS2.p1.15.m8.1.1.1.2"></times><apply id="S3.SS2.p1.15.m8.1.1.1.3.cmml" xref="S3.SS2.p1.15.m8.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.15.m8.1.1.1.3.1.cmml" xref="S3.SS2.p1.15.m8.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p1.15.m8.1.1.1.3.2.cmml" xref="S3.SS2.p1.15.m8.1.1.1.3.2">ğµ</ci><ci id="S3.SS2.p1.15.m8.1.1.1.3.3.cmml" xref="S3.SS2.p1.15.m8.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.SS2.p1.15.m8.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.15.m8.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1">subscript</csymbol><apply id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.2">ğ‘š</ci><apply id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3"><times id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.1.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.1"></times><ci id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.2.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.2">ğ‘–</ci><ci id="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.3.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.2.3.3">ğ‘›</ci></apply></apply><ci id="S3.SS2.p1.15.m8.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.15.m8.1.1.1.1.1.1.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.15.m8.1c">V_{c}=B_{c}(m^{in}_{c})</annotation></semantics></math>, where <math id="S3.SS2.p1.16.m9.1" class="ltx_Math" alttext="B_{c}" display="inline"><semantics id="S3.SS2.p1.16.m9.1a"><msub id="S3.SS2.p1.16.m9.1.1" xref="S3.SS2.p1.16.m9.1.1.cmml"><mi id="S3.SS2.p1.16.m9.1.1.2" xref="S3.SS2.p1.16.m9.1.1.2.cmml">B</mi><mi id="S3.SS2.p1.16.m9.1.1.3" xref="S3.SS2.p1.16.m9.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.16.m9.1b"><apply id="S3.SS2.p1.16.m9.1.1.cmml" xref="S3.SS2.p1.16.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.16.m9.1.1.1.cmml" xref="S3.SS2.p1.16.m9.1.1">subscript</csymbol><ci id="S3.SS2.p1.16.m9.1.1.2.cmml" xref="S3.SS2.p1.16.m9.1.1.2">ğµ</ci><ci id="S3.SS2.p1.16.m9.1.1.3.cmml" xref="S3.SS2.p1.16.m9.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.16.m9.1c">B_{c}</annotation></semantics></math> is the back-project operation using a projection matrix of camera <math id="S3.SS2.p1.17.m10.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p1.17.m10.1a"><mi id="S3.SS2.p1.17.m10.1.1" xref="S3.SS2.p1.17.m10.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.17.m10.1b"><ci id="S3.SS2.p1.17.m10.1.1.cmml" xref="S3.SS2.p1.17.m10.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.17.m10.1c">c</annotation></semantics></math>. 3D features from all the views are aggregated using a 3D softmax operation:</p>
<table id="S3.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex2.m1.5" class="ltx_Math" alttext="V^{in}=\sum_{c}\left(\frac{\exp(V_{c})}{\sum_{c}\exp(V_{c})}\circ V_{c}\right)." display="block"><semantics id="S3.Ex2.m1.5a"><mrow id="S3.Ex2.m1.5.5.1" xref="S3.Ex2.m1.5.5.1.1.cmml"><mrow id="S3.Ex2.m1.5.5.1.1" xref="S3.Ex2.m1.5.5.1.1.cmml"><msup id="S3.Ex2.m1.5.5.1.1.3" xref="S3.Ex2.m1.5.5.1.1.3.cmml"><mi id="S3.Ex2.m1.5.5.1.1.3.2" xref="S3.Ex2.m1.5.5.1.1.3.2.cmml">V</mi><mrow id="S3.Ex2.m1.5.5.1.1.3.3" xref="S3.Ex2.m1.5.5.1.1.3.3.cmml"><mi id="S3.Ex2.m1.5.5.1.1.3.3.2" xref="S3.Ex2.m1.5.5.1.1.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.5.5.1.1.3.3.1" xref="S3.Ex2.m1.5.5.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.5.5.1.1.3.3.3" xref="S3.Ex2.m1.5.5.1.1.3.3.3.cmml">n</mi></mrow></msup><mo rspace="0.111em" id="S3.Ex2.m1.5.5.1.1.2" xref="S3.Ex2.m1.5.5.1.1.2.cmml">=</mo><mrow id="S3.Ex2.m1.5.5.1.1.1" xref="S3.Ex2.m1.5.5.1.1.1.cmml"><munder id="S3.Ex2.m1.5.5.1.1.1.2" xref="S3.Ex2.m1.5.5.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.Ex2.m1.5.5.1.1.1.2.2" xref="S3.Ex2.m1.5.5.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S3.Ex2.m1.5.5.1.1.1.2.3" xref="S3.Ex2.m1.5.5.1.1.1.2.3.cmml">c</mi></munder><mrow id="S3.Ex2.m1.5.5.1.1.1.1.1" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.cmml"><mo id="S3.Ex2.m1.5.5.1.1.1.1.1.2" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex2.m1.5.5.1.1.1.1.1.1" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.cmml"><mfrac id="S3.Ex2.m1.4.4" xref="S3.Ex2.m1.4.4.cmml"><mrow id="S3.Ex2.m1.2.2.2.2" xref="S3.Ex2.m1.2.2.2.3.cmml"><mi id="S3.Ex2.m1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.cmml">exp</mi><mo id="S3.Ex2.m1.2.2.2.2a" xref="S3.Ex2.m1.2.2.2.3.cmml">â¡</mo><mrow id="S3.Ex2.m1.2.2.2.2.1" xref="S3.Ex2.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.Ex2.m1.2.2.2.2.1.2" xref="S3.Ex2.m1.2.2.2.3.cmml">(</mo><msub id="S3.Ex2.m1.2.2.2.2.1.1" xref="S3.Ex2.m1.2.2.2.2.1.1.cmml"><mi id="S3.Ex2.m1.2.2.2.2.1.1.2" xref="S3.Ex2.m1.2.2.2.2.1.1.2.cmml">V</mi><mi id="S3.Ex2.m1.2.2.2.2.1.1.3" xref="S3.Ex2.m1.2.2.2.2.1.1.3.cmml">c</mi></msub><mo stretchy="false" id="S3.Ex2.m1.2.2.2.2.1.3" xref="S3.Ex2.m1.2.2.2.3.cmml">)</mo></mrow></mrow><mrow id="S3.Ex2.m1.4.4.4" xref="S3.Ex2.m1.4.4.4.cmml"><msub id="S3.Ex2.m1.4.4.4.3" xref="S3.Ex2.m1.4.4.4.3.cmml"><mo id="S3.Ex2.m1.4.4.4.3.2" xref="S3.Ex2.m1.4.4.4.3.2.cmml">âˆ‘</mo><mi id="S3.Ex2.m1.4.4.4.3.3" xref="S3.Ex2.m1.4.4.4.3.3.cmml">c</mi></msub><mrow id="S3.Ex2.m1.4.4.4.2.1" xref="S3.Ex2.m1.4.4.4.2.2.cmml"><mi id="S3.Ex2.m1.3.3.3.1" xref="S3.Ex2.m1.3.3.3.1.cmml">exp</mi><mo id="S3.Ex2.m1.4.4.4.2.1a" xref="S3.Ex2.m1.4.4.4.2.2.cmml">â¡</mo><mrow id="S3.Ex2.m1.4.4.4.2.1.1" xref="S3.Ex2.m1.4.4.4.2.2.cmml"><mo stretchy="false" id="S3.Ex2.m1.4.4.4.2.1.1.2" xref="S3.Ex2.m1.4.4.4.2.2.cmml">(</mo><msub id="S3.Ex2.m1.4.4.4.2.1.1.1" xref="S3.Ex2.m1.4.4.4.2.1.1.1.cmml"><mi id="S3.Ex2.m1.4.4.4.2.1.1.1.2" xref="S3.Ex2.m1.4.4.4.2.1.1.1.2.cmml">V</mi><mi id="S3.Ex2.m1.4.4.4.2.1.1.1.3" xref="S3.Ex2.m1.4.4.4.2.1.1.1.3.cmml">c</mi></msub><mo stretchy="false" id="S3.Ex2.m1.4.4.4.2.1.1.3" xref="S3.Ex2.m1.4.4.4.2.2.cmml">)</mo></mrow></mrow></mrow></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.Ex2.m1.5.5.1.1.1.1.1.1.1" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.1.cmml">âˆ˜</mo><msub id="S3.Ex2.m1.5.5.1.1.1.1.1.1.2" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.2" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.2.cmml">V</mi><mi id="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.3" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.3.cmml">c</mi></msub></mrow><mo id="S3.Ex2.m1.5.5.1.1.1.1.1.3" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.Ex2.m1.5.5.1.2" xref="S3.Ex2.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.5b"><apply id="S3.Ex2.m1.5.5.1.1.cmml" xref="S3.Ex2.m1.5.5.1"><eq id="S3.Ex2.m1.5.5.1.1.2.cmml" xref="S3.Ex2.m1.5.5.1.1.2"></eq><apply id="S3.Ex2.m1.5.5.1.1.3.cmml" xref="S3.Ex2.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.5.5.1.1.3.1.cmml" xref="S3.Ex2.m1.5.5.1.1.3">superscript</csymbol><ci id="S3.Ex2.m1.5.5.1.1.3.2.cmml" xref="S3.Ex2.m1.5.5.1.1.3.2">ğ‘‰</ci><apply id="S3.Ex2.m1.5.5.1.1.3.3.cmml" xref="S3.Ex2.m1.5.5.1.1.3.3"><times id="S3.Ex2.m1.5.5.1.1.3.3.1.cmml" xref="S3.Ex2.m1.5.5.1.1.3.3.1"></times><ci id="S3.Ex2.m1.5.5.1.1.3.3.2.cmml" xref="S3.Ex2.m1.5.5.1.1.3.3.2">ğ‘–</ci><ci id="S3.Ex2.m1.5.5.1.1.3.3.3.cmml" xref="S3.Ex2.m1.5.5.1.1.3.3.3">ğ‘›</ci></apply></apply><apply id="S3.Ex2.m1.5.5.1.1.1.cmml" xref="S3.Ex2.m1.5.5.1.1.1"><apply id="S3.Ex2.m1.5.5.1.1.1.2.cmml" xref="S3.Ex2.m1.5.5.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.5.5.1.1.1.2.1.cmml" xref="S3.Ex2.m1.5.5.1.1.1.2">subscript</csymbol><sum id="S3.Ex2.m1.5.5.1.1.1.2.2.cmml" xref="S3.Ex2.m1.5.5.1.1.1.2.2"></sum><ci id="S3.Ex2.m1.5.5.1.1.1.2.3.cmml" xref="S3.Ex2.m1.5.5.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.Ex2.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.5.5.1.1.1.1.1"><compose id="S3.Ex2.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.1"></compose><apply id="S3.Ex2.m1.4.4.cmml" xref="S3.Ex2.m1.4.4"><divide id="S3.Ex2.m1.4.4.5.cmml" xref="S3.Ex2.m1.4.4"></divide><apply id="S3.Ex2.m1.2.2.2.3.cmml" xref="S3.Ex2.m1.2.2.2.2"><exp id="S3.Ex2.m1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1"></exp><apply id="S3.Ex2.m1.2.2.2.2.1.1.cmml" xref="S3.Ex2.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.2.2.1.1.1.cmml" xref="S3.Ex2.m1.2.2.2.2.1.1">subscript</csymbol><ci id="S3.Ex2.m1.2.2.2.2.1.1.2.cmml" xref="S3.Ex2.m1.2.2.2.2.1.1.2">ğ‘‰</ci><ci id="S3.Ex2.m1.2.2.2.2.1.1.3.cmml" xref="S3.Ex2.m1.2.2.2.2.1.1.3">ğ‘</ci></apply></apply><apply id="S3.Ex2.m1.4.4.4.cmml" xref="S3.Ex2.m1.4.4.4"><apply id="S3.Ex2.m1.4.4.4.3.cmml" xref="S3.Ex2.m1.4.4.4.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.4.4.4.3.1.cmml" xref="S3.Ex2.m1.4.4.4.3">subscript</csymbol><sum id="S3.Ex2.m1.4.4.4.3.2.cmml" xref="S3.Ex2.m1.4.4.4.3.2"></sum><ci id="S3.Ex2.m1.4.4.4.3.3.cmml" xref="S3.Ex2.m1.4.4.4.3.3">ğ‘</ci></apply><apply id="S3.Ex2.m1.4.4.4.2.2.cmml" xref="S3.Ex2.m1.4.4.4.2.1"><exp id="S3.Ex2.m1.3.3.3.1.cmml" xref="S3.Ex2.m1.3.3.3.1"></exp><apply id="S3.Ex2.m1.4.4.4.2.1.1.1.cmml" xref="S3.Ex2.m1.4.4.4.2.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.4.4.4.2.1.1.1.1.cmml" xref="S3.Ex2.m1.4.4.4.2.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.4.4.4.2.1.1.1.2.cmml" xref="S3.Ex2.m1.4.4.4.2.1.1.1.2">ğ‘‰</ci><ci id="S3.Ex2.m1.4.4.4.2.1.1.1.3.cmml" xref="S3.Ex2.m1.4.4.4.2.1.1.1.3">ğ‘</ci></apply></apply></apply></apply><apply id="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.2">ğ‘‰</ci><ci id="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex2.m1.5.5.1.1.1.1.1.1.2.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.5c">V^{in}=\sum_{c}\left(\frac{\exp(V_{c})}{\sum_{c}\exp(V_{c})}\circ V_{c}\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.18" class="ltx_p">The framework of learning-based volumetric aggregation of intermediate feature maps has been previously introduced by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, yielding state-of-the-art performance, but it requires a large number of voxels and high computational load since the final output of the network is a voxel-wise representation. We instead use a human kinematic embedding, as mentioned in section <a href="#S3.SS1" title="3.1 SMPL body model â€£ 3 Method â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, aggregating relevant information with a much smaller number of parameters, which enables our method to make predictions in real-time.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Regression network</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.9" class="ltx_p">The final regressor is composed of 2 networks: a volumetric encoder, <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="e_{3D}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">e</mi><mrow id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mn id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.1.1.3.1" xref="S3.SS3.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ğ‘’</ci><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><times id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.1"></times><cn type="integer" id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">3</cn><ci id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">e_{3D}</annotation></semantics></math>, and an iterative fully-connected regressor, <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="f^{reg}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msup id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">f</mi><mrow id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.2.m2.1.1.3.1" xref="S3.SS3.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.2.m2.1.1.3.1a" xref="S3.SS3.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.2.m2.1.1.3.4" xref="S3.SS3.p1.2.m2.1.1.3.4.cmml">g</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">ğ‘“</ci><apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3"><times id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3.1"></times><ci id="S3.SS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.SS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3">ğ‘’</ci><ci id="S3.SS3.p1.2.m2.1.1.3.4.cmml" xref="S3.SS3.p1.2.m2.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">f^{reg}</annotation></semantics></math>. The aggregated volumetric map is encoded into a <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="2\times 2\times 2" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mrow id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mn id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.3.m3.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.3.m3.1.1.1a" xref="S3.SS3.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="S3.SS3.p1.3.m3.1.1.4" xref="S3.SS3.p1.3.m3.1.1.4.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><times id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1"></times><cn type="integer" id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">2</cn><cn type="integer" id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">2</cn><cn type="integer" id="S3.SS3.p1.3.m3.1.1.4.cmml" xref="S3.SS3.p1.3.m3.1.1.4">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">2\times 2\times 2</annotation></semantics></math> volume, <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="V^{out}=e_{3D}(V^{in})" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mrow id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><msup id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml"><mi id="S3.SS3.p1.4.m4.1.1.3.2" xref="S3.SS3.p1.4.m4.1.1.3.2.cmml">V</mi><mrow id="S3.SS3.p1.4.m4.1.1.3.3" xref="S3.SS3.p1.4.m4.1.1.3.3.cmml"><mi id="S3.SS3.p1.4.m4.1.1.3.3.2" xref="S3.SS3.p1.4.m4.1.1.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.3.3.1" xref="S3.SS3.p1.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.4.m4.1.1.3.3.3" xref="S3.SS3.p1.4.m4.1.1.3.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.3.3.1a" xref="S3.SS3.p1.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.4.m4.1.1.3.3.4" xref="S3.SS3.p1.4.m4.1.1.3.3.4.cmml">t</mi></mrow></msup><mo id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">=</mo><mrow id="S3.SS3.p1.4.m4.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.cmml"><msub id="S3.SS3.p1.4.m4.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.1.3.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.3.2" xref="S3.SS3.p1.4.m4.1.1.1.3.2.cmml">e</mi><mrow id="S3.SS3.p1.4.m4.1.1.1.3.3" xref="S3.SS3.p1.4.m4.1.1.1.3.3.cmml"><mn id="S3.SS3.p1.4.m4.1.1.1.3.3.2" xref="S3.SS3.p1.4.m4.1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1.3.3.1" xref="S3.SS3.p1.4.m4.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.4.m4.1.1.1.3.3.3" xref="S3.SS3.p1.4.m4.1.1.1.3.3.3.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS3.p1.4.m4.1.1.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml">(</mo><msup id="S3.SS3.p1.4.m4.1.1.1.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.cmml">V</mi><mrow id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.3.cmml">n</mi></mrow></msup><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><eq id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2"></eq><apply id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.3.2">ğ‘‰</ci><apply id="S3.SS3.p1.4.m4.1.1.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3"><times id="S3.SS3.p1.4.m4.1.1.3.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3.1"></times><ci id="S3.SS3.p1.4.m4.1.1.3.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3.2">ğ‘œ</ci><ci id="S3.SS3.p1.4.m4.1.1.3.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3.3">ğ‘¢</ci><ci id="S3.SS3.p1.4.m4.1.1.3.3.4.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3.4">ğ‘¡</ci></apply></apply><apply id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1"><times id="S3.SS3.p1.4.m4.1.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.2"></times><apply id="S3.SS3.p1.4.m4.1.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.1.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3.2">ğ‘’</ci><apply id="S3.SS3.p1.4.m4.1.1.1.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3.3"><times id="S3.SS3.p1.4.m4.1.1.1.3.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3.3.1"></times><cn type="integer" id="S3.SS3.p1.4.m4.1.1.1.3.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3.3.2">3</cn><ci id="S3.SS3.p1.4.m4.1.1.1.3.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3.3.3">ğ·</ci></apply></apply><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1">superscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.2">ğ‘‰</ci><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3"><times id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.1"></times><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.2">ğ‘–</ci><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.3">ğ‘›</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">V^{out}=e_{3D}(V^{in})</annotation></semantics></math>. We then flatten the volume and obtain the final estimation, SMPL parameters <math id="S3.SS3.p1.5.m5.2" class="ltx_Math" alttext="\Theta=\{\theta,\beta\}" display="inline"><semantics id="S3.SS3.p1.5.m5.2a"><mrow id="S3.SS3.p1.5.m5.2.3" xref="S3.SS3.p1.5.m5.2.3.cmml"><mi mathvariant="normal" id="S3.SS3.p1.5.m5.2.3.2" xref="S3.SS3.p1.5.m5.2.3.2.cmml">Î˜</mi><mo id="S3.SS3.p1.5.m5.2.3.1" xref="S3.SS3.p1.5.m5.2.3.1.cmml">=</mo><mrow id="S3.SS3.p1.5.m5.2.3.3.2" xref="S3.SS3.p1.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS3.p1.5.m5.2.3.3.2.1" xref="S3.SS3.p1.5.m5.2.3.3.1.cmml">{</mo><mi id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">Î¸</mi><mo id="S3.SS3.p1.5.m5.2.3.3.2.2" xref="S3.SS3.p1.5.m5.2.3.3.1.cmml">,</mo><mi id="S3.SS3.p1.5.m5.2.2" xref="S3.SS3.p1.5.m5.2.2.cmml">Î²</mi><mo stretchy="false" id="S3.SS3.p1.5.m5.2.3.3.2.3" xref="S3.SS3.p1.5.m5.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.2b"><apply id="S3.SS3.p1.5.m5.2.3.cmml" xref="S3.SS3.p1.5.m5.2.3"><eq id="S3.SS3.p1.5.m5.2.3.1.cmml" xref="S3.SS3.p1.5.m5.2.3.1"></eq><ci id="S3.SS3.p1.5.m5.2.3.2.cmml" xref="S3.SS3.p1.5.m5.2.3.2">Î˜</ci><set id="S3.SS3.p1.5.m5.2.3.3.1.cmml" xref="S3.SS3.p1.5.m5.2.3.3.2"><ci id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">ğœƒ</ci><ci id="S3.SS3.p1.5.m5.2.2.cmml" xref="S3.SS3.p1.5.m5.2.2">ğ›½</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.2c">\Theta=\{\theta,\beta\}</annotation></semantics></math>, using fully connected layers. Inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, we use a similar iterative structure that estimates final SMPL parameters <math id="S3.SS3.p1.6.m6.2" class="ltx_Math" alttext="\Theta^{reg}=(\theta^{reg},\beta^{reg})" display="inline"><semantics id="S3.SS3.p1.6.m6.2a"><mrow id="S3.SS3.p1.6.m6.2.2" xref="S3.SS3.p1.6.m6.2.2.cmml"><msup id="S3.SS3.p1.6.m6.2.2.4" xref="S3.SS3.p1.6.m6.2.2.4.cmml"><mi mathvariant="normal" id="S3.SS3.p1.6.m6.2.2.4.2" xref="S3.SS3.p1.6.m6.2.2.4.2.cmml">Î˜</mi><mrow id="S3.SS3.p1.6.m6.2.2.4.3" xref="S3.SS3.p1.6.m6.2.2.4.3.cmml"><mi id="S3.SS3.p1.6.m6.2.2.4.3.2" xref="S3.SS3.p1.6.m6.2.2.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.6.m6.2.2.4.3.1" xref="S3.SS3.p1.6.m6.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.6.m6.2.2.4.3.3" xref="S3.SS3.p1.6.m6.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.6.m6.2.2.4.3.1a" xref="S3.SS3.p1.6.m6.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.6.m6.2.2.4.3.4" xref="S3.SS3.p1.6.m6.2.2.4.3.4.cmml">g</mi></mrow></msup><mo id="S3.SS3.p1.6.m6.2.2.3" xref="S3.SS3.p1.6.m6.2.2.3.cmml">=</mo><mrow id="S3.SS3.p1.6.m6.2.2.2.2" xref="S3.SS3.p1.6.m6.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p1.6.m6.2.2.2.2.3" xref="S3.SS3.p1.6.m6.2.2.2.3.cmml">(</mo><msup id="S3.SS3.p1.6.m6.1.1.1.1.1" xref="S3.SS3.p1.6.m6.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.6.m6.1.1.1.1.1.2" xref="S3.SS3.p1.6.m6.1.1.1.1.1.2.cmml">Î¸</mi><mrow id="S3.SS3.p1.6.m6.1.1.1.1.1.3" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p1.6.m6.1.1.1.1.1.3.2" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.6.m6.1.1.1.1.1.3.1" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.6.m6.1.1.1.1.1.3.3" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.6.m6.1.1.1.1.1.3.1a" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.6.m6.1.1.1.1.1.3.4" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.4.cmml">g</mi></mrow></msup><mo id="S3.SS3.p1.6.m6.2.2.2.2.4" xref="S3.SS3.p1.6.m6.2.2.2.3.cmml">,</mo><msup id="S3.SS3.p1.6.m6.2.2.2.2.2" xref="S3.SS3.p1.6.m6.2.2.2.2.2.cmml"><mi id="S3.SS3.p1.6.m6.2.2.2.2.2.2" xref="S3.SS3.p1.6.m6.2.2.2.2.2.2.cmml">Î²</mi><mrow id="S3.SS3.p1.6.m6.2.2.2.2.2.3" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.cmml"><mi id="S3.SS3.p1.6.m6.2.2.2.2.2.3.2" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.6.m6.2.2.2.2.2.3.1" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.6.m6.2.2.2.2.2.3.3" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.6.m6.2.2.2.2.2.3.1a" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.6.m6.2.2.2.2.2.3.4" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.4.cmml">g</mi></mrow></msup><mo stretchy="false" id="S3.SS3.p1.6.m6.2.2.2.2.5" xref="S3.SS3.p1.6.m6.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.2b"><apply id="S3.SS3.p1.6.m6.2.2.cmml" xref="S3.SS3.p1.6.m6.2.2"><eq id="S3.SS3.p1.6.m6.2.2.3.cmml" xref="S3.SS3.p1.6.m6.2.2.3"></eq><apply id="S3.SS3.p1.6.m6.2.2.4.cmml" xref="S3.SS3.p1.6.m6.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.2.2.4.1.cmml" xref="S3.SS3.p1.6.m6.2.2.4">superscript</csymbol><ci id="S3.SS3.p1.6.m6.2.2.4.2.cmml" xref="S3.SS3.p1.6.m6.2.2.4.2">Î˜</ci><apply id="S3.SS3.p1.6.m6.2.2.4.3.cmml" xref="S3.SS3.p1.6.m6.2.2.4.3"><times id="S3.SS3.p1.6.m6.2.2.4.3.1.cmml" xref="S3.SS3.p1.6.m6.2.2.4.3.1"></times><ci id="S3.SS3.p1.6.m6.2.2.4.3.2.cmml" xref="S3.SS3.p1.6.m6.2.2.4.3.2">ğ‘Ÿ</ci><ci id="S3.SS3.p1.6.m6.2.2.4.3.3.cmml" xref="S3.SS3.p1.6.m6.2.2.4.3.3">ğ‘’</ci><ci id="S3.SS3.p1.6.m6.2.2.4.3.4.cmml" xref="S3.SS3.p1.6.m6.2.2.4.3.4">ğ‘”</ci></apply></apply><interval closure="open" id="S3.SS3.p1.6.m6.2.2.2.3.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2"><apply id="S3.SS3.p1.6.m6.1.1.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1">superscript</csymbol><ci id="S3.SS3.p1.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.2">ğœƒ</ci><apply id="S3.SS3.p1.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3"><times id="S3.SS3.p1.6.m6.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.1"></times><ci id="S3.SS3.p1.6.m6.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.SS3.p1.6.m6.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.3">ğ‘’</ci><ci id="S3.SS3.p1.6.m6.1.1.1.1.1.3.4.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.4">ğ‘”</ci></apply></apply><apply id="S3.SS3.p1.6.m6.2.2.2.2.2.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2">superscript</csymbol><ci id="S3.SS3.p1.6.m6.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2.2">ğ›½</ci><apply id="S3.SS3.p1.6.m6.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3"><times id="S3.SS3.p1.6.m6.2.2.2.2.2.3.1.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.1"></times><ci id="S3.SS3.p1.6.m6.2.2.2.2.2.3.2.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.2">ğ‘Ÿ</ci><ci id="S3.SS3.p1.6.m6.2.2.2.2.2.3.3.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.3">ğ‘’</ci><ci id="S3.SS3.p1.6.m6.2.2.2.2.2.3.4.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.4">ğ‘”</ci></apply></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.2c">\Theta^{reg}=(\theta^{reg},\beta^{reg})</annotation></semantics></math> by iterative estimation: <math id="S3.SS3.p1.7.m7.1" class="ltx_Math" alttext="\Theta_{i+1}=\Theta_{i}+\Delta\Theta_{i}" display="inline"><semantics id="S3.SS3.p1.7.m7.1a"><mrow id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml"><msub id="S3.SS3.p1.7.m7.1.1.2" xref="S3.SS3.p1.7.m7.1.1.2.cmml"><mi mathvariant="normal" id="S3.SS3.p1.7.m7.1.1.2.2" xref="S3.SS3.p1.7.m7.1.1.2.2.cmml">Î˜</mi><mrow id="S3.SS3.p1.7.m7.1.1.2.3" xref="S3.SS3.p1.7.m7.1.1.2.3.cmml"><mi id="S3.SS3.p1.7.m7.1.1.2.3.2" xref="S3.SS3.p1.7.m7.1.1.2.3.2.cmml">i</mi><mo id="S3.SS3.p1.7.m7.1.1.2.3.1" xref="S3.SS3.p1.7.m7.1.1.2.3.1.cmml">+</mo><mn id="S3.SS3.p1.7.m7.1.1.2.3.3" xref="S3.SS3.p1.7.m7.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS3.p1.7.m7.1.1.1" xref="S3.SS3.p1.7.m7.1.1.1.cmml">=</mo><mrow id="S3.SS3.p1.7.m7.1.1.3" xref="S3.SS3.p1.7.m7.1.1.3.cmml"><msub id="S3.SS3.p1.7.m7.1.1.3.2" xref="S3.SS3.p1.7.m7.1.1.3.2.cmml"><mi mathvariant="normal" id="S3.SS3.p1.7.m7.1.1.3.2.2" xref="S3.SS3.p1.7.m7.1.1.3.2.2.cmml">Î˜</mi><mi id="S3.SS3.p1.7.m7.1.1.3.2.3" xref="S3.SS3.p1.7.m7.1.1.3.2.3.cmml">i</mi></msub><mo id="S3.SS3.p1.7.m7.1.1.3.1" xref="S3.SS3.p1.7.m7.1.1.3.1.cmml">+</mo><mrow id="S3.SS3.p1.7.m7.1.1.3.3" xref="S3.SS3.p1.7.m7.1.1.3.3.cmml"><mi mathvariant="normal" id="S3.SS3.p1.7.m7.1.1.3.3.2" xref="S3.SS3.p1.7.m7.1.1.3.3.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.7.m7.1.1.3.3.1" xref="S3.SS3.p1.7.m7.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.SS3.p1.7.m7.1.1.3.3.3" xref="S3.SS3.p1.7.m7.1.1.3.3.3.cmml"><mi mathvariant="normal" id="S3.SS3.p1.7.m7.1.1.3.3.3.2" xref="S3.SS3.p1.7.m7.1.1.3.3.3.2.cmml">Î˜</mi><mi id="S3.SS3.p1.7.m7.1.1.3.3.3.3" xref="S3.SS3.p1.7.m7.1.1.3.3.3.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><apply id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1"><eq id="S3.SS3.p1.7.m7.1.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1.1"></eq><apply id="S3.SS3.p1.7.m7.1.1.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.2.1.cmml" xref="S3.SS3.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.2.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2.2">Î˜</ci><apply id="S3.SS3.p1.7.m7.1.1.2.3.cmml" xref="S3.SS3.p1.7.m7.1.1.2.3"><plus id="S3.SS3.p1.7.m7.1.1.2.3.1.cmml" xref="S3.SS3.p1.7.m7.1.1.2.3.1"></plus><ci id="S3.SS3.p1.7.m7.1.1.2.3.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2.3.2">ğ‘–</ci><cn type="integer" id="S3.SS3.p1.7.m7.1.1.2.3.3.cmml" xref="S3.SS3.p1.7.m7.1.1.2.3.3">1</cn></apply></apply><apply id="S3.SS3.p1.7.m7.1.1.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3"><plus id="S3.SS3.p1.7.m7.1.1.3.1.cmml" xref="S3.SS3.p1.7.m7.1.1.3.1"></plus><apply id="S3.SS3.p1.7.m7.1.1.3.2.cmml" xref="S3.SS3.p1.7.m7.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.3.2.1.cmml" xref="S3.SS3.p1.7.m7.1.1.3.2">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.3.2.2.cmml" xref="S3.SS3.p1.7.m7.1.1.3.2.2">Î˜</ci><ci id="S3.SS3.p1.7.m7.1.1.3.2.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p1.7.m7.1.1.3.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3.3"><times id="S3.SS3.p1.7.m7.1.1.3.3.1.cmml" xref="S3.SS3.p1.7.m7.1.1.3.3.1"></times><ci id="S3.SS3.p1.7.m7.1.1.3.3.2.cmml" xref="S3.SS3.p1.7.m7.1.1.3.3.2">Î”</ci><apply id="S3.SS3.p1.7.m7.1.1.3.3.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.3.3.3.1.cmml" xref="S3.SS3.p1.7.m7.1.1.3.3.3">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.3.3.3.2.cmml" xref="S3.SS3.p1.7.m7.1.1.3.3.3.2">Î˜</ci><ci id="S3.SS3.p1.7.m7.1.1.3.3.3.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3.3.3.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">\Theta_{i+1}=\Theta_{i}+\Delta\Theta_{i}</annotation></semantics></math>. However, our model does not estimate camera translation, since we assume that the camera calibration is given. We finally reconstruct the 3D human body mesh with <math id="S3.SS3.p1.8.m8.1" class="ltx_Math" alttext="N=6890" display="inline"><semantics id="S3.SS3.p1.8.m8.1a"><mrow id="S3.SS3.p1.8.m8.1.1" xref="S3.SS3.p1.8.m8.1.1.cmml"><mi id="S3.SS3.p1.8.m8.1.1.2" xref="S3.SS3.p1.8.m8.1.1.2.cmml">N</mi><mo id="S3.SS3.p1.8.m8.1.1.1" xref="S3.SS3.p1.8.m8.1.1.1.cmml">=</mo><mn id="S3.SS3.p1.8.m8.1.1.3" xref="S3.SS3.p1.8.m8.1.1.3.cmml">6890</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b"><apply id="S3.SS3.p1.8.m8.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1"><eq id="S3.SS3.p1.8.m8.1.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1.1"></eq><ci id="S3.SS3.p1.8.m8.1.1.2.cmml" xref="S3.SS3.p1.8.m8.1.1.2">ğ‘</ci><cn type="integer" id="S3.SS3.p1.8.m8.1.1.3.cmml" xref="S3.SS3.p1.8.m8.1.1.3">6890</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">N=6890</annotation></semantics></math> vertices, <math id="S3.SS3.p1.9.m9.2" class="ltx_Math" alttext="M^{reg}=\mathcal{M}(\theta^{reg},\beta^{reg})" display="inline"><semantics id="S3.SS3.p1.9.m9.2a"><mrow id="S3.SS3.p1.9.m9.2.2" xref="S3.SS3.p1.9.m9.2.2.cmml"><msup id="S3.SS3.p1.9.m9.2.2.4" xref="S3.SS3.p1.9.m9.2.2.4.cmml"><mi id="S3.SS3.p1.9.m9.2.2.4.2" xref="S3.SS3.p1.9.m9.2.2.4.2.cmml">M</mi><mrow id="S3.SS3.p1.9.m9.2.2.4.3" xref="S3.SS3.p1.9.m9.2.2.4.3.cmml"><mi id="S3.SS3.p1.9.m9.2.2.4.3.2" xref="S3.SS3.p1.9.m9.2.2.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.9.m9.2.2.4.3.1" xref="S3.SS3.p1.9.m9.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.9.m9.2.2.4.3.3" xref="S3.SS3.p1.9.m9.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.9.m9.2.2.4.3.1a" xref="S3.SS3.p1.9.m9.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.9.m9.2.2.4.3.4" xref="S3.SS3.p1.9.m9.2.2.4.3.4.cmml">g</mi></mrow></msup><mo id="S3.SS3.p1.9.m9.2.2.3" xref="S3.SS3.p1.9.m9.2.2.3.cmml">=</mo><mrow id="S3.SS3.p1.9.m9.2.2.2" xref="S3.SS3.p1.9.m9.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.9.m9.2.2.2.4" xref="S3.SS3.p1.9.m9.2.2.2.4.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.9.m9.2.2.2.3" xref="S3.SS3.p1.9.m9.2.2.2.3.cmml">â€‹</mo><mrow id="S3.SS3.p1.9.m9.2.2.2.2.2" xref="S3.SS3.p1.9.m9.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p1.9.m9.2.2.2.2.2.3" xref="S3.SS3.p1.9.m9.2.2.2.2.3.cmml">(</mo><msup id="S3.SS3.p1.9.m9.1.1.1.1.1.1" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.9.m9.1.1.1.1.1.1.2" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.2.cmml">Î¸</mi><mrow id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.2" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.1" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.3" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.1a" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.4" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.4.cmml">g</mi></mrow></msup><mo id="S3.SS3.p1.9.m9.2.2.2.2.2.4" xref="S3.SS3.p1.9.m9.2.2.2.2.3.cmml">,</mo><msup id="S3.SS3.p1.9.m9.2.2.2.2.2.2" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.cmml"><mi id="S3.SS3.p1.9.m9.2.2.2.2.2.2.2" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.2.cmml">Î²</mi><mrow id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.cmml"><mi id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.2" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.1" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.3" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.1a" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.4" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.4.cmml">g</mi></mrow></msup><mo stretchy="false" id="S3.SS3.p1.9.m9.2.2.2.2.2.5" xref="S3.SS3.p1.9.m9.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m9.2b"><apply id="S3.SS3.p1.9.m9.2.2.cmml" xref="S3.SS3.p1.9.m9.2.2"><eq id="S3.SS3.p1.9.m9.2.2.3.cmml" xref="S3.SS3.p1.9.m9.2.2.3"></eq><apply id="S3.SS3.p1.9.m9.2.2.4.cmml" xref="S3.SS3.p1.9.m9.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m9.2.2.4.1.cmml" xref="S3.SS3.p1.9.m9.2.2.4">superscript</csymbol><ci id="S3.SS3.p1.9.m9.2.2.4.2.cmml" xref="S3.SS3.p1.9.m9.2.2.4.2">ğ‘€</ci><apply id="S3.SS3.p1.9.m9.2.2.4.3.cmml" xref="S3.SS3.p1.9.m9.2.2.4.3"><times id="S3.SS3.p1.9.m9.2.2.4.3.1.cmml" xref="S3.SS3.p1.9.m9.2.2.4.3.1"></times><ci id="S3.SS3.p1.9.m9.2.2.4.3.2.cmml" xref="S3.SS3.p1.9.m9.2.2.4.3.2">ğ‘Ÿ</ci><ci id="S3.SS3.p1.9.m9.2.2.4.3.3.cmml" xref="S3.SS3.p1.9.m9.2.2.4.3.3">ğ‘’</ci><ci id="S3.SS3.p1.9.m9.2.2.4.3.4.cmml" xref="S3.SS3.p1.9.m9.2.2.4.3.4">ğ‘”</ci></apply></apply><apply id="S3.SS3.p1.9.m9.2.2.2.cmml" xref="S3.SS3.p1.9.m9.2.2.2"><times id="S3.SS3.p1.9.m9.2.2.2.3.cmml" xref="S3.SS3.p1.9.m9.2.2.2.3"></times><ci id="S3.SS3.p1.9.m9.2.2.2.4.cmml" xref="S3.SS3.p1.9.m9.2.2.2.4">â„³</ci><interval closure="open" id="S3.SS3.p1.9.m9.2.2.2.2.3.cmml" xref="S3.SS3.p1.9.m9.2.2.2.2.2"><apply id="S3.SS3.p1.9.m9.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m9.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS3.p1.9.m9.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.2">ğœƒ</ci><apply id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3"><times id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.1"></times><ci id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.3">ğ‘’</ci><ci id="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.4.cmml" xref="S3.SS3.p1.9.m9.1.1.1.1.1.1.3.4">ğ‘”</ci></apply></apply><apply id="S3.SS3.p1.9.m9.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m9.2.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2">superscript</csymbol><ci id="S3.SS3.p1.9.m9.2.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.2">ğ›½</ci><apply id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3"><times id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.1.cmml" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.1"></times><ci id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.2.cmml" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.2">ğ‘Ÿ</ci><ci id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.3.cmml" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.3">ğ‘’</ci><ci id="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.4.cmml" xref="S3.SS3.p1.9.m9.2.2.2.2.2.2.3.4">ğ‘”</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m9.2c">M^{reg}=\mathcal{M}(\theta^{reg},\beta^{reg})</annotation></semantics></math>. We train our model in an end-to-end manner using common 2D and 3D supervisions:</p>
<table id="S3.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex3.m1.1" class="ltx_Math" alttext="L_{3D}=\big{|}\big{|}X_{3D}^{reg}-X_{3D}^{gt}\big{|}\big{|}," display="block"><semantics id="S3.Ex3.m1.1a"><mrow id="S3.Ex3.m1.1.1.1" xref="S3.Ex3.m1.1.1.1.1.cmml"><mrow id="S3.Ex3.m1.1.1.1.1" xref="S3.Ex3.m1.1.1.1.1.cmml"><msub id="S3.Ex3.m1.1.1.1.1.3" xref="S3.Ex3.m1.1.1.1.1.3.cmml"><mi id="S3.Ex3.m1.1.1.1.1.3.2" xref="S3.Ex3.m1.1.1.1.1.3.2.cmml">L</mi><mrow id="S3.Ex3.m1.1.1.1.1.3.3" xref="S3.Ex3.m1.1.1.1.1.3.3.cmml"><mn id="S3.Ex3.m1.1.1.1.1.3.3.2" xref="S3.Ex3.m1.1.1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.1.1.3.3.1" xref="S3.Ex3.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.1.1.3.3.3" xref="S3.Ex3.m1.1.1.1.1.3.3.3.cmml">D</mi></mrow></msub><mo id="S3.Ex3.m1.1.1.1.1.2" xref="S3.Ex3.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.Ex3.m1.1.1.1.1.1.1" xref="S3.Ex3.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.Ex3.m1.1.1.1.1.1.1.2" xref="S3.Ex3.m1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.Ex3.m1.1.1.1.1.1.1.1" xref="S3.Ex3.m1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.Ex3.m1.1.1.1.1.1.1.1.2" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.2" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.2.cmml">X</mi><mrow id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.cmml"><mn id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.2" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.1" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.3" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.3.cmml">D</mi></mrow><mrow id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.2" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.1" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.3" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.1a" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.4" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.4.cmml">g</mi></mrow></msubsup><mo id="S3.Ex3.m1.1.1.1.1.1.1.1.1" xref="S3.Ex3.m1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.Ex3.m1.1.1.1.1.1.1.1.3" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.2" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.2.cmml">X</mi><mrow id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.cmml"><mn id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.2" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.1" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.3" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.3.cmml">D</mi></mrow><mrow id="S3.Ex3.m1.1.1.1.1.1.1.1.3.3" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.2" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.1" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.3" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msubsup></mrow><mo stretchy="false" id="S3.Ex3.m1.1.1.1.1.1.1.3" xref="S3.Ex3.m1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow></mrow><mo id="S3.Ex3.m1.1.1.1.2" xref="S3.Ex3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex3.m1.1b"><apply id="S3.Ex3.m1.1.1.1.1.cmml" xref="S3.Ex3.m1.1.1.1"><eq id="S3.Ex3.m1.1.1.1.1.2.cmml" xref="S3.Ex3.m1.1.1.1.1.2"></eq><apply id="S3.Ex3.m1.1.1.1.1.3.cmml" xref="S3.Ex3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.1.1.3.1.cmml" xref="S3.Ex3.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex3.m1.1.1.1.1.3.2.cmml" xref="S3.Ex3.m1.1.1.1.1.3.2">ğ¿</ci><apply id="S3.Ex3.m1.1.1.1.1.3.3.cmml" xref="S3.Ex3.m1.1.1.1.1.3.3"><times id="S3.Ex3.m1.1.1.1.1.3.3.1.cmml" xref="S3.Ex3.m1.1.1.1.1.3.3.1"></times><cn type="integer" id="S3.Ex3.m1.1.1.1.1.3.3.2.cmml" xref="S3.Ex3.m1.1.1.1.1.3.3.2">3</cn><ci id="S3.Ex3.m1.1.1.1.1.3.3.3.cmml" xref="S3.Ex3.m1.1.1.1.1.3.3.3">ğ·</ci></apply></apply><apply id="S3.Ex3.m1.1.1.1.1.1.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex3.m1.1.1.1.1.1.2.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.Ex3.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1"><minus id="S3.Ex3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.1"></minus><apply id="S3.Ex3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.2">ğ‘‹</ci><apply id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3"><times id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.1"></times><cn type="integer" id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.2">3</cn><ci id="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.2.3.3">ğ·</ci></apply></apply><apply id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3"><times id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.2">ğ‘Ÿ</ci><ci id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.3">ğ‘’</ci><ci id="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.2.3.4">ğ‘”</ci></apply></apply><apply id="S3.Ex3.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.2">ğ‘‹</ci><apply id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3"><times id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.1"></times><cn type="integer" id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.2">3</cn><ci id="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.2.3.3">ğ·</ci></apply></apply><apply id="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.3"><times id="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.2">ğ‘”</ci><ci id="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.Ex3.m1.1.1.1.1.1.1.1.3.3.3">ğ‘¡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex3.m1.1c">L_{3D}=\big{|}\big{|}X_{3D}^{reg}-X_{3D}^{gt}\big{|}\big{|},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S3.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex4.m1.5" class="ltx_Math" alttext="L_{2D}=\sum_{c}\big{|}\big{|}X_{c,2D}^{reg}-X_{c,2D}^{gt}\big{|}\big{|}," display="block"><semantics id="S3.Ex4.m1.5a"><mrow id="S3.Ex4.m1.5.5.1" xref="S3.Ex4.m1.5.5.1.1.cmml"><mrow id="S3.Ex4.m1.5.5.1.1" xref="S3.Ex4.m1.5.5.1.1.cmml"><msub id="S3.Ex4.m1.5.5.1.1.3" xref="S3.Ex4.m1.5.5.1.1.3.cmml"><mi id="S3.Ex4.m1.5.5.1.1.3.2" xref="S3.Ex4.m1.5.5.1.1.3.2.cmml">L</mi><mrow id="S3.Ex4.m1.5.5.1.1.3.3" xref="S3.Ex4.m1.5.5.1.1.3.3.cmml"><mn id="S3.Ex4.m1.5.5.1.1.3.3.2" xref="S3.Ex4.m1.5.5.1.1.3.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.Ex4.m1.5.5.1.1.3.3.1" xref="S3.Ex4.m1.5.5.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex4.m1.5.5.1.1.3.3.3" xref="S3.Ex4.m1.5.5.1.1.3.3.3.cmml">D</mi></mrow></msub><mo rspace="0.111em" id="S3.Ex4.m1.5.5.1.1.2" xref="S3.Ex4.m1.5.5.1.1.2.cmml">=</mo><mrow id="S3.Ex4.m1.5.5.1.1.1" xref="S3.Ex4.m1.5.5.1.1.1.cmml"><munder id="S3.Ex4.m1.5.5.1.1.1.2" xref="S3.Ex4.m1.5.5.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.Ex4.m1.5.5.1.1.1.2.2" xref="S3.Ex4.m1.5.5.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S3.Ex4.m1.5.5.1.1.1.2.3" xref="S3.Ex4.m1.5.5.1.1.1.2.3.cmml">c</mi></munder><mrow id="S3.Ex4.m1.5.5.1.1.1.1.1" xref="S3.Ex4.m1.5.5.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.Ex4.m1.5.5.1.1.1.1.1.2" xref="S3.Ex4.m1.5.5.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.Ex4.m1.5.5.1.1.1.1.1.1" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.cmml"><msubsup id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.2.2" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.2.2.cmml">X</mi><mrow id="S3.Ex4.m1.2.2.2.2" xref="S3.Ex4.m1.2.2.2.3.cmml"><mi id="S3.Ex4.m1.1.1.1.1" xref="S3.Ex4.m1.1.1.1.1.cmml">c</mi><mo id="S3.Ex4.m1.2.2.2.2.2" xref="S3.Ex4.m1.2.2.2.3.cmml">,</mo><mrow id="S3.Ex4.m1.2.2.2.2.1" xref="S3.Ex4.m1.2.2.2.2.1.cmml"><mn id="S3.Ex4.m1.2.2.2.2.1.2" xref="S3.Ex4.m1.2.2.2.2.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.Ex4.m1.2.2.2.2.1.1" xref="S3.Ex4.m1.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.Ex4.m1.2.2.2.2.1.3" xref="S3.Ex4.m1.2.2.2.2.1.3.cmml">D</mi></mrow></mrow><mrow id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.cmml"><mi id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.2" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.1" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.3" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.1a" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.4" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.4.cmml">g</mi></mrow></msubsup><mo id="S3.Ex4.m1.5.5.1.1.1.1.1.1.1" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.2.2" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.2.2.cmml">X</mi><mrow id="S3.Ex4.m1.4.4.2.2" xref="S3.Ex4.m1.4.4.2.3.cmml"><mi id="S3.Ex4.m1.3.3.1.1" xref="S3.Ex4.m1.3.3.1.1.cmml">c</mi><mo id="S3.Ex4.m1.4.4.2.2.2" xref="S3.Ex4.m1.4.4.2.3.cmml">,</mo><mrow id="S3.Ex4.m1.4.4.2.2.1" xref="S3.Ex4.m1.4.4.2.2.1.cmml"><mn id="S3.Ex4.m1.4.4.2.2.1.2" xref="S3.Ex4.m1.4.4.2.2.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.Ex4.m1.4.4.2.2.1.1" xref="S3.Ex4.m1.4.4.2.2.1.1.cmml">â€‹</mo><mi id="S3.Ex4.m1.4.4.2.2.1.3" xref="S3.Ex4.m1.4.4.2.2.1.3.cmml">D</mi></mrow></mrow><mrow id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.cmml"><mi id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.2" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.1" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.3" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msubsup></mrow><mo stretchy="false" id="S3.Ex4.m1.5.5.1.1.1.1.1.3" xref="S3.Ex4.m1.5.5.1.1.1.1.2.1.cmml">â€–</mo></mrow></mrow></mrow><mo id="S3.Ex4.m1.5.5.1.2" xref="S3.Ex4.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex4.m1.5b"><apply id="S3.Ex4.m1.5.5.1.1.cmml" xref="S3.Ex4.m1.5.5.1"><eq id="S3.Ex4.m1.5.5.1.1.2.cmml" xref="S3.Ex4.m1.5.5.1.1.2"></eq><apply id="S3.Ex4.m1.5.5.1.1.3.cmml" xref="S3.Ex4.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.5.5.1.1.3.1.cmml" xref="S3.Ex4.m1.5.5.1.1.3">subscript</csymbol><ci id="S3.Ex4.m1.5.5.1.1.3.2.cmml" xref="S3.Ex4.m1.5.5.1.1.3.2">ğ¿</ci><apply id="S3.Ex4.m1.5.5.1.1.3.3.cmml" xref="S3.Ex4.m1.5.5.1.1.3.3"><times id="S3.Ex4.m1.5.5.1.1.3.3.1.cmml" xref="S3.Ex4.m1.5.5.1.1.3.3.1"></times><cn type="integer" id="S3.Ex4.m1.5.5.1.1.3.3.2.cmml" xref="S3.Ex4.m1.5.5.1.1.3.3.2">2</cn><ci id="S3.Ex4.m1.5.5.1.1.3.3.3.cmml" xref="S3.Ex4.m1.5.5.1.1.3.3.3">ğ·</ci></apply></apply><apply id="S3.Ex4.m1.5.5.1.1.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1"><apply id="S3.Ex4.m1.5.5.1.1.1.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.5.5.1.1.1.2.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.2">subscript</csymbol><sum id="S3.Ex4.m1.5.5.1.1.1.2.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.2.2"></sum><ci id="S3.Ex4.m1.5.5.1.1.1.2.3.cmml" xref="S3.Ex4.m1.5.5.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.Ex4.m1.5.5.1.1.1.1.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex4.m1.5.5.1.1.1.1.2.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.2">norm</csymbol><apply id="S3.Ex4.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1"><minus id="S3.Ex4.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.1"></minus><apply id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.2.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.2.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.2.2">ğ‘‹</ci><list id="S3.Ex4.m1.2.2.2.3.cmml" xref="S3.Ex4.m1.2.2.2.2"><ci id="S3.Ex4.m1.1.1.1.1.cmml" xref="S3.Ex4.m1.1.1.1.1">ğ‘</ci><apply id="S3.Ex4.m1.2.2.2.2.1.cmml" xref="S3.Ex4.m1.2.2.2.2.1"><times id="S3.Ex4.m1.2.2.2.2.1.1.cmml" xref="S3.Ex4.m1.2.2.2.2.1.1"></times><cn type="integer" id="S3.Ex4.m1.2.2.2.2.1.2.cmml" xref="S3.Ex4.m1.2.2.2.2.1.2">2</cn><ci id="S3.Ex4.m1.2.2.2.2.1.3.cmml" xref="S3.Ex4.m1.2.2.2.2.1.3">ğ·</ci></apply></list></apply><apply id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3"><times id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.1"></times><ci id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.2">ğ‘Ÿ</ci><ci id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.3.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.3">ğ‘’</ci><ci id="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.4.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.2.3.4">ğ‘”</ci></apply></apply><apply id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.2.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.2.2">ğ‘‹</ci><list id="S3.Ex4.m1.4.4.2.3.cmml" xref="S3.Ex4.m1.4.4.2.2"><ci id="S3.Ex4.m1.3.3.1.1.cmml" xref="S3.Ex4.m1.3.3.1.1">ğ‘</ci><apply id="S3.Ex4.m1.4.4.2.2.1.cmml" xref="S3.Ex4.m1.4.4.2.2.1"><times id="S3.Ex4.m1.4.4.2.2.1.1.cmml" xref="S3.Ex4.m1.4.4.2.2.1.1"></times><cn type="integer" id="S3.Ex4.m1.4.4.2.2.1.2.cmml" xref="S3.Ex4.m1.4.4.2.2.1.2">2</cn><ci id="S3.Ex4.m1.4.4.2.2.1.3.cmml" xref="S3.Ex4.m1.4.4.2.2.1.3">ğ·</ci></apply></list></apply><apply id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3"><times id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.1.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.1"></times><ci id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.2.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.2">ğ‘”</ci><ci id="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.3.cmml" xref="S3.Ex4.m1.5.5.1.1.1.1.1.1.3.3.3">ğ‘¡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex4.m1.5c">L_{2D}=\sum_{c}\big{|}\big{|}X_{c,2D}^{reg}-X_{c,2D}^{gt}\big{|}\big{|},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.10" class="ltx_p">where predicted 3D and 2D joint locations are computed by the pretrained joint regressor <math id="S3.SS3.p1.10.m1.1" class="ltx_Math" alttext="\mathcal{W}" display="inline"><semantics id="S3.SS3.p1.10.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.10.m1.1.1" xref="S3.SS3.p1.10.m1.1.1.cmml">ğ’²</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.10.m1.1b"><ci id="S3.SS3.p1.10.m1.1.1.cmml" xref="S3.SS3.p1.10.m1.1.1">ğ’²</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.10.m1.1c">\mathcal{W}</annotation></semantics></math>:</p>
<table id="S3.Ex5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex5.m1.3" class="ltx_Math" alttext="X_{3D}^{reg}=\mathcal{W}(M^{reg}),\hskip 8.53581ptX_{c,2D}^{reg}=P_{c}X_{3D}^{reg}," display="block"><semantics id="S3.Ex5.m1.3a"><mrow id="S3.Ex5.m1.3.3.1"><mrow id="S3.Ex5.m1.3.3.1.1.2" xref="S3.Ex5.m1.3.3.1.1.3.cmml"><mrow id="S3.Ex5.m1.3.3.1.1.1.1" xref="S3.Ex5.m1.3.3.1.1.1.1.cmml"><msubsup id="S3.Ex5.m1.3.3.1.1.1.1.3" xref="S3.Ex5.m1.3.3.1.1.1.1.3.cmml"><mi id="S3.Ex5.m1.3.3.1.1.1.1.3.2.2" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.2.cmml">X</mi><mrow id="S3.Ex5.m1.3.3.1.1.1.1.3.2.3" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.cmml"><mn id="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.2" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.1" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.3" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.3.cmml">D</mi></mrow><mrow id="S3.Ex5.m1.3.3.1.1.1.1.3.3" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.cmml"><mi id="S3.Ex5.m1.3.3.1.1.1.1.3.3.2" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.1.1.3.3.1" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.1.1.3.3.3" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.1.1.3.3.1a" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.1.1.3.3.4" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.4.cmml">g</mi></mrow></msubsup><mo id="S3.Ex5.m1.3.3.1.1.1.1.2" xref="S3.Ex5.m1.3.3.1.1.1.1.2.cmml">=</mo><mrow id="S3.Ex5.m1.3.3.1.1.1.1.1" xref="S3.Ex5.m1.3.3.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex5.m1.3.3.1.1.1.1.1.3" xref="S3.Ex5.m1.3.3.1.1.1.1.1.3.cmml">ğ’²</mi><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.1.1.1.2" xref="S3.Ex5.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">M</mi><mrow id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.2" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.1" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.3" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.1a" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.4" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.4.cmml">g</mi></mrow></msup><mo stretchy="false" id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo rspace="1.017em" id="S3.Ex5.m1.3.3.1.1.2.3" xref="S3.Ex5.m1.3.3.1.1.3a.cmml">,</mo><mrow id="S3.Ex5.m1.3.3.1.1.2.2" xref="S3.Ex5.m1.3.3.1.1.2.2.cmml"><msubsup id="S3.Ex5.m1.3.3.1.1.2.2.2" xref="S3.Ex5.m1.3.3.1.1.2.2.2.cmml"><mi id="S3.Ex5.m1.3.3.1.1.2.2.2.2.2" xref="S3.Ex5.m1.3.3.1.1.2.2.2.2.2.cmml">X</mi><mrow id="S3.Ex5.m1.2.2.2.2" xref="S3.Ex5.m1.2.2.2.3.cmml"><mi id="S3.Ex5.m1.1.1.1.1" xref="S3.Ex5.m1.1.1.1.1.cmml">c</mi><mo id="S3.Ex5.m1.2.2.2.2.2" xref="S3.Ex5.m1.2.2.2.3.cmml">,</mo><mrow id="S3.Ex5.m1.2.2.2.2.1" xref="S3.Ex5.m1.2.2.2.2.1.cmml"><mn id="S3.Ex5.m1.2.2.2.2.1.2" xref="S3.Ex5.m1.2.2.2.2.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.2.2.2.2.1.1" xref="S3.Ex5.m1.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.2.2.2.2.1.3" xref="S3.Ex5.m1.2.2.2.2.1.3.cmml">D</mi></mrow></mrow><mrow id="S3.Ex5.m1.3.3.1.1.2.2.2.3" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.cmml"><mi id="S3.Ex5.m1.3.3.1.1.2.2.2.3.2" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.2.2.2.3.1" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.2.2.2.3.3" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.2.2.2.3.1a" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.2.2.2.3.4" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.4.cmml">g</mi></mrow></msubsup><mo id="S3.Ex5.m1.3.3.1.1.2.2.1" xref="S3.Ex5.m1.3.3.1.1.2.2.1.cmml">=</mo><mrow id="S3.Ex5.m1.3.3.1.1.2.2.3" xref="S3.Ex5.m1.3.3.1.1.2.2.3.cmml"><msub id="S3.Ex5.m1.3.3.1.1.2.2.3.2" xref="S3.Ex5.m1.3.3.1.1.2.2.3.2.cmml"><mi id="S3.Ex5.m1.3.3.1.1.2.2.3.2.2" xref="S3.Ex5.m1.3.3.1.1.2.2.3.2.2.cmml">P</mi><mi id="S3.Ex5.m1.3.3.1.1.2.2.3.2.3" xref="S3.Ex5.m1.3.3.1.1.2.2.3.2.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.2.2.3.1" xref="S3.Ex5.m1.3.3.1.1.2.2.3.1.cmml">â€‹</mo><msubsup id="S3.Ex5.m1.3.3.1.1.2.2.3.3" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.cmml"><mi id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.2" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.2.cmml">X</mi><mrow id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.cmml"><mn id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.2" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.1" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.3" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.3.cmml">D</mi></mrow><mrow id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.cmml"><mi id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.2" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.1" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.3" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.1a" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.4" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.4.cmml">g</mi></mrow></msubsup></mrow></mrow></mrow><mo id="S3.Ex5.m1.3.3.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex5.m1.3b"><apply id="S3.Ex5.m1.3.3.1.1.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.Ex5.m1.3.3.1.1.3a.cmml" xref="S3.Ex5.m1.3.3.1.1.2.3">formulae-sequence</csymbol><apply id="S3.Ex5.m1.3.3.1.1.1.1.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1"><eq id="S3.Ex5.m1.3.3.1.1.1.1.2.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.2"></eq><apply id="S3.Ex5.m1.3.3.1.1.1.1.3.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex5.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3">superscript</csymbol><apply id="S3.Ex5.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex5.m1.3.3.1.1.1.1.3.2.1.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex5.m1.3.3.1.1.1.1.3.2.2.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.2">ğ‘‹</ci><apply id="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.3"><times id="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.1.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.1"></times><cn type="integer" id="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.2.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.2">3</cn><ci id="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.3.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.2.3.3">ğ·</ci></apply></apply><apply id="S3.Ex5.m1.3.3.1.1.1.1.3.3.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3"><times id="S3.Ex5.m1.3.3.1.1.1.1.3.3.1.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.1"></times><ci id="S3.Ex5.m1.3.3.1.1.1.1.3.3.2.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.2">ğ‘Ÿ</ci><ci id="S3.Ex5.m1.3.3.1.1.1.1.3.3.3.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.3">ğ‘’</ci><ci id="S3.Ex5.m1.3.3.1.1.1.1.3.3.4.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.3.3.4">ğ‘”</ci></apply></apply><apply id="S3.Ex5.m1.3.3.1.1.1.1.1.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1"><times id="S3.Ex5.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.2"></times><ci id="S3.Ex5.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.3">ğ’²</ci><apply id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.2">ğ‘€</ci><apply id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3"><times id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.3">ğ‘’</ci><ci id="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.Ex5.m1.3.3.1.1.1.1.1.1.1.1.3.4">ğ‘”</ci></apply></apply></apply></apply><apply id="S3.Ex5.m1.3.3.1.1.2.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2"><eq id="S3.Ex5.m1.3.3.1.1.2.2.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.1"></eq><apply id="S3.Ex5.m1.3.3.1.1.2.2.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.Ex5.m1.3.3.1.1.2.2.2.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2">superscript</csymbol><apply id="S3.Ex5.m1.3.3.1.1.2.2.2.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.Ex5.m1.3.3.1.1.2.2.2.2.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2">subscript</csymbol><ci id="S3.Ex5.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2.2.2">ğ‘‹</ci><list id="S3.Ex5.m1.2.2.2.3.cmml" xref="S3.Ex5.m1.2.2.2.2"><ci id="S3.Ex5.m1.1.1.1.1.cmml" xref="S3.Ex5.m1.1.1.1.1">ğ‘</ci><apply id="S3.Ex5.m1.2.2.2.2.1.cmml" xref="S3.Ex5.m1.2.2.2.2.1"><times id="S3.Ex5.m1.2.2.2.2.1.1.cmml" xref="S3.Ex5.m1.2.2.2.2.1.1"></times><cn type="integer" id="S3.Ex5.m1.2.2.2.2.1.2.cmml" xref="S3.Ex5.m1.2.2.2.2.1.2">2</cn><ci id="S3.Ex5.m1.2.2.2.2.1.3.cmml" xref="S3.Ex5.m1.2.2.2.2.1.3">ğ·</ci></apply></list></apply><apply id="S3.Ex5.m1.3.3.1.1.2.2.2.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3"><times id="S3.Ex5.m1.3.3.1.1.2.2.2.3.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.1"></times><ci id="S3.Ex5.m1.3.3.1.1.2.2.2.3.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.2">ğ‘Ÿ</ci><ci id="S3.Ex5.m1.3.3.1.1.2.2.2.3.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.3">ğ‘’</ci><ci id="S3.Ex5.m1.3.3.1.1.2.2.2.3.4.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.2.3.4">ğ‘”</ci></apply></apply><apply id="S3.Ex5.m1.3.3.1.1.2.2.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3"><times id="S3.Ex5.m1.3.3.1.1.2.2.3.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.1"></times><apply id="S3.Ex5.m1.3.3.1.1.2.2.3.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.2"><csymbol cd="ambiguous" id="S3.Ex5.m1.3.3.1.1.2.2.3.2.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.2">subscript</csymbol><ci id="S3.Ex5.m1.3.3.1.1.2.2.3.2.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.2.2">ğ‘ƒ</ci><ci id="S3.Ex5.m1.3.3.1.1.2.2.3.2.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.2.3">ğ‘</ci></apply><apply id="S3.Ex5.m1.3.3.1.1.2.2.3.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S3.Ex5.m1.3.3.1.1.2.2.3.3.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3">superscript</csymbol><apply id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3">subscript</csymbol><ci id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.2">ğ‘‹</ci><apply id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3"><times id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.1"></times><cn type="integer" id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.2">3</cn><ci id="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.2.3.3">ğ·</ci></apply></apply><apply id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3"><times id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.1.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.1"></times><ci id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.2.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.2">ğ‘Ÿ</ci><ci id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.3.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.3">ğ‘’</ci><ci id="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.4.cmml" xref="S3.Ex5.m1.3.3.1.1.2.2.3.3.3.4">ğ‘”</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex5.m1.3c">X_{3D}^{reg}=\mathcal{W}(M^{reg}),\hskip 8.53581ptX_{c,2D}^{reg}=P_{c}X_{3D}^{reg},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.12" class="ltx_p">where <math id="S3.SS3.p1.11.m1.1" class="ltx_Math" alttext="P_{c}" display="inline"><semantics id="S3.SS3.p1.11.m1.1a"><msub id="S3.SS3.p1.11.m1.1.1" xref="S3.SS3.p1.11.m1.1.1.cmml"><mi id="S3.SS3.p1.11.m1.1.1.2" xref="S3.SS3.p1.11.m1.1.1.2.cmml">P</mi><mi id="S3.SS3.p1.11.m1.1.1.3" xref="S3.SS3.p1.11.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.11.m1.1b"><apply id="S3.SS3.p1.11.m1.1.1.cmml" xref="S3.SS3.p1.11.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.11.m1.1.1.1.cmml" xref="S3.SS3.p1.11.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.11.m1.1.1.2.cmml" xref="S3.SS3.p1.11.m1.1.1.2">ğ‘ƒ</ci><ci id="S3.SS3.p1.11.m1.1.1.3.cmml" xref="S3.SS3.p1.11.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.11.m1.1c">P_{c}</annotation></semantics></math> is the projection matrix of camera <math id="S3.SS3.p1.12.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS3.p1.12.m2.1a"><mi id="S3.SS3.p1.12.m2.1.1" xref="S3.SS3.p1.12.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.12.m2.1b"><ci id="S3.SS3.p1.12.m2.1.1.cmml" xref="S3.SS3.p1.12.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.12.m2.1c">c</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.5" class="ltx_p">We also train our model with a loss term on SMPL parameters, which is beneficial for two reasons: (1) it is linear to our model prediction and (2) it can weakly penalize infeasible poses and shapes, since the labels are generated from a similar algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> that uses a pose and shape prior function.</p>
<table id="S3.Ex6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex6.m1.1" class="ltx_Math" alttext="L_{\Theta}=\big{|}\big{|}\Theta^{reg}-\Theta^{gt}\big{|}\big{|}" display="block"><semantics id="S3.Ex6.m1.1a"><mrow id="S3.Ex6.m1.1.1" xref="S3.Ex6.m1.1.1.cmml"><msub id="S3.Ex6.m1.1.1.3" xref="S3.Ex6.m1.1.1.3.cmml"><mi id="S3.Ex6.m1.1.1.3.2" xref="S3.Ex6.m1.1.1.3.2.cmml">L</mi><mi mathvariant="normal" id="S3.Ex6.m1.1.1.3.3" xref="S3.Ex6.m1.1.1.3.3.cmml">Î˜</mi></msub><mo id="S3.Ex6.m1.1.1.2" xref="S3.Ex6.m1.1.1.2.cmml">=</mo><mrow id="S3.Ex6.m1.1.1.1.1" xref="S3.Ex6.m1.1.1.1.2.cmml"><mo stretchy="false" id="S3.Ex6.m1.1.1.1.1.2" xref="S3.Ex6.m1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.Ex6.m1.1.1.1.1.1" xref="S3.Ex6.m1.1.1.1.1.1.cmml"><msup id="S3.Ex6.m1.1.1.1.1.1.2" xref="S3.Ex6.m1.1.1.1.1.1.2.cmml"><mi mathvariant="normal" id="S3.Ex6.m1.1.1.1.1.1.2.2" xref="S3.Ex6.m1.1.1.1.1.1.2.2.cmml">Î˜</mi><mrow id="S3.Ex6.m1.1.1.1.1.1.2.3" xref="S3.Ex6.m1.1.1.1.1.1.2.3.cmml"><mi id="S3.Ex6.m1.1.1.1.1.1.2.3.2" xref="S3.Ex6.m1.1.1.1.1.1.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.Ex6.m1.1.1.1.1.1.2.3.1" xref="S3.Ex6.m1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex6.m1.1.1.1.1.1.2.3.3" xref="S3.Ex6.m1.1.1.1.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex6.m1.1.1.1.1.1.2.3.1a" xref="S3.Ex6.m1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex6.m1.1.1.1.1.1.2.3.4" xref="S3.Ex6.m1.1.1.1.1.1.2.3.4.cmml">g</mi></mrow></msup><mo id="S3.Ex6.m1.1.1.1.1.1.1" xref="S3.Ex6.m1.1.1.1.1.1.1.cmml">âˆ’</mo><msup id="S3.Ex6.m1.1.1.1.1.1.3" xref="S3.Ex6.m1.1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S3.Ex6.m1.1.1.1.1.1.3.2" xref="S3.Ex6.m1.1.1.1.1.1.3.2.cmml">Î˜</mi><mrow id="S3.Ex6.m1.1.1.1.1.1.3.3" xref="S3.Ex6.m1.1.1.1.1.1.3.3.cmml"><mi id="S3.Ex6.m1.1.1.1.1.1.3.3.2" xref="S3.Ex6.m1.1.1.1.1.1.3.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.Ex6.m1.1.1.1.1.1.3.3.1" xref="S3.Ex6.m1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.Ex6.m1.1.1.1.1.1.3.3.3" xref="S3.Ex6.m1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msup></mrow><mo stretchy="false" id="S3.Ex6.m1.1.1.1.1.3" xref="S3.Ex6.m1.1.1.1.2.1.cmml">â€–</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex6.m1.1b"><apply id="S3.Ex6.m1.1.1.cmml" xref="S3.Ex6.m1.1.1"><eq id="S3.Ex6.m1.1.1.2.cmml" xref="S3.Ex6.m1.1.1.2"></eq><apply id="S3.Ex6.m1.1.1.3.cmml" xref="S3.Ex6.m1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex6.m1.1.1.3.1.cmml" xref="S3.Ex6.m1.1.1.3">subscript</csymbol><ci id="S3.Ex6.m1.1.1.3.2.cmml" xref="S3.Ex6.m1.1.1.3.2">ğ¿</ci><ci id="S3.Ex6.m1.1.1.3.3.cmml" xref="S3.Ex6.m1.1.1.3.3">Î˜</ci></apply><apply id="S3.Ex6.m1.1.1.1.2.cmml" xref="S3.Ex6.m1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex6.m1.1.1.1.2.1.cmml" xref="S3.Ex6.m1.1.1.1.1.2">norm</csymbol><apply id="S3.Ex6.m1.1.1.1.1.1.cmml" xref="S3.Ex6.m1.1.1.1.1.1"><minus id="S3.Ex6.m1.1.1.1.1.1.1.cmml" xref="S3.Ex6.m1.1.1.1.1.1.1"></minus><apply id="S3.Ex6.m1.1.1.1.1.1.2.cmml" xref="S3.Ex6.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex6.m1.1.1.1.1.1.2.1.cmml" xref="S3.Ex6.m1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.Ex6.m1.1.1.1.1.1.2.2.cmml" xref="S3.Ex6.m1.1.1.1.1.1.2.2">Î˜</ci><apply id="S3.Ex6.m1.1.1.1.1.1.2.3.cmml" xref="S3.Ex6.m1.1.1.1.1.1.2.3"><times id="S3.Ex6.m1.1.1.1.1.1.2.3.1.cmml" xref="S3.Ex6.m1.1.1.1.1.1.2.3.1"></times><ci id="S3.Ex6.m1.1.1.1.1.1.2.3.2.cmml" xref="S3.Ex6.m1.1.1.1.1.1.2.3.2">ğ‘Ÿ</ci><ci id="S3.Ex6.m1.1.1.1.1.1.2.3.3.cmml" xref="S3.Ex6.m1.1.1.1.1.1.2.3.3">ğ‘’</ci><ci id="S3.Ex6.m1.1.1.1.1.1.2.3.4.cmml" xref="S3.Ex6.m1.1.1.1.1.1.2.3.4">ğ‘”</ci></apply></apply><apply id="S3.Ex6.m1.1.1.1.1.1.3.cmml" xref="S3.Ex6.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex6.m1.1.1.1.1.1.3.1.cmml" xref="S3.Ex6.m1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.Ex6.m1.1.1.1.1.1.3.2.cmml" xref="S3.Ex6.m1.1.1.1.1.1.3.2">Î˜</ci><apply id="S3.Ex6.m1.1.1.1.1.1.3.3.cmml" xref="S3.Ex6.m1.1.1.1.1.1.3.3"><times id="S3.Ex6.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.Ex6.m1.1.1.1.1.1.3.3.1"></times><ci id="S3.Ex6.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.Ex6.m1.1.1.1.1.1.3.3.2">ğ‘”</ci><ci id="S3.Ex6.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.Ex6.m1.1.1.1.1.1.3.3.3">ğ‘¡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex6.m1.1c">L_{\Theta}=\big{|}\big{|}\Theta^{reg}-\Theta^{gt}\big{|}\big{|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.1" class="ltx_p">This loss is applied when the ground truth SMPL parameters <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="\Theta^{gt}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msup id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">Î˜</mi><mrow id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">Î˜</ci><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><times id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.1"></times><ci id="S3.SS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.2">ğ‘”</ci><ci id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\Theta^{gt}</annotation></semantics></math> are available. Otherwise, we use explicit prior terms, as given below:</p>
<table id="S3.Ex7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex7.m1.1" class="ltx_Math" alttext="L_{prior}=L_{\theta}+L_{\beta}." display="block"><semantics id="S3.Ex7.m1.1a"><mrow id="S3.Ex7.m1.1.1.1" xref="S3.Ex7.m1.1.1.1.1.cmml"><mrow id="S3.Ex7.m1.1.1.1.1" xref="S3.Ex7.m1.1.1.1.1.cmml"><msub id="S3.Ex7.m1.1.1.1.1.2" xref="S3.Ex7.m1.1.1.1.1.2.cmml"><mi id="S3.Ex7.m1.1.1.1.1.2.2" xref="S3.Ex7.m1.1.1.1.1.2.2.cmml">L</mi><mrow id="S3.Ex7.m1.1.1.1.1.2.3" xref="S3.Ex7.m1.1.1.1.1.2.3.cmml"><mi id="S3.Ex7.m1.1.1.1.1.2.3.2" xref="S3.Ex7.m1.1.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.Ex7.m1.1.1.1.1.2.3.1" xref="S3.Ex7.m1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex7.m1.1.1.1.1.2.3.3" xref="S3.Ex7.m1.1.1.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.Ex7.m1.1.1.1.1.2.3.1a" xref="S3.Ex7.m1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex7.m1.1.1.1.1.2.3.4" xref="S3.Ex7.m1.1.1.1.1.2.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.Ex7.m1.1.1.1.1.2.3.1b" xref="S3.Ex7.m1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex7.m1.1.1.1.1.2.3.5" xref="S3.Ex7.m1.1.1.1.1.2.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.Ex7.m1.1.1.1.1.2.3.1c" xref="S3.Ex7.m1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.Ex7.m1.1.1.1.1.2.3.6" xref="S3.Ex7.m1.1.1.1.1.2.3.6.cmml">r</mi></mrow></msub><mo id="S3.Ex7.m1.1.1.1.1.1" xref="S3.Ex7.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.Ex7.m1.1.1.1.1.3" xref="S3.Ex7.m1.1.1.1.1.3.cmml"><msub id="S3.Ex7.m1.1.1.1.1.3.2" xref="S3.Ex7.m1.1.1.1.1.3.2.cmml"><mi id="S3.Ex7.m1.1.1.1.1.3.2.2" xref="S3.Ex7.m1.1.1.1.1.3.2.2.cmml">L</mi><mi id="S3.Ex7.m1.1.1.1.1.3.2.3" xref="S3.Ex7.m1.1.1.1.1.3.2.3.cmml">Î¸</mi></msub><mo id="S3.Ex7.m1.1.1.1.1.3.1" xref="S3.Ex7.m1.1.1.1.1.3.1.cmml">+</mo><msub id="S3.Ex7.m1.1.1.1.1.3.3" xref="S3.Ex7.m1.1.1.1.1.3.3.cmml"><mi id="S3.Ex7.m1.1.1.1.1.3.3.2" xref="S3.Ex7.m1.1.1.1.1.3.3.2.cmml">L</mi><mi id="S3.Ex7.m1.1.1.1.1.3.3.3" xref="S3.Ex7.m1.1.1.1.1.3.3.3.cmml">Î²</mi></msub></mrow></mrow><mo lspace="0em" id="S3.Ex7.m1.1.1.1.2" xref="S3.Ex7.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex7.m1.1b"><apply id="S3.Ex7.m1.1.1.1.1.cmml" xref="S3.Ex7.m1.1.1.1"><eq id="S3.Ex7.m1.1.1.1.1.1.cmml" xref="S3.Ex7.m1.1.1.1.1.1"></eq><apply id="S3.Ex7.m1.1.1.1.1.2.cmml" xref="S3.Ex7.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex7.m1.1.1.1.1.2.1.cmml" xref="S3.Ex7.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex7.m1.1.1.1.1.2.2.cmml" xref="S3.Ex7.m1.1.1.1.1.2.2">ğ¿</ci><apply id="S3.Ex7.m1.1.1.1.1.2.3.cmml" xref="S3.Ex7.m1.1.1.1.1.2.3"><times id="S3.Ex7.m1.1.1.1.1.2.3.1.cmml" xref="S3.Ex7.m1.1.1.1.1.2.3.1"></times><ci id="S3.Ex7.m1.1.1.1.1.2.3.2.cmml" xref="S3.Ex7.m1.1.1.1.1.2.3.2">ğ‘</ci><ci id="S3.Ex7.m1.1.1.1.1.2.3.3.cmml" xref="S3.Ex7.m1.1.1.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S3.Ex7.m1.1.1.1.1.2.3.4.cmml" xref="S3.Ex7.m1.1.1.1.1.2.3.4">ğ‘–</ci><ci id="S3.Ex7.m1.1.1.1.1.2.3.5.cmml" xref="S3.Ex7.m1.1.1.1.1.2.3.5">ğ‘œ</ci><ci id="S3.Ex7.m1.1.1.1.1.2.3.6.cmml" xref="S3.Ex7.m1.1.1.1.1.2.3.6">ğ‘Ÿ</ci></apply></apply><apply id="S3.Ex7.m1.1.1.1.1.3.cmml" xref="S3.Ex7.m1.1.1.1.1.3"><plus id="S3.Ex7.m1.1.1.1.1.3.1.cmml" xref="S3.Ex7.m1.1.1.1.1.3.1"></plus><apply id="S3.Ex7.m1.1.1.1.1.3.2.cmml" xref="S3.Ex7.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.Ex7.m1.1.1.1.1.3.2.1.cmml" xref="S3.Ex7.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.Ex7.m1.1.1.1.1.3.2.2.cmml" xref="S3.Ex7.m1.1.1.1.1.3.2.2">ğ¿</ci><ci id="S3.Ex7.m1.1.1.1.1.3.2.3.cmml" xref="S3.Ex7.m1.1.1.1.1.3.2.3">ğœƒ</ci></apply><apply id="S3.Ex7.m1.1.1.1.1.3.3.cmml" xref="S3.Ex7.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.Ex7.m1.1.1.1.1.3.3.1.cmml" xref="S3.Ex7.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.Ex7.m1.1.1.1.1.3.3.2.cmml" xref="S3.Ex7.m1.1.1.1.1.3.3.2">ğ¿</ci><ci id="S3.Ex7.m1.1.1.1.1.3.3.3.cmml" xref="S3.Ex7.m1.1.1.1.1.3.3.3">ğ›½</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex7.m1.1c">L_{prior}=L_{\theta}+L_{\beta}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.6" class="ltx_p">Here, we use a pose prior built on the CMU MoCap dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, which is parametrized based using the SMPL model with a previously proposed method, MoSh <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
The pose prior loss is approximately calculated using the minimum operator introduced by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>:</p>
<table id="S3.Ex8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex8.m1.6" class="ltx_Math" alttext="L_{\theta}=\min_{j}(-log(cg_{j}\mathcal{N}(\theta;\mu_{\theta,j},\Sigma_{\theta,j})))." display="block"><semantics id="S3.Ex8.m1.6a"><mrow id="S3.Ex8.m1.6.6.1" xref="S3.Ex8.m1.6.6.1.1.cmml"><mrow id="S3.Ex8.m1.6.6.1.1" xref="S3.Ex8.m1.6.6.1.1.cmml"><msub id="S3.Ex8.m1.6.6.1.1.4" xref="S3.Ex8.m1.6.6.1.1.4.cmml"><mi id="S3.Ex8.m1.6.6.1.1.4.2" xref="S3.Ex8.m1.6.6.1.1.4.2.cmml">L</mi><mi id="S3.Ex8.m1.6.6.1.1.4.3" xref="S3.Ex8.m1.6.6.1.1.4.3.cmml">Î¸</mi></msub><mo id="S3.Ex8.m1.6.6.1.1.3" xref="S3.Ex8.m1.6.6.1.1.3.cmml">=</mo><mrow id="S3.Ex8.m1.6.6.1.1.2.2" xref="S3.Ex8.m1.6.6.1.1.2.3.cmml"><munder id="S3.Ex8.m1.6.6.1.1.1.1.1" xref="S3.Ex8.m1.6.6.1.1.1.1.1.cmml"><mi id="S3.Ex8.m1.6.6.1.1.1.1.1.2" xref="S3.Ex8.m1.6.6.1.1.1.1.1.2.cmml">min</mi><mi id="S3.Ex8.m1.6.6.1.1.1.1.1.3" xref="S3.Ex8.m1.6.6.1.1.1.1.1.3.cmml">j</mi></munder><mo id="S3.Ex8.m1.6.6.1.1.2.2a" xref="S3.Ex8.m1.6.6.1.1.2.3.cmml">â¡</mo><mrow id="S3.Ex8.m1.6.6.1.1.2.2.2" xref="S3.Ex8.m1.6.6.1.1.2.3.cmml"><mo stretchy="false" id="S3.Ex8.m1.6.6.1.1.2.2.2.2" xref="S3.Ex8.m1.6.6.1.1.2.3.cmml">(</mo><mrow id="S3.Ex8.m1.6.6.1.1.2.2.2.1" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.cmml"><mo id="S3.Ex8.m1.6.6.1.1.2.2.2.1a" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.cmml">âˆ’</mo><mrow id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.cmml"><mi id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.3" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.2" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.2.cmml">â€‹</mo><mi id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.4" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.2a" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.2.cmml">â€‹</mo><mi id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.5" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.2b" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.2.cmml">â€‹</mo><mrow id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.2" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.cmml"><mi id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.4" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.3" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.3.cmml">â€‹</mo><msub id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.cmml"><mi id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.2" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.2.cmml">g</mi><mi id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.3" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.3a" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.3.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.6" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.6.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.3b" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.3.cmml">â€‹</mo><mrow id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.3" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.3.cmml">(</mo><mi id="S3.Ex8.m1.5.5" xref="S3.Ex8.m1.5.5.cmml">Î¸</mi><mo id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.4" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.3.cmml">;</mo><msub id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1.2" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1.2.cmml">Î¼</mi><mrow id="S3.Ex8.m1.2.2.2.4" xref="S3.Ex8.m1.2.2.2.3.cmml"><mi id="S3.Ex8.m1.1.1.1.1" xref="S3.Ex8.m1.1.1.1.1.cmml">Î¸</mi><mo id="S3.Ex8.m1.2.2.2.4.1" xref="S3.Ex8.m1.2.2.2.3.cmml">,</mo><mi id="S3.Ex8.m1.2.2.2.2" xref="S3.Ex8.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.5" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2.cmml"><mi mathvariant="normal" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2.2" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2.2.cmml">Î£</mi><mrow id="S3.Ex8.m1.4.4.2.4" xref="S3.Ex8.m1.4.4.2.3.cmml"><mi id="S3.Ex8.m1.3.3.1.1" xref="S3.Ex8.m1.3.3.1.1.cmml">Î¸</mi><mo id="S3.Ex8.m1.4.4.2.4.1" xref="S3.Ex8.m1.4.4.2.3.cmml">,</mo><mi id="S3.Ex8.m1.4.4.2.2" xref="S3.Ex8.m1.4.4.2.2.cmml">j</mi></mrow></msub><mo stretchy="false" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.6" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.3" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.Ex8.m1.6.6.1.1.2.2.2.3" xref="S3.Ex8.m1.6.6.1.1.2.3.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.Ex8.m1.6.6.1.2" xref="S3.Ex8.m1.6.6.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex8.m1.6b"><apply id="S3.Ex8.m1.6.6.1.1.cmml" xref="S3.Ex8.m1.6.6.1"><eq id="S3.Ex8.m1.6.6.1.1.3.cmml" xref="S3.Ex8.m1.6.6.1.1.3"></eq><apply id="S3.Ex8.m1.6.6.1.1.4.cmml" xref="S3.Ex8.m1.6.6.1.1.4"><csymbol cd="ambiguous" id="S3.Ex8.m1.6.6.1.1.4.1.cmml" xref="S3.Ex8.m1.6.6.1.1.4">subscript</csymbol><ci id="S3.Ex8.m1.6.6.1.1.4.2.cmml" xref="S3.Ex8.m1.6.6.1.1.4.2">ğ¿</ci><ci id="S3.Ex8.m1.6.6.1.1.4.3.cmml" xref="S3.Ex8.m1.6.6.1.1.4.3">ğœƒ</ci></apply><apply id="S3.Ex8.m1.6.6.1.1.2.3.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2"><apply id="S3.Ex8.m1.6.6.1.1.1.1.1.cmml" xref="S3.Ex8.m1.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex8.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.Ex8.m1.6.6.1.1.1.1.1">subscript</csymbol><min id="S3.Ex8.m1.6.6.1.1.1.1.1.2.cmml" xref="S3.Ex8.m1.6.6.1.1.1.1.1.2"></min><ci id="S3.Ex8.m1.6.6.1.1.1.1.1.3.cmml" xref="S3.Ex8.m1.6.6.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.Ex8.m1.6.6.1.1.2.2.2.1.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1"><minus id="S3.Ex8.m1.6.6.1.1.2.2.2.1.2.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1"></minus><apply id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1"><times id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.2.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.2"></times><ci id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.3.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.3">ğ‘™</ci><ci id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.4.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.4">ğ‘œ</ci><ci id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.5.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.5">ğ‘”</ci><apply id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1"><times id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.3.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.3"></times><ci id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.4.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.4">ğ‘</ci><apply id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.1.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5">subscript</csymbol><ci id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.2.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.2">ğ‘”</ci><ci id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.3.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.5.3">ğ‘—</ci></apply><ci id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.6.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.6">ğ’©</ci><list id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.3.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2"><ci id="S3.Ex8.m1.5.5.cmml" xref="S3.Ex8.m1.5.5">ğœƒ</ci><apply id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.1.1.1.2">ğœ‡</ci><list id="S3.Ex8.m1.2.2.2.3.cmml" xref="S3.Ex8.m1.2.2.2.4"><ci id="S3.Ex8.m1.1.1.1.1.cmml" xref="S3.Ex8.m1.1.1.1.1">ğœƒ</ci><ci id="S3.Ex8.m1.2.2.2.2.cmml" xref="S3.Ex8.m1.2.2.2.2">ğ‘—</ci></list></apply><apply id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2.1.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2.2.cmml" xref="S3.Ex8.m1.6.6.1.1.2.2.2.1.1.1.1.1.2.2.2.2">Î£</ci><list id="S3.Ex8.m1.4.4.2.3.cmml" xref="S3.Ex8.m1.4.4.2.4"><ci id="S3.Ex8.m1.3.3.1.1.cmml" xref="S3.Ex8.m1.3.3.1.1">ğœƒ</ci><ci id="S3.Ex8.m1.4.4.2.2.cmml" xref="S3.Ex8.m1.4.4.2.2">ğ‘—</ci></list></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex8.m1.6c">L_{\theta}=\min_{j}(-log(cg_{j}\mathcal{N}(\theta;\mu_{\theta,j},\Sigma_{\theta,j}))).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.4" class="ltx_p">We use <math id="S3.SS3.p2.2.m1.1" class="ltx_Math" alttext="N=8" display="inline"><semantics id="S3.SS3.p2.2.m1.1a"><mrow id="S3.SS3.p2.2.m1.1.1" xref="S3.SS3.p2.2.m1.1.1.cmml"><mi id="S3.SS3.p2.2.m1.1.1.2" xref="S3.SS3.p2.2.m1.1.1.2.cmml">N</mi><mo id="S3.SS3.p2.2.m1.1.1.1" xref="S3.SS3.p2.2.m1.1.1.1.cmml">=</mo><mn id="S3.SS3.p2.2.m1.1.1.3" xref="S3.SS3.p2.2.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m1.1b"><apply id="S3.SS3.p2.2.m1.1.1.cmml" xref="S3.SS3.p2.2.m1.1.1"><eq id="S3.SS3.p2.2.m1.1.1.1.cmml" xref="S3.SS3.p2.2.m1.1.1.1"></eq><ci id="S3.SS3.p2.2.m1.1.1.2.cmml" xref="S3.SS3.p2.2.m1.1.1.2">ğ‘</ci><cn type="integer" id="S3.SS3.p2.2.m1.1.1.3.cmml" xref="S3.SS3.p2.2.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m1.1c">N=8</annotation></semantics></math> Gaussians model given by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
For the shape prior <math id="S3.SS3.p2.3.m2.1" class="ltx_Math" alttext="L_{\beta}" display="inline"><semantics id="S3.SS3.p2.3.m2.1a"><msub id="S3.SS3.p2.3.m2.1.1" xref="S3.SS3.p2.3.m2.1.1.cmml"><mi id="S3.SS3.p2.3.m2.1.1.2" xref="S3.SS3.p2.3.m2.1.1.2.cmml">L</mi><mi id="S3.SS3.p2.3.m2.1.1.3" xref="S3.SS3.p2.3.m2.1.1.3.cmml">Î²</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m2.1b"><apply id="S3.SS3.p2.3.m2.1.1.cmml" xref="S3.SS3.p2.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m2.1.1.1.cmml" xref="S3.SS3.p2.3.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.3.m2.1.1.2.cmml" xref="S3.SS3.p2.3.m2.1.1.2">ğ¿</ci><ci id="S3.SS3.p2.3.m2.1.1.3.cmml" xref="S3.SS3.p2.3.m2.1.1.3">ğ›½</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m2.1c">L_{\beta}</annotation></semantics></math>, we simply use <math id="S3.SS3.p2.4.m3.1" class="ltx_Math" alttext="L2" display="inline"><semantics id="S3.SS3.p2.4.m3.1a"><mrow id="S3.SS3.p2.4.m3.1.1" xref="S3.SS3.p2.4.m3.1.1.cmml"><mi id="S3.SS3.p2.4.m3.1.1.2" xref="S3.SS3.p2.4.m3.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m3.1.1.1" xref="S3.SS3.p2.4.m3.1.1.1.cmml">â€‹</mo><mn id="S3.SS3.p2.4.m3.1.1.3" xref="S3.SS3.p2.4.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m3.1b"><apply id="S3.SS3.p2.4.m3.1.1.cmml" xref="S3.SS3.p2.4.m3.1.1"><times id="S3.SS3.p2.4.m3.1.1.1.cmml" xref="S3.SS3.p2.4.m3.1.1.1"></times><ci id="S3.SS3.p2.4.m3.1.1.2.cmml" xref="S3.SS3.p2.4.m3.1.1.2">ğ¿</ci><cn type="integer" id="S3.SS3.p2.4.m3.1.1.3.cmml" xref="S3.SS3.p2.4.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m3.1c">L2</annotation></semantics></math> regularization:</p>
<table id="S3.Ex9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex9.m1.2" class="ltx_Math" alttext="L_{\beta}=\big{|}\big{|}\beta\big{|}\big{|}." display="block"><semantics id="S3.Ex9.m1.2a"><mrow id="S3.Ex9.m1.2.2.1" xref="S3.Ex9.m1.2.2.1.1.cmml"><mrow id="S3.Ex9.m1.2.2.1.1" xref="S3.Ex9.m1.2.2.1.1.cmml"><msub id="S3.Ex9.m1.2.2.1.1.2" xref="S3.Ex9.m1.2.2.1.1.2.cmml"><mi id="S3.Ex9.m1.2.2.1.1.2.2" xref="S3.Ex9.m1.2.2.1.1.2.2.cmml">L</mi><mi id="S3.Ex9.m1.2.2.1.1.2.3" xref="S3.Ex9.m1.2.2.1.1.2.3.cmml">Î²</mi></msub><mo id="S3.Ex9.m1.2.2.1.1.1" xref="S3.Ex9.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.Ex9.m1.2.2.1.1.3.2" xref="S3.Ex9.m1.2.2.1.1.3.1.cmml"><mo stretchy="false" id="S3.Ex9.m1.2.2.1.1.3.2.1" xref="S3.Ex9.m1.2.2.1.1.3.1.1.cmml">â€–</mo><mi id="S3.Ex9.m1.1.1" xref="S3.Ex9.m1.1.1.cmml">Î²</mi><mo stretchy="false" id="S3.Ex9.m1.2.2.1.1.3.2.2" xref="S3.Ex9.m1.2.2.1.1.3.1.1.cmml">â€–</mo></mrow></mrow><mo lspace="0em" id="S3.Ex9.m1.2.2.1.2" xref="S3.Ex9.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex9.m1.2b"><apply id="S3.Ex9.m1.2.2.1.1.cmml" xref="S3.Ex9.m1.2.2.1"><eq id="S3.Ex9.m1.2.2.1.1.1.cmml" xref="S3.Ex9.m1.2.2.1.1.1"></eq><apply id="S3.Ex9.m1.2.2.1.1.2.cmml" xref="S3.Ex9.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.Ex9.m1.2.2.1.1.2.1.cmml" xref="S3.Ex9.m1.2.2.1.1.2">subscript</csymbol><ci id="S3.Ex9.m1.2.2.1.1.2.2.cmml" xref="S3.Ex9.m1.2.2.1.1.2.2">ğ¿</ci><ci id="S3.Ex9.m1.2.2.1.1.2.3.cmml" xref="S3.Ex9.m1.2.2.1.1.2.3">ğ›½</ci></apply><apply id="S3.Ex9.m1.2.2.1.1.3.1.cmml" xref="S3.Ex9.m1.2.2.1.1.3.2"><csymbol cd="latexml" id="S3.Ex9.m1.2.2.1.1.3.1.1.cmml" xref="S3.Ex9.m1.2.2.1.1.3.2.1">norm</csymbol><ci id="S3.Ex9.m1.1.1.cmml" xref="S3.Ex9.m1.1.1">ğ›½</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex9.m1.2c">L_{\beta}=\big{|}\big{|}\beta\big{|}\big{|}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.7" class="ltx_p">Again, we clarify that these explicit prior terms are applied only when the ground truth SMPL parameters are not available.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2011.13427/assets/Figure4.png" id="S3.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="340" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Architecture of the 3D residual block. The 3D encoder consists of several residual blocks and 3D pooling layers to encode the aggregated volume into a dense feature vector.</figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Implementation details</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Datasets collected in a calibrated multi-view setting are required to train our learnable volumetric aggregation model, which uses camera extrinsics and intrinsics directly for the back-project operation. Rather than training the entire framework with these datasets, which were mostly captured indoors, we pretrained our 2D encoder using the same configuration proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> on both outdoor and indoor datasets: LSP, LSP-Extension <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, MS-COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, MPII <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, MPI-INF-3DHP, Human3.6M for 10 epochs to generalize the model. We then jointly trained the entire pipeline with multi-view datasets, Human3.6M and MPI-INF-3DHP, while setting the learning rate of the 2D encoder as 1/10 of the rest of the model. We confirmed that pretraining the backbone network significantly improves the performance of our model, even when tested on the indoor datasets. As described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, we also use the camera parameters of the Human3.6M dataset provided by Martinez <em id="S3.SS4.p1.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S3.SS4.p1.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and crop input images using provided bounding box annotations.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.7" class="ltx_p">We use ResNet50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> for the 2D encoder (<math id="S3.SS4.p2.1.m1.1" class="ltx_Math" alttext="e_{2D}" display="inline"><semantics id="S3.SS4.p2.1.m1.1a"><msub id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">e</mi><mrow id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml"><mn id="S3.SS4.p2.1.m1.1.1.3.2" xref="S3.SS4.p2.1.m1.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS4.p2.1.m1.1.1.3.1" xref="S3.SS4.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.1.m1.1.1.3.3" xref="S3.SS4.p2.1.m1.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">ğ‘’</ci><apply id="S3.SS4.p2.1.m1.1.1.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3"><times id="S3.SS4.p2.1.m1.1.1.3.1.cmml" xref="S3.SS4.p2.1.m1.1.1.3.1"></times><cn type="integer" id="S3.SS4.p2.1.m1.1.1.3.2.cmml" xref="S3.SS4.p2.1.m1.1.1.3.2">2</cn><ci id="S3.SS4.p2.1.m1.1.1.3.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">e_{2D}</annotation></semantics></math>) architecture and aggregate the feature maps into the cuboid consisting <math id="S3.SS4.p2.2.m2.1" class="ltx_Math" alttext="16\times 16\times 16" display="inline"><semantics id="S3.SS4.p2.2.m2.1a"><mrow id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml"><mn id="S3.SS4.p2.2.m2.1.1.2" xref="S3.SS4.p2.2.m2.1.1.2.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p2.2.m2.1.1.1" xref="S3.SS4.p2.2.m2.1.1.1.cmml">Ã—</mo><mn id="S3.SS4.p2.2.m2.1.1.3" xref="S3.SS4.p2.2.m2.1.1.3.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p2.2.m2.1.1.1a" xref="S3.SS4.p2.2.m2.1.1.1.cmml">Ã—</mo><mn id="S3.SS4.p2.2.m2.1.1.4" xref="S3.SS4.p2.2.m2.1.1.4.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><apply id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1"><times id="S3.SS4.p2.2.m2.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1.1"></times><cn type="integer" id="S3.SS4.p2.2.m2.1.1.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2">16</cn><cn type="integer" id="S3.SS4.p2.2.m2.1.1.3.cmml" xref="S3.SS4.p2.2.m2.1.1.3">16</cn><cn type="integer" id="S3.SS4.p2.2.m2.1.1.4.cmml" xref="S3.SS4.p2.2.m2.1.1.4">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">16\times 16\times 16</annotation></semantics></math> voxels per each batch and channel after processing the feature maps with output channel <math id="S3.SS4.p2.3.m3.1" class="ltx_Math" alttext="K=256" display="inline"><semantics id="S3.SS4.p2.3.m3.1a"><mrow id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml"><mi id="S3.SS4.p2.3.m3.1.1.2" xref="S3.SS4.p2.3.m3.1.1.2.cmml">K</mi><mo id="S3.SS4.p2.3.m3.1.1.1" xref="S3.SS4.p2.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS4.p2.3.m3.1.1.3" xref="S3.SS4.p2.3.m3.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><apply id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1"><eq id="S3.SS4.p2.3.m3.1.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1.1"></eq><ci id="S3.SS4.p2.3.m3.1.1.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2">ğ¾</ci><cn type="integer" id="S3.SS4.p2.3.m3.1.1.3.cmml" xref="S3.SS4.p2.3.m3.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">K=256</annotation></semantics></math>. The length of the volume in global coordinates is set as 2500 <span id="S3.SS4.p2.7.1" class="ltx_text ltx_font_italic">mm</span> to ensure that the projected information is thoroughly contained in the volume. The center of the volume is calculated using algebraic triangulation of the 2D pelvis location, detected via OpenPose <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> in each camera view. We build 3D encoder <math id="S3.SS4.p2.4.m4.1" class="ltx_Math" alttext="e_{3D}" display="inline"><semantics id="S3.SS4.p2.4.m4.1a"><msub id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml"><mi id="S3.SS4.p2.4.m4.1.1.2" xref="S3.SS4.p2.4.m4.1.1.2.cmml">e</mi><mrow id="S3.SS4.p2.4.m4.1.1.3" xref="S3.SS4.p2.4.m4.1.1.3.cmml"><mn id="S3.SS4.p2.4.m4.1.1.3.2" xref="S3.SS4.p2.4.m4.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.1.1.3.1" xref="S3.SS4.p2.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.1.1.3.3" xref="S3.SS4.p2.4.m4.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.1b"><apply id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.1.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.p2.4.m4.1.1.2.cmml" xref="S3.SS4.p2.4.m4.1.1.2">ğ‘’</ci><apply id="S3.SS4.p2.4.m4.1.1.3.cmml" xref="S3.SS4.p2.4.m4.1.1.3"><times id="S3.SS4.p2.4.m4.1.1.3.1.cmml" xref="S3.SS4.p2.4.m4.1.1.3.1"></times><cn type="integer" id="S3.SS4.p2.4.m4.1.1.3.2.cmml" xref="S3.SS4.p2.4.m4.1.1.3.2">3</cn><ci id="S3.SS4.p2.4.m4.1.1.3.3.cmml" xref="S3.SS4.p2.4.m4.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.1c">e_{3D}</annotation></semantics></math> composed of several residual blocks and 3D pooling layers, where the architecture of each residual block is described in Figure <a href="#S3.F4" title="Figure 4 â€£ 3.3 Regression network â€£ 3 Method â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Also, final regression network <math id="S3.SS4.p2.5.m5.1" class="ltx_Math" alttext="f^{reg}" display="inline"><semantics id="S3.SS4.p2.5.m5.1a"><msup id="S3.SS4.p2.5.m5.1.1" xref="S3.SS4.p2.5.m5.1.1.cmml"><mi id="S3.SS4.p2.5.m5.1.1.2" xref="S3.SS4.p2.5.m5.1.1.2.cmml">f</mi><mrow id="S3.SS4.p2.5.m5.1.1.3" xref="S3.SS4.p2.5.m5.1.1.3.cmml"><mi id="S3.SS4.p2.5.m5.1.1.3.2" xref="S3.SS4.p2.5.m5.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.5.m5.1.1.3.1" xref="S3.SS4.p2.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.5.m5.1.1.3.3" xref="S3.SS4.p2.5.m5.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.5.m5.1.1.3.1a" xref="S3.SS4.p2.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.5.m5.1.1.3.4" xref="S3.SS4.p2.5.m5.1.1.3.4.cmml">g</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m5.1b"><apply id="S3.SS4.p2.5.m5.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.5.m5.1.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS4.p2.5.m5.1.1.2.cmml" xref="S3.SS4.p2.5.m5.1.1.2">ğ‘“</ci><apply id="S3.SS4.p2.5.m5.1.1.3.cmml" xref="S3.SS4.p2.5.m5.1.1.3"><times id="S3.SS4.p2.5.m5.1.1.3.1.cmml" xref="S3.SS4.p2.5.m5.1.1.3.1"></times><ci id="S3.SS4.p2.5.m5.1.1.3.2.cmml" xref="S3.SS4.p2.5.m5.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.SS4.p2.5.m5.1.1.3.3.cmml" xref="S3.SS4.p2.5.m5.1.1.3.3">ğ‘’</ci><ci id="S3.SS4.p2.5.m5.1.1.3.4.cmml" xref="S3.SS4.p2.5.m5.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.5.m5.1c">f^{reg}</annotation></semantics></math> consists of 2 fully connected layers with 4-steps iterative regression method introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. We set the learning rate of pretrained 2D backbone to <math id="S3.SS4.p2.6.m6.1" class="ltx_Math" alttext="10^{-5}" display="inline"><semantics id="S3.SS4.p2.6.m6.1a"><msup id="S3.SS4.p2.6.m6.1.1" xref="S3.SS4.p2.6.m6.1.1.cmml"><mn id="S3.SS4.p2.6.m6.1.1.2" xref="S3.SS4.p2.6.m6.1.1.2.cmml">10</mn><mrow id="S3.SS4.p2.6.m6.1.1.3" xref="S3.SS4.p2.6.m6.1.1.3.cmml"><mo id="S3.SS4.p2.6.m6.1.1.3a" xref="S3.SS4.p2.6.m6.1.1.3.cmml">âˆ’</mo><mn id="S3.SS4.p2.6.m6.1.1.3.2" xref="S3.SS4.p2.6.m6.1.1.3.2.cmml">5</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.6.m6.1b"><apply id="S3.SS4.p2.6.m6.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.6.m6.1.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1">superscript</csymbol><cn type="integer" id="S3.SS4.p2.6.m6.1.1.2.cmml" xref="S3.SS4.p2.6.m6.1.1.2">10</cn><apply id="S3.SS4.p2.6.m6.1.1.3.cmml" xref="S3.SS4.p2.6.m6.1.1.3"><minus id="S3.SS4.p2.6.m6.1.1.3.1.cmml" xref="S3.SS4.p2.6.m6.1.1.3"></minus><cn type="integer" id="S3.SS4.p2.6.m6.1.1.3.2.cmml" xref="S3.SS4.p2.6.m6.1.1.3.2">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.6.m6.1c">10^{-5}</annotation></semantics></math> and the rest of the model to <math id="S3.SS4.p2.7.m7.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S3.SS4.p2.7.m7.1a"><msup id="S3.SS4.p2.7.m7.1.1" xref="S3.SS4.p2.7.m7.1.1.cmml"><mn id="S3.SS4.p2.7.m7.1.1.2" xref="S3.SS4.p2.7.m7.1.1.2.cmml">10</mn><mrow id="S3.SS4.p2.7.m7.1.1.3" xref="S3.SS4.p2.7.m7.1.1.3.cmml"><mo id="S3.SS4.p2.7.m7.1.1.3a" xref="S3.SS4.p2.7.m7.1.1.3.cmml">âˆ’</mo><mn id="S3.SS4.p2.7.m7.1.1.3.2" xref="S3.SS4.p2.7.m7.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.7.m7.1b"><apply id="S3.SS4.p2.7.m7.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.7.m7.1.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1">superscript</csymbol><cn type="integer" id="S3.SS4.p2.7.m7.1.1.2.cmml" xref="S3.SS4.p2.7.m7.1.1.2">10</cn><apply id="S3.SS4.p2.7.m7.1.1.3.cmml" xref="S3.SS4.p2.7.m7.1.1.3"><minus id="S3.SS4.p2.7.m7.1.1.3.1.cmml" xref="S3.SS4.p2.7.m7.1.1.3"></minus><cn type="integer" id="S3.SS4.p2.7.m7.1.1.3.2.cmml" xref="S3.SS4.p2.7.m7.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.7.m7.1c">10^{-4}</annotation></semantics></math> and used Adam solver <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2011.13427/assets/Figure5.png" id="S3.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="795" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Qualitative results of our approach on Human3.6M (rows 1-4) and MPI-INF-3DHP (rows 5-8). The model takes 4 multi-view images as input and predicts a single reconstructed human body overlaid to each camera view.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We conducted experiments on two publicly available multi-view datasets, Human3.6M and MPI-INF-3DHP. For the first experiment, we trained our model on Human3.6M dataset for 20 epochs and for the second experiment, we fine-tuned on MPI-INF-3DHP for another 10 epochs.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets and evaluation metrics</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Human3.6M.</span>
This is one of the largest benchmarks for indoor 3D human pose estimation. The dataset includes 3.6 million video frames from 4 different viewpoints, captured at 50Hz frames per seconds. The 3D ground truth annotation was collected using a marker-based motion capture system with 10 infrared cameras. <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">Mean per joint position error</span> (MPJPE), the Euclidean distance between the prediction of our model and the given 3D joint labels after root joint alignment (in <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="mm" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">ğ‘š</ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">mm</annotation></semantics></math>) is used for the evaluation. We also evaluated the performance after applying Procrustes analysis, by computing a similarity transform and aligning the prediction to the ground truth. We denote 3D error after the alignment as PA MPJPE and compare with prior methods as well. We generated labels of SMPL parameters using the 3D version of SMPLify and used it for direct supervision on SMPL parameters, as the 3D error of the label is much smaller than the error of our prediction. We trained our model using subjects S1, S5, S6, S7, S8, and tested on subjects S9 and S11.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">MPI-INF-3DHP.</span>
MPI-INF-3DHP dataset is another multi-view dataset, mostly captured indoors using a green-screen studio and 14 cameras. Only a subset of 4 cameras, however, is used for both training and testing. Unlike Human3.6M, this dataset does not incorporate a marker-based motion capture system. As a result, the 3D label is relatively inaccurate. We evaluated our modelâ€™s performance after applying Procrustes analysis using the same metric that was used for the Human3.6M dataset: MPJPE. We also use <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_italic">Percentage of Correct Keypoints</span> (PCK) and <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_italic">Area Under the Curve</span> (AUC) to compare against other multi-view approaches after applying Procrustes analysis. AUC is calculated with interval of 5 <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="mm" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><times id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"></times><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">ğ‘š</ci><ci id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">mm</annotation></semantics></math>, following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. For this dataset, we did not achieve enough accuracy for SMPL parameter labels and therefore did not use direct supervision, but applied the explicit prior terms described at Section <a href="#S3.SS3" title="3.3 Regression network â€£ 3 Method â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>. We trained our model on subjects S1 to S7 and tested on subject S8.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Quantitative evaluation</h3>

<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:248.4pt;height:96.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-61.7pt,23.9pt) scale(0.668215467406705,0.668215467406705) ;">
<table id="S4.T1.2.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.2.2.2.3.1" class="ltx_tr">
<th id="S4.T1.2.2.2.3.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T1.2.2.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T1.2.2.2.3.1.2.1" class="ltx_text">MPJPE</span></th>
<th id="S4.T1.2.2.2.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T1.2.2.2.3.1.3.1" class="ltx_text">PA MPJPE</span></th>
<th id="S4.T1.2.2.2.3.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">camera</th>
<th id="S4.T1.2.2.2.3.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">feature</th>
</tr>
<tr id="S4.T1.2.2.2.4.2" class="ltx_tr">
<th id="S4.T1.2.2.2.4.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T1.2.2.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">calib.</th>
<th id="S4.T1.2.2.2.4.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">aggregation</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.2.2.2.5.1" class="ltx_tr">
<th id="S4.T1.2.2.2.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt">SPIN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</th>
<td id="S4.T1.2.2.2.5.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S4.T1.2.2.2.5.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">41.1</td>
<td id="S4.T1.2.2.2.5.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">No</td>
<td id="S4.T1.2.2.2.5.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">No</td>
</tr>
<tr id="S4.T1.2.2.2.6.2" class="ltx_tr">
<th id="S4.T1.2.2.2.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">MuVS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</th>
<td id="S4.T1.2.2.2.6.2.2" class="ltx_td ltx_align_center ltx_border_r">58.22</td>
<td id="S4.T1.2.2.2.6.2.3" class="ltx_td ltx_align_center ltx_border_r">47.09</td>
<td id="S4.T1.2.2.2.6.2.4" class="ltx_td ltx_align_center ltx_border_r">Yes</td>
<td id="S4.T1.2.2.2.6.2.5" class="ltx_td ltx_align_center ltx_border_r">No</td>
</tr>
<tr id="S4.T1.2.2.2.7.3" class="ltx_tr">
<th id="S4.T1.2.2.2.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Liang <em id="S4.T1.2.2.2.7.3.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S4.T1.2.2.2.7.3.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</th>
<td id="S4.T1.2.2.2.7.3.2" class="ltx_td ltx_align_center ltx_border_r">79.85</td>
<td id="S4.T1.2.2.2.7.3.3" class="ltx_td ltx_align_center ltx_border_r">45.13</td>
<td id="S4.T1.2.2.2.7.3.4" class="ltx_td ltx_align_center ltx_border_r">No</td>
<td id="S4.T1.2.2.2.7.3.5" class="ltx_td ltx_align_center ltx_border_r">No</td>
</tr>
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">SPIN<sup id="S4.T1.1.1.1.1.1.1" class="ltx_sup">4</sup>
</th>
<td id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r">57.5</td>
<td id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r">35.4</td>
<td id="S4.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r">No</td>
<td id="S4.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r">No</td>
</tr>
<tr id="S4.T1.2.2.2.2" class="ltx_tr">
<th id="S4.T1.2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">SPIN<sup id="S4.T1.2.2.2.2.1.1" class="ltx_sup"><span id="S4.T1.2.2.2.2.1.1.1" class="ltx_text ltx_font_italic">4,cal</span></sup>
</th>
<td id="S4.T1.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r">49.8</td>
<td id="S4.T1.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r">35.4</td>
<td id="S4.T1.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r">Yes</td>
<td id="S4.T1.2.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r">No</td>
</tr>
<tr id="S4.T1.2.2.2.8.4" class="ltx_tr">
<th id="S4.T1.2.2.2.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Ours</th>
<td id="S4.T1.2.2.2.8.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.2.2.2.8.4.2.1" class="ltx_text ltx_font_bold">46.9</span></td>
<td id="S4.T1.2.2.2.8.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.2.2.2.8.4.3.1" class="ltx_text ltx_font_bold">32.5</span></td>
<td id="S4.T1.2.2.2.8.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Yes</td>
<td id="S4.T1.2.2.2.8.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Yes</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison of different models on the Human3.6M dataset (in <span id="S4.T1.4.1" class="ltx_text ltx_font_italic">mm</span>), with each model trained on different datasets. The second column MPJPE is calculated after Procrustes analysis (PA). Our model shows better result before and after the PA alignment.</figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">Here, we present our results and compare them with other multi-view approaches. For fair comparison with SPIN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, which is a single-view approach that shows state-of-the-art performance in model-based human body reconstruction, we implemented a multi-view version. We independently predict SMPL parameters from each camera view and average pose and shape along the axis of 4 viewpoints. Since body orientation is dependent on camera pose, we do not average it. Instead, we take two different strategies to estimate body orientation. The first uses only the prediction from the frontal camera, assuming it includes more information than any other view. This approach does not require camera calibration, and we denote it as SPIN<sup id="S4.SS2.p1.2.1" class="ltx_sup">4</sup>, given that the final reconstruction uses 4 input images. The second strategy is to transform body orientation predictions from all the cameras to a global coordinate system and average them. This coordinate transformation requires calibration. We thus denote it as SPIN<sup id="S4.SS2.p1.2.2" class="ltx_sup"><span id="S4.SS2.p1.2.2.1" class="ltx_text ltx_font_italic">4,cal</span></sup>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Although each model was trained on the different datasets, for performance comparison, we tested on the same datasets. In Table <a href="#S4.T1" title="Table 1 â€£ 4.2 Quantitative evaluation â€£ 4 Experiments â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we present the performance of our model on the Human3.6M dataset and compare it against state-of-the-art regression methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> and an optimization algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Our approach outperform the previous models both before and after Procrustes analysis.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:198.7pt;height:39.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-35.8pt,7.1pt) scale(0.735314293972971,0.735314293972971) ;">
<table id="S4.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">PCK</th>
<th id="S4.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">AUC</th>
<th id="S4.T2.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">MPJPE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.2.1" class="ltx_tr">
<th id="S4.T2.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt">Liang <em id="S4.T2.1.1.2.1.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S4.T2.1.1.2.1.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</th>
<td id="S4.T2.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">95</td>
<td id="S4.T2.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">63</td>
<td id="S4.T2.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">62</td>
</tr>
<tr id="S4.T2.1.1.3.2" class="ltx_tr">
<th id="S4.T2.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Ours</th>
<td id="S4.T2.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.1.1.3.2.2.1" class="ltx_text ltx_font_bold">97.4</span></td>
<td id="S4.T2.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.1.1.3.2.3.1" class="ltx_text ltx_font_bold">65.5</span></td>
<td id="S4.T2.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.1.1.3.2.4.1" class="ltx_text ltx_font_bold">50.2</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of models on the MPI-INF-3DHP dataset, where each model is trained on different datasets. Evaluation was calculated after aligning the prediction using Procrustes analysis. Higher PCK / AUC and lower MPJPE stands for better results. Our approach outperforms the previous multi-view method.</figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Similarly, we present our result on the MPI-INF-3DHP dataset in Table <a href="#S4.T2" title="Table 2 â€£ 4.2 Quantitative evaluation â€£ 4 Experiments â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Here we do not compare against SPIN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, since the publicly available version of SPIN has been trained on all multi-view data from MPI-INF-3DHP, including the test subject that we used to evaluate our mode. These comparisons indicate that our model outperforms prior model-based approaches with multiple images.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:248.4pt;height:72.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-61.8pt,18.0pt) scale(0.667592067698269,0.667592067698269) ;">
<table id="S4.T3.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1.2.1" class="ltx_tr">
<th id="S4.T3.1.1.1.2.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T3.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">number of</th>
<th id="S4.T3.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">GPU memory</th>
<th id="S4.T3.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">inference</th>
</tr>
<tr id="S4.T3.1.1.1.3.2" class="ltx_tr">
<th id="S4.T3.1.1.1.3.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T3.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">parameters</th>
<th id="S4.T3.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">usage</th>
<th id="S4.T3.1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">time</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1.4.1" class="ltx_tr">
<th id="S4.T3.1.1.1.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt">Liang <em id="S4.T3.1.1.1.4.1.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S4.T3.1.1.1.4.1.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</th>
<td id="S4.T3.1.1.1.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">27M</td>
<td id="S4.T3.1.1.1.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.30MB</td>
<td id="S4.T3.1.1.1.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">29ms</td>
</tr>
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">SPIN<sup id="S4.T3.1.1.1.1.1.1" class="ltx_sup"><span id="S4.T3.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">4</span></sup>
</th>
<td id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r">27M</td>
<td id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r">1.32GB</td>
<td id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r">6ms</td>
</tr>
<tr id="S4.T3.1.1.1.5.2" class="ltx_tr">
<th id="S4.T3.1.1.1.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Iskekov <em id="S4.T3.1.1.1.5.2.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S4.T3.1.1.1.5.2.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>
</th>
<td id="S4.T3.1.1.1.5.2.2" class="ltx_td ltx_align_center ltx_border_r">86M</td>
<td id="S4.T3.1.1.1.5.2.3" class="ltx_td ltx_align_center ltx_border_r">6.08GB</td>
<td id="S4.T3.1.1.1.5.2.4" class="ltx_td ltx_align_center ltx_border_r">91ms</td>
</tr>
<tr id="S4.T3.1.1.1.6.3" class="ltx_tr">
<th id="S4.T3.1.1.1.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Ours</th>
<td id="S4.T3.1.1.1.6.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">72M</td>
<td id="S4.T3.1.1.1.6.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">1.98GB</td>
<td id="S4.T3.1.1.1.6.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">14ms</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of computational costs. We compare our model with the other aggregation methods in terms of the number of model parameters, model size, and inference time.</figcaption>
</figure>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">We further evaluated our modelâ€™s computational efficiency and compared against state-of-the-art approaches for both 3D keypoints detection and model-based 3D human pose reconstruction. Using GeForce RTX 2080Ti GPU, we measured an average of 100 iterations of inference time and GPU usage of each model with 4 input images with a shape of 224 <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mo id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><times id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">\times</annotation></semantics></math> 224. Under the similar aggregation architecture, our model-based approach significantly reduces GPU memory usage and inference time compared to the previous learnable triangulation approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Furthermore, our model has comparable computational load with other model-based approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> in terms of memory usage. We even achieve faster inference than stage-by-stage and view-by-view estimation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. This result shows that the learnable volumetric aggregation for model-based 3D body reconstruction yields both high precision and real-time inference.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2011.13427/assets/Figure6_1.png" id="S4.F6.1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="150" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2011.13427/assets/Figure6_2.png" id="S4.F6.2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="150" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2011.13427/assets/Figure6_3.png" id="S4.F6.3.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="179" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>
Qualitative comparison of our method with multi-view input images versus occluded single image. Image 1: input image for single-view model, Image 2: image from the other view, Output 1: prediction from single-view model, Output 2: prediction from multi-view model. Red circles show how multi-view model benefits from different views.</figcaption>
</figure>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">We also report qualitative results of our approach on both datasets, Human3.6M and MPi-INF-3DHP in Figure <a href="#S3.F5" title="Figure 5 â€£ 3.4 Implementation details â€£ 3 Method â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The reconstructed 3D human body overlaid on original images from each view might seem less accurate compared to the reported figures of single-view approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. However, this is natural since the primary goal of single-view approaches is to reconstruct a 3D human body that is the best fit with the given view. Our model, however, reconstructs a human body that aligns with all input images. Also, we report qualitative comparison of our method using multi-view images against only a single-view image with occlusion in Figure <a href="#S4.F6" title="Figure 6 â€£ 4.2 Quantitative evaluation â€£ 4 Experiments â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2011.13427/assets/Figure7.png" id="S4.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="538" height="579" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Examples of erroneous predictions that have self-collision. Figures on right are the original pose of the subjects, while figures on left are the reconstructed body poses. Red circles show the regions of self-collision.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Limitations</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Despite showing the state-of-the-art performance, our method still has limitations. One is self-collision. Similar to other model-based regression methods, we do not apply any penalty function for collision (or segment penetration), and therefor the prediction might suffer from self-collision. Figure <a href="#S4.F7" title="Figure 7 â€£ 4.2 Quantitative evaluation â€£ 4 Experiments â€£ Multi-view Human Pose and Shape Estimation Using Learnable Volumetric Aggregation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> illustrates examples of self-collision, where 3D errors are comparable to the average (less than 50 <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="mm" display="inline"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><times id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></times><ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">ğ‘š</ci><ci id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">mm</annotation></semantics></math> before applying Procrustes analysis). These erroneous predictions usually happen when the two different body segments of the subjects are contacting each other. In this case, it is difficult to penalize these pose by only relying on prior distribution of human pose, since the set of predicted pose might be close enough to the ground truth. In this regard, additional penalty functions need to be introduced to prevent collisions. Another limitation, in the context of translating vision-based approaches to healthcare applications, is that we report joint center errors, but not errors in 3D kinematics (i.e., joint angles). Biomechanists and rehabilitation specialists are trained to interpret mobility limitations in terms of joint kinematics. In the future more emphasis may be placed on expanding the metrics used to evaluate and compare computer vision models, allowing the medical community to assess their transnational potential.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We propose a learnable aggregation method for 3D human body shape and pose estimation from multi-view RGB images. Our method improves previous approaches in three ways. First, it uses salient information from a parametric body model to improve computational efficiency compared to the priorly proposed learnable volumetric aggregation, which uses voxel-wise predictions. This makes the model ideal for real-time inference. Second, it achieves state-of-the-art performance in multi-view human pose and shape estimatio. Our method significantly outperforms prior methods on benchmark datasets. Last, the proposed feature-level aggregation approach is promising for future work in motion capture with multi-view cameras. Although previously proposed methods can still take multi-view input images and benefit from different views, to the our best knowledge, there is no approach that aggregates extracted features into a global space containing information from all views. Since current motion analysis networks, mostly based on a single-view video, estimate human motion using per-frame features from temporal regression networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, our approach is more likely to be incorporated with video inference methods and advance video-based motion analysis in multi-view settings.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="http://mocap.cs.cmu.edu/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">http://mocap.cs.cmu.edu/</a><span id="bib.bib1.2.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
M. Andriluka, L. Pishchulin, P. Gehler, and B. Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">2d human pose estimation: New benchmark and state of the art
analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2014 IEEE Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 3686â€“3693, 2014.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Federica Bogo, Angjoo Kanazawa, Christoph Lassner, Peter Gehler, Javier Romero,
and MichaelÂ J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Keep it smpl: Automatic estimation of 3d human pose and shape from a
single image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Lecture Notes in Computer Science</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, page 561â€“578, 2016.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Z. Cao, G. Hidalgo Martinez, T. Simon, S. Wei, and Y.Â A. Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Openpose: Realtime multi-person 2d pose estimation using part
affinity fields.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">,
2019.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
CristianÂ Sminchisescu CatalinÂ Ionescu, FuxinÂ Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Latent structured models for human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Computer Vision</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, 2011.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:90%;">, abs/1512.03385, 2015.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Yinghao Huang, Federica Bogo, Christoph Lassner, Angjoo Kanazawa, PeterÂ V.
Gehler, Javier Romero, Ijaz Akhter, and MichaelÂ J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Towards accurate marker-less human shape and pose estimation over
time.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 International Conference on 3D Vision (3DV)</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:90%;">, Oct 2017.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Eldar Insafutdinov, Leonid Pishchulin, Bjoern Andres, Mykhaylo Andriluka, and
Bernt Schieke.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Deepercut: A deeper, stronger, and faster multi-person pose
estimation model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV)</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Karim Iskakov, Egor Burkov, Victor Lempitsky, and Yury Malkov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Learnable triangulation of human pose.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Computer Vision (ICCV)</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
AaronÂ S. Jackson, Chris Manafas, and Georgios Tzimiropoulos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">3d human body reconstruction from a single image via volumetric
regression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision â€“ ECCV 2018 Workshops</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, page 64â€“77, 2019.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Sam Johnson and Mark Everingham.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Clustered pose and nonlinear appearance models for human pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the British Machine Vision Conference</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages
12.1â€“12.11. BMVA Press, 2010.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.6.1" class="ltx_text" style="font-size:90%;">doi:10.5244/C.24.12.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Hanbyul Joo, Tomas Simon, Xulong Li, Hao Liu, Lei Tan, Lin Gui, Sean Banerjee,
Timothy Godisart, Bart Nabbe, Iain Matthews, and et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Panoptic studio: A massively multiview system for social interaction
capture.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">,
41(1):190â€“204, Jan 2019.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Hanbyul Joo, Tomas Simon, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Total capture: A 3d deformation model for tracking faces, hands, and
bodies.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE/CVF Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib13.4.2" class="ltx_text" style="font-size:90%;">, Jun 2018.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Abdolrahim Kadkhodamohammadi and Nicolas Padoy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">A generalizable approach for multi-view 3d human pose regression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Machine Vision and Applications</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 32(1), Oct 2020.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Angjoo Kanazawa, MichaelÂ J. Black, DavidÂ W. Jacobs, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">End-to-end recovery of human shape and pose.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Angjoo Kanazawa, JasonÂ Y. Zhang, Panna Felsen, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Learning 3d human dynamics from video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, Jun 2019.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Robinette Kathleen, Blackwell Sherri, Daanen Hein, Boehmer Mark, Fleming Scott,
Brill Tina, Hoeferlin David, and Burnsides Dennis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Civilian american and european surface anthropometry resource
(caesar) final report.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Tech. Rep. AFRL-HEWP-TR-2002-0169</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:90%;">, 2002.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
DiederikÂ P. Kingma and Jimmy Ba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Adam: A method for stochastic optimization, 2014.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Muhammed Kocabas, Nikos Athanasiou, and MichaelÂ J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Vibe: Video inference for human body pose and shape estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, Jun 2020.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Nikos Kolotouros, Georgios Pavlakos, MichaelÂ J Black, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Learning to reconstruct 3d human pose and shape via model-fitting in
the loop.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Junbang Liang and MingÂ C. Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Shape-aware human pose and shape reconstruction using multi-view
images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Computer Vision (ICCV)</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, SergeÂ J. Belongie, LubomirÂ D. Bourdev, RossÂ B.
Girshick, James Hays, Pietro Perona, Deva Ramanan, Piotr DollÃ¡r, and
C.Â Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Microsoft COCO: common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, abs/1405.0312, 2014.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Matthew Loper, Naureen Mahmood, and MichaelÂ J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Mosh: Motion and shape capture from sparse markers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Trans. Graph.</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 33(6), Nov. 2014.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and MichaelÂ J.
Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">SMPL: A skinned multi-person linear model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Trans. Graphics (Proc. SIGGRAPH Asia)</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 34(6):248:1â€“248:16,
Oct. 2015.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Julieta Martinez, Rayat Hossain, Javier Romero, and JamesÂ J. Little.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">A simple yet effective baseline for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Dushyant Mehta, Helge Rhodin, Dan Casas, Pascal Fua, Oleksandr Sotnychenko,
Weipeng Xu, and Christian Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Monocular 3d human pose estimation in the wild using improved cnn
supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">3D Vision (3DV), 2017 Fifth International Conference on</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">.
IEEE, 2017.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Gyeongsik Moon, JuÂ Yong Chang, and KyoungÂ Mu Lee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">V2v-posenet: Voxel-to-voxel prediction network for accurate 3d hand
and human pose estimation from a single depth map.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, June 2018.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Gyeongsik Moon and KyoungÂ Mu Lee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">I2l-meshnet: Image-to-lixel prediction network for accurate 3d human
pose and mesh estimation from a single rgb image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Lecture Notes in Computer Science</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, page 752â€“768, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Edwin Olson and Pratik Agarwal.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Inference on networks of mixtures for robust robot mapping.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The International Journal of Robotics Research</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">, 32(7):826â€“840,
2013.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, AhmedÂ A.
Osman, Dimitrios Tzionas, and MichaelÂ J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Expressive body capture: 3d hands, face, and body from a single
image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, Jun 2019.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Georgios Pavlakos, Xiaowei Zhou, KonstantinosÂ G. Derpanis, and Kostas
Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Harvesting multiple views for marker-less 3d human pose annotations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">, Jul 2017.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Learning to estimate 3d human pose and shape from a single color
image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, June 2018.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, BjÃ¶rn Andres, Mykhaylo
Andriluka, Peter Gehler, and Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Deepcut: Joint subset partition and labeling for multi person pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, pages 4929â€“4937. IEEE, June 2016.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Haibo Qiu, Chunyu Wang, Jingdong Wang, Naiyan Wang, and Wenjun Zeng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Cross view fusion for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, October 2019.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Edoardo Remelli, Shangchen Han, Sina Honari, Pascal Fua, and Robert Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Lightweight multi-view 3d pose estimation through camera-disentangled
representation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">, Jun 2020.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
GÃ¼l Varol, Duygu Ceylan, Bryan Russell, Jimei Yang, Ersin Yumer, Ivan Laptev,
and Cordelia Schmid.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Bodynet: Volumetric inference of 3d human body shapes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Lecture Notes in Computer Science</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, page 20â€“38, 2018.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Shih-En Wei, Varun Ramakrishna, Takeo Kanade, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Convolutional pose machines.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Jason Zhang, Panna Felsen, Angjoo Kanazawa, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Predicting 3d human dynamics from video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE/CVF International Conference on Computer Vision
(ICCV)</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, Oct 2019.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2011.13426" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2011.13427" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2011.13427">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2011.13427" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2011.13428" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 05:24:12 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
