<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.14718] Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images</title><meta property="og:description" content="This paper focuses on the scale imbalance problem of semi-supervised object detection (SSOD) in aerial images. Compared to natural images, objects in aerial images show smaller sizes and larger quantities per image, in…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.14718">

<!--Generated on Tue Feb 27 22:17:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
aerial images,  semi-supervised learning,  object detection
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ruixiang Zhang
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chang Xu
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fang Xu
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wen Yang
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Guangjun He
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Huai Yu
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gui-Song Xia
</span><span class="ltx_author_notes">This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.R. Zhang, C. Xu, F. Xu, W. Yang, and H. Yu are with the School of Electronic Information, Wuhan University, Wuhan, 430072 China. <em id="id4.2.id1" class="ltx_emph ltx_font_italic">E-mail: <span id="id4.2.id1.1" class="ltx_text ltx_font_upright">{</span>zhangruixiang, xuchangeis, xufang, yangwen, yuhuai<span id="id4.2.id1.2" class="ltx_text ltx_font_upright">}</span>@whu.edu.cn</em>G. He is with the State Key Laboratory of Space-Ground Integrated Information Technology, Beijing, 100086, China. <em id="id1.1.1" class="ltx_emph ltx_font_italic">E-mail: hgjun<math id="id1.1.1.m1.1" class="ltx_Math" alttext="\_" display="inline"><semantics id="id1.1.1.m1.1a"><mi mathvariant="normal" id="id1.1.1.m1.1.1" xref="id1.1.1.m1.1.1.cmml">_</mi><annotation-xml encoding="MathML-Content" id="id1.1.1.m1.1b"><ci id="id1.1.1.m1.1.1.cmml" xref="id1.1.1.m1.1.1">_</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.m1.1c">\_</annotation></semantics></math>2006@163.com</em>G. S. Xia is with the School of Computer Science, Wuhan University,
Wuhan 430072, China. <em id="id5.3.id1" class="ltx_emph ltx_font_italic">E-mail: guisong.xia@whu.edu.cn</em>Manuscript received XXX, 2022; revised XXX.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.2" class="ltx_p">This paper focuses on the scale imbalance problem of semi-supervised object detection (SSOD) in aerial images. Compared to natural images, objects in aerial images show smaller sizes and larger quantities per image, increasing the difficulty of manual annotation. Meanwhile, the advanced SSOD technique can train superior detectors by leveraging limited labeled data and massive unlabeled data, saving annotation costs. However, as an understudied task in aerial images, SSOD suffers from a drastic performance drop when facing a large proportion of small objects.
By analyzing the predictions between small and large objects, we identify three imbalance issues caused by the scale bias, <span id="id3.2.1" class="ltx_text ltx_font_italic">i.e.,</span> pseudo-label imbalance, label assignment imbalance, and negative learning imbalance. To tackle these issues, we propose a novel Scale-discriminative Semi-Supervised Object Detection (S<sup id="id3.2.2" class="ltx_sup">3</sup>OD) learning pipeline for aerial images. In our S<sup id="id3.2.3" class="ltx_sup">3</sup>OD, three key components, Size-aware Adaptive Thresholding (SAT), Size-rebalanced Label Assignment (SLA), and Teacher-guided Negative Learning (TNL), are proposed to warrant scale unbiased learning.
Specifically, SAT adaptively selects appropriate thresholds to filter pseudo-labels for objects at different scales. SLA balances positive samples of objects at different scales through resampling and reweighting. TNL alleviates the imbalance in negative samples by leveraging information generated by a teacher model.
Extensive experiments conducted on the DOTA-v1.5 benchmark demonstrate the superiority of our proposed methods over state-of-the-art competitors. Codes will be released soon.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
aerial images, semi-supervised learning, object detection

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Object detection in aerial imagery (ODAI) is a significant research field<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>, <a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>, <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>. Currently, deep learning-based methods dominate the field of aerial image object detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>]</cite>.
Supervised by manual annotations, these aerial object detectors can achieve superior performance. However, the annotation process is laborious, time-consuming, and expensive, limiting the quantity of labeled data. This dilemma is even more pronounced in aerial images, where the ubiquitous small and densely arranged objects introduce a great burden to the labeling process.
To better leverage the precious labeled data and the relatively easily available unlabeled data, semi-supervised object detection (SSOD) methods attract more and more attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>, <a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>, <a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>. Using only one-tenth labels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>, the SSOD method nowadays can achieve comparable performance to the fully-supervised method on the MS COCO benchmark <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.4" class="ltx_p">In spite of the significant advancements in SSOD for natural images, we observe that they face an improvement bottleneck for aerial images. Some existing SSOD methods, such as STAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite> and Soft-Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>, can yield performance improvements of more than 50<math id="S1.p2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S1.p2.1.m1.1a"><mo id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><csymbol cd="latexml" id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">\%</annotation></semantics></math> on MS COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite> using only 1<math id="S1.p2.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S1.p2.2.m2.1a"><mo id="S1.p2.2.m2.1.1" xref="S1.p2.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><csymbol cd="latexml" id="S1.p2.2.m2.1.1.cmml" xref="S1.p2.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">\%</annotation></semantics></math> labels. By contrast, when adapting these methods to aerial images, for example, the widely used DOTA-v1.5 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>, as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, they provide fairly limited improvement. For Soft-teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>, 105<math id="S1.p2.3.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S1.p2.3.m3.1a"><mo id="S1.p2.3.m3.1.1" xref="S1.p2.3.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S1.p2.3.m3.1b"><csymbol cd="latexml" id="S1.p2.3.m3.1.1.cmml" xref="S1.p2.3.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.3.m3.1c">\%</annotation></semantics></math> on MS COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite> <span id="S1.p2.4.1" class="ltx_text ltx_font_italic">v.s.</span> 28<math id="S1.p2.4.m4.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S1.p2.4.m4.1a"><mo id="S1.p2.4.m4.1.1" xref="S1.p2.4.m4.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S1.p2.4.m4.1b"><csymbol cd="latexml" id="S1.p2.4.m4.1.1.cmml" xref="S1.p2.4.m4.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.4.m4.1c">\%</annotation></semantics></math> on DOTA-v1.5 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2310.14718/assets/fig0_v3.2.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="275" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>(a) The line chart shows the comparison of SSOD-baseline, Soft-teacher, and our S<sup id="S1.F1.11.1" class="ltx_sup">3</sup>OD on DOTA-v1.5 validation set under different amounts of labelled training data. The bar chart shows the improvement over supervised baselines. (b) Detection results of supervised setting under 1<math id="S1.F1.6.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S1.F1.6.m2.1b"><mo id="S1.F1.6.m2.1.1" xref="S1.F1.6.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S1.F1.6.m2.1c"><csymbol cd="latexml" id="S1.F1.6.m2.1.1.cmml" xref="S1.F1.6.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.6.m2.1d">\%</annotation></semantics></math> labeling rate. (c) Detection results of our S<sup id="S1.F1.12.2" class="ltx_sup">3</sup>OD of semi-supervised setting under 1<math id="S1.F1.8.m4.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S1.F1.8.m4.1b"><mo id="S1.F1.8.m4.1.1" xref="S1.F1.8.m4.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S1.F1.8.m4.1c"><csymbol cd="latexml" id="S1.F1.8.m4.1.1.cmml" xref="S1.F1.8.m4.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.8.m4.1d">\%</annotation></semantics></math> labeling rate.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">This motivates us to rethink what factors lead to the dramatic degradation of SSOD methods on aerial imagery. For generality, we employ a vanilla teacher-student framework commonly used in the SOTA SSOD methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>, <a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> for analysis.
Specifically, observing that one of the typical characteristics of aerial imagery is its smaller object size, we investigate the indications of correctly predicted small objects<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>According to the definition in MS COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite>, we empirically regard instances with a pixel area smaller than 1024 (32*32) pixels as small objects, the others with areas larger than 1024 pixels are called large objects.</span></span></span> versus all objects, as shown in Fig. <a href="#S1.F2" title="Figure 2 ‣ I Introduction ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (a).
Interestingly, we find out that the SSOD framework further enlarges the gap between the predicted confidence of small and large objects, which implies that the learning of small objects and large objects is severely unbalanced. Given the overwhelming ratio of small objects in aerial images (66% in DOTA-v1.5 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite>), it is thus natural to draw the conclusion that such scale bias in existing SSOD frameworks is one of the main obstacles impeding their performance for ODAI.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2310.14718/assets/fig2_v2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="287" height="212" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>(a) Comparing the average confidence scores of all objects and small objects in correct predictions under the three settings of supervised by 100<math id="S1.F2.4.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S1.F2.4.m1.1b"><mo id="S1.F2.4.m1.1.1" xref="S1.F2.4.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S1.F2.4.m1.1c"><csymbol cd="latexml" id="S1.F2.4.m1.1.1.cmml" xref="S1.F2.4.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.4.m1.1d">\%</annotation></semantics></math> labeled data, supervised by 1<math id="S1.F2.5.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S1.F2.5.m2.1b"><mo id="S1.F2.5.m2.1.1" xref="S1.F2.5.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S1.F2.5.m2.1c"><csymbol cd="latexml" id="S1.F2.5.m2.1.1.cmml" xref="S1.F2.5.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.5.m2.1d">\%</annotation></semantics></math> labeled data, semi-supervised by 1<math id="S1.F2.6.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S1.F2.6.m3.1b"><mo id="S1.F2.6.m3.1.1" xref="S1.F2.6.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S1.F2.6.m3.1c"><csymbol cd="latexml" id="S1.F2.6.m3.1.1.cmml" xref="S1.F2.6.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.6.m3.1d">\%</annotation></semantics></math> labeled data. (The IoUs of the predicted boxes and GroundTruths greater than 0.5 are regarded as the correct predictions, noting that the average confidence score does not represent the test performance) (b) The distribution between the confidence scores and instances number of predictions during semi-supervised training. The top is for large objects, and the bottom is for small objects. (Note that on the vertical axis, the number of large objects is much higher than that of small objects.)</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We identify three essential causes that lead to the scale bias by delving into the learning pipeline of existing SSOD frameworks, namely the pseudo-label imbalance, label assignment imbalance, and negative learning imbalance issues.
First of all, pseudo-labels between small objects and large objects are unbalanced. In the general SSOD methods, a fixed pseudo-label threshold is often used to pick out high-quality predictions on unlabeled data as pseudo-labels, for example, the Soft-Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite> chooses 0.9 to get the best performance. However, as shown in Fig. <a href="#S1.F2" title="Figure 2 ‣ I Introduction ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (a), the average confidence of correct predictions of small objects tends to be much lower than larger objects, even for the fully supervised case. Therefore, a fixed threshold is bound to fail in simultaneously satisfying the optimal screening of different-sized objects. To further support this point of view, we elaborate on the confidence-sample number distribution of small/large objects during semi-supervised training, as shown in Fig. <a href="#S1.F2" title="Figure 2 ‣ I Introduction ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (b). Compared to large objects, the correctly predicted small objects are more scattered across the whole confidence score ranges. The above observation indicates that the fixed threshold pseudo-labeling manner suffers from a quality-quantity dilemma for different-sized objects. On the one hand, the high threshold in previous works can ensure high-quality pseudo-labels while leading to a drastic loss of supervision information for small objects. On the other hand, although lowering the threshold can compensate more pseudo-labels for small objects, it will introduce much low-quality and inaccurate supervision for large objects.</p>
</div>
<figure id="S1.F3" class="ltx_figure"><img src="/html/2310.14718/assets/fig2__.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="255" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The imbalance issues in the assignment of positive and negative samples in SSOD. The green represents GroundTruths or pseudo-labels used for supervision, the red represents the proposals or positive samples regarded as the foreground, and the dark blue represents the proposals or negative samples regarded as the background. (a) For large objects, more foreground proposals can be assigned. (b) For small objects, it is more challenging to match foreground proposals. (c) Biased pseudo-labels may misclassify the foreground proposals into the background. (d) Sparse pseudo-labels lose a lot of true objects, which are likely to be picked as negative samples, confusing the detector.</figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Moreover, small objects are confronted with sample insufficiency and lack of supervision problems during label assignment in the SSOD framework, exacerbating the unbalanced learning. To illustrate these problems, we take the mainstream two-stage anchor-based detector Faster R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite> for analysis. The Faster R-CNN heuristically presents a set of anchors at each feature point in the RPN stage. For small objects, a slight location deviation between the ground truth (GT) and the anchor will lead to severe mismatch issues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>, <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite>, yielding low IoU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite> between these two boxes’ region.
This characteristic of small objects brings about two adverse effects to the SSOD framework, we provide schematic diagrams in Fig. <a href="#S1.F3" title="Figure 3 ‣ I Introduction ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (a), (b), and (c). From one perspective, heuristic-tuned anchors are easy to drift from small GTs, and small GTs are prone to be matched with much fewer positive anchors than large objects. In other words, small objects are facing a positive sample/anchor insufficiency issue.
From another perspective, small objects are lacking in supervision during the training process. Since foreground small objects are harder to be matched with pseudo-labels, the average number of positive supervision (positive classification/regression loss) posed to each de facto small object is much smaller than the large object. Therefore, the SSOD is biased towards focusing on the learning of larger objects.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In addition, negative sample learning is inclined to mistakenly suppress foreground small objects. Here we show two pieces of evidence. First of all, as discussed in Fig. <a href="#S1.F2" title="Figure 2 ‣ I Introduction ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (b), the confidence of correctly predicted small objects is dispersed across the whole score range. Second, the recall of small objects is much lower than large objects, there remain many undiscovered small objects in the “background” region.
Hence, when sampling negative samples for classification, the de facto foreground small objects are more likely to be wrongly treated as the background, as shown in Fig. <a href="#S1.F3" title="Figure 3 ‣ I Introduction ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (d), depressing the recall.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.2" class="ltx_p">To address the aforementioned issues in SSOD, we propose a novel framework called Scale-discriminative Semi-Supervised Object Detection (S<sup id="S1.p7.2.1" class="ltx_sup">3</sup>OD) for aerial imagery. Built upon the popular SSOD framework, S<sup id="S1.p7.2.2" class="ltx_sup">3</sup>OD introduces three new modules: Size-aware Adaptive Thresholding (SAT), Size-rebalanced Label Assignment (SLA), and Teacher-guided Negative Learning (TNL). These modules aim to optimize the performance of SSOD in aerial images from the perspectives of pseudo-label selection, positive sample assignment, and negative learning. Specifically, SAT performs the pseudo-labeling of small and large objects in a <span id="S1.p7.2.3" class="ltx_text ltx_font_italic">dividing-and-conquering</span> manner, allowing for the retention of more pseudo-labels for small objects, thereby alleviating the quantity imbalance between large and small pseudo-labels.
SLA utilizes a distribution-based re-sampling strategy, mitigating the impact of positive sample quantity imbalance problems between small and large objects. Additionally, the label assignment strategy is modified by reweighting the loss, thus reducing the adverse influence of small objects’ lack of supervision.
TNL leverages the information from the teacher model to correct the selection of negative samples. For one, the teacher model helps filter out proposals that are likely to be positive samples during preliminary screening. For another, the predictions from the teacher model can further uncover hard samples, enhancing the network’s discriminative capability.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Overall, the main contributions of this paper are as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We point out that the scale imbalance problem is one of the key obstacles impeding SSOD’s performance on aerial imagery. We further systemically identify the pseudo-label imbalance, label assignment imbalance, and negative learning imbalance issues in a standard SSOD framework.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We propose a novel SSOD framework for aerial images, called S<sup id="S1.I1.i2.p1.1.1" class="ltx_sup">3</sup>OD. Specifically, we introduce Size-aware Adaptive Threshold (SAT) to select more appropriate pseudo-labels, Size-rebalanced Label Assignment (SLA) for balanced anchor assignment, and Teacher-guided Negative Learning (TNL) for discriminative negative learning.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Extensive experiments on representative aerial image datasets demonstrate the significant improvements and advancements achieved by our proposed methods.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">The rest of this paper is arranged as follows. First, we introduce related work about aerial image object detection and SSOD in Section II. Then, we provide a detailed description of our method in Section III, including the overall framework and the proposed three modules. The experiments and analysis are discussed in Section IV. Furthermore, we also discuss the insights and limitations in Section V. Finally, we draw a conclusion in Section VI.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we briefly review the recent progress of object detectors for aerial images. Then we provide a brief review of the relevant SSOD methods. Finally, we review the SSOD methods for aerial images.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Object Detection in Aerial Images</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In the past decade, object detection has been greatly advanced with the development of deep learning. The mainstream detection frameworks include a series of anchor-based detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>, anchor-free detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite>, and trendy transformer-based detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>, <a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>]</cite>.
These algorithms have achieved excellent results on natural images. Different from general natural images, one huge difference in ODAI is that the objects are arbitrary-oriented, so the horizontal bounding box cannot represent the object boundary well. In recent years, detectors based on rotated boxes occupy a dominant position in ODAI. For example, the Rotated RPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite> tackles rotated object detection by employing additional rotated anchor boxes. RoI Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite> learns to convert RPN-generated horizontal proposals into rotated ones, while S2ANet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a>]</cite> utilizes the DCN to explicitly align features with anchors. Oriented R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>]</cite> generates oriented proposals directly from anchors at the RPN stage. Additionally, there are also several works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>, <a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite> that customize anchor-free detectors for rotated detection.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Another main characteristic of the aerial image is its high proportion of small objects, bringing severe challenges for existing object detectors.
Super-resolution, as a straightforward and effective idea, is incorporated into small objects detection in several works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>, <a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>, <a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">42</span></a>]</cite>.
Besides, the SCRDet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite> and SCRDet++ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> optimize the feature extraction process and emphasize richer feature information, to enhance small objects.
Moreover, some works have found that the label assignment strategy in the existing detectors is extremely unfriendly to small objects, and proposed some new label assignment strategies like NWD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite>, RFLA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite>.
DCFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite> also explores dynamic priors and balanced learning for small object detection.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">The above methods effectively optimize the detector scheme based on the characteristics of objects in aerial images, thereby enhancing detection performance. However, these deep learning-based methods usually require plenty of training data with expensive annotation costs. In contrast, we explore the application of semi-supervised detection algorithms for aerial images to effectively alleviate the demand for annotations.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Semi-Supervised Object Detection</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The early semi-supervised learning methods in the computer community are developed for image classification. One key idea is consistency regularization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>, <a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>, <a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>, <a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>, <a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>, <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>, <a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite>, which aims to force the network to produce consistent predictions on data with different augmentations. Another idea is pseudo-label learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>, <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">53</span></a>, <a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>, <a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">55</span></a>, <a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>]</cite>, which uses self-training to obtain pseudo-labels for unlabeled samples through the pre-detector training with labeled data. Most SOTA methods combine the above two ideas <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>, <a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>, <a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>, <a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>, <a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite>. Inspired by the above methods, semi-supervised learning has also made a lot of progress in detection in recent years.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Nowadays, the dominant line of works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>, <a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>, <a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">63</span></a>, <a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">64</span></a>, <a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">65</span></a>, <a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">66</span></a>, <a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a>]</cite> combines the ideas of pseudo-label learning and consistency regularization into the framework of object detection. STAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite> is one representative method, which uses labeled data to train the network, and then predicts and filters suitable pseudo-labels on unlabeled images with different augmentations. After that, all the data are mixed to train together. Then, some methods such as Unbiased teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>, Humble teachers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>]</cite>, Interactive self-training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">69</span></a>]</cite>, Soft-teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>, introduce the Exponential Moving Average (EMA) idea in MeanTeacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite> into semi-supervised object detection. The model is updated after each iteration of training, which realizes end-to-end training and also provides a new paradigm for subsequent SSOD works. Based on this paradigm, the current semi-supervised object detection research lays emphasis on how to select reliable pseudo-labels and how to use pseudo-labels for more effective supervised learning.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Regarding the selection of pseudo-labels, on one hand, some studies explore more robust metrics for measuring the quality of pseudo-labels, incorporating the accuracy of localization with classification confidence. For example, in Soft-teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>, box jittering is employed to obtain the accuracy of the box, then boxes with high accuracy are used for regression supervision. Similarly, Unbiased Teacherv2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">70</span></a>]</cite> and RUPL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">71</span></a>]</cite> directly model regression uncertainty to select the pseudo-labels with high location accuracy. On the other hand, there are several works exploring different pseudo-label thresholds. S4OD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite> defines the threshold based on F1-score on the validation set. ASTOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">73</span></a>]</cite> selects a threshold that can ensure the recall. Consistent-Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite> selects classwise thresholds to get better matching thresholds.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">In terms of effectively exploiting pseudo-labels for learning, Soft-teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite> and PseCo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> leverages the predictions of teacher networks to assist pseudo-label supervision. PseCo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>, Consistent teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>, and ARSL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">74</span></a>]</cite> propose to better assign positive and negative samples with the supervision of inaccurate pseudo-labels. YOLOv5 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">75</span></a>]</cite> and LabelMatch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">76</span></a>]</cite> group pseudo-labels into reliable and unreliable ones, and apply different forms of supervision. DLS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite> and Dense Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite> supervise the student network via dense predictions from the teacher network.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p">From the perspective of consistency regularization, strategies such as feature alignment at different scales are employed in MixTeacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">77</span></a>]</cite>, SED <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">78</span></a>]</cite>, and PseCo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>. MUM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">79</span></a>]</cite> applies mixup at both the image and feature levels, introducing stronger perturbations to the samples to enhance consistency regularization.
Additionally, there are also explorations from the perspective of sampling. CropBank <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">80</span></a>]</cite> constructs a sample bank to supplement samples from minority classes, mitigating the impact of class imbalance. Active Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">81</span></a>]</cite> optimizes the sampling of unlabeled data by evaluating it from multiple dimensions and selecting appropriate unlabeled data for training. Furthermore, methods like Omni-DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">82</span></a>]</cite> and Semi-DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">83</span></a>]</cite> explore semi-supervised detection frameworks based on the Transformer.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p id="S2.SS2.p6.1" class="ltx_p">The aforementioned methods have achieved promising results. However, the specific characteristics of aerial images, like small and arbitrary orientations, make limitations in achieving the best performance in semi-supervised detection tasks in the context of aerial images. In contrast, our method takes these characteristics into account and presents a suitable SSOD framework for aerial images.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">SSOD for Aerial Images</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Indeed, there have been several studies focusing on SSOD in aerial images. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">84</span></a>]</cite> utilizes a GAN network to generate adversarial negative samples for training the network’s classification. However, it has only been tested on sparse small datasets and lacks universality. SOOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">85</span></a>]</cite> adopts the current mainstream semi-supervised detection paradigm and incorporates the orientations of targets in aerial images into the semi-supervised detection algorithm, achieving performance improvement. This method strengthens supervision based on the rotation consistency of densely arranged targets in aerial images. However, it still does not effectively address the challenges posed by small objects, which remains an urgent problem to be tackled.
In contrast, our method carefully considers the influence of small objects on different stages of SSOD in aerial images. We tackle the issue of imbalance caused by scale bias by selecting appropriate pseudo-labels and effectively utilizing them for supervision. In particular, we present very competitive results on SSOD for aerial images.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2310.14718/assets/fig__s3od.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="678" height="297" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The pipeline of the proposed S<sup id="S2.F4.4.1" class="ltx_sup">3</sup>OD. Each training batch contains both labeled and unlabeled data. The labeled data uses Ground Truth for general supervised training. The training of unlabeled data is based on the teacher-student model, and the teacher network is updated by the EMA of the student network. The teacher network inferences the unlabeled data, and then selects appropriate pseudo-labels through SAT. SLA assigns positive samples based on the pseudo-labels. TNL strengthens the negative learning based on the ambiguous predictions of the teacher network.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Methods</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section details our proposed method S<sup id="S3.p1.1.1" class="ltx_sup">3</sup>OD. First, we will introduce the overall architecture of the basic semi-supervised object detection we adopted, and then we will introduce our proposed methods for SSOD in aerial images, including SAT, SLA, and TNL.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">The Basic Framework</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.7" class="ltx_p">We follow the mainstream paradigm of pseudo-label learning for the overall framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>, <a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>, as shown in Fig. <a href="#S2.F4" title="Figure 4 ‣ II-C SSOD for Aerial Images ‣ II Related Work ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
We take the common teacher-student model as the basic framework, where the student model is updated with the normal back-propagation, and the teacher model is the Exponential Moving Average (EMA) of the student model.
Given the labeled dataset <math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="D_{l}=\left\{I_{l},G_{l}\right\}" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml"><msub id="S3.SS1.p1.1.m1.2.2.4" xref="S3.SS1.p1.1.m1.2.2.4.cmml"><mi id="S3.SS1.p1.1.m1.2.2.4.2" xref="S3.SS1.p1.1.m1.2.2.4.2.cmml">D</mi><mi id="S3.SS1.p1.1.m1.2.2.4.3" xref="S3.SS1.p1.1.m1.2.2.4.3.cmml">l</mi></msub><mo id="S3.SS1.p1.1.m1.2.2.3" xref="S3.SS1.p1.1.m1.2.2.3.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.2.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.3.cmml"><mo id="S3.SS1.p1.1.m1.2.2.2.2.3" xref="S3.SS1.p1.1.m1.2.2.2.3.cmml">{</mo><msub id="S3.SS1.p1.1.m1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml">I</mi><mi id="S3.SS1.p1.1.m1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S3.SS1.p1.1.m1.2.2.2.2.4" xref="S3.SS1.p1.1.m1.2.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.1.m1.2.2.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.1.m1.2.2.2.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.2.2.2.cmml">G</mi><mi id="S3.SS1.p1.1.m1.2.2.2.2.2.3" xref="S3.SS1.p1.1.m1.2.2.2.2.2.3.cmml">l</mi></msub><mo id="S3.SS1.p1.1.m1.2.2.2.2.5" xref="S3.SS1.p1.1.m1.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2"><eq id="S3.SS1.p1.1.m1.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.3"></eq><apply id="S3.SS1.p1.1.m1.2.2.4.cmml" xref="S3.SS1.p1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.4.1.cmml" xref="S3.SS1.p1.1.m1.2.2.4">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.4.2.cmml" xref="S3.SS1.p1.1.m1.2.2.4.2">𝐷</ci><ci id="S3.SS1.p1.1.m1.2.2.4.3.cmml" xref="S3.SS1.p1.1.m1.2.2.4.3">𝑙</ci></apply><set id="S3.SS1.p1.1.m1.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2"><apply id="S3.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2">𝐼</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.3">𝑙</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2.2">𝐺</ci><ci id="S3.SS1.p1.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2.3">𝑙</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">D_{l}=\left\{I_{l},G_{l}\right\}</annotation></semantics></math> and the unlabeled dataset <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="D_{u}=\left\{I_{u}\right\}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><msub id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">D</mi><mi id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml">u</mi></msub><mo id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">=</mo><mrow id="S3.SS1.p1.2.m2.1.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.2.cmml"><mo id="S3.SS1.p1.2.m2.1.1.1.1.2" xref="S3.SS1.p1.2.m2.1.1.1.2.cmml">{</mo><msub id="S3.SS1.p1.2.m2.1.1.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.1.1.1.1.1.2.cmml">I</mi><mi id="S3.SS1.p1.2.m2.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.cmml">u</mi></msub><mo id="S3.SS1.p1.2.m2.1.1.1.1.3" xref="S3.SS1.p1.2.m2.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><eq id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2"></eq><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">𝐷</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">𝑢</ci></apply><set id="S3.SS1.p1.2.m2.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1"><apply id="S3.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.2">𝐼</ci><ci id="S3.SS1.p1.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3">𝑢</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">D_{u}=\left\{I_{u}\right\}</annotation></semantics></math>, <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="I_{l}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">I</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝐼</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">I_{l}</annotation></semantics></math> and <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="G_{l}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">G</mi><mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝐺</ci><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">G_{l}</annotation></semantics></math> represent the labeled images and the corresponding GTs, <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="I_{u}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">I</mi><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">𝐼</ci><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">I_{u}</annotation></semantics></math> represent the unlabeled images. In each training iteration, labeled and unlabeled data are randomly sampled from <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="D_{l}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">𝐷</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">D_{l}</annotation></semantics></math> and <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="D_{u}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><msub id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">𝐷</ci><ci id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">D_{u}</annotation></semantics></math>, respectively, to train the student branch.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">For the labeled data, a standard training pipeline is employed. The labeled data images are input to the network for forward propagation, and the supervised loss <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{sup}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">ℒ</mi><mrow id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml"><mi id="S3.SS1.p2.1.m1.1.1.3.2" xref="S3.SS1.p2.1.m1.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.1.1.3.1" xref="S3.SS1.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.1.m1.1.1.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.1.1.3.1a" xref="S3.SS1.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.1.m1.1.1.3.4" xref="S3.SS1.p2.1.m1.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ℒ</ci><apply id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3"><times id="S3.SS1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3.1"></times><ci id="S3.SS1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.2">𝑠</ci><ci id="S3.SS1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3">𝑢</ci><ci id="S3.SS1.p2.1.m1.1.1.3.4.cmml" xref="S3.SS1.p2.1.m1.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{L}_{sup}</annotation></semantics></math> is calculated by:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{sup}=\mathcal{L}_{det}(I_{l},G_{l})." display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.4.2" xref="S3.E1.m1.1.1.1.1.4.2.cmml">ℒ</mi><mrow id="S3.E1.m1.1.1.1.1.4.3" xref="S3.E1.m1.1.1.1.1.4.3.cmml"><mi id="S3.E1.m1.1.1.1.1.4.3.2" xref="S3.E1.m1.1.1.1.1.4.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.4.3.1" xref="S3.E1.m1.1.1.1.1.4.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.4.3.3" xref="S3.E1.m1.1.1.1.1.4.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.4.3.1a" xref="S3.E1.m1.1.1.1.1.4.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.4.3.4" xref="S3.E1.m1.1.1.1.1.4.3.4.cmml">p</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml"><msub id="S3.E1.m1.1.1.1.1.2.4" xref="S3.E1.m1.1.1.1.1.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.2.4.2" xref="S3.E1.m1.1.1.1.1.2.4.2.cmml">ℒ</mi><mrow id="S3.E1.m1.1.1.1.1.2.4.3" xref="S3.E1.m1.1.1.1.1.2.4.3.cmml"><mi id="S3.E1.m1.1.1.1.1.2.4.3.2" xref="S3.E1.m1.1.1.1.1.2.4.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2.4.3.1" xref="S3.E1.m1.1.1.1.1.2.4.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.2.4.3.3" xref="S3.E1.m1.1.1.1.1.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2.4.3.1a" xref="S3.E1.m1.1.1.1.1.2.4.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.2.4.3.4" xref="S3.E1.m1.1.1.1.1.2.4.3.4.cmml">t</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.2.3.cmml">​</mo><mrow id="S3.E1.m1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S3.E1.m1.1.1.1.1.2.2.2.4" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E1.m1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.cmml">G</mi><mi id="S3.E1.m1.1.1.1.1.2.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3.cmml">l</mi></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2.2.2.5" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"></eq><apply id="S3.E1.m1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.4.1.cmml" xref="S3.E1.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.4.2.cmml" xref="S3.E1.m1.1.1.1.1.4.2">ℒ</ci><apply id="S3.E1.m1.1.1.1.1.4.3.cmml" xref="S3.E1.m1.1.1.1.1.4.3"><times id="S3.E1.m1.1.1.1.1.4.3.1.cmml" xref="S3.E1.m1.1.1.1.1.4.3.1"></times><ci id="S3.E1.m1.1.1.1.1.4.3.2.cmml" xref="S3.E1.m1.1.1.1.1.4.3.2">𝑠</ci><ci id="S3.E1.m1.1.1.1.1.4.3.3.cmml" xref="S3.E1.m1.1.1.1.1.4.3.3">𝑢</ci><ci id="S3.E1.m1.1.1.1.1.4.3.4.cmml" xref="S3.E1.m1.1.1.1.1.4.3.4">𝑝</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"><times id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3"></times><apply id="S3.E1.m1.1.1.1.1.2.4.cmml" xref="S3.E1.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.4.1.cmml" xref="S3.E1.m1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.4.2.cmml" xref="S3.E1.m1.1.1.1.1.2.4.2">ℒ</ci><apply id="S3.E1.m1.1.1.1.1.2.4.3.cmml" xref="S3.E1.m1.1.1.1.1.2.4.3"><times id="S3.E1.m1.1.1.1.1.2.4.3.1.cmml" xref="S3.E1.m1.1.1.1.1.2.4.3.1"></times><ci id="S3.E1.m1.1.1.1.1.2.4.3.2.cmml" xref="S3.E1.m1.1.1.1.1.2.4.3.2">𝑑</ci><ci id="S3.E1.m1.1.1.1.1.2.4.3.3.cmml" xref="S3.E1.m1.1.1.1.1.2.4.3.3">𝑒</ci><ci id="S3.E1.m1.1.1.1.1.2.4.3.4.cmml" xref="S3.E1.m1.1.1.1.1.2.4.3.4">𝑡</ci></apply></apply><interval closure="open" id="S3.E1.m1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">𝐼</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">𝑙</ci></apply><apply id="S3.E1.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2">𝐺</ci><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3">𝑙</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\mathcal{L}_{sup}=\mathcal{L}_{det}(I_{l},G_{l}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.3" class="ltx_p">For the unlabeled data, weak and strong augmentations are respectively applied to the teacher and student models to enforce consistency regularization. The purpose of this step is to encourage the network to output consistent predictions for perturbed data and enhance the extraction of semantically invariant features. Following previous works, weak augmentation typically includes random flipping and resizing, while strong augmentation involves random rotation, translation, shearing, erasing, solarizing, adjusting color, contrast, sharpening, etc. In this paper, we did not explore new augmentation methods, and all strong and weak augmentation used are off-the-shelf approaches.
After applying strong and weak augmentations, each unlabeled image produces two views. The view with weak augmentation is input into the teacher model for inference, resulting in predicted detection results. Based on a predetermined threshold, suitable predictions are selected as pseudo-labels <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="P_{u}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">P</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">𝑃</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">P_{u}</annotation></semantics></math> for the unlabeled image. The view with strong augmentation, along with the pseudo-labels <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="P_{u}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">P</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">𝑃</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">P_{u}</annotation></semantics></math>, is fed into the student model. By leveraging the supervision signal provided by the pseudo-labels, the unsupervised loss <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{unsup}" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">ℒ</mi><mrow id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml"><mi id="S3.SS1.p3.3.m3.1.1.3.2" xref="S3.SS1.p3.3.m3.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.1.1.3.1" xref="S3.SS1.p3.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p3.3.m3.1.1.3.3" xref="S3.SS1.p3.3.m3.1.1.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.1.1.3.1a" xref="S3.SS1.p3.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p3.3.m3.1.1.3.4" xref="S3.SS1.p3.3.m3.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.1.1.3.1b" xref="S3.SS1.p3.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p3.3.m3.1.1.3.5" xref="S3.SS1.p3.3.m3.1.1.3.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.1.1.3.1c" xref="S3.SS1.p3.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p3.3.m3.1.1.3.6" xref="S3.SS1.p3.3.m3.1.1.3.6.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">ℒ</ci><apply id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3"><times id="S3.SS1.p3.3.m3.1.1.3.1.cmml" xref="S3.SS1.p3.3.m3.1.1.3.1"></times><ci id="S3.SS1.p3.3.m3.1.1.3.2.cmml" xref="S3.SS1.p3.3.m3.1.1.3.2">𝑢</ci><ci id="S3.SS1.p3.3.m3.1.1.3.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3">𝑛</ci><ci id="S3.SS1.p3.3.m3.1.1.3.4.cmml" xref="S3.SS1.p3.3.m3.1.1.3.4">𝑠</ci><ci id="S3.SS1.p3.3.m3.1.1.3.5.cmml" xref="S3.SS1.p3.3.m3.1.1.3.5">𝑢</ci><ci id="S3.SS1.p3.3.m3.1.1.3.6.cmml" xref="S3.SS1.p3.3.m3.1.1.3.6">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\mathcal{L}_{unsup}</annotation></semantics></math> is calculated by:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\mathcal{L}_{unsup}=\mathcal{L}_{det}(I_{u},P_{u})." display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.1.1.1.1.4.2" xref="S3.E2.m1.1.1.1.1.4.2.cmml">ℒ</mi><mrow id="S3.E2.m1.1.1.1.1.4.3" xref="S3.E2.m1.1.1.1.1.4.3.cmml"><mi id="S3.E2.m1.1.1.1.1.4.3.2" xref="S3.E2.m1.1.1.1.1.4.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.4.3.1" xref="S3.E2.m1.1.1.1.1.4.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.4.3.3" xref="S3.E2.m1.1.1.1.1.4.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.4.3.1a" xref="S3.E2.m1.1.1.1.1.4.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.4.3.4" xref="S3.E2.m1.1.1.1.1.4.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.4.3.1b" xref="S3.E2.m1.1.1.1.1.4.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.4.3.5" xref="S3.E2.m1.1.1.1.1.4.3.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.4.3.1c" xref="S3.E2.m1.1.1.1.1.4.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.4.3.6" xref="S3.E2.m1.1.1.1.1.4.3.6.cmml">p</mi></mrow></msub><mo id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml"><msub id="S3.E2.m1.1.1.1.1.2.4" xref="S3.E2.m1.1.1.1.1.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.1.1.1.1.2.4.2" xref="S3.E2.m1.1.1.1.1.2.4.2.cmml">ℒ</mi><mrow id="S3.E2.m1.1.1.1.1.2.4.3" xref="S3.E2.m1.1.1.1.1.2.4.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.4.3.2" xref="S3.E2.m1.1.1.1.1.2.4.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.4.3.1" xref="S3.E2.m1.1.1.1.1.2.4.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.2.4.3.3" xref="S3.E2.m1.1.1.1.1.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.4.3.1a" xref="S3.E2.m1.1.1.1.1.2.4.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.2.4.3.4" xref="S3.E2.m1.1.1.1.1.2.4.3.4.cmml">t</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.2.3.cmml">​</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml">u</mi></msub><mo id="S3.E2.m1.1.1.1.1.2.2.2.4" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E2.m1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml">P</mi><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml">u</mi></msub><mo stretchy="false" id="S3.E2.m1.1.1.1.1.2.2.2.5" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"></eq><apply id="S3.E2.m1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.4.1.cmml" xref="S3.E2.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.4.2.cmml" xref="S3.E2.m1.1.1.1.1.4.2">ℒ</ci><apply id="S3.E2.m1.1.1.1.1.4.3.cmml" xref="S3.E2.m1.1.1.1.1.4.3"><times id="S3.E2.m1.1.1.1.1.4.3.1.cmml" xref="S3.E2.m1.1.1.1.1.4.3.1"></times><ci id="S3.E2.m1.1.1.1.1.4.3.2.cmml" xref="S3.E2.m1.1.1.1.1.4.3.2">𝑢</ci><ci id="S3.E2.m1.1.1.1.1.4.3.3.cmml" xref="S3.E2.m1.1.1.1.1.4.3.3">𝑛</ci><ci id="S3.E2.m1.1.1.1.1.4.3.4.cmml" xref="S3.E2.m1.1.1.1.1.4.3.4">𝑠</ci><ci id="S3.E2.m1.1.1.1.1.4.3.5.cmml" xref="S3.E2.m1.1.1.1.1.4.3.5">𝑢</ci><ci id="S3.E2.m1.1.1.1.1.4.3.6.cmml" xref="S3.E2.m1.1.1.1.1.4.3.6">𝑝</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"><times id="S3.E2.m1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.3"></times><apply id="S3.E2.m1.1.1.1.1.2.4.cmml" xref="S3.E2.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.4.1.cmml" xref="S3.E2.m1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.4.2.cmml" xref="S3.E2.m1.1.1.1.1.2.4.2">ℒ</ci><apply id="S3.E2.m1.1.1.1.1.2.4.3.cmml" xref="S3.E2.m1.1.1.1.1.2.4.3"><times id="S3.E2.m1.1.1.1.1.2.4.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.4.3.1"></times><ci id="S3.E2.m1.1.1.1.1.2.4.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.4.3.2">𝑑</ci><ci id="S3.E2.m1.1.1.1.1.2.4.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.4.3.3">𝑒</ci><ci id="S3.E2.m1.1.1.1.1.2.4.3.4.cmml" xref="S3.E2.m1.1.1.1.1.2.4.3.4">𝑡</ci></apply></apply><interval closure="open" id="S3.E2.m1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2"><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2">𝐼</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3">𝑢</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2">𝑃</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3">𝑢</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\mathcal{L}_{unsup}=\mathcal{L}_{det}(I_{u},P_{u}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.2" class="ltx_p">The overall loss function is formulated as:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\mathcal{L}=\mathcal{L}_{sup}+\alpha*\mathcal{L}_{unsup}," display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml">ℒ</mi><mo id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><msub id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.3.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.cmml">ℒ</mi><mrow id="S3.E3.m1.1.1.1.1.3.2.3" xref="S3.E3.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.2.3.2" xref="S3.E3.m1.1.1.1.1.3.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.2.3.1" xref="S3.E3.m1.1.1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.2.3.3" xref="S3.E3.m1.1.1.1.1.3.2.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.2.3.1a" xref="S3.E3.m1.1.1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.2.3.4" xref="S3.E3.m1.1.1.1.1.3.2.3.4.cmml">p</mi></mrow></msub><mo id="S3.E3.m1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.3.3.2.cmml">α</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.1.1.1.1.3.3.1" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">∗</mo><msub id="S3.E3.m1.1.1.1.1.3.3.3" xref="S3.E3.m1.1.1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.3.3.3.2" xref="S3.E3.m1.1.1.1.1.3.3.3.2.cmml">ℒ</mi><mrow id="S3.E3.m1.1.1.1.1.3.3.3.3" xref="S3.E3.m1.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.3.3.3.2" xref="S3.E3.m1.1.1.1.1.3.3.3.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.3.3.1" xref="S3.E3.m1.1.1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.3.3.3" xref="S3.E3.m1.1.1.1.1.3.3.3.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.3.3.1a" xref="S3.E3.m1.1.1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.3.3.4" xref="S3.E3.m1.1.1.1.1.3.3.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.3.3.1b" xref="S3.E3.m1.1.1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.3.3.5" xref="S3.E3.m1.1.1.1.1.3.3.3.3.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.3.3.1c" xref="S3.E3.m1.1.1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.3.3.6" xref="S3.E3.m1.1.1.1.1.3.3.3.3.6.cmml">p</mi></mrow></msub></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"></eq><ci id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2">ℒ</ci><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><plus id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.1"></plus><apply id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2">ℒ</ci><apply id="S3.E3.m1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.3"><times id="S3.E3.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2.3.1"></times><ci id="S3.E3.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.3.2">𝑠</ci><ci id="S3.E3.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.3.3">𝑢</ci><ci id="S3.E3.m1.1.1.1.1.3.2.3.4.cmml" xref="S3.E3.m1.1.1.1.1.3.2.3.4">𝑝</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3"><times id="S3.E3.m1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1"></times><ci id="S3.E3.m1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.2">𝛼</ci><apply id="S3.E3.m1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.2">ℒ</ci><apply id="S3.E3.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.3"><times id="S3.E3.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.3.1"></times><ci id="S3.E3.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.3.2">𝑢</ci><ci id="S3.E3.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.3.3">𝑛</ci><ci id="S3.E3.m1.1.1.1.1.3.3.3.3.4.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.3.4">𝑠</ci><ci id="S3.E3.m1.1.1.1.1.3.3.3.3.5.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.3.5">𝑢</ci><ci id="S3.E3.m1.1.1.1.1.3.3.3.3.6.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.3.6">𝑝</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\mathcal{L}=\mathcal{L}_{sup}+\alpha*\mathcal{L}_{unsup},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p4.1" class="ltx_p">where <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\alpha</annotation></semantics></math> represents a weight parameter utilized to balance the contribution of unlabeled data.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">To enable a fair comparison with previous methods, we take the well-established rotated version of Faster R-CNN as the basic detector. Without losing generality, our approach is applicable to any anchor-based detection method with the two-stage framework.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Size-aware Adaptive Thresholding</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Most of the existing SSOD methods utilize a fixed threshold to filter pseudo-labels. However, when processing data with unbalanced distribution, fixed thresholds are not always conducive to all situations. Previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite> have pointed out the class confidence imbalance problem, where the class-wise reweighing or sampling strategy was correspondingly proposed to tackle this issue. Nevertheless, as analyzed in Sec. <a href="#S1" title="I Introduction ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, existing works commonly neglect the size-confidence imbalance issue in aerial imagery.
Towards this end, we propose to define pseudo-labels in a size <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">dividing-and-conquering</span> manner, and we name this strategy Size-aware Adaptive Thresholding (SAT).</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">In the SAT, we first compute the statistics of all predicted results from the teacher model with confidence scores higher than 0.5 within a batch. These results are then divided into two distributions based on the size of the object bounding boxes: one for large objects and the other for small objects. After this, the <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">P</annotation></semantics></math>-th percentile of each distribution is chosen as the threshold for large and small predictions, respectively, in order to retain a balanced quantity of reliable pseudo-labels for different-sized objects.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Size-rebalanced Label Assignment</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">After obtaining a series of pseudo-labels, we need to assign positive or negative (<span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">pos/neg</span>) labels to predefined anchors based on the obtained pseudo-labels to train the object detector. Meanwhile, the sample assignment between pseudo-labels and anchors plays quite a significant role in the performance of SSOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>, <a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>.
During this process, we observe two problems for aerial images, <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_italic">i.e.,</span> the sample insufficiency issue and the feature inconsistency issue, as discussed in Sec. <a href="#S1" title="I Introduction ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.4" class="ltx_p">To address these issues, we propose the Size-rebalanced Label Assignment (SLA) strategy, which explores size-balanced learning through two key aspects: distribution-based re-sampling and size-aware re-weighting. In the distribution-based re-sampling, we model the rotated box <math id="S3.SS3.p2.1.m1.5" class="ltx_Math" alttext="(cx,cy,w,h,\theta)" display="inline"><semantics id="S3.SS3.p2.1.m1.5a"><mrow id="S3.SS3.p2.1.m1.5.5.2" xref="S3.SS3.p2.1.m1.5.5.3.cmml"><mo stretchy="false" id="S3.SS3.p2.1.m1.5.5.2.3" xref="S3.SS3.p2.1.m1.5.5.3.cmml">(</mo><mrow id="S3.SS3.p2.1.m1.4.4.1.1" xref="S3.SS3.p2.1.m1.4.4.1.1.cmml"><mi id="S3.SS3.p2.1.m1.4.4.1.1.2" xref="S3.SS3.p2.1.m1.4.4.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.4.4.1.1.1" xref="S3.SS3.p2.1.m1.4.4.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.1.m1.4.4.1.1.3" xref="S3.SS3.p2.1.m1.4.4.1.1.3.cmml">x</mi></mrow><mo id="S3.SS3.p2.1.m1.5.5.2.4" xref="S3.SS3.p2.1.m1.5.5.3.cmml">,</mo><mrow id="S3.SS3.p2.1.m1.5.5.2.2" xref="S3.SS3.p2.1.m1.5.5.2.2.cmml"><mi id="S3.SS3.p2.1.m1.5.5.2.2.2" xref="S3.SS3.p2.1.m1.5.5.2.2.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.5.5.2.2.1" xref="S3.SS3.p2.1.m1.5.5.2.2.1.cmml">​</mo><mi id="S3.SS3.p2.1.m1.5.5.2.2.3" xref="S3.SS3.p2.1.m1.5.5.2.2.3.cmml">y</mi></mrow><mo id="S3.SS3.p2.1.m1.5.5.2.5" xref="S3.SS3.p2.1.m1.5.5.3.cmml">,</mo><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">w</mi><mo id="S3.SS3.p2.1.m1.5.5.2.6" xref="S3.SS3.p2.1.m1.5.5.3.cmml">,</mo><mi id="S3.SS3.p2.1.m1.2.2" xref="S3.SS3.p2.1.m1.2.2.cmml">h</mi><mo id="S3.SS3.p2.1.m1.5.5.2.7" xref="S3.SS3.p2.1.m1.5.5.3.cmml">,</mo><mi id="S3.SS3.p2.1.m1.3.3" xref="S3.SS3.p2.1.m1.3.3.cmml">θ</mi><mo stretchy="false" id="S3.SS3.p2.1.m1.5.5.2.8" xref="S3.SS3.p2.1.m1.5.5.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.5b"><vector id="S3.SS3.p2.1.m1.5.5.3.cmml" xref="S3.SS3.p2.1.m1.5.5.2"><apply id="S3.SS3.p2.1.m1.4.4.1.1.cmml" xref="S3.SS3.p2.1.m1.4.4.1.1"><times id="S3.SS3.p2.1.m1.4.4.1.1.1.cmml" xref="S3.SS3.p2.1.m1.4.4.1.1.1"></times><ci id="S3.SS3.p2.1.m1.4.4.1.1.2.cmml" xref="S3.SS3.p2.1.m1.4.4.1.1.2">𝑐</ci><ci id="S3.SS3.p2.1.m1.4.4.1.1.3.cmml" xref="S3.SS3.p2.1.m1.4.4.1.1.3">𝑥</ci></apply><apply id="S3.SS3.p2.1.m1.5.5.2.2.cmml" xref="S3.SS3.p2.1.m1.5.5.2.2"><times id="S3.SS3.p2.1.m1.5.5.2.2.1.cmml" xref="S3.SS3.p2.1.m1.5.5.2.2.1"></times><ci id="S3.SS3.p2.1.m1.5.5.2.2.2.cmml" xref="S3.SS3.p2.1.m1.5.5.2.2.2">𝑐</ci><ci id="S3.SS3.p2.1.m1.5.5.2.2.3.cmml" xref="S3.SS3.p2.1.m1.5.5.2.2.3">𝑦</ci></apply><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">𝑤</ci><ci id="S3.SS3.p2.1.m1.2.2.cmml" xref="S3.SS3.p2.1.m1.2.2">ℎ</ci><ci id="S3.SS3.p2.1.m1.3.3.cmml" xref="S3.SS3.p2.1.m1.3.3">𝜃</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.5c">(cx,cy,w,h,\theta)</annotation></semantics></math> into the two-dimensional Gaussian distribution <math id="S3.SS3.p2.2.m2.2" class="ltx_Math" alttext="\mathcal{N}(\boldsymbol{\mu},\boldsymbol{\Sigma})" display="inline"><semantics id="S3.SS3.p2.2.m2.2a"><mrow id="S3.SS3.p2.2.m2.2.3" xref="S3.SS3.p2.2.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.2.m2.2.3.2" xref="S3.SS3.p2.2.m2.2.3.2.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.2.m2.2.3.1" xref="S3.SS3.p2.2.m2.2.3.1.cmml">​</mo><mrow id="S3.SS3.p2.2.m2.2.3.3.2" xref="S3.SS3.p2.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS3.p2.2.m2.2.3.3.2.1" xref="S3.SS3.p2.2.m2.2.3.3.1.cmml">(</mo><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">𝝁</mi><mo id="S3.SS3.p2.2.m2.2.3.3.2.2" xref="S3.SS3.p2.2.m2.2.3.3.1.cmml">,</mo><mi id="S3.SS3.p2.2.m2.2.2" xref="S3.SS3.p2.2.m2.2.2.cmml">𝚺</mi><mo stretchy="false" id="S3.SS3.p2.2.m2.2.3.3.2.3" xref="S3.SS3.p2.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.2b"><apply id="S3.SS3.p2.2.m2.2.3.cmml" xref="S3.SS3.p2.2.m2.2.3"><times id="S3.SS3.p2.2.m2.2.3.1.cmml" xref="S3.SS3.p2.2.m2.2.3.1"></times><ci id="S3.SS3.p2.2.m2.2.3.2.cmml" xref="S3.SS3.p2.2.m2.2.3.2">𝒩</ci><interval closure="open" id="S3.SS3.p2.2.m2.2.3.3.1.cmml" xref="S3.SS3.p2.2.m2.2.3.3.2"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">𝝁</ci><ci id="S3.SS3.p2.2.m2.2.2.cmml" xref="S3.SS3.p2.2.m2.2.2">𝚺</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.2c">\mathcal{N}(\boldsymbol{\mu},\boldsymbol{\Sigma})</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">86</span></a>, <a href="#bib.bib87" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">87</span></a>]</cite>, in which the box’s geometry center <math id="S3.SS3.p2.3.m3.2" class="ltx_Math" alttext="\boldsymbol{\mu}=(cx,cy)" display="inline"><semantics id="S3.SS3.p2.3.m3.2a"><mrow id="S3.SS3.p2.3.m3.2.2" xref="S3.SS3.p2.3.m3.2.2.cmml"><mi id="S3.SS3.p2.3.m3.2.2.4" xref="S3.SS3.p2.3.m3.2.2.4.cmml">𝝁</mi><mo id="S3.SS3.p2.3.m3.2.2.3" xref="S3.SS3.p2.3.m3.2.2.3.cmml">=</mo><mrow id="S3.SS3.p2.3.m3.2.2.2.2" xref="S3.SS3.p2.3.m3.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p2.3.m3.2.2.2.2.3" xref="S3.SS3.p2.3.m3.2.2.2.3.cmml">(</mo><mrow id="S3.SS3.p2.3.m3.1.1.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.1.1.1.2" xref="S3.SS3.p2.3.m3.1.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.1.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.3.m3.1.1.1.1.1.3" xref="S3.SS3.p2.3.m3.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.SS3.p2.3.m3.2.2.2.2.4" xref="S3.SS3.p2.3.m3.2.2.2.3.cmml">,</mo><mrow id="S3.SS3.p2.3.m3.2.2.2.2.2" xref="S3.SS3.p2.3.m3.2.2.2.2.2.cmml"><mi id="S3.SS3.p2.3.m3.2.2.2.2.2.2" xref="S3.SS3.p2.3.m3.2.2.2.2.2.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.2.2.2.2.2.1" xref="S3.SS3.p2.3.m3.2.2.2.2.2.1.cmml">​</mo><mi id="S3.SS3.p2.3.m3.2.2.2.2.2.3" xref="S3.SS3.p2.3.m3.2.2.2.2.2.3.cmml">y</mi></mrow><mo stretchy="false" id="S3.SS3.p2.3.m3.2.2.2.2.5" xref="S3.SS3.p2.3.m3.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.2b"><apply id="S3.SS3.p2.3.m3.2.2.cmml" xref="S3.SS3.p2.3.m3.2.2"><eq id="S3.SS3.p2.3.m3.2.2.3.cmml" xref="S3.SS3.p2.3.m3.2.2.3"></eq><ci id="S3.SS3.p2.3.m3.2.2.4.cmml" xref="S3.SS3.p2.3.m3.2.2.4">𝝁</ci><interval closure="open" id="S3.SS3.p2.3.m3.2.2.2.3.cmml" xref="S3.SS3.p2.3.m3.2.2.2.2"><apply id="S3.SS3.p2.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1.1.1"><times id="S3.SS3.p2.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1.1.1.1"></times><ci id="S3.SS3.p2.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.1.1.1.2">𝑐</ci><ci id="S3.SS3.p2.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.1.1.1.3">𝑥</ci></apply><apply id="S3.SS3.p2.3.m3.2.2.2.2.2.cmml" xref="S3.SS3.p2.3.m3.2.2.2.2.2"><times id="S3.SS3.p2.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS3.p2.3.m3.2.2.2.2.2.1"></times><ci id="S3.SS3.p2.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS3.p2.3.m3.2.2.2.2.2.2">𝑐</ci><ci id="S3.SS3.p2.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS3.p2.3.m3.2.2.2.2.2.3">𝑦</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.2c">\boldsymbol{\mu}=(cx,cy)</annotation></semantics></math> serves as the Gaussian’s mean vector. And <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="\boldsymbol{\Sigma}" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">𝚺</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">𝚺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\boldsymbol{\Sigma}</annotation></semantics></math> is the covariance matrix of the Gaussian distribution, which can be computed by:</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.4" class="ltx_Math" alttext="\small\mathbf{\Sigma}=\begin{bmatrix}\cos{\theta}&amp;-\sin{\theta}\\
\sin{\theta}&amp;\cos{\theta}\end{bmatrix}\begin{bmatrix}\frac{w^{2}}{4}&amp;0\\
0&amp;\frac{h^{2}}{4}\end{bmatrix}\begin{bmatrix}\cos{\theta}&amp;\sin{\theta}\\
-\sin{\theta}&amp;\cos{\theta}\end{bmatrix}." display="block"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.4.1" xref="S3.E4.m1.4.4.1.1.cmml"><mrow id="S3.E4.m1.4.4.1.1" xref="S3.E4.m1.4.4.1.1.cmml"><mi mathsize="90%" id="S3.E4.m1.4.4.1.1.2" xref="S3.E4.m1.4.4.1.1.2.cmml">𝚺</mi><mo mathsize="90%" id="S3.E4.m1.4.4.1.1.1" xref="S3.E4.m1.4.4.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.4.4.1.1.3" xref="S3.E4.m1.4.4.1.1.3.cmml"><mrow id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.2.cmml"><mo id="S3.E4.m1.1.1.3.1" xref="S3.E4.m1.1.1.2.1.cmml">[</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mtr id="S3.E4.m1.1.1.1.1a" xref="S3.E4.m1.1.1.1.1.cmml"><mtd id="S3.E4.m1.1.1.1.1b" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">cos</mi><mo lspace="0.167em" id="S3.E4.m1.1.1.1.1.1.1.1a" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml">⁡</mo><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.2.cmml">θ</mi></mrow></mtd><mtd id="S3.E4.m1.1.1.1.1c" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.2.1" xref="S3.E4.m1.1.1.1.1.1.2.1.cmml"><mo mathsize="90%" rspace="0.167em" id="S3.E4.m1.1.1.1.1.1.2.1a" xref="S3.E4.m1.1.1.1.1.1.2.1.cmml">−</mo><mrow id="S3.E4.m1.1.1.1.1.1.2.1.2" xref="S3.E4.m1.1.1.1.1.1.2.1.2.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.2.1.2.1" xref="S3.E4.m1.1.1.1.1.1.2.1.2.1.cmml">sin</mi><mo lspace="0.167em" id="S3.E4.m1.1.1.1.1.1.2.1.2a" xref="S3.E4.m1.1.1.1.1.1.2.1.2.cmml">⁡</mo><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.2.1.2.2" xref="S3.E4.m1.1.1.1.1.1.2.1.2.2.cmml">θ</mi></mrow></mrow></mtd></mtr><mtr id="S3.E4.m1.1.1.1.1d" xref="S3.E4.m1.1.1.1.1.cmml"><mtd id="S3.E4.m1.1.1.1.1e" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.2.1.1" xref="S3.E4.m1.1.1.1.1.2.1.1.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.2.1.1.1" xref="S3.E4.m1.1.1.1.1.2.1.1.1.cmml">sin</mi><mo lspace="0.167em" id="S3.E4.m1.1.1.1.1.2.1.1a" xref="S3.E4.m1.1.1.1.1.2.1.1.cmml">⁡</mo><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.2.1.1.2" xref="S3.E4.m1.1.1.1.1.2.1.1.2.cmml">θ</mi></mrow></mtd><mtd id="S3.E4.m1.1.1.1.1f" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.2.2.1" xref="S3.E4.m1.1.1.1.1.2.2.1.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.2.2.1.1" xref="S3.E4.m1.1.1.1.1.2.2.1.1.cmml">cos</mi><mo lspace="0.167em" id="S3.E4.m1.1.1.1.1.2.2.1a" xref="S3.E4.m1.1.1.1.1.2.2.1.cmml">⁡</mo><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.2.2.1.2" xref="S3.E4.m1.1.1.1.1.2.2.1.2.cmml">θ</mi></mrow></mtd></mtr></mtable><mo id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.2.1.cmml">]</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.3.1" xref="S3.E4.m1.4.4.1.1.3.1.cmml">​</mo><mrow id="S3.E4.m1.2.2.3" xref="S3.E4.m1.2.2.2.cmml"><mo id="S3.E4.m1.2.2.3.1" xref="S3.E4.m1.2.2.2.1.cmml">[</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.E4.m1.2.2.1.1" xref="S3.E4.m1.2.2.1.1.cmml"><mtr id="S3.E4.m1.2.2.1.1a" xref="S3.E4.m1.2.2.1.1.cmml"><mtd id="S3.E4.m1.2.2.1.1b" xref="S3.E4.m1.2.2.1.1.cmml"><mstyle displaystyle="false" id="S3.E4.m1.2.2.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.cmml"><mfrac id="S3.E4.m1.2.2.1.1.1.1.1a" xref="S3.E4.m1.2.2.1.1.1.1.1.cmml"><msup id="S3.E4.m1.2.2.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S3.E4.m1.2.2.1.1.1.1.1.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.2.2.cmml">w</mi><mn mathsize="90%" id="S3.E4.m1.2.2.1.1.1.1.1.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.2.3.cmml">2</mn></msup><mn mathsize="90%" id="S3.E4.m1.2.2.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.1.3.cmml">4</mn></mfrac></mstyle></mtd><mtd id="S3.E4.m1.2.2.1.1c" xref="S3.E4.m1.2.2.1.1.cmml"><mn mathsize="90%" id="S3.E4.m1.2.2.1.1.1.2.1" xref="S3.E4.m1.2.2.1.1.1.2.1.cmml">0</mn></mtd></mtr><mtr id="S3.E4.m1.2.2.1.1d" xref="S3.E4.m1.2.2.1.1.cmml"><mtd id="S3.E4.m1.2.2.1.1e" xref="S3.E4.m1.2.2.1.1.cmml"><mn mathsize="90%" id="S3.E4.m1.2.2.1.1.2.1.1" xref="S3.E4.m1.2.2.1.1.2.1.1.cmml">0</mn></mtd><mtd id="S3.E4.m1.2.2.1.1f" xref="S3.E4.m1.2.2.1.1.cmml"><mstyle displaystyle="false" id="S3.E4.m1.2.2.1.1.2.2.1" xref="S3.E4.m1.2.2.1.1.2.2.1.cmml"><mfrac id="S3.E4.m1.2.2.1.1.2.2.1a" xref="S3.E4.m1.2.2.1.1.2.2.1.cmml"><msup id="S3.E4.m1.2.2.1.1.2.2.1.2" xref="S3.E4.m1.2.2.1.1.2.2.1.2.cmml"><mi mathsize="90%" id="S3.E4.m1.2.2.1.1.2.2.1.2.2" xref="S3.E4.m1.2.2.1.1.2.2.1.2.2.cmml">h</mi><mn mathsize="90%" id="S3.E4.m1.2.2.1.1.2.2.1.2.3" xref="S3.E4.m1.2.2.1.1.2.2.1.2.3.cmml">2</mn></msup><mn mathsize="90%" id="S3.E4.m1.2.2.1.1.2.2.1.3" xref="S3.E4.m1.2.2.1.1.2.2.1.3.cmml">4</mn></mfrac></mstyle></mtd></mtr></mtable><mo id="S3.E4.m1.2.2.3.2" xref="S3.E4.m1.2.2.2.1.cmml">]</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.3.1a" xref="S3.E4.m1.4.4.1.1.3.1.cmml">​</mo><mrow id="S3.E4.m1.3.3.3" xref="S3.E4.m1.3.3.2.cmml"><mo id="S3.E4.m1.3.3.3.1" xref="S3.E4.m1.3.3.2.1.cmml">[</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><mtr id="S3.E4.m1.3.3.1.1a" xref="S3.E4.m1.3.3.1.1.cmml"><mtd id="S3.E4.m1.3.3.1.1b" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E4.m1.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml">cos</mi><mo lspace="0.167em" id="S3.E4.m1.3.3.1.1.1.1.1a" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml">⁡</mo><mi mathsize="90%" id="S3.E4.m1.3.3.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">θ</mi></mrow></mtd><mtd id="S3.E4.m1.3.3.1.1c" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.1.2.1" xref="S3.E4.m1.3.3.1.1.1.2.1.cmml"><mi mathsize="90%" id="S3.E4.m1.3.3.1.1.1.2.1.1" xref="S3.E4.m1.3.3.1.1.1.2.1.1.cmml">sin</mi><mo lspace="0.167em" id="S3.E4.m1.3.3.1.1.1.2.1a" xref="S3.E4.m1.3.3.1.1.1.2.1.cmml">⁡</mo><mi mathsize="90%" id="S3.E4.m1.3.3.1.1.1.2.1.2" xref="S3.E4.m1.3.3.1.1.1.2.1.2.cmml">θ</mi></mrow></mtd></mtr><mtr id="S3.E4.m1.3.3.1.1d" xref="S3.E4.m1.3.3.1.1.cmml"><mtd id="S3.E4.m1.3.3.1.1e" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.2.1.1" xref="S3.E4.m1.3.3.1.1.2.1.1.cmml"><mo mathsize="90%" rspace="0.167em" id="S3.E4.m1.3.3.1.1.2.1.1a" xref="S3.E4.m1.3.3.1.1.2.1.1.cmml">−</mo><mrow id="S3.E4.m1.3.3.1.1.2.1.1.2" xref="S3.E4.m1.3.3.1.1.2.1.1.2.cmml"><mi mathsize="90%" id="S3.E4.m1.3.3.1.1.2.1.1.2.1" xref="S3.E4.m1.3.3.1.1.2.1.1.2.1.cmml">sin</mi><mo lspace="0.167em" id="S3.E4.m1.3.3.1.1.2.1.1.2a" xref="S3.E4.m1.3.3.1.1.2.1.1.2.cmml">⁡</mo><mi mathsize="90%" id="S3.E4.m1.3.3.1.1.2.1.1.2.2" xref="S3.E4.m1.3.3.1.1.2.1.1.2.2.cmml">θ</mi></mrow></mrow></mtd><mtd id="S3.E4.m1.3.3.1.1f" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.2.2.1" xref="S3.E4.m1.3.3.1.1.2.2.1.cmml"><mi mathsize="90%" id="S3.E4.m1.3.3.1.1.2.2.1.1" xref="S3.E4.m1.3.3.1.1.2.2.1.1.cmml">cos</mi><mo lspace="0.167em" id="S3.E4.m1.3.3.1.1.2.2.1a" xref="S3.E4.m1.3.3.1.1.2.2.1.cmml">⁡</mo><mi mathsize="90%" id="S3.E4.m1.3.3.1.1.2.2.1.2" xref="S3.E4.m1.3.3.1.1.2.2.1.2.cmml">θ</mi></mrow></mtd></mtr></mtable><mo id="S3.E4.m1.3.3.3.2" xref="S3.E4.m1.3.3.2.1.cmml">]</mo></mrow></mrow></mrow><mo lspace="0em" mathsize="90%" id="S3.E4.m1.4.4.1.2" xref="S3.E4.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.4.1.1.cmml" xref="S3.E4.m1.4.4.1"><eq id="S3.E4.m1.4.4.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1"></eq><ci id="S3.E4.m1.4.4.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.2">𝚺</ci><apply id="S3.E4.m1.4.4.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.3"><times id="S3.E4.m1.4.4.1.1.3.1.cmml" xref="S3.E4.m1.4.4.1.1.3.1"></times><apply id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.3"><csymbol cd="latexml" id="S3.E4.m1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.3.1">matrix</csymbol><matrix id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1"><matrixrow id="S3.E4.m1.1.1.1.1a.cmml" xref="S3.E4.m1.1.1.1.1"><apply id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><cos id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"></cos><ci id="S3.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.2">𝜃</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.2.1"><minus id="S3.E4.m1.1.1.1.1.1.2.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.2.1"></minus><apply id="S3.E4.m1.1.1.1.1.1.2.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2.1.2"><sin id="S3.E4.m1.1.1.1.1.1.2.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.2.1.2.1"></sin><ci id="S3.E4.m1.1.1.1.1.1.2.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2.1.2.2">𝜃</ci></apply></apply></matrixrow><matrixrow id="S3.E4.m1.1.1.1.1b.cmml" xref="S3.E4.m1.1.1.1.1"><apply id="S3.E4.m1.1.1.1.1.2.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1"><sin id="S3.E4.m1.1.1.1.1.2.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1"></sin><ci id="S3.E4.m1.1.1.1.1.2.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.2">𝜃</ci></apply><apply id="S3.E4.m1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1"><cos id="S3.E4.m1.1.1.1.1.2.2.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1"></cos><ci id="S3.E4.m1.1.1.1.1.2.2.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.2">𝜃</ci></apply></matrixrow></matrix></apply><apply id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.3"><csymbol cd="latexml" id="S3.E4.m1.2.2.2.1.cmml" xref="S3.E4.m1.2.2.3.1">matrix</csymbol><matrix id="S3.E4.m1.2.2.1.1.cmml" xref="S3.E4.m1.2.2.1.1"><matrixrow id="S3.E4.m1.2.2.1.1a.cmml" xref="S3.E4.m1.2.2.1.1"><apply id="S3.E4.m1.2.2.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1"><divide id="S3.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1"></divide><apply id="S3.E4.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.2.2">𝑤</ci><cn type="integer" id="S3.E4.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.2.3">2</cn></apply><cn type="integer" id="S3.E4.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.3">4</cn></apply><cn type="integer" id="S3.E4.m1.2.2.1.1.1.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.2.1">0</cn></matrixrow><matrixrow id="S3.E4.m1.2.2.1.1b.cmml" xref="S3.E4.m1.2.2.1.1"><cn type="integer" id="S3.E4.m1.2.2.1.1.2.1.1.cmml" xref="S3.E4.m1.2.2.1.1.2.1.1">0</cn><apply id="S3.E4.m1.2.2.1.1.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.2.2.1"><divide id="S3.E4.m1.2.2.1.1.2.2.1.1.cmml" xref="S3.E4.m1.2.2.1.1.2.2.1"></divide><apply id="S3.E4.m1.2.2.1.1.2.2.1.2.cmml" xref="S3.E4.m1.2.2.1.1.2.2.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.2.2.1.2.1.cmml" xref="S3.E4.m1.2.2.1.1.2.2.1.2">superscript</csymbol><ci id="S3.E4.m1.2.2.1.1.2.2.1.2.2.cmml" xref="S3.E4.m1.2.2.1.1.2.2.1.2.2">ℎ</ci><cn type="integer" id="S3.E4.m1.2.2.1.1.2.2.1.2.3.cmml" xref="S3.E4.m1.2.2.1.1.2.2.1.2.3">2</cn></apply><cn type="integer" id="S3.E4.m1.2.2.1.1.2.2.1.3.cmml" xref="S3.E4.m1.2.2.1.1.2.2.1.3">4</cn></apply></matrixrow></matrix></apply><apply id="S3.E4.m1.3.3.2.cmml" xref="S3.E4.m1.3.3.3"><csymbol cd="latexml" id="S3.E4.m1.3.3.2.1.cmml" xref="S3.E4.m1.3.3.3.1">matrix</csymbol><matrix id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1.1"><matrixrow id="S3.E4.m1.3.3.1.1a.cmml" xref="S3.E4.m1.3.3.1.1"><apply id="S3.E4.m1.3.3.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1"><cos id="S3.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1"></cos><ci id="S3.E4.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2">𝜃</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.2.1"><sin id="S3.E4.m1.3.3.1.1.1.2.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.2.1.1"></sin><ci id="S3.E4.m1.3.3.1.1.1.2.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.2.1.2">𝜃</ci></apply></matrixrow><matrixrow id="S3.E4.m1.3.3.1.1b.cmml" xref="S3.E4.m1.3.3.1.1"><apply id="S3.E4.m1.3.3.1.1.2.1.1.cmml" xref="S3.E4.m1.3.3.1.1.2.1.1"><minus id="S3.E4.m1.3.3.1.1.2.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.2.1.1"></minus><apply id="S3.E4.m1.3.3.1.1.2.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2.1.1.2"><sin id="S3.E4.m1.3.3.1.1.2.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.2.1.1.2.1"></sin><ci id="S3.E4.m1.3.3.1.1.2.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.2.1.1.2.2">𝜃</ci></apply></apply><apply id="S3.E4.m1.3.3.1.1.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.2.2.1"><cos id="S3.E4.m1.3.3.1.1.2.2.1.1.cmml" xref="S3.E4.m1.3.3.1.1.2.2.1.1"></cos><ci id="S3.E4.m1.3.3.1.1.2.2.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2.2.1.2">𝜃</ci></apply></matrixrow></matrix></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">\small\mathbf{\Sigma}=\begin{bmatrix}\cos{\theta}&amp;-\sin{\theta}\\
\sin{\theta}&amp;\cos{\theta}\end{bmatrix}\begin{bmatrix}\frac{w^{2}}{4}&amp;0\\
0&amp;\frac{h^{2}}{4}\end{bmatrix}\begin{bmatrix}\cos{\theta}&amp;\sin{\theta}\\
-\sin{\theta}&amp;\cos{\theta}\end{bmatrix}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.2" class="ltx_p">Based on the distribution-based modeling, we use the Wasserstein distance to measure the similarity between pseudo-boxes and anchors since the Wasserstein distance is demonstrated conducive to tiny objects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>, <a href="#bib.bib86" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">86</span></a>]</cite> in label assignment, mainly owing to its ability to measure non-overlapping boxes. Specifically, the Wasserstein distance between the Gaussian pseudo-box <math id="S3.SS3.p4.1.m1.2" class="ltx_Math" alttext="\mathcal{N}_{p}(\boldsymbol{\mu}_{p},\boldsymbol{\Sigma}_{p})" display="inline"><semantics id="S3.SS3.p4.1.m1.2a"><mrow id="S3.SS3.p4.1.m1.2.2" xref="S3.SS3.p4.1.m1.2.2.cmml"><msub id="S3.SS3.p4.1.m1.2.2.4" xref="S3.SS3.p4.1.m1.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.1.m1.2.2.4.2" xref="S3.SS3.p4.1.m1.2.2.4.2.cmml">𝒩</mi><mi id="S3.SS3.p4.1.m1.2.2.4.3" xref="S3.SS3.p4.1.m1.2.2.4.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p4.1.m1.2.2.3" xref="S3.SS3.p4.1.m1.2.2.3.cmml">​</mo><mrow id="S3.SS3.p4.1.m1.2.2.2.2" xref="S3.SS3.p4.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p4.1.m1.2.2.2.2.3" xref="S3.SS3.p4.1.m1.2.2.2.3.cmml">(</mo><msub id="S3.SS3.p4.1.m1.1.1.1.1.1" xref="S3.SS3.p4.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.1.1.1.2.cmml">𝝁</mi><mi id="S3.SS3.p4.1.m1.1.1.1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.SS3.p4.1.m1.2.2.2.2.4" xref="S3.SS3.p4.1.m1.2.2.2.3.cmml">,</mo><msub id="S3.SS3.p4.1.m1.2.2.2.2.2" xref="S3.SS3.p4.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS3.p4.1.m1.2.2.2.2.2.2" xref="S3.SS3.p4.1.m1.2.2.2.2.2.2.cmml">𝚺</mi><mi id="S3.SS3.p4.1.m1.2.2.2.2.2.3" xref="S3.SS3.p4.1.m1.2.2.2.2.2.3.cmml">p</mi></msub><mo stretchy="false" id="S3.SS3.p4.1.m1.2.2.2.2.5" xref="S3.SS3.p4.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.2b"><apply id="S3.SS3.p4.1.m1.2.2.cmml" xref="S3.SS3.p4.1.m1.2.2"><times id="S3.SS3.p4.1.m1.2.2.3.cmml" xref="S3.SS3.p4.1.m1.2.2.3"></times><apply id="S3.SS3.p4.1.m1.2.2.4.cmml" xref="S3.SS3.p4.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.2.2.4.1.cmml" xref="S3.SS3.p4.1.m1.2.2.4">subscript</csymbol><ci id="S3.SS3.p4.1.m1.2.2.4.2.cmml" xref="S3.SS3.p4.1.m1.2.2.4.2">𝒩</ci><ci id="S3.SS3.p4.1.m1.2.2.4.3.cmml" xref="S3.SS3.p4.1.m1.2.2.4.3">𝑝</ci></apply><interval closure="open" id="S3.SS3.p4.1.m1.2.2.2.3.cmml" xref="S3.SS3.p4.1.m1.2.2.2.2"><apply id="S3.SS3.p4.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.1.1.1.2">𝝁</ci><ci id="S3.SS3.p4.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.1.1.1.3">𝑝</ci></apply><apply id="S3.SS3.p4.1.m1.2.2.2.2.2.cmml" xref="S3.SS3.p4.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS3.p4.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p4.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS3.p4.1.m1.2.2.2.2.2.2">𝚺</ci><ci id="S3.SS3.p4.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS3.p4.1.m1.2.2.2.2.2.3">𝑝</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.2c">\mathcal{N}_{p}(\boldsymbol{\mu}_{p},\boldsymbol{\Sigma}_{p})</annotation></semantics></math> and the Gaussian anchor <math id="S3.SS3.p4.2.m2.2" class="ltx_Math" alttext="\mathcal{N}_{a}(\boldsymbol{\mu}_{a},\boldsymbol{\Sigma}_{a})" display="inline"><semantics id="S3.SS3.p4.2.m2.2a"><mrow id="S3.SS3.p4.2.m2.2.2" xref="S3.SS3.p4.2.m2.2.2.cmml"><msub id="S3.SS3.p4.2.m2.2.2.4" xref="S3.SS3.p4.2.m2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.2.m2.2.2.4.2" xref="S3.SS3.p4.2.m2.2.2.4.2.cmml">𝒩</mi><mi id="S3.SS3.p4.2.m2.2.2.4.3" xref="S3.SS3.p4.2.m2.2.2.4.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p4.2.m2.2.2.3" xref="S3.SS3.p4.2.m2.2.2.3.cmml">​</mo><mrow id="S3.SS3.p4.2.m2.2.2.2.2" xref="S3.SS3.p4.2.m2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p4.2.m2.2.2.2.2.3" xref="S3.SS3.p4.2.m2.2.2.2.3.cmml">(</mo><msub id="S3.SS3.p4.2.m2.1.1.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.2" xref="S3.SS3.p4.2.m2.1.1.1.1.1.2.cmml">𝝁</mi><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.3" xref="S3.SS3.p4.2.m2.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.SS3.p4.2.m2.2.2.2.2.4" xref="S3.SS3.p4.2.m2.2.2.2.3.cmml">,</mo><msub id="S3.SS3.p4.2.m2.2.2.2.2.2" xref="S3.SS3.p4.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS3.p4.2.m2.2.2.2.2.2.2" xref="S3.SS3.p4.2.m2.2.2.2.2.2.2.cmml">𝚺</mi><mi id="S3.SS3.p4.2.m2.2.2.2.2.2.3" xref="S3.SS3.p4.2.m2.2.2.2.2.2.3.cmml">a</mi></msub><mo stretchy="false" id="S3.SS3.p4.2.m2.2.2.2.2.5" xref="S3.SS3.p4.2.m2.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.2b"><apply id="S3.SS3.p4.2.m2.2.2.cmml" xref="S3.SS3.p4.2.m2.2.2"><times id="S3.SS3.p4.2.m2.2.2.3.cmml" xref="S3.SS3.p4.2.m2.2.2.3"></times><apply id="S3.SS3.p4.2.m2.2.2.4.cmml" xref="S3.SS3.p4.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.2.2.4.1.cmml" xref="S3.SS3.p4.2.m2.2.2.4">subscript</csymbol><ci id="S3.SS3.p4.2.m2.2.2.4.2.cmml" xref="S3.SS3.p4.2.m2.2.2.4.2">𝒩</ci><ci id="S3.SS3.p4.2.m2.2.2.4.3.cmml" xref="S3.SS3.p4.2.m2.2.2.4.3">𝑎</ci></apply><interval closure="open" id="S3.SS3.p4.2.m2.2.2.2.3.cmml" xref="S3.SS3.p4.2.m2.2.2.2.2"><apply id="S3.SS3.p4.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.2">𝝁</ci><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.3">𝑎</ci></apply><apply id="S3.SS3.p4.2.m2.2.2.2.2.2.cmml" xref="S3.SS3.p4.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS3.p4.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p4.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS3.p4.2.m2.2.2.2.2.2.2">𝚺</ci><ci id="S3.SS3.p4.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS3.p4.2.m2.2.2.2.2.2.3">𝑎</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.2c">\mathcal{N}_{a}(\boldsymbol{\mu}_{a},\boldsymbol{\Sigma}_{a})</annotation></semantics></math> has a closed form solution, which can be simplified as:</p>
<table id="S3.E5" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E5X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E5X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle W_{2}^{2}(\mathcal{N}_{p},\mathcal{N}_{a})=" display="inline"><semantics id="S3.E5X.2.1.1.m1.2a"><mrow id="S3.E5X.2.1.1.m1.2.2" xref="S3.E5X.2.1.1.m1.2.2.cmml"><mrow id="S3.E5X.2.1.1.m1.2.2.2" xref="S3.E5X.2.1.1.m1.2.2.2.cmml"><msubsup id="S3.E5X.2.1.1.m1.2.2.2.4" xref="S3.E5X.2.1.1.m1.2.2.2.4.cmml"><mi id="S3.E5X.2.1.1.m1.2.2.2.4.2.2" xref="S3.E5X.2.1.1.m1.2.2.2.4.2.2.cmml">W</mi><mn id="S3.E5X.2.1.1.m1.2.2.2.4.2.3" xref="S3.E5X.2.1.1.m1.2.2.2.4.2.3.cmml">2</mn><mn id="S3.E5X.2.1.1.m1.2.2.2.4.3" xref="S3.E5X.2.1.1.m1.2.2.2.4.3.cmml">2</mn></msubsup><mo lspace="0em" rspace="0em" id="S3.E5X.2.1.1.m1.2.2.2.3" xref="S3.E5X.2.1.1.m1.2.2.2.3.cmml">​</mo><mrow id="S3.E5X.2.1.1.m1.2.2.2.2.2" xref="S3.E5X.2.1.1.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E5X.2.1.1.m1.2.2.2.2.2.3" xref="S3.E5X.2.1.1.m1.2.2.2.2.3.cmml">(</mo><msub id="S3.E5X.2.1.1.m1.1.1.1.1.1.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.2.cmml">𝒩</mi><mi id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.E5X.2.1.1.m1.2.2.2.2.2.4" xref="S3.E5X.2.1.1.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.E5X.2.1.1.m1.2.2.2.2.2.2" xref="S3.E5X.2.1.1.m1.2.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5X.2.1.1.m1.2.2.2.2.2.2.2" xref="S3.E5X.2.1.1.m1.2.2.2.2.2.2.2.cmml">𝒩</mi><mi id="S3.E5X.2.1.1.m1.2.2.2.2.2.2.3" xref="S3.E5X.2.1.1.m1.2.2.2.2.2.2.3.cmml">a</mi></msub><mo stretchy="false" id="S3.E5X.2.1.1.m1.2.2.2.2.2.5" xref="S3.E5X.2.1.1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E5X.2.1.1.m1.2.2.3" xref="S3.E5X.2.1.1.m1.2.2.3.cmml">=</mo><mi id="S3.E5X.2.1.1.m1.2.2.4" xref="S3.E5X.2.1.1.m1.2.2.4.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S3.E5X.2.1.1.m1.2b"><apply id="S3.E5X.2.1.1.m1.2.2.cmml" xref="S3.E5X.2.1.1.m1.2.2"><eq id="S3.E5X.2.1.1.m1.2.2.3.cmml" xref="S3.E5X.2.1.1.m1.2.2.3"></eq><apply id="S3.E5X.2.1.1.m1.2.2.2.cmml" xref="S3.E5X.2.1.1.m1.2.2.2"><times id="S3.E5X.2.1.1.m1.2.2.2.3.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.3"></times><apply id="S3.E5X.2.1.1.m1.2.2.2.4.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.2.2.2.4.1.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.4">superscript</csymbol><apply id="S3.E5X.2.1.1.m1.2.2.2.4.2.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.2.2.2.4.2.1.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.4">subscript</csymbol><ci id="S3.E5X.2.1.1.m1.2.2.2.4.2.2.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.4.2.2">𝑊</ci><cn type="integer" id="S3.E5X.2.1.1.m1.2.2.2.4.2.3.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.4.2.3">2</cn></apply><cn type="integer" id="S3.E5X.2.1.1.m1.2.2.2.4.3.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.4.3">2</cn></apply><interval closure="open" id="S3.E5X.2.1.1.m1.2.2.2.2.3.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.2.2"><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.2">𝒩</ci><ci id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.3">𝑝</ci></apply><apply id="S3.E5X.2.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E5X.2.1.1.m1.2.2.2.2.2.2.2.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.2.2.2.2">𝒩</ci><ci id="S3.E5X.2.1.1.m1.2.2.2.2.2.2.3.cmml" xref="S3.E5X.2.1.1.m1.2.2.2.2.2.2.3">𝑎</ci></apply></interval></apply><csymbol cd="latexml" id="S3.E5X.2.1.1.m1.2.2.4.cmml" xref="S3.E5X.2.1.1.m1.2.2.4">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5X.2.1.1.m1.2c">\displaystyle W_{2}^{2}(\mathcal{N}_{p},\mathcal{N}_{a})=</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E5X.3.2.2.m1.1" class="ltx_Math" alttext="\displaystyle\left\|\mathbf{\mu}_{p}-\mathbf{\mu}_{a}\right\|_{2}^{2}" display="inline"><semantics id="S3.E5X.3.2.2.m1.1a"><msubsup id="S3.E5X.3.2.2.m1.1.1" xref="S3.E5X.3.2.2.m1.1.1.cmml"><mrow id="S3.E5X.3.2.2.m1.1.1.1.1.1" xref="S3.E5X.3.2.2.m1.1.1.1.1.2.cmml"><mo id="S3.E5X.3.2.2.m1.1.1.1.1.1.2" xref="S3.E5X.3.2.2.m1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E5X.3.2.2.m1.1.1.1.1.1.1" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.cmml"><msub id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.2" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.2.cmml">μ</mi><mi id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.3" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.3.cmml">p</mi></msub><mo id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.1" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.2" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.2.cmml">μ</mi><mi id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.3" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.3.cmml">a</mi></msub></mrow><mo id="S3.E5X.3.2.2.m1.1.1.1.1.1.3" xref="S3.E5X.3.2.2.m1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E5X.3.2.2.m1.1.1.1.3" xref="S3.E5X.3.2.2.m1.1.1.1.3.cmml">2</mn><mn id="S3.E5X.3.2.2.m1.1.1.3" xref="S3.E5X.3.2.2.m1.1.1.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="S3.E5X.3.2.2.m1.1b"><apply id="S3.E5X.3.2.2.m1.1.1.cmml" xref="S3.E5X.3.2.2.m1.1.1"><csymbol cd="ambiguous" id="S3.E5X.3.2.2.m1.1.1.2.cmml" xref="S3.E5X.3.2.2.m1.1.1">superscript</csymbol><apply id="S3.E5X.3.2.2.m1.1.1.1.cmml" xref="S3.E5X.3.2.2.m1.1.1"><csymbol cd="ambiguous" id="S3.E5X.3.2.2.m1.1.1.1.2.cmml" xref="S3.E5X.3.2.2.m1.1.1">subscript</csymbol><apply id="S3.E5X.3.2.2.m1.1.1.1.1.2.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5X.3.2.2.m1.1.1.1.1.2.1.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1"><minus id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.1"></minus><apply id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.2">𝜇</ci><ci id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.2.3">𝑝</ci></apply><apply id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.2">𝜇</ci><ci id="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.1.1.1.3.3">𝑎</ci></apply></apply></apply><cn type="integer" id="S3.E5X.3.2.2.m1.1.1.1.3.cmml" xref="S3.E5X.3.2.2.m1.1.1.1.3">2</cn></apply><cn type="integer" id="S3.E5X.3.2.2.m1.1.1.3.cmml" xref="S3.E5X.3.2.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5X.3.2.2.m1.1c">\displaystyle\left\|\mathbf{\mu}_{p}-\mathbf{\mu}_{a}\right\|_{2}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(5)</span></td>
</tr>
<tr id="S3.E5Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E5Xa.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle+\operatorname{Tr}\left(\boldsymbol{\Sigma}_{p}+\boldsymbol{\Sigma}_{a}-2\left(\boldsymbol{\Sigma}_{p}^{1/2}\boldsymbol{\Sigma}_{a}\boldsymbol{\Sigma}_{p}^{1/2}\right)^{1/2}\right)." display="inline"><semantics id="S3.E5Xa.2.1.1.m1.2a"><mrow id="S3.E5Xa.2.1.1.m1.2.2.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.cmml"><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.cmml"><mo rspace="0.167em" id="S3.E5Xa.2.1.1.m1.2.2.1.1a" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.cmml">+</mo><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.2.cmml"><mi id="S3.E5Xa.2.1.1.m1.1.1" xref="S3.E5Xa.2.1.1.m1.1.1.cmml">Tr</mi><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1a" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.2.cmml">⁡</mo><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.2.cmml"><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.2.cmml">(</mo><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.cmml"><msub id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.2.cmml">𝚺</mi><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.3.cmml">p</mi></msub><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.1.cmml">+</mo><msub id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.2.cmml">𝚺</mi><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.3.cmml">a</mi></msub></mrow><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mn id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml">​</mo><msup id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">𝚺</mi><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">p</mi><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mn id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">1</mn><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">/</mo><mn id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">2</mn></mrow></msubsup><mo lspace="0em" rspace="0em" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">​</mo><msub id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">𝚺</mi><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1a" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">​</mo><msubsup id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.2.cmml">𝚺</mi><mi id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.3.cmml">p</mi><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.cmml"><mn id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.2.cmml">1</mn><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.1.cmml">/</mo><mn id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.3.cmml">2</mn></mrow></msubsup></mrow><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mrow id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mn id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml">1</mn><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.1" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml">/</mo><mn id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml">2</mn></mrow></msup></mrow></mrow><mo id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.3" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E5Xa.2.1.1.m1.2.2.1.2" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5Xa.2.1.1.m1.2b"><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1"><plus id="S3.E5Xa.2.1.1.m1.2.2.1.1.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1"></plus><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1"><ci id="S3.E5Xa.2.1.1.m1.1.1.cmml" xref="S3.E5Xa.2.1.1.m1.1.1">Tr</ci><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1"><minus id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.2"></minus><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3"><plus id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.1"></plus><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.2">𝚺</ci><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.3">𝑝</ci></apply><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.2">𝚺</ci><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.3">𝑎</ci></apply></apply><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.2"></times><cn type="integer" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.3">2</cn><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1"><times id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1"></times><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.2">𝚺</ci><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.3">𝑝</ci></apply><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3"><divide id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.1"></divide><cn type="integer" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.2">1</cn><cn type="integer" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.3">2</cn></apply></apply><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2">𝚺</ci><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑎</ci></apply><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4">superscript</csymbol><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.2">𝚺</ci><ci id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.2.3">𝑝</ci></apply><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3"><divide id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.1"></divide><cn type="integer" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.2">1</cn><cn type="integer" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.3.3">2</cn></apply></apply></apply><apply id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3"><divide id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.1"></divide><cn type="integer" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.2">1</cn><cn type="integer" id="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5Xa.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.3.3">2</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5Xa.2.1.1.m1.2c">\displaystyle+\operatorname{Tr}\left(\boldsymbol{\Sigma}_{p}+\boldsymbol{\Sigma}_{a}-2\left(\boldsymbol{\Sigma}_{p}^{1/2}\boldsymbol{\Sigma}_{a}\boldsymbol{\Sigma}_{p}^{1/2}\right)^{1/2}\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.3" class="ltx_p">For brevity, we call this metric WD. With WD, we can now calculate the similarity between all preset anchors and pseudo-boxes. For each pseudo-box, we assign the top <math id="S3.SS3.p5.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p5.1.m1.1a"><mi id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><ci id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">K</annotation></semantics></math> anchors that yield the highest similarity with the pseudo-box as positive samples. In general, the strategy of WD with top <math id="S3.SS3.p5.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p5.2.m2.1a"><mi id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><ci id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">K</annotation></semantics></math> sampling can alleviate the imbalance among the positive anchor sampling process to some extent. On the one hand, compared with IoU, distribution-based modeling has a wider definition domain and the WD can obtain the similarity score between a given pseudo-box and all anchor boxes in the image. On the other hand, the top <math id="S3.SS3.p5.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p5.3.m3.1a"><mi id="S3.SS3.p5.3.m3.1.1" xref="S3.SS3.p5.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.1b"><ci id="S3.SS3.p5.3.m3.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.1c">K</annotation></semantics></math> sampling strategy can solve the problem that large objects are easier to be matched with more anchors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite>.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.2" class="ltx_p">In addition to the distribution-based re-sampling, we design a novel size-aware re-weighting method. During the training process, we count the quantity of large and small positive samples in each batch. When calculating loss, we re-weight the loss of large and small positive samples to further balance the contribution of large and small objects in training. Given the loss of small positive samples <math id="S3.SS3.p6.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{s}" display="inline"><semantics id="S3.SS3.p6.1.m1.1a"><msub id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p6.1.m1.1.1.2" xref="S3.SS3.p6.1.m1.1.1.2.cmml">ℒ</mi><mi id="S3.SS3.p6.1.m1.1.1.3" xref="S3.SS3.p6.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><apply id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.1.m1.1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p6.1.m1.1.1.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2">ℒ</ci><ci id="S3.SS3.p6.1.m1.1.1.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">\mathcal{L}_{s}</annotation></semantics></math>, and loss of large positive samples <math id="S3.SS3.p6.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{l}" display="inline"><semantics id="S3.SS3.p6.2.m2.1a"><msub id="S3.SS3.p6.2.m2.1.1" xref="S3.SS3.p6.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p6.2.m2.1.1.2" xref="S3.SS3.p6.2.m2.1.1.2.cmml">ℒ</mi><mi id="S3.SS3.p6.2.m2.1.1.3" xref="S3.SS3.p6.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.2.m2.1b"><apply id="S3.SS3.p6.2.m2.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.2.m2.1.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p6.2.m2.1.1.2.cmml" xref="S3.SS3.p6.2.m2.1.1.2">ℒ</ci><ci id="S3.SS3.p6.2.m2.1.1.3.cmml" xref="S3.SS3.p6.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.2.m2.1c">\mathcal{L}_{l}</annotation></semantics></math>, the re-weighted loss of all positive samples can be calculated by:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="\mathcal{L}_{pos}=\frac{N_{pos}}{2N_{s}}\sum_{i=0}^{N_{s}}\mathcal{L}_{s}^{i}+\frac{N_{pos}}{2N_{l}}\sum_{j=0}^{N_{l}}\mathcal{L}_{l}^{j}," display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.2.2" xref="S3.E6.m1.1.1.1.1.2.2.cmml">ℒ</mi><mrow id="S3.E6.m1.1.1.1.1.2.3" xref="S3.E6.m1.1.1.1.1.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.2.3.2" xref="S3.E6.m1.1.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.2.3.1" xref="S3.E6.m1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.2.3.3" xref="S3.E6.m1.1.1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.2.3.1a" xref="S3.E6.m1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.2.3.4" xref="S3.E6.m1.1.1.1.1.2.3.4.cmml">s</mi></mrow></msub><mo id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><mrow id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml"><mfrac id="S3.E6.m1.1.1.1.1.3.2.2" xref="S3.E6.m1.1.1.1.1.3.2.2.cmml"><msub id="S3.E6.m1.1.1.1.1.3.2.2.2" xref="S3.E6.m1.1.1.1.1.3.2.2.2.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.2.2.2" xref="S3.E6.m1.1.1.1.1.3.2.2.2.2.cmml">N</mi><mrow id="S3.E6.m1.1.1.1.1.3.2.2.2.3" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.2.2.3.2" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.2.2.3.1" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.3.2.2.2.3.3" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.2.2.3.1a" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.3.2.2.2.3.4" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.4.cmml">s</mi></mrow></msub><mrow id="S3.E6.m1.1.1.1.1.3.2.2.3" xref="S3.E6.m1.1.1.1.1.3.2.2.3.cmml"><mn id="S3.E6.m1.1.1.1.1.3.2.2.3.2" xref="S3.E6.m1.1.1.1.1.3.2.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.2.3.1" xref="S3.E6.m1.1.1.1.1.3.2.2.3.1.cmml">​</mo><msub id="S3.E6.m1.1.1.1.1.3.2.2.3.3" xref="S3.E6.m1.1.1.1.1.3.2.2.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.2.3.3.2" xref="S3.E6.m1.1.1.1.1.3.2.2.3.3.2.cmml">N</mi><mi id="S3.E6.m1.1.1.1.1.3.2.2.3.3.3" xref="S3.E6.m1.1.1.1.1.3.2.2.3.3.3.cmml">s</mi></msub></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.1" xref="S3.E6.m1.1.1.1.1.3.2.1.cmml">​</mo><mrow id="S3.E6.m1.1.1.1.1.3.2.3" xref="S3.E6.m1.1.1.1.1.3.2.3.cmml"><munderover id="S3.E6.m1.1.1.1.1.3.2.3.1" xref="S3.E6.m1.1.1.1.1.3.2.3.1.cmml"><mo movablelimits="false" id="S3.E6.m1.1.1.1.1.3.2.3.1.2.2" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.2.cmml">∑</mo><mrow id="S3.E6.m1.1.1.1.1.3.2.3.1.2.3" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.2" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.2.cmml">i</mi><mo id="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.1" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.3" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.3.cmml">0</mn></mrow><msub id="S3.E6.m1.1.1.1.1.3.2.3.1.3" xref="S3.E6.m1.1.1.1.1.3.2.3.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.3.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.3.1.3.2.cmml">N</mi><mi id="S3.E6.m1.1.1.1.1.3.2.3.1.3.3" xref="S3.E6.m1.1.1.1.1.3.2.3.1.3.3.cmml">s</mi></msub></munderover><msubsup id="S3.E6.m1.1.1.1.1.3.2.3.2" xref="S3.E6.m1.1.1.1.1.3.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.3.2.3.2.2.2" xref="S3.E6.m1.1.1.1.1.3.2.3.2.2.2.cmml">ℒ</mi><mi id="S3.E6.m1.1.1.1.1.3.2.3.2.2.3" xref="S3.E6.m1.1.1.1.1.3.2.3.2.2.3.cmml">s</mi><mi id="S3.E6.m1.1.1.1.1.3.2.3.2.3" xref="S3.E6.m1.1.1.1.1.3.2.3.2.3.cmml">i</mi></msubsup></mrow></mrow><mo id="S3.E6.m1.1.1.1.1.3.1" xref="S3.E6.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E6.m1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3.cmml"><mfrac id="S3.E6.m1.1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.cmml"><msub id="S3.E6.m1.1.1.1.1.3.3.2.2" xref="S3.E6.m1.1.1.1.1.3.3.2.2.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.2.2.2" xref="S3.E6.m1.1.1.1.1.3.3.2.2.2.cmml">N</mi><mrow id="S3.E6.m1.1.1.1.1.3.3.2.2.3" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.2.2.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.3.2.2.3.1" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.3.3.2.2.3.3" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.3.2.2.3.1a" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.3.3.2.2.3.4" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.4.cmml">s</mi></mrow></msub><mrow id="S3.E6.m1.1.1.1.1.3.3.2.3" xref="S3.E6.m1.1.1.1.1.3.3.2.3.cmml"><mn id="S3.E6.m1.1.1.1.1.3.3.2.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.3.2.3.1" xref="S3.E6.m1.1.1.1.1.3.3.2.3.1.cmml">​</mo><msub id="S3.E6.m1.1.1.1.1.3.3.2.3.3" xref="S3.E6.m1.1.1.1.1.3.3.2.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.2.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.3.3.2.cmml">N</mi><mi id="S3.E6.m1.1.1.1.1.3.3.2.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.2.3.3.3.cmml">l</mi></msub></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.3.1" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">​</mo><mrow id="S3.E6.m1.1.1.1.1.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.cmml"><munderover id="S3.E6.m1.1.1.1.1.3.3.3.1" xref="S3.E6.m1.1.1.1.1.3.3.3.1.cmml"><mo movablelimits="false" id="S3.E6.m1.1.1.1.1.3.3.3.1.2.2" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.2.cmml">∑</mo><mrow id="S3.E6.m1.1.1.1.1.3.3.3.1.2.3" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.2" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.2.cmml">j</mi><mo id="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.1" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.1.cmml">=</mo><mn id="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.3.cmml">0</mn></mrow><msub id="S3.E6.m1.1.1.1.1.3.3.3.1.3" xref="S3.E6.m1.1.1.1.1.3.3.3.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.3.1.3.2" xref="S3.E6.m1.1.1.1.1.3.3.3.1.3.2.cmml">N</mi><mi id="S3.E6.m1.1.1.1.1.3.3.3.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.1.3.3.cmml">l</mi></msub></munderover><msubsup id="S3.E6.m1.1.1.1.1.3.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.3.3.3.2.2.2" xref="S3.E6.m1.1.1.1.1.3.3.3.2.2.2.cmml">ℒ</mi><mi id="S3.E6.m1.1.1.1.1.3.3.3.2.2.3" xref="S3.E6.m1.1.1.1.1.3.3.3.2.2.3.cmml">l</mi><mi id="S3.E6.m1.1.1.1.1.3.3.3.2.3" xref="S3.E6.m1.1.1.1.1.3.3.3.2.3.cmml">j</mi></msubsup></mrow></mrow></mrow></mrow><mo id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><eq id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"></eq><apply id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.2.2">ℒ</ci><apply id="S3.E6.m1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.2.3"><times id="S3.E6.m1.1.1.1.1.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.2.3.1"></times><ci id="S3.E6.m1.1.1.1.1.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.2.3.2">𝑝</ci><ci id="S3.E6.m1.1.1.1.1.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.2.3.3">𝑜</ci><ci id="S3.E6.m1.1.1.1.1.2.3.4.cmml" xref="S3.E6.m1.1.1.1.1.2.3.4">𝑠</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><plus id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.1"></plus><apply id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2"><times id="S3.E6.m1.1.1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1"></times><apply id="S3.E6.m1.1.1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2"><divide id="S3.E6.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2"></divide><apply id="S3.E6.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2.2">𝑁</ci><apply id="S3.E6.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3"><times id="S3.E6.m1.1.1.1.1.3.2.2.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.2.2.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.2">𝑝</ci><ci id="S3.E6.m1.1.1.1.1.3.2.2.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.3">𝑜</ci><ci id="S3.E6.m1.1.1.1.1.3.2.2.2.3.4.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2.3.4">𝑠</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.3"><times id="S3.E6.m1.1.1.1.1.3.2.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.3.1"></times><cn type="integer" id="S3.E6.m1.1.1.1.1.3.2.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.3.2">2</cn><apply id="S3.E6.m1.1.1.1.1.3.2.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.2.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.3.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.2.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.3.3.2">𝑁</ci><ci id="S3.E6.m1.1.1.1.1.3.2.2.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.3.3.3">𝑠</ci></apply></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3"><apply id="S3.E6.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.3.1.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.3.2.3.1.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.3.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1">subscript</csymbol><sum id="S3.E6.m1.1.1.1.1.3.2.3.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.2"></sum><apply id="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.3"><eq id="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.1"></eq><ci id="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.2">𝑖</ci><cn type="integer" id="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1.2.3.3">0</cn></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.2.3.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.3.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.3.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1.3.2">𝑁</ci><ci id="S3.E6.m1.1.1.1.1.3.2.3.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1.3.3">𝑠</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.3.2.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.3.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.3.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2.2.2">ℒ</ci><ci id="S3.E6.m1.1.1.1.1.3.2.3.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2.2.3">𝑠</ci></apply><ci id="S3.E6.m1.1.1.1.1.3.2.3.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2.3">𝑖</ci></apply></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3"><times id="S3.E6.m1.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.1"></times><apply id="S3.E6.m1.1.1.1.1.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2"><divide id="S3.E6.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2"></divide><apply id="S3.E6.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.3.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.2.2">𝑁</ci><apply id="S3.E6.m1.1.1.1.1.3.3.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3"><times id="S3.E6.m1.1.1.1.1.3.3.2.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.3.2.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.2">𝑝</ci><ci id="S3.E6.m1.1.1.1.1.3.3.2.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.3">𝑜</ci><ci id="S3.E6.m1.1.1.1.1.3.3.2.2.3.4.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.2.3.4">𝑠</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.3"><times id="S3.E6.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.3.1"></times><cn type="integer" id="S3.E6.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.3.2">2</cn><apply id="S3.E6.m1.1.1.1.1.3.3.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.2.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.3.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.3.2.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.3.3.2">𝑁</ci><ci id="S3.E6.m1.1.1.1.1.3.3.2.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.3.3.3">𝑙</ci></apply></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3"><apply id="S3.E6.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.3.1.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.3.3.3.1.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.3.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1">subscript</csymbol><sum id="S3.E6.m1.1.1.1.1.3.3.3.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.2"></sum><apply id="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.3"><eq id="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.1"></eq><ci id="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.2">𝑗</ci><cn type="integer" id="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1.2.3.3">0</cn></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.3.3.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.3.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.3.3.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1.3.2">𝑁</ci><ci id="S3.E6.m1.1.1.1.1.3.3.3.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1.3.3">𝑙</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.3.3.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.3.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.3.3.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2.2.2">ℒ</ci><ci id="S3.E6.m1.1.1.1.1.3.3.3.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2.2.3">𝑙</ci></apply><ci id="S3.E6.m1.1.1.1.1.3.3.3.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\mathcal{L}_{pos}=\frac{N_{pos}}{2N_{s}}\sum_{i=0}^{N_{s}}\mathcal{L}_{s}^{i}+\frac{N_{pos}}{2N_{l}}\sum_{j=0}^{N_{l}}\mathcal{L}_{l}^{j},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p6.5" class="ltx_p">where <math id="S3.SS3.p6.3.m1.1" class="ltx_Math" alttext="N_{s}" display="inline"><semantics id="S3.SS3.p6.3.m1.1a"><msub id="S3.SS3.p6.3.m1.1.1" xref="S3.SS3.p6.3.m1.1.1.cmml"><mi id="S3.SS3.p6.3.m1.1.1.2" xref="S3.SS3.p6.3.m1.1.1.2.cmml">N</mi><mi id="S3.SS3.p6.3.m1.1.1.3" xref="S3.SS3.p6.3.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.3.m1.1b"><apply id="S3.SS3.p6.3.m1.1.1.cmml" xref="S3.SS3.p6.3.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.3.m1.1.1.1.cmml" xref="S3.SS3.p6.3.m1.1.1">subscript</csymbol><ci id="S3.SS3.p6.3.m1.1.1.2.cmml" xref="S3.SS3.p6.3.m1.1.1.2">𝑁</ci><ci id="S3.SS3.p6.3.m1.1.1.3.cmml" xref="S3.SS3.p6.3.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.3.m1.1c">N_{s}</annotation></semantics></math> and <math id="S3.SS3.p6.4.m2.1" class="ltx_Math" alttext="N_{l}" display="inline"><semantics id="S3.SS3.p6.4.m2.1a"><msub id="S3.SS3.p6.4.m2.1.1" xref="S3.SS3.p6.4.m2.1.1.cmml"><mi id="S3.SS3.p6.4.m2.1.1.2" xref="S3.SS3.p6.4.m2.1.1.2.cmml">N</mi><mi id="S3.SS3.p6.4.m2.1.1.3" xref="S3.SS3.p6.4.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.4.m2.1b"><apply id="S3.SS3.p6.4.m2.1.1.cmml" xref="S3.SS3.p6.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.4.m2.1.1.1.cmml" xref="S3.SS3.p6.4.m2.1.1">subscript</csymbol><ci id="S3.SS3.p6.4.m2.1.1.2.cmml" xref="S3.SS3.p6.4.m2.1.1.2">𝑁</ci><ci id="S3.SS3.p6.4.m2.1.1.3.cmml" xref="S3.SS3.p6.4.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.4.m2.1c">N_{l}</annotation></semantics></math> are the number of small and large positive samples, <math id="S3.SS3.p6.5.m3.1" class="ltx_Math" alttext="N_{pos}=N_{s}+N_{l}" display="inline"><semantics id="S3.SS3.p6.5.m3.1a"><mrow id="S3.SS3.p6.5.m3.1.1" xref="S3.SS3.p6.5.m3.1.1.cmml"><msub id="S3.SS3.p6.5.m3.1.1.2" xref="S3.SS3.p6.5.m3.1.1.2.cmml"><mi id="S3.SS3.p6.5.m3.1.1.2.2" xref="S3.SS3.p6.5.m3.1.1.2.2.cmml">N</mi><mrow id="S3.SS3.p6.5.m3.1.1.2.3" xref="S3.SS3.p6.5.m3.1.1.2.3.cmml"><mi id="S3.SS3.p6.5.m3.1.1.2.3.2" xref="S3.SS3.p6.5.m3.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.5.m3.1.1.2.3.1" xref="S3.SS3.p6.5.m3.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p6.5.m3.1.1.2.3.3" xref="S3.SS3.p6.5.m3.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.5.m3.1.1.2.3.1a" xref="S3.SS3.p6.5.m3.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p6.5.m3.1.1.2.3.4" xref="S3.SS3.p6.5.m3.1.1.2.3.4.cmml">s</mi></mrow></msub><mo id="S3.SS3.p6.5.m3.1.1.1" xref="S3.SS3.p6.5.m3.1.1.1.cmml">=</mo><mrow id="S3.SS3.p6.5.m3.1.1.3" xref="S3.SS3.p6.5.m3.1.1.3.cmml"><msub id="S3.SS3.p6.5.m3.1.1.3.2" xref="S3.SS3.p6.5.m3.1.1.3.2.cmml"><mi id="S3.SS3.p6.5.m3.1.1.3.2.2" xref="S3.SS3.p6.5.m3.1.1.3.2.2.cmml">N</mi><mi id="S3.SS3.p6.5.m3.1.1.3.2.3" xref="S3.SS3.p6.5.m3.1.1.3.2.3.cmml">s</mi></msub><mo id="S3.SS3.p6.5.m3.1.1.3.1" xref="S3.SS3.p6.5.m3.1.1.3.1.cmml">+</mo><msub id="S3.SS3.p6.5.m3.1.1.3.3" xref="S3.SS3.p6.5.m3.1.1.3.3.cmml"><mi id="S3.SS3.p6.5.m3.1.1.3.3.2" xref="S3.SS3.p6.5.m3.1.1.3.3.2.cmml">N</mi><mi id="S3.SS3.p6.5.m3.1.1.3.3.3" xref="S3.SS3.p6.5.m3.1.1.3.3.3.cmml">l</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.5.m3.1b"><apply id="S3.SS3.p6.5.m3.1.1.cmml" xref="S3.SS3.p6.5.m3.1.1"><eq id="S3.SS3.p6.5.m3.1.1.1.cmml" xref="S3.SS3.p6.5.m3.1.1.1"></eq><apply id="S3.SS3.p6.5.m3.1.1.2.cmml" xref="S3.SS3.p6.5.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p6.5.m3.1.1.2.1.cmml" xref="S3.SS3.p6.5.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.p6.5.m3.1.1.2.2.cmml" xref="S3.SS3.p6.5.m3.1.1.2.2">𝑁</ci><apply id="S3.SS3.p6.5.m3.1.1.2.3.cmml" xref="S3.SS3.p6.5.m3.1.1.2.3"><times id="S3.SS3.p6.5.m3.1.1.2.3.1.cmml" xref="S3.SS3.p6.5.m3.1.1.2.3.1"></times><ci id="S3.SS3.p6.5.m3.1.1.2.3.2.cmml" xref="S3.SS3.p6.5.m3.1.1.2.3.2">𝑝</ci><ci id="S3.SS3.p6.5.m3.1.1.2.3.3.cmml" xref="S3.SS3.p6.5.m3.1.1.2.3.3">𝑜</ci><ci id="S3.SS3.p6.5.m3.1.1.2.3.4.cmml" xref="S3.SS3.p6.5.m3.1.1.2.3.4">𝑠</ci></apply></apply><apply id="S3.SS3.p6.5.m3.1.1.3.cmml" xref="S3.SS3.p6.5.m3.1.1.3"><plus id="S3.SS3.p6.5.m3.1.1.3.1.cmml" xref="S3.SS3.p6.5.m3.1.1.3.1"></plus><apply id="S3.SS3.p6.5.m3.1.1.3.2.cmml" xref="S3.SS3.p6.5.m3.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p6.5.m3.1.1.3.2.1.cmml" xref="S3.SS3.p6.5.m3.1.1.3.2">subscript</csymbol><ci id="S3.SS3.p6.5.m3.1.1.3.2.2.cmml" xref="S3.SS3.p6.5.m3.1.1.3.2.2">𝑁</ci><ci id="S3.SS3.p6.5.m3.1.1.3.2.3.cmml" xref="S3.SS3.p6.5.m3.1.1.3.2.3">𝑠</ci></apply><apply id="S3.SS3.p6.5.m3.1.1.3.3.cmml" xref="S3.SS3.p6.5.m3.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS3.p6.5.m3.1.1.3.3.1.cmml" xref="S3.SS3.p6.5.m3.1.1.3.3">subscript</csymbol><ci id="S3.SS3.p6.5.m3.1.1.3.3.2.cmml" xref="S3.SS3.p6.5.m3.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p6.5.m3.1.1.3.3.3.cmml" xref="S3.SS3.p6.5.m3.1.1.3.3.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.5.m3.1c">N_{pos}=N_{s}+N_{l}</annotation></semantics></math> is the number of all positive samples.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Teacher-guided Negative Learning</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">To overcome the concern that negative sample learning will mistakenly suppress undiscovered small objects, we introduce the Teacher-guided Negative Learning (TNL) approach for unbiased negative sample learning.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">Object detectors’ predictions are not always <span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_italic">black and white</span>. More practically, there exist numerous ambiguous predictions that cannot certainly be labeled as foreground or background via a simple threshold. Due to limited pixels and information, this ambiguity is more severe for small object prediction.
Existing SSOD methods usually discard these ambiguous predictions, avoiding misleading gradients while sacrificing their potential contribution to training. Fortunately, some study on other semi-supervised learning tasks (e.g., U<sup id="S3.SS4.p2.1.2" class="ltx_sup">2</sup>PL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">88</span></a>]</cite>, ANL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite>) suggests that the ambiguous results predicted by the network can be excavated to aid learning. Thus, we cast a further look at ambiguous predictions in the SSOD task for ODAI.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">In the proposed TNL, we design two steps to make the detector rethink the utility of these ambiguous samples. In the first step, the regions of the negative proposals are input into the teacher model to obtain classification confidence scores of background. Subsequently, we select negative proposals with higher background scores (larger than 0.7) for negative sample supervision, aiming to effectively eliminate False Negatives (FN).
However, this approach gives rise to a new issue: the selected negative samples often turn out to be overly simplistic, discarding the learning of hard samples. This limitation impacts the network’s discriminative capacity, leading to a significant increase in False Positives (FP) at the later stages of training.
Hence, to enhance the network’s discriminative ability of hard samples, we incorporate the network’s predictions with confidence scores lower than 0.5 as soft hard samples into the negative sample proposals. Based on the original confidence predictions, we re-weight the loss of these hard samples, the lower the confidence score, the higher the weight, thus granting them greater significance during the training of negative samples. The loss <math id="S3.SS4.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{neg}" display="inline"><semantics id="S3.SS4.p3.1.m1.1a"><msub id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p3.1.m1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.2.cmml">ℒ</mi><mrow id="S3.SS4.p3.1.m1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.3.cmml"><mi id="S3.SS4.p3.1.m1.1.1.3.2" xref="S3.SS4.p3.1.m1.1.1.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.3.1" xref="S3.SS4.p3.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS4.p3.1.m1.1.1.3.3" xref="S3.SS4.p3.1.m1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.3.1a" xref="S3.SS4.p3.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS4.p3.1.m1.1.1.3.4" xref="S3.SS4.p3.1.m1.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><apply id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.1.m1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p3.1.m1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.2">ℒ</ci><apply id="S3.SS4.p3.1.m1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3"><times id="S3.SS4.p3.1.m1.1.1.3.1.cmml" xref="S3.SS4.p3.1.m1.1.1.3.1"></times><ci id="S3.SS4.p3.1.m1.1.1.3.2.cmml" xref="S3.SS4.p3.1.m1.1.1.3.2">𝑛</ci><ci id="S3.SS4.p3.1.m1.1.1.3.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3.3">𝑒</ci><ci id="S3.SS4.p3.1.m1.1.1.3.4.cmml" xref="S3.SS4.p3.1.m1.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">\mathcal{L}_{neg}</annotation></semantics></math> of all negative samples can be calculated by:</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.1" class="ltx_Math" alttext="\mathcal{L}_{neg}=\sum_{i=0}^{N_{h}}2(1-s_{i}^{2})\mathcal{L}_{h}^{i}+\sum_{i=0}^{N_{n}}\mathcal{L}_{n}^{i}," display="block"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mrow id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.3.2.cmml">ℒ</mi><mrow id="S3.E7.m1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.3.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.3.2" xref="S3.E7.m1.1.1.1.1.3.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.1" xref="S3.E7.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E7.m1.1.1.1.1.3.3.3" xref="S3.E7.m1.1.1.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.1a" xref="S3.E7.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E7.m1.1.1.1.1.3.3.4" xref="S3.E7.m1.1.1.1.1.3.3.4.cmml">g</mi></mrow></msub><mo rspace="0.111em" id="S3.E7.m1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E7.m1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.cmml"><mrow id="S3.E7.m1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><munderover id="S3.E7.m1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E7.m1.1.1.1.1.1.1.2.2.2" xref="S3.E7.m1.1.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E7.m1.1.1.1.1.1.1.2.2.3" xref="S3.E7.m1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.2.2.3.2" xref="S3.E7.m1.1.1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E7.m1.1.1.1.1.1.1.2.2.3.1" xref="S3.E7.m1.1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E7.m1.1.1.1.1.1.1.2.2.3.3" xref="S3.E7.m1.1.1.1.1.1.1.2.2.3.3.cmml">0</mn></mrow><msub id="S3.E7.m1.1.1.1.1.1.1.2.3" xref="S3.E7.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.2.3.2" xref="S3.E7.m1.1.1.1.1.1.1.2.3.2.cmml">N</mi><mi id="S3.E7.m1.1.1.1.1.1.1.2.3.3" xref="S3.E7.m1.1.1.1.1.1.1.2.3.3.cmml">h</mi></msub></munderover><mrow id="S3.E7.m1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.cmml"><mn id="S3.E7.m1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.1.3.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E7.m1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msubsup id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">s</mi><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">i</mi><mn id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">2</mn></msubsup></mrow><mo stretchy="false" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.1.1.1.2a" xref="S3.E7.m1.1.1.1.1.1.1.1.2.cmml">​</mo><msubsup id="S3.E7.m1.1.1.1.1.1.1.1.4" xref="S3.E7.m1.1.1.1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1.1.1.1.1.1.4.2.2" xref="S3.E7.m1.1.1.1.1.1.1.1.4.2.2.cmml">ℒ</mi><mi id="S3.E7.m1.1.1.1.1.1.1.1.4.2.3" xref="S3.E7.m1.1.1.1.1.1.1.1.4.2.3.cmml">h</mi><mi id="S3.E7.m1.1.1.1.1.1.1.1.4.3" xref="S3.E7.m1.1.1.1.1.1.1.1.4.3.cmml">i</mi></msubsup></mrow></mrow><mo rspace="0.055em" id="S3.E7.m1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E7.m1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.3.cmml"><munderover id="S3.E7.m1.1.1.1.1.1.3.1" xref="S3.E7.m1.1.1.1.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E7.m1.1.1.1.1.1.3.1.2.2" xref="S3.E7.m1.1.1.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.E7.m1.1.1.1.1.1.3.1.2.3" xref="S3.E7.m1.1.1.1.1.1.3.1.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.3.1.2.3.2" xref="S3.E7.m1.1.1.1.1.1.3.1.2.3.2.cmml">i</mi><mo id="S3.E7.m1.1.1.1.1.1.3.1.2.3.1" xref="S3.E7.m1.1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.E7.m1.1.1.1.1.1.3.1.2.3.3" xref="S3.E7.m1.1.1.1.1.1.3.1.2.3.3.cmml">0</mn></mrow><msub id="S3.E7.m1.1.1.1.1.1.3.1.3" xref="S3.E7.m1.1.1.1.1.1.3.1.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.3.1.3.2" xref="S3.E7.m1.1.1.1.1.1.3.1.3.2.cmml">N</mi><mi id="S3.E7.m1.1.1.1.1.1.3.1.3.3" xref="S3.E7.m1.1.1.1.1.1.3.1.3.3.cmml">n</mi></msub></munderover><msubsup id="S3.E7.m1.1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1.1.1.1.3.2.2.2" xref="S3.E7.m1.1.1.1.1.1.3.2.2.2.cmml">ℒ</mi><mi id="S3.E7.m1.1.1.1.1.1.3.2.2.3" xref="S3.E7.m1.1.1.1.1.1.3.2.2.3.cmml">n</mi><mi id="S3.E7.m1.1.1.1.1.1.3.2.3" xref="S3.E7.m1.1.1.1.1.1.3.2.3.cmml">i</mi></msubsup></mrow></mrow></mrow><mo id="S3.E7.m1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><eq id="S3.E7.m1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.2"></eq><apply id="S3.E7.m1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2">ℒ</ci><apply id="S3.E7.m1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3"><times id="S3.E7.m1.1.1.1.1.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.3.1"></times><ci id="S3.E7.m1.1.1.1.1.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.3.2">𝑛</ci><ci id="S3.E7.m1.1.1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3">𝑒</ci><ci id="S3.E7.m1.1.1.1.1.3.3.4.cmml" xref="S3.E7.m1.1.1.1.1.3.3.4">𝑔</ci></apply></apply><apply id="S3.E7.m1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1"><plus id="S3.E7.m1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.2"></plus><apply id="S3.E7.m1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1"><apply id="S3.E7.m1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E7.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2">subscript</csymbol><sum id="S3.E7.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.2.2"></sum><apply id="S3.E7.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.2.3"><eq id="S3.E7.m1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E7.m1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S3.E7.m1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.2.3.3">0</cn></apply></apply><apply id="S3.E7.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.3.2">𝑁</ci><ci id="S3.E7.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.3.3">ℎ</ci></apply></apply><apply id="S3.E7.m1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1"><times id="S3.E7.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.2"></times><cn type="integer" id="S3.E7.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.3">2</cn><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1"><minus id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.2">1</cn><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.2">𝑠</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply><cn type="integer" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3.3">2</cn></apply></apply><apply id="S3.E7.m1.1.1.1.1.1.1.1.4.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.4">superscript</csymbol><apply id="S3.E7.m1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.4.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.4.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.4.2.2">ℒ</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.4.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.4.2.3">ℎ</ci></apply><ci id="S3.E7.m1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.4.3">𝑖</ci></apply></apply></apply><apply id="S3.E7.m1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.3"><apply id="S3.E7.m1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.3.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1">superscript</csymbol><apply id="S3.E7.m1.1.1.1.1.1.3.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.3.1.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1">subscript</csymbol><sum id="S3.E7.m1.1.1.1.1.1.3.1.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1.2.2"></sum><apply id="S3.E7.m1.1.1.1.1.1.3.1.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1.2.3"><eq id="S3.E7.m1.1.1.1.1.1.3.1.2.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1.2.3.1"></eq><ci id="S3.E7.m1.1.1.1.1.1.3.1.2.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1.2.3.2">𝑖</ci><cn type="integer" id="S3.E7.m1.1.1.1.1.1.3.1.2.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1.2.3.3">0</cn></apply></apply><apply id="S3.E7.m1.1.1.1.1.1.3.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.3.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.3.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1.3.2">𝑁</ci><ci id="S3.E7.m1.1.1.1.1.1.3.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.3.1.3.3">𝑛</ci></apply></apply><apply id="S3.E7.m1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.3.2">superscript</csymbol><apply id="S3.E7.m1.1.1.1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.3.2.2.2">ℒ</ci><ci id="S3.E7.m1.1.1.1.1.1.3.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.3.2.2.3">𝑛</ci></apply><ci id="S3.E7.m1.1.1.1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.3.2.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">\mathcal{L}_{neg}=\sum_{i=0}^{N_{h}}2(1-s_{i}^{2})\mathcal{L}_{h}^{i}+\sum_{i=0}^{N_{n}}\mathcal{L}_{n}^{i},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p3.5" class="ltx_p">where <math id="S3.SS4.p3.2.m1.1" class="ltx_Math" alttext="N_{h}" display="inline"><semantics id="S3.SS4.p3.2.m1.1a"><msub id="S3.SS4.p3.2.m1.1.1" xref="S3.SS4.p3.2.m1.1.1.cmml"><mi id="S3.SS4.p3.2.m1.1.1.2" xref="S3.SS4.p3.2.m1.1.1.2.cmml">N</mi><mi id="S3.SS4.p3.2.m1.1.1.3" xref="S3.SS4.p3.2.m1.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m1.1b"><apply id="S3.SS4.p3.2.m1.1.1.cmml" xref="S3.SS4.p3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m1.1.1.1.cmml" xref="S3.SS4.p3.2.m1.1.1">subscript</csymbol><ci id="S3.SS4.p3.2.m1.1.1.2.cmml" xref="S3.SS4.p3.2.m1.1.1.2">𝑁</ci><ci id="S3.SS4.p3.2.m1.1.1.3.cmml" xref="S3.SS4.p3.2.m1.1.1.3">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m1.1c">N_{h}</annotation></semantics></math> and <math id="S3.SS4.p3.3.m2.1" class="ltx_Math" alttext="N_{n}" display="inline"><semantics id="S3.SS4.p3.3.m2.1a"><msub id="S3.SS4.p3.3.m2.1.1" xref="S3.SS4.p3.3.m2.1.1.cmml"><mi id="S3.SS4.p3.3.m2.1.1.2" xref="S3.SS4.p3.3.m2.1.1.2.cmml">N</mi><mi id="S3.SS4.p3.3.m2.1.1.3" xref="S3.SS4.p3.3.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m2.1b"><apply id="S3.SS4.p3.3.m2.1.1.cmml" xref="S3.SS4.p3.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.3.m2.1.1.1.cmml" xref="S3.SS4.p3.3.m2.1.1">subscript</csymbol><ci id="S3.SS4.p3.3.m2.1.1.2.cmml" xref="S3.SS4.p3.3.m2.1.1.2">𝑁</ci><ci id="S3.SS4.p3.3.m2.1.1.3.cmml" xref="S3.SS4.p3.3.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m2.1c">N_{n}</annotation></semantics></math> are the numbers of hard negative samples and normal negative samples, <math id="S3.SS4.p3.4.m3.1" class="ltx_Math" alttext="N_{neg}=N_{h}+N_{n}" display="inline"><semantics id="S3.SS4.p3.4.m3.1a"><mrow id="S3.SS4.p3.4.m3.1.1" xref="S3.SS4.p3.4.m3.1.1.cmml"><msub id="S3.SS4.p3.4.m3.1.1.2" xref="S3.SS4.p3.4.m3.1.1.2.cmml"><mi id="S3.SS4.p3.4.m3.1.1.2.2" xref="S3.SS4.p3.4.m3.1.1.2.2.cmml">N</mi><mrow id="S3.SS4.p3.4.m3.1.1.2.3" xref="S3.SS4.p3.4.m3.1.1.2.3.cmml"><mi id="S3.SS4.p3.4.m3.1.1.2.3.2" xref="S3.SS4.p3.4.m3.1.1.2.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.4.m3.1.1.2.3.1" xref="S3.SS4.p3.4.m3.1.1.2.3.1.cmml">​</mo><mi id="S3.SS4.p3.4.m3.1.1.2.3.3" xref="S3.SS4.p3.4.m3.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.4.m3.1.1.2.3.1a" xref="S3.SS4.p3.4.m3.1.1.2.3.1.cmml">​</mo><mi id="S3.SS4.p3.4.m3.1.1.2.3.4" xref="S3.SS4.p3.4.m3.1.1.2.3.4.cmml">g</mi></mrow></msub><mo id="S3.SS4.p3.4.m3.1.1.1" xref="S3.SS4.p3.4.m3.1.1.1.cmml">=</mo><mrow id="S3.SS4.p3.4.m3.1.1.3" xref="S3.SS4.p3.4.m3.1.1.3.cmml"><msub id="S3.SS4.p3.4.m3.1.1.3.2" xref="S3.SS4.p3.4.m3.1.1.3.2.cmml"><mi id="S3.SS4.p3.4.m3.1.1.3.2.2" xref="S3.SS4.p3.4.m3.1.1.3.2.2.cmml">N</mi><mi id="S3.SS4.p3.4.m3.1.1.3.2.3" xref="S3.SS4.p3.4.m3.1.1.3.2.3.cmml">h</mi></msub><mo id="S3.SS4.p3.4.m3.1.1.3.1" xref="S3.SS4.p3.4.m3.1.1.3.1.cmml">+</mo><msub id="S3.SS4.p3.4.m3.1.1.3.3" xref="S3.SS4.p3.4.m3.1.1.3.3.cmml"><mi id="S3.SS4.p3.4.m3.1.1.3.3.2" xref="S3.SS4.p3.4.m3.1.1.3.3.2.cmml">N</mi><mi id="S3.SS4.p3.4.m3.1.1.3.3.3" xref="S3.SS4.p3.4.m3.1.1.3.3.3.cmml">n</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.4.m3.1b"><apply id="S3.SS4.p3.4.m3.1.1.cmml" xref="S3.SS4.p3.4.m3.1.1"><eq id="S3.SS4.p3.4.m3.1.1.1.cmml" xref="S3.SS4.p3.4.m3.1.1.1"></eq><apply id="S3.SS4.p3.4.m3.1.1.2.cmml" xref="S3.SS4.p3.4.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p3.4.m3.1.1.2.1.cmml" xref="S3.SS4.p3.4.m3.1.1.2">subscript</csymbol><ci id="S3.SS4.p3.4.m3.1.1.2.2.cmml" xref="S3.SS4.p3.4.m3.1.1.2.2">𝑁</ci><apply id="S3.SS4.p3.4.m3.1.1.2.3.cmml" xref="S3.SS4.p3.4.m3.1.1.2.3"><times id="S3.SS4.p3.4.m3.1.1.2.3.1.cmml" xref="S3.SS4.p3.4.m3.1.1.2.3.1"></times><ci id="S3.SS4.p3.4.m3.1.1.2.3.2.cmml" xref="S3.SS4.p3.4.m3.1.1.2.3.2">𝑛</ci><ci id="S3.SS4.p3.4.m3.1.1.2.3.3.cmml" xref="S3.SS4.p3.4.m3.1.1.2.3.3">𝑒</ci><ci id="S3.SS4.p3.4.m3.1.1.2.3.4.cmml" xref="S3.SS4.p3.4.m3.1.1.2.3.4">𝑔</ci></apply></apply><apply id="S3.SS4.p3.4.m3.1.1.3.cmml" xref="S3.SS4.p3.4.m3.1.1.3"><plus id="S3.SS4.p3.4.m3.1.1.3.1.cmml" xref="S3.SS4.p3.4.m3.1.1.3.1"></plus><apply id="S3.SS4.p3.4.m3.1.1.3.2.cmml" xref="S3.SS4.p3.4.m3.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS4.p3.4.m3.1.1.3.2.1.cmml" xref="S3.SS4.p3.4.m3.1.1.3.2">subscript</csymbol><ci id="S3.SS4.p3.4.m3.1.1.3.2.2.cmml" xref="S3.SS4.p3.4.m3.1.1.3.2.2">𝑁</ci><ci id="S3.SS4.p3.4.m3.1.1.3.2.3.cmml" xref="S3.SS4.p3.4.m3.1.1.3.2.3">ℎ</ci></apply><apply id="S3.SS4.p3.4.m3.1.1.3.3.cmml" xref="S3.SS4.p3.4.m3.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS4.p3.4.m3.1.1.3.3.1.cmml" xref="S3.SS4.p3.4.m3.1.1.3.3">subscript</csymbol><ci id="S3.SS4.p3.4.m3.1.1.3.3.2.cmml" xref="S3.SS4.p3.4.m3.1.1.3.3.2">𝑁</ci><ci id="S3.SS4.p3.4.m3.1.1.3.3.3.cmml" xref="S3.SS4.p3.4.m3.1.1.3.3.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.4.m3.1c">N_{neg}=N_{h}+N_{n}</annotation></semantics></math> is the number of all negative samples. <math id="S3.SS4.p3.5.m4.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS4.p3.5.m4.1a"><mi id="S3.SS4.p3.5.m4.1.1" xref="S3.SS4.p3.5.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.5.m4.1b"><ci id="S3.SS4.p3.5.m4.1.1.cmml" xref="S3.SS4.p3.5.m4.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.5.m4.1c">s</annotation></semantics></math> are the confidence scores of the hard negative samples.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiment</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Dataset and Evaluation Protocol</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We use DOTA-v1.5 for experiments, which is a typical dataset in previous small object detection study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite> and semi-supervised object detection study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">85</span></a>]</cite>.
DOTA-v1.5 is updated based on DOTA-v1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">89</span></a>]</cite>. Compared to v1.0, the images in v1.5 remains unchanged, but there are additional annotations for small objects. These enriched annotations of small objects allow the dataset to better reflect the characteristics of real-world aerial imagery objects.
The DOTA-v1.5 comprises 2,806 large-scale aerial images and 40,289 annotations. It is divided into three sets. The training set consists of 1,411 images, the validation set has 458 images, and the test set contains 937 images without released annotations. Following the common setting of SSOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>, we conducted two sets of experiments: <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Partially Labeled Data</span> and <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_bold">Fully Labeled Data</span>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.3" class="ltx_p">In the <span id="S4.SS1.p2.3.1" class="ltx_text ltx_font_bold">Partially Labeled Data</span> experiments, 1<math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mo id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><csymbol cd="latexml" id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\%</annotation></semantics></math>, 5<math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mo id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><csymbol cd="latexml" id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\%</annotation></semantics></math>, and 10<math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mo id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><csymbol cd="latexml" id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\%</annotation></semantics></math> of the training set are randomly sampled as labeled data, while the remaining data serves as unlabeled data. To mitigate the impact of random sampling, we perform 5-fold cross-validation for each sampling rate and reported the mean and variance of the results.
In the <span id="S4.SS1.p2.3.2" class="ltx_text ltx_font_bold">Fully Labeled Data</span> experiments, we utilize the test set without released annotations as unlabeled data, while using the entire training set as labeled data.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Note that aerial images are typically large-size and are often cropped before training. Moreover, sampling from the entire large images at a 1<math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mo id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><csymbol cd="latexml" id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\%</annotation></semantics></math> sampling rate would make it difficult to cover all the categories adequately. Sampling from the cropped smaller images allows for a better representation of the overall data distribution. Therefore, in our experiments, we first perform cropping on all the images before sampling.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">In all experiments, we report the evaluation results on the validation set using the commonly used mean Average Precision (mAP) under the IoU threshold 0.5, following the MS COCO evaluation metric.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Quantitative comparison between the proposed S<sup id="S4.T1.30.1" class="ltx_sup">3</sup>OD and SOTA SSOD methods. Experiments are performed on the validation set of DOTA-v1.5 under the training with different labeling rates. The best results are in bold.</figcaption>
<div id="S4.T1.28" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:117.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-81.4pt,22.1pt) scale(0.726972910028222,0.726972910028222) ;">
<table id="S4.T1.28.26" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.28.26.27" class="ltx_tr">
<td id="S4.T1.28.26.27.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T1.28.26.27.1.1" class="ltx_text">Methods</span></td>
<td id="S4.T1.28.26.27.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T1.28.26.27.2.1" class="ltx_text">Setting</span></td>
<td id="S4.T1.28.26.27.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Partially Labeled Data</td>
<td id="S4.T1.28.26.27.4" class="ltx_td ltx_align_center ltx_border_tt">Fully Labeled Data</td>
<td id="S4.T1.28.26.27.5" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S4.T1.6.4.4" class="ltx_tr">
<td id="S4.T1.3.1.1.1" class="ltx_td ltx_align_center ltx_border_t">1<math id="S4.T1.3.1.1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T1.3.1.1.1.m1.1a"><mo id="S4.T1.3.1.1.1.m1.1.1" xref="S4.T1.3.1.1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.3.1.1.1.m1.1.1.cmml" xref="S4.T1.3.1.1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.1.1.1.m1.1c">\%</annotation></semantics></math>
</td>
<td id="S4.T1.4.2.2.2" class="ltx_td ltx_align_center ltx_border_t">5<math id="S4.T1.4.2.2.2.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T1.4.2.2.2.m1.1a"><mo id="S4.T1.4.2.2.2.m1.1.1" xref="S4.T1.4.2.2.2.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.2.2.2.m1.1b"><csymbol cd="latexml" id="S4.T1.4.2.2.2.m1.1.1.cmml" xref="S4.T1.4.2.2.2.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.2.2.2.m1.1c">\%</annotation></semantics></math>
</td>
<td id="S4.T1.5.3.3.3" class="ltx_td ltx_align_center ltx_border_t">10<math id="S4.T1.5.3.3.3.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T1.5.3.3.3.m1.1a"><mo id="S4.T1.5.3.3.3.m1.1.1" xref="S4.T1.5.3.3.3.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.3.3.3.m1.1b"><csymbol cd="latexml" id="S4.T1.5.3.3.3.m1.1.1.cmml" xref="S4.T1.5.3.3.3.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.3.3.3.m1.1c">\%</annotation></semantics></math>
</td>
<td id="S4.T1.6.4.4.4" class="ltx_td ltx_align_center ltx_border_t">100<math id="S4.T1.6.4.4.4.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T1.6.4.4.4.m1.1a"><mo id="S4.T1.6.4.4.4.m1.1.1" xref="S4.T1.6.4.4.4.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.4.4.4.m1.1b"><csymbol cd="latexml" id="S4.T1.6.4.4.4.m1.1.1.cmml" xref="S4.T1.6.4.4.4.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.4.4.4.m1.1c">\%</annotation></semantics></math>
</td>
<td id="S4.T1.6.4.4.5" class="ltx_td"></td>
</tr>
<tr id="S4.T1.9.7.7" class="ltx_tr">
<td id="S4.T1.9.7.7.4" class="ltx_td ltx_align_center ltx_border_t">Rotated Faster RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite>
</td>
<td id="S4.T1.9.7.7.5" class="ltx_td ltx_align_center ltx_border_t">Supervised</td>
<td id="S4.T1.7.5.5.1" class="ltx_td ltx_align_center ltx_border_t">29.30<math id="S4.T1.7.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.7.5.5.1.m1.1a"><mo id="S4.T1.7.5.5.1.m1.1.1" xref="S4.T1.7.5.5.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.5.5.1.m1.1b"><csymbol cd="latexml" id="S4.T1.7.5.5.1.m1.1.1.cmml" xref="S4.T1.7.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.5.5.1.m1.1c">\pm</annotation></semantics></math>1.62</td>
<td id="S4.T1.8.6.6.2" class="ltx_td ltx_align_center ltx_border_t">47.08<math id="S4.T1.8.6.6.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.8.6.6.2.m1.1a"><mo id="S4.T1.8.6.6.2.m1.1.1" xref="S4.T1.8.6.6.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.6.6.2.m1.1b"><csymbol cd="latexml" id="S4.T1.8.6.6.2.m1.1.1.cmml" xref="S4.T1.8.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.6.6.2.m1.1c">\pm</annotation></semantics></math>0.97</td>
<td id="S4.T1.9.7.7.3" class="ltx_td ltx_align_center ltx_border_t">54.36<math id="S4.T1.9.7.7.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.9.7.7.3.m1.1a"><mo id="S4.T1.9.7.7.3.m1.1.1" xref="S4.T1.9.7.7.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.7.7.3.m1.1b"><csymbol cd="latexml" id="S4.T1.9.7.7.3.m1.1.1.cmml" xref="S4.T1.9.7.7.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.7.7.3.m1.1c">\pm</annotation></semantics></math>0.98</td>
<td id="S4.T1.9.7.7.6" class="ltx_td ltx_align_center ltx_border_t">63.6</td>
<td id="S4.T1.9.7.7.7" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S4.T1.12.10.10" class="ltx_tr">
<td id="S4.T1.12.10.10.4" class="ltx_td ltx_align_center ltx_border_t">SSOD baseline</td>
<td id="S4.T1.12.10.10.5" class="ltx_td ltx_align_center ltx_border_t">Semi-supervised</td>
<td id="S4.T1.10.8.8.1" class="ltx_td ltx_align_center ltx_border_t">33.30<math id="S4.T1.10.8.8.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.10.8.8.1.m1.1a"><mo id="S4.T1.10.8.8.1.m1.1.1" xref="S4.T1.10.8.8.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.8.8.1.m1.1b"><csymbol cd="latexml" id="S4.T1.10.8.8.1.m1.1.1.cmml" xref="S4.T1.10.8.8.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.8.8.1.m1.1c">\pm</annotation></semantics></math>2.54</td>
<td id="S4.T1.11.9.9.2" class="ltx_td ltx_align_center ltx_border_t">51.36<math id="S4.T1.11.9.9.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.11.9.9.2.m1.1a"><mo id="S4.T1.11.9.9.2.m1.1.1" xref="S4.T1.11.9.9.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.9.9.2.m1.1b"><csymbol cd="latexml" id="S4.T1.11.9.9.2.m1.1.1.cmml" xref="S4.T1.11.9.9.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.9.9.2.m1.1c">\pm</annotation></semantics></math>0.82</td>
<td id="S4.T1.12.10.10.3" class="ltx_td ltx_align_center ltx_border_t">57.08<math id="S4.T1.12.10.10.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.12.10.10.3.m1.1a"><mo id="S4.T1.12.10.10.3.m1.1.1" xref="S4.T1.12.10.10.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.12.10.10.3.m1.1b"><csymbol cd="latexml" id="S4.T1.12.10.10.3.m1.1.1.cmml" xref="S4.T1.12.10.10.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.10.10.3.m1.1c">\pm</annotation></semantics></math>0.74</td>
<td id="S4.T1.12.10.10.6" class="ltx_td ltx_align_center ltx_border_t">64.9 <span id="S4.T1.12.10.10.6.1" class="ltx_text" style="color:#00E000;">(+1.3)</span>
</td>
<td id="S4.T1.12.10.10.7" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S4.T1.15.13.13" class="ltx_tr">
<td id="S4.T1.15.13.13.4" class="ltx_td ltx_align_center">STAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite>
</td>
<td id="S4.T1.15.13.13.5" class="ltx_td ltx_align_center">Semi-supervised</td>
<td id="S4.T1.13.11.11.1" class="ltx_td ltx_align_center">33.98<math id="S4.T1.13.11.11.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.13.11.11.1.m1.1a"><mo id="S4.T1.13.11.11.1.m1.1.1" xref="S4.T1.13.11.11.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.13.11.11.1.m1.1b"><csymbol cd="latexml" id="S4.T1.13.11.11.1.m1.1.1.cmml" xref="S4.T1.13.11.11.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.11.11.1.m1.1c">\pm</annotation></semantics></math>2.13</td>
<td id="S4.T1.14.12.12.2" class="ltx_td ltx_align_center">50.86<math id="S4.T1.14.12.12.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.14.12.12.2.m1.1a"><mo id="S4.T1.14.12.12.2.m1.1.1" xref="S4.T1.14.12.12.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.14.12.12.2.m1.1b"><csymbol cd="latexml" id="S4.T1.14.12.12.2.m1.1.1.cmml" xref="S4.T1.14.12.12.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.12.12.2.m1.1c">\pm</annotation></semantics></math>1.63</td>
<td id="S4.T1.15.13.13.3" class="ltx_td ltx_align_center">56.72<math id="S4.T1.15.13.13.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.15.13.13.3.m1.1a"><mo id="S4.T1.15.13.13.3.m1.1.1" xref="S4.T1.15.13.13.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.15.13.13.3.m1.1b"><csymbol cd="latexml" id="S4.T1.15.13.13.3.m1.1.1.cmml" xref="S4.T1.15.13.13.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.13.13.3.m1.1c">\pm</annotation></semantics></math>0.75</td>
<td id="S4.T1.15.13.13.6" class="ltx_td ltx_align_center">63.8 <span id="S4.T1.15.13.13.6.1" class="ltx_text" style="color:#00E000;">(+0.2)</span>
</td>
<td id="S4.T1.15.13.13.7" class="ltx_td"></td>
</tr>
<tr id="S4.T1.18.16.16" class="ltx_tr">
<td id="S4.T1.18.16.16.4" class="ltx_td ltx_align_center">Unbiased Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>
</td>
<td id="S4.T1.18.16.16.5" class="ltx_td ltx_align_center">Semi-supervised</td>
<td id="S4.T1.16.14.14.1" class="ltx_td ltx_align_center">33.46<math id="S4.T1.16.14.14.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.16.14.14.1.m1.1a"><mo id="S4.T1.16.14.14.1.m1.1.1" xref="S4.T1.16.14.14.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.16.14.14.1.m1.1b"><csymbol cd="latexml" id="S4.T1.16.14.14.1.m1.1.1.cmml" xref="S4.T1.16.14.14.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.14.14.1.m1.1c">\pm</annotation></semantics></math>2.35</td>
<td id="S4.T1.17.15.15.2" class="ltx_td ltx_align_center">48.20<math id="S4.T1.17.15.15.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.17.15.15.2.m1.1a"><mo id="S4.T1.17.15.15.2.m1.1.1" xref="S4.T1.17.15.15.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.17.15.15.2.m1.1b"><csymbol cd="latexml" id="S4.T1.17.15.15.2.m1.1.1.cmml" xref="S4.T1.17.15.15.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.17.15.15.2.m1.1c">\pm</annotation></semantics></math>1.14</td>
<td id="S4.T1.18.16.16.3" class="ltx_td ltx_align_center">54.74<math id="S4.T1.18.16.16.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.18.16.16.3.m1.1a"><mo id="S4.T1.18.16.16.3.m1.1.1" xref="S4.T1.18.16.16.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.18.16.16.3.m1.1b"><csymbol cd="latexml" id="S4.T1.18.16.16.3.m1.1.1.cmml" xref="S4.T1.18.16.16.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.18.16.16.3.m1.1c">\pm</annotation></semantics></math>0.84</td>
<td id="S4.T1.18.16.16.6" class="ltx_td ltx_align_center">64.8 <span id="S4.T1.18.16.16.6.1" class="ltx_text" style="color:#00E000;">(+1.2)</span>
</td>
<td id="S4.T1.18.16.16.7" class="ltx_td"></td>
</tr>
<tr id="S4.T1.21.19.19" class="ltx_tr">
<td id="S4.T1.21.19.19.4" class="ltx_td ltx_align_center">Soft Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>
</td>
<td id="S4.T1.21.19.19.5" class="ltx_td ltx_align_center">Semi-supervised</td>
<td id="S4.T1.19.17.17.1" class="ltx_td ltx_align_center">37.52<math id="S4.T1.19.17.17.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.19.17.17.1.m1.1a"><mo id="S4.T1.19.17.17.1.m1.1.1" xref="S4.T1.19.17.17.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.19.17.17.1.m1.1b"><csymbol cd="latexml" id="S4.T1.19.17.17.1.m1.1.1.cmml" xref="S4.T1.19.17.17.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.19.17.17.1.m1.1c">\pm</annotation></semantics></math>2.44</td>
<td id="S4.T1.20.18.18.2" class="ltx_td ltx_align_center">52.90<math id="S4.T1.20.18.18.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.20.18.18.2.m1.1a"><mo id="S4.T1.20.18.18.2.m1.1.1" xref="S4.T1.20.18.18.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.20.18.18.2.m1.1b"><csymbol cd="latexml" id="S4.T1.20.18.18.2.m1.1.1.cmml" xref="S4.T1.20.18.18.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.20.18.18.2.m1.1c">\pm</annotation></semantics></math>1.24</td>
<td id="S4.T1.21.19.19.3" class="ltx_td ltx_align_center">57.78<math id="S4.T1.21.19.19.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.21.19.19.3.m1.1a"><mo id="S4.T1.21.19.19.3.m1.1.1" xref="S4.T1.21.19.19.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.21.19.19.3.m1.1b"><csymbol cd="latexml" id="S4.T1.21.19.19.3.m1.1.1.cmml" xref="S4.T1.21.19.19.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.21.19.19.3.m1.1c">\pm</annotation></semantics></math>0.32</td>
<td id="S4.T1.21.19.19.6" class="ltx_td ltx_align_center">65.1 <span id="S4.T1.21.19.19.6.1" class="ltx_text" style="color:#00E000;">(+1.5)</span>
</td>
<td id="S4.T1.21.19.19.7" class="ltx_td"></td>
</tr>
<tr id="S4.T1.24.22.22" class="ltx_tr">
<td id="S4.T1.24.22.22.4" class="ltx_td ltx_align_center">PseCo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>
</td>
<td id="S4.T1.24.22.22.5" class="ltx_td ltx_align_center">Semi-supervised</td>
<td id="S4.T1.22.20.20.1" class="ltx_td ltx_align_center">37.60<math id="S4.T1.22.20.20.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.22.20.20.1.m1.1a"><mo id="S4.T1.22.20.20.1.m1.1.1" xref="S4.T1.22.20.20.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.22.20.20.1.m1.1b"><csymbol cd="latexml" id="S4.T1.22.20.20.1.m1.1.1.cmml" xref="S4.T1.22.20.20.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.22.20.20.1.m1.1c">\pm</annotation></semantics></math>2.46</td>
<td id="S4.T1.23.21.21.2" class="ltx_td ltx_align_center">52.98<math id="S4.T1.23.21.21.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.23.21.21.2.m1.1a"><mo id="S4.T1.23.21.21.2.m1.1.1" xref="S4.T1.23.21.21.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.23.21.21.2.m1.1b"><csymbol cd="latexml" id="S4.T1.23.21.21.2.m1.1.1.cmml" xref="S4.T1.23.21.21.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.23.21.21.2.m1.1c">\pm</annotation></semantics></math>1.41</td>
<td id="S4.T1.24.22.22.3" class="ltx_td ltx_align_center">58.26<math id="S4.T1.24.22.22.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.24.22.22.3.m1.1a"><mo id="S4.T1.24.22.22.3.m1.1.1" xref="S4.T1.24.22.22.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.24.22.22.3.m1.1b"><csymbol cd="latexml" id="S4.T1.24.22.22.3.m1.1.1.cmml" xref="S4.T1.24.22.22.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.24.22.22.3.m1.1c">\pm</annotation></semantics></math>0.85</td>
<td id="S4.T1.24.22.22.6" class="ltx_td ltx_align_center">65.5 <span id="S4.T1.24.22.22.6.1" class="ltx_text" style="color:#00E000;">(+1.9)</span>
</td>
<td id="S4.T1.24.22.22.7" class="ltx_td"></td>
</tr>
<tr id="S4.T1.28.26.26" class="ltx_tr">
<td id="S4.T1.25.23.23.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.25.23.23.1.1" class="ltx_text ltx_font_bold">S<sup id="S4.T1.25.23.23.1.1.1" class="ltx_sup"><span id="S4.T1.25.23.23.1.1.1.1" class="ltx_text ltx_font_medium">3</span></sup>OD (Ours)</span></td>
<td id="S4.T1.28.26.26.5" class="ltx_td ltx_align_center ltx_border_bb">Semi-supervised</td>
<td id="S4.T1.26.24.24.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.26.24.24.2.1" class="ltx_text ltx_font_bold">40.02<math id="S4.T1.26.24.24.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.26.24.24.2.1.m1.1a"><mo id="S4.T1.26.24.24.2.1.m1.1.1" xref="S4.T1.26.24.24.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.26.24.24.2.1.m1.1b"><csymbol cd="latexml" id="S4.T1.26.24.24.2.1.m1.1.1.cmml" xref="S4.T1.26.24.24.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.26.24.24.2.1.m1.1c">\pm</annotation></semantics></math>1.68</span></td>
<td id="S4.T1.27.25.25.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.27.25.25.3.1" class="ltx_text ltx_font_bold">54.88<math id="S4.T1.27.25.25.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.27.25.25.3.1.m1.1a"><mo id="S4.T1.27.25.25.3.1.m1.1.1" xref="S4.T1.27.25.25.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.27.25.25.3.1.m1.1b"><csymbol cd="latexml" id="S4.T1.27.25.25.3.1.m1.1.1.cmml" xref="S4.T1.27.25.25.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.27.25.25.3.1.m1.1c">\pm</annotation></semantics></math>1.22</span></td>
<td id="S4.T1.28.26.26.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.28.26.26.4.1" class="ltx_text ltx_font_bold">60.24<math id="S4.T1.28.26.26.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.28.26.26.4.1.m1.1a"><mo id="S4.T1.28.26.26.4.1.m1.1.1" xref="S4.T1.28.26.26.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.28.26.26.4.1.m1.1b"><csymbol cd="latexml" id="S4.T1.28.26.26.4.1.m1.1.1.cmml" xref="S4.T1.28.26.26.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.28.26.26.4.1.m1.1c">\pm</annotation></semantics></math>0.42</span></td>
<td id="S4.T1.28.26.26.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.28.26.26.6.1" class="ltx_text ltx_font_bold">67.3 <span id="S4.T1.28.26.26.6.1.1" class="ltx_text" style="color:#00E000;">(+3.7)</span></span></td>
<td id="S4.T1.28.26.26.7" class="ltx_td ltx_border_bb"></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>The performance of the proposed S<sup id="S4.T2.7.1" class="ltx_sup">3</sup>OD and SOTA SSOD methods on several representative categories in the validation set of DOTA-v1.5. The training use 1<math id="S4.T2.4.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T2.4.m2.1b"><mo id="S4.T2.4.m2.1.1" xref="S4.T2.4.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.m2.1c"><csymbol cd="latexml" id="S4.T2.4.m2.1.1.cmml" xref="S4.T2.4.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.m2.1d">\%</annotation></semantics></math> labeled data. The best results are in bold.</figcaption>
<div id="S4.T2.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:424.9pt;height:106.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-73.7pt,18.6pt) scale(0.742333954378515,0.742333954378515) ;">
<table id="S4.T2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.5.1.2" class="ltx_tr">
<td id="S4.T2.5.1.2.1" class="ltx_td ltx_align_center ltx_border_tt">Methods</td>
<td id="S4.T2.5.1.2.2" class="ltx_td ltx_align_center ltx_border_tt">Setting</td>
<td id="S4.T2.5.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">SP</td>
<td id="S4.T2.5.1.2.4" class="ltx_td ltx_align_center ltx_border_tt">PL</td>
<td id="S4.T2.5.1.2.5" class="ltx_td ltx_align_center ltx_border_tt">SV</td>
<td id="S4.T2.5.1.2.6" class="ltx_td ltx_align_center ltx_border_tt">LV</td>
<td id="S4.T2.5.1.2.7" class="ltx_td ltx_align_center ltx_border_tt">BR</td>
<td id="S4.T2.5.1.2.8" class="ltx_td ltx_align_center ltx_border_tt">ST</td>
<td id="S4.T2.5.1.2.9" class="ltx_td ltx_align_center ltx_border_tt">HB</td>
<td id="S4.T2.5.1.2.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt">mAP</td>
</tr>
<tr id="S4.T2.5.1.3" class="ltx_tr">
<td id="S4.T2.5.1.3.1" class="ltx_td ltx_align_center ltx_border_t">Rotated Faster RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite>
</td>
<td id="S4.T2.5.1.3.2" class="ltx_td ltx_align_center ltx_border_t">Supervised</td>
<td id="S4.T2.5.1.3.3" class="ltx_td ltx_align_center ltx_border_t">60.9</td>
<td id="S4.T2.5.1.3.4" class="ltx_td ltx_align_center ltx_border_t">68.7</td>
<td id="S4.T2.5.1.3.5" class="ltx_td ltx_align_center ltx_border_t">22.6</td>
<td id="S4.T2.5.1.3.6" class="ltx_td ltx_align_center ltx_border_t">44.9</td>
<td id="S4.T2.5.1.3.7" class="ltx_td ltx_align_center ltx_border_t">12.1</td>
<td id="S4.T2.5.1.3.8" class="ltx_td ltx_align_center ltx_border_t">43.6</td>
<td id="S4.T2.5.1.3.9" class="ltx_td ltx_align_center ltx_border_t">28.2</td>
<td id="S4.T2.5.1.3.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">29.4</td>
</tr>
<tr id="S4.T2.5.1.4" class="ltx_tr">
<td id="S4.T2.5.1.4.1" class="ltx_td ltx_align_center ltx_border_t">SSOD baseline</td>
<td id="S4.T2.5.1.4.2" class="ltx_td ltx_align_center ltx_border_t">Semi-supervised</td>
<td id="S4.T2.5.1.4.3" class="ltx_td ltx_align_center ltx_border_t">60.1</td>
<td id="S4.T2.5.1.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.5.1.4.4.1" class="ltx_text ltx_font_bold">89.3</span></td>
<td id="S4.T2.5.1.4.5" class="ltx_td ltx_align_center ltx_border_t">9.1</td>
<td id="S4.T2.5.1.4.6" class="ltx_td ltx_align_center ltx_border_t">50.9</td>
<td id="S4.T2.5.1.4.7" class="ltx_td ltx_align_center ltx_border_t">21.4</td>
<td id="S4.T2.5.1.4.8" class="ltx_td ltx_align_center ltx_border_t">50.8</td>
<td id="S4.T2.5.1.4.9" class="ltx_td ltx_align_center ltx_border_t">18.5</td>
<td id="S4.T2.5.1.4.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">36.0 <span id="S4.T2.5.1.4.10.1" class="ltx_text" style="color:#00E000;">(+6.6)</span>
</td>
</tr>
<tr id="S4.T2.5.1.5" class="ltx_tr">
<td id="S4.T2.5.1.5.1" class="ltx_td ltx_align_center">STAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite>
</td>
<td id="S4.T2.5.1.5.2" class="ltx_td ltx_align_center">Semi-supervised</td>
<td id="S4.T2.5.1.5.3" class="ltx_td ltx_align_center"><span id="S4.T2.5.1.5.3.1" class="ltx_text ltx_font_bold">71.0</span></td>
<td id="S4.T2.5.1.5.4" class="ltx_td ltx_align_center">78.1</td>
<td id="S4.T2.5.1.5.5" class="ltx_td ltx_align_center">23.8</td>
<td id="S4.T2.5.1.5.6" class="ltx_td ltx_align_center">52.3</td>
<td id="S4.T2.5.1.5.7" class="ltx_td ltx_align_center">15.2</td>
<td id="S4.T2.5.1.5.8" class="ltx_td ltx_align_center">49.9</td>
<td id="S4.T2.5.1.5.9" class="ltx_td ltx_align_center">29.2</td>
<td id="S4.T2.5.1.5.10" class="ltx_td ltx_nopad_r ltx_align_center">34.2 <span id="S4.T2.5.1.5.10.1" class="ltx_text" style="color:#00E000;">(+4.8)</span>
</td>
</tr>
<tr id="S4.T2.5.1.6" class="ltx_tr">
<td id="S4.T2.5.1.6.1" class="ltx_td ltx_align_center">Unbiased Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>
</td>
<td id="S4.T2.5.1.6.2" class="ltx_td ltx_align_center">Semi-supervised</td>
<td id="S4.T2.5.1.6.3" class="ltx_td ltx_align_center">65.1</td>
<td id="S4.T2.5.1.6.4" class="ltx_td ltx_align_center">88.7</td>
<td id="S4.T2.5.1.6.5" class="ltx_td ltx_align_center">14.4</td>
<td id="S4.T2.5.1.6.6" class="ltx_td ltx_align_center">44.1</td>
<td id="S4.T2.5.1.6.7" class="ltx_td ltx_align_center">22.1</td>
<td id="S4.T2.5.1.6.8" class="ltx_td ltx_align_center">48.2</td>
<td id="S4.T2.5.1.6.9" class="ltx_td ltx_align_center">27.2</td>
<td id="S4.T2.5.1.6.10" class="ltx_td ltx_nopad_r ltx_align_center">35.3 <span id="S4.T2.5.1.6.10.1" class="ltx_text" style="color:#00E000;">(+5.9)</span>
</td>
</tr>
<tr id="S4.T2.5.1.7" class="ltx_tr">
<td id="S4.T2.5.1.7.1" class="ltx_td ltx_align_center">Soft Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>
</td>
<td id="S4.T2.5.1.7.2" class="ltx_td ltx_align_center">Semi-supervised</td>
<td id="S4.T2.5.1.7.3" class="ltx_td ltx_align_center">69.8</td>
<td id="S4.T2.5.1.7.4" class="ltx_td ltx_align_center">88.3</td>
<td id="S4.T2.5.1.7.5" class="ltx_td ltx_align_center">24.1</td>
<td id="S4.T2.5.1.7.6" class="ltx_td ltx_align_center">57.7</td>
<td id="S4.T2.5.1.7.7" class="ltx_td ltx_align_center">19.3</td>
<td id="S4.T2.5.1.7.8" class="ltx_td ltx_align_center">54.1</td>
<td id="S4.T2.5.1.7.9" class="ltx_td ltx_align_center">27.1</td>
<td id="S4.T2.5.1.7.10" class="ltx_td ltx_nopad_r ltx_align_center">37.5 <span id="S4.T2.5.1.7.10.1" class="ltx_text" style="color:#00E000;">(+8.1)</span>
</td>
</tr>
<tr id="S4.T2.5.1.8" class="ltx_tr">
<td id="S4.T2.5.1.8.1" class="ltx_td ltx_align_center">PseCo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>
</td>
<td id="S4.T2.5.1.8.2" class="ltx_td ltx_align_center">Semi-supervised</td>
<td id="S4.T2.5.1.8.3" class="ltx_td ltx_align_center">69.9</td>
<td id="S4.T2.5.1.8.4" class="ltx_td ltx_align_center">87.3</td>
<td id="S4.T2.5.1.8.5" class="ltx_td ltx_align_center">29.8</td>
<td id="S4.T2.5.1.8.6" class="ltx_td ltx_align_center">48.3</td>
<td id="S4.T2.5.1.8.7" class="ltx_td ltx_align_center">15.3</td>
<td id="S4.T2.5.1.8.8" class="ltx_td ltx_align_center">55.2</td>
<td id="S4.T2.5.1.8.9" class="ltx_td ltx_align_center"><span id="S4.T2.5.1.8.9.1" class="ltx_text ltx_font_bold">35.1</span></td>
<td id="S4.T2.5.1.8.10" class="ltx_td ltx_nopad_r ltx_align_center">37.9 <span id="S4.T2.5.1.8.10.1" class="ltx_text" style="color:#00E000;">(+8.5)</span>
</td>
</tr>
<tr id="S4.T2.5.1.1" class="ltx_tr">
<td id="S4.T2.5.1.1.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.5.1.1.1.1" class="ltx_text ltx_font_bold">S<sup id="S4.T2.5.1.1.1.1.1" class="ltx_sup"><span id="S4.T2.5.1.1.1.1.1.1" class="ltx_text ltx_font_medium">3</span></sup>OD (Ours)</span></td>
<td id="S4.T2.5.1.1.2" class="ltx_td ltx_align_center ltx_border_bb">Semi-supervised</td>
<td id="S4.T2.5.1.1.3" class="ltx_td ltx_align_center ltx_border_bb">70.9</td>
<td id="S4.T2.5.1.1.4" class="ltx_td ltx_align_center ltx_border_bb">88.5</td>
<td id="S4.T2.5.1.1.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.5.1.1.5.1" class="ltx_text ltx_font_bold">39.7</span></td>
<td id="S4.T2.5.1.1.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.5.1.1.6.1" class="ltx_text ltx_font_bold">58.7</span></td>
<td id="S4.T2.5.1.1.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.5.1.1.7.1" class="ltx_text ltx_font_bold">23.6</span></td>
<td id="S4.T2.5.1.1.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.5.1.1.8.1" class="ltx_text ltx_font_bold">68.6</span></td>
<td id="S4.T2.5.1.1.9" class="ltx_td ltx_align_center ltx_border_bb">29.0</td>
<td id="S4.T2.5.1.1.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S4.T2.5.1.1.10.1" class="ltx_text ltx_font_bold">41.9 <span id="S4.T2.5.1.1.10.1.1" class="ltx_text" style="color:#00E000;">(+12.5)</span></span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Implementation Details</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We use Rotated Faster RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite> as the base rotated object detector and choose ResNet50 w/ FPN as the backbone. The implementation of the base detector is based on the MMRotate framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">90</span></a>]</cite>. Following the settings in aerial image object detection, all large-sized images are cropped to <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\rm{1024}\times\rm{1024}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">1024</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">1024</cn><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\rm{1024}\times\rm{1024}</annotation></semantics></math> pixels with a 200-pixel overlap.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The supervised baseline is trained using stochastic gradient descent (SGD) optimizer. We set the learning rate (LR) to 0.002 and the batch size (BS) to 4.
All SSOD methods are also trained using SGD optimizer with an LR of 0.002 and a BS of 5 (4 unlabeled images and 1 labeled image). The beta value is set to 4.0 to control the contributions of unlabeled data.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.3" class="ltx_p">For partially labeled data, we train on 1 RTX4090 GPU for 100k iterations with 1<math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mo id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><csymbol cd="latexml" id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\%</annotation></semantics></math> and 5<math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mo id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><csymbol cd="latexml" id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">\%</annotation></semantics></math> labeled data. For 10<math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mo id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><csymbol cd="latexml" id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">\%</annotation></semantics></math> labeled data, we train the model for 160k iterations on 1 RTX4090 GPU to ensure more comprehensive training.
For fully labeled data, we train the model for 300k iterations on 1 RTX4090 GPU.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.14718/assets/fig_vis_supervised.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_img_portrait" width="105" height="560" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F5.sf1.3.2" class="ltx_text" style="font-size:80%;">Supervised <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.14718/assets/fig_vis_ssod_baseline.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_img_portrait" width="105" height="560" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F5.sf2.3.2" class="ltx_text" style="font-size:80%;">Unbiased Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.14718/assets/fig_vis_soft_teacher.png" id="S4.F5.sf3.g1" class="ltx_graphics ltx_img_portrait" width="105" height="560" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S4.F5.sf3.3.2" class="ltx_text" style="font-size:80%;">Soft Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.14718/assets/fig_vis_pseco.png" id="S4.F5.sf4.g1" class="ltx_graphics ltx_img_portrait" width="105" height="560" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf4.2.1.1" class="ltx_text" style="font-size:80%;">(d)</span> </span><span id="S4.F5.sf4.3.2" class="ltx_text" style="font-size:80%;">Pseco <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.14718/assets/fig_vis_s3od.png" id="S4.F5.sf5.g1" class="ltx_graphics ltx_img_portrait" width="105" height="560" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf5.5.2.1" class="ltx_text" style="font-size:80%;">(e)</span> </span><span id="S4.F5.sf5.2.1" class="ltx_text" style="font-size:80%;">S<sup id="S4.F5.sf5.2.1.1" class="ltx_sup">3</sup>OD(Ours)</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Visualization of the detection results of different SSOD methods. Correct predictions are marked with green boxes, false positive predictions are marked with yellow boxes, and missing targets are marked with red boxes.
</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Main Results</span>
</h3>

<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS1.5.1.1" class="ltx_text">IV-C</span>1 </span>Quantitative Analysis</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">We compare our proposed S<sup id="S4.SS3.SSS1.p1.1.1" class="ltx_sup">3</sup>OD with existing SOTA SSOD methods on the DOTA-v1.5 dataset, including STAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite>, Unbiased Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>, Soft-teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>, and PseCo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>. Additionally, we use the base framework without the three modules proposed in our method as an SSOD baseline. We re-implement the SOTA SSOD method for rotated object detection and adjust the appropriate hyperparameters to better adapt SSOD for aerial images. In the experiments, to ensure a fair comparison, we apply the same weak/strong augmentation strategy for all experiments. The results are shown in Tab. <a href="#S4.T1" title="TABLE I ‣ IV-A Dataset and Evaluation Protocol ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.5" class="ltx_p">For partially labeled data, our proposed S<sup id="S4.SS3.SSS1.p2.5.1" class="ltx_sup">3</sup>OD method achieves the best performance under the training of 1<math id="S4.SS3.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS3.SSS1.p2.2.m2.1a"><mo id="S4.SS3.SSS1.p2.2.m2.1.1" xref="S4.SS3.SSS1.p2.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p2.2.m2.1b"><csymbol cd="latexml" id="S4.SS3.SSS1.p2.2.m2.1.1.cmml" xref="S4.SS3.SSS1.p2.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p2.2.m2.1c">\%</annotation></semantics></math>, 5<math id="S4.SS3.SSS1.p2.3.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS3.SSS1.p2.3.m3.1a"><mo id="S4.SS3.SSS1.p2.3.m3.1.1" xref="S4.SS3.SSS1.p2.3.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p2.3.m3.1b"><csymbol cd="latexml" id="S4.SS3.SSS1.p2.3.m3.1.1.cmml" xref="S4.SS3.SSS1.p2.3.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p2.3.m3.1c">\%</annotation></semantics></math>, and 10<math id="S4.SS3.SSS1.p2.4.m4.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS3.SSS1.p2.4.m4.1a"><mo id="S4.SS3.SSS1.p2.4.m4.1.1" xref="S4.SS3.SSS1.p2.4.m4.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p2.4.m4.1b"><csymbol cd="latexml" id="S4.SS3.SSS1.p2.4.m4.1.1.cmml" xref="S4.SS3.SSS1.p2.4.m4.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p2.4.m4.1c">\%</annotation></semantics></math> labeling rate, reaching 40.02 mAP, 54.88 mAP, and 60.24 mAP respectively. This outperforms the supervised baseline by 10.72 points, 7.8 points, and 5.88 points, respectively. Similarly, our method also surpasses the SOTA method PseCo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> by 2.42 points, 1.90 points, and 1.98 points at different labeling rates. For fully labeled data, S<sup id="S4.SS3.SSS1.p2.5.2" class="ltx_sup">3</sup>OD also achieves optimal performance, exceeding the supervised baseline by 3.7 points to 67.3 mAP.
Considering the above results, our method outperforms the SOTAs by a large margin at all labeling rates on aerial images. The outstanding performance also demonstrates the superiority of our method in semi-supervised object detection tasks for aerial images.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.5" class="ltx_p">To further demonstrate our method’s effectiveness on small objects, we select several representative categories from aerial images, including ship (SP), plane (PL), small-vehicle (SV), large-vehicle (LV), bridge (BR), storage-tank (ST), and harbor (HB). In order to thoroughly validate the improvement of semi-supervised learning with limited labeled data, we present the results of S<sup id="S4.SS3.SSS1.p3.5.1" class="ltx_sup">3</sup>OD and other SOTA methods for each category at a labeling rate of 1<math id="S4.SS3.SSS1.p3.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS3.SSS1.p3.2.m2.1a"><mo id="S4.SS3.SSS1.p3.2.m2.1.1" xref="S4.SS3.SSS1.p3.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.2.m2.1b"><csymbol cd="latexml" id="S4.SS3.SSS1.p3.2.m2.1.1.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.2.m2.1c">\%</annotation></semantics></math>, as shown in Tab. <a href="#S4.T2" title="TABLE II ‣ IV-A Dataset and Evaluation Protocol ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> (Reproducibility experiments generally exhibit similar trends, so we randomly select one fold for demonstration).
From the results, our method shows significant improvements compared to supervised detection results in all categories. Among the categories with the highest proportions in the entire dataset, including “ship”, “small-vehicle”, and “large-vehicle”, our method achieves improvements of 16.4<math id="S4.SS3.SSS1.p3.3.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS3.SSS1.p3.3.m3.1a"><mo id="S4.SS3.SSS1.p3.3.m3.1.1" xref="S4.SS3.SSS1.p3.3.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.3.m3.1b"><csymbol cd="latexml" id="S4.SS3.SSS1.p3.3.m3.1.1.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.3.m3.1c">\%</annotation></semantics></math>, 75.7<math id="S4.SS3.SSS1.p3.4.m4.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS3.SSS1.p3.4.m4.1a"><mo id="S4.SS3.SSS1.p3.4.m4.1.1" xref="S4.SS3.SSS1.p3.4.m4.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.4.m4.1b"><csymbol cd="latexml" id="S4.SS3.SSS1.p3.4.m4.1.1.cmml" xref="S4.SS3.SSS1.p3.4.m4.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.4.m4.1c">\%</annotation></semantics></math>, and 30.7<math id="S4.SS3.SSS1.p3.5.m5.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS3.SSS1.p3.5.m5.1a"><mo id="S4.SS3.SSS1.p3.5.m5.1.1" xref="S4.SS3.SSS1.p3.5.m5.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.5.m5.1b"><csymbol cd="latexml" id="S4.SS3.SSS1.p3.5.m5.1.1.cmml" xref="S4.SS3.SSS1.p3.5.m5.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.5.m5.1c">\%</annotation></semantics></math> respectively. Focusing on small objects, “ships”, “small-vehicle”, and “storage-tank” are mostly in small object sizes. Our method outperforms other SSOD methods in these three categories. Additionally, “small-vehicle” is the category with the most instances and the highest number of small objects in aerial images. Our method shows significant improvement in this category. In contrast, other SSOD methods show minimal improvement in “small-vehicle” detection, and the performance of the baseline SSOD is even lower than that of supervised learning. This confirms our previous observation that generic semi-supervised detection methods are inclined to focus on large objects while neglecting the learning of small objects, thus affecting the ability to detect small objects.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS2.5.1.1" class="ltx_text">IV-C</span>2 </span>Qualitative Analysis</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">Fig. <a href="#S4.F5" title="Figure 5 ‣ IV-B Implementation Details ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents the qualitative comparison between S<sup id="S4.SS3.SSS2.p1.1.1" class="ltx_sup">3</sup>OD and other SOTA methods. We can see that, by introducing the proposed strategies, false negatives (red boxes) of small objects are remarkably reduced, indicating that small objects are more sufficiently learned. Furthermore, by focusing on the number of yellow boxes in the image, it can be noticed that compared to other SOTA SSOD methods, our approach demonstrates a stronger suppression effect on false alarms, which is the desired effect of the proposed TNL (Teacher-guided Negative Labeling) technique.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_italic">Ablation Study</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In this section, we conduct detailed ablations to validate our key designs. Without losing generality, all the ablation experiments are performed on the single data fold with 1<math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mo id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\%</annotation></semantics></math> labeling rate.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Component analysis of the proposed method</figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:164.8pt;height:123.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-25.9pt,19.4pt) scale(0.76070642350541,0.76070642350541) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.2" class="ltx_tr">
<td id="S4.T3.1.1.2.1" class="ltx_td ltx_border_tt"></td>
<td id="S4.T3.1.1.2.2" class="ltx_td ltx_align_center ltx_border_tt">SAT</td>
<td id="S4.T3.1.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">SLA</td>
<td id="S4.T3.1.1.2.4" class="ltx_td ltx_align_center ltx_border_tt">TNL</td>
<td id="S4.T3.1.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt">mAP</td>
</tr>
<tr id="S4.T3.1.1.3" class="ltx_tr">
<td id="S4.T3.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t">SSOD baseline</td>
<td id="S4.T3.1.1.3.2" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.1.1.3.3" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.1.1.3.4" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.1.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">36.0</td>
</tr>
<tr id="S4.T3.1.1.4" class="ltx_tr">
<td id="S4.T3.1.1.4.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="6"><span id="S4.T3.1.1.4.1.1" class="ltx_text"><span id="S4.T3.1.1.4.1.1.1" class="ltx_text"></span> <span id="S4.T3.1.1.4.1.1.2" class="ltx_text">
<span id="S4.T3.1.1.4.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.1.1.4.1.1.2.1.1" class="ltx_tr">
<span id="S4.T3.1.1.4.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Different</span></span>
<span id="S4.T3.1.1.4.1.1.2.1.2" class="ltx_tr">
<span id="S4.T3.1.1.4.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Configurations</span></span>
</span></span> <span id="S4.T3.1.1.4.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.T3.1.1.4.2" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T3.1.1.4.3" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.1.1.4.4" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.1.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">39.6</td>
</tr>
<tr id="S4.T3.1.1.5" class="ltx_tr">
<td id="S4.T3.1.1.5.1" class="ltx_td"></td>
<td id="S4.T3.1.1.5.2" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.5.3" class="ltx_td"></td>
<td id="S4.T3.1.1.5.4" class="ltx_td ltx_nopad_r ltx_align_center">37.8</td>
</tr>
<tr id="S4.T3.1.1.6" class="ltx_tr">
<td id="S4.T3.1.1.6.1" class="ltx_td"></td>
<td id="S4.T3.1.1.6.2" class="ltx_td"></td>
<td id="S4.T3.1.1.6.3" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.6.4" class="ltx_td ltx_nopad_r ltx_align_center">38.1</td>
</tr>
<tr id="S4.T3.1.1.7" class="ltx_tr">
<td id="S4.T3.1.1.7.1" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.7.2" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.7.3" class="ltx_td"></td>
<td id="S4.T3.1.1.7.4" class="ltx_td ltx_nopad_r ltx_align_center">40.1</td>
</tr>
<tr id="S4.T3.1.1.8" class="ltx_tr">
<td id="S4.T3.1.1.8.1" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.8.2" class="ltx_td"></td>
<td id="S4.T3.1.1.8.3" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.8.4" class="ltx_td ltx_nopad_r ltx_align_center">40.4</td>
</tr>
<tr id="S4.T3.1.1.9" class="ltx_tr">
<td id="S4.T3.1.1.9.1" class="ltx_td"></td>
<td id="S4.T3.1.1.9.2" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.9.3" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.9.4" class="ltx_td ltx_nopad_r ltx_align_center">40.4</td>
</tr>
<tr id="S4.T3.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">S<sup id="S4.T3.1.1.1.1.1.1" class="ltx_sup"><span id="S4.T3.1.1.1.1.1.1.1" class="ltx_text ltx_font_medium">3</span></sup>OD (Ours)</span></td>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">✓</td>
<td id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">✓</td>
<td id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">✓</td>
<td id="S4.T3.1.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T3.1.1.1.5.1" class="ltx_text ltx_font_bold">41.9</span></td>
</tr>
</table>
</span></div>
</figure>
<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS1.5.1.1" class="ltx_text">IV-D</span>1 </span>Component Analysis</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p">To verify the effectiveness of each proposed strategy individually, we conduct experiments with all possible combinations of the proposed three strategies. As depicted in Tab. <a href="#S4.T3" title="TABLE III ‣ IV-D Ablation Study ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, the baseline SSOD algorithm achieves an mAP of 36.0 when no additional strategies are employed. When we apply any of the proposed strategies, the baseline performance is consistently improved. By gradually incorporating all three strategies, the mAP shows a progress improvement, verifying each design’s effectiveness. Notably, SAT contributes significantly to the improvements. SAT enhances the baseline performance by 3.6 points because it directly impacts the supervision of small objects. These findings indirectly affirm the substantial impact of small objects on aerial image SSOD performance. Fortunately, our proposed methods effectively mitigate this impact, making them highly suitable for SSOD tasks in aerial images.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:50%;"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Performance of SSOD with different thresholds used for selecting pseudo-labels</figcaption>
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:173.4pt;height:175.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(24.5pt,-24.8pt) scale(1.39438009172777,1.39438009172777) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.2" class="ltx_tr">
<td id="S4.T4.1.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T4.1.1.2.1.1" class="ltx_text" style="font-size:50%;">Methods</span></td>
<td id="S4.T4.1.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T4.1.1.2.2.1" class="ltx_text" style="font-size:50%;">Setting</span></td>
<td id="S4.T4.1.1.2.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.2.3.1" class="ltx_text" style="font-size:50%;">mAP</span></td>
</tr>
<tr id="S4.T4.1.1.3" class="ltx_tr">
<td id="S4.T4.1.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T4.1.1.3.1.1" class="ltx_text" style="font-size:50%;"><span id="S4.T4.1.1.3.1.1.1" class="ltx_text"></span> <span id="S4.T4.1.1.3.1.1.2" class="ltx_text">
<span id="S4.T4.1.1.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.1.3.1.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.1.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Fixed</span></span>
<span id="S4.T4.1.1.3.1.1.2.1.2" class="ltx_tr">
<span id="S4.T4.1.1.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Threshold</span></span>
</span></span> <span id="S4.T4.1.1.3.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.T4.1.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.1.1.3.2.1" class="ltx_text" style="font-size:50%;">0.7</span></td>
<td id="S4.T4.1.1.3.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T4.1.1.3.3.1" class="ltx_text" style="font-size:50%;">33.6</span></td>
</tr>
<tr id="S4.T4.1.1.4" class="ltx_tr">
<td id="S4.T4.1.1.4.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.1.1.4.1.1" class="ltx_text" style="font-size:50%;">0.8</span></td>
<td id="S4.T4.1.1.4.2" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.4.2.1" class="ltx_text" style="font-size:50%;">36.6</span></td>
</tr>
<tr id="S4.T4.1.1.5" class="ltx_tr">
<td id="S4.T4.1.1.5.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.1.1.5.1.1" class="ltx_text" style="font-size:50%;">0.9</span></td>
<td id="S4.T4.1.1.5.2" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.5.2.1" class="ltx_text" style="font-size:50%;">36.0</span></td>
</tr>
<tr id="S4.T4.1.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T4.1.1.1.1.1" class="ltx_text" style="font-size:50%;">Large-0.9 </span><math id="S4.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S4.T4.1.1.1.1.m1.1a"><mo mathsize="50%" id="S4.T4.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.m1.1b"><and id="S4.T4.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.m1.1c">\&amp;</annotation></semantics></math><span id="S4.T4.1.1.1.1.2" class="ltx_text" style="font-size:50%;"> Small-0.8</span>
</td>
<td id="S4.T4.1.1.1.2" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.1.2.1" class="ltx_text" style="font-size:50%;">38.1</span></td>
</tr>
<tr id="S4.T4.1.1.6" class="ltx_tr">
<td id="S4.T4.1.1.6.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T4.1.1.6.1.1" class="ltx_text" style="font-size:50%;"><span id="S4.T4.1.1.6.1.1.1" class="ltx_text"></span> <span id="S4.T4.1.1.6.1.1.2" class="ltx_text">
<span id="S4.T4.1.1.6.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.1.6.1.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.1.6.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Adaptive</span></span>
<span id="S4.T4.1.1.6.1.1.2.1.2" class="ltx_tr">
<span id="S4.T4.1.1.6.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Threshold</span></span>
</span></span> <span id="S4.T4.1.1.6.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.T4.1.1.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.1.1.6.2.1" class="ltx_text" style="font-size:50%;">Class-aware</span></td>
<td id="S4.T4.1.1.6.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T4.1.1.6.3.1" class="ltx_text" style="font-size:50%;">35.2</span></td>
</tr>
<tr id="S4.T4.1.1.7" class="ltx_tr">
<td id="S4.T4.1.1.7.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T4.1.1.7.1.1" class="ltx_text" style="font-size:50%;">Size-aware (Ours)</span></td>
<td id="S4.T4.1.1.7.2" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S4.T4.1.1.7.2.1" class="ltx_text ltx_font_bold" style="font-size:50%;">39.6</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:50%;"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Effects of different percent numbers used in SAT</figcaption>
<div id="S4.T5.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:199.5pt;height:48.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(26.0pt,-6.3pt) scale(1.35269227063943,1.35269227063943) ;">
<table id="S4.T5.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.2.2.2" class="ltx_tr">
<td id="S4.T5.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<math id="S4.T5.1.1.1.1.m1.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S4.T5.1.1.1.1.m1.1a"><mi mathsize="50%" id="S4.T5.1.1.1.1.m1.1.1" xref="S4.T5.1.1.1.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.1.m1.1b"><ci id="S4.T5.1.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.1.m1.1c">P</annotation></semantics></math><span id="S4.T5.2.2.2.2.1" class="ltx_text" style="font-size:50%;">(</span><math id="S4.T5.2.2.2.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T5.2.2.2.2.m2.1a"><mo mathsize="50%" id="S4.T5.2.2.2.2.m2.1.1" xref="S4.T5.2.2.2.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.2.m2.1b"><csymbol cd="latexml" id="S4.T5.2.2.2.2.m2.1.1.cmml" xref="S4.T5.2.2.2.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.2.m2.1c">\%</annotation></semantics></math><span id="S4.T5.2.2.2.2.2" class="ltx_text" style="font-size:50%;">)</span>
</td>
<td id="S4.T5.2.2.2.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.2.2.2.3.1" class="ltx_text" style="font-size:50%;">25</span></td>
<td id="S4.T5.2.2.2.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.2.2.2.4.1" class="ltx_text" style="font-size:50%;">30</span></td>
<td id="S4.T5.2.2.2.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.2.2.2.5.1" class="ltx_text" style="font-size:50%;">35</span></td>
<td id="S4.T5.2.2.2.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.2.2.2.6.1" class="ltx_text" style="font-size:50%;">40</span></td>
<td id="S4.T5.2.2.2.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.2.2.2.7.1" class="ltx_text" style="font-size:50%;">45</span></td>
<td id="S4.T5.2.2.2.8" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S4.T5.2.2.2.8.1" class="ltx_text" style="font-size:50%;">50</span></td>
</tr>
<tr id="S4.T5.2.2.3" class="ltx_tr">
<td id="S4.T5.2.2.3.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S4.T5.2.2.3.1.1" class="ltx_text" style="font-size:50%;">mAP</span></td>
<td id="S4.T5.2.2.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.2.2.3.2.1" class="ltx_text" style="font-size:50%;">38.7</span></td>
<td id="S4.T5.2.2.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.2.2.3.3.1" class="ltx_text" style="font-size:50%;">39.4</span></td>
<td id="S4.T5.2.2.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.2.2.3.4.1" class="ltx_text ltx_font_bold" style="font-size:50%;">39.6</span></td>
<td id="S4.T5.2.2.3.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.2.2.3.5.1" class="ltx_text" style="font-size:50%;">38.4</span></td>
<td id="S4.T5.2.2.3.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.2.2.3.6.1" class="ltx_text" style="font-size:50%;">37.8</span></td>
<td id="S4.T5.2.2.3.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.2.2.3.7.1" class="ltx_text" style="font-size:50%;">34.0</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2310.14718/assets/fig6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="275" height="262" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Visualization of pseudo-labels selection. (a) and (c) are under the fixed threshold of 0.9, (b) and (d) are under our SAT.</figcaption>
</figure>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS2.5.1.1" class="ltx_text">IV-D</span>2 </span>Comparisons of Different Thresholds</h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.1" class="ltx_p">For the threshold of selecting pseudo-labels, we compare several ways of setting the threshold. These include a fixed threshold of 0.9 (baseline), a fixed threshold of 0.8 and 0.7, setting thresholds based on the object scale where a threshold of 0.9 is used for large objects and 0.8 for small objects, setting thresholds based on category distribution, and the proposed SAT method in this paper. Results are listed in Tab. <a href="#S4.T4" title="TABLE IV ‣ IV-D1 Component Analysis ‣ IV-D Ablation Study ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>. Compared to a completely fixed threshold, setting different thresholds for large and small objects shows higher performance, indicating that the optimal threshold for pseudo-labels is different for small and large objects. The proposed SAT method still improves performance, demonstrating that adapting the threshold based on the distribution is a superior strategy. Additionally, compared to setting thresholds separately for large and small objects, the proposed SAT method only requires adjusting one hyperparameter, the percentile value <math id="S4.SS4.SSS2.p1.1.m1.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S4.SS4.SSS2.p1.1.m1.1a"><mi id="S4.SS4.SSS2.p1.1.m1.1.1" xref="S4.SS4.SSS2.p1.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.1.m1.1b"><ci id="S4.SS4.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS2.p1.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.1.m1.1c">P</annotation></semantics></math> used in SAT. Tab. <a href="#S4.T5" title="TABLE V ‣ IV-D1 Component Analysis ‣ IV-D Ablation Study ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> also presents ablation experiments with different percentile values, showing that the optimal performance is achieved when using the 35th percentile of the distribution.</p>
</div>
<div id="S4.SS4.SSS2.p2" class="ltx_para">
<p id="S4.SS4.SSS2.p2.1" class="ltx_p">Furthermore, we provide visualizations of the selected pseudo-labels when training under different strategies in Fig. <a href="#S4.F6" title="Figure 6 ‣ IV-D1 Component Analysis ‣ IV-D Ablation Study ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. In this figure, green boxes denote the correct pseudo-labels, yellow boxes denote the false pseudo-labels, and red boxes denote objects missing to be pseudo-labeled. It can be observed that when using a fixed threshold, a large number of small objects are filtered out, while our method can retain more accurate pseudo-labels for small objects.</p>
</div>
</section>
<section id="S4.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS3.5.1.1" class="ltx_text">IV-D</span>3 </span>Different compositions in SLA</h4>

<div id="S4.SS4.SSS3.p1" class="ltx_para">
<p id="S4.SS4.SSS3.p1.3" class="ltx_p">Here, we dissect different compositions in SLA. Results are shown in Tab. <a href="#S4.T6" title="TABLE VI ‣ IV-D3 Different compositions in SLA ‣ IV-D Ablation Study ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>. When the distribution-based re-sampling strategy is used to replace the original IoU+Threhold strategy, we can achieve an improvement of 0.5 mAP. However, this improvement is relatively modest due to the limited supervision information for small objects in pseudo-labels. On the other side, when we incorporate the re-weighting strategy, which includes training loss for both large and small objects (SLA), we can achieve a more notable improvement of 1.8 mAP. This verifies that re-weighting can partially mitigate the issue of imbalanced training samples for different-sized objects during the training process. Additionally, we conduct tests on the optimal value of the hyper-parameter <math id="S4.SS4.SSS3.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS4.SSS3.p1.1.m1.1a"><mi id="S4.SS4.SSS3.p1.1.m1.1.1" xref="S4.SS4.SSS3.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS3.p1.1.m1.1b"><ci id="S4.SS4.SSS3.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS3.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS3.p1.1.m1.1c">K</annotation></semantics></math> within the complete S<sup id="S4.SS4.SSS3.p1.3.1" class="ltx_sup">3</sup>OD framework, as presented in Tab. <a href="#S4.T7" title="TABLE VII ‣ IV-D3 Different compositions in SLA ‣ IV-D Ablation Study ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a>. The best performance is achieved when <math id="S4.SS4.SSS3.p1.3.m3.1" class="ltx_Math" alttext="K=2" display="inline"><semantics id="S4.SS4.SSS3.p1.3.m3.1a"><mrow id="S4.SS4.SSS3.p1.3.m3.1.1" xref="S4.SS4.SSS3.p1.3.m3.1.1.cmml"><mi id="S4.SS4.SSS3.p1.3.m3.1.1.2" xref="S4.SS4.SSS3.p1.3.m3.1.1.2.cmml">K</mi><mo id="S4.SS4.SSS3.p1.3.m3.1.1.1" xref="S4.SS4.SSS3.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS4.SSS3.p1.3.m3.1.1.3" xref="S4.SS4.SSS3.p1.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS3.p1.3.m3.1b"><apply id="S4.SS4.SSS3.p1.3.m3.1.1.cmml" xref="S4.SS4.SSS3.p1.3.m3.1.1"><eq id="S4.SS4.SSS3.p1.3.m3.1.1.1.cmml" xref="S4.SS4.SSS3.p1.3.m3.1.1.1"></eq><ci id="S4.SS4.SSS3.p1.3.m3.1.1.2.cmml" xref="S4.SS4.SSS3.p1.3.m3.1.1.2">𝐾</ci><cn type="integer" id="S4.SS4.SSS3.p1.3.m3.1.1.3.cmml" xref="S4.SS4.SSS3.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS3.p1.3.m3.1c">K=2</annotation></semantics></math>.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:50%;"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>Component analysis of the SLA</figcaption>
<div id="S4.T6.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:112.7pt;height:105.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(17.7pt,-16.5pt) scale(1.45940242817257,1.45940242817257) ;">
<table id="S4.T6.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.3.1.1" class="ltx_tr">
<td id="S4.T6.3.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S4.T6.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T6.3.1.1.2.1" class="ltx_text" style="font-size:50%;">Setting</span></td>
<td id="S4.T6.3.1.1.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S4.T6.3.1.1.3.1" class="ltx_text" style="font-size:50%;">mAP</span></td>
</tr>
<tr id="S4.T6.3.1.2" class="ltx_tr">
<td id="S4.T6.3.1.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.3.1.2.1.1" class="ltx_text" style="font-size:50%;">I</span></td>
<td id="S4.T6.3.1.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.3.1.2.2.1" class="ltx_text" style="font-size:50%;">Baseline</span></td>
<td id="S4.T6.3.1.2.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T6.3.1.2.3.1" class="ltx_text" style="font-size:50%;">36.0</span></td>
</tr>
<tr id="S4.T6.3.1.3" class="ltx_tr">
<td id="S4.T6.3.1.3.1" class="ltx_td ltx_align_center"><span id="S4.T6.3.1.3.1.1" class="ltx_text" style="font-size:50%;">II</span></td>
<td id="S4.T6.3.1.3.2" class="ltx_td ltx_align_center"><span id="S4.T6.3.1.3.2.1" class="ltx_text" style="font-size:50%;">Resampling</span></td>
<td id="S4.T6.3.1.3.3" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T6.3.1.3.3.1" class="ltx_text" style="font-size:50%;">36.5</span></td>
</tr>
<tr id="S4.T6.3.1.4" class="ltx_tr">
<td id="S4.T6.3.1.4.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.3.1.4.1.1" class="ltx_text" style="font-size:50%;">IV</span></td>
<td id="S4.T6.3.1.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.3.1.4.2.1" class="ltx_text" style="font-size:50%;">SLA</span></td>
<td id="S4.T6.3.1.4.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S4.T6.3.1.4.3.1" class="ltx_text ltx_font_bold" style="font-size:50%;">37.8</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:50%;"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>Effects of parameters <math id="S4.T7.2.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.T7.2.m1.1b"><mi id="S4.T7.2.m1.1.1" xref="S4.T7.2.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.T7.2.m1.1c"><ci id="S4.T7.2.m1.1.1.cmml" xref="S4.T7.2.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.2.m1.1d">K</annotation></semantics></math></figcaption>
<div id="S4.T7.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:164.8pt;height:56.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(30.3pt,-10.5pt) scale(1.58123383092736,1.58123383092736) ;">
<table id="S4.T7.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.3.1.1" class="ltx_tr">
<td id="S4.T7.3.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><math id="S4.T7.3.1.1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.T7.3.1.1.1.m1.1a"><mi mathsize="50%" id="S4.T7.3.1.1.1.m1.1.1" xref="S4.T7.3.1.1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.T7.3.1.1.1.m1.1b"><ci id="S4.T7.3.1.1.1.m1.1.1.cmml" xref="S4.T7.3.1.1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.3.1.1.1.m1.1c">K</annotation></semantics></math></td>
<td id="S4.T7.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.3.1.1.2.1" class="ltx_text" style="font-size:50%;">1</span></td>
<td id="S4.T7.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.3.1.1.3.1" class="ltx_text" style="font-size:50%;">2</span></td>
<td id="S4.T7.3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.3.1.1.4.1" class="ltx_text" style="font-size:50%;">3</span></td>
<td id="S4.T7.3.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S4.T7.3.1.1.5.1" class="ltx_text" style="font-size:50%;">4</span></td>
</tr>
<tr id="S4.T7.3.1.2" class="ltx_tr">
<td id="S4.T7.3.1.2.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S4.T7.3.1.2.1.1" class="ltx_text" style="font-size:50%;">mAP</span></td>
<td id="S4.T7.3.1.2.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T7.3.1.2.2.1" class="ltx_text" style="font-size:50%;">39.8</span></td>
<td id="S4.T7.3.1.2.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T7.3.1.2.3.1" class="ltx_text ltx_font_bold" style="font-size:50%;">41.9</span></td>
<td id="S4.T7.3.1.2.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T7.3.1.2.4.1" class="ltx_text" style="font-size:50%;">41.1</span></td>
<td id="S4.T7.3.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T7.3.1.2.5.1" class="ltx_text" style="font-size:50%;">40.7</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:50%;"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span>Component analysis of the negative learning</figcaption>
<div id="S4.T8.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:173.4pt;height:136.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(29.7pt,-23.5pt) scale(1.52154344864642,1.52154344864642) ;">
<table id="S4.T8.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.T8.2.2.3" class="ltx_tr">
<td id="S4.T8.2.2.3.1" class="ltx_td ltx_border_tt"></td>
<td id="S4.T8.2.2.3.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T8.2.2.3.2.1" class="ltx_text" style="font-size:50%;">Setting</span></td>
<td id="S4.T8.2.2.3.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T8.2.2.3.3.1" class="ltx_text" style="font-size:50%;">FA</span></td>
<td id="S4.T8.2.2.3.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S4.T8.2.2.3.4.1" class="ltx_text" style="font-size:50%;">mAP</span></td>
</tr>
<tr id="S4.T8.2.2.4" class="ltx_tr">
<td id="S4.T8.2.2.4.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.2.2.4.1.1" class="ltx_text" style="font-size:50%;">I</span></td>
<td id="S4.T8.2.2.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.2.2.4.2.1" class="ltx_text" style="font-size:50%;">T-BG</span></td>
<td id="S4.T8.2.2.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.2.2.4.3.1" class="ltx_text" style="font-size:50%;">0.832</span></td>
<td id="S4.T8.2.2.4.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T8.2.2.4.4.1" class="ltx_text" style="font-size:50%;">37.7</span></td>
</tr>
<tr id="S4.T8.1.1.1" class="ltx_tr">
<td id="S4.T8.1.1.1.2" class="ltx_td ltx_align_center"><span id="S4.T8.1.1.1.2.1" class="ltx_text" style="font-size:50%;">II</span></td>
<td id="S4.T8.1.1.1.1" class="ltx_td ltx_align_center">
<span id="S4.T8.1.1.1.1.1" class="ltx_text" style="font-size:50%;">T-BG</span><math id="S4.T8.1.1.1.1.m1.1" class="ltx_Math" alttext="\_" display="inline"><semantics id="S4.T8.1.1.1.1.m1.1a"><mi mathsize="50%" mathvariant="normal" id="S4.T8.1.1.1.1.m1.1.1" xref="S4.T8.1.1.1.1.m1.1.1.cmml">_</mi><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.1.m1.1b"><ci id="S4.T8.1.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.1.m1.1.1">_</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.1.m1.1c">\_</annotation></semantics></math><span id="S4.T8.1.1.1.1.2" class="ltx_text" style="font-size:50%;">reweight</span>
</td>
<td id="S4.T8.1.1.1.3" class="ltx_td ltx_align_center"><span id="S4.T8.1.1.1.3.1" class="ltx_text" style="font-size:50%;">0.759</span></td>
<td id="S4.T8.1.1.1.4" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T8.1.1.1.4.1" class="ltx_text" style="font-size:50%;">39.5</span></td>
</tr>
<tr id="S4.T8.2.2.2" class="ltx_tr">
<td id="S4.T8.2.2.2.2" class="ltx_td ltx_align_center"><span id="S4.T8.2.2.2.2.1" class="ltx_text" style="font-size:50%;">III</span></td>
<td id="S4.T8.2.2.2.1" class="ltx_td ltx_align_center">
<span id="S4.T8.2.2.2.1.1" class="ltx_text" style="font-size:50%;">T-BG</span><math id="S4.T8.2.2.2.1.m1.1" class="ltx_Math" alttext="\_" display="inline"><semantics id="S4.T8.2.2.2.1.m1.1a"><mi mathsize="50%" mathvariant="normal" id="S4.T8.2.2.2.1.m1.1.1" xref="S4.T8.2.2.2.1.m1.1.1.cmml">_</mi><annotation-xml encoding="MathML-Content" id="S4.T8.2.2.2.1.m1.1b"><ci id="S4.T8.2.2.2.1.m1.1.1.cmml" xref="S4.T8.2.2.2.1.m1.1.1">_</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.2.2.2.1.m1.1c">\_</annotation></semantics></math><span id="S4.T8.2.2.2.1.2" class="ltx_text" style="font-size:50%;">HNS</span>
</td>
<td id="S4.T8.2.2.2.3" class="ltx_td ltx_align_center"><span id="S4.T8.2.2.2.3.1" class="ltx_text" style="font-size:50%;">0.747</span></td>
<td id="S4.T8.2.2.2.4" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T8.2.2.2.4.1" class="ltx_text" style="font-size:50%;">41.2</span></td>
</tr>
<tr id="S4.T8.2.2.5" class="ltx_tr">
<td id="S4.T8.2.2.5.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.2.2.5.1.1" class="ltx_text" style="font-size:50%;">IV</span></td>
<td id="S4.T8.2.2.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.2.2.5.2.1" class="ltx_text" style="font-size:50%;">TNL (Ours)</span></td>
<td id="S4.T8.2.2.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.2.2.5.3.1" class="ltx_text" style="font-size:50%;">0.652</span></td>
<td id="S4.T8.2.2.5.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S4.T8.2.2.5.4.1" class="ltx_text ltx_font_bold" style="font-size:50%;">41.9</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS4.5.1.1" class="ltx_text">IV-D</span>4 </span>Different strategies of Negative learning</h4>

<div id="S4.SS4.SSS4.p1" class="ltx_para">
<p id="S4.SS4.SSS4.p1.5" class="ltx_p">For the selection of negative samples, we also compare several different strategies, including:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">T-BG: Only using the teacher model to select negative samples with high background confidence scores (higher than 0.7).</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">T-BG<math id="S4.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\_" display="inline"><semantics id="S4.I1.i2.p1.1.m1.1a"><mi mathvariant="normal" id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">_</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b"><ci id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">_</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">\_</annotation></semantics></math>reweight: Following the strategy in Soft-teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>, use the background confidence scores to reweight the loss of negative samples.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">T-BG<math id="S4.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="\_" display="inline"><semantics id="S4.I1.i3.p1.1.m1.1a"><mi mathvariant="normal" id="S4.I1.i3.p1.1.m1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.cmml">_</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.1b"><ci id="S4.I1.i3.p1.1.m1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1">_</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.1c">\_</annotation></semantics></math>HNS: Under the setting of T-BG, incorporate low-confidence predictions of the teacher model directly as hard negative samples.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">TNL: Under the setting of T-BG, incorporate the weighted low-confidence predictions of the teacher model as hard negative samples.</p>
</div>
</li>
</ul>
<p id="S4.SS4.SSS4.p1.4" class="ltx_p">Here, we also calculate the overall false alarm (FA) of the detection results of the validation set under each setting, which reflects the model’s ability to discriminate negative samples. A high false alarm represents that the detector struggles to differentiate negative samples, indicating insufficient classification performance. We get <math id="S4.SS4.SSS4.p1.1.m1.1" class="ltx_Math" alttext="FA=FP/P" display="inline"><semantics id="S4.SS4.SSS4.p1.1.m1.1a"><mrow id="S4.SS4.SSS4.p1.1.m1.1.1" xref="S4.SS4.SSS4.p1.1.m1.1.1.cmml"><mrow id="S4.SS4.SSS4.p1.1.m1.1.1.2" xref="S4.SS4.SSS4.p1.1.m1.1.1.2.cmml"><mi id="S4.SS4.SSS4.p1.1.m1.1.1.2.2" xref="S4.SS4.SSS4.p1.1.m1.1.1.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS4.p1.1.m1.1.1.2.1" xref="S4.SS4.SSS4.p1.1.m1.1.1.2.1.cmml">​</mo><mi id="S4.SS4.SSS4.p1.1.m1.1.1.2.3" xref="S4.SS4.SSS4.p1.1.m1.1.1.2.3.cmml">A</mi></mrow><mo id="S4.SS4.SSS4.p1.1.m1.1.1.1" xref="S4.SS4.SSS4.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S4.SS4.SSS4.p1.1.m1.1.1.3" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.cmml"><mrow id="S4.SS4.SSS4.p1.1.m1.1.1.3.2" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.2.cmml"><mi id="S4.SS4.SSS4.p1.1.m1.1.1.3.2.2" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS4.p1.1.m1.1.1.3.2.1" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S4.SS4.SSS4.p1.1.m1.1.1.3.2.3" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.2.3.cmml">P</mi></mrow><mo id="S4.SS4.SSS4.p1.1.m1.1.1.3.1" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.1.cmml">/</mo><mi id="S4.SS4.SSS4.p1.1.m1.1.1.3.3" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.3.cmml">P</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS4.p1.1.m1.1b"><apply id="S4.SS4.SSS4.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1"><eq id="S4.SS4.SSS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.1"></eq><apply id="S4.SS4.SSS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.2"><times id="S4.SS4.SSS4.p1.1.m1.1.1.2.1.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.2.1"></times><ci id="S4.SS4.SSS4.p1.1.m1.1.1.2.2.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.2.2">𝐹</ci><ci id="S4.SS4.SSS4.p1.1.m1.1.1.2.3.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.2.3">𝐴</ci></apply><apply id="S4.SS4.SSS4.p1.1.m1.1.1.3.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.3"><divide id="S4.SS4.SSS4.p1.1.m1.1.1.3.1.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.1"></divide><apply id="S4.SS4.SSS4.p1.1.m1.1.1.3.2.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.2"><times id="S4.SS4.SSS4.p1.1.m1.1.1.3.2.1.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.2.1"></times><ci id="S4.SS4.SSS4.p1.1.m1.1.1.3.2.2.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.2.2">𝐹</ci><ci id="S4.SS4.SSS4.p1.1.m1.1.1.3.2.3.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.2.3">𝑃</ci></apply><ci id="S4.SS4.SSS4.p1.1.m1.1.1.3.3.cmml" xref="S4.SS4.SSS4.p1.1.m1.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS4.p1.1.m1.1c">FA=FP/P</annotation></semantics></math>, where <math id="S4.SS4.SSS4.p1.2.m2.1" class="ltx_Math" alttext="FP" display="inline"><semantics id="S4.SS4.SSS4.p1.2.m2.1a"><mrow id="S4.SS4.SSS4.p1.2.m2.1.1" xref="S4.SS4.SSS4.p1.2.m2.1.1.cmml"><mi id="S4.SS4.SSS4.p1.2.m2.1.1.2" xref="S4.SS4.SSS4.p1.2.m2.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS4.p1.2.m2.1.1.1" xref="S4.SS4.SSS4.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS4.SSS4.p1.2.m2.1.1.3" xref="S4.SS4.SSS4.p1.2.m2.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS4.p1.2.m2.1b"><apply id="S4.SS4.SSS4.p1.2.m2.1.1.cmml" xref="S4.SS4.SSS4.p1.2.m2.1.1"><times id="S4.SS4.SSS4.p1.2.m2.1.1.1.cmml" xref="S4.SS4.SSS4.p1.2.m2.1.1.1"></times><ci id="S4.SS4.SSS4.p1.2.m2.1.1.2.cmml" xref="S4.SS4.SSS4.p1.2.m2.1.1.2">𝐹</ci><ci id="S4.SS4.SSS4.p1.2.m2.1.1.3.cmml" xref="S4.SS4.SSS4.p1.2.m2.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS4.p1.2.m2.1c">FP</annotation></semantics></math> represents the total number of incorrect detections, <math id="S4.SS4.SSS4.p1.3.m3.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S4.SS4.SSS4.p1.3.m3.1a"><mi id="S4.SS4.SSS4.p1.3.m3.1.1" xref="S4.SS4.SSS4.p1.3.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS4.p1.3.m3.1b"><ci id="S4.SS4.SSS4.p1.3.m3.1.1.cmml" xref="S4.SS4.SSS4.p1.3.m3.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS4.p1.3.m3.1c">P</annotation></semantics></math> represents the number of detected objects and objects with <math id="S4.SS4.SSS4.p1.4.m4.1" class="ltx_Math" alttext="IoU&lt;0.5" display="inline"><semantics id="S4.SS4.SSS4.p1.4.m4.1a"><mrow id="S4.SS4.SSS4.p1.4.m4.1.1" xref="S4.SS4.SSS4.p1.4.m4.1.1.cmml"><mrow id="S4.SS4.SSS4.p1.4.m4.1.1.2" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.cmml"><mi id="S4.SS4.SSS4.p1.4.m4.1.1.2.2" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS4.p1.4.m4.1.1.2.1" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.1.cmml">​</mo><mi id="S4.SS4.SSS4.p1.4.m4.1.1.2.3" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS4.p1.4.m4.1.1.2.1a" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.1.cmml">​</mo><mi id="S4.SS4.SSS4.p1.4.m4.1.1.2.4" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.4.cmml">U</mi></mrow><mo id="S4.SS4.SSS4.p1.4.m4.1.1.1" xref="S4.SS4.SSS4.p1.4.m4.1.1.1.cmml">&lt;</mo><mn id="S4.SS4.SSS4.p1.4.m4.1.1.3" xref="S4.SS4.SSS4.p1.4.m4.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS4.p1.4.m4.1b"><apply id="S4.SS4.SSS4.p1.4.m4.1.1.cmml" xref="S4.SS4.SSS4.p1.4.m4.1.1"><lt id="S4.SS4.SSS4.p1.4.m4.1.1.1.cmml" xref="S4.SS4.SSS4.p1.4.m4.1.1.1"></lt><apply id="S4.SS4.SSS4.p1.4.m4.1.1.2.cmml" xref="S4.SS4.SSS4.p1.4.m4.1.1.2"><times id="S4.SS4.SSS4.p1.4.m4.1.1.2.1.cmml" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.1"></times><ci id="S4.SS4.SSS4.p1.4.m4.1.1.2.2.cmml" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.2">𝐼</ci><ci id="S4.SS4.SSS4.p1.4.m4.1.1.2.3.cmml" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.3">𝑜</ci><ci id="S4.SS4.SSS4.p1.4.m4.1.1.2.4.cmml" xref="S4.SS4.SSS4.p1.4.m4.1.1.2.4">𝑈</ci></apply><cn type="float" id="S4.SS4.SSS4.p1.4.m4.1.1.3.cmml" xref="S4.SS4.SSS4.p1.4.m4.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS4.p1.4.m4.1c">IoU&lt;0.5</annotation></semantics></math> between the prediction and ground truth were classified as false positives. From the results of Tab. <a href="#S4.T8" title="TABLE VIII ‣ IV-D3 Different compositions in SLA ‣ IV-D Ablation Study ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a>, we can observe that directly using T-BG to select negative samples leads to a boom in the false alarm rate. The increase in false alarms accumulates more errors in the network, resulting in performance degradation. Utilizing T-BG to reweight the negative samples can partially retain the effect of false negative samples and improve performance. Our method effectively utilizes ambiguous predictions generated by the teacher model as challenging negative samples, leading to better performance improvement. Compared to directly introducing these hard negative samples, using confidence score weighting can obtain better results. This is because, among these low-confidence predictions, a small number of positive samples may also exist. Weighting them can reduce the impact of these potential positive samples and avoid confusion between positive and negative samples by the network.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Discussion</span>
</h2>

<figure id="S5.F7" class="ltx_figure"><img src="/html/2310.14718/assets/fig7.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="349" height="262" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Comparing the average confidence scores of all objects and small objects in correct predictions under the three settings of supervised by 100<math id="S5.F7.4.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.F7.4.m1.1b"><mo id="S5.F7.4.m1.1.1" xref="S5.F7.4.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.F7.4.m1.1c"><csymbol cd="latexml" id="S5.F7.4.m1.1.1.cmml" xref="S5.F7.4.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.4.m1.1d">\%</annotation></semantics></math> labeled data, supervised, semi-supervised, and our S<sup id="S5.F7.8.1" class="ltx_sup">3</sup>OD by 1<math id="S5.F7.6.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.F7.6.m3.1b"><mo id="S5.F7.6.m3.1.1" xref="S5.F7.6.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.F7.6.m3.1c"><csymbol cd="latexml" id="S5.F7.6.m3.1.1.cmml" xref="S5.F7.6.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.6.m3.1d">\%</annotation></semantics></math> labeled data.</figcaption>
</figure>
<div id="S5.p1" class="ltx_para">
<p id="S5.p1.3" class="ltx_p">Overall, extensive experiments have convincingly demonstrated the effectiveness of our proposed S<sup id="S5.p1.3.1" class="ltx_sup">3</sup>OD. The detection mAP for specific categories and the corresponding visualizations also provide sufficient evidence that the S<sup id="S5.p1.3.2" class="ltx_sup">3</sup>OD can optimize the detection performance of small objects on semi-supervised object detection in aerial images. To further support this point, we present the small objects’ average predicted scores of different methods after semi-supervised training, which is in Fig. <a href="#S5.F7" title="Figure 7 ‣ V Discussion ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. It is clear that, in comparison to existing SSOD methods that overlook small object information in unlabeled images and solely enhance the detection of large objects, our S<sup id="S5.p1.3.3" class="ltx_sup">3</sup>OD method achieves a more balanced improvement in the detection performance across all scales of objects. This, in turn, validates that our method mitigates the impact of small objects on semi-supervised object detection in aerial images.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">However, apart from numerous small objects, we observe that some objects with extreme characteristics also have poor performance, such as objects with elongated aspect ratios, including ‘bridge’ and ‘harbor’. Based on the detection results for the ‘Harbor’ (HB) category in Tab. <a href="#S4.T2" title="TABLE II ‣ IV-A Dataset and Evaluation Protocol ‣ IV Experiment ‣ Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, it is evident that the SSOD method does not exhibit substantial enhancements for harbors, and our method performs similarly to existing methods when dealing with these objects. The underlying reason is that objects with these characteristics face a disadvantaged position even in detection, compared to objects with regular shapes. Similarly, these objects might be disregarded during semi-supervised training. And it is equally important to adopt differentiated criteria and select more suitable pseudo-label supervision information for disadvantaged objects with other extreme characteristics. Furthermore, aerial image object detection also faces an inherent imbalance issue, known as class imbalance. Compared to natural scenes, aerial image objects often exhibit a more severe long-tail distribution, and the class imbalance is further amplified in the process of semi-supervised detection. Categories with a larger number of samples tend to show better detection performance, allowing for the acquisition of more reliable pseudo-labels for supervision. In contrast, categories with fewer samples are more prone to being overlooked within this virtuous cycle. How to effectively mitigate these biases within the semi-supervised pipeline, will be further explored in our future work.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.3" class="ltx_p">In this paper, we analyze the key factors influencing the performance of SSOD for aerial images and identify that existing SSOD methods tend to overlook the presence of small objects, which constitute a significant portion of aerial images. To address this challenge, we design a novel framework S<sup id="S6.p1.3.1" class="ltx_sup">3</sup>OD to tackle the various imbalance challenges caused by small objects. In S<sup id="S6.p1.3.2" class="ltx_sup">3</sup>OD, we adopt an adaptive approach to select scale-sensitive thresholds, allowing us to retain more supervision information for small objects during the pseudo-label generation stage. To mitigate the imbalance problem resulting from limited supervision, we introduce a label assignment strategy with Gaussian-based sampling and size-aware re-weighting, ensuring a more equitable assignment of positive samples for objects of different scales. Furthermore, we leverage the ambiguous predictions generated by the teacher model to enhance the model’s ability to learn from challenging negative samples. Through integrating the three designs, our S<sup id="S6.p1.3.3" class="ltx_sup">3</sup>OD framework presents a significant leap forward compared to the current SOTA SSOD methods for aerial images.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.2.2.1" class="ltx_text" style="font-size:90%;">[1]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.4.1" class="ltx_text" style="font-size:90%;">
Y. Liu, Q. Li, Y. Yuan, Q. Du, and Q. Wang, “Abnet: Adaptive balanced network for multiscale object detection in remote sensing imagery,” </span><em id="bib.bib1.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</em><span id="bib.bib1.6.3" class="ltx_text" style="font-size:90%;">, vol. 60, pp. 1–14, 2022.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.2.2.1" class="ltx_text" style="font-size:90%;">[2]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.4.1" class="ltx_text" style="font-size:90%;">
J. Wang, F. Li, and H. Bi, “Gaussian focal loss: Learning distribution polarized angle prediction for rotated object detection in aerial images,” </span><em id="bib.bib2.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</em><span id="bib.bib2.6.3" class="ltx_text" style="font-size:90%;">, vol. 60, pp. 1–13, 2022.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.2.2.1" class="ltx_text" style="font-size:90%;">[3]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.4.1" class="ltx_text" style="font-size:90%;">
X. Zhang, G. Wang, P. Zhu, T. Zhang, C. Li, and L. Jiao, “Grs-det: An anchor-free rotation ship detector based on gaussian-mask in remote sensing images,” </span><em id="bib.bib3.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</em><span id="bib.bib3.6.3" class="ltx_text" style="font-size:90%;">, vol. 59, no. 4, pp. 3518–3531, 2020.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.2.2.1" class="ltx_text" style="font-size:90%;">[4]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.4.1" class="ltx_text" style="font-size:90%;">
F. Shi, T. Zhang, and T. Zhang, “Orientation-aware vehicle detection in aerial images via an anchor-free object detection approach,” </span><em id="bib.bib4.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</em><span id="bib.bib4.6.3" class="ltx_text" style="font-size:90%;">, vol. 59, no. 6, pp. 5221–5233, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.2.2.1" class="ltx_text" style="font-size:90%;">[5]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.4.1" class="ltx_text" style="font-size:90%;">
R. Zhang, H. Guo, F. Xu, W. Yang, H. Yu, H. Zhang, and G.-S. Xia, “Optical-enhanced oil tank detection in high-resolution sar images,” </span><em id="bib.bib5.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</em><span id="bib.bib5.6.3" class="ltx_text" style="font-size:90%;">, vol. 60, pp. 1–12, 2022.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.2.2.1" class="ltx_text" style="font-size:90%;">[6]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.4.1" class="ltx_text" style="font-size:90%;">
D. Liang, Q. Geng, Z. Wei, D. A. Vorontsov, E. L. Kim, M. Wei, and H. Zhou, “Anchor retouching via model interaction for robust object detection in aerial images,” </span><em id="bib.bib6.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</em><span id="bib.bib6.6.3" class="ltx_text" style="font-size:90%;">, vol. 60, pp. 1–13, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.2.2.1" class="ltx_text" style="font-size:90%;">[7]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.4.1" class="ltx_text" style="font-size:90%;">
J. Ding, N. Xue, G.-S. Xia, X. Bai, W. Yang, M. Y. Yang, S. Belongie, J. Luo, M. Datcu, M. Pelillo </span><em id="bib.bib7.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib7.6.3" class="ltx_text" style="font-size:90%;">, “Object detection in aerial images: A large-scale benchmark and challenges,” </span><em id="bib.bib7.7.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span id="bib.bib7.8.5" class="ltx_text" style="font-size:90%;">, vol. 44, no. 11, pp. 7778–7796, 2021.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.2.2.1" class="ltx_text" style="font-size:90%;">[8]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.4.1" class="ltx_text" style="font-size:90%;">
G.-S. Xia, X. Bai, J. Ding, Z. Zhu, S. Belongie, J. Luo, M. Datcu, M. Pelillo, and L. Zhang, “Dota: A large-scale dataset for object detection in aerial images,” in </span><em id="bib.bib8.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib8.6.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 3974–3983.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.2.2.1" class="ltx_text" style="font-size:90%;">[9]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.4.1" class="ltx_text" style="font-size:90%;">
K. Li, G. Wan, G. Cheng, L. Meng, and J. Han, “Object detection in optical remote sensing images: A survey and a new benchmark,” </span><em id="bib.bib9.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ISPRS Journal of Photogrammetry and Remote Sensing</em><span id="bib.bib9.6.3" class="ltx_text" style="font-size:90%;">, vol. 159, pp. 296–307, 2020.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.2.2.1" class="ltx_text" style="font-size:90%;">[10]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.4.1" class="ltx_text" style="font-size:90%;">
J. Yi, P. Wu, B. Liu, Q. Huang, H. Qu, and D. Metaxas, “Oriented object detection in aerial images with box boundary-aware vectors,” in </span><em id="bib.bib10.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em><span id="bib.bib10.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 2150–2159.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.2.2.1" class="ltx_text" style="font-size:90%;">[11]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.4.1" class="ltx_text" style="font-size:90%;">
J. Ding, N. Xue, Y. Long, G.-S. Xia, and Q. Lu, “Learning roi transformer for oriented object detection in aerial images,” in </span><em id="bib.bib11.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib11.6.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 2849–2858.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.2.2.1" class="ltx_text" style="font-size:90%;">[12]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.4.1" class="ltx_text" style="font-size:90%;">
J. Wang, W. Yang, H.-C. Li, H. Zhang, and G.-S. Xia, “Learning center probability map for detecting objects in aerial images,” </span><em id="bib.bib12.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</em><span id="bib.bib12.6.3" class="ltx_text" style="font-size:90%;">, vol. 59, no. 5, pp. 4307–4323, 2020.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.2.2.1" class="ltx_text" style="font-size:90%;">[13]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.4.1" class="ltx_text" style="font-size:90%;">
J. Jeong, S. Lee, J. Kim, and N. Kwak, “Consistency-based semi-supervised learning for object detection,” </span><em id="bib.bib13.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib13.6.3" class="ltx_text" style="font-size:90%;">, vol. 32, 2019.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.2.2.1" class="ltx_text" style="font-size:90%;">[14]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.4.1" class="ltx_text" style="font-size:90%;">
K. Sohn, Z. Zhang, C.-L. Li, H. Zhang, C.-Y. Lee, and T. Pfister, “A simple semi-supervised learning framework for object detection,” </span><em id="bib.bib14.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2005.04757</em><span id="bib.bib14.6.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.2.2.1" class="ltx_text" style="font-size:90%;">[15]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.4.1" class="ltx_text" style="font-size:90%;">
Y.-C. Liu, C.-Y. Ma, Z. He, C.-W. Kuo, K. Chen, P. Zhang, B. Wu, Z. Kira, and P. Vajda, “Unbiased teacher for semi-supervised object detection,” </span><em id="bib.bib15.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib15.6.3" class="ltx_text" style="font-size:90%;">, pp. 1–17, 2021.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.2.2.1" class="ltx_text" style="font-size:90%;">[16]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.4.1" class="ltx_text" style="font-size:90%;">
M. Xu, Z. Zhang, H. Hu, J. Wang, L. Wang, F. Wei, X. Bai, and Z. Liu, “End-to-end semi-supervised object detection with soft teacher,” in </span><em id="bib.bib16.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib16.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 3060–3069.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.2.2.1" class="ltx_text" style="font-size:90%;">[17]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.4.1" class="ltx_text" style="font-size:90%;">
G. Li, X. Li, Y. Wang, Y. Wu, D. Liang, and S. Zhang, “Pseco: Pseudo labeling and consistency training for semi-supervised object detection,” in </span><em id="bib.bib17.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</em><span id="bib.bib17.6.3" class="ltx_text" style="font-size:90%;">.   Springer, 2022, pp. 457–472.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.2.2.1" class="ltx_text" style="font-size:90%;">[18]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.4.1" class="ltx_text" style="font-size:90%;">
H. Zhou, Z. Ge, S. Liu, W. Mao, Z. Li, H. Yu, and J. Sun, “Dense teacher: Dense pseudo-labels for semi-supervised object detection,” in </span><em id="bib.bib18.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</em><span id="bib.bib18.6.3" class="ltx_text" style="font-size:90%;">.   Springer, 2022, pp. 35–50.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.2.2.1" class="ltx_text" style="font-size:90%;">[19]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.4.1" class="ltx_text" style="font-size:90%;">
X. Wang, X. Yang, S. Zhang, Y. Li, L. Feng, S. Fang, C. Lyu, K. Chen, and W. Zhang, “Consistent-teacher: Towards reducing inconsistent pseudo-targets in semi-supervised object detection,” in </span><em id="bib.bib19.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib19.6.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 3240–3249.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.2.2.1" class="ltx_text" style="font-size:90%;">[20]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.4.1" class="ltx_text" style="font-size:90%;">
T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick, “Microsoft coco: Common objects in context,” in </span><em id="bib.bib20.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</em><span id="bib.bib20.6.3" class="ltx_text" style="font-size:90%;">.   Springer, 2014, pp. 740–755.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.2.2.1" class="ltx_text" style="font-size:90%;">[21]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.4.1" class="ltx_text" style="font-size:90%;">
B. Chen, P. Li, X. Chen, B. Wang, L. Zhang, and X.-S. Hua, “Dense learning based semi-supervised object detection,” in </span><em id="bib.bib21.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib21.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 4815–4824.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.2.2.1" class="ltx_text" style="font-size:90%;">[22]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.4.1" class="ltx_text" style="font-size:90%;">
J. Wang, W. Yang, H. Guo, R. Zhang, and G.-S. Xia, “Tiny object detection in aerial images,” in </span><em id="bib.bib22.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 25th International Conference on Pattern Recognition (ICPR)</em><span id="bib.bib22.6.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2021, pp. 3791–3798.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.2.2.1" class="ltx_text" style="font-size:90%;">[23]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.4.1" class="ltx_text" style="font-size:90%;">
S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: towards real-time object detection with region proposal networks,” </span><em id="bib.bib23.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span id="bib.bib23.6.3" class="ltx_text" style="font-size:90%;">, vol. 39, no. 6, pp. 1137–1149, 2016.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.2.2.1" class="ltx_text" style="font-size:90%;">[24]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.4.1" class="ltx_text" style="font-size:90%;">
C. Xu, J. Wang, W. Yang, H. Yu, L. Yu, and G.-S. Xia, “Detecting tiny objects in aerial images: A normalized wasserstein distance and a new benchmark,” </span><em id="bib.bib24.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ISPRS Journal of Photogrammetry and Remote Sensing</em><span id="bib.bib24.6.3" class="ltx_text" style="font-size:90%;">, vol. 190, pp. 79–93, 2022.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.2.2.1" class="ltx_text" style="font-size:90%;">[25]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.4.1" class="ltx_text" style="font-size:90%;">
C. Xu, J. Wang, W. Yang, H. Yu, L. Yu, and G.-S. Xia, “Rfla: Gaussian receptive field based label assignment for tiny object detection,” in </span><em id="bib.bib25.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</em><span id="bib.bib25.6.3" class="ltx_text" style="font-size:90%;">.   Springer, 2022, pp. 526–543.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.2.2.1" class="ltx_text" style="font-size:90%;">[26]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.4.1" class="ltx_text" style="font-size:90%;">
C. Xu, J. Ding, J. Wang, W. Yang, H. Yu, L. Yu, and G.-S. Xia, “Dynamic coarse-to-fine learning for oriented tiny object detection,” in </span><em id="bib.bib26.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib26.6.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 7318–7328.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.2.2.1" class="ltx_text" style="font-size:90%;">[27]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.4.1" class="ltx_text" style="font-size:90%;">
Z. Cai and N. Vasconcelos, “Cascade R-CNN: Delving into high quality object detection,” in </span><em id="bib.bib27.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib27.6.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 6154–6162.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.2.2.1" class="ltx_text" style="font-size:90%;">[28]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.4.1" class="ltx_text" style="font-size:90%;">
T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár, “Focal loss for dense object detection,” in </span><em id="bib.bib28.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer vision</em><span id="bib.bib28.6.3" class="ltx_text" style="font-size:90%;">, 2017, pp. 2980–2988.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.2.2.1" class="ltx_text" style="font-size:90%;">[29]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.4.1" class="ltx_text" style="font-size:90%;">
S. Qiao, L.-C. Chen, and A. Yuille, “Detectors: Detecting objects with recursive feature pyramid and switchable atrous convolution,” in </span><em id="bib.bib29.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib29.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 10 213–10 224.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.2.2.1" class="ltx_text" style="font-size:90%;">[30]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.4.1" class="ltx_text" style="font-size:90%;">
Z. Tian, C. Shen, H. Chen, and T. He, “Fcos: Fully convolutional one-stage object detection,” in </span><em id="bib.bib30.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib30.6.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 9627–9636.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.2.2.1" class="ltx_text" style="font-size:90%;">[31]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.4.1" class="ltx_text" style="font-size:90%;">
H. Law and J. Deng, “Cornernet: Detecting objects as paired keypoints,” in </span><em id="bib.bib31.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</em><span id="bib.bib31.6.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 734–750.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.2.2.1" class="ltx_text" style="font-size:90%;">[32]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.4.1" class="ltx_text" style="font-size:90%;">
K. Duan, S. Bai, L. Xie, H. Qi, Q. Huang, and Q. Tian, “Centernet: Keypoint triplets for object detection,” in </span><em id="bib.bib32.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib32.6.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 6569–6578.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.2.2.1" class="ltx_text" style="font-size:90%;">[33]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.4.1" class="ltx_text" style="font-size:90%;">
N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, and S. Zagoruyko, “End-to-end object detection with transformers,” in </span><em id="bib.bib33.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</em><span id="bib.bib33.6.3" class="ltx_text" style="font-size:90%;">.   Springer, 2020, pp. 213–229.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.2.2.1" class="ltx_text" style="font-size:90%;">[34]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.4.1" class="ltx_text" style="font-size:90%;">
X. Zhu, W. Su, L. Lu, B. Li, X. Wang, and J. Dai, “Deformable detr: Deformable transformers for end-to-end object detection,” </span><em id="bib.bib34.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib34.6.3" class="ltx_text" style="font-size:90%;">, pp. 1–16, 2021.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.2.2.1" class="ltx_text" style="font-size:90%;">[35]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.4.1" class="ltx_text" style="font-size:90%;">
J. Ma, W. Shao, H. Ye, L. Wang, H. Wang, Y. Zheng, and X. Xue, “Arbitrary-oriented scene text detection via rotation proposals,” </span><em id="bib.bib35.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Multimedia</em><span id="bib.bib35.6.3" class="ltx_text" style="font-size:90%;">, vol. 20, no. 11, pp. 3111–3122, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.2.2.1" class="ltx_text" style="font-size:90%;">[36]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.4.1" class="ltx_text" style="font-size:90%;">
J. Han, J. Ding, J. Li, and G.-S. Xia, “Align deep features for oriented object detection,” </span><em id="bib.bib36.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</em><span id="bib.bib36.6.3" class="ltx_text" style="font-size:90%;">, vol. 60, pp. 1–11, 2021.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.2.2.1" class="ltx_text" style="font-size:90%;">[37]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.4.1" class="ltx_text" style="font-size:90%;">
X. Xie, G. Cheng, J. Wang, X. Yao, and J. Han, “Oriented r-cnn for object detection,” in </span><em id="bib.bib37.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib37.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 3520–3529.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.2.2.1" class="ltx_text" style="font-size:90%;">[38]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.4.1" class="ltx_text" style="font-size:90%;">
W. Li, Y. Chen, K. Hu, and J. Zhu, “Oriented reppoints for aerial object detection,” in </span><em id="bib.bib38.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib38.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 1829–1838.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.2.2.1" class="ltx_text" style="font-size:90%;">[39]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.4.1" class="ltx_text" style="font-size:90%;">
Z. Li, B. Hou, Z. Wu, L. Jiao, B. Ren, and C. Yang, “Fcosr: A simple anchor-free rotated detector for aerial object detection,” </span><em id="bib.bib39.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2111.10780</em><span id="bib.bib39.6.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.2.2.1" class="ltx_text" style="font-size:90%;">[40]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.4.1" class="ltx_text" style="font-size:90%;">
J. Shermeyer and A. Van Etten, “The effects of super-resolution on object detection performance in satellite imagery,” in </span><em id="bib.bib40.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</em><span id="bib.bib40.6.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 1–10.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.2.2.1" class="ltx_text" style="font-size:90%;">[41]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.4.1" class="ltx_text" style="font-size:90%;">
L. Courtrai, M.-T. Pham, and S. Lefèvre, “Small object detection in remote sensing images based on super-resolution with auxiliary generative adversarial networks,” </span><em id="bib.bib41.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Remote Sensing</em><span id="bib.bib41.6.3" class="ltx_text" style="font-size:90%;">, vol. 12, no. 19, p. 3152, 2020.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.2.2.1" class="ltx_text" style="font-size:90%;">[42]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.4.1" class="ltx_text" style="font-size:90%;">
S. M. A. Bashir and Y. Wang, “Small object detection in remote sensing images with residual feature aggregation-based super-resolution and object detector network,” </span><em id="bib.bib42.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Remote Sensing</em><span id="bib.bib42.6.3" class="ltx_text" style="font-size:90%;">, vol. 13, no. 9, p. 1854, 2021.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.2.2.1" class="ltx_text" style="font-size:90%;">[43]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.4.1" class="ltx_text" style="font-size:90%;">
X. Yang, J. Yang, J. Yan, Y. Zhang, T. Zhang, Z. Guo, X. Sun, and K. Fu, “Scrdet: Towards more robust detection for small, cluttered and rotated objects,” in </span><em id="bib.bib43.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib43.6.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 8232–8241.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.2.2.1" class="ltx_text" style="font-size:90%;">[44]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.4.1" class="ltx_text" style="font-size:90%;">
X. Yang, J. Yan, W. Liao, X. Yang, J. Tang, and T. He, “Scrdet++: Detecting small, cluttered and rotated objects via instance-level feature denoising and rotation loss smoothing,” </span><em id="bib.bib44.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span id="bib.bib44.6.3" class="ltx_text" style="font-size:90%;">, vol. 45, no. 2, pp. 2384–2399, 2022.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.2.2.1" class="ltx_text" style="font-size:90%;">[45]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.4.1" class="ltx_text" style="font-size:90%;">
M. Sajjadi, M. Javanmardi, and T. Tasdizen, “Regularization with stochastic transformations and perturbations for deep semi-supervised learning,” </span><em id="bib.bib45.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib45.6.3" class="ltx_text" style="font-size:90%;">, vol. 29, 2016.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.2.2.1" class="ltx_text" style="font-size:90%;">[46]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.4.1" class="ltx_text" style="font-size:90%;">
S. Laine and T. Aila, “Temporal ensembling for semi-supervised learning,” </span><em id="bib.bib46.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib46.6.3" class="ltx_text" style="font-size:90%;">, pp. 1–13, 2017.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.2.2.1" class="ltx_text" style="font-size:90%;">[47]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.4.1" class="ltx_text" style="font-size:90%;">
A. Tarvainen and H. Valpola, “Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results,” </span><em id="bib.bib47.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib47.6.3" class="ltx_text" style="font-size:90%;">, vol. 30, 2017.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.2.2.1" class="ltx_text" style="font-size:90%;">[48]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.4.1" class="ltx_text" style="font-size:90%;">
D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot, A. Oliver, and C. A. Raffel, “Mixmatch: A holistic approach to semi-supervised learning,” </span><em id="bib.bib48.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib48.6.3" class="ltx_text" style="font-size:90%;">, vol. 32, 2019.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.2.2.1" class="ltx_text" style="font-size:90%;">[49]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.4.1" class="ltx_text" style="font-size:90%;">
D. Berthelot, N. Carlini, E. D. Cubuk, A. Kurakin, K. Sohn, H. Zhang, and C. Raffel, “Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring,” </span><em id="bib.bib49.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib49.6.3" class="ltx_text" style="font-size:90%;">, pp. 1–13, 2020.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.2.2.1" class="ltx_text" style="font-size:90%;">[50]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.4.1" class="ltx_text" style="font-size:90%;">
Q. Xie, Z. Dai, E. Hovy, T. Luong, and Q. Le, “Unsupervised data augmentation for consistency training,” </span><em id="bib.bib50.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib50.6.3" class="ltx_text" style="font-size:90%;">, vol. 33, pp. 6256–6268, 2020.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.2.2.1" class="ltx_text" style="font-size:90%;">[51]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.4.1" class="ltx_text" style="font-size:90%;">
D. Lee, S. Kim, I. Kim, Y. Cheon, M. Cho, and W.-S. Han, “Contrastive regularization for semi-supervised learning,” in </span><em id="bib.bib51.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib51.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 3911–3920.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.2.2.1" class="ltx_text" style="font-size:90%;">[52]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.4.1" class="ltx_text" style="font-size:90%;">
D.-H. Lee </span><em id="bib.bib52.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib52.6.3" class="ltx_text" style="font-size:90%;">, “Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks,” in </span><em id="bib.bib52.7.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">Workshop on challenges in representation learning, ICML</em><span id="bib.bib52.8.5" class="ltx_text" style="font-size:90%;">, vol. 3, no. 2, 2013, p. 896.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.2.2.1" class="ltx_text" style="font-size:90%;">[53]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.4.1" class="ltx_text" style="font-size:90%;">
Y. Grandvalet and Y. Bengio, “Semi-supervised learning by entropy minimization,” </span><em id="bib.bib53.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib53.6.3" class="ltx_text" style="font-size:90%;">, vol. 17, 2004.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.2.2.1" class="ltx_text" style="font-size:90%;">[54]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.4.1" class="ltx_text" style="font-size:90%;">
Q. Xie, M.-T. Luong, E. Hovy, and Q. V. Le, “Self-training with noisy student improves imagenet classification,” in </span><em id="bib.bib54.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib54.6.3" class="ltx_text" style="font-size:90%;">, 2020, pp. 10 687–10 698.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.2.2.1" class="ltx_text" style="font-size:90%;">[55]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.4.1" class="ltx_text" style="font-size:90%;">
M. N. Rizve, K. Duarte, Y. S. Rawat, and M. Shah, “In defense of pseudo-labeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning,” in </span><em id="bib.bib55.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib55.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 1–20.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.2.2.1" class="ltx_text" style="font-size:90%;">[56]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.4.1" class="ltx_text" style="font-size:90%;">
H. Pham, Z. Dai, Q. Xie, and Q. V. Le, “Meta pseudo labels,” in </span><em id="bib.bib56.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib56.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 11 557–11 568.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.2.2.1" class="ltx_text" style="font-size:90%;">[57]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.4.1" class="ltx_text" style="font-size:90%;">
K. Sohn, D. Berthelot, N. Carlini, Z. Zhang, H. Zhang, C. A. Raffel, E. D. Cubuk, A. Kurakin, and C.-L. Li, “Fixmatch: Simplifying semi-supervised learning with consistency and confidence,” </span><em id="bib.bib57.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib57.6.3" class="ltx_text" style="font-size:90%;">, vol. 33, pp. 596–608, 2020.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.2.2.1" class="ltx_text" style="font-size:90%;">[58]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.4.1" class="ltx_text" style="font-size:90%;">
B. Zhang, Y. Wang, W. Hou, H. Wu, J. Wang, M. Okumura, and T. Shinozaki, “Flexmatch: Boosting semi-supervised learning with curriculum pseudo labeling,” </span><em id="bib.bib58.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib58.6.3" class="ltx_text" style="font-size:90%;">, vol. 34, pp. 18 408–18 419, 2021.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.2.2.1" class="ltx_text" style="font-size:90%;">[59]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.4.1" class="ltx_text" style="font-size:90%;">
B. Kim, J. Choo, Y.-D. Kwon, S. Joe, S. Min, and Y. Gwon, “Selfmatch: Combining contrastive self-supervision and consistency for semi-supervised learning,” </span><em id="bib.bib59.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2101.06480</em><span id="bib.bib59.6.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.2.2.1" class="ltx_text" style="font-size:90%;">[60]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.4.1" class="ltx_text" style="font-size:90%;">
J. Wang, T. Lukasiewicz, D. Massiceti, X. Hu, V. Pavlovic, and A. Neophytou, “Np-match: When neural processes meet semi-supervised learning,” in </span><em id="bib.bib60.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</em><span id="bib.bib60.6.3" class="ltx_text" style="font-size:90%;">.   PMLR, 2022, pp. 22 919–22 934.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.2.2.1" class="ltx_text" style="font-size:90%;">[61]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.4.1" class="ltx_text" style="font-size:90%;">
M. Zheng, S. You, L. Huang, F. Wang, C. Qian, and C. Xu, “Simmatch: Semi-supervised learning with similarity matching,” in </span><em id="bib.bib61.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib61.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 14 471–14 481.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib62.2.2.1" class="ltx_text" style="font-size:90%;">[62]</span></span>
<span class="ltx_bibblock"><span id="bib.bib62.4.1" class="ltx_text" style="font-size:90%;">
Y. Chen, X. Tan, B. Zhao, Z. Chen, R. Song, J. Liang, and X. Lu, “Boosting semi-supervised learning by exploiting all unlabeled data,” in </span><em id="bib.bib62.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib62.6.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 7548–7557.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib63.2.2.1" class="ltx_text" style="font-size:90%;">[63]</span></span>
<span class="ltx_bibblock"><span id="bib.bib63.4.1" class="ltx_text" style="font-size:90%;">
J. Jeong, V. Verma, M. Hyun, J. Kannala, and N. Kwak, “Interpolation-based semi-supervised learning for object detection,” in </span><em id="bib.bib63.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib63.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 11 602–11 611.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib64.2.2.1" class="ltx_text" style="font-size:90%;">[64]</span></span>
<span class="ltx_bibblock"><span id="bib.bib64.4.1" class="ltx_text" style="font-size:90%;">
Q. Zhou, C. Yu, Z. Wang, Q. Qian, and H. Li, “Instant-teaching: An end-to-end semi-supervised object detection framework,” in </span><em id="bib.bib64.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib64.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 4081–4090.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib65.2.2.1" class="ltx_text" style="font-size:90%;">[65]</span></span>
<span class="ltx_bibblock"><span id="bib.bib65.4.1" class="ltx_text" style="font-size:90%;">
Z. Wang, Y. Li, Y. Guo, L. Fang, and S. Wang, “Data-uncertainty guided multi-phase learning for semi-supervised object detection,” in </span><em id="bib.bib65.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib65.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 4568–4577.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib66.2.2.1" class="ltx_text" style="font-size:90%;">[66]</span></span>
<span class="ltx_bibblock"><span id="bib.bib66.4.1" class="ltx_text" style="font-size:90%;">
H. Li, Z. Wu, A. Shrivastava, and L. S. Davis, “Rethinking pseudo labels for semi-supervised object detection,” in </span><em id="bib.bib66.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial Intelligence</em><span id="bib.bib66.6.3" class="ltx_text" style="font-size:90%;">, vol. 36, no. 2, 2022, pp. 1314–1322.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib67.2.2.1" class="ltx_text" style="font-size:90%;">[67]</span></span>
<span class="ltx_bibblock"><span id="bib.bib67.4.1" class="ltx_text" style="font-size:90%;">
L. Zhang, Y. Sun, and W. Wei, “Mind the gap: Polishing pseudo labels for accurate semi-supervised object detection,” </span><em id="bib.bib67.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2207.08185</em><span id="bib.bib67.6.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib68.2.2.1" class="ltx_text" style="font-size:90%;">[68]</span></span>
<span class="ltx_bibblock"><span id="bib.bib68.4.1" class="ltx_text" style="font-size:90%;">
Y. Tang, W. Chen, Y. Luo, and Y. Zhang, “Humble teachers teach better students for semi-supervised object detection,” in </span><em id="bib.bib68.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib68.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 3132–3141.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib69.2.2.1" class="ltx_text" style="font-size:90%;">[69]</span></span>
<span class="ltx_bibblock"><span id="bib.bib69.4.1" class="ltx_text" style="font-size:90%;">
Q. Yang, X. Wei, B. Wang, X.-S. Hua, and L. Zhang, “Interactive self-training with mean teachers for semi-supervised object detection,” in </span><em id="bib.bib69.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib69.6.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 5941–5950.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib70.2.2.1" class="ltx_text" style="font-size:90%;">[70]</span></span>
<span class="ltx_bibblock"><span id="bib.bib70.4.1" class="ltx_text" style="font-size:90%;">
Y.-C. Liu, C.-Y. Ma, and Z. Kira, “Unbiased teacher v2: Semi-supervised object detection for anchor-free and anchor-based detectors,” in </span><em id="bib.bib70.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib70.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 9819–9828.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib71.2.2.1" class="ltx_text" style="font-size:90%;">[71]</span></span>
<span class="ltx_bibblock"><span id="bib.bib71.4.1" class="ltx_text" style="font-size:90%;">
H. Choi, Z. Chen, X. Shi, and T.-K. Kim, “Semi-supervised object detection with object-wise contrastive learning and regression uncertainty,” </span><em id="bib.bib71.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">British Machine Vision Conference</em><span id="bib.bib71.6.3" class="ltx_text" style="font-size:90%;">, pp. 1–20, 2022.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib72.2.2.1" class="ltx_text" style="font-size:90%;">[72]</span></span>
<span class="ltx_bibblock"><span id="bib.bib72.4.1" class="ltx_text" style="font-size:90%;">
Y. Zhang, X. Yao, C. Liu, F. Chen, X. Song, T. Xing, R. Hu, H. Chai, P. Xu, and G. Zhang, “S4od: Semi-supervised learning for single-stage object detection,” </span><em id="bib.bib72.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2204.04492</em><span id="bib.bib72.6.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib73.2.2.1" class="ltx_text" style="font-size:90%;">[73]</span></span>
<span class="ltx_bibblock"><span id="bib.bib73.4.1" class="ltx_text" style="font-size:90%;">
R. Vandeghen, G. Louppe, and M. Van Droogenbroeck, “Adaptive self-training for object detection,” </span><em id="bib.bib73.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2212.05911</em><span id="bib.bib73.6.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib74.2.2.1" class="ltx_text" style="font-size:90%;">[74]</span></span>
<span class="ltx_bibblock"><span id="bib.bib74.4.1" class="ltx_text" style="font-size:90%;">
C. Liu, W. Zhang, X. Lin, W. Zhang, X. Tan, J. Han, X. Li, E. Ding, and J. Wang, “Ambiguity-resistant semi-supervised learning for dense object detection,” in </span><em id="bib.bib74.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib74.6.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 15 579–15 588.
</span>
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib75.2.2.1" class="ltx_text" style="font-size:90%;">[75]</span></span>
<span class="ltx_bibblock"><span id="bib.bib75.4.1" class="ltx_text" style="font-size:90%;">
B. Xu, M. Chen, W. Guan, and L. Hu, “Efficient teacher: Semi-supervised object detection for yolov5,” </span><em id="bib.bib75.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2302.07577</em><span id="bib.bib75.6.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib76.2.2.1" class="ltx_text" style="font-size:90%;">[76]</span></span>
<span class="ltx_bibblock"><span id="bib.bib76.4.1" class="ltx_text" style="font-size:90%;">
B. Chen, W. Chen, S. Yang, Y. Xuan, J. Song, D. Xie, S. Pu, M. Song, and Y. Zhuang, “Label matching semi-supervised object detection,” in </span><em id="bib.bib76.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib76.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 14 381–14 390.
</span>
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib77.2.2.1" class="ltx_text" style="font-size:90%;">[77]</span></span>
<span class="ltx_bibblock"><span id="bib.bib77.4.1" class="ltx_text" style="font-size:90%;">
L. Liu, B. Zhang, J. Zhang, W. Zhang, Z. Gan, G. Tian, W. Zhu, Y. Wang, and C. Wang, “Mixteacher: Mining promising labels with mixed scale teacher for semi-supervised object detection,” in </span><em id="bib.bib77.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib77.6.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 7370–7379.
</span>
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib78.2.2.1" class="ltx_text" style="font-size:90%;">[78]</span></span>
<span class="ltx_bibblock"><span id="bib.bib78.4.1" class="ltx_text" style="font-size:90%;">
Q. Guo, Y. Mu, J. Chen, T. Wang, Y. Yu, and P. Luo, “Scale-equivalent distillation for semi-supervised object detection,” in </span><em id="bib.bib78.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib78.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 14 522–14 531.
</span>
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib79.2.2.1" class="ltx_text" style="font-size:90%;">[79]</span></span>
<span class="ltx_bibblock"><span id="bib.bib79.4.1" class="ltx_text" style="font-size:90%;">
J. Kim, J. Jang, S. Seo, J. Jeong, J. Na, and N. Kwak, “Mum: Mix image tiles and unmix feature tiles for semi-supervised object detection,” in </span><em id="bib.bib79.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib79.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 14 512–14 521.
</span>
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib80.2.2.1" class="ltx_text" style="font-size:90%;">[80]</span></span>
<span class="ltx_bibblock"><span id="bib.bib80.4.1" class="ltx_text" style="font-size:90%;">
F. Zhang, T. Pan, and B. Wang, “Semi-supervised object detection with adaptive class-rebalancing self-training,” in </span><em id="bib.bib80.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial Intelligence</em><span id="bib.bib80.6.3" class="ltx_text" style="font-size:90%;">, vol. 36, no. 3, 2022, pp. 3252–3261.
</span>
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib81.2.2.1" class="ltx_text" style="font-size:90%;">[81]</span></span>
<span class="ltx_bibblock"><span id="bib.bib81.4.1" class="ltx_text" style="font-size:90%;">
P. Mi, J. Lin, Y. Zhou, Y. Shen, G. Luo, X. Sun, L. Cao, R. Fu, Q. Xu, and R. Ji, “Active teacher for semi-supervised object detection,” in </span><em id="bib.bib81.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib81.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 14 482–14 491.
</span>
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib82.2.2.1" class="ltx_text" style="font-size:90%;">[82]</span></span>
<span class="ltx_bibblock"><span id="bib.bib82.4.1" class="ltx_text" style="font-size:90%;">
P. Wang, Z. Cai, H. Yang, G. Swaminathan, N. Vasconcelos, B. Schiele, and S. Soatto, “Omni-detr: Omni-supervised object detection with transformers,” in </span><em id="bib.bib82.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib82.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 9367–9376.
</span>
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib83.2.2.1" class="ltx_text" style="font-size:90%;">[83]</span></span>
<span class="ltx_bibblock"><span id="bib.bib83.4.1" class="ltx_text" style="font-size:90%;">
J. Zhang, X. Lin, W. Zhang, K. Wang, X. Tan, and J. Han, “Semi-detr: Semi-supervised object detection with detection transformers,” in </span><em id="bib.bib83.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib83.6.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib84.2.2.1" class="ltx_text" style="font-size:90%;">[84]</span></span>
<span class="ltx_bibblock"><span id="bib.bib84.4.1" class="ltx_text" style="font-size:90%;">
G. Chen, L. Liu, W. Hu, and Z. Pan, “Semi-supervised object detection in remote sensing images using generative adversarial networks,” in </span><em id="bib.bib84.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium</em><span id="bib.bib84.6.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2018, pp. 2503–2506.
</span>
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib85.2.2.1" class="ltx_text" style="font-size:90%;">[85]</span></span>
<span class="ltx_bibblock"><span id="bib.bib85.4.1" class="ltx_text" style="font-size:90%;">
W. Hua, D. Liang, J. Li, X. Liu, Z. Zou, X. Ye, and X. Bai, “Sood: Towards semi-supervised oriented object detection,” in </span><em id="bib.bib85.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib85.6.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 15 558–15 567.
</span>
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib86.2.2.1" class="ltx_text" style="font-size:90%;">[86]</span></span>
<span class="ltx_bibblock"><span id="bib.bib86.4.1" class="ltx_text" style="font-size:90%;">
X. Yang, J. Yan, Q. Ming, W. Wang, X. Zhang, and Q. Tian, “Rethinking rotated object detection with gaussian wasserstein distance loss,” in </span><em id="bib.bib86.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</em><span id="bib.bib86.6.3" class="ltx_text" style="font-size:90%;">.   PMLR, 2021, pp. 11 830–11 841.
</span>
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib87.2.2.1" class="ltx_text" style="font-size:90%;">[87]</span></span>
<span class="ltx_bibblock"><span id="bib.bib87.4.1" class="ltx_text" style="font-size:90%;">
X. Yang, X. Yang, J. Yang, Q. Ming, W. Wang, Q. Tian, and J. Yan, “Learning high-precision bounding box for rotated object detection via kullback-leibler divergence,” </span><em id="bib.bib87.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib87.6.3" class="ltx_text" style="font-size:90%;">, vol. 34, pp. 18 381–18 394, 2021.
</span>
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib88.2.2.1" class="ltx_text" style="font-size:90%;">[88]</span></span>
<span class="ltx_bibblock"><span id="bib.bib88.4.1" class="ltx_text" style="font-size:90%;">
Y. Wang, H. Wang, Y. Shen, J. Fei, W. Li, G. Jin, L. Wu, R. Zhao, and X. Le, “Semi-supervised semantic segmentation using unreliable pseudo-labels,” in </span><em id="bib.bib88.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib88.6.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 4248–4257.
</span>
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib89.2.2.1" class="ltx_text" style="font-size:90%;">[89]</span></span>
<span class="ltx_bibblock"><span id="bib.bib89.4.1" class="ltx_text" style="font-size:90%;">
G.-S. Xia, X. Bai, J. Ding, Z. Zhu, S. Belongie, J. Luo, M. Datcu, M. Pelillo, and L. Zhang, “DOTA: A large-scale dataset for object detection in aerial images,” in </span><em id="bib.bib89.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib89.6.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 3974–3983.
</span>
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib90.2.2.1" class="ltx_text" style="font-size:90%;">[90]</span></span>
<span class="ltx_bibblock"><span id="bib.bib90.4.1" class="ltx_text" style="font-size:90%;">
Y. Zhou, X. Yang, G. Zhang, J. Wang, Y. Liu, L. Hou, X. Jiang, X. Liu, J. Yan, C. Lyu </span><em id="bib.bib90.5.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib90.6.3" class="ltx_text" style="font-size:90%;">, “Mmrotate: A rotated object detection benchmark using pytorch,” in </span><em id="bib.bib90.7.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 30th ACM International Conference on Multimedia</em><span id="bib.bib90.8.5" class="ltx_text" style="font-size:90%;">, 2022, pp. 7331–7334.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.14717" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.14718" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.14718">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.14718" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.14719" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 22:17:07 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
