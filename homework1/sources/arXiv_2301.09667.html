<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2301.09667] Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans</title><meta property="og:description" content="Object recognition systems are usually trained and evaluated on high resolution images. However, in real world applications, it is common that the images have low resolutions or have small sizes. In this study, we firs…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2301.09667">

<!--Generated on Fri Mar  1 06:19:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Computer Vision,  Deep Neural Network,  Object Recognition,  Multi-Resolution,  Faster-RCNN,  Human Visual System
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\history</span>
<p id="p1.2" class="ltx_p">Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.
<a target="_blank" href="https:/doi.org/10.1109/ACCESS.2017.DOI" title="" class="ltx_ref">10.1109/ACCESS.2017.DOI</a></p>
</div>
<h1 class="ltx_title ltx_title_document">Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">AMIR GHASEMI
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
NASRIN BAYAT
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
FATEMEH MOTTAGHIAN
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
AKRAM BAYAT1
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">The Berkeley Institute for Data Science, Berkeley, California, USA
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Object recognition systems are usually trained and evaluated on high resolution images. However, in real world applications, it is common that the images have low resolutions or have small sizes. In this study, we first track the performance of the state-of-the-art deep object recognition network, Faster-RCNN, as a function of image resolution. The results reveals negative effects of low resolution images on recognition performance. They also show that different spatial frequencies convey different information about the objects in recognition process. It means multi-resolution recognition system can provides better insight into optimal selection of features that results in better recognition of objects. This is similar to the mechanisms of the human visual systems that are able to implement multi-scale representation of a visual scene simultaneously. Then, we propose a multi-resolution object recognition framework rather than a single-resolution network. The proposed framework is evaluated on the PASCAL VOC2007 database. The experimental results show the performance of our adapted multi-resolution Faster-RCNN framework outperforms the single-resolution Faster-RCNN on input images with various resolutions with an increase in the mean Average Precision (mAP) of 9.14% across all resolutions and 1.2% on the full-spectrum images. Furthermore, the proposed model yields robustness of the performance over a wide range of spatial frequencies.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Computer Vision, Deep Neural Network, Object Recognition, Multi-Resolution, Faster-RCNN, Human Visual System

</div>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined">\titlepgskip</span>
<p id="p2.2" class="ltx_p">=-15pt</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recent advances in deep neural networks (DNN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and access to very large datasets with million annotated data especially for computer vision applications have led to state-of-the-art results in many problem domains such as object detection and scene classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. For example, Faster-RCNN network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> achieved the impressive results in recognition and localization of objects in natural scenes or GoogleNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> reached approximately to the human performance in classification of the ImageNet database <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite the significant achievements, a major drawback of the current deep neural networks for visual recognition is that they have been trained and evaluated on high quality images in which their performances drop significantly in classification of the low resolution images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">in other words, previous works only focus on full spectrum image resolutions when training their networks, but the variety of real-world applications, from moving objects to small size images, often demand different constraints.
Given the real-world resource constraints such as low resolution and small size images, recognition efficiency and performance becomes increasingly important for object detection. However to achieve better efficiency, accuracy usually is scarifies.
This paper aims to tackle this problem by systematically studying the performance of the object recognition networks (e.g., Faster-RCNN) under the various resolutions of input images.
Then, we propose a method based on the mechanism of the human visual system that produces better and robust performance in deep object detection networks with both higher accuracy and better efficiency across a wide rang of image resolutions.
To evaluate the performance of our proposed method for object recognition, we choose the Faster-RCNN network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> as one of the best existing models in terms of the accuracy on PASCAL VOC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> image database.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Object Detection in Human Visual System -</span> Visual perception in humans is a process that human acquire knowledge about their environment. This process is initiated when surrounding light enters the eye and induces electrical signals subsequently processed within the brain where an image is formed.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">A large volume of studies has shown that human visual system has the ability to adapt to changes in environment in different ways, in which each adjustment may need different mechanisms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. For example adaptation to color encompasses different adjustments including sensitivity changes in the cones.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Human visual system has also spatial adaptations. As an example, tilt aftereffects can be deduced with both real and subjective contours, with asymmetries between them which encourages adaptation at different cortical sites <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Visual objects in the real world are observed in contextual scenes which are usually relevant from physical and semantic perspective. With regard to blurriness, Bar <span id="S2.p4.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> deployed a blurred, low frequency representation of a scene and showed that human visual system is able to determine ambiguous objects.
<br class="ltx_break"><span id="S2.p4.1.2" class="ltx_text ltx_font_bold">Object Detection in Computer Vision -</span> It deals with discovering instances of semantic objects of a certain class (e.g. buildings, cars, or humans) in images and videos. Most traditional approaches for object detection used well-established computer vision methods which relies on extracting feature descriptors (e.g., SIFT, SURF, BRIEF, etc.)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. However, with the emerge of deep neural networks (in particular, convolutional neural network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>) and its remarkable success in computer vision, the majority of recent works in object detection for digital images and videos have shifted towards using them as the primary technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. The state-of-the-art technique using DNN can be categorized into two main types: one-stage methods and two stage-methods. One-stage methods prioritize inference speed (e.g., YOLO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, SSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and RetinaNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>). Two-stage methods prioritize detection accuracy (e.g., Faster R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, Mask R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and Cascade R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>).</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">In this study, we focus on improving detection accuracy and efficiency in detecting objects in low resolution images and videos. As said before, the existing neural networks are generally trained and tested on high quality images, in which when they are fed in with low quality images, their performance in detecting and recognizing objects reduces remarkably <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. However, in real life, there are many cases that images have low resolution. To solve this issue, motivated by the capability of human visual system in adapting to different range of resolution, we propose a multi-resolution method which improves the performance of the model which it is fed in with blurry images.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Tracking Object recognition network performance</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we explain our methodology to track performance of the state of the art deep object recognition network, faster-RCNN with various resolution levels along with notation and problem formulation.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Model Architecture</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We deploy Faster-RCNN framework for object detection and localization. The Faster-RCNN uses Region Proposal Network (RPN) and an object detection network that share convolutional layers for fast testing. The baseline network is VGG-16 and its Conv 5-3 features are used for region proposal. We adapted the Faster-RCNN based on the publicly available code in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
and implemented it with a few modifications in TensorFlow to evaluate the performance of the network on 4952 images of the PASCAL VOC2007 test dataset with full resolution (full spectrum in the frequency domain).</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Notation and Problem Formulation</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">As said before, we evaluate the performance of the Faster-RCNN network on the PASCAL VOC2007 image database under multiple resolutions. For this purpose, we create a set of image databases whose resolutions vary systematically from extremely coarse to very fine. This is performed by applying the two-dimensional Gaussian low pass filter in various cut off frequencies to the PASCAL VOC2007 image database in the frequency domain. The results of this process resemble blurring of an image to reduce the details of high frequency components of that image in multiple levels. To simplify, instead of applying a two dimensional (2D) Gaussian function to each pixel of an image which is equivalent to convolving a 2D Gaussian with the image, we apply the product of their individual Fourier transforms. We then re-transform the resulting product into the spatial domain to obtain the image in the desired resolution (<math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="I_{f_{c}}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">I</mi><msub id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.3.2.cmml">f</mi><mi id="S3.SS2.p1.1.m1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.cmml">c</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">𝐼</ci><apply id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.2">𝑓</ci><ci id="S3.SS2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">I_{f_{c}}</annotation></semantics></math>).</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Attenuating frequencies using low pass Gaussian filters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> results in a smoother image in the spatial domain. This process is formalized in the following equations:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.8" class="ltx_Math" alttext="\hat{F}_{f_{c}}(u,v)=F(u,v)H_{f_{c}}(u,v),f_{min}&lt;f_{c}&lt;f_{max}" display="block"><semantics id="S3.E1.m1.8a"><mrow id="S3.E1.m1.8.8.2" xref="S3.E1.m1.8.8.3.cmml"><mrow id="S3.E1.m1.7.7.1.1" xref="S3.E1.m1.7.7.1.1.cmml"><mrow id="S3.E1.m1.7.7.1.1.2" xref="S3.E1.m1.7.7.1.1.2.cmml"><msub id="S3.E1.m1.7.7.1.1.2.2" xref="S3.E1.m1.7.7.1.1.2.2.cmml"><mover accent="true" id="S3.E1.m1.7.7.1.1.2.2.2" xref="S3.E1.m1.7.7.1.1.2.2.2.cmml"><mi id="S3.E1.m1.7.7.1.1.2.2.2.2" xref="S3.E1.m1.7.7.1.1.2.2.2.2.cmml">F</mi><mo id="S3.E1.m1.7.7.1.1.2.2.2.1" xref="S3.E1.m1.7.7.1.1.2.2.2.1.cmml">^</mo></mover><msub id="S3.E1.m1.7.7.1.1.2.2.3" xref="S3.E1.m1.7.7.1.1.2.2.3.cmml"><mi id="S3.E1.m1.7.7.1.1.2.2.3.2" xref="S3.E1.m1.7.7.1.1.2.2.3.2.cmml">f</mi><mi id="S3.E1.m1.7.7.1.1.2.2.3.3" xref="S3.E1.m1.7.7.1.1.2.2.3.3.cmml">c</mi></msub></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.2.1" xref="S3.E1.m1.7.7.1.1.2.1.cmml">​</mo><mrow id="S3.E1.m1.7.7.1.1.2.3.2" xref="S3.E1.m1.7.7.1.1.2.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.7.7.1.1.2.3.2.1" xref="S3.E1.m1.7.7.1.1.2.3.1.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">u</mi><mo id="S3.E1.m1.7.7.1.1.2.3.2.2" xref="S3.E1.m1.7.7.1.1.2.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">v</mi><mo stretchy="false" id="S3.E1.m1.7.7.1.1.2.3.2.3" xref="S3.E1.m1.7.7.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.7.7.1.1.1" xref="S3.E1.m1.7.7.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.7.7.1.1.3" xref="S3.E1.m1.7.7.1.1.3.cmml"><mi id="S3.E1.m1.7.7.1.1.3.2" xref="S3.E1.m1.7.7.1.1.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.3.1" xref="S3.E1.m1.7.7.1.1.3.1.cmml">​</mo><mrow id="S3.E1.m1.7.7.1.1.3.3.2" xref="S3.E1.m1.7.7.1.1.3.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.7.7.1.1.3.3.2.1" xref="S3.E1.m1.7.7.1.1.3.3.1.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">u</mi><mo id="S3.E1.m1.7.7.1.1.3.3.2.2" xref="S3.E1.m1.7.7.1.1.3.3.1.cmml">,</mo><mi id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">v</mi><mo stretchy="false" id="S3.E1.m1.7.7.1.1.3.3.2.3" xref="S3.E1.m1.7.7.1.1.3.3.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.3.1a" xref="S3.E1.m1.7.7.1.1.3.1.cmml">​</mo><msub id="S3.E1.m1.7.7.1.1.3.4" xref="S3.E1.m1.7.7.1.1.3.4.cmml"><mi id="S3.E1.m1.7.7.1.1.3.4.2" xref="S3.E1.m1.7.7.1.1.3.4.2.cmml">H</mi><msub id="S3.E1.m1.7.7.1.1.3.4.3" xref="S3.E1.m1.7.7.1.1.3.4.3.cmml"><mi id="S3.E1.m1.7.7.1.1.3.4.3.2" xref="S3.E1.m1.7.7.1.1.3.4.3.2.cmml">f</mi><mi id="S3.E1.m1.7.7.1.1.3.4.3.3" xref="S3.E1.m1.7.7.1.1.3.4.3.3.cmml">c</mi></msub></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.3.1b" xref="S3.E1.m1.7.7.1.1.3.1.cmml">​</mo><mrow id="S3.E1.m1.7.7.1.1.3.5.2" xref="S3.E1.m1.7.7.1.1.3.5.1.cmml"><mo stretchy="false" id="S3.E1.m1.7.7.1.1.3.5.2.1" xref="S3.E1.m1.7.7.1.1.3.5.1.cmml">(</mo><mi id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml">u</mi><mo id="S3.E1.m1.7.7.1.1.3.5.2.2" xref="S3.E1.m1.7.7.1.1.3.5.1.cmml">,</mo><mi id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml">v</mi><mo stretchy="false" id="S3.E1.m1.7.7.1.1.3.5.2.3" xref="S3.E1.m1.7.7.1.1.3.5.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.8.8.2.3" xref="S3.E1.m1.8.8.3a.cmml">,</mo><mrow id="S3.E1.m1.8.8.2.2" xref="S3.E1.m1.8.8.2.2.cmml"><msub id="S3.E1.m1.8.8.2.2.2" xref="S3.E1.m1.8.8.2.2.2.cmml"><mi id="S3.E1.m1.8.8.2.2.2.2" xref="S3.E1.m1.8.8.2.2.2.2.cmml">f</mi><mrow id="S3.E1.m1.8.8.2.2.2.3" xref="S3.E1.m1.8.8.2.2.2.3.cmml"><mi id="S3.E1.m1.8.8.2.2.2.3.2" xref="S3.E1.m1.8.8.2.2.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.8.8.2.2.2.3.1" xref="S3.E1.m1.8.8.2.2.2.3.1.cmml">​</mo><mi id="S3.E1.m1.8.8.2.2.2.3.3" xref="S3.E1.m1.8.8.2.2.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.8.8.2.2.2.3.1a" xref="S3.E1.m1.8.8.2.2.2.3.1.cmml">​</mo><mi id="S3.E1.m1.8.8.2.2.2.3.4" xref="S3.E1.m1.8.8.2.2.2.3.4.cmml">n</mi></mrow></msub><mo id="S3.E1.m1.8.8.2.2.3" xref="S3.E1.m1.8.8.2.2.3.cmml">&lt;</mo><msub id="S3.E1.m1.8.8.2.2.4" xref="S3.E1.m1.8.8.2.2.4.cmml"><mi id="S3.E1.m1.8.8.2.2.4.2" xref="S3.E1.m1.8.8.2.2.4.2.cmml">f</mi><mi id="S3.E1.m1.8.8.2.2.4.3" xref="S3.E1.m1.8.8.2.2.4.3.cmml">c</mi></msub><mo id="S3.E1.m1.8.8.2.2.5" xref="S3.E1.m1.8.8.2.2.5.cmml">&lt;</mo><msub id="S3.E1.m1.8.8.2.2.6" xref="S3.E1.m1.8.8.2.2.6.cmml"><mi id="S3.E1.m1.8.8.2.2.6.2" xref="S3.E1.m1.8.8.2.2.6.2.cmml">f</mi><mrow id="S3.E1.m1.8.8.2.2.6.3" xref="S3.E1.m1.8.8.2.2.6.3.cmml"><mi id="S3.E1.m1.8.8.2.2.6.3.2" xref="S3.E1.m1.8.8.2.2.6.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.8.8.2.2.6.3.1" xref="S3.E1.m1.8.8.2.2.6.3.1.cmml">​</mo><mi id="S3.E1.m1.8.8.2.2.6.3.3" xref="S3.E1.m1.8.8.2.2.6.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.8.8.2.2.6.3.1a" xref="S3.E1.m1.8.8.2.2.6.3.1.cmml">​</mo><mi id="S3.E1.m1.8.8.2.2.6.3.4" xref="S3.E1.m1.8.8.2.2.6.3.4.cmml">x</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.8b"><apply id="S3.E1.m1.8.8.3.cmml" xref="S3.E1.m1.8.8.2"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.3a.cmml" xref="S3.E1.m1.8.8.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.7.7.1.1.cmml" xref="S3.E1.m1.7.7.1.1"><eq id="S3.E1.m1.7.7.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.1"></eq><apply id="S3.E1.m1.7.7.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.2"><times id="S3.E1.m1.7.7.1.1.2.1.cmml" xref="S3.E1.m1.7.7.1.1.2.1"></times><apply id="S3.E1.m1.7.7.1.1.2.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.2.2.1.cmml" xref="S3.E1.m1.7.7.1.1.2.2">subscript</csymbol><apply id="S3.E1.m1.7.7.1.1.2.2.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2.2"><ci id="S3.E1.m1.7.7.1.1.2.2.2.1.cmml" xref="S3.E1.m1.7.7.1.1.2.2.2.1">^</ci><ci id="S3.E1.m1.7.7.1.1.2.2.2.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2.2.2">𝐹</ci></apply><apply id="S3.E1.m1.7.7.1.1.2.2.3.cmml" xref="S3.E1.m1.7.7.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.2.2.3.1.cmml" xref="S3.E1.m1.7.7.1.1.2.2.3">subscript</csymbol><ci id="S3.E1.m1.7.7.1.1.2.2.3.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2.3.2">𝑓</ci><ci id="S3.E1.m1.7.7.1.1.2.2.3.3.cmml" xref="S3.E1.m1.7.7.1.1.2.2.3.3">𝑐</ci></apply></apply><interval closure="open" id="S3.E1.m1.7.7.1.1.2.3.1.cmml" xref="S3.E1.m1.7.7.1.1.2.3.2"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝑢</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">𝑣</ci></interval></apply><apply id="S3.E1.m1.7.7.1.1.3.cmml" xref="S3.E1.m1.7.7.1.1.3"><times id="S3.E1.m1.7.7.1.1.3.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1"></times><ci id="S3.E1.m1.7.7.1.1.3.2.cmml" xref="S3.E1.m1.7.7.1.1.3.2">𝐹</ci><interval closure="open" id="S3.E1.m1.7.7.1.1.3.3.1.cmml" xref="S3.E1.m1.7.7.1.1.3.3.2"><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝑢</ci><ci id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">𝑣</ci></interval><apply id="S3.E1.m1.7.7.1.1.3.4.cmml" xref="S3.E1.m1.7.7.1.1.3.4"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.3.4.1.cmml" xref="S3.E1.m1.7.7.1.1.3.4">subscript</csymbol><ci id="S3.E1.m1.7.7.1.1.3.4.2.cmml" xref="S3.E1.m1.7.7.1.1.3.4.2">𝐻</ci><apply id="S3.E1.m1.7.7.1.1.3.4.3.cmml" xref="S3.E1.m1.7.7.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.3.4.3.1.cmml" xref="S3.E1.m1.7.7.1.1.3.4.3">subscript</csymbol><ci id="S3.E1.m1.7.7.1.1.3.4.3.2.cmml" xref="S3.E1.m1.7.7.1.1.3.4.3.2">𝑓</ci><ci id="S3.E1.m1.7.7.1.1.3.4.3.3.cmml" xref="S3.E1.m1.7.7.1.1.3.4.3.3">𝑐</ci></apply></apply><interval closure="open" id="S3.E1.m1.7.7.1.1.3.5.1.cmml" xref="S3.E1.m1.7.7.1.1.3.5.2"><ci id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5">𝑢</ci><ci id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6">𝑣</ci></interval></apply></apply><apply id="S3.E1.m1.8.8.2.2.cmml" xref="S3.E1.m1.8.8.2.2"><and id="S3.E1.m1.8.8.2.2a.cmml" xref="S3.E1.m1.8.8.2.2"></and><apply id="S3.E1.m1.8.8.2.2b.cmml" xref="S3.E1.m1.8.8.2.2"><lt id="S3.E1.m1.8.8.2.2.3.cmml" xref="S3.E1.m1.8.8.2.2.3"></lt><apply id="S3.E1.m1.8.8.2.2.2.cmml" xref="S3.E1.m1.8.8.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.2.2.2.1.cmml" xref="S3.E1.m1.8.8.2.2.2">subscript</csymbol><ci id="S3.E1.m1.8.8.2.2.2.2.cmml" xref="S3.E1.m1.8.8.2.2.2.2">𝑓</ci><apply id="S3.E1.m1.8.8.2.2.2.3.cmml" xref="S3.E1.m1.8.8.2.2.2.3"><times id="S3.E1.m1.8.8.2.2.2.3.1.cmml" xref="S3.E1.m1.8.8.2.2.2.3.1"></times><ci id="S3.E1.m1.8.8.2.2.2.3.2.cmml" xref="S3.E1.m1.8.8.2.2.2.3.2">𝑚</ci><ci id="S3.E1.m1.8.8.2.2.2.3.3.cmml" xref="S3.E1.m1.8.8.2.2.2.3.3">𝑖</ci><ci id="S3.E1.m1.8.8.2.2.2.3.4.cmml" xref="S3.E1.m1.8.8.2.2.2.3.4">𝑛</ci></apply></apply><apply id="S3.E1.m1.8.8.2.2.4.cmml" xref="S3.E1.m1.8.8.2.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.2.2.4.1.cmml" xref="S3.E1.m1.8.8.2.2.4">subscript</csymbol><ci id="S3.E1.m1.8.8.2.2.4.2.cmml" xref="S3.E1.m1.8.8.2.2.4.2">𝑓</ci><ci id="S3.E1.m1.8.8.2.2.4.3.cmml" xref="S3.E1.m1.8.8.2.2.4.3">𝑐</ci></apply></apply><apply id="S3.E1.m1.8.8.2.2c.cmml" xref="S3.E1.m1.8.8.2.2"><lt id="S3.E1.m1.8.8.2.2.5.cmml" xref="S3.E1.m1.8.8.2.2.5"></lt><share href="#S3.E1.m1.8.8.2.2.4.cmml" id="S3.E1.m1.8.8.2.2d.cmml" xref="S3.E1.m1.8.8.2.2"></share><apply id="S3.E1.m1.8.8.2.2.6.cmml" xref="S3.E1.m1.8.8.2.2.6"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.2.2.6.1.cmml" xref="S3.E1.m1.8.8.2.2.6">subscript</csymbol><ci id="S3.E1.m1.8.8.2.2.6.2.cmml" xref="S3.E1.m1.8.8.2.2.6.2">𝑓</ci><apply id="S3.E1.m1.8.8.2.2.6.3.cmml" xref="S3.E1.m1.8.8.2.2.6.3"><times id="S3.E1.m1.8.8.2.2.6.3.1.cmml" xref="S3.E1.m1.8.8.2.2.6.3.1"></times><ci id="S3.E1.m1.8.8.2.2.6.3.2.cmml" xref="S3.E1.m1.8.8.2.2.6.3.2">𝑚</ci><ci id="S3.E1.m1.8.8.2.2.6.3.3.cmml" xref="S3.E1.m1.8.8.2.2.6.3.3">𝑎</ci><ci id="S3.E1.m1.8.8.2.2.6.3.4.cmml" xref="S3.E1.m1.8.8.2.2.6.3.4">𝑥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.8c">\hat{F}_{f_{c}}(u,v)=F(u,v)H_{f_{c}}(u,v),f_{min}&lt;f_{c}&lt;f_{max}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="H_{f_{c}}(u,v)=e^{-\frac{u^{2}+v^{2}}{2f_{c}^{2}}}" display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.3" xref="S3.E2.m1.2.3.cmml"><mrow id="S3.E2.m1.2.3.2" xref="S3.E2.m1.2.3.2.cmml"><msub id="S3.E2.m1.2.3.2.2" xref="S3.E2.m1.2.3.2.2.cmml"><mi id="S3.E2.m1.2.3.2.2.2" xref="S3.E2.m1.2.3.2.2.2.cmml">H</mi><msub id="S3.E2.m1.2.3.2.2.3" xref="S3.E2.m1.2.3.2.2.3.cmml"><mi id="S3.E2.m1.2.3.2.2.3.2" xref="S3.E2.m1.2.3.2.2.3.2.cmml">f</mi><mi id="S3.E2.m1.2.3.2.2.3.3" xref="S3.E2.m1.2.3.2.2.3.3.cmml">c</mi></msub></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.3.2.1" xref="S3.E2.m1.2.3.2.1.cmml">​</mo><mrow id="S3.E2.m1.2.3.2.3.2" xref="S3.E2.m1.2.3.2.3.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.3.2.3.2.1" xref="S3.E2.m1.2.3.2.3.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">u</mi><mo id="S3.E2.m1.2.3.2.3.2.2" xref="S3.E2.m1.2.3.2.3.1.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">v</mi><mo stretchy="false" id="S3.E2.m1.2.3.2.3.2.3" xref="S3.E2.m1.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.3.1" xref="S3.E2.m1.2.3.1.cmml">=</mo><msup id="S3.E2.m1.2.3.3" xref="S3.E2.m1.2.3.3.cmml"><mi id="S3.E2.m1.2.3.3.2" xref="S3.E2.m1.2.3.3.2.cmml">e</mi><mrow id="S3.E2.m1.2.3.3.3" xref="S3.E2.m1.2.3.3.3.cmml"><mo id="S3.E2.m1.2.3.3.3a" xref="S3.E2.m1.2.3.3.3.cmml">−</mo><mfrac id="S3.E2.m1.2.3.3.3.2" xref="S3.E2.m1.2.3.3.3.2.cmml"><mrow id="S3.E2.m1.2.3.3.3.2.2" xref="S3.E2.m1.2.3.3.3.2.2.cmml"><msup id="S3.E2.m1.2.3.3.3.2.2.2" xref="S3.E2.m1.2.3.3.3.2.2.2.cmml"><mi id="S3.E2.m1.2.3.3.3.2.2.2.2" xref="S3.E2.m1.2.3.3.3.2.2.2.2.cmml">u</mi><mn id="S3.E2.m1.2.3.3.3.2.2.2.3" xref="S3.E2.m1.2.3.3.3.2.2.2.3.cmml">2</mn></msup><mo id="S3.E2.m1.2.3.3.3.2.2.1" xref="S3.E2.m1.2.3.3.3.2.2.1.cmml">+</mo><msup id="S3.E2.m1.2.3.3.3.2.2.3" xref="S3.E2.m1.2.3.3.3.2.2.3.cmml"><mi id="S3.E2.m1.2.3.3.3.2.2.3.2" xref="S3.E2.m1.2.3.3.3.2.2.3.2.cmml">v</mi><mn id="S3.E2.m1.2.3.3.3.2.2.3.3" xref="S3.E2.m1.2.3.3.3.2.2.3.3.cmml">2</mn></msup></mrow><mrow id="S3.E2.m1.2.3.3.3.2.3" xref="S3.E2.m1.2.3.3.3.2.3.cmml"><mn id="S3.E2.m1.2.3.3.3.2.3.2" xref="S3.E2.m1.2.3.3.3.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.3.3.3.2.3.1" xref="S3.E2.m1.2.3.3.3.2.3.1.cmml">​</mo><msubsup id="S3.E2.m1.2.3.3.3.2.3.3" xref="S3.E2.m1.2.3.3.3.2.3.3.cmml"><mi id="S3.E2.m1.2.3.3.3.2.3.3.2.2" xref="S3.E2.m1.2.3.3.3.2.3.3.2.2.cmml">f</mi><mi id="S3.E2.m1.2.3.3.3.2.3.3.2.3" xref="S3.E2.m1.2.3.3.3.2.3.3.2.3.cmml">c</mi><mn id="S3.E2.m1.2.3.3.3.2.3.3.3" xref="S3.E2.m1.2.3.3.3.2.3.3.3.cmml">2</mn></msubsup></mrow></mfrac></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.3.cmml" xref="S3.E2.m1.2.3"><eq id="S3.E2.m1.2.3.1.cmml" xref="S3.E2.m1.2.3.1"></eq><apply id="S3.E2.m1.2.3.2.cmml" xref="S3.E2.m1.2.3.2"><times id="S3.E2.m1.2.3.2.1.cmml" xref="S3.E2.m1.2.3.2.1"></times><apply id="S3.E2.m1.2.3.2.2.cmml" xref="S3.E2.m1.2.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.2.2.1.cmml" xref="S3.E2.m1.2.3.2.2">subscript</csymbol><ci id="S3.E2.m1.2.3.2.2.2.cmml" xref="S3.E2.m1.2.3.2.2.2">𝐻</ci><apply id="S3.E2.m1.2.3.2.2.3.cmml" xref="S3.E2.m1.2.3.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.2.2.3.1.cmml" xref="S3.E2.m1.2.3.2.2.3">subscript</csymbol><ci id="S3.E2.m1.2.3.2.2.3.2.cmml" xref="S3.E2.m1.2.3.2.2.3.2">𝑓</ci><ci id="S3.E2.m1.2.3.2.2.3.3.cmml" xref="S3.E2.m1.2.3.2.2.3.3">𝑐</ci></apply></apply><interval closure="open" id="S3.E2.m1.2.3.2.3.1.cmml" xref="S3.E2.m1.2.3.2.3.2"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑢</ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝑣</ci></interval></apply><apply id="S3.E2.m1.2.3.3.cmml" xref="S3.E2.m1.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.3.1.cmml" xref="S3.E2.m1.2.3.3">superscript</csymbol><ci id="S3.E2.m1.2.3.3.2.cmml" xref="S3.E2.m1.2.3.3.2">𝑒</ci><apply id="S3.E2.m1.2.3.3.3.cmml" xref="S3.E2.m1.2.3.3.3"><minus id="S3.E2.m1.2.3.3.3.1.cmml" xref="S3.E2.m1.2.3.3.3"></minus><apply id="S3.E2.m1.2.3.3.3.2.cmml" xref="S3.E2.m1.2.3.3.3.2"><divide id="S3.E2.m1.2.3.3.3.2.1.cmml" xref="S3.E2.m1.2.3.3.3.2"></divide><apply id="S3.E2.m1.2.3.3.3.2.2.cmml" xref="S3.E2.m1.2.3.3.3.2.2"><plus id="S3.E2.m1.2.3.3.3.2.2.1.cmml" xref="S3.E2.m1.2.3.3.3.2.2.1"></plus><apply id="S3.E2.m1.2.3.3.3.2.2.2.cmml" xref="S3.E2.m1.2.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.3.3.2.2.2.1.cmml" xref="S3.E2.m1.2.3.3.3.2.2.2">superscript</csymbol><ci id="S3.E2.m1.2.3.3.3.2.2.2.2.cmml" xref="S3.E2.m1.2.3.3.3.2.2.2.2">𝑢</ci><cn type="integer" id="S3.E2.m1.2.3.3.3.2.2.2.3.cmml" xref="S3.E2.m1.2.3.3.3.2.2.2.3">2</cn></apply><apply id="S3.E2.m1.2.3.3.3.2.2.3.cmml" xref="S3.E2.m1.2.3.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.3.3.2.2.3.1.cmml" xref="S3.E2.m1.2.3.3.3.2.2.3">superscript</csymbol><ci id="S3.E2.m1.2.3.3.3.2.2.3.2.cmml" xref="S3.E2.m1.2.3.3.3.2.2.3.2">𝑣</ci><cn type="integer" id="S3.E2.m1.2.3.3.3.2.2.3.3.cmml" xref="S3.E2.m1.2.3.3.3.2.2.3.3">2</cn></apply></apply><apply id="S3.E2.m1.2.3.3.3.2.3.cmml" xref="S3.E2.m1.2.3.3.3.2.3"><times id="S3.E2.m1.2.3.3.3.2.3.1.cmml" xref="S3.E2.m1.2.3.3.3.2.3.1"></times><cn type="integer" id="S3.E2.m1.2.3.3.3.2.3.2.cmml" xref="S3.E2.m1.2.3.3.3.2.3.2">2</cn><apply id="S3.E2.m1.2.3.3.3.2.3.3.cmml" xref="S3.E2.m1.2.3.3.3.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.3.3.2.3.3.1.cmml" xref="S3.E2.m1.2.3.3.3.2.3.3">superscript</csymbol><apply id="S3.E2.m1.2.3.3.3.2.3.3.2.cmml" xref="S3.E2.m1.2.3.3.3.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.3.3.2.3.3.2.1.cmml" xref="S3.E2.m1.2.3.3.3.2.3.3">subscript</csymbol><ci id="S3.E2.m1.2.3.3.3.2.3.3.2.2.cmml" xref="S3.E2.m1.2.3.3.3.2.3.3.2.2">𝑓</ci><ci id="S3.E2.m1.2.3.3.3.2.3.3.2.3.cmml" xref="S3.E2.m1.2.3.3.3.2.3.3.2.3">𝑐</ci></apply><cn type="integer" id="S3.E2.m1.2.3.3.3.2.3.3.3.cmml" xref="S3.E2.m1.2.3.3.3.2.3.3.3">2</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">H_{f_{c}}(u,v)=e^{-\frac{u^{2}+v^{2}}{2f_{c}^{2}}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.3" class="ltx_Math" alttext="I_{f_{c}}=f^{-1}\left[\hat{\mathcal{F}}_{f_{c}}(u,v)\right]" display="block"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><msub id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml"><mi id="S3.E3.m1.3.3.3.2" xref="S3.E3.m1.3.3.3.2.cmml">I</mi><msub id="S3.E3.m1.3.3.3.3" xref="S3.E3.m1.3.3.3.3.cmml"><mi id="S3.E3.m1.3.3.3.3.2" xref="S3.E3.m1.3.3.3.3.2.cmml">f</mi><mi id="S3.E3.m1.3.3.3.3.3" xref="S3.E3.m1.3.3.3.3.3.cmml">c</mi></msub></msub><mo id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.cmml"><msup id="S3.E3.m1.3.3.1.3" xref="S3.E3.m1.3.3.1.3.cmml"><mi id="S3.E3.m1.3.3.1.3.2" xref="S3.E3.m1.3.3.1.3.2.cmml">f</mi><mrow id="S3.E3.m1.3.3.1.3.3" xref="S3.E3.m1.3.3.1.3.3.cmml"><mo id="S3.E3.m1.3.3.1.3.3a" xref="S3.E3.m1.3.3.1.3.3.cmml">−</mo><mn id="S3.E3.m1.3.3.1.3.3.2" xref="S3.E3.m1.3.3.1.3.3.2.cmml">1</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.2" xref="S3.E3.m1.3.3.1.2.cmml">​</mo><mrow id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.2.cmml"><mo id="S3.E3.m1.3.3.1.1.1.2" xref="S3.E3.m1.3.3.1.1.2.1.cmml">[</mo><mrow id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml"><mover accent="true" id="S3.E3.m1.3.3.1.1.1.1.2.2" xref="S3.E3.m1.3.3.1.1.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.1.1.1.1.2.2.2" xref="S3.E3.m1.3.3.1.1.1.1.2.2.2.cmml">ℱ</mi><mo id="S3.E3.m1.3.3.1.1.1.1.2.2.1" xref="S3.E3.m1.3.3.1.1.1.1.2.2.1.cmml">^</mo></mover><msub id="S3.E3.m1.3.3.1.1.1.1.2.3" xref="S3.E3.m1.3.3.1.1.1.1.2.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.2.3.2" xref="S3.E3.m1.3.3.1.1.1.1.2.3.2.cmml">f</mi><mi id="S3.E3.m1.3.3.1.1.1.1.2.3.3" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3.cmml">c</mi></msub></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml">​</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.1.3.2.1" xref="S3.E3.m1.3.3.1.1.1.1.3.1.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">u</mi><mo id="S3.E3.m1.3.3.1.1.1.1.3.2.2" xref="S3.E3.m1.3.3.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">v</mi><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.1.3.2.3" xref="S3.E3.m1.3.3.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.3" xref="S3.E3.m1.3.3.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2"></eq><apply id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3">subscript</csymbol><ci id="S3.E3.m1.3.3.3.2.cmml" xref="S3.E3.m1.3.3.3.2">𝐼</ci><apply id="S3.E3.m1.3.3.3.3.cmml" xref="S3.E3.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3.3">subscript</csymbol><ci id="S3.E3.m1.3.3.3.3.2.cmml" xref="S3.E3.m1.3.3.3.3.2">𝑓</ci><ci id="S3.E3.m1.3.3.3.3.3.cmml" xref="S3.E3.m1.3.3.3.3.3">𝑐</ci></apply></apply><apply id="S3.E3.m1.3.3.1.cmml" xref="S3.E3.m1.3.3.1"><times id="S3.E3.m1.3.3.1.2.cmml" xref="S3.E3.m1.3.3.1.2"></times><apply id="S3.E3.m1.3.3.1.3.cmml" xref="S3.E3.m1.3.3.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.3.1.cmml" xref="S3.E3.m1.3.3.1.3">superscript</csymbol><ci id="S3.E3.m1.3.3.1.3.2.cmml" xref="S3.E3.m1.3.3.1.3.2">𝑓</ci><apply id="S3.E3.m1.3.3.1.3.3.cmml" xref="S3.E3.m1.3.3.1.3.3"><minus id="S3.E3.m1.3.3.1.3.3.1.cmml" xref="S3.E3.m1.3.3.1.3.3"></minus><cn type="integer" id="S3.E3.m1.3.3.1.3.3.2.cmml" xref="S3.E3.m1.3.3.1.3.3.2">1</cn></apply></apply><apply id="S3.E3.m1.3.3.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.3.3.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1"></times><apply id="S3.E3.m1.3.3.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2">subscript</csymbol><apply id="S3.E3.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2"><ci id="S3.E3.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2.1">^</ci><ci id="S3.E3.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2.2">ℱ</ci></apply><apply id="S3.E3.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3.2">𝑓</ci><ci id="S3.E3.m1.3.3.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.3.3">𝑐</ci></apply></apply><interval closure="open" id="S3.E3.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝑢</ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝑣</ci></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">I_{f_{c}}=f^{-1}\left[\hat{\mathcal{F}}_{f_{c}}(u,v)\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.10" class="ltx_p">where <math id="S3.SS2.p3.1.m1.2" class="ltx_Math" alttext="F(u,v)" display="inline"><semantics id="S3.SS2.p3.1.m1.2a"><mrow id="S3.SS2.p3.1.m1.2.3" xref="S3.SS2.p3.1.m1.2.3.cmml"><mi id="S3.SS2.p3.1.m1.2.3.2" xref="S3.SS2.p3.1.m1.2.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.2.3.1" xref="S3.SS2.p3.1.m1.2.3.1.cmml">​</mo><mrow id="S3.SS2.p3.1.m1.2.3.3.2" xref="S3.SS2.p3.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p3.1.m1.2.3.3.2.1" xref="S3.SS2.p3.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">u</mi><mo id="S3.SS2.p3.1.m1.2.3.3.2.2" xref="S3.SS2.p3.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS2.p3.1.m1.2.2" xref="S3.SS2.p3.1.m1.2.2.cmml">v</mi><mo stretchy="false" id="S3.SS2.p3.1.m1.2.3.3.2.3" xref="S3.SS2.p3.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.2b"><apply id="S3.SS2.p3.1.m1.2.3.cmml" xref="S3.SS2.p3.1.m1.2.3"><times id="S3.SS2.p3.1.m1.2.3.1.cmml" xref="S3.SS2.p3.1.m1.2.3.1"></times><ci id="S3.SS2.p3.1.m1.2.3.2.cmml" xref="S3.SS2.p3.1.m1.2.3.2">𝐹</ci><interval closure="open" id="S3.SS2.p3.1.m1.2.3.3.1.cmml" xref="S3.SS2.p3.1.m1.2.3.3.2"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑢</ci><ci id="S3.SS2.p3.1.m1.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2">𝑣</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.2c">F(u,v)</annotation></semantics></math> is the Fourier transform of the full-spectrum image <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">I</annotation></semantics></math> and <math id="S3.SS2.p3.3.m3.2" class="ltx_Math" alttext="u,v" display="inline"><semantics id="S3.SS2.p3.3.m3.2a"><mrow id="S3.SS2.p3.3.m3.2.3.2" xref="S3.SS2.p3.3.m3.2.3.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">u</mi><mo id="S3.SS2.p3.3.m3.2.3.2.1" xref="S3.SS2.p3.3.m3.2.3.1.cmml">,</mo><mi id="S3.SS2.p3.3.m3.2.2" xref="S3.SS2.p3.3.m3.2.2.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.2b"><list id="S3.SS2.p3.3.m3.2.3.1.cmml" xref="S3.SS2.p3.3.m3.2.3.2"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝑢</ci><ci id="S3.SS2.p3.3.m3.2.2.cmml" xref="S3.SS2.p3.3.m3.2.2">𝑣</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.2c">u,v</annotation></semantics></math> are representative of a particular spatial frequency contained in the spatial domain of image <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">I</annotation></semantics></math>. For instance, <math id="S3.SS2.p3.5.m5.2" class="ltx_Math" alttext="F(0,0)" display="inline"><semantics id="S3.SS2.p3.5.m5.2a"><mrow id="S3.SS2.p3.5.m5.2.3" xref="S3.SS2.p3.5.m5.2.3.cmml"><mi id="S3.SS2.p3.5.m5.2.3.2" xref="S3.SS2.p3.5.m5.2.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.2.3.1" xref="S3.SS2.p3.5.m5.2.3.1.cmml">​</mo><mrow id="S3.SS2.p3.5.m5.2.3.3.2" xref="S3.SS2.p3.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p3.5.m5.2.3.3.2.1" xref="S3.SS2.p3.5.m5.2.3.3.1.cmml">(</mo><mn id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">0</mn><mo id="S3.SS2.p3.5.m5.2.3.3.2.2" xref="S3.SS2.p3.5.m5.2.3.3.1.cmml">,</mo><mn id="S3.SS2.p3.5.m5.2.2" xref="S3.SS2.p3.5.m5.2.2.cmml">0</mn><mo stretchy="false" id="S3.SS2.p3.5.m5.2.3.3.2.3" xref="S3.SS2.p3.5.m5.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.2b"><apply id="S3.SS2.p3.5.m5.2.3.cmml" xref="S3.SS2.p3.5.m5.2.3"><times id="S3.SS2.p3.5.m5.2.3.1.cmml" xref="S3.SS2.p3.5.m5.2.3.1"></times><ci id="S3.SS2.p3.5.m5.2.3.2.cmml" xref="S3.SS2.p3.5.m5.2.3.2">𝐹</ci><interval closure="open" id="S3.SS2.p3.5.m5.2.3.3.1.cmml" xref="S3.SS2.p3.5.m5.2.3.3.2"><cn type="integer" id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">0</cn><cn type="integer" id="S3.SS2.p3.5.m5.2.2.cmml" xref="S3.SS2.p3.5.m5.2.2">0</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.2c">F(0,0)</annotation></semantics></math> represents the DC-component of the image which corresponds to the average brightness. <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="H_{f_{c}}" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><msub id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">H</mi><msub id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml"><mi id="S3.SS2.p3.6.m6.1.1.3.2" xref="S3.SS2.p3.6.m6.1.1.3.2.cmml">f</mi><mi id="S3.SS2.p3.6.m6.1.1.3.3" xref="S3.SS2.p3.6.m6.1.1.3.3.cmml">c</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">𝐻</ci><apply id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.3.1.cmml" xref="S3.SS2.p3.6.m6.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.3.2.cmml" xref="S3.SS2.p3.6.m6.1.1.3.2">𝑓</ci><ci id="S3.SS2.p3.6.m6.1.1.3.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">H_{f_{c}}</annotation></semantics></math> is the 2D Gaussian spatial filter with cut-off frequency of <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="f_{c}" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><msub id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">f</mi><mi id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2">𝑓</ci><ci id="S3.SS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">f_{c}</annotation></semantics></math> ranging from <math id="S3.SS2.p3.8.m8.1" class="ltx_Math" alttext="f_{min}" display="inline"><semantics id="S3.SS2.p3.8.m8.1a"><msub id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml"><mi id="S3.SS2.p3.8.m8.1.1.2" xref="S3.SS2.p3.8.m8.1.1.2.cmml">f</mi><mrow id="S3.SS2.p3.8.m8.1.1.3" xref="S3.SS2.p3.8.m8.1.1.3.cmml"><mi id="S3.SS2.p3.8.m8.1.1.3.2" xref="S3.SS2.p3.8.m8.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.8.m8.1.1.3.1" xref="S3.SS2.p3.8.m8.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.8.m8.1.1.3.3" xref="S3.SS2.p3.8.m8.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.8.m8.1.1.3.1a" xref="S3.SS2.p3.8.m8.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.8.m8.1.1.3.4" xref="S3.SS2.p3.8.m8.1.1.3.4.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><apply id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m8.1.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">subscript</csymbol><ci id="S3.SS2.p3.8.m8.1.1.2.cmml" xref="S3.SS2.p3.8.m8.1.1.2">𝑓</ci><apply id="S3.SS2.p3.8.m8.1.1.3.cmml" xref="S3.SS2.p3.8.m8.1.1.3"><times id="S3.SS2.p3.8.m8.1.1.3.1.cmml" xref="S3.SS2.p3.8.m8.1.1.3.1"></times><ci id="S3.SS2.p3.8.m8.1.1.3.2.cmml" xref="S3.SS2.p3.8.m8.1.1.3.2">𝑚</ci><ci id="S3.SS2.p3.8.m8.1.1.3.3.cmml" xref="S3.SS2.p3.8.m8.1.1.3.3">𝑖</ci><ci id="S3.SS2.p3.8.m8.1.1.3.4.cmml" xref="S3.SS2.p3.8.m8.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">f_{min}</annotation></semantics></math> to <math id="S3.SS2.p3.9.m9.1" class="ltx_Math" alttext="f_{max}" display="inline"><semantics id="S3.SS2.p3.9.m9.1a"><msub id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml"><mi id="S3.SS2.p3.9.m9.1.1.2" xref="S3.SS2.p3.9.m9.1.1.2.cmml">f</mi><mrow id="S3.SS2.p3.9.m9.1.1.3" xref="S3.SS2.p3.9.m9.1.1.3.cmml"><mi id="S3.SS2.p3.9.m9.1.1.3.2" xref="S3.SS2.p3.9.m9.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.9.m9.1.1.3.1" xref="S3.SS2.p3.9.m9.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.9.m9.1.1.3.3" xref="S3.SS2.p3.9.m9.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.9.m9.1.1.3.1a" xref="S3.SS2.p3.9.m9.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.9.m9.1.1.3.4" xref="S3.SS2.p3.9.m9.1.1.3.4.cmml">x</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><apply id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m9.1.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.p3.9.m9.1.1.2.cmml" xref="S3.SS2.p3.9.m9.1.1.2">𝑓</ci><apply id="S3.SS2.p3.9.m9.1.1.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3"><times id="S3.SS2.p3.9.m9.1.1.3.1.cmml" xref="S3.SS2.p3.9.m9.1.1.3.1"></times><ci id="S3.SS2.p3.9.m9.1.1.3.2.cmml" xref="S3.SS2.p3.9.m9.1.1.3.2">𝑚</ci><ci id="S3.SS2.p3.9.m9.1.1.3.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3.3">𝑎</ci><ci id="S3.SS2.p3.9.m9.1.1.3.4.cmml" xref="S3.SS2.p3.9.m9.1.1.3.4">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">f_{max}</annotation></semantics></math> which is defined systematically between the center and the edge of the Fourier image, <math id="S3.SS2.p3.10.m10.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS2.p3.10.m10.1a"><mi id="S3.SS2.p3.10.m10.1.1" xref="S3.SS2.p3.10.m10.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m10.1b"><ci id="S3.SS2.p3.10.m10.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m10.1c">F</annotation></semantics></math> , as follows:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.2" class="ltx_Math" alttext="f_{c}=c.\frac{w}{20}" display="block"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.2.1" xref="S3.E4.m1.2.2.2.cmml"><mrow id="S3.E4.m1.2.2.1.1" xref="S3.E4.m1.2.2.1.1.cmml"><msub id="S3.E4.m1.2.2.1.1.2" xref="S3.E4.m1.2.2.1.1.2.cmml"><mi id="S3.E4.m1.2.2.1.1.2.2" xref="S3.E4.m1.2.2.1.1.2.2.cmml">f</mi><mi id="S3.E4.m1.2.2.1.1.2.3" xref="S3.E4.m1.2.2.1.1.2.3.cmml">c</mi></msub><mo id="S3.E4.m1.2.2.1.1.1" xref="S3.E4.m1.2.2.1.1.1.cmml">=</mo><mi id="S3.E4.m1.2.2.1.1.3" xref="S3.E4.m1.2.2.1.1.3.cmml">c</mi></mrow><mo lspace="0em" rspace="0.167em" id="S3.E4.m1.2.2.1.2" xref="S3.E4.m1.2.2.2a.cmml">.</mo><mfrac id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><mi id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">w</mi><mn id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml">20</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2a.cmml" xref="S3.E4.m1.2.2.1.2">formulae-sequence</csymbol><apply id="S3.E4.m1.2.2.1.1.cmml" xref="S3.E4.m1.2.2.1.1"><eq id="S3.E4.m1.2.2.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1"></eq><apply id="S3.E4.m1.2.2.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.2.1.cmml" xref="S3.E4.m1.2.2.1.1.2">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.2.2.cmml" xref="S3.E4.m1.2.2.1.1.2.2">𝑓</ci><ci id="S3.E4.m1.2.2.1.1.2.3.cmml" xref="S3.E4.m1.2.2.1.1.2.3">𝑐</ci></apply><ci id="S3.E4.m1.2.2.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.3">𝑐</ci></apply><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><divide id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1"></divide><ci id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2">𝑤</ci><cn type="integer" id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3">20</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">f_{c}=c.\frac{w}{20}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.11" class="ltx_p">In this way, for a given image <math id="S3.SS2.p3.11.m1.1" class="ltx_Math" alttext="I_{w\times h}" display="inline"><semantics id="S3.SS2.p3.11.m1.1a"><msub id="S3.SS2.p3.11.m1.1.1" xref="S3.SS2.p3.11.m1.1.1.cmml"><mi id="S3.SS2.p3.11.m1.1.1.2" xref="S3.SS2.p3.11.m1.1.1.2.cmml">I</mi><mrow id="S3.SS2.p3.11.m1.1.1.3" xref="S3.SS2.p3.11.m1.1.1.3.cmml"><mi id="S3.SS2.p3.11.m1.1.1.3.2" xref="S3.SS2.p3.11.m1.1.1.3.2.cmml">w</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.11.m1.1.1.3.1" xref="S3.SS2.p3.11.m1.1.1.3.1.cmml">×</mo><mi id="S3.SS2.p3.11.m1.1.1.3.3" xref="S3.SS2.p3.11.m1.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m1.1b"><apply id="S3.SS2.p3.11.m1.1.1.cmml" xref="S3.SS2.p3.11.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.11.m1.1.1.1.cmml" xref="S3.SS2.p3.11.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.11.m1.1.1.2.cmml" xref="S3.SS2.p3.11.m1.1.1.2">𝐼</ci><apply id="S3.SS2.p3.11.m1.1.1.3.cmml" xref="S3.SS2.p3.11.m1.1.1.3"><times id="S3.SS2.p3.11.m1.1.1.3.1.cmml" xref="S3.SS2.p3.11.m1.1.1.3.1"></times><ci id="S3.SS2.p3.11.m1.1.1.3.2.cmml" xref="S3.SS2.p3.11.m1.1.1.3.2">𝑤</ci><ci id="S3.SS2.p3.11.m1.1.1.3.3.cmml" xref="S3.SS2.p3.11.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m1.1c">I_{w\times h}</annotation></semantics></math>:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.4" class="ltx_Math" alttext="f_{min}=\frac{S}{20},f_{max}=S,S=max(w,h)" display="block"><semantics id="S3.E5.m1.4a"><mrow id="S3.E5.m1.4.4.2" xref="S3.E5.m1.4.4.3.cmml"><mrow id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.1.cmml"><msub id="S3.E5.m1.3.3.1.1.2" xref="S3.E5.m1.3.3.1.1.2.cmml"><mi id="S3.E5.m1.3.3.1.1.2.2" xref="S3.E5.m1.3.3.1.1.2.2.cmml">f</mi><mrow id="S3.E5.m1.3.3.1.1.2.3" xref="S3.E5.m1.3.3.1.1.2.3.cmml"><mi id="S3.E5.m1.3.3.1.1.2.3.2" xref="S3.E5.m1.3.3.1.1.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.2.3.1" xref="S3.E5.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.3.3.1.1.2.3.3" xref="S3.E5.m1.3.3.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.2.3.1a" xref="S3.E5.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.3.3.1.1.2.3.4" xref="S3.E5.m1.3.3.1.1.2.3.4.cmml">n</mi></mrow></msub><mo id="S3.E5.m1.3.3.1.1.1" xref="S3.E5.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S3.E5.m1.3.3.1.1.3" xref="S3.E5.m1.3.3.1.1.3.cmml"><mi id="S3.E5.m1.3.3.1.1.3.2" xref="S3.E5.m1.3.3.1.1.3.2.cmml">S</mi><mn id="S3.E5.m1.3.3.1.1.3.3" xref="S3.E5.m1.3.3.1.1.3.3.cmml">20</mn></mfrac></mrow><mo id="S3.E5.m1.4.4.2.3" xref="S3.E5.m1.4.4.3a.cmml">,</mo><mrow id="S3.E5.m1.4.4.2.2.2" xref="S3.E5.m1.4.4.2.2.3.cmml"><mrow id="S3.E5.m1.4.4.2.2.1.1" xref="S3.E5.m1.4.4.2.2.1.1.cmml"><msub id="S3.E5.m1.4.4.2.2.1.1.2" xref="S3.E5.m1.4.4.2.2.1.1.2.cmml"><mi id="S3.E5.m1.4.4.2.2.1.1.2.2" xref="S3.E5.m1.4.4.2.2.1.1.2.2.cmml">f</mi><mrow id="S3.E5.m1.4.4.2.2.1.1.2.3" xref="S3.E5.m1.4.4.2.2.1.1.2.3.cmml"><mi id="S3.E5.m1.4.4.2.2.1.1.2.3.2" xref="S3.E5.m1.4.4.2.2.1.1.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.2.2.1.1.2.3.1" xref="S3.E5.m1.4.4.2.2.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.4.4.2.2.1.1.2.3.3" xref="S3.E5.m1.4.4.2.2.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.2.2.1.1.2.3.1a" xref="S3.E5.m1.4.4.2.2.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.4.4.2.2.1.1.2.3.4" xref="S3.E5.m1.4.4.2.2.1.1.2.3.4.cmml">x</mi></mrow></msub><mo id="S3.E5.m1.4.4.2.2.1.1.1" xref="S3.E5.m1.4.4.2.2.1.1.1.cmml">=</mo><mi id="S3.E5.m1.4.4.2.2.1.1.3" xref="S3.E5.m1.4.4.2.2.1.1.3.cmml">S</mi></mrow><mo id="S3.E5.m1.4.4.2.2.2.3" xref="S3.E5.m1.4.4.2.2.3a.cmml">,</mo><mrow id="S3.E5.m1.4.4.2.2.2.2" xref="S3.E5.m1.4.4.2.2.2.2.cmml"><mi id="S3.E5.m1.4.4.2.2.2.2.2" xref="S3.E5.m1.4.4.2.2.2.2.2.cmml">S</mi><mo id="S3.E5.m1.4.4.2.2.2.2.1" xref="S3.E5.m1.4.4.2.2.2.2.1.cmml">=</mo><mrow id="S3.E5.m1.4.4.2.2.2.2.3" xref="S3.E5.m1.4.4.2.2.2.2.3.cmml"><mi id="S3.E5.m1.4.4.2.2.2.2.3.2" xref="S3.E5.m1.4.4.2.2.2.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.2.2.2.2.3.1" xref="S3.E5.m1.4.4.2.2.2.2.3.1.cmml">​</mo><mi id="S3.E5.m1.4.4.2.2.2.2.3.3" xref="S3.E5.m1.4.4.2.2.2.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.2.2.2.2.3.1a" xref="S3.E5.m1.4.4.2.2.2.2.3.1.cmml">​</mo><mi id="S3.E5.m1.4.4.2.2.2.2.3.4" xref="S3.E5.m1.4.4.2.2.2.2.3.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.2.2.2.2.3.1b" xref="S3.E5.m1.4.4.2.2.2.2.3.1.cmml">​</mo><mrow id="S3.E5.m1.4.4.2.2.2.2.3.5.2" xref="S3.E5.m1.4.4.2.2.2.2.3.5.1.cmml"><mo stretchy="false" id="S3.E5.m1.4.4.2.2.2.2.3.5.2.1" xref="S3.E5.m1.4.4.2.2.2.2.3.5.1.cmml">(</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">w</mi><mo id="S3.E5.m1.4.4.2.2.2.2.3.5.2.2" xref="S3.E5.m1.4.4.2.2.2.2.3.5.1.cmml">,</mo><mi id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml">h</mi><mo stretchy="false" id="S3.E5.m1.4.4.2.2.2.2.3.5.2.3" xref="S3.E5.m1.4.4.2.2.2.2.3.5.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.4b"><apply id="S3.E5.m1.4.4.3.cmml" xref="S3.E5.m1.4.4.2"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.3a.cmml" xref="S3.E5.m1.4.4.2.3">formulae-sequence</csymbol><apply id="S3.E5.m1.3.3.1.1.cmml" xref="S3.E5.m1.3.3.1.1"><eq id="S3.E5.m1.3.3.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1"></eq><apply id="S3.E5.m1.3.3.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.1.cmml" xref="S3.E5.m1.3.3.1.1.2">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.2.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2">𝑓</ci><apply id="S3.E5.m1.3.3.1.1.2.3.cmml" xref="S3.E5.m1.3.3.1.1.2.3"><times id="S3.E5.m1.3.3.1.1.2.3.1.cmml" xref="S3.E5.m1.3.3.1.1.2.3.1"></times><ci id="S3.E5.m1.3.3.1.1.2.3.2.cmml" xref="S3.E5.m1.3.3.1.1.2.3.2">𝑚</ci><ci id="S3.E5.m1.3.3.1.1.2.3.3.cmml" xref="S3.E5.m1.3.3.1.1.2.3.3">𝑖</ci><ci id="S3.E5.m1.3.3.1.1.2.3.4.cmml" xref="S3.E5.m1.3.3.1.1.2.3.4">𝑛</ci></apply></apply><apply id="S3.E5.m1.3.3.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.3"><divide id="S3.E5.m1.3.3.1.1.3.1.cmml" xref="S3.E5.m1.3.3.1.1.3"></divide><ci id="S3.E5.m1.3.3.1.1.3.2.cmml" xref="S3.E5.m1.3.3.1.1.3.2">𝑆</ci><cn type="integer" id="S3.E5.m1.3.3.1.1.3.3.cmml" xref="S3.E5.m1.3.3.1.1.3.3">20</cn></apply></apply><apply id="S3.E5.m1.4.4.2.2.3.cmml" xref="S3.E5.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.2.2.3a.cmml" xref="S3.E5.m1.4.4.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E5.m1.4.4.2.2.1.1.cmml" xref="S3.E5.m1.4.4.2.2.1.1"><eq id="S3.E5.m1.4.4.2.2.1.1.1.cmml" xref="S3.E5.m1.4.4.2.2.1.1.1"></eq><apply id="S3.E5.m1.4.4.2.2.1.1.2.cmml" xref="S3.E5.m1.4.4.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.2.2.1.1.2.1.cmml" xref="S3.E5.m1.4.4.2.2.1.1.2">subscript</csymbol><ci id="S3.E5.m1.4.4.2.2.1.1.2.2.cmml" xref="S3.E5.m1.4.4.2.2.1.1.2.2">𝑓</ci><apply id="S3.E5.m1.4.4.2.2.1.1.2.3.cmml" xref="S3.E5.m1.4.4.2.2.1.1.2.3"><times id="S3.E5.m1.4.4.2.2.1.1.2.3.1.cmml" xref="S3.E5.m1.4.4.2.2.1.1.2.3.1"></times><ci id="S3.E5.m1.4.4.2.2.1.1.2.3.2.cmml" xref="S3.E5.m1.4.4.2.2.1.1.2.3.2">𝑚</ci><ci id="S3.E5.m1.4.4.2.2.1.1.2.3.3.cmml" xref="S3.E5.m1.4.4.2.2.1.1.2.3.3">𝑎</ci><ci id="S3.E5.m1.4.4.2.2.1.1.2.3.4.cmml" xref="S3.E5.m1.4.4.2.2.1.1.2.3.4">𝑥</ci></apply></apply><ci id="S3.E5.m1.4.4.2.2.1.1.3.cmml" xref="S3.E5.m1.4.4.2.2.1.1.3">𝑆</ci></apply><apply id="S3.E5.m1.4.4.2.2.2.2.cmml" xref="S3.E5.m1.4.4.2.2.2.2"><eq id="S3.E5.m1.4.4.2.2.2.2.1.cmml" xref="S3.E5.m1.4.4.2.2.2.2.1"></eq><ci id="S3.E5.m1.4.4.2.2.2.2.2.cmml" xref="S3.E5.m1.4.4.2.2.2.2.2">𝑆</ci><apply id="S3.E5.m1.4.4.2.2.2.2.3.cmml" xref="S3.E5.m1.4.4.2.2.2.2.3"><times id="S3.E5.m1.4.4.2.2.2.2.3.1.cmml" xref="S3.E5.m1.4.4.2.2.2.2.3.1"></times><ci id="S3.E5.m1.4.4.2.2.2.2.3.2.cmml" xref="S3.E5.m1.4.4.2.2.2.2.3.2">𝑚</ci><ci id="S3.E5.m1.4.4.2.2.2.2.3.3.cmml" xref="S3.E5.m1.4.4.2.2.2.2.3.3">𝑎</ci><ci id="S3.E5.m1.4.4.2.2.2.2.3.4.cmml" xref="S3.E5.m1.4.4.2.2.2.2.3.4">𝑥</ci><interval closure="open" id="S3.E5.m1.4.4.2.2.2.2.3.5.1.cmml" xref="S3.E5.m1.4.4.2.2.2.2.3.5.2"><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝑤</ci><ci id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2">ℎ</ci></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.4c">f_{min}=\frac{S}{20},f_{max}=S,S=max(w,h)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.13" class="ltx_p">By doing so, we systematically create 20 image databases from the PASCAL VOC2007 database in twenty-scale resolutions, namely PASCAL VOC2007- <math id="S3.SS2.p3.12.m1.1" class="ltx_Math" alttext="R_{1}" display="inline"><semantics id="S3.SS2.p3.12.m1.1a"><msub id="S3.SS2.p3.12.m1.1.1" xref="S3.SS2.p3.12.m1.1.1.cmml"><mi id="S3.SS2.p3.12.m1.1.1.2" xref="S3.SS2.p3.12.m1.1.1.2.cmml">R</mi><mn id="S3.SS2.p3.12.m1.1.1.3" xref="S3.SS2.p3.12.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m1.1b"><apply id="S3.SS2.p3.12.m1.1.1.cmml" xref="S3.SS2.p3.12.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.12.m1.1.1.1.cmml" xref="S3.SS2.p3.12.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.12.m1.1.1.2.cmml" xref="S3.SS2.p3.12.m1.1.1.2">𝑅</ci><cn type="integer" id="S3.SS2.p3.12.m1.1.1.3.cmml" xref="S3.SS2.p3.12.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m1.1c">R_{1}</annotation></semantics></math>, . . . , PASCAL VOC2007- <math id="S3.SS2.p3.13.m2.1" class="ltx_Math" alttext="R_{20}" display="inline"><semantics id="S3.SS2.p3.13.m2.1a"><msub id="S3.SS2.p3.13.m2.1.1" xref="S3.SS2.p3.13.m2.1.1.cmml"><mi id="S3.SS2.p3.13.m2.1.1.2" xref="S3.SS2.p3.13.m2.1.1.2.cmml">R</mi><mn id="S3.SS2.p3.13.m2.1.1.3" xref="S3.SS2.p3.13.m2.1.1.3.cmml">20</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.13.m2.1b"><apply id="S3.SS2.p3.13.m2.1.1.cmml" xref="S3.SS2.p3.13.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.13.m2.1.1.1.cmml" xref="S3.SS2.p3.13.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.13.m2.1.1.2.cmml" xref="S3.SS2.p3.13.m2.1.1.2">𝑅</ci><cn type="integer" id="S3.SS2.p3.13.m2.1.1.3.cmml" xref="S3.SS2.p3.13.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.13.m2.1c">R_{20}</annotation></semantics></math>.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2301.09667/assets/figures/fig10.jpg" id="S3.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="287" height="157" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The performance of multi-resolution Faster- RCNN obtained from the combination of 5 models on 5 resolution levels (<math id="S3.F1.4.m1.4" class="ltx_Math" alttext="R_{5},R_{10},R_{18},R_{20}" display="inline"><semantics id="S3.F1.4.m1.4b"><mrow id="S3.F1.4.m1.4.4.4" xref="S3.F1.4.m1.4.4.5.cmml"><msub id="S3.F1.4.m1.1.1.1.1" xref="S3.F1.4.m1.1.1.1.1.cmml"><mi id="S3.F1.4.m1.1.1.1.1.2" xref="S3.F1.4.m1.1.1.1.1.2.cmml">R</mi><mn id="S3.F1.4.m1.1.1.1.1.3" xref="S3.F1.4.m1.1.1.1.1.3.cmml">5</mn></msub><mo id="S3.F1.4.m1.4.4.4.5" xref="S3.F1.4.m1.4.4.5.cmml">,</mo><msub id="S3.F1.4.m1.2.2.2.2" xref="S3.F1.4.m1.2.2.2.2.cmml"><mi id="S3.F1.4.m1.2.2.2.2.2" xref="S3.F1.4.m1.2.2.2.2.2.cmml">R</mi><mn id="S3.F1.4.m1.2.2.2.2.3" xref="S3.F1.4.m1.2.2.2.2.3.cmml">10</mn></msub><mo id="S3.F1.4.m1.4.4.4.6" xref="S3.F1.4.m1.4.4.5.cmml">,</mo><msub id="S3.F1.4.m1.3.3.3.3" xref="S3.F1.4.m1.3.3.3.3.cmml"><mi id="S3.F1.4.m1.3.3.3.3.2" xref="S3.F1.4.m1.3.3.3.3.2.cmml">R</mi><mn id="S3.F1.4.m1.3.3.3.3.3" xref="S3.F1.4.m1.3.3.3.3.3.cmml">18</mn></msub><mo id="S3.F1.4.m1.4.4.4.7" xref="S3.F1.4.m1.4.4.5.cmml">,</mo><msub id="S3.F1.4.m1.4.4.4.4" xref="S3.F1.4.m1.4.4.4.4.cmml"><mi id="S3.F1.4.m1.4.4.4.4.2" xref="S3.F1.4.m1.4.4.4.4.2.cmml">R</mi><mn id="S3.F1.4.m1.4.4.4.4.3" xref="S3.F1.4.m1.4.4.4.4.3.cmml">20</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.F1.4.m1.4c"><list id="S3.F1.4.m1.4.4.5.cmml" xref="S3.F1.4.m1.4.4.4"><apply id="S3.F1.4.m1.1.1.1.1.cmml" xref="S3.F1.4.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.F1.4.m1.1.1.1.1.1.cmml" xref="S3.F1.4.m1.1.1.1.1">subscript</csymbol><ci id="S3.F1.4.m1.1.1.1.1.2.cmml" xref="S3.F1.4.m1.1.1.1.1.2">𝑅</ci><cn type="integer" id="S3.F1.4.m1.1.1.1.1.3.cmml" xref="S3.F1.4.m1.1.1.1.1.3">5</cn></apply><apply id="S3.F1.4.m1.2.2.2.2.cmml" xref="S3.F1.4.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.F1.4.m1.2.2.2.2.1.cmml" xref="S3.F1.4.m1.2.2.2.2">subscript</csymbol><ci id="S3.F1.4.m1.2.2.2.2.2.cmml" xref="S3.F1.4.m1.2.2.2.2.2">𝑅</ci><cn type="integer" id="S3.F1.4.m1.2.2.2.2.3.cmml" xref="S3.F1.4.m1.2.2.2.2.3">10</cn></apply><apply id="S3.F1.4.m1.3.3.3.3.cmml" xref="S3.F1.4.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.F1.4.m1.3.3.3.3.1.cmml" xref="S3.F1.4.m1.3.3.3.3">subscript</csymbol><ci id="S3.F1.4.m1.3.3.3.3.2.cmml" xref="S3.F1.4.m1.3.3.3.3.2">𝑅</ci><cn type="integer" id="S3.F1.4.m1.3.3.3.3.3.cmml" xref="S3.F1.4.m1.3.3.3.3.3">18</cn></apply><apply id="S3.F1.4.m1.4.4.4.4.cmml" xref="S3.F1.4.m1.4.4.4.4"><csymbol cd="ambiguous" id="S3.F1.4.m1.4.4.4.4.1.cmml" xref="S3.F1.4.m1.4.4.4.4">subscript</csymbol><ci id="S3.F1.4.m1.4.4.4.4.2.cmml" xref="S3.F1.4.m1.4.4.4.4.2">𝑅</ci><cn type="integer" id="S3.F1.4.m1.4.4.4.4.3.cmml" xref="S3.F1.4.m1.4.4.4.4.3">20</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.4.m1.4d">R_{5},R_{10},R_{18},R_{20}</annotation></semantics></math>, and Full-spectrum). All models have been evaluated on multi-resolution test databases (<math id="S3.F1.5.m2.3" class="ltx_Math" alttext="R_{1},...,R_{20}" display="inline"><semantics id="S3.F1.5.m2.3b"><mrow id="S3.F1.5.m2.3.3.2" xref="S3.F1.5.m2.3.3.3.cmml"><msub id="S3.F1.5.m2.2.2.1.1" xref="S3.F1.5.m2.2.2.1.1.cmml"><mi id="S3.F1.5.m2.2.2.1.1.2" xref="S3.F1.5.m2.2.2.1.1.2.cmml">R</mi><mn id="S3.F1.5.m2.2.2.1.1.3" xref="S3.F1.5.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.F1.5.m2.3.3.2.3" xref="S3.F1.5.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.F1.5.m2.1.1" xref="S3.F1.5.m2.1.1.cmml">…</mi><mo id="S3.F1.5.m2.3.3.2.4" xref="S3.F1.5.m2.3.3.3.cmml">,</mo><msub id="S3.F1.5.m2.3.3.2.2" xref="S3.F1.5.m2.3.3.2.2.cmml"><mi id="S3.F1.5.m2.3.3.2.2.2" xref="S3.F1.5.m2.3.3.2.2.2.cmml">R</mi><mn id="S3.F1.5.m2.3.3.2.2.3" xref="S3.F1.5.m2.3.3.2.2.3.cmml">20</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.F1.5.m2.3c"><list id="S3.F1.5.m2.3.3.3.cmml" xref="S3.F1.5.m2.3.3.2"><apply id="S3.F1.5.m2.2.2.1.1.cmml" xref="S3.F1.5.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.F1.5.m2.2.2.1.1.1.cmml" xref="S3.F1.5.m2.2.2.1.1">subscript</csymbol><ci id="S3.F1.5.m2.2.2.1.1.2.cmml" xref="S3.F1.5.m2.2.2.1.1.2">𝑅</ci><cn type="integer" id="S3.F1.5.m2.2.2.1.1.3.cmml" xref="S3.F1.5.m2.2.2.1.1.3">1</cn></apply><ci id="S3.F1.5.m2.1.1.cmml" xref="S3.F1.5.m2.1.1">…</ci><apply id="S3.F1.5.m2.3.3.2.2.cmml" xref="S3.F1.5.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.F1.5.m2.3.3.2.2.1.cmml" xref="S3.F1.5.m2.3.3.2.2">subscript</csymbol><ci id="S3.F1.5.m2.3.3.2.2.2.cmml" xref="S3.F1.5.m2.3.3.2.2.2">𝑅</ci><cn type="integer" id="S3.F1.5.m2.3.3.2.2.3.cmml" xref="S3.F1.5.m2.3.3.2.2.3">20</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.5.m2.3d">R_{1},...,R_{20}</annotation></semantics></math>)
</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Performance V.S. Resolutions</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">However, the state of the art object detectors are trained and tested on high resolution images but a most important question is how we can have detectors that give us the best balance of resolution and accuracy for different application needed. In this section, we evaluate the comparison of accuracy v.s. resolution tradeoff.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p"><span id="S4.p2.1.1" class="ltx_text ltx_font_bold">Dataset.</span> The PASCAL Visual Object Classes 2007 (VOC2007) Dataset is considered as our image database that contains 9963 images that are categorized into 20 object classes as explained in the previous section. The data has been split into 5011 images for training and validation and 4952 test images. The distribution of images and objects by class is approximately equal across the training, validation and test datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.
<br class="ltx_break">Figure <a href="#S4.F2" title="Figure 2 ‣ IV Performance V.S. Resolutions ‣ Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates examples of an image from PASCAL VOC2007 database in the multiple levels of spatial frequencies ranging from low to high frequencies.</p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S4.F2.1" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_top" style="width:140.9pt;">
<img src="/html/2301.09667/assets/figures/fig1.jpg" id="S4.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="452" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S4.F2.2" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_top" style="width:140.9pt;">
<img src="/html/2301.09667/assets/figures/fig2.jpg" id="S4.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="450" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S4.F2.3" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_top" style="width:140.9pt;">
<img src="/html/2301.09667/assets/figures/fig3.jpg" id="S4.F2.3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S4.F2.4" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_top" style="width:140.9pt;">
<img src="/html/2301.09667/assets/figures/fig4.jpg" id="S4.F2.4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="444" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S4.F2.5" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_top" style="width:140.9pt;">
<img src="/html/2301.09667/assets/figures/fig5.jpg" id="S4.F2.5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="444" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S4.F2.6" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_top" style="width:140.9pt;">
<img src="/html/2301.09667/assets/figures/fig6.jpg" id="S4.F2.6.g1" class="ltx_graphics ltx_img_landscape" width="598" height="450" alt="Refer to caption">
</div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S4.F2.29.1" class="ltx_text ltx_font_bold">Top row from left to right.</span> Resolutions: full-spectrum, <math id="S4.F2.17.m1.1" class="ltx_Math" alttext="R_{20}" display="inline"><semantics id="S4.F2.17.m1.1b"><msub id="S4.F2.17.m1.1.1" xref="S4.F2.17.m1.1.1.cmml"><mi id="S4.F2.17.m1.1.1.2" xref="S4.F2.17.m1.1.1.2.cmml">R</mi><mn id="S4.F2.17.m1.1.1.3" xref="S4.F2.17.m1.1.1.3.cmml">20</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F2.17.m1.1c"><apply id="S4.F2.17.m1.1.1.cmml" xref="S4.F2.17.m1.1.1"><csymbol cd="ambiguous" id="S4.F2.17.m1.1.1.1.cmml" xref="S4.F2.17.m1.1.1">subscript</csymbol><ci id="S4.F2.17.m1.1.1.2.cmml" xref="S4.F2.17.m1.1.1.2">𝑅</ci><cn type="integer" id="S4.F2.17.m1.1.1.3.cmml" xref="S4.F2.17.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.17.m1.1d">R_{20}</annotation></semantics></math> blurred with (<math id="S4.F2.18.m2.1" class="ltx_math_unparsed" alttext="f_{c}=20\textperiodcentered\frac{w}{20})" display="inline"><semantics id="S4.F2.18.m2.1b"><mrow id="S4.F2.18.m2.1c"><msub id="S4.F2.18.m2.1.1"><mi id="S4.F2.18.m2.1.1.2">f</mi><mi id="S4.F2.18.m2.1.1.3">c</mi></msub><mo id="S4.F2.18.m2.1.2">=</mo><mn id="S4.F2.18.m2.1.3">20</mn><mi mathvariant="normal" id="S4.F2.18.m2.1.4">·</mi><mfrac id="S4.F2.18.m2.1.5"><mi id="S4.F2.18.m2.1.5.2">w</mi><mn id="S4.F2.18.m2.1.5.3">20</mn></mfrac><mo stretchy="false" id="S4.F2.18.m2.1.6">)</mo></mrow><annotation encoding="application/x-tex" id="S4.F2.18.m2.1d">f_{c}=20\textperiodcentered\frac{w}{20})</annotation></semantics></math>, <math id="S4.F2.19.m3.1" class="ltx_Math" alttext="R_{18}" display="inline"><semantics id="S4.F2.19.m3.1b"><msub id="S4.F2.19.m3.1.1" xref="S4.F2.19.m3.1.1.cmml"><mi id="S4.F2.19.m3.1.1.2" xref="S4.F2.19.m3.1.1.2.cmml">R</mi><mn id="S4.F2.19.m3.1.1.3" xref="S4.F2.19.m3.1.1.3.cmml">18</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F2.19.m3.1c"><apply id="S4.F2.19.m3.1.1.cmml" xref="S4.F2.19.m3.1.1"><csymbol cd="ambiguous" id="S4.F2.19.m3.1.1.1.cmml" xref="S4.F2.19.m3.1.1">subscript</csymbol><ci id="S4.F2.19.m3.1.1.2.cmml" xref="S4.F2.19.m3.1.1.2">𝑅</ci><cn type="integer" id="S4.F2.19.m3.1.1.3.cmml" xref="S4.F2.19.m3.1.1.3">18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.19.m3.1d">R_{18}</annotation></semantics></math>: blurred with (<math id="S4.F2.20.m4.1" class="ltx_math_unparsed" alttext="f_{c}=18\textperiodcentered\frac{w}{20})" display="inline"><semantics id="S4.F2.20.m4.1b"><mrow id="S4.F2.20.m4.1c"><msub id="S4.F2.20.m4.1.1"><mi id="S4.F2.20.m4.1.1.2">f</mi><mi id="S4.F2.20.m4.1.1.3">c</mi></msub><mo id="S4.F2.20.m4.1.2">=</mo><mn id="S4.F2.20.m4.1.3">18</mn><mi mathvariant="normal" id="S4.F2.20.m4.1.4">·</mi><mfrac id="S4.F2.20.m4.1.5"><mi id="S4.F2.20.m4.1.5.2">w</mi><mn id="S4.F2.20.m4.1.5.3">20</mn></mfrac><mo stretchy="false" id="S4.F2.20.m4.1.6">)</mo></mrow><annotation encoding="application/x-tex" id="S4.F2.20.m4.1d">f_{c}=18\textperiodcentered\frac{w}{20})</annotation></semantics></math>. <span id="S4.F2.30.2" class="ltx_text ltx_font_bold">Bottom row from left to right.</span> Resolutions: <math id="S4.F2.21.m5.1" class="ltx_Math" alttext="R_{8}" display="inline"><semantics id="S4.F2.21.m5.1b"><msub id="S4.F2.21.m5.1.1" xref="S4.F2.21.m5.1.1.cmml"><mi id="S4.F2.21.m5.1.1.2" xref="S4.F2.21.m5.1.1.2.cmml">R</mi><mn id="S4.F2.21.m5.1.1.3" xref="S4.F2.21.m5.1.1.3.cmml">8</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F2.21.m5.1c"><apply id="S4.F2.21.m5.1.1.cmml" xref="S4.F2.21.m5.1.1"><csymbol cd="ambiguous" id="S4.F2.21.m5.1.1.1.cmml" xref="S4.F2.21.m5.1.1">subscript</csymbol><ci id="S4.F2.21.m5.1.1.2.cmml" xref="S4.F2.21.m5.1.1.2">𝑅</ci><cn type="integer" id="S4.F2.21.m5.1.1.3.cmml" xref="S4.F2.21.m5.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.21.m5.1d">R_{8}</annotation></semantics></math> blurred with (<math id="S4.F2.22.m6.1" class="ltx_math_unparsed" alttext="f_{c}=8\textperiodcentered\frac{w}{20})" display="inline"><semantics id="S4.F2.22.m6.1b"><mrow id="S4.F2.22.m6.1c"><msub id="S4.F2.22.m6.1.1"><mi id="S4.F2.22.m6.1.1.2">f</mi><mi id="S4.F2.22.m6.1.1.3">c</mi></msub><mo id="S4.F2.22.m6.1.2">=</mo><mn id="S4.F2.22.m6.1.3">8</mn><mi mathvariant="normal" id="S4.F2.22.m6.1.4">·</mi><mfrac id="S4.F2.22.m6.1.5"><mi id="S4.F2.22.m6.1.5.2">w</mi><mn id="S4.F2.22.m6.1.5.3">20</mn></mfrac><mo stretchy="false" id="S4.F2.22.m6.1.6">)</mo></mrow><annotation encoding="application/x-tex" id="S4.F2.22.m6.1d">f_{c}=8\textperiodcentered\frac{w}{20})</annotation></semantics></math>, <math id="S4.F2.23.m7.1" class="ltx_Math" alttext="R_{5}" display="inline"><semantics id="S4.F2.23.m7.1b"><msub id="S4.F2.23.m7.1.1" xref="S4.F2.23.m7.1.1.cmml"><mi id="S4.F2.23.m7.1.1.2" xref="S4.F2.23.m7.1.1.2.cmml">R</mi><mn id="S4.F2.23.m7.1.1.3" xref="S4.F2.23.m7.1.1.3.cmml">5</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F2.23.m7.1c"><apply id="S4.F2.23.m7.1.1.cmml" xref="S4.F2.23.m7.1.1"><csymbol cd="ambiguous" id="S4.F2.23.m7.1.1.1.cmml" xref="S4.F2.23.m7.1.1">subscript</csymbol><ci id="S4.F2.23.m7.1.1.2.cmml" xref="S4.F2.23.m7.1.1.2">𝑅</ci><cn type="integer" id="S4.F2.23.m7.1.1.3.cmml" xref="S4.F2.23.m7.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.23.m7.1d">R_{5}</annotation></semantics></math>: blurred with (<math id="S4.F2.24.m8.1" class="ltx_math_unparsed" alttext="f_{c}=5\textperiodcentered\frac{w}{20})" display="inline"><semantics id="S4.F2.24.m8.1b"><mrow id="S4.F2.24.m8.1c"><msub id="S4.F2.24.m8.1.1"><mi id="S4.F2.24.m8.1.1.2">f</mi><mi id="S4.F2.24.m8.1.1.3">c</mi></msub><mo id="S4.F2.24.m8.1.2">=</mo><mn id="S4.F2.24.m8.1.3">5</mn><mi mathvariant="normal" id="S4.F2.24.m8.1.4">·</mi><mfrac id="S4.F2.24.m8.1.5"><mi id="S4.F2.24.m8.1.5.2">w</mi><mn id="S4.F2.24.m8.1.5.3">20</mn></mfrac><mo stretchy="false" id="S4.F2.24.m8.1.6">)</mo></mrow><annotation encoding="application/x-tex" id="S4.F2.24.m8.1d">f_{c}=5\textperiodcentered\frac{w}{20})</annotation></semantics></math>, <math id="S4.F2.25.m9.1" class="ltx_Math" alttext="R_{1}" display="inline"><semantics id="S4.F2.25.m9.1b"><msub id="S4.F2.25.m9.1.1" xref="S4.F2.25.m9.1.1.cmml"><mi id="S4.F2.25.m9.1.1.2" xref="S4.F2.25.m9.1.1.2.cmml">R</mi><mn id="S4.F2.25.m9.1.1.3" xref="S4.F2.25.m9.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F2.25.m9.1c"><apply id="S4.F2.25.m9.1.1.cmml" xref="S4.F2.25.m9.1.1"><csymbol cd="ambiguous" id="S4.F2.25.m9.1.1.1.cmml" xref="S4.F2.25.m9.1.1">subscript</csymbol><ci id="S4.F2.25.m9.1.1.2.cmml" xref="S4.F2.25.m9.1.1.2">𝑅</ci><cn type="integer" id="S4.F2.25.m9.1.1.3.cmml" xref="S4.F2.25.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.25.m9.1d">R_{1}</annotation></semantics></math>: blurred with (<math id="S4.F2.26.m10.1" class="ltx_math_unparsed" alttext="f_{c}=1\textperiodcentered\frac{w}{20})" display="inline"><semantics id="S4.F2.26.m10.1b"><mrow id="S4.F2.26.m10.1c"><msub id="S4.F2.26.m10.1.1"><mi id="S4.F2.26.m10.1.1.2">f</mi><mi id="S4.F2.26.m10.1.1.3">c</mi></msub><mo id="S4.F2.26.m10.1.2">=</mo><mn id="S4.F2.26.m10.1.3">1</mn><mi mathvariant="normal" id="S4.F2.26.m10.1.4">·</mi><mfrac id="S4.F2.26.m10.1.5"><mi id="S4.F2.26.m10.1.5.2">w</mi><mn id="S4.F2.26.m10.1.5.3">20</mn></mfrac><mo stretchy="false" id="S4.F2.26.m10.1.6">)</mo></mrow><annotation encoding="application/x-tex" id="S4.F2.26.m10.1d">f_{c}=1\textperiodcentered\frac{w}{20})</annotation></semantics></math></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Performance Evaluation of the Faster-RCNN on Different Resolutions</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">To track the performance in the object detection, our performance evaluation metric is the mean Average Precision (mAP) which is a very common and popular performance measure in object detection tasks. The Average Precision is defined as the fraction of the images with a relevant detected object among all images with detected objects. In other words, the average precision is the area under the precision-recall curve for each categories of objects. The mean average precision is computed by taking the mean of the average precision for all category of objects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2301.09667/assets/figures/fig7.jpg" id="S4.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="287" height="174" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Illustration of the performance of Faster- RCNN network on recognition of objects on the PASCAL VOC 2007 test dataset (4952 images) in multiple resolutions.</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Figure <a href="#S4.F3" title="Figure 3 ‣ IV-A Performance Evaluation of the Faster-RCNN on Different Resolutions ‣ IV Performance V.S. Resolutions ‣ Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the Faster-RCNN results of detection when tested on the PASCAL VOC2007 test data in various levels of resolution (<math id="S4.SS1.p2.1.m1.3" class="ltx_Math" alttext="R_{1},...,R_{20}" display="inline"><semantics id="S4.SS1.p2.1.m1.3a"><mrow id="S4.SS1.p2.1.m1.3.3.2" xref="S4.SS1.p2.1.m1.3.3.3.cmml"><msub id="S4.SS1.p2.1.m1.2.2.1.1" xref="S4.SS1.p2.1.m1.2.2.1.1.cmml"><mi id="S4.SS1.p2.1.m1.2.2.1.1.2" xref="S4.SS1.p2.1.m1.2.2.1.1.2.cmml">R</mi><mn id="S4.SS1.p2.1.m1.2.2.1.1.3" xref="S4.SS1.p2.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.p2.1.m1.3.3.2.3" xref="S4.SS1.p2.1.m1.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">…</mi><mo id="S4.SS1.p2.1.m1.3.3.2.4" xref="S4.SS1.p2.1.m1.3.3.3.cmml">,</mo><msub id="S4.SS1.p2.1.m1.3.3.2.2" xref="S4.SS1.p2.1.m1.3.3.2.2.cmml"><mi id="S4.SS1.p2.1.m1.3.3.2.2.2" xref="S4.SS1.p2.1.m1.3.3.2.2.2.cmml">R</mi><mn id="S4.SS1.p2.1.m1.3.3.2.2.3" xref="S4.SS1.p2.1.m1.3.3.2.2.3.cmml">20</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.3b"><list id="S4.SS1.p2.1.m1.3.3.3.cmml" xref="S4.SS1.p2.1.m1.3.3.2"><apply id="S4.SS1.p2.1.m1.2.2.1.1.cmml" xref="S4.SS1.p2.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.2.2.1.1.1.cmml" xref="S4.SS1.p2.1.m1.2.2.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.2.2.1.1.2.cmml" xref="S4.SS1.p2.1.m1.2.2.1.1.2">𝑅</ci><cn type="integer" id="S4.SS1.p2.1.m1.2.2.1.1.3.cmml" xref="S4.SS1.p2.1.m1.2.2.1.1.3">1</cn></apply><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">…</ci><apply id="S4.SS1.p2.1.m1.3.3.2.2.cmml" xref="S4.SS1.p2.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.3.3.2.2.1.cmml" xref="S4.SS1.p2.1.m1.3.3.2.2">subscript</csymbol><ci id="S4.SS1.p2.1.m1.3.3.2.2.2.cmml" xref="S4.SS1.p2.1.m1.3.3.2.2.2">𝑅</ci><cn type="integer" id="S4.SS1.p2.1.m1.3.3.2.2.3.cmml" xref="S4.SS1.p2.1.m1.3.3.2.2.3">20</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.3c">R_{1},...,R_{20}</annotation></semantics></math>) as explained in the previous section. The results reveal that the performance of the Full-spectrum Model drops off quickly for low resolution images compared with the high resolution and full-spectrum images. This indicates that the representations that are learned for the object recognition in a deep neural network highly depend to the information from all spatial frequencies simultaneously. Hence, the lack of information from the specific scale negatively influences the recognition performance. However, the human visual system can detect objects in most of the resolution levels since the human brain provides representations of objects and scenes at multiple scales so that it can still interpret the scenes and objects even in a single level representation.
<br class="ltx_break"></p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Performance comparison (mAP) of Faster- RCNN models trained on different resolutions for different resolution test cases created from PASCAL VOC2007 database</figcaption>
<table id="S4.T1.8.8" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.4.4.4" class="ltx_tr">
<th id="S4.T1.4.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_rr ltx_border_tt">
<span id="S4.T1.4.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.4.4.4.5.1.1" class="ltx_p" style="width:83.4pt;">Database-Resolution</span>
</span>
</th>
<td id="S4.T1.4.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T1.4.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.4.4.4.6.1.1" class="ltx_p" style="width:64.0pt;">Full-spectrum Model mAP(%)</span>
</span>
</td>
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S4.T1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\frac{20}{20}" display="inline"><semantics id="S4.T1.1.1.1.1.1.1.m1.1a"><mfrac id="S4.T1.1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.1.m1.1.1.cmml"><mn id="S4.T1.1.1.1.1.1.1.m1.1.1.2" xref="S4.T1.1.1.1.1.1.1.m1.1.1.2.cmml">20</mn><mn id="S4.T1.1.1.1.1.1.1.m1.1.1.3" xref="S4.T1.1.1.1.1.1.1.m1.1.1.3.cmml">20</mn></mfrac><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.m1.1.1"><divide id="S4.T1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.m1.1.1"></divide><cn type="integer" id="S4.T1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T1.1.1.1.1.1.1.m1.1.1.2">20</cn><cn type="integer" id="S4.T1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T1.1.1.1.1.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.1.m1.1c">\frac{20}{20}</annotation></semantics></math> -Model mAP(%)</span>
</span>
</td>
<td id="S4.T1.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T1.2.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.2.2.2.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S4.T1.2.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\frac{18}{20}" display="inline"><semantics id="S4.T1.2.2.2.2.1.1.m1.1a"><mfrac id="S4.T1.2.2.2.2.1.1.m1.1.1" xref="S4.T1.2.2.2.2.1.1.m1.1.1.cmml"><mn id="S4.T1.2.2.2.2.1.1.m1.1.1.2" xref="S4.T1.2.2.2.2.1.1.m1.1.1.2.cmml">18</mn><mn id="S4.T1.2.2.2.2.1.1.m1.1.1.3" xref="S4.T1.2.2.2.2.1.1.m1.1.1.3.cmml">20</mn></mfrac><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.1.1.m1.1b"><apply id="S4.T1.2.2.2.2.1.1.m1.1.1.cmml" xref="S4.T1.2.2.2.2.1.1.m1.1.1"><divide id="S4.T1.2.2.2.2.1.1.m1.1.1.1.cmml" xref="S4.T1.2.2.2.2.1.1.m1.1.1"></divide><cn type="integer" id="S4.T1.2.2.2.2.1.1.m1.1.1.2.cmml" xref="S4.T1.2.2.2.2.1.1.m1.1.1.2">18</cn><cn type="integer" id="S4.T1.2.2.2.2.1.1.m1.1.1.3.cmml" xref="S4.T1.2.2.2.2.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.1.1.m1.1c">\frac{18}{20}</annotation></semantics></math> -Model mAP(%)</span>
</span>
</td>
<td id="S4.T1.3.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T1.3.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.3.3.1.1" class="ltx_p" style="width:42.7pt;"><math id="S4.T1.3.3.3.3.1.1.m1.1" class="ltx_Math" alttext="\frac{10}{20}" display="inline"><semantics id="S4.T1.3.3.3.3.1.1.m1.1a"><mfrac id="S4.T1.3.3.3.3.1.1.m1.1.1" xref="S4.T1.3.3.3.3.1.1.m1.1.1.cmml"><mn id="S4.T1.3.3.3.3.1.1.m1.1.1.2" xref="S4.T1.3.3.3.3.1.1.m1.1.1.2.cmml">10</mn><mn id="S4.T1.3.3.3.3.1.1.m1.1.1.3" xref="S4.T1.3.3.3.3.1.1.m1.1.1.3.cmml">20</mn></mfrac><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.1.1.m1.1b"><apply id="S4.T1.3.3.3.3.1.1.m1.1.1.cmml" xref="S4.T1.3.3.3.3.1.1.m1.1.1"><divide id="S4.T1.3.3.3.3.1.1.m1.1.1.1.cmml" xref="S4.T1.3.3.3.3.1.1.m1.1.1"></divide><cn type="integer" id="S4.T1.3.3.3.3.1.1.m1.1.1.2.cmml" xref="S4.T1.3.3.3.3.1.1.m1.1.1.2">10</cn><cn type="integer" id="S4.T1.3.3.3.3.1.1.m1.1.1.3.cmml" xref="S4.T1.3.3.3.3.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.1.1.m1.1c">\frac{10}{20}</annotation></semantics></math> -Model mAP(%)</span>
</span>
</td>
<td id="S4.T1.4.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T1.4.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.4.4.4.4.1.1" class="ltx_p" style="width:42.7pt;"><math id="S4.T1.4.4.4.4.1.1.m1.1" class="ltx_Math" alttext="\frac{5}{20}" display="inline"><semantics id="S4.T1.4.4.4.4.1.1.m1.1a"><mfrac id="S4.T1.4.4.4.4.1.1.m1.1.1" xref="S4.T1.4.4.4.4.1.1.m1.1.1.cmml"><mn id="S4.T1.4.4.4.4.1.1.m1.1.1.2" xref="S4.T1.4.4.4.4.1.1.m1.1.1.2.cmml">5</mn><mn id="S4.T1.4.4.4.4.1.1.m1.1.1.3" xref="S4.T1.4.4.4.4.1.1.m1.1.1.3.cmml">20</mn></mfrac><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.1.1.m1.1b"><apply id="S4.T1.4.4.4.4.1.1.m1.1.1.cmml" xref="S4.T1.4.4.4.4.1.1.m1.1.1"><divide id="S4.T1.4.4.4.4.1.1.m1.1.1.1.cmml" xref="S4.T1.4.4.4.4.1.1.m1.1.1"></divide><cn type="integer" id="S4.T1.4.4.4.4.1.1.m1.1.1.2.cmml" xref="S4.T1.4.4.4.4.1.1.m1.1.1.2">5</cn><cn type="integer" id="S4.T1.4.4.4.4.1.1.m1.1.1.3.cmml" xref="S4.T1.4.4.4.4.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.1.1.m1.1c">\frac{5}{20}</annotation></semantics></math> -Model mAP(%)</span>
</span>
</td>
</tr>
<tr id="S4.T1.8.8.9.1" class="ltx_tr">
<th id="S4.T1.8.8.9.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_rr ltx_border_t">
<span id="S4.T1.8.8.9.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.9.1.1.1.1" class="ltx_p" style="width:83.4pt;">Full-spectrum</span>
</span>
</th>
<td id="S4.T1.8.8.9.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.8.8.9.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.9.1.2.1.1" class="ltx_p" style="width:64.0pt;">68.1%</span>
</span>
</td>
<td id="S4.T1.8.8.9.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.8.8.9.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.9.1.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S4.T1.8.8.9.1.3.1.1.1" class="ltx_text ltx_font_bold">68.7%</span></span>
</span>
</td>
<td id="S4.T1.8.8.9.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.8.8.9.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.9.1.4.1.1" class="ltx_p" style="width:42.7pt;">68.4%</span>
</span>
</td>
<td id="S4.T1.8.8.9.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.8.8.9.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.9.1.5.1.1" class="ltx_p" style="width:42.7pt;">67.6%</span>
</span>
</td>
<td id="S4.T1.8.8.9.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.8.8.9.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.9.1.6.1.1" class="ltx_p" style="width:42.7pt;">61.6%</span>
</span>
</td>
</tr>
<tr id="S4.T1.5.5.5" class="ltx_tr">
<th id="S4.T1.5.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_rr ltx_border_t">
<span id="S4.T1.5.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.5.1.1.1" class="ltx_p" style="width:83.4pt;"><math id="S4.T1.5.5.5.1.1.1.m1.1" class="ltx_Math" alttext="R_{20}" display="inline"><semantics id="S4.T1.5.5.5.1.1.1.m1.1a"><msub id="S4.T1.5.5.5.1.1.1.m1.1.1" xref="S4.T1.5.5.5.1.1.1.m1.1.1.cmml"><mi id="S4.T1.5.5.5.1.1.1.m1.1.1.2" xref="S4.T1.5.5.5.1.1.1.m1.1.1.2.cmml">R</mi><mn id="S4.T1.5.5.5.1.1.1.m1.1.1.3" xref="S4.T1.5.5.5.1.1.1.m1.1.1.3.cmml">20</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.1.1.1.m1.1b"><apply id="S4.T1.5.5.5.1.1.1.m1.1.1.cmml" xref="S4.T1.5.5.5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.5.5.5.1.1.1.m1.1.1.1.cmml" xref="S4.T1.5.5.5.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T1.5.5.5.1.1.1.m1.1.1.2.cmml" xref="S4.T1.5.5.5.1.1.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S4.T1.5.5.5.1.1.1.m1.1.1.3.cmml" xref="S4.T1.5.5.5.1.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.1.1.1.m1.1c">R_{20}</annotation></semantics></math></span>
</span>
</th>
<td id="S4.T1.5.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.5.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.5.2.1.1" class="ltx_p" style="width:64.0pt;">63.9%</span>
</span>
</td>
<td id="S4.T1.5.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.5.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.5.3.1.1" class="ltx_p" style="width:42.7pt;">67.2%</span>
</span>
</td>
<td id="S4.T1.5.5.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.5.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.5.4.1.1" class="ltx_p" style="width:42.7pt;"><span id="S4.T1.5.5.5.4.1.1.1" class="ltx_text ltx_font_bold">67.3%</span></span>
</span>
</td>
<td id="S4.T1.5.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.5.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.5.5.1.1" class="ltx_p" style="width:42.7pt;">66.6%</span>
</span>
</td>
<td id="S4.T1.5.5.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.5.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.5.6.1.1" class="ltx_p" style="width:42.7pt;">61.7%</span>
</span>
</td>
</tr>
<tr id="S4.T1.6.6.6" class="ltx_tr">
<th id="S4.T1.6.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_rr ltx_border_t">
<span id="S4.T1.6.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.6.1.1.1" class="ltx_p" style="width:83.4pt;"><math id="S4.T1.6.6.6.1.1.1.m1.1" class="ltx_Math" alttext="R_{18}" display="inline"><semantics id="S4.T1.6.6.6.1.1.1.m1.1a"><msub id="S4.T1.6.6.6.1.1.1.m1.1.1" xref="S4.T1.6.6.6.1.1.1.m1.1.1.cmml"><mi id="S4.T1.6.6.6.1.1.1.m1.1.1.2" xref="S4.T1.6.6.6.1.1.1.m1.1.1.2.cmml">R</mi><mn id="S4.T1.6.6.6.1.1.1.m1.1.1.3" xref="S4.T1.6.6.6.1.1.1.m1.1.1.3.cmml">18</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.1.1.1.m1.1b"><apply id="S4.T1.6.6.6.1.1.1.m1.1.1.cmml" xref="S4.T1.6.6.6.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.6.6.6.1.1.1.m1.1.1.1.cmml" xref="S4.T1.6.6.6.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T1.6.6.6.1.1.1.m1.1.1.2.cmml" xref="S4.T1.6.6.6.1.1.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S4.T1.6.6.6.1.1.1.m1.1.1.3.cmml" xref="S4.T1.6.6.6.1.1.1.m1.1.1.3">18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.1.1.1.m1.1c">R_{18}</annotation></semantics></math></span>
</span>
</th>
<td id="S4.T1.6.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.6.2.1.1" class="ltx_p" style="width:64.0pt;">63.7%</span>
</span>
</td>
<td id="S4.T1.6.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.6.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S4.T1.6.6.6.3.1.1.1" class="ltx_text ltx_font_bold">67.5%</span></span>
</span>
</td>
<td id="S4.T1.6.6.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.6.4.1.1" class="ltx_p" style="width:42.7pt;">67.3%</span>
</span>
</td>
<td id="S4.T1.6.6.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.6.5.1.1" class="ltx_p" style="width:42.7pt;">66.7%</span>
</span>
</td>
<td id="S4.T1.6.6.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.6.6.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.6.6.1.1" class="ltx_p" style="width:42.7pt;">62.1%</span>
</span>
</td>
</tr>
<tr id="S4.T1.7.7.7" class="ltx_tr">
<th id="S4.T1.7.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_rr ltx_border_t">
<span id="S4.T1.7.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.7.7.7.1.1.1" class="ltx_p" style="width:83.4pt;"><math id="S4.T1.7.7.7.1.1.1.m1.1" class="ltx_Math" alttext="R_{10}" display="inline"><semantics id="S4.T1.7.7.7.1.1.1.m1.1a"><msub id="S4.T1.7.7.7.1.1.1.m1.1.1" xref="S4.T1.7.7.7.1.1.1.m1.1.1.cmml"><mi id="S4.T1.7.7.7.1.1.1.m1.1.1.2" xref="S4.T1.7.7.7.1.1.1.m1.1.1.2.cmml">R</mi><mn id="S4.T1.7.7.7.1.1.1.m1.1.1.3" xref="S4.T1.7.7.7.1.1.1.m1.1.1.3.cmml">10</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.1.1.1.m1.1b"><apply id="S4.T1.7.7.7.1.1.1.m1.1.1.cmml" xref="S4.T1.7.7.7.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.7.7.7.1.1.1.m1.1.1.1.cmml" xref="S4.T1.7.7.7.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T1.7.7.7.1.1.1.m1.1.1.2.cmml" xref="S4.T1.7.7.7.1.1.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S4.T1.7.7.7.1.1.1.m1.1.1.3.cmml" xref="S4.T1.7.7.7.1.1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.7.1.1.1.m1.1c">R_{10}</annotation></semantics></math></span>
</span>
</th>
<td id="S4.T1.7.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.7.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.7.7.7.2.1.1" class="ltx_p" style="width:64.0pt;">60.1%</span>
</span>
</td>
<td id="S4.T1.7.7.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.7.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.7.7.7.3.1.1" class="ltx_p" style="width:42.7pt;">64.9%</span>
</span>
</td>
<td id="S4.T1.7.7.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.7.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.7.7.7.4.1.1" class="ltx_p" style="width:42.7pt;">65.3%</span>
</span>
</td>
<td id="S4.T1.7.7.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.7.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.7.7.7.5.1.1" class="ltx_p" style="width:42.7pt;"><span id="S4.T1.7.7.7.5.1.1.1" class="ltx_text ltx_font_bold">65.9%</span></span>
</span>
</td>
<td id="S4.T1.7.7.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.7.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.7.7.7.6.1.1" class="ltx_p" style="width:42.7pt;">63.5%</span>
</span>
</td>
</tr>
<tr id="S4.T1.8.8.8" class="ltx_tr">
<th id="S4.T1.8.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_rr ltx_border_t">
<span id="S4.T1.8.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.8.1.1.1" class="ltx_p" style="width:83.4pt;"><math id="S4.T1.8.8.8.1.1.1.m1.1" class="ltx_Math" alttext="R_{5}" display="inline"><semantics id="S4.T1.8.8.8.1.1.1.m1.1a"><msub id="S4.T1.8.8.8.1.1.1.m1.1.1" xref="S4.T1.8.8.8.1.1.1.m1.1.1.cmml"><mi id="S4.T1.8.8.8.1.1.1.m1.1.1.2" xref="S4.T1.8.8.8.1.1.1.m1.1.1.2.cmml">R</mi><mn id="S4.T1.8.8.8.1.1.1.m1.1.1.3" xref="S4.T1.8.8.8.1.1.1.m1.1.1.3.cmml">5</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.8.1.1.1.m1.1b"><apply id="S4.T1.8.8.8.1.1.1.m1.1.1.cmml" xref="S4.T1.8.8.8.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.8.8.8.1.1.1.m1.1.1.1.cmml" xref="S4.T1.8.8.8.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T1.8.8.8.1.1.1.m1.1.1.2.cmml" xref="S4.T1.8.8.8.1.1.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S4.T1.8.8.8.1.1.1.m1.1.1.3.cmml" xref="S4.T1.8.8.8.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.8.1.1.1.m1.1c">R_{5}</annotation></semantics></math></span>
</span>
</th>
<td id="S4.T1.8.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S4.T1.8.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.8.2.1.1" class="ltx_p" style="width:64.0pt;">45.5%</span>
</span>
</td>
<td id="S4.T1.8.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S4.T1.8.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.8.3.1.1" class="ltx_p" style="width:42.7pt;">52.3%</span>
</span>
</td>
<td id="S4.T1.8.8.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S4.T1.8.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.8.4.1.1" class="ltx_p" style="width:42.7pt;">51.2%</span>
</span>
</td>
<td id="S4.T1.8.8.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S4.T1.8.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.8.5.1.1" class="ltx_p" style="width:42.7pt;">57.0%</span>
</span>
</td>
<td id="S4.T1.8.8.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T1.8.8.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.8.6.1.1" class="ltx_p" style="width:42.7pt;"><span id="S4.T1.8.8.8.6.1.1.1" class="ltx_text ltx_font_bold">61.3%</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Deploying a Multi-Resolution Faster-RCNN</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We propose a Multi-Resolution Faster-RCNN model that is made up of 5 end-to-end trained models on various resolution levels. A combination rule is applied during the test scheme such that a given image is passed through all 5 models and the best object recognition results are derived based on the combination rule that will be discussed shortly.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The combinational rule is adopted as an external module independent of the training scheme. To detect objects in a given input image to the Multi-Resolution Faster- RCNN model, all detections are collected from each of the five individual models. Each detected object is provided in the form of a bounding box and a score indicating the predicted probability of that bounding box belonging to an object class. The number of detections in each model may vary between 0 to 300, depending on the input image. Thus it is expected to have between 1 to 1500 proposed objects (presented as bounding box coordinates, predicted class score, and object class) for the combination of all five models. However, many of these bounding boxes highly overlap. For this, non-maximum suppression is used on the collection of all detected bounding boxes to reduce the redundancy. The Intersection-over-Union (IoU) threshold for non- maximum suppression is adopted at 0.7 to remove the redundant bounding boxes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. All remaining objects are proposed as the detection results of the Multi-Resolution Faster-RCNN model. Figure <a href="#S4.F4" title="Figure 4 ‣ IV-B Deploying a Multi-Resolution Faster-RCNN ‣ IV Performance V.S. Resolutions ‣ Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the detection scheme.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">For evaluation of the the Multi-Resolution Faster-RCNN model, the process is implemented using the five models that were trained on PASCAL VOC2007 training/validation data (5K) in five different resolutions. Then, 20 test databases in 20 levels of resolutions were generated from the PASCAL VOC2007 test data (5k). For
each test database (corresponding to a certain resolution), the results of object detections from 5 models are obtained. Non-maximum suppression is adapted both based on the IoU threshold value of 0.7 as well as highest overlap with the ground truth bounding boxes. The detection results for five models and the Multi-resolution Faster-RCNN on 20 test databases (PASCAL VOC2007-<math id="S4.SS2.p3.1.m1.3" class="ltx_Math" alttext="R_{1,...,20}" display="inline"><semantics id="S4.SS2.p3.1.m1.3a"><msub id="S4.SS2.p3.1.m1.3.4" xref="S4.SS2.p3.1.m1.3.4.cmml"><mi id="S4.SS2.p3.1.m1.3.4.2" xref="S4.SS2.p3.1.m1.3.4.2.cmml">R</mi><mrow id="S4.SS2.p3.1.m1.3.3.3.5" xref="S4.SS2.p3.1.m1.3.3.3.4.cmml"><mn id="S4.SS2.p3.1.m1.1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.1.cmml">1</mn><mo id="S4.SS2.p3.1.m1.3.3.3.5.1" xref="S4.SS2.p3.1.m1.3.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S4.SS2.p3.1.m1.2.2.2.2" xref="S4.SS2.p3.1.m1.2.2.2.2.cmml">…</mi><mo id="S4.SS2.p3.1.m1.3.3.3.5.2" xref="S4.SS2.p3.1.m1.3.3.3.4.cmml">,</mo><mn id="S4.SS2.p3.1.m1.3.3.3.3" xref="S4.SS2.p3.1.m1.3.3.3.3.cmml">20</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.3b"><apply id="S4.SS2.p3.1.m1.3.4.cmml" xref="S4.SS2.p3.1.m1.3.4"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.3.4.1.cmml" xref="S4.SS2.p3.1.m1.3.4">subscript</csymbol><ci id="S4.SS2.p3.1.m1.3.4.2.cmml" xref="S4.SS2.p3.1.m1.3.4.2">𝑅</ci><list id="S4.SS2.p3.1.m1.3.3.3.4.cmml" xref="S4.SS2.p3.1.m1.3.3.3.5"><cn type="integer" id="S4.SS2.p3.1.m1.1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1">1</cn><ci id="S4.SS2.p3.1.m1.2.2.2.2.cmml" xref="S4.SS2.p3.1.m1.2.2.2.2">…</ci><cn type="integer" id="S4.SS2.p3.1.m1.3.3.3.3.cmml" xref="S4.SS2.p3.1.m1.3.3.3.3">20</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.3c">R_{1,...,20}</annotation></semantics></math>) are shown in Figure <a href="#S3.F1" title="Figure 1 ‣ III-B Notation and Problem Formulation ‣ III Tracking Object recognition network performance ‣ Improving Performance of Object Detection using the Mechanisms of Visual Recognition in Humans" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The combined model, Multi-Resolution Faster-RCNN, outperforms all the models in detecting images in all ranges of resolutions. The results indicate the robustness, efficiency, and higher performance of the Multi-Resolution Faster-RCNN regardless of the resolution of the input image in comparison to the Faster-RCNN for object recognition.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2301.09667/assets/figures/fig11.jpg" id="S4.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="401" height="190" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The detection scheme in the Multi-Resolution Faster-RCNN.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion and Future Work</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Inspired by the capability of human visual system for adapting to different resolution of images, in this work, we developed a multi-resolution deep object recognition framework which solves the issue of significant drop in the detection accuracy that happens for deep neural networks when trained and evaluated on different resolutions. This indicates that the
representations that are learned for the object recognition in deep neural network
highly depend to the information from all spatial frequencies simultaneously. Hence,
the lack of information from the certain scale negatively influence the recognition performance. To address this, we propose a Multi-Resolution Faster-RCNN model that is made up of 5 end to end
trained models on various resolution levels. The combination rule is applied during
the test scheme such that a given image is passed through all 5 models and the best
object recognition results are derived based on the combination rule. Our experiments show that
the Multi-Resolution Faster-RCNN outperforms the original Faster-RCNN object detector in
detecting images in all ranges of resolutions. The results indicate the robustness,
efficiency, and higher performance of the Multi-Resolution Faster-RCNN regardless
of the resolution of the input image than Faster-RCNN for object recognition.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
N. Bayat and J.-H. Park, “Particle swarm optimization based demand response
using artificial neural network based load prediction,” in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">2022 North
American Power Symposium (NAPS)</em>, 2022, pp. 1–5.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Bayat and M. Pomplun, “Deriving high-level scene descriptions from deep
scene cnn features,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2017 Seventh International Conference on Image
Processing Theory, Tools and Applications (IPTA)</em>.   IEEE, 2017, pp. 1–6.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. Bayat, C. Anderson, and P. Shah, “Automated end-to-end deep learning
framework for classification and tumor localization from native non-stained
pathology images,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Medical Imaging 2021: Image Processing</em>, vol.
11596.   SPIE, 2021, pp. 43–54.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Bayat, H. Do Koh, A. Kumar Nand, M. Pereira, and M. Pomplun, “Scene grammar
in human and machine recognition of objects and scenes,” in
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition Workshops</em>, 2018, pp. 1992–1999.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva, “Learning deep
features for scene recognition using places database,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Advances in
neural information processing systems</em>, vol. 27, pp. 487–495, 2014.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature hierarchies
for accurate object detection and semantic segmentation,” in
<em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern
recognition</em>, 2014, pp. 580–587.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
N. Bayat, E. Rastegari, and Q. Li, “Human gait recognition using bag of words
feature representation method,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.13317</em>,
2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time
object detection with region proposal networks,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on
pattern analysis and machine intelligence</em>, vol. 39, no. 6, pp. 1137–1149,
2016.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern
recognition</em>, 2015, pp. 1–9.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet: A
large-scale hierarchical image database,” in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">2009 IEEE conference on
computer vision and pattern recognition</em>.   Ieee, 2009, pp. 248–255.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. Dodge and L. Karam, “Understanding how image quality affects deep neural
networks,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">2016 eighth international conference on quality of
multimedia experience (QoMEX)</em>.   IEEE,
2016, pp. 1–6.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J.-H. Kim, S. Kwon, J. Fu, and J.-H. Park, “Hair follicle classification and
hair loss severity estimation using mask r-cnn,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Journal of Imaging</em>,
vol. 8, no. 10, p. 283, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman, “The
pascal visual object classes (voc) challenge,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">International journal
of computer vision</em>, vol. 88, no. 2, pp. 303–338, 2010.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. A. Webster, “Visual adaptation,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Annual review of vision science</em>,
vol. 1, pp. 547–567, 2015.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
D. P. McGovern, N. W. Roach, and B. S. Webb, “Perceptual learning reconfigures
the effects of visual adaptation,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Journal of Neuroscience</em>, vol. 32,
no. 39, pp. 13 621–13 629, 2012.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
H. Harris, M. Gliksberg, and D. Sagi, “Generalized perceptual learning in the
absence of sensory adaptation,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Current biology</em>, vol. 22, no. 19, pp.
1813–1817, 2012.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
M. A. Webster, “Adaptation and visual coding,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Journal of vision</em>,
vol. 11, no. 5, pp. 3–3, 2011.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
C. M. Howard and M. A. Webster, “Mccollough effect,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Scholarpedia</em>,
vol. 6, no. 2, p. 8175, 2011.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
M. Bar, “Visual objects in context,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Nature Reviews Neuroscience</em>,
vol. 5, no. 8, pp. 617–629, 2004.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
D. G. Lowe, “Object recognition from local scale-invariant features,” in
<em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the seventh IEEE international conference on computer
vision</em>, vol. 2.   Ieee, 1999, pp.
1150–1157.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
H. Bay, T. Tuytelaars, and L. Van Gool, “Surf: Speeded up robust features,”
in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">European conference on computer vision</em>.   Springer, 2006, pp. 404–417.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
M. Calonder, V. Lepetit, C. Strecha, and P. Fua, “Brief: Binary robust
independent elementary features,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">European conference on computer
vision</em>.   Springer, 2010, pp. 778–792.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
N. Westlake, H. Cai, and P. Hall, “Detecting people in artwork with cnns,” in
<em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>.   Springer, 2016, pp. 825–841.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look once:
Unified, real-time object detection,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE
conference on computer vision and pattern recognition</em>, 2016, pp. 779–788.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and A. C. Berg,
“Ssd: Single shot multibox detector,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">European conference on
computer vision</em>.   Springer, 2016, pp.
21–37.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár, “Focal loss for
dense object detection,” in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international
conference on computer vision</em>, 2017, pp. 2980–2988.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
K. He, G. Gkioxari, P. Dollár, and R. Girshick, “Mask r-cnn,” in
<em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer vision</em>,
2017, pp. 2961–2969.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Z. Cai and N. Vasconcelos, “Cascade r-cnn: Delving into high quality object
detection,” in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision
and pattern recognition</em>, 2018, pp. 6154–6162.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
S. P. Kannojia and G. Jaiswal, “Effects of varying resolution on performance
of cnn based image classification: An experimental study,” <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Int. J.
Comput. Sci. Eng</em>, vol. 6, no. 9, pp. 451–456, 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
X. Chen and A. Gupta, “An implementation of faster rcnn with study for region
sampling,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1702.02138</em>, 2017.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
N. Bayat, D. D. Davey, M. Coathup, and J.-H. Park, “White blood cell
classification using multi-attention data augmentation and regularization,”
<em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Big Data and Cognitive Computing</em>, vol. 6, no. 4, p. 122, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman, “The
pascal visual object classes challenge 2007 (voc2007) results,” 2007.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
N. Bayat, E. Rastegari, and Q. Li, “Human gait recognition using bag of words
feature-representation method, in: Tareq ahram and christianne falcão (eds)
human factors and wearable technologies,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">AHFE (2022) International
Conference.AHFE Open Access, vol 29. AHFE International, USA</em>, 2022.
[Online]. Available: <a target="_blank" href="http://doi.org/10.54941/ahfe1001481" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://doi.org/10.54941/ahfe1001481</a>

</span>
</li>
</ul>
</section>
<div id="p3" class="ltx_para">
<span id="p3.1" class="ltx_ERROR undefined">\EOD</span>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2301.09666" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2301.09667" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2301.09667">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2301.09667" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2301.09668" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 06:19:26 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
