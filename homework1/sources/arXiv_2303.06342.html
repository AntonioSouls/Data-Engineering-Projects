<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.06342] Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author</title><meta property="og:description" content="Recent works have shown the superior robustness of four-dimensional (4D) Radar-based three-dimensional (3D) object detection in adverse weather conditions.
However, processing 4D Radar data remains a challenge due to t…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.06342">

<!--Generated on Thu Feb 29 20:30:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
4D Radar,  3D object detection,  adverse weathers
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection
<span id="id2.2" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span><sup id="id2.2.1" class="ltx_sup"><span id="id2.2.1.1" class="ltx_text ltx_font_italic">†</span></sup>co-first authors, <sup id="id2.2.2" class="ltx_sup"><span id="id2.2.2.1" class="ltx_text ltx_font_italic">∗</span></sup>corresponding author</span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dong-Hee Paek<sup id="id5.2.id1" class="ltx_sup"><span id="id5.2.id1.1" class="ltx_text ltx_font_italic">†</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id6.3.id1" class="ltx_text ltx_font_italic">CCS Graduate School of Mobility</span>
<br class="ltx_break"><span id="id7.4.id2" class="ltx_text ltx_font_italic">KAIST
<br class="ltx_break"></span>Daejeon, Republic of Korea 
<br class="ltx_break">donghee.paek@kaist.ac.kr
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Seung-Hyun Kong<sup id="id8.2.id1" class="ltx_sup"><span id="id8.2.id1.1" class="ltx_text ltx_font_italic">†∗</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id9.3.id1" class="ltx_text ltx_font_italic">CCS Graduate School of Mobility</span>
<br class="ltx_break"><span id="id10.4.id2" class="ltx_text ltx_font_italic">KAIST
<br class="ltx_break"></span>Daejeon, Republic of Korea 
<br class="ltx_break">skong@kaist.ac.kr
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kevin Tirta Wijaya
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id11.1.id1" class="ltx_text ltx_font_italic">Robotics Program</span>
<br class="ltx_break"><span id="id12.2.id2" class="ltx_text ltx_font_italic">KAIST
<br class="ltx_break"></span>Daejeon, Republic of Korea 
<br class="ltx_break">kevintirta.w@gmail.com
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.id1" class="ltx_p">Recent works have shown the superior robustness of four-dimensional (4D) Radar-based three-dimensional (3D) object detection in adverse weather conditions.
However, processing 4D Radar data remains a challenge due to the large data size, which require substantial amount of memory for computing and storage.
In previous work, an online density reduction is performed on the 4D Radar Tensor (4DRT) to reduce the data size, in which the density reduction level is chosen arbitrarily.
However, the impact of density reduction on the detection performance and memory consumption remains largely unknown.
In this paper, we aim to address this issue by conducting extensive hyperparamter tuning on the density reduction level.
Experimental results show that increasing the density level from 0.01% to 50% of the original 4DRT density level proportionally improves the detection performance, at a cost of memory consumption.
However, when the density level is increased beyond 5%, only the memory consumption increases, while the detection performance oscillates below the peak point.
In addition to the optimized density hyperparameter, we also introduce 4D Sparse Radar Tensor (4DSRT), a new representation for 4D Radar data with offline density reduction, leading to a significantly reduced raw data size.
An optimized development kit for training the neural networks is also provided, which along with the utilization of 4DSRT, improves training speed by a factor of 17.1 compared to the state-of-the-art 4DRT-based neural networks.
All codes are available at: <span id="id13.id1.1" class="ltx_text ltx_font_italic">https://github.com/kaist-avelab/K-Radar</span>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
4D Radar, 3D object detection, adverse weathers

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">INTRODUCTION</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Perception is an essential module for autonomous driving systems because the information acquired by the perception module will be used as inputs for the subsequent planning and control modules.
Therefore, a robust perception module that can operate under challenging driving conditions (e.g., adverse weather conditions) is urgently needed.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.2" class="ltx_p">In recent years, numerous studies have introduced deep learning-based perception modules with remarkable accuracy for various autonomous driving tasks such as lane detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and object detection<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
These studies often rely on RGB images as inputs to the neural networks, mainly due to the abundance of camera-based datasets available to the public.
In addition, RGB images have a relatively straightforward data structure with low dimensionality and high correlation between neighboring pixels, which enable the neural networks to learn high-dimensional representations efficiently.
However, RGB cameras are vulnerable to low illumination conditions, can be easily obstructed by raindrops and snowflakes, and lack of depth information that is crucial for proper 3D understanding of the surroundings.
In contrast, the LiDAR sensors use infrared signals to measure the surroundings with up to cm-level resolution and without being affected by the illumination conditions.
However, infrared signals with a wavelenght of about <math id="S1.p2.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S1.p2.1.m1.1a"><mi id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><ci id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">\lambda</annotation></semantics></math> = 850nm <math id="S1.p2.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p2.2.m2.1a"><mo id="S1.p2.2.m2.1.1" xref="S1.p2.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><csymbol cd="latexml" id="S1.p2.2.m2.1.1.cmml" xref="S1.p2.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">\sim</annotation></semantics></math> 1,550nm cannot pass through raindrops or snowflakes, which results in unreliable measurements under adverse weather conditions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Radar sensors, on the other hand, utilizes signals with a longer wavelength (<math id="S1.p3.1.m1.1" class="ltx_Math" alttext="\lambda\approx" display="inline"><semantics id="S1.p3.1.m1.1a"><mrow id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml"><mi id="S1.p3.1.m1.1.1.2" xref="S1.p3.1.m1.1.1.2.cmml">λ</mi><mo id="S1.p3.1.m1.1.1.1" xref="S1.p3.1.m1.1.1.1.cmml">≈</mo><mi id="S1.p3.1.m1.1.1.3" xref="S1.p3.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><apply id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1"><approx id="S1.p3.1.m1.1.1.1.cmml" xref="S1.p3.1.m1.1.1.1"></approx><ci id="S1.p3.1.m1.1.1.2.cmml" xref="S1.p3.1.m1.1.1.2">𝜆</ci><csymbol cd="latexml" id="S1.p3.1.m1.1.1.3.cmml" xref="S1.p3.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\lambda\approx</annotation></semantics></math> 4mm) compared to LiDAR sensors.
This enables Radar signals to pass through raindrops and snowflakes, allowing for accurate measurements even under adverse weather conditions.
The robustness of Radar sensors (particularly Frequency Modulated Continuous Wave (FMCW) Radars) in adverse weather conditions has been studied in several works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
Additionally, FMCW Radars can be easily implemented into hardwares, resulting in the widespread use of FMCW Radar in the automotive industry.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2303.06342/assets/fmcw_data_type.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="272" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The signal processing steps of an FMCW Radar to convert the received signals into a dense Radar Tensor (RT). The signals are first processed through RF circuits that include a low noise amplifier (LNA), a local oscillator (LO), and an analog-to-digital converter (ADC). The RT is obtained by applying the Fast Fourier Transform (FFT) algorithm to the processed FMCW signals.</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2303.06342/assets/k-radar_data.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="1196" height="813" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Samples of the K-Radar dataset for various weather conditions. Each column shows (1) 4D Radar tensors (4DRTs), (2) front view camera images, (3) Lidar point clouds (LPCs), and (4<math id="S1.F2.5.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.F2.5.m1.1b"><mo id="S1.F2.5.m1.1.1" xref="S1.F2.5.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.F2.5.m1.1c"><csymbol cd="latexml" id="S1.F2.5.m1.1.1.cmml" xref="S1.F2.5.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.5.m1.1d">\sim</annotation></semantics></math>7) 4D sparse Radar tensors (4DSRTs) with various density (0.01<math id="S1.F2.6.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.F2.6.m2.1b"><mo id="S1.F2.6.m2.1.1" xref="S1.F2.6.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.F2.6.m2.1c"><csymbol cd="latexml" id="S1.F2.6.m2.1.1.cmml" xref="S1.F2.6.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.6.m2.1d">\sim</annotation></semantics></math>10%), where (1<math id="S1.F2.7.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.F2.7.m3.1b"><mo id="S1.F2.7.m3.1.1" xref="S1.F2.7.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.F2.7.m3.1c"><csymbol cd="latexml" id="S1.F2.7.m3.1.1.cmml" xref="S1.F2.7.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.7.m3.1d">\sim</annotation></semantics></math>3) are obtained from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, and (4<math id="S1.F2.8.m4.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.F2.8.m4.1b"><mo id="S1.F2.8.m4.1.1" xref="S1.F2.8.m4.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.F2.8.m4.1c"><csymbol cd="latexml" id="S1.F2.8.m4.1.1.cmml" xref="S1.F2.8.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.8.m4.1d">\sim</annotation></semantics></math>7) are our contributions. 4DRTs are depicted in a two-dimensional Cartesian coordinate system (BEV), since their dense 3D spatial information are hard to be visualized. 4DSRTs are represented in black points with LPCs.</figcaption>
</figure>
<figure id="S1.F3" class="ltx_figure"><img src="/html/2303.06342/assets/rtnh.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="1196" height="318" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Overall structure of Radar Tensor Network with Height (RTNH) and comparison of the two types of Radar data (Radar Tensor and Sparse Radar Tensor). RoI, FM, DFM, and PW denotes region of interests, feature map, dense feature map, and power, respectively.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">As illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, an FMCW Radar output is a Radar Tensor (RT), a dense tensor that is populated by non-zero power measurements in all axes.
The RT is obtained by applying the Fast Fourier Transform (FFT) algorithm on the hardware-processed FMCW signals.
Due to the density, an RT provides rich information regarding the environment, but at a cost of a large amount of memory for storage and computations.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">With the availability of dense RTs, many studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> have proposed RT-based object detection networks that achieve similar detection performance to camera and Lidar-based object detection networks.
In particular, the K-Radar dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> provides a collection of 4D Radar Tensor (4DRT) that consists of power measurements along the Doppler, range, azimuth, and elevation dimensions.
This is in contrast to the conventional 3D Radar tensor (3DRT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> that do not provide elevation information.
The importance of the additional elevation information has been shown in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, where the 4DRT-based Radar Tensor Network with Height (RTNH) significantly outperforms the Radar Tensor Network without height (RTN) in the 3D object detection task.
In addition, the 4DRT-based RTNH achieves similar 3D object detection results to LiDAR point cloud-based (LPC-based) neural network, PointPillars <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, in road environments under clear weather conditions, and significantly outperforms the LPC-based network in adverse weather conditions such as sleet and heavy snow.
These results indicate the importance of 4D Radar sensors for a robust perception in adverse weather conditions.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">While the advantages of 4DRT-based networks are clear, it remains challenging to conduct experiments on the 4DRT data.
This is mainly because of the size of the 4DRT data is prohibitively large (i.e., <math id="S1.p6.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p6.1.m1.1a"><mo id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><csymbol cd="latexml" id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">\sim</annotation></semantics></math>12TB).
In the prior work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, the size of the 4DRT data is reduced by performing a density reduction online during training, where the ouput density level is chosen arbitrarily.
The effects of density reduction on the detection performance and memory consumption, however, remains largely unknown.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">In this paper, we aim to address this issue by conducting extensive hyperparamter tuning on the density reduction level.
As expected, experimental results show that increasing the density level from 0.01% to 50% of the original 4DRT density level proportionally improves the detection performance, at a cost of memory consumption.
Interestingly, however, when the density level is increased beyond 5%, only the memory consumption increases, while the detection performance oscillates below the peak point.
This optimized density reduction level could act as a guide for the automotive radar industry for designing the pre-processing steps at hardwarde-level implementations.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">In addition to the optimized density reduction hyperparameter, we introduce the 4D Sparse Radar Tensor (4DSRT), a new representation for 4D Radar data.
Unlike 4DRT, we perform the polar-to-Cartesian transformation and the density reduction offline, which significantly reduce the raw data size of 4DSRT.
When the 4DSRT is used along with the optimized development kit for training the neural networks, the training speed is improved by a factor of 17.1 times compared with the original 4DRT-based neural networks.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">In a summary, our contributions are as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We conduct an extensive hyperparameter tuning for the density reduction level of the 4DRT. We observe that increasing the density level up to 5% proportionally improves the detection performance, but provides there is no clear benefits beyond that. This insight can serve as a hardware guide for the 4D Radar industry.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We propose 4D sparse Radar Tensor (4DSRT), a new representation for 4D Radar data that allows for a reduction in memory size. The new representation could improve accessibility of 4D Radar data, especially for resource-limited environments.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We provide an optimized devkit for 4DSRT which, when used along with the 4DSRT, could improve the training speed by a factor of 17.1 compared to the 4DRT-based neural networks.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p10" class="ltx_para">
<p id="S1.p10.1" class="ltx_p">The rest of this paper is structured as follows: Section 2 provides an overview of the K-Radar dataset and the 4DRT-based baseline neural network, RTNH. Section 3 explains the 4DSRT data presented in this paper. Section 4 presents the experimental results of the RTNH using 4DSRT with various density. Finally, Section 5 summarizes the paper.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Works</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we provide an overview of the related works, especially on the K-Radar dataset and the Radar Tensor Network with Height (RTNH) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">K-Radar Dataset</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Deep neural networks typically require abundant and diverse training data to be able to generalize to various conditions.
Within the field of autonomous driving, there are numerous publicly-available datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> with a large number of samples, obtained with various types of sensors such as RGB camera, LiDAR, 3D Radar, and 4D Radar.
Among these sensors, 4D Radar has the advantages of preserving 3D spatial information while also being robust to adverse weather conditions such as rain and snow.
However, a large-scale 4D Radar dataset collected from diverse environments including adverse weather conditions has not been available until the introduction of K-Radar <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">K-Radar, as shown in Fig. <a href="#S1.F2" title="Figure 2 ‣ I INTRODUCTION ‣ Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, is a 4DRT-based object detection dataset and benchmark that contains 35K frames of 4DRT data with power measurements along the Doppler, range, azimuth, and elevation dimensions.
It includes challenging driving conditions such as adverse weathers (fog, rain, and snow) and various road structures (urban, suburban roads, alleyways, and highways).
In addition to the 4DRT, auxiliary measurements such as LiDAR point clouds, surround stereo images, and RTK-GPS measurements are also provided.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Radar Tensor Network with Height (RTNH)</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In addition to the dataset, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> also proposes Radar Tensor Network with Height (RTNH), a 4DRT-based 3D object detection network that fully utilizes 3D spatial information available in the 4DRT.
As shown in Fig. <a href="#S1.F3" title="Figure 3 ‣ I INTRODUCTION ‣ Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the RTNH network consists of a pre-processing, a backbone, a neck, and a head.
In the pre-processing, the 4DRT is converted from the polar coordinate into the Cartesian coordinate, resulting in a 3DRT-XYZ within the region of interest (RoI).
Note that the Doppler dimension is reduced by computing the mean value along the dimension.
The backbone then efficiently extracts the feature maps that represent relevant information for bounding box predictions using 3D sparse convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> blocks.
The sparse convolution is performed on the sparse Radar tensor (SRT), which consists of the top-10% of power measurements with the highest values in the 3DRT-XYZ.
Lastly, the head predicts 3D bounding boxes from the concatenated feature maps output of the neck.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">While RTNH outperforms the Radar Tensor Network without height (RTN) in terms of detection performance, the training process of RTNH is relatively slow due to the processing time of a 4DRT, particularly the data reading operation of the 4DRT.
In addition, the prohibitively large 4DRT data size of 12TB becomes a challenge to the accessibility of 4D Radar data, resulting in a slow download speed and high (and potentially costly) storage requirement.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Sparse Radar Tensor</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">As shown in Fig. <a href="#S1.F3" title="Figure 3 ‣ I INTRODUCTION ‣ Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, a 4D Sparse Radar Tensor (4DSRT) is the sparse representation of a 4D Radar Tensor (4DRT) that can be used as an input to 4D Radar-based neural networks such as the RTNH.
To construct a 4DSRT, we transform the 4DRT from a polar coordinate into a Cartesian coordinate, and then perform a pooling operation, where the top-<math id="S3.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">N</annotation></semantics></math>% elements with the highest power measurements are retained.
These post-pooling values are then used as the input to the nural networks.
Note that unlike <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> that performs the coordinate transformation and pooling operation at every iteration of the training process, we only need to perform the transformation and pooling once for each unique 4DRT, and reuse the corresponding 4DSRT for every subsequent iterations.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Compared with a 4DRT, a 4DSRT requires significantly lower memory and number of computations because the number of elements in a 4DSRT is only <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">N</annotation></semantics></math>% of a 4DRT.
As a result, the advantages of utilizing 4DSRT are twofold.
First, the 4DSRT representation improves the accessibility of the K-Radar dataset.
Since the 4D Radar data size is significantly reduced, we can easily host the complete dataset in a commercial cloud-based storage service.
This would bring the advantage of higher uptime and download bandwidth compared with hosting the dataset in a local server, as is the case of the original K-Radar.
Therefore, a higher number of uninterrupted parallel access to the dataset can be supported.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Second, utilizing 4DSRT significantly improves the training speed.
This is because when we train using 4DRTs, the majority of the training time is used for reading the 4DRT elements from the disk, and for pre-processing the 4DRT with Polar-to-Cartesian transform with interpolation that requires a large number of computations.
Because the number of elements in the 4DSRT is significantly smaller, and the pre-processing is only performed once, we observe that the training speed of 4DSRT-based networks can be improved by a factor of 17.1 compared with 4DRT-based networks.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.4" class="ltx_p">One of the most important hyperparameter for 4DSRT is the density reduction level <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p4.1.m1.1a"><mi id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><ci id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">N</annotation></semantics></math>.
In prior work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, for the online density reduction of 4DRT, <math id="S3.p4.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p4.2.m2.1a"><mi id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><ci id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">N</annotation></semantics></math> is arbitrarily chosen as 10%.
However, we observe that <math id="S3.p4.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p4.3.m3.1a"><mi id="S3.p4.3.m3.1.1" xref="S3.p4.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p4.3.m3.1b"><ci id="S3.p4.3.m3.1.1.cmml" xref="S3.p4.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.3.m3.1c">N</annotation></semantics></math> has profound effects on both detection performance and memory consumption, and therefore should be chosen carefuly.
We discuss the most optimal value for <math id="S3.p4.4.m4.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p4.4.m4.1a"><mi id="S3.p4.4.m4.1.1" xref="S3.p4.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p4.4.m4.1b"><ci id="S3.p4.4.m4.1.1.cmml" xref="S3.p4.4.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.4.m4.1c">N</annotation></semantics></math> in Subsection IV. C.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we first describe the experiment setup and metrics that are used in the experiments.
Then, we discuss the experiment results of 4DSRT-based RTNH with various density of 4DSRT.
We also provide a comparison of training speed between 4DSRT-based RTNH and 4DRT-based RTNH.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Experiment Setup</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In the experiments, the networks are implemented with PyTorch 1.11.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> on Ubuntu machines equipped with RTX3090 GPUs.
The batch size is set to 4, and the network is optimized using Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> for 11 epochs with a learning rate of 0.001.
We follow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and set the detection target to the Sedan class, which has the highest number of samples in the K-Radar dataset.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Metric</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">In the experiments, we evaluate the performance of the 3D object detection using Intersection Over Union (IOU)-based Average Precision (AP) metric.
The results are presented in terms of APs for both BEV (<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="AP_{BEV}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS2.p1.1.m1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.3.3.2" xref="S4.SS2.p1.1.m1.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.3.1" xref="S4.SS2.p1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.3.1a" xref="S4.SS2.p1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.3.4" xref="S4.SS2.p1.1.m1.1.1.3.3.4.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">𝐴</ci><apply id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.3.2">𝑃</ci><apply id="S4.SS2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3"><times id="S4.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3.1"></times><ci id="S4.SS2.p1.1.m1.1.1.3.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3.2">𝐵</ci><ci id="S4.SS2.p1.1.m1.1.1.3.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3.3">𝐸</ci><ci id="S4.SS2.p1.1.m1.1.1.3.3.4.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3.4">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">AP_{BEV}</annotation></semantics></math>) and 3D (<math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">​</mo><msub id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml"><mi id="S4.SS2.p1.2.m2.1.1.3.2" xref="S4.SS2.p1.2.m2.1.1.3.2.cmml">P</mi><mrow id="S4.SS2.p1.2.m2.1.1.3.3" xref="S4.SS2.p1.2.m2.1.1.3.3.cmml"><mn id="S4.SS2.p1.2.m2.1.1.3.3.2" xref="S4.SS2.p1.2.m2.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.3.1" xref="S4.SS2.p1.2.m2.1.1.3.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.3.3" xref="S4.SS2.p1.2.m2.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><times id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></times><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">𝐴</ci><apply id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.3.1.cmml" xref="S4.SS2.p1.2.m2.1.1.3">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.3.2.cmml" xref="S4.SS2.p1.2.m2.1.1.3.2">𝑃</ci><apply id="S4.SS2.p1.2.m2.1.1.3.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3.3"><times id="S4.SS2.p1.2.m2.1.1.3.3.1.cmml" xref="S4.SS2.p1.2.m2.1.1.3.3.1"></times><cn type="integer" id="S4.SS2.p1.2.m2.1.1.3.3.2.cmml" xref="S4.SS2.p1.2.m2.1.1.3.3.2">3</cn><ci id="S4.SS2.p1.2.m2.1.1.3.3.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">AP_{3D}</annotation></semantics></math>) bounding box predictions, following the protocol in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, we consider a prediction to be a true positive if the IoU is greater than 0.3.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Comparison of RTNH with 4DSRT of various density</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.9" class="ltx_p">Table <a href="#S4.T1" title="TABLE I ‣ IV-C Comparison of RTNH with 4DSRT of various density ‣ IV Experiments ‣ Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> and Table <a href="#S4.T2" title="TABLE II ‣ IV-C Comparison of RTNH with 4DSRT of various density ‣ IV Experiments ‣ Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> show the <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml"><mi id="S4.SS3.p1.1.m1.1.1.3.2" xref="S4.SS3.p1.1.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS3.p1.1.m1.1.1.3.3" xref="S4.SS3.p1.1.m1.1.1.3.3.cmml"><mn id="S4.SS3.p1.1.m1.1.1.3.3.2" xref="S4.SS3.p1.1.m1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p1.1.m1.1.1.3.3.1" xref="S4.SS3.p1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.1.m1.1.1.3.3.3" xref="S4.SS3.p1.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><times id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></times><ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">𝐴</ci><apply id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.3.1.cmml" xref="S4.SS3.p1.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.3.2.cmml" xref="S4.SS3.p1.1.m1.1.1.3.2">𝑃</ci><apply id="S4.SS3.p1.1.m1.1.1.3.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3.3"><times id="S4.SS3.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS3.p1.1.m1.1.1.3.3.1"></times><cn type="integer" id="S4.SS3.p1.1.m1.1.1.3.3.2.cmml" xref="S4.SS3.p1.1.m1.1.1.3.3.2">3</cn><ci id="S4.SS3.p1.1.m1.1.1.3.3.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">AP_{3D}</annotation></semantics></math> and <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="AP_{BEV}" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml">​</mo><msub id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml"><mi id="S4.SS3.p1.2.m2.1.1.3.2" xref="S4.SS3.p1.2.m2.1.1.3.2.cmml">P</mi><mrow id="S4.SS3.p1.2.m2.1.1.3.3" xref="S4.SS3.p1.2.m2.1.1.3.3.cmml"><mi id="S4.SS3.p1.2.m2.1.1.3.3.2" xref="S4.SS3.p1.2.m2.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.3.3.1" xref="S4.SS3.p1.2.m2.1.1.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.2.m2.1.1.3.3.3" xref="S4.SS3.p1.2.m2.1.1.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.3.3.1a" xref="S4.SS3.p1.2.m2.1.1.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.2.m2.1.1.3.3.4" xref="S4.SS3.p1.2.m2.1.1.3.3.4.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><times id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1"></times><ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">𝐴</ci><apply id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.3.1.cmml" xref="S4.SS3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.3.2">𝑃</ci><apply id="S4.SS3.p1.2.m2.1.1.3.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3"><times id="S4.SS3.p1.2.m2.1.1.3.3.1.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3.1"></times><ci id="S4.SS3.p1.2.m2.1.1.3.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3.2">𝐵</ci><ci id="S4.SS3.p1.2.m2.1.1.3.3.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3.3">𝐸</ci><ci id="S4.SS3.p1.2.m2.1.1.3.3.4.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3.4">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">AP_{BEV}</annotation></semantics></math>, respectively, of 4DSRT-based RTNH networks with various density.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, a density of 10% is arbitrarily chosen as the density level of the input tensor.
However, as we can see in the tables, it is not the most optimal density level when considering the memory consumption and <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="AP" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mrow id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mi id="S4.SS3.p1.3.m3.1.1.2" xref="S4.SS3.p1.3.m3.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.1" xref="S4.SS3.p1.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.1.1.3" xref="S4.SS3.p1.3.m3.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><times id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1.1"></times><ci id="S4.SS3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.p1.3.m3.1.1.2">𝐴</ci><ci id="S4.SS3.p1.3.m3.1.1.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">AP</annotation></semantics></math> performance.
As shown in the tables, the memory consumption grows proportional to the density of the 4DSRT from 205 MB for the 0.01% density level to 802 MB for the 50% density level.
However, increasing the density level does not guarantee an increase in the detection performance.
Specifically, the total <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mrow id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><mi id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.4.m4.1.1.1" xref="S4.SS3.p1.4.m4.1.1.1.cmml">​</mo><msub id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml"><mi id="S4.SS3.p1.4.m4.1.1.3.2" xref="S4.SS3.p1.4.m4.1.1.3.2.cmml">P</mi><mrow id="S4.SS3.p1.4.m4.1.1.3.3" xref="S4.SS3.p1.4.m4.1.1.3.3.cmml"><mn id="S4.SS3.p1.4.m4.1.1.3.3.2" xref="S4.SS3.p1.4.m4.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p1.4.m4.1.1.3.3.1" xref="S4.SS3.p1.4.m4.1.1.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.4.m4.1.1.3.3.3" xref="S4.SS3.p1.4.m4.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><times id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1"></times><ci id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2">𝐴</ci><apply id="S4.SS3.p1.4.m4.1.1.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.4.m4.1.1.3.1.cmml" xref="S4.SS3.p1.4.m4.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.4.m4.1.1.3.2.cmml" xref="S4.SS3.p1.4.m4.1.1.3.2">𝑃</ci><apply id="S4.SS3.p1.4.m4.1.1.3.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3.3"><times id="S4.SS3.p1.4.m4.1.1.3.3.1.cmml" xref="S4.SS3.p1.4.m4.1.1.3.3.1"></times><cn type="integer" id="S4.SS3.p1.4.m4.1.1.3.3.2.cmml" xref="S4.SS3.p1.4.m4.1.1.3.3.2">3</cn><ci id="S4.SS3.p1.4.m4.1.1.3.3.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">AP_{3D}</annotation></semantics></math> and total <math id="S4.SS3.p1.5.m5.1" class="ltx_Math" alttext="AP_{BEV}" display="inline"><semantics id="S4.SS3.p1.5.m5.1a"><mrow id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><mi id="S4.SS3.p1.5.m5.1.1.2" xref="S4.SS3.p1.5.m5.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.5.m5.1.1.1" xref="S4.SS3.p1.5.m5.1.1.1.cmml">​</mo><msub id="S4.SS3.p1.5.m5.1.1.3" xref="S4.SS3.p1.5.m5.1.1.3.cmml"><mi id="S4.SS3.p1.5.m5.1.1.3.2" xref="S4.SS3.p1.5.m5.1.1.3.2.cmml">P</mi><mrow id="S4.SS3.p1.5.m5.1.1.3.3" xref="S4.SS3.p1.5.m5.1.1.3.3.cmml"><mi id="S4.SS3.p1.5.m5.1.1.3.3.2" xref="S4.SS3.p1.5.m5.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.5.m5.1.1.3.3.1" xref="S4.SS3.p1.5.m5.1.1.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.5.m5.1.1.3.3.3" xref="S4.SS3.p1.5.m5.1.1.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.5.m5.1.1.3.3.1a" xref="S4.SS3.p1.5.m5.1.1.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.5.m5.1.1.3.3.4" xref="S4.SS3.p1.5.m5.1.1.3.3.4.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><times id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1.1"></times><ci id="S4.SS3.p1.5.m5.1.1.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2">𝐴</ci><apply id="S4.SS3.p1.5.m5.1.1.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m5.1.1.3.1.cmml" xref="S4.SS3.p1.5.m5.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.5.m5.1.1.3.2.cmml" xref="S4.SS3.p1.5.m5.1.1.3.2">𝑃</ci><apply id="S4.SS3.p1.5.m5.1.1.3.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3"><times id="S4.SS3.p1.5.m5.1.1.3.3.1.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3.1"></times><ci id="S4.SS3.p1.5.m5.1.1.3.3.2.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3.2">𝐵</ci><ci id="S4.SS3.p1.5.m5.1.1.3.3.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3.3">𝐸</ci><ci id="S4.SS3.p1.5.m5.1.1.3.3.4.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3.4">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">AP_{BEV}</annotation></semantics></math> increases proportionally to the density of the 4DSRT only from 0.01% density level to 5% density level, with peak performance of <math id="S4.SS3.p1.6.m6.1" class="ltx_Math" alttext="AP_{3D}=47.9\%" display="inline"><semantics id="S4.SS3.p1.6.m6.1a"><mrow id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml"><mrow id="S4.SS3.p1.6.m6.1.1.2" xref="S4.SS3.p1.6.m6.1.1.2.cmml"><mi id="S4.SS3.p1.6.m6.1.1.2.2" xref="S4.SS3.p1.6.m6.1.1.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.6.m6.1.1.2.1" xref="S4.SS3.p1.6.m6.1.1.2.1.cmml">​</mo><msub id="S4.SS3.p1.6.m6.1.1.2.3" xref="S4.SS3.p1.6.m6.1.1.2.3.cmml"><mi id="S4.SS3.p1.6.m6.1.1.2.3.2" xref="S4.SS3.p1.6.m6.1.1.2.3.2.cmml">P</mi><mrow id="S4.SS3.p1.6.m6.1.1.2.3.3" xref="S4.SS3.p1.6.m6.1.1.2.3.3.cmml"><mn id="S4.SS3.p1.6.m6.1.1.2.3.3.2" xref="S4.SS3.p1.6.m6.1.1.2.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p1.6.m6.1.1.2.3.3.1" xref="S4.SS3.p1.6.m6.1.1.2.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.6.m6.1.1.2.3.3.3" xref="S4.SS3.p1.6.m6.1.1.2.3.3.3.cmml">D</mi></mrow></msub></mrow><mo id="S4.SS3.p1.6.m6.1.1.1" xref="S4.SS3.p1.6.m6.1.1.1.cmml">=</mo><mrow id="S4.SS3.p1.6.m6.1.1.3" xref="S4.SS3.p1.6.m6.1.1.3.cmml"><mn id="S4.SS3.p1.6.m6.1.1.3.2" xref="S4.SS3.p1.6.m6.1.1.3.2.cmml">47.9</mn><mo id="S4.SS3.p1.6.m6.1.1.3.1" xref="S4.SS3.p1.6.m6.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><apply id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1"><eq id="S4.SS3.p1.6.m6.1.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1.1"></eq><apply id="S4.SS3.p1.6.m6.1.1.2.cmml" xref="S4.SS3.p1.6.m6.1.1.2"><times id="S4.SS3.p1.6.m6.1.1.2.1.cmml" xref="S4.SS3.p1.6.m6.1.1.2.1"></times><ci id="S4.SS3.p1.6.m6.1.1.2.2.cmml" xref="S4.SS3.p1.6.m6.1.1.2.2">𝐴</ci><apply id="S4.SS3.p1.6.m6.1.1.2.3.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS3.p1.6.m6.1.1.2.3.1.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3">subscript</csymbol><ci id="S4.SS3.p1.6.m6.1.1.2.3.2.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3.2">𝑃</ci><apply id="S4.SS3.p1.6.m6.1.1.2.3.3.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3.3"><times id="S4.SS3.p1.6.m6.1.1.2.3.3.1.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3.3.1"></times><cn type="integer" id="S4.SS3.p1.6.m6.1.1.2.3.3.2.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3.3.2">3</cn><ci id="S4.SS3.p1.6.m6.1.1.2.3.3.3.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3.3.3">𝐷</ci></apply></apply></apply><apply id="S4.SS3.p1.6.m6.1.1.3.cmml" xref="S4.SS3.p1.6.m6.1.1.3"><csymbol cd="latexml" id="S4.SS3.p1.6.m6.1.1.3.1.cmml" xref="S4.SS3.p1.6.m6.1.1.3.1">percent</csymbol><cn type="float" id="S4.SS3.p1.6.m6.1.1.3.2.cmml" xref="S4.SS3.p1.6.m6.1.1.3.2">47.9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">AP_{3D}=47.9\%</annotation></semantics></math> at 5% density level and <math id="S4.SS3.p1.7.m7.1" class="ltx_Math" alttext="AP_{BEV}=61.9\%" display="inline"><semantics id="S4.SS3.p1.7.m7.1a"><mrow id="S4.SS3.p1.7.m7.1.1" xref="S4.SS3.p1.7.m7.1.1.cmml"><mrow id="S4.SS3.p1.7.m7.1.1.2" xref="S4.SS3.p1.7.m7.1.1.2.cmml"><mi id="S4.SS3.p1.7.m7.1.1.2.2" xref="S4.SS3.p1.7.m7.1.1.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.7.m7.1.1.2.1" xref="S4.SS3.p1.7.m7.1.1.2.1.cmml">​</mo><msub id="S4.SS3.p1.7.m7.1.1.2.3" xref="S4.SS3.p1.7.m7.1.1.2.3.cmml"><mi id="S4.SS3.p1.7.m7.1.1.2.3.2" xref="S4.SS3.p1.7.m7.1.1.2.3.2.cmml">P</mi><mrow id="S4.SS3.p1.7.m7.1.1.2.3.3" xref="S4.SS3.p1.7.m7.1.1.2.3.3.cmml"><mi id="S4.SS3.p1.7.m7.1.1.2.3.3.2" xref="S4.SS3.p1.7.m7.1.1.2.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.7.m7.1.1.2.3.3.1" xref="S4.SS3.p1.7.m7.1.1.2.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.7.m7.1.1.2.3.3.3" xref="S4.SS3.p1.7.m7.1.1.2.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.7.m7.1.1.2.3.3.1a" xref="S4.SS3.p1.7.m7.1.1.2.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.7.m7.1.1.2.3.3.4" xref="S4.SS3.p1.7.m7.1.1.2.3.3.4.cmml">V</mi></mrow></msub></mrow><mo id="S4.SS3.p1.7.m7.1.1.1" xref="S4.SS3.p1.7.m7.1.1.1.cmml">=</mo><mrow id="S4.SS3.p1.7.m7.1.1.3" xref="S4.SS3.p1.7.m7.1.1.3.cmml"><mn id="S4.SS3.p1.7.m7.1.1.3.2" xref="S4.SS3.p1.7.m7.1.1.3.2.cmml">61.9</mn><mo id="S4.SS3.p1.7.m7.1.1.3.1" xref="S4.SS3.p1.7.m7.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m7.1b"><apply id="S4.SS3.p1.7.m7.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1"><eq id="S4.SS3.p1.7.m7.1.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1.1"></eq><apply id="S4.SS3.p1.7.m7.1.1.2.cmml" xref="S4.SS3.p1.7.m7.1.1.2"><times id="S4.SS3.p1.7.m7.1.1.2.1.cmml" xref="S4.SS3.p1.7.m7.1.1.2.1"></times><ci id="S4.SS3.p1.7.m7.1.1.2.2.cmml" xref="S4.SS3.p1.7.m7.1.1.2.2">𝐴</ci><apply id="S4.SS3.p1.7.m7.1.1.2.3.cmml" xref="S4.SS3.p1.7.m7.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS3.p1.7.m7.1.1.2.3.1.cmml" xref="S4.SS3.p1.7.m7.1.1.2.3">subscript</csymbol><ci id="S4.SS3.p1.7.m7.1.1.2.3.2.cmml" xref="S4.SS3.p1.7.m7.1.1.2.3.2">𝑃</ci><apply id="S4.SS3.p1.7.m7.1.1.2.3.3.cmml" xref="S4.SS3.p1.7.m7.1.1.2.3.3"><times id="S4.SS3.p1.7.m7.1.1.2.3.3.1.cmml" xref="S4.SS3.p1.7.m7.1.1.2.3.3.1"></times><ci id="S4.SS3.p1.7.m7.1.1.2.3.3.2.cmml" xref="S4.SS3.p1.7.m7.1.1.2.3.3.2">𝐵</ci><ci id="S4.SS3.p1.7.m7.1.1.2.3.3.3.cmml" xref="S4.SS3.p1.7.m7.1.1.2.3.3.3">𝐸</ci><ci id="S4.SS3.p1.7.m7.1.1.2.3.3.4.cmml" xref="S4.SS3.p1.7.m7.1.1.2.3.3.4">𝑉</ci></apply></apply></apply><apply id="S4.SS3.p1.7.m7.1.1.3.cmml" xref="S4.SS3.p1.7.m7.1.1.3"><csymbol cd="latexml" id="S4.SS3.p1.7.m7.1.1.3.1.cmml" xref="S4.SS3.p1.7.m7.1.1.3.1">percent</csymbol><cn type="float" id="S4.SS3.p1.7.m7.1.1.3.2.cmml" xref="S4.SS3.p1.7.m7.1.1.3.2">61.9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.7.m7.1c">AP_{BEV}=61.9\%</annotation></semantics></math> at 3% density level.
For density levels over 5%, the detection performance oscillates at <math id="S4.SS3.p1.8.m8.1" class="ltx_Math" alttext="AP_{3D}\approx 47\%" display="inline"><semantics id="S4.SS3.p1.8.m8.1a"><mrow id="S4.SS3.p1.8.m8.1.1" xref="S4.SS3.p1.8.m8.1.1.cmml"><mrow id="S4.SS3.p1.8.m8.1.1.2" xref="S4.SS3.p1.8.m8.1.1.2.cmml"><mi id="S4.SS3.p1.8.m8.1.1.2.2" xref="S4.SS3.p1.8.m8.1.1.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.8.m8.1.1.2.1" xref="S4.SS3.p1.8.m8.1.1.2.1.cmml">​</mo><msub id="S4.SS3.p1.8.m8.1.1.2.3" xref="S4.SS3.p1.8.m8.1.1.2.3.cmml"><mi id="S4.SS3.p1.8.m8.1.1.2.3.2" xref="S4.SS3.p1.8.m8.1.1.2.3.2.cmml">P</mi><mrow id="S4.SS3.p1.8.m8.1.1.2.3.3" xref="S4.SS3.p1.8.m8.1.1.2.3.3.cmml"><mn id="S4.SS3.p1.8.m8.1.1.2.3.3.2" xref="S4.SS3.p1.8.m8.1.1.2.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p1.8.m8.1.1.2.3.3.1" xref="S4.SS3.p1.8.m8.1.1.2.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.8.m8.1.1.2.3.3.3" xref="S4.SS3.p1.8.m8.1.1.2.3.3.3.cmml">D</mi></mrow></msub></mrow><mo id="S4.SS3.p1.8.m8.1.1.1" xref="S4.SS3.p1.8.m8.1.1.1.cmml">≈</mo><mrow id="S4.SS3.p1.8.m8.1.1.3" xref="S4.SS3.p1.8.m8.1.1.3.cmml"><mn id="S4.SS3.p1.8.m8.1.1.3.2" xref="S4.SS3.p1.8.m8.1.1.3.2.cmml">47</mn><mo id="S4.SS3.p1.8.m8.1.1.3.1" xref="S4.SS3.p1.8.m8.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.8.m8.1b"><apply id="S4.SS3.p1.8.m8.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1"><approx id="S4.SS3.p1.8.m8.1.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1"></approx><apply id="S4.SS3.p1.8.m8.1.1.2.cmml" xref="S4.SS3.p1.8.m8.1.1.2"><times id="S4.SS3.p1.8.m8.1.1.2.1.cmml" xref="S4.SS3.p1.8.m8.1.1.2.1"></times><ci id="S4.SS3.p1.8.m8.1.1.2.2.cmml" xref="S4.SS3.p1.8.m8.1.1.2.2">𝐴</ci><apply id="S4.SS3.p1.8.m8.1.1.2.3.cmml" xref="S4.SS3.p1.8.m8.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.2.3.1.cmml" xref="S4.SS3.p1.8.m8.1.1.2.3">subscript</csymbol><ci id="S4.SS3.p1.8.m8.1.1.2.3.2.cmml" xref="S4.SS3.p1.8.m8.1.1.2.3.2">𝑃</ci><apply id="S4.SS3.p1.8.m8.1.1.2.3.3.cmml" xref="S4.SS3.p1.8.m8.1.1.2.3.3"><times id="S4.SS3.p1.8.m8.1.1.2.3.3.1.cmml" xref="S4.SS3.p1.8.m8.1.1.2.3.3.1"></times><cn type="integer" id="S4.SS3.p1.8.m8.1.1.2.3.3.2.cmml" xref="S4.SS3.p1.8.m8.1.1.2.3.3.2">3</cn><ci id="S4.SS3.p1.8.m8.1.1.2.3.3.3.cmml" xref="S4.SS3.p1.8.m8.1.1.2.3.3.3">𝐷</ci></apply></apply></apply><apply id="S4.SS3.p1.8.m8.1.1.3.cmml" xref="S4.SS3.p1.8.m8.1.1.3"><csymbol cd="latexml" id="S4.SS3.p1.8.m8.1.1.3.1.cmml" xref="S4.SS3.p1.8.m8.1.1.3.1">percent</csymbol><cn type="integer" id="S4.SS3.p1.8.m8.1.1.3.2.cmml" xref="S4.SS3.p1.8.m8.1.1.3.2">47</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.8.m8.1c">AP_{3D}\approx 47\%</annotation></semantics></math> and <math id="S4.SS3.p1.9.m9.1" class="ltx_Math" alttext="AP_{BEV}\approx 57\%" display="inline"><semantics id="S4.SS3.p1.9.m9.1a"><mrow id="S4.SS3.p1.9.m9.1.1" xref="S4.SS3.p1.9.m9.1.1.cmml"><mrow id="S4.SS3.p1.9.m9.1.1.2" xref="S4.SS3.p1.9.m9.1.1.2.cmml"><mi id="S4.SS3.p1.9.m9.1.1.2.2" xref="S4.SS3.p1.9.m9.1.1.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.9.m9.1.1.2.1" xref="S4.SS3.p1.9.m9.1.1.2.1.cmml">​</mo><msub id="S4.SS3.p1.9.m9.1.1.2.3" xref="S4.SS3.p1.9.m9.1.1.2.3.cmml"><mi id="S4.SS3.p1.9.m9.1.1.2.3.2" xref="S4.SS3.p1.9.m9.1.1.2.3.2.cmml">P</mi><mrow id="S4.SS3.p1.9.m9.1.1.2.3.3" xref="S4.SS3.p1.9.m9.1.1.2.3.3.cmml"><mi id="S4.SS3.p1.9.m9.1.1.2.3.3.2" xref="S4.SS3.p1.9.m9.1.1.2.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.9.m9.1.1.2.3.3.1" xref="S4.SS3.p1.9.m9.1.1.2.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.9.m9.1.1.2.3.3.3" xref="S4.SS3.p1.9.m9.1.1.2.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.9.m9.1.1.2.3.3.1a" xref="S4.SS3.p1.9.m9.1.1.2.3.3.1.cmml">​</mo><mi id="S4.SS3.p1.9.m9.1.1.2.3.3.4" xref="S4.SS3.p1.9.m9.1.1.2.3.3.4.cmml">V</mi></mrow></msub></mrow><mo id="S4.SS3.p1.9.m9.1.1.1" xref="S4.SS3.p1.9.m9.1.1.1.cmml">≈</mo><mrow id="S4.SS3.p1.9.m9.1.1.3" xref="S4.SS3.p1.9.m9.1.1.3.cmml"><mn id="S4.SS3.p1.9.m9.1.1.3.2" xref="S4.SS3.p1.9.m9.1.1.3.2.cmml">57</mn><mo id="S4.SS3.p1.9.m9.1.1.3.1" xref="S4.SS3.p1.9.m9.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.9.m9.1b"><apply id="S4.SS3.p1.9.m9.1.1.cmml" xref="S4.SS3.p1.9.m9.1.1"><approx id="S4.SS3.p1.9.m9.1.1.1.cmml" xref="S4.SS3.p1.9.m9.1.1.1"></approx><apply id="S4.SS3.p1.9.m9.1.1.2.cmml" xref="S4.SS3.p1.9.m9.1.1.2"><times id="S4.SS3.p1.9.m9.1.1.2.1.cmml" xref="S4.SS3.p1.9.m9.1.1.2.1"></times><ci id="S4.SS3.p1.9.m9.1.1.2.2.cmml" xref="S4.SS3.p1.9.m9.1.1.2.2">𝐴</ci><apply id="S4.SS3.p1.9.m9.1.1.2.3.cmml" xref="S4.SS3.p1.9.m9.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS3.p1.9.m9.1.1.2.3.1.cmml" xref="S4.SS3.p1.9.m9.1.1.2.3">subscript</csymbol><ci id="S4.SS3.p1.9.m9.1.1.2.3.2.cmml" xref="S4.SS3.p1.9.m9.1.1.2.3.2">𝑃</ci><apply id="S4.SS3.p1.9.m9.1.1.2.3.3.cmml" xref="S4.SS3.p1.9.m9.1.1.2.3.3"><times id="S4.SS3.p1.9.m9.1.1.2.3.3.1.cmml" xref="S4.SS3.p1.9.m9.1.1.2.3.3.1"></times><ci id="S4.SS3.p1.9.m9.1.1.2.3.3.2.cmml" xref="S4.SS3.p1.9.m9.1.1.2.3.3.2">𝐵</ci><ci id="S4.SS3.p1.9.m9.1.1.2.3.3.3.cmml" xref="S4.SS3.p1.9.m9.1.1.2.3.3.3">𝐸</ci><ci id="S4.SS3.p1.9.m9.1.1.2.3.3.4.cmml" xref="S4.SS3.p1.9.m9.1.1.2.3.3.4">𝑉</ci></apply></apply></apply><apply id="S4.SS3.p1.9.m9.1.1.3.cmml" xref="S4.SS3.p1.9.m9.1.1.3"><csymbol cd="latexml" id="S4.SS3.p1.9.m9.1.1.3.1.cmml" xref="S4.SS3.p1.9.m9.1.1.3.1">percent</csymbol><cn type="integer" id="S4.SS3.p1.9.m9.1.1.3.2.cmml" xref="S4.SS3.p1.9.m9.1.1.3.2">57</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.9.m9.1c">AP_{BEV}\approx 57\%</annotation></semantics></math>.
These results, which is intuitively illustrated in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-C Comparison of RTNH with 4DSRT of various density ‣ IV Experiments ‣ Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, provide a valuable insight on the optimal value for 4DSRT density level, and can be used as a guideline for hardware-level implementation in the automotive radar industry <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>3D detection performance comparison of RTNH with inputs of 4DSRT of various density. We report the average precision (<math id="S4.T1.2.m1.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S4.T1.2.m1.1b"><mrow id="S4.T1.2.m1.1.1" xref="S4.T1.2.m1.1.1.cmml"><mi id="S4.T1.2.m1.1.1.2" xref="S4.T1.2.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.T1.2.m1.1.1.1" xref="S4.T1.2.m1.1.1.1.cmml">​</mo><msub id="S4.T1.2.m1.1.1.3" xref="S4.T1.2.m1.1.1.3.cmml"><mi id="S4.T1.2.m1.1.1.3.2" xref="S4.T1.2.m1.1.1.3.2.cmml">P</mi><mrow id="S4.T1.2.m1.1.1.3.3" xref="S4.T1.2.m1.1.1.3.3.cmml"><mn id="S4.T1.2.m1.1.1.3.3.2" xref="S4.T1.2.m1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.T1.2.m1.1.1.3.3.1" xref="S4.T1.2.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.T1.2.m1.1.1.3.3.3" xref="S4.T1.2.m1.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.2.m1.1c"><apply id="S4.T1.2.m1.1.1.cmml" xref="S4.T1.2.m1.1.1"><times id="S4.T1.2.m1.1.1.1.cmml" xref="S4.T1.2.m1.1.1.1"></times><ci id="S4.T1.2.m1.1.1.2.cmml" xref="S4.T1.2.m1.1.1.2">𝐴</ci><apply id="S4.T1.2.m1.1.1.3.cmml" xref="S4.T1.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T1.2.m1.1.1.3.1.cmml" xref="S4.T1.2.m1.1.1.3">subscript</csymbol><ci id="S4.T1.2.m1.1.1.3.2.cmml" xref="S4.T1.2.m1.1.1.3.2">𝑃</ci><apply id="S4.T1.2.m1.1.1.3.3.cmml" xref="S4.T1.2.m1.1.1.3.3"><times id="S4.T1.2.m1.1.1.3.3.1.cmml" xref="S4.T1.2.m1.1.1.3.3.1"></times><cn type="integer" id="S4.T1.2.m1.1.1.3.3.2.cmml" xref="S4.T1.2.m1.1.1.3.3.2">3</cn><ci id="S4.T1.2.m1.1.1.3.3.3.cmml" xref="S4.T1.2.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.m1.1d">AP_{3D}</annotation></semantics></math>) of the total test set and individual weather conditions.</figcaption>
<table id="S4.T1.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.3.1.1" class="ltx_tr">
<th id="S4.T1.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T1.3.1.1.1.1" class="ltx_text ltx_font_bold">Density[%]</span></th>
<th id="S4.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T1.3.1.1.2.1" class="ltx_text ltx_font_bold">GPU RAM[MB]</span></th>
<th id="S4.T1.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T1.3.1.1.3.1" class="ltx_text ltx_font_bold">Total[%]</span></th>
<th id="S4.T1.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.3.1.1.4.1" class="ltx_text ltx_font_bold">Normal[%]</span></th>
<th id="S4.T1.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.3.1.1.5.1" class="ltx_text ltx_font_bold">Overcast[%]</span></th>
<th id="S4.T1.3.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.3.1.1.6.1" class="ltx_text ltx_font_bold">Fog[%]</span></th>
<th id="S4.T1.3.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.3.1.1.7.1" class="ltx_text ltx_font_bold">Rain[%]</span></th>
<th id="S4.T1.3.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.3.1.1.8.1" class="ltx_text ltx_font_bold">Sleet[%]</span></th>
<th id="S4.T1.3.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.3.1.1.9.1" class="ltx_text ltx_font_bold">Light snow[%]</span></th>
<th id="S4.T1.3.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.3.1.1.10.1" class="ltx_text ltx_font_bold">Heavy snow[%]</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.3.2.1" class="ltx_tr">
<th id="S4.T1.3.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">0.01</th>
<th id="S4.T1.3.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T1.3.2.1.2.1" class="ltx_text ltx_font_bold">205</span></th>
<th id="S4.T1.3.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">16.8</th>
<td id="S4.T1.3.2.1.4" class="ltx_td ltx_align_center ltx_border_t">18.3</td>
<td id="S4.T1.3.2.1.5" class="ltx_td ltx_align_center ltx_border_t">13.6</td>
<td id="S4.T1.3.2.1.6" class="ltx_td ltx_align_center ltx_border_t">23.5</td>
<td id="S4.T1.3.2.1.7" class="ltx_td ltx_align_center ltx_border_t">16.9</td>
<td id="S4.T1.3.2.1.8" class="ltx_td ltx_align_center ltx_border_t">27.1</td>
<td id="S4.T1.3.2.1.9" class="ltx_td ltx_align_center ltx_border_t">23.1</td>
<td id="S4.T1.3.2.1.10" class="ltx_td ltx_align_center ltx_border_t">32.2</td>
</tr>
<tr id="S4.T1.3.3.2" class="ltx_tr">
<th id="S4.T1.3.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<th id="S4.T1.3.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">212</th>
<th id="S4.T1.3.3.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">35.2</th>
<td id="S4.T1.3.3.2.4" class="ltx_td ltx_align_center">34.9</td>
<td id="S4.T1.3.3.2.5" class="ltx_td ltx_align_center">30.9</td>
<td id="S4.T1.3.3.2.6" class="ltx_td ltx_align_center">53.8</td>
<td id="S4.T1.3.3.2.7" class="ltx_td ltx_align_center">26.9</td>
<td id="S4.T1.3.3.2.8" class="ltx_td ltx_align_center">33.4</td>
<td id="S4.T1.3.3.2.9" class="ltx_td ltx_align_center">41.8</td>
<td id="S4.T1.3.3.2.10" class="ltx_td ltx_align_center">41.6</td>
</tr>
<tr id="S4.T1.3.4.3" class="ltx_tr">
<th id="S4.T1.3.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1</th>
<th id="S4.T1.3.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">245</th>
<th id="S4.T1.3.4.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">43.0</th>
<td id="S4.T1.3.4.3.4" class="ltx_td ltx_align_center">45.0</td>
<td id="S4.T1.3.4.3.5" class="ltx_td ltx_align_center">43.2</td>
<td id="S4.T1.3.4.3.6" class="ltx_td ltx_align_center">48.0</td>
<td id="S4.T1.3.4.3.7" class="ltx_td ltx_align_center">35.4</td>
<td id="S4.T1.3.4.3.8" class="ltx_td ltx_align_center"><span id="S4.T1.3.4.3.8.1" class="ltx_text ltx_font_bold">41.8</span></td>
<td id="S4.T1.3.4.3.9" class="ltx_td ltx_align_center">57.7</td>
<td id="S4.T1.3.4.3.10" class="ltx_td ltx_align_center">41.0</td>
</tr>
<tr id="S4.T1.3.5.4" class="ltx_tr">
<th id="S4.T1.3.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3</th>
<th id="S4.T1.3.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">325</th>
<th id="S4.T1.3.5.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">44.6</th>
<td id="S4.T1.3.5.4.4" class="ltx_td ltx_align_center">49.4</td>
<td id="S4.T1.3.5.4.5" class="ltx_td ltx_align_center">52.5</td>
<td id="S4.T1.3.5.4.6" class="ltx_td ltx_align_center">52.1</td>
<td id="S4.T1.3.5.4.7" class="ltx_td ltx_align_center">36.3</td>
<td id="S4.T1.3.5.4.8" class="ltx_td ltx_align_center">37.5</td>
<td id="S4.T1.3.5.4.9" class="ltx_td ltx_align_center"><span id="S4.T1.3.5.4.9.1" class="ltx_text ltx_font_bold">59.5</span></td>
<td id="S4.T1.3.5.4.10" class="ltx_td ltx_align_center">44.2</td>
</tr>
<tr id="S4.T1.3.6.5" class="ltx_tr">
<th id="S4.T1.3.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">5</th>
<th id="S4.T1.3.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">380</th>
<th id="S4.T1.3.6.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.3.6.5.3.1" class="ltx_text ltx_font_bold">47.9</span></th>
<td id="S4.T1.3.6.5.4" class="ltx_td ltx_align_center">50.4</td>
<td id="S4.T1.3.6.5.5" class="ltx_td ltx_align_center">56.5</td>
<td id="S4.T1.3.6.5.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.5.6.1" class="ltx_text ltx_font_bold">60.4</span></td>
<td id="S4.T1.3.6.5.7" class="ltx_td ltx_align_center">38.8</td>
<td id="S4.T1.3.6.5.8" class="ltx_td ltx_align_center">39.2</td>
<td id="S4.T1.3.6.5.9" class="ltx_td ltx_align_center">53.2</td>
<td id="S4.T1.3.6.5.10" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.5.10.1" class="ltx_text ltx_font_bold">50.3</span></td>
</tr>
<tr id="S4.T1.3.7.6" class="ltx_tr">
<th id="S4.T1.3.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">10</th>
<th id="S4.T1.3.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">421</th>
<th id="S4.T1.3.7.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">47.4</th>
<td id="S4.T1.3.7.6.4" class="ltx_td ltx_align_center">49.9</td>
<td id="S4.T1.3.7.6.5" class="ltx_td ltx_align_center">56.7</td>
<td id="S4.T1.3.7.6.6" class="ltx_td ltx_align_center">52.8</td>
<td id="S4.T1.3.7.6.7" class="ltx_td ltx_align_center">42.0</td>
<td id="S4.T1.3.7.6.8" class="ltx_td ltx_align_center">41.5</td>
<td id="S4.T1.3.7.6.9" class="ltx_td ltx_align_center">50.6</td>
<td id="S4.T1.3.7.6.10" class="ltx_td ltx_align_center">44.5</td>
</tr>
<tr id="S4.T1.3.8.7" class="ltx_tr">
<th id="S4.T1.3.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">15</th>
<th id="S4.T1.3.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">567</th>
<th id="S4.T1.3.8.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">46.9</th>
<td id="S4.T1.3.8.7.4" class="ltx_td ltx_align_center">50.0</td>
<td id="S4.T1.3.8.7.5" class="ltx_td ltx_align_center">56.5</td>
<td id="S4.T1.3.8.7.6" class="ltx_td ltx_align_center">57.2</td>
<td id="S4.T1.3.8.7.7" class="ltx_td ltx_align_center">39.3</td>
<td id="S4.T1.3.8.7.8" class="ltx_td ltx_align_center">30.4</td>
<td id="S4.T1.3.8.7.9" class="ltx_td ltx_align_center">51.0</td>
<td id="S4.T1.3.8.7.10" class="ltx_td ltx_align_center">41.3</td>
</tr>
<tr id="S4.T1.3.9.8" class="ltx_tr">
<th id="S4.T1.3.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">20</th>
<th id="S4.T1.3.9.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">623</th>
<th id="S4.T1.3.9.8.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">47.1</th>
<td id="S4.T1.3.9.8.4" class="ltx_td ltx_align_center">49.0</td>
<td id="S4.T1.3.9.8.5" class="ltx_td ltx_align_center">57.4</td>
<td id="S4.T1.3.9.8.6" class="ltx_td ltx_align_center">56.6</td>
<td id="S4.T1.3.9.8.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.9.8.7.1" class="ltx_text ltx_font_bold">42.3</span></td>
<td id="S4.T1.3.9.8.8" class="ltx_td ltx_align_center">30.6</td>
<td id="S4.T1.3.9.8.9" class="ltx_td ltx_align_center">52.0</td>
<td id="S4.T1.3.9.8.10" class="ltx_td ltx_align_center">48.9</td>
</tr>
<tr id="S4.T1.3.10.9" class="ltx_tr">
<th id="S4.T1.3.10.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">30</th>
<th id="S4.T1.3.10.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">697</th>
<th id="S4.T1.3.10.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">45.4</th>
<td id="S4.T1.3.10.9.4" class="ltx_td ltx_align_center">48.7</td>
<td id="S4.T1.3.10.9.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.10.9.5.1" class="ltx_text ltx_font_bold">57.7</span></td>
<td id="S4.T1.3.10.9.6" class="ltx_td ltx_align_center">52.3</td>
<td id="S4.T1.3.10.9.7" class="ltx_td ltx_align_center">40.6</td>
<td id="S4.T1.3.10.9.8" class="ltx_td ltx_align_center">24.4</td>
<td id="S4.T1.3.10.9.9" class="ltx_td ltx_align_center">51.6</td>
<td id="S4.T1.3.10.9.10" class="ltx_td ltx_align_center">41.0</td>
</tr>
<tr id="S4.T1.3.11.10" class="ltx_tr">
<th id="S4.T1.3.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">50</th>
<th id="S4.T1.3.11.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">802</th>
<th id="S4.T1.3.11.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">46.1</th>
<td id="S4.T1.3.11.10.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T1.3.11.10.4.1" class="ltx_text ltx_font_bold">50.6</span></td>
<td id="S4.T1.3.11.10.5" class="ltx_td ltx_align_center ltx_border_b">55.0</td>
<td id="S4.T1.3.11.10.6" class="ltx_td ltx_align_center ltx_border_b">54.5</td>
<td id="S4.T1.3.11.10.7" class="ltx_td ltx_align_center ltx_border_b">38.2</td>
<td id="S4.T1.3.11.10.8" class="ltx_td ltx_align_center ltx_border_b">22.2</td>
<td id="S4.T1.3.11.10.9" class="ltx_td ltx_align_center ltx_border_b">57.6</td>
<td id="S4.T1.3.11.10.10" class="ltx_td ltx_align_center ltx_border_b">49.5</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>BEV detection performance comparison of RTNH with inputs of 4DSRT of various density. We report the average precision (<math id="S4.T2.2.m1.1" class="ltx_Math" alttext="AP_{BEV}" display="inline"><semantics id="S4.T2.2.m1.1b"><mrow id="S4.T2.2.m1.1.1" xref="S4.T2.2.m1.1.1.cmml"><mi id="S4.T2.2.m1.1.1.2" xref="S4.T2.2.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.T2.2.m1.1.1.1" xref="S4.T2.2.m1.1.1.1.cmml">​</mo><msub id="S4.T2.2.m1.1.1.3" xref="S4.T2.2.m1.1.1.3.cmml"><mi id="S4.T2.2.m1.1.1.3.2" xref="S4.T2.2.m1.1.1.3.2.cmml">P</mi><mrow id="S4.T2.2.m1.1.1.3.3" xref="S4.T2.2.m1.1.1.3.3.cmml"><mi id="S4.T2.2.m1.1.1.3.3.2" xref="S4.T2.2.m1.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.T2.2.m1.1.1.3.3.1" xref="S4.T2.2.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.T2.2.m1.1.1.3.3.3" xref="S4.T2.2.m1.1.1.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.T2.2.m1.1.1.3.3.1b" xref="S4.T2.2.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.T2.2.m1.1.1.3.3.4" xref="S4.T2.2.m1.1.1.3.3.4.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.m1.1c"><apply id="S4.T2.2.m1.1.1.cmml" xref="S4.T2.2.m1.1.1"><times id="S4.T2.2.m1.1.1.1.cmml" xref="S4.T2.2.m1.1.1.1"></times><ci id="S4.T2.2.m1.1.1.2.cmml" xref="S4.T2.2.m1.1.1.2">𝐴</ci><apply id="S4.T2.2.m1.1.1.3.cmml" xref="S4.T2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T2.2.m1.1.1.3.1.cmml" xref="S4.T2.2.m1.1.1.3">subscript</csymbol><ci id="S4.T2.2.m1.1.1.3.2.cmml" xref="S4.T2.2.m1.1.1.3.2">𝑃</ci><apply id="S4.T2.2.m1.1.1.3.3.cmml" xref="S4.T2.2.m1.1.1.3.3"><times id="S4.T2.2.m1.1.1.3.3.1.cmml" xref="S4.T2.2.m1.1.1.3.3.1"></times><ci id="S4.T2.2.m1.1.1.3.3.2.cmml" xref="S4.T2.2.m1.1.1.3.3.2">𝐵</ci><ci id="S4.T2.2.m1.1.1.3.3.3.cmml" xref="S4.T2.2.m1.1.1.3.3.3">𝐸</ci><ci id="S4.T2.2.m1.1.1.3.3.4.cmml" xref="S4.T2.2.m1.1.1.3.3.4">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.m1.1d">AP_{BEV}</annotation></semantics></math>) of the total test set and individual weather conditions.</figcaption>
<table id="S4.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.3.1.1" class="ltx_tr">
<th id="S4.T2.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.3.1.1.1.1" class="ltx_text ltx_font_bold">Density[%]</span></th>
<th id="S4.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.3.1.1.2.1" class="ltx_text ltx_font_bold">GPU RAM[MB]</span></th>
<th id="S4.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.3.1.1.3.1" class="ltx_text ltx_font_bold">Total[%]</span></th>
<th id="S4.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.3.1.1.4.1" class="ltx_text ltx_font_bold">Normal[%]</span></th>
<th id="S4.T2.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.3.1.1.5.1" class="ltx_text ltx_font_bold">Overcast[%]</span></th>
<th id="S4.T2.3.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.3.1.1.6.1" class="ltx_text ltx_font_bold">Fog[%]</span></th>
<th id="S4.T2.3.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.3.1.1.7.1" class="ltx_text ltx_font_bold">Rain[%]</span></th>
<th id="S4.T2.3.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.3.1.1.8.1" class="ltx_text ltx_font_bold">Sleet[%]</span></th>
<th id="S4.T2.3.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.3.1.1.9.1" class="ltx_text ltx_font_bold">Light snow[%]</span></th>
<th id="S4.T2.3.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.3.1.1.10.1" class="ltx_text ltx_font_bold">Heavy snow[%]</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.2.1" class="ltx_tr">
<th id="S4.T2.3.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">0.01</th>
<th id="S4.T2.3.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.3.2.1.2.1" class="ltx_text ltx_font_bold">205</span></th>
<th id="S4.T2.3.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">24.2</th>
<td id="S4.T2.3.2.1.4" class="ltx_td ltx_align_center ltx_border_t">22.5</td>
<td id="S4.T2.3.2.1.5" class="ltx_td ltx_align_center ltx_border_t">13.8</td>
<td id="S4.T2.3.2.1.6" class="ltx_td ltx_align_center ltx_border_t">44.6</td>
<td id="S4.T2.3.2.1.7" class="ltx_td ltx_align_center ltx_border_t">20.0</td>
<td id="S4.T2.3.2.1.8" class="ltx_td ltx_align_center ltx_border_t">37.3</td>
<td id="S4.T2.3.2.1.9" class="ltx_td ltx_align_center ltx_border_t">24.9</td>
<td id="S4.T2.3.2.1.10" class="ltx_td ltx_align_center ltx_border_t">34.7</td>
</tr>
<tr id="S4.T2.3.3.2" class="ltx_tr">
<th id="S4.T2.3.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<th id="S4.T2.3.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">212</th>
<th id="S4.T2.3.3.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">42.6</th>
<td id="S4.T2.3.3.2.4" class="ltx_td ltx_align_center">42.8</td>
<td id="S4.T2.3.3.2.5" class="ltx_td ltx_align_center">31.4</td>
<td id="S4.T2.3.3.2.6" class="ltx_td ltx_align_center">65.6</td>
<td id="S4.T2.3.3.2.7" class="ltx_td ltx_align_center">34.2</td>
<td id="S4.T2.3.3.2.8" class="ltx_td ltx_align_center">44.8</td>
<td id="S4.T2.3.3.2.9" class="ltx_td ltx_align_center">44.2</td>
<td id="S4.T2.3.3.2.10" class="ltx_td ltx_align_center">48.6</td>
</tr>
<tr id="S4.T2.3.4.3" class="ltx_tr">
<th id="S4.T2.3.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1</th>
<th id="S4.T2.3.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">245</th>
<th id="S4.T2.3.4.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">55.5</th>
<td id="S4.T2.3.4.3.4" class="ltx_td ltx_align_center">56.1</td>
<td id="S4.T2.3.4.3.5" class="ltx_td ltx_align_center">51.1</td>
<td id="S4.T2.3.4.3.6" class="ltx_td ltx_align_center">66.8</td>
<td id="S4.T2.3.4.3.7" class="ltx_td ltx_align_center">50.6</td>
<td id="S4.T2.3.4.3.8" class="ltx_td ltx_align_center">57.7</td>
<td id="S4.T2.3.4.3.9" class="ltx_td ltx_align_center">62.1</td>
<td id="S4.T2.3.4.3.10" class="ltx_td ltx_align_center">59.0</td>
</tr>
<tr id="S4.T2.3.5.4" class="ltx_tr">
<th id="S4.T2.3.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3</th>
<th id="S4.T2.3.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">325</th>
<th id="S4.T2.3.5.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T2.3.5.4.3.1" class="ltx_text ltx_font_bold">61.9</span></th>
<td id="S4.T2.3.5.4.4" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.4.4.1" class="ltx_text ltx_font_bold">60.8</span></td>
<td id="S4.T2.3.5.4.5" class="ltx_td ltx_align_center">61.7</td>
<td id="S4.T2.3.5.4.6" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.4.6.1" class="ltx_text ltx_font_bold">79.9</span></td>
<td id="S4.T2.3.5.4.7" class="ltx_td ltx_align_center">53.3</td>
<td id="S4.T2.3.5.4.8" class="ltx_td ltx_align_center">59.1</td>
<td id="S4.T2.3.5.4.9" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.4.9.1" class="ltx_text ltx_font_bold">66.2</span></td>
<td id="S4.T2.3.5.4.10" class="ltx_td ltx_align_center">59.0</td>
</tr>
<tr id="S4.T2.3.6.5" class="ltx_tr">
<th id="S4.T2.3.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">5</th>
<th id="S4.T2.3.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">380</th>
<th id="S4.T2.3.6.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">59.4</th>
<td id="S4.T2.3.6.5.4" class="ltx_td ltx_align_center">60.5</td>
<td id="S4.T2.3.6.5.5" class="ltx_td ltx_align_center">65.2</td>
<td id="S4.T2.3.6.5.6" class="ltx_td ltx_align_center">73.6</td>
<td id="S4.T2.3.6.5.7" class="ltx_td ltx_align_center">53.8</td>
<td id="S4.T2.3.6.5.8" class="ltx_td ltx_align_center">60.1</td>
<td id="S4.T2.3.6.5.9" class="ltx_td ltx_align_center">56.1</td>
<td id="S4.T2.3.6.5.10" class="ltx_td ltx_align_center"><span id="S4.T2.3.6.5.10.1" class="ltx_text ltx_font_bold">61.4</span></td>
</tr>
<tr id="S4.T2.3.7.6" class="ltx_tr">
<th id="S4.T2.3.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">10</th>
<th id="S4.T2.3.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">421</th>
<th id="S4.T2.3.7.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">58.4</th>
<td id="S4.T2.3.7.6.4" class="ltx_td ltx_align_center">58.5</td>
<td id="S4.T2.3.7.6.5" class="ltx_td ltx_align_center">64.2</td>
<td id="S4.T2.3.7.6.6" class="ltx_td ltx_align_center">76.2</td>
<td id="S4.T2.3.7.6.7" class="ltx_td ltx_align_center">58.4</td>
<td id="S4.T2.3.7.6.8" class="ltx_td ltx_align_center"><span id="S4.T2.3.7.6.8.1" class="ltx_text ltx_font_bold">60.3</span></td>
<td id="S4.T2.3.7.6.9" class="ltx_td ltx_align_center">57.6</td>
<td id="S4.T2.3.7.6.10" class="ltx_td ltx_align_center">56.6</td>
</tr>
<tr id="S4.T2.3.8.7" class="ltx_tr">
<th id="S4.T2.3.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">15</th>
<th id="S4.T2.3.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">567</th>
<th id="S4.T2.3.8.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">57.1</th>
<td id="S4.T2.3.8.7.4" class="ltx_td ltx_align_center">59.0</td>
<td id="S4.T2.3.8.7.5" class="ltx_td ltx_align_center">71.3</td>
<td id="S4.T2.3.8.7.6" class="ltx_td ltx_align_center">70.0</td>
<td id="S4.T2.3.8.7.7" class="ltx_td ltx_align_center">55.4</td>
<td id="S4.T2.3.8.7.8" class="ltx_td ltx_align_center">46.3</td>
<td id="S4.T2.3.8.7.9" class="ltx_td ltx_align_center">55.9</td>
<td id="S4.T2.3.8.7.10" class="ltx_td ltx_align_center">50.7</td>
</tr>
<tr id="S4.T2.3.9.8" class="ltx_tr">
<th id="S4.T2.3.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">20</th>
<th id="S4.T2.3.9.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">623</th>
<th id="S4.T2.3.9.8.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">57.7</th>
<td id="S4.T2.3.9.8.4" class="ltx_td ltx_align_center">58.1</td>
<td id="S4.T2.3.9.8.5" class="ltx_td ltx_align_center">70.6</td>
<td id="S4.T2.3.9.8.6" class="ltx_td ltx_align_center">71.8</td>
<td id="S4.T2.3.9.8.7" class="ltx_td ltx_align_center"><span id="S4.T2.3.9.8.7.1" class="ltx_text ltx_font_bold">60.3</span></td>
<td id="S4.T2.3.9.8.8" class="ltx_td ltx_align_center">45.4</td>
<td id="S4.T2.3.9.8.9" class="ltx_td ltx_align_center">58.0</td>
<td id="S4.T2.3.9.8.10" class="ltx_td ltx_align_center">57.6</td>
</tr>
<tr id="S4.T2.3.10.9" class="ltx_tr">
<th id="S4.T2.3.10.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">30</th>
<th id="S4.T2.3.10.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">697</th>
<th id="S4.T2.3.10.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">55.9</th>
<td id="S4.T2.3.10.9.4" class="ltx_td ltx_align_center">56.7</td>
<td id="S4.T2.3.10.9.5" class="ltx_td ltx_align_center">70.9</td>
<td id="S4.T2.3.10.9.6" class="ltx_td ltx_align_center">71.2</td>
<td id="S4.T2.3.10.9.7" class="ltx_td ltx_align_center">55.6</td>
<td id="S4.T2.3.10.9.8" class="ltx_td ltx_align_center">44.3</td>
<td id="S4.T2.3.10.9.9" class="ltx_td ltx_align_center">56.3</td>
<td id="S4.T2.3.10.9.10" class="ltx_td ltx_align_center">46.1</td>
</tr>
<tr id="S4.T2.3.11.10" class="ltx_tr">
<th id="S4.T2.3.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">50</th>
<th id="S4.T2.3.11.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">802</th>
<th id="S4.T2.3.11.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">57.8</th>
<td id="S4.T2.3.11.10.4" class="ltx_td ltx_align_center ltx_border_b">59.9</td>
<td id="S4.T2.3.11.10.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.3.11.10.5.1" class="ltx_text ltx_font_bold">71.9</span></td>
<td id="S4.T2.3.11.10.6" class="ltx_td ltx_align_center ltx_border_b">77.7</td>
<td id="S4.T2.3.11.10.7" class="ltx_td ltx_align_center ltx_border_b">56.1</td>
<td id="S4.T2.3.11.10.8" class="ltx_td ltx_align_center ltx_border_b">37.1</td>
<td id="S4.T2.3.11.10.9" class="ltx_td ltx_align_center ltx_border_b">63.8</td>
<td id="S4.T2.3.11.10.10" class="ltx_td ltx_align_center ltx_border_b">53.8</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2303.06342/assets/perf.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="568" height="462" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Detection performance comparison between RTNH with inputs of various density. We visualize the memory size for each variant with different color values.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Comparison of training speed whether utilizing 4DSRT</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Table <a href="#S4.T3" title="TABLE III ‣ IV-D Comparison of training speed whether utilizing 4DSRT ‣ IV Experiments ‣ Enhanced K-Radar: Optimal Density Reduction to Improve Detection Performance and Accessibility of 4D Radar Tensor-based Object Detection †co-first authors, ∗corresponding author" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> shows the comparison of training speed between a 4DSRT-based network and a 4DRT-based network.
We find that utilizing 4DSRT during training leads to a training speed of 8.04 iteration/s, compared with 0.47 iteration/s for 4DRT-based training.
The 17.1 times improvement in training speed clearly testify the benefits of 4DSRT over 4DRT.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Comparison of training speed between a 4DSRT and a 4DRT-based network.</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Network input</span></td>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Training speed [iteration/s]</span></td>
</tr>
<tr id="S4.T3.1.2.2" class="ltx_tr">
<td id="S4.T3.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4DSRT</td>
<td id="S4.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">8.04</td>
</tr>
<tr id="S4.T3.1.3.3" class="ltx_tr">
<td id="S4.T3.1.3.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">4DRT</td>
<td id="S4.T3.1.3.3.2" class="ltx_td ltx_align_center ltx_border_b">0.47</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we have proposed the 4D Sparse Radar Tensor (4DSRT), a sparse representation of 4D Radar data with significantly lower data size compared with the dense 4D Radar Tensor (4DRT).
Unlike prior work, that arbitrarily choose the density reduction level, we have conducted an extensive hyperparameter tuning to find the most optimal density reduction level for the 4DSRT.
We have found that a 5% density reduction would result in the best performance in terms of <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">​</mo><msub id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml"><mi id="S5.p1.1.m1.1.1.3.2" xref="S5.p1.1.m1.1.1.3.2.cmml">P</mi><mrow id="S5.p1.1.m1.1.1.3.3" xref="S5.p1.1.m1.1.1.3.3.cmml"><mn id="S5.p1.1.m1.1.1.3.3.2" xref="S5.p1.1.m1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.3.3.1" xref="S5.p1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.3.3.3" xref="S5.p1.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><times id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></times><ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">𝐴</ci><apply id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.p1.1.m1.1.1.3.1.cmml" xref="S5.p1.1.m1.1.1.3">subscript</csymbol><ci id="S5.p1.1.m1.1.1.3.2.cmml" xref="S5.p1.1.m1.1.1.3.2">𝑃</ci><apply id="S5.p1.1.m1.1.1.3.3.cmml" xref="S5.p1.1.m1.1.1.3.3"><times id="S5.p1.1.m1.1.1.3.3.1.cmml" xref="S5.p1.1.m1.1.1.3.3.1"></times><cn type="integer" id="S5.p1.1.m1.1.1.3.3.2.cmml" xref="S5.p1.1.m1.1.1.3.3.2">3</cn><ci id="S5.p1.1.m1.1.1.3.3.3.cmml" xref="S5.p1.1.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">AP_{3D}</annotation></semantics></math>, and further increases in the density level do not result in better detection performance, indicating that a denser 4DSRT does not guarantee a better detection performance.
In addition, we have provided a highly-optimized development kit that, when used along with the 4DSRT, can improve the training speed by a factor of 17.1.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgment</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.2" class="ltx_p">This work was supported by Institute of Information <math id="Sx1.p1.1.m1.1" class="ltx_Math" alttext="\And" display="inline"><semantics id="Sx1.p1.1.m1.1a"><mo id="Sx1.p1.1.m1.1.1" xref="Sx1.p1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="Sx1.p1.1.m1.1b"><and id="Sx1.p1.1.m1.1.1.cmml" xref="Sx1.p1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="Sx1.p1.1.m1.1c">\And</annotation></semantics></math> communications Technology Planning <math id="Sx1.p1.2.m2.1" class="ltx_Math" alttext="\And" display="inline"><semantics id="Sx1.p1.2.m2.1a"><mo id="Sx1.p1.2.m2.1.1" xref="Sx1.p1.2.m2.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="Sx1.p1.2.m2.1b"><and id="Sx1.p1.2.m2.1.1.cmml" xref="Sx1.p1.2.m2.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="Sx1.p1.2.m2.1c">\And</annotation></semantics></math> Evaluation (IITP) grant funded by Korea government (MSIT) (No.2020-0-00440, Development of Artificial Intelligence Technology that Continuously Improves Itself as the Situation Changes in the Real World).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
T. Zheng, Y. Huang, Y. Liu, W. Tang, Z. Yang, D. Cai, and X. He, “Clrnet:
Cross layer refinement network for lane detection,” in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the IEEE/CVF conference on computer vision and pattern recognition</em>, 2022,
pp. 898–907.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
L. Liu, X. Chen, S. Zhu, and P. Tan, “Condlanenet: a top-to-down lane
detection framework based on conditional convolution,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the IEEE/CVF International Conference on Computer Vision</em>, 2021, pp.
3773–3782.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Z. Qin, H. Wang, and X. Li, “Ultra fast structure-aware deep lane detection,”
in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK,
August 23–28, 2020, Proceedings, Part XXIV 16</em>.   Springer, 2020, pp. 276–291.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
D.-H. Paek, S.-H. Kong, and K. T. Wijaya, “K-lane: Lidar lane dataset and
benchmark for urban roads and highways,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
Workshops</em>, June 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A. H. Lang, S. Vora, H. Caesar, L. Zhou, J. Yang, and O. Beijbom,
“Pointpillars: Fast encoders for object detection from point clouds,” in
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition</em>, 2019, pp. 12 697–12 705.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time
object detection with region proposal networks,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Advances in neural
information processing systems</em>, vol. 28, 2015.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Deng, S. Shi, P. Li, W. Zhou, Y. Zhang, and H. Li, “Voxel r-cnn: Towards
high performance voxel-based 3d object detection,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the AAAI Conference on Artificial Intelligence</em>, vol. 35, no. 2, 2021, pp.
1201–1209.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S. Shi, C. Guo, L. Jiang, Z. Wang, J. Shi, X. Wang, and H. Li, “Pv-rcnn:
Point-voxel feature set abstraction for 3d object detection,” in
<em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition</em>, 2020, pp. 10 529–10 538.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Shi, L. Jiang, J. Deng, Z. Wang, C. Guo, J. Shi, X. Wang, and H. Li,
“Pv-rcnn++: Point-voxel feature set abstraction with local vector
representation for 3d object detection,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">International Journal of
Computer Vision</em>, pp. 1–21, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Kurup and J. Bos, “Dsor: A scalable statistical filter for removing falling
snow from lidar point clouds in severe winter weather,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2109.07078</em>, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
D.-H. Paek, S.-H. Kong, and K. T. Wijaya, “K-radar: 4d radar object detection
for autonomous driving in various weather conditions,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Thirty-sixth
Conference on Neural Information Processing Systems Datasets and Benchmarks
Track</em>, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
F. J. Abdu, Y. Zhang, M. Fu, Y. Li, and Z. Deng, “Application of deep learning
on millimeter-wave radar signals: A review,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 21, no. 6,
2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M. Sheeny, E. De Pellegrin, S. Mukherjee, A. Ahrabian, S. Wang, and A. Wallace,
“Radiate: A radar dataset for automotive perception in bad weather,” in
<em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">2021 IEEE International Conference on Robotics and Automation
(ICRA)</em>.   IEEE, 2021, pp. 1–7.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
X. Dong, P. Wang, P. Zhang, and L. Liu, “Probabilistic oriented object
detection in automotive radar,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, June
2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
M. Mostajabi, C. M. Wang, D. Ranjan, and G. Hsyu, “High resolution radar
dataset for semi-supervised learning of dynamic objects,” in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">2020
IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops
(CVPRW)</em>, 2020, pp. 450–457.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A. Geiger, P. Lenz, C. Stiller, and R. Urtasun, “Vision meets robotics: The
KITTI dataset,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">The International Journal of Robotics Research</em>,
vol. 32, no. 11, pp. 1231–1237, Aug. 2013.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan,
Y. Pan, G. Baldan, and O. Beijbom, “nuscenes: A multimodal dataset for
autonomous driving,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR)</em>, June 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. Meyer and G. Kuschk, “Automotive radar dataset for deep learning based 3d
object detection,” in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">2019 16th European Radar Conference (EuRAD)</em>,
2019, pp. 129–132.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
B. Liu, M. Wang, H. Foroosh, M. Tappen, and M. Penksy, “Sparse convolutional
neural networks,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2015 IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, 2015, pp. 806–814.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
Z. Lin, N. Gimelshein, L. Antiga <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Pytorch: An imperative
style, high-performance deep learning library,” <em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">Advances in neural
information processing systems</em>, vol. 32, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
<em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6980</em>, 2014.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A. Geiger, P. Lenz, and R. Urtasun, “Are we ready for autonomous driving? the
kitti vision benchmark suite,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2012 IEEE Conference on Computer
Vision and Pattern Recognition</em>, 2012, pp. 3354–3361.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
S. M. Patole, M. Torlak, D. Wang, and M. Ali, “Automotive radars: A review of
signal processing techniques,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>,
vol. 34, no. 2, pp. 22–35, 2017.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2303.06341" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2303.06342" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2303.06342">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.06342" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2303.06343" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 20:30:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
