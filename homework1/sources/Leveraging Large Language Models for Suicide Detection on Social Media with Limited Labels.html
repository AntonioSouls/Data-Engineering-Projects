<!DOCTYPE html><html lang="en" data-theme="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels</title>
<!--Generated on Sun Oct  6 14:44:38 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">




<meta content="
large language models,  text classification,  limited labels,  prompt engineering,  suicide detection,  social media analysis
" lang="en" name="keywords">
<base href="https://arxiv.org/html/2410.04501v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2410.04501v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2410.04501v1/#myForm">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2410.04501v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2410.04501v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S1" title="In Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S2" title="In Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Datasets and metrics</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S2.SS1" title="In II Datasets and metrics ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">Datasets</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S2.SS2" title="In II Datasets and metrics ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Metrics</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S3" title="In Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S3.SS1" title="In III Related Work ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Deep learning approaches for text classification</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S3.SS2" title="In III Related Work ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Large Language Models for Mental Health Detection</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4" title="In Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Leveraging Large Language Models for suicide classification with limited labels</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS1" title="In IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Generating pseudo-labels for unlabeled data</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS2" title="In IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Fine-tuning Large Language Models for suicide classification</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS3" title="In IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Ensemble Model for a robust and performant classifier</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S5" title="In Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6" title="In Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Analysis and Discussion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S7" title="In Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VII </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: mathalfa</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: arXiv.org perpetual non-exclusive license</a><div id="watermark-tr">arXiv:2410.04501v1 [cs.CL] 06 Oct 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels
<br class="ltx_break">
</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vy Nguyen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id4.1.id1">Northeastern University
<br class="ltx_break"></span>Boston, MA, USA 
<br class="ltx_break">nguyen.vy7@northeastern.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chau Pham
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id5.1.id1">Boston University
<br class="ltx_break"></span>Boston, MA, USA 
<br class="ltx_break">chaupham@bu.edu
</span></span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id3.3">The increasing frequency of suicidal thoughts highlights the importance of early detection and intervention. Social media platforms, where users often share personal experiences and seek help, could be utilized to identify individuals at risk. However, the large volume of daily posts makes manual review impractical. This paper explores the use of Large Language Models (LLMs) to automatically detect suicidal content in text-based social media posts. We propose a novel method for generating pseudo-labels for unlabeled data by prompting LLMs, along with traditional classification fine-tuning techniques to enhance label accuracy.
To create a strong suicide detection model, we develop an ensemble approach involving prompting with <span class="ltx_text ltx_font_italic" id="id3.3.1">Qwen2-72B-Instruct</span>, and using fine-tuned models such as <span class="ltx_text ltx_font_italic" id="id3.3.2">Llama3-8B</span>, <span class="ltx_text ltx_font_italic" id="id3.3.3">Llama3.1-8B</span>, and <span class="ltx_text ltx_font_italic" id="id3.3.4">Gemma2-9B</span>. We evaluate our approach on the dataset of the Suicide Ideation Detection on Social Media Challenge, a track of the IEEE Big Data 2024 Big Data Cup. Additionally, we conduct a comprehensive analysis to assess the impact of different models and fine-tuning strategies on detection performance. Experimental results show that the ensemble model significantly improves the detection accuracy, by <math alttext="\mathbf{5}" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mn id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">𝟓</mn><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><cn id="id1.1.m1.1.1.cmml" type="integer" xref="id1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\mathbf{5}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">bold_5</annotation></semantics></math>% points compared with the individual models. It achieves a weight F1 score of <math alttext="\mathbf{0.770}" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><mn class="ltx_mathvariant_bold" id="id2.2.m2.1.1" mathvariant="bold" xref="id2.2.m2.1.1.cmml">0.770</mn><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><cn id="id2.2.m2.1.1.cmml" type="float" xref="id2.2.m2.1.1">0.770</cn></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">\mathbf{0.770}</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">bold_0.770</annotation></semantics></math> on the public test set, and <math alttext="\mathbf{0.731}" class="ltx_Math" display="inline" id="id3.3.m3.1"><semantics id="id3.3.m3.1a"><mn class="ltx_mathvariant_bold" id="id3.3.m3.1.1" mathvariant="bold" xref="id3.3.m3.1.1.cmml">0.731</mn><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><cn id="id3.3.m3.1.1.cmml" type="float" xref="id3.3.m3.1.1">0.731</cn></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">\mathbf{0.731}</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.1d">bold_0.731</annotation></semantics></math> on the private test set, providing a promising solution for identifying suicidal content in social media. Our analysis shows that the choice of LLMs affects the prompting performance, with larger models providing better accuracy. Our code and checkpoints are publicly available at <a class="ltx_ref ltx_href ltx_font_italic" href="https://github.com/khanhvynguyen/Suicide_Detection_LLMs" style="color:#FC42A2;" title=""><span class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/khanhvynguyen/Suicide_Detection_LLMs</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
large language models, text classification, limited labels, prompt engineering, suicide detection, social media analysis

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Suicide is a significant societal issue, with over <math alttext="700{,}000" class="ltx_Math" display="inline" id="S1.p1.1.m1.2"><semantics id="S1.p1.1.m1.2a"><mrow id="S1.p1.1.m1.2.3.2" xref="S1.p1.1.m1.2.3.1.cmml"><mn id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">700</mn><mo id="S1.p1.1.m1.2.3.2.1" xref="S1.p1.1.m1.2.3.1.cmml">,</mo><mn id="S1.p1.1.m1.2.2" xref="S1.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.2b"><list id="S1.p1.1.m1.2.3.1.cmml" xref="S1.p1.1.m1.2.3.2"><cn id="S1.p1.1.m1.1.1.cmml" type="integer" xref="S1.p1.1.m1.1.1">700</cn><cn id="S1.p1.1.m1.2.2.cmml" type="integer" xref="S1.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.2c">700{,}000</annotation><annotation encoding="application/x-llamapun" id="S1.p1.1.m1.2d">700 , 000</annotation></semantics></math> people taking their own lives and many more attempting to do so<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib1" title="">1</a>]</cite>. Unfortunately, the prevalence of suicidal thoughts and attempts is increasing. Thus, early identification of suicidal thoughts is crucial for preventing serious consequences and providing timely support. Social media platforms have emerged as potential sources for detecting suicidal thoughts and attempts, as people often share their experiences or seek help on these platforms. However, the sheer volume of new posts daily makes it impractical for mental health professionals to review all of them and offer assistance or resources.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Deep learning techniques in natural language processing (NLP) have demonstrated significant potential in automating the identification of suicidal content in social media posts. These techniques, due to their ability to recognize subtle patterns in text data, are increasingly used to classify and detect posts indicating suicidal thoughts. The process typically involves three main tasks: collecting textual data from social media platforms, labeling the data, and building a deep learning-based classifier. The process of labeling is time-consuming and requires domain experts, which results in very limited annotated datasets. Additionally, social media posts may contain vague or implicit intent, necessitating a strong language understanding ability for accurate classification. These factors pose a challenge in developing an effective model for detecting suicide.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S1.T1">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Definition of four suicide risk levels with increasing severe risk levels&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib2" title="">2</a>]</cite></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S1.T1.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S1.T1.6.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S1.T1.6.1.1.1"><span class="ltx_text ltx_font_bold" id="S1.T1.6.1.1.1.1" style="font-size:90%;">Category</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S1.T1.6.1.1.2"><span class="ltx_text ltx_font_bold" id="S1.T1.6.1.1.2.1" style="font-size:90%;">Definition</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.T1.6.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.6.2.1.1"><span class="ltx_text" id="S1.T1.6.2.1.1.1" style="font-size:90%;">Indicator</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.6.2.1.2"><span class="ltx_text" id="S1.T1.6.2.1.2.1" style="font-size:90%;">The post content has no explicit expression
concerning suicide.</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.6.3.2">
<td class="ltx_td ltx_align_left" id="S1.T1.6.3.2.1"><span class="ltx_text" id="S1.T1.6.3.2.1.1" style="font-size:90%;">Ideation</span></td>
<td class="ltx_td ltx_align_left" id="S1.T1.6.3.2.2"><span class="ltx_text" id="S1.T1.6.3.2.2.1" style="font-size:90%;">The post content has explicit suicidal expression
but there is no plan to commit suicide.</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.6.4.3">
<td class="ltx_td ltx_align_left" id="S1.T1.6.4.3.1"><span class="ltx_text" id="S1.T1.6.4.3.1.1" style="font-size:90%;">Behaviour</span></td>
<td class="ltx_td ltx_align_left" id="S1.T1.6.4.3.2"><span class="ltx_text" id="S1.T1.6.4.3.2.1" style="font-size:90%;">The post content has explicit suicidal expression
and a plan to commit suicide or self-harming
behaviours.</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.6.5.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S1.T1.6.5.4.1"><span class="ltx_text" id="S1.T1.6.5.4.1.1" style="font-size:90%;">Attempt</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S1.T1.6.5.4.2"><span class="ltx_text" id="S1.T1.6.5.4.2.1" style="font-size:90%;">The post content has explicit expressions
concerning historic suicide attempts.</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S1.T2">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Distribution of suicide risk level annotation of <math alttext="500" class="ltx_Math" display="inline" id="S1.T2.2.m1.1"><semantics id="S1.T2.2.m1.1b"><mn id="S1.T2.2.m1.1.1" xref="S1.T2.2.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S1.T2.2.m1.1c"><cn id="S1.T2.2.m1.1.1.cmml" type="integer" xref="S1.T2.2.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.T2.2.m1.1d">500</annotation><annotation encoding="application/x-llamapun" id="S1.T2.2.m1.1e">500</annotation></semantics></math> labeled posts in the training set</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S1.T2.7">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S1.T2.7.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S1.T2.7.1.1.1"><span class="ltx_text ltx_font_bold" id="S1.T2.7.1.1.1.1" style="font-size:90%;">Class</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T2.7.1.1.2"><span class="ltx_text ltx_font_bold" id="S1.T2.7.1.1.2.1" style="font-size:90%;">Number of posts</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T2.7.1.1.3"><span class="ltx_text ltx_font_bold" id="S1.T2.7.1.1.3.1" style="font-size:90%;">Percent Proportion (%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.T2.7.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S1.T2.7.2.1.1"><span class="ltx_text" id="S1.T2.7.2.1.1.1" style="font-size:90%;">Indicator</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.7.2.1.2"><span class="ltx_text" id="S1.T2.7.2.1.2.1" style="font-size:90%;">129</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.7.2.1.3"><span class="ltx_text" id="S1.T2.7.2.1.3.1" style="font-size:90%;">25.8</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.7.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T2.7.3.2.1"><span class="ltx_text" id="S1.T2.7.3.2.1.1" style="font-size:90%;">Ideation</span></th>
<td class="ltx_td ltx_align_center" id="S1.T2.7.3.2.2"><span class="ltx_text" id="S1.T2.7.3.2.2.1" style="font-size:90%;">190</span></td>
<td class="ltx_td ltx_align_center" id="S1.T2.7.3.2.3"><span class="ltx_text" id="S1.T2.7.3.2.3.1" style="font-size:90%;">38.0</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.7.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T2.7.4.3.1"><span class="ltx_text" id="S1.T2.7.4.3.1.1" style="font-size:90%;">Behaviour</span></th>
<td class="ltx_td ltx_align_center" id="S1.T2.7.4.3.2"><span class="ltx_text" id="S1.T2.7.4.3.2.1" style="font-size:90%;">140</span></td>
<td class="ltx_td ltx_align_center" id="S1.T2.7.4.3.3"><span class="ltx_text" id="S1.T2.7.4.3.3.1" style="font-size:90%;">28.0</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.7.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S1.T2.7.5.4.1"><span class="ltx_text" id="S1.T2.7.5.4.1.1" style="font-size:90%;">Attempt</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.7.5.4.2"><span class="ltx_text" id="S1.T2.7.5.4.2.1" style="font-size:90%;">41</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.7.5.4.3"><span class="ltx_text" id="S1.T2.7.5.4.3.1" style="font-size:90%;">8.2</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this study, we investigate the use of Large Language Models (LLMs) to classify the signs of suicide from user posts. We start by proposing a method for generating pseudo-labels for unlabeled data. We annotate user posts using LLMs (<em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">e.g</em>.<span class="ltx_text" id="S1.p3.1.2"></span>, <span class="ltx_text ltx_font_italic" id="S1.p3.1.3">Qwen2-72B-Instruct</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib3" title="">3</a>]</cite>) using prompting. To minimize the noise in the labeling process, we fine-tune two more models (<span class="ltx_text ltx_font_italic" id="S1.p3.1.4">Llama3-8B</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a>]</cite> and <span class="ltx_text ltx_font_italic" id="S1.p3.1.5">DepRoBERTa</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib5" title="">5</a>]</cite>) on a small set of annotated data to filter out unreliable labels. The unlabeled data with pseudo-labels is combined with the small set of labeled data to form a new training set. We then fine-tune some more LLMs (<em class="ltx_emph ltx_font_italic" id="S1.p3.1.6">e.g</em>., <span class="ltx_text ltx_font_italic" id="S1.p3.1.7">Llama3-8B</span>, <span class="ltx_text ltx_font_italic" id="S1.p3.1.8">Gemma2-9B</span>) on the newly formed dataset, and evaluate the effectiveness of the models in suicide classification. Finally, we combine these fine-tuned models, together with prompting LLMs, to create an ensemble for a more robust and performant suicide detector. We apply our approach to <span class="ltx_text ltx_font_italic" id="S1.p3.1.9">the Suicide Ideation Detection on Social Media Challenge</span>, a track in the IEEE Big Data 2024 Big Data Cup. Additionally, we provide analysis and discussion to gain insights into the results, such as how different LLMs affect the prompting performance, and choices of the loss function when fine-tuning. In summary, our contributions are:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Using Large Language Models (LLMs) with prompting to generate pseudo labels for unlabeled datasets, mitigating the issue of limited labeled data.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Investigating current state-of-the-art text classification methods using LLMs for suicide detection.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Experimenting with these approaches, using <span class="ltx_text ltx_font_italic" id="S1.I1.i3.p1.1.1">the Suicide Ideation Detection on Social Media Challenge</span> dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib2" title="">2</a>]</cite> to find a robust and performant model for the task.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">Conducting a comprehensive ablation study to clarify the effectiveness of our method.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Datasets and metrics</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.5.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.6.2">Datasets</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.12">The data used in this study is from the Suicide Risk On Social Media Detection Challenge 2024 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib2" title="">2</a>]</cite>. The dataset comprises a training set of <math alttext="500" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><mn id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><cn id="S2.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S2.SS1.p1.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">500</annotation></semantics></math> labeled and <math alttext="1{,}500" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.2"><semantics id="S2.SS1.p1.2.m2.2a"><mrow id="S2.SS1.p1.2.m2.2.3.2" xref="S2.SS1.p1.2.m2.2.3.1.cmml"><mn id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">1</mn><mo id="S2.SS1.p1.2.m2.2.3.2.1" xref="S2.SS1.p1.2.m2.2.3.1.cmml">,</mo><mn id="S2.SS1.p1.2.m2.2.2" xref="S2.SS1.p1.2.m2.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.2b"><list id="S2.SS1.p1.2.m2.2.3.1.cmml" xref="S2.SS1.p1.2.m2.2.3.2"><cn id="S2.SS1.p1.2.m2.1.1.cmml" type="integer" xref="S2.SS1.p1.2.m2.1.1">1</cn><cn id="S2.SS1.p1.2.m2.2.2.cmml" type="integer" xref="S2.SS1.p1.2.m2.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.2c">1{,}500</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.2d">1 , 500</annotation></semantics></math> unlabeled Reddit posts. To acquire <math alttext="500" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mn id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><cn id="S2.SS1.p1.3.m3.1.1.cmml" type="integer" xref="S2.SS1.p1.3.m3.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">500</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">500</annotation></semantics></math> annotated posts, the authors gathered <math alttext="139{,}455" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.2"><semantics id="S2.SS1.p1.4.m4.2a"><mrow id="S2.SS1.p1.4.m4.2.3.2" xref="S2.SS1.p1.4.m4.2.3.1.cmml"><mn id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">139</mn><mo id="S2.SS1.p1.4.m4.2.3.2.1" xref="S2.SS1.p1.4.m4.2.3.1.cmml">,</mo><mn id="S2.SS1.p1.4.m4.2.2" xref="S2.SS1.p1.4.m4.2.2.cmml">455</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.2b"><list id="S2.SS1.p1.4.m4.2.3.1.cmml" xref="S2.SS1.p1.4.m4.2.3.2"><cn id="S2.SS1.p1.4.m4.1.1.cmml" type="integer" xref="S2.SS1.p1.4.m4.1.1">139</cn><cn id="S2.SS1.p1.4.m4.2.2.cmml" type="integer" xref="S2.SS1.p1.4.m4.2.2">455</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.2c">139{,}455</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.2d">139 , 455</annotation></semantics></math> posts from <math alttext="76{,}186" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m5.2"><semantics id="S2.SS1.p1.5.m5.2a"><mrow id="S2.SS1.p1.5.m5.2.3.2" xref="S2.SS1.p1.5.m5.2.3.1.cmml"><mn id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">76</mn><mo id="S2.SS1.p1.5.m5.2.3.2.1" xref="S2.SS1.p1.5.m5.2.3.1.cmml">,</mo><mn id="S2.SS1.p1.5.m5.2.2" xref="S2.SS1.p1.5.m5.2.2.cmml">186</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.2b"><list id="S2.SS1.p1.5.m5.2.3.1.cmml" xref="S2.SS1.p1.5.m5.2.3.2"><cn id="S2.SS1.p1.5.m5.1.1.cmml" type="integer" xref="S2.SS1.p1.5.m5.1.1">76</cn><cn id="S2.SS1.p1.5.m5.2.2.cmml" type="integer" xref="S2.SS1.p1.5.m5.2.2">186</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.2c">76{,}186</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m5.2d">76 , 186</annotation></semantics></math> users between 01/01/2020 and 31/12/2021. Various pre-processing steps were undertaken, including the removal of user identity-related data (<em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.12.1">e.g</em>.<span class="ltx_text" id="S2.SS1.p1.12.2"></span>, names, addresses, emails, and links) to protect privacy, as well as the elimination of overlapping posts and comments from the same user. For each user, their last posts were considered as a representation of their latest suicide ideation state. Such posts were denoted as <span class="ltx_text ltx_font_italic" id="S2.SS1.p1.12.3">targeted posts</span>. Subsequently, <math alttext="500" class="ltx_Math" display="inline" id="S2.SS1.p1.6.m6.1"><semantics id="S2.SS1.p1.6.m6.1a"><mn id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><cn id="S2.SS1.p1.6.m6.1.1.cmml" type="integer" xref="S2.SS1.p1.6.m6.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">500</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.6.m6.1d">500</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.p1.12.4">targeted posts</span> from <math alttext="500" class="ltx_Math" display="inline" id="S2.SS1.p1.7.m7.1"><semantics id="S2.SS1.p1.7.m7.1a"><mn id="S2.SS1.p1.7.m7.1.1" xref="S2.SS1.p1.7.m7.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.1b"><cn id="S2.SS1.p1.7.m7.1.1.cmml" type="integer" xref="S2.SS1.p1.7.m7.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">500</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.7.m7.1d">500</annotation></semantics></math> random users were selected for annotation from the filtered dataset, which contained a total of <math alttext="3{,}998" class="ltx_Math" display="inline" id="S2.SS1.p1.8.m8.2"><semantics id="S2.SS1.p1.8.m8.2a"><mrow id="S2.SS1.p1.8.m8.2.3.2" xref="S2.SS1.p1.8.m8.2.3.1.cmml"><mn id="S2.SS1.p1.8.m8.1.1" xref="S2.SS1.p1.8.m8.1.1.cmml">3</mn><mo id="S2.SS1.p1.8.m8.2.3.2.1" xref="S2.SS1.p1.8.m8.2.3.1.cmml">,</mo><mn id="S2.SS1.p1.8.m8.2.2" xref="S2.SS1.p1.8.m8.2.2.cmml">998</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.2b"><list id="S2.SS1.p1.8.m8.2.3.1.cmml" xref="S2.SS1.p1.8.m8.2.3.2"><cn id="S2.SS1.p1.8.m8.1.1.cmml" type="integer" xref="S2.SS1.p1.8.m8.1.1">3</cn><cn id="S2.SS1.p1.8.m8.2.2.cmml" type="integer" xref="S2.SS1.p1.8.m8.2.2">998</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.2c">3{,}998</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.8.m8.2d">3 , 998</annotation></semantics></math> posts from <math alttext="1{,}791" class="ltx_Math" display="inline" id="S2.SS1.p1.9.m9.2"><semantics id="S2.SS1.p1.9.m9.2a"><mrow id="S2.SS1.p1.9.m9.2.3.2" xref="S2.SS1.p1.9.m9.2.3.1.cmml"><mn id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">1</mn><mo id="S2.SS1.p1.9.m9.2.3.2.1" xref="S2.SS1.p1.9.m9.2.3.1.cmml">,</mo><mn id="S2.SS1.p1.9.m9.2.2" xref="S2.SS1.p1.9.m9.2.2.cmml">791</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.2b"><list id="S2.SS1.p1.9.m9.2.3.1.cmml" xref="S2.SS1.p1.9.m9.2.3.2"><cn id="S2.SS1.p1.9.m9.1.1.cmml" type="integer" xref="S2.SS1.p1.9.m9.1.1">1</cn><cn id="S2.SS1.p1.9.m9.2.2.cmml" type="integer" xref="S2.SS1.p1.9.m9.2.2">791</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.2c">1{,}791</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.9.m9.2d">1 , 791</annotation></semantics></math> users. The annotation scheme for the suicide risk level label is depicted in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S1.T1" title="TABLE I ‣ I Introduction ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">I</span></a>. Statistics for the four annotated suicide risk categories from the <math alttext="500" class="ltx_Math" display="inline" id="S2.SS1.p1.10.m10.1"><semantics id="S2.SS1.p1.10.m10.1a"><mn id="S2.SS1.p1.10.m10.1.1" xref="S2.SS1.p1.10.m10.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.10.m10.1b"><cn id="S2.SS1.p1.10.m10.1.1.cmml" type="integer" xref="S2.SS1.p1.10.m10.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.10.m10.1c">500</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.10.m10.1d">500</annotation></semantics></math> labeled posts are outlined in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S1.T2" title="TABLE II ‣ I Introduction ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">II</span></a>. It is worth mentioning that the training dataset is imbalanced, with only <math alttext="8" class="ltx_Math" display="inline" id="S2.SS1.p1.11.m11.1"><semantics id="S2.SS1.p1.11.m11.1a"><mn id="S2.SS1.p1.11.m11.1.1" xref="S2.SS1.p1.11.m11.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.11.m11.1b"><cn id="S2.SS1.p1.11.m11.1.1.cmml" type="integer" xref="S2.SS1.p1.11.m11.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.11.m11.1c">8</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.11.m11.1d">8</annotation></semantics></math>% labeled as <span class="ltx_text ltx_font_italic" id="S2.SS1.p1.12.5">Attempt</span>. Most of the posts are short, typically less than <math alttext="2{,}000" class="ltx_Math" display="inline" id="S2.SS1.p1.12.m12.2"><semantics id="S2.SS1.p1.12.m12.2a"><mrow id="S2.SS1.p1.12.m12.2.3.2" xref="S2.SS1.p1.12.m12.2.3.1.cmml"><mn id="S2.SS1.p1.12.m12.1.1" xref="S2.SS1.p1.12.m12.1.1.cmml">2</mn><mo id="S2.SS1.p1.12.m12.2.3.2.1" xref="S2.SS1.p1.12.m12.2.3.1.cmml">,</mo><mn id="S2.SS1.p1.12.m12.2.2" xref="S2.SS1.p1.12.m12.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.12.m12.2b"><list id="S2.SS1.p1.12.m12.2.3.1.cmml" xref="S2.SS1.p1.12.m12.2.3.2"><cn id="S2.SS1.p1.12.m12.1.1.cmml" type="integer" xref="S2.SS1.p1.12.m12.1.1">2</cn><cn id="S2.SS1.p1.12.m12.2.2.cmml" type="integer" xref="S2.SS1.p1.12.m12.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.12.m12.2c">2{,}000</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.12.m12.2d">2 , 000</annotation></semantics></math> words, as illustrated in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.F7.sf1" title="In Figure 7 ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">7(a)</span></a>. An example of a Reddit post in the training set is shown as follows.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">“<span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.1">I want to end it, I want to end it but I don’t know how, when or anything else</span>”. (True label: <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.2">Ideation</span>)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="389" id="S2.F1.g1" src="https://arxiv.org/html/2410.04501v1/x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.21.5.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text ltx_font_bold" id="S2.F1.8.4" style="font-size:90%;">An overview of our approach.<span class="ltx_text ltx_font_medium" id="S2.F1.8.4.5"> </span>(a) pseudo-labels generation for unlabeled data<span class="ltx_text ltx_font_medium" id="S2.F1.5.1.1">. We first use <math alttext="500" class="ltx_Math" display="inline" id="S2.F1.5.1.1.m1.1"><semantics id="S2.F1.5.1.1.m1.1b"><mn id="S2.F1.5.1.1.m1.1.1" xref="S2.F1.5.1.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S2.F1.5.1.1.m1.1c"><cn id="S2.F1.5.1.1.m1.1.1.cmml" type="integer" xref="S2.F1.5.1.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.5.1.1.m1.1d">500</annotation><annotation encoding="application/x-llamapun" id="S2.F1.5.1.1.m1.1e">500</annotation></semantics></math> labeled posts to fine-tune <span class="ltx_text ltx_font_italic" id="S2.F1.5.1.1.1">DepRoBERTa</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib5" title="">5</a>]</cite> and <span class="ltx_text ltx_font_italic" id="S2.F1.5.1.1.2">Llama3-8B</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a>]</cite> for the classification task. Then, we combine these models with </span><span class="ltx_text ltx_font_italic" id="S2.F1.8.4.6" style="color:#5844D0;">Qwen2-72B-Instruct</span><span class="ltx_text ltx_font_medium" id="S2.F1.8.4.4"> via prompting to annotate <math alttext="1{,}500" class="ltx_Math" display="inline" id="S2.F1.6.2.2.m1.2"><semantics id="S2.F1.6.2.2.m1.2b"><mrow id="S2.F1.6.2.2.m1.2.3.2" xref="S2.F1.6.2.2.m1.2.3.1.cmml"><mn id="S2.F1.6.2.2.m1.1.1" xref="S2.F1.6.2.2.m1.1.1.cmml">1</mn><mo id="S2.F1.6.2.2.m1.2.3.2.1" xref="S2.F1.6.2.2.m1.2.3.1.cmml">,</mo><mn id="S2.F1.6.2.2.m1.2.2" xref="S2.F1.6.2.2.m1.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.6.2.2.m1.2c"><list id="S2.F1.6.2.2.m1.2.3.1.cmml" xref="S2.F1.6.2.2.m1.2.3.2"><cn id="S2.F1.6.2.2.m1.1.1.cmml" type="integer" xref="S2.F1.6.2.2.m1.1.1">1</cn><cn id="S2.F1.6.2.2.m1.2.2.cmml" type="integer" xref="S2.F1.6.2.2.m1.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.6.2.2.m1.2d">1{,}500</annotation><annotation encoding="application/x-llamapun" id="S2.F1.6.2.2.m1.2e">1 , 500</annotation></semantics></math> posts in the unlabeled dataset. We keep only <math alttext="\approx 900" class="ltx_Math" display="inline" id="S2.F1.7.3.3.m2.1"><semantics id="S2.F1.7.3.3.m2.1b"><mrow id="S2.F1.7.3.3.m2.1.1" xref="S2.F1.7.3.3.m2.1.1.cmml"><mi id="S2.F1.7.3.3.m2.1.1.2" xref="S2.F1.7.3.3.m2.1.1.2.cmml"></mi><mo id="S2.F1.7.3.3.m2.1.1.1" xref="S2.F1.7.3.3.m2.1.1.1.cmml">≈</mo><mn id="S2.F1.7.3.3.m2.1.1.3" xref="S2.F1.7.3.3.m2.1.1.3.cmml">900</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.7.3.3.m2.1c"><apply id="S2.F1.7.3.3.m2.1.1.cmml" xref="S2.F1.7.3.3.m2.1.1"><approx id="S2.F1.7.3.3.m2.1.1.1.cmml" xref="S2.F1.7.3.3.m2.1.1.1"></approx><csymbol cd="latexml" id="S2.F1.7.3.3.m2.1.1.2.cmml" xref="S2.F1.7.3.3.m2.1.1.2">absent</csymbol><cn id="S2.F1.7.3.3.m2.1.1.3.cmml" type="integer" xref="S2.F1.7.3.3.m2.1.1.3">900</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.7.3.3.m2.1d">\approx 900</annotation><annotation encoding="application/x-llamapun" id="S2.F1.7.3.3.m2.1e">≈ 900</annotation></semantics></math> posts for which all three models predict the same and combine these with the <math alttext="500" class="ltx_Math" display="inline" id="S2.F1.8.4.4.m3.1"><semantics id="S2.F1.8.4.4.m3.1b"><mn id="S2.F1.8.4.4.m3.1.1" xref="S2.F1.8.4.4.m3.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S2.F1.8.4.4.m3.1c"><cn id="S2.F1.8.4.4.m3.1.1.cmml" type="integer" xref="S2.F1.8.4.4.m3.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.8.4.4.m3.1d">500</annotation><annotation encoding="application/x-llamapun" id="S2.F1.8.4.4.m3.1e">500</annotation></semantics></math> labeled posts to form a new training set (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS1" title="IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>). </span>(b) LLMs fine-tuning<span class="ltx_text ltx_font_medium" id="S2.F1.8.4.7">. We then fine-tune </span><span class="ltx_text ltx_font_italic" id="S2.F1.8.4.8" style="color:#F28822;">Llama3-8B</span><span class="ltx_text ltx_font_medium" id="S2.F1.8.4.9">, </span><span class="ltx_text ltx_font_italic" id="S2.F1.8.4.10" style="color:#EF42F5;">Llama3.1-8B</span><span class="ltx_text ltx_font_medium" id="S2.F1.8.4.11">, and </span><span class="ltx_text ltx_font_italic" id="S2.F1.8.4.12" style="color:#00E6E6;">Gemma2-9B</span><span class="ltx_text ltx_font_medium" id="S2.F1.8.4.13"> on the newly formed dataset with Macro Double Soft F1 loss (Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS2" title="IV-B Fine-tuning Large Language Models for suicide classification ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>). </span>(c) Model Ensembling<span class="ltx_text ltx_font_medium" id="S2.F1.8.4.14">. These fine-tuned models are combined with prompting </span><span class="ltx_text ltx_font_italic" id="S2.F1.8.4.15" style="color:#5844D0;">Qwen2-72B-Instruct</span><span class="ltx_text ltx_font_medium" id="S2.F1.8.4.16"> to create an ensemble model for classifying new user posts
(Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS3" title="IV-C Ensemble Model for a robust and performant classifier ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-C</span></span></a>).</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.5.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.6.2">Metrics</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">We report <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">accuracy</span> and <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.2">weighted F1</span> scores for evaluating the model’s performance. Following prior work&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib2" title="">2</a>]</cite>, we utilize the weighted F1 score as the main metric since it provides a balanced measure of precision and recall, while also addressing class imbalance as depicted in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S1.T2" title="TABLE II ‣ I Introduction ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">II</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.4">Let <math alttext="C" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">italic_C</annotation></semantics></math> represent the total number of classes, <math alttext="N" class="ltx_Math" display="inline" id="S2.SS2.p2.2.m2.1"><semantics id="S2.SS2.p2.2.m2.1a"><mi id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><ci id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.2.m2.1d">italic_N</annotation></semantics></math> be the total number of observations, and <math alttext="n_{c}" class="ltx_Math" display="inline" id="S2.SS2.p2.3.m3.1"><semantics id="S2.SS2.p2.3.m3.1a"><msub id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml"><mi id="S2.SS2.p2.3.m3.1.1.2" xref="S2.SS2.p2.3.m3.1.1.2.cmml">n</mi><mi id="S2.SS2.p2.3.m3.1.1.3" xref="S2.SS2.p2.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.1b"><apply id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.3.m3.1.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p2.3.m3.1.1.2.cmml" xref="S2.SS2.p2.3.m3.1.1.2">𝑛</ci><ci id="S2.SS2.p2.3.m3.1.1.3.cmml" xref="S2.SS2.p2.3.m3.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.1c">n_{c}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.3.m3.1d">italic_n start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> be the number of observations belonging to class <math alttext="c" class="ltx_Math" display="inline" id="S2.SS2.p2.4.m4.1"><semantics id="S2.SS2.p2.4.m4.1a"><mi id="S2.SS2.p2.4.m4.1.1" xref="S2.SS2.p2.4.m4.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.4.m4.1b"><ci id="S2.SS2.p2.4.m4.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.4.m4.1c">c</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.4.m4.1d">italic_c</annotation></semantics></math>. The weighted F1 score is defined as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathrm{F1}_{\text{weighted}}=\sum_{c=1}^{C}\frac{n_{c}}{N}\cdot\mathrm{F1}_{c}" class="ltx_Math" display="block" id="S2.E1.m1.1"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><msub id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.2.2" xref="S2.E1.m1.1.1.2.2.cmml">F1</mi><mtext id="S2.E1.m1.1.1.2.3" xref="S2.E1.m1.1.1.2.3a.cmml">weighted</mtext></msub><mo id="S2.E1.m1.1.1.1" rspace="0.111em" xref="S2.E1.m1.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><munderover id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml"><mo id="S2.E1.m1.1.1.3.1.2.2" movablelimits="false" xref="S2.E1.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.E1.m1.1.1.3.1.2.3" xref="S2.E1.m1.1.1.3.1.2.3.cmml"><mi id="S2.E1.m1.1.1.3.1.2.3.2" xref="S2.E1.m1.1.1.3.1.2.3.2.cmml">c</mi><mo id="S2.E1.m1.1.1.3.1.2.3.1" xref="S2.E1.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.E1.m1.1.1.3.1.2.3.3" xref="S2.E1.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.1.1.3.1.3" xref="S2.E1.m1.1.1.3.1.3.cmml">C</mi></munderover><mrow id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml"><mfrac id="S2.E1.m1.1.1.3.2.2" xref="S2.E1.m1.1.1.3.2.2.cmml"><msub id="S2.E1.m1.1.1.3.2.2.2" xref="S2.E1.m1.1.1.3.2.2.2.cmml"><mi id="S2.E1.m1.1.1.3.2.2.2.2" xref="S2.E1.m1.1.1.3.2.2.2.2.cmml">n</mi><mi id="S2.E1.m1.1.1.3.2.2.2.3" xref="S2.E1.m1.1.1.3.2.2.2.3.cmml">c</mi></msub><mi id="S2.E1.m1.1.1.3.2.2.3" xref="S2.E1.m1.1.1.3.2.2.3.cmml">N</mi></mfrac><mo id="S2.E1.m1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.E1.m1.1.1.3.2.1.cmml">⋅</mo><msub id="S2.E1.m1.1.1.3.2.3" xref="S2.E1.m1.1.1.3.2.3.cmml"><mi id="S2.E1.m1.1.1.3.2.3.2" xref="S2.E1.m1.1.1.3.2.3.2.cmml">F1</mi><mi id="S2.E1.m1.1.1.3.2.3.3" xref="S2.E1.m1.1.1.3.2.3.3.cmml">c</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"></eq><apply id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.2.2">F1</ci><ci id="S2.E1.m1.1.1.2.3a.cmml" xref="S2.E1.m1.1.1.2.3"><mtext id="S2.E1.m1.1.1.2.3.cmml" mathsize="70%" xref="S2.E1.m1.1.1.2.3">weighted</mtext></ci></apply><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><apply id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.1.cmml" xref="S2.E1.m1.1.1.3.1">superscript</csymbol><apply id="S2.E1.m1.1.1.3.1.2.cmml" xref="S2.E1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.2.1.cmml" xref="S2.E1.m1.1.1.3.1">subscript</csymbol><sum id="S2.E1.m1.1.1.3.1.2.2.cmml" xref="S2.E1.m1.1.1.3.1.2.2"></sum><apply id="S2.E1.m1.1.1.3.1.2.3.cmml" xref="S2.E1.m1.1.1.3.1.2.3"><eq id="S2.E1.m1.1.1.3.1.2.3.1.cmml" xref="S2.E1.m1.1.1.3.1.2.3.1"></eq><ci id="S2.E1.m1.1.1.3.1.2.3.2.cmml" xref="S2.E1.m1.1.1.3.1.2.3.2">𝑐</ci><cn id="S2.E1.m1.1.1.3.1.2.3.3.cmml" type="integer" xref="S2.E1.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.1.1.3.1.3.cmml" xref="S2.E1.m1.1.1.3.1.3">𝐶</ci></apply><apply id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2"><ci id="S2.E1.m1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2.1">⋅</ci><apply id="S2.E1.m1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2"><divide id="S2.E1.m1.1.1.3.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2.2"></divide><apply id="S2.E1.m1.1.1.3.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2.2.2">𝑛</ci><ci id="S2.E1.m1.1.1.3.2.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.2.2.3">𝑐</ci></apply><ci id="S2.E1.m1.1.1.3.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.2.3">𝑁</ci></apply><apply id="S2.E1.m1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.3.1.cmml" xref="S2.E1.m1.1.1.3.2.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.3.2.cmml" xref="S2.E1.m1.1.1.3.2.3.2">F1</ci><ci id="S2.E1.m1.1.1.3.2.3.3.cmml" xref="S2.E1.m1.1.1.3.2.3.3">𝑐</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\mathrm{F1}_{\text{weighted}}=\sum_{c=1}^{C}\frac{n_{c}}{N}\cdot\mathrm{F1}_{c}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.1d">F1 start_POSTSUBSCRIPT weighted end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_c = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT divide start_ARG italic_n start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT end_ARG start_ARG italic_N end_ARG ⋅ F1 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p3.4">where <math alttext="\mathrm{F1}_{c}" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><msub id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml"><mi id="S2.SS2.p3.1.m1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.2.cmml">F1</mi><mi id="S2.SS2.p3.1.m1.1.1.3" xref="S2.SS2.p3.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.1.m1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p3.1.m1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.2">F1</ci><ci id="S2.SS2.p3.1.m1.1.1.3.cmml" xref="S2.SS2.p3.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">\mathrm{F1}_{c}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.1.m1.1d">F1 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> denotes the F1 score for class <math alttext="c" class="ltx_Math" display="inline" id="S2.SS2.p3.2.m2.1"><semantics id="S2.SS2.p3.2.m2.1a"><mi id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><ci id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">c</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.2.m2.1d">italic_c</annotation></semantics></math>. This method ensures a more accurate evaluation by reflecting the significance of each class in the overall performance metric. For simplicity, we use <math alttext="\mathrm{F1}" class="ltx_Math" display="inline" id="S2.SS2.p3.3.m3.1"><semantics id="S2.SS2.p3.3.m3.1a"><mi id="S2.SS2.p3.3.m3.1.1" xref="S2.SS2.p3.3.m3.1.1.cmml">F1</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m3.1b"><ci id="S2.SS2.p3.3.m3.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1">F1</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m3.1c">\mathrm{F1}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.3.m3.1d">F1</annotation></semantics></math> score to indicate weighted <math alttext="\mathrm{F1}" class="ltx_Math" display="inline" id="S2.SS2.p3.4.m4.1"><semantics id="S2.SS2.p3.4.m4.1a"><mi id="S2.SS2.p3.4.m4.1.1" xref="S2.SS2.p3.4.m4.1.1.cmml">F1</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.4.m4.1b"><ci id="S2.SS2.p3.4.m4.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1">F1</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.4.m4.1c">\mathrm{F1}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.4.m4.1d">F1</annotation></semantics></math> score in this paper.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Related Work</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Deep learning approaches for text classification</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In this section, we discuss three primary approaches to text classification: <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">Feature extraction</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2">Classification fine-tuning</span>, and <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.3">Large Language Models (LLMs) via prompt engineering</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Feature extraction approaches</span> begin with extracting features from the input text and then training a classifier for the downstream task. Some traditional methods such as <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.2">Word2Vec</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib6" title="">6</a>]</cite> and <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.3">GloVe</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib7" title="">7</a>]</cite> have been widely used. These methods represent words as high-dimensional vectors learned from word co-occurrence statistics. However, they often struggle to capture the complexities of language as they cannot capture the context in the input. Transformer-based models (<em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.1.4">e.g</em>.<span class="ltx_text" id="S3.SS1.p2.1.5"></span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.6">BERT</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib8" title="">8</a>]</cite>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.7">LLaMA3</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a>]</cite>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.8">GPT-4</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib9" title="">9</a>]</cite>), have recently become more commonly used as feature extractors due to their high performance&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib10" title="">10</a>]</cite>. These models, which were trained on large corpora of text, use attention mechanisms&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib11" title="">11</a>]</cite> to capture the context of words in a sentence. This enables them to understand the meaning of words in a specific context. The embeddings produced by the LLM’s pretrained parameters serve as input features for training traditional machine learning classifiers like <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.9">XGBoost</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib12" title="">12</a>]</cite>. By freezing the LLM’s parameters during this process, we can leverage its ability to capture intricate linguistic patterns without the need for extensive fine-tuning. This hybrid approach combines the strengths of LLMs in feature extraction with the simplicity of traditional classifiers, offering an effective and efficient method for text classification.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Classification fine-tuning</span> involves updating a model’s parameters on a specific dataset for a particular task. This is different from the feature extraction approach, where frozen language models are used to generate features for separate classifiers. Fine-tuning usually involves initializing the model’s weights with its pretrained weights. Subsequently, the final layer is replaced with a new randomly initialized linear layer (<em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.2">i.e</em>.<span class="ltx_text" id="S3.SS1.p3.1.3"></span>, classifier head) that maps the feature dimension to the number of classes. The model is then fine-tuned on a labeled dataset relevant to the target classification task. This approach utilizes transfer learning, where the knowledge gained during pretraining on extensive text data is applied to the specific task at hand.
Recent advancements have shown that fine-tuning can significantly improve the model’s ability to capture domain-specific language patterns, leading to enhanced accuracy and reliability in predictions&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib15" title="">15</a>]</cite>. Our approach involves fine-tuning pre-trained models on suicide datasets to better capture the nuances of suicidal thoughts, thus improving predictive performance. However, fine-tuning these large models can be challenging. To effectively fine-tune LLMs, efficient training techniques are necessary, such as Flash Attention&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib16" title="">16</a>]</cite> for faster attention computation with reduced memory requirements, bottleneck adapter layers for fine-tuning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib17" title="">17</a>]</cite>, LoRA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib18" title="">18</a>]</cite> for decreasing parameter count using low-rank matrices, and Bitsandbytes for quantization to lower memory usage during training.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">LLMs via prompt engineering</span> have become a critical method for improving the capabilities of LLMs (<em class="ltx_emph ltx_font_italic" id="S3.SS1.p4.1.2">e.g</em>.<span class="ltx_text" id="S3.SS1.p4.1.3"></span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.4">LLaMA3</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a>]</cite>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.5">GPT-4</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib9" title="">9</a>]</cite>) across various downstream tasks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib19" title="">19</a>]</cite>. In this approach, a <span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.6">prompt</span> - that is, a task-specific instruction along with some examples (few-shot) and a question - can be directly input into LLMs to obtain a response for the question. This technique enhances the model’s effectiveness by utilizing in-context learning, without the need to modify the model parameters. To further enhance the reasoning ability of LLMs, Wang&nbsp;<em class="ltx_emph ltx_font_italic" id="S3.SS1.p4.1.7">et al</em>.<span class="ltx_text" id="S3.SS1.p4.1.8"></span> introduced Self-Consistency, where a single LLM generates multiple responses to a given question and then uses majority voting to determine the final answer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib20" title="">20</a>]</cite>.
Wei&nbsp;<em class="ltx_emph ltx_font_italic" id="S3.SS1.p4.1.9">et al</em>.<span class="ltx_text" id="S3.SS1.p4.1.10"></span> introduced Chain-of-Thought (CoT), a method that employs a series of intermediate reasoning steps to reach the final answer. In another line of work, Du&nbsp;<em class="ltx_emph ltx_font_italic" id="S3.SS1.p4.1.11">et al</em>.<span class="ltx_text" id="S3.SS1.p4.1.12"></span> organized multiple LLMs in a debate setting, where each LLM independently generates an initial response, and then communicates to reach a consensus on a final answer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib21" title="">21</a>]</cite>. Meanwhile, Pham&nbsp;<em class="ltx_emph ltx_font_italic" id="S3.SS1.p4.1.13">et al</em>.<span class="ltx_text" id="S3.SS1.p4.1.14"></span> removed the token sampling step from LLMs, allowing LLMs to debate more effectively through the raw transformer output embeddings&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib22" title="">22</a>]</cite>. Overall, these techniques have been effective in improving the performance of LLMs through the use of prompts in downstream tasks. In our approach, we utilize LLMs with few-shot CoT prompting to generate pseudo-labels for unlabeled data, aiding in the creation of a substantial training set for the fine-tuning phase.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">Large Language Models for Mental Health Detection</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Recent research has expanded the use of large language models (LLMs) for detecting mental health issues. Lan <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.1">et al</em>.<span class="ltx_text" id="S3.SS2.p1.1.2"></span> proposed combining LLMs and traditional classifiers to integrate medical knowledge-guided features, achieving both high accuracy and explainability in depression detection&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib23" title="">23</a>]</cite>. Poswiata <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.3">et al</em>.<span class="ltx_text" id="S3.SS2.p1.1.4"></span> introduced fine-tuning <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.5">RoBERTa</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib24" title="">24</a>]</cite> on depression-related posts to achieve an effective depression detector&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib5" title="">5</a>]</cite>. Yang <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.6">et al</em>.<span class="ltx_text" id="S3.SS2.p1.1.7"></span> introduced <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.8">MentalLLaMA</span> based on <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.9">LLaMA2</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib25" title="">25</a>]</cite>, for interpretable mental health analysis with instruction-following capability&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib26" title="">26</a>]</cite>. Arcan <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.10">et al</em>.<span class="ltx_text" id="S3.SS2.p1.1.11"></span> provided a comprehensive evaluation of <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.12">LLaMA2</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.13">ChatGPT-4</span> for mental health tasks, revealing both the potential and limitations of LLM-based methods in this field&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib27" title="">27</a>]</cite>. There is another line of work in utilizing open-source LLMs to identify evidence in online posts that indicates the level of suicidal risks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib28" title="">28</a>]</cite>. As for suicide detection, Li <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.14">et al</em>.<span class="ltx_text" id="S3.SS2.p1.1.15"></span> proposed a new benchmark, consisting of fine-grained annotations of suicidal posts with BERT-based models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib2" title="">2</a>]</cite>. Meanwhile, Qi <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.16">et al</em>.<span class="ltx_text" id="S3.SS2.p1.1.17"></span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib29" title="">29</a>]</cite> presented another benchmark for Chinese social media datasets, assessing the performance of traditional models and Chinese LLMs such as <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.18">Chinese-LLaMa-2-7B</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib30" title="">30</a>]</cite>. In this paper, we focus on using state-of-the-art LLMs under a limited labeled data setting to create an effective and reliable classifier for identifying suicidal content in English social media posts.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Leveraging Large Language Models for suicide classification with limited labels</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.2">Given a user post (<em class="ltx_emph ltx_font_italic" id="S4.p1.2.1">i.e</em>., text) <math alttext="T" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mi id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">italic_T</annotation></semantics></math>, our goal is to train a model that takes <math alttext="T" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mi id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">italic_T</annotation></semantics></math> as input to classify the suicide risk levels. Our method involves using Large Language Models (LLMs) with few-shot Chain-of-Thought prompting&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib31" title="">31</a>]</cite>, and classification fine-tuning, as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S2.F1" title="Figure 1 ‣ II-A Datasets ‣ II Datasets and metrics ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">1</span></a>. First, we generate pseudo-labels for unlabeled data to mitigate the issue of limited labeled data (Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS1" title="IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>). High-confidence pseudo-labels are retained and combined with the labeled data to create the training set. Next, we fine-tune some LLMs such as <span class="ltx_text ltx_font_italic" id="S4.p1.2.2">Llama3-8B</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a>]</cite>, <span class="ltx_text ltx_font_italic" id="S4.p1.2.3">Gemma2-9B</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib32" title="">32</a>]</cite> using the new training set with Macro Double Soft F1 loss<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib33" title="">33</a>]</cite> (Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS2" title="IV-B Fine-tuning Large Language Models for suicide classification ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>). Finally, we create an ensemble model using <span class="ltx_text ltx_font_italic" id="S4.p1.2.4">Qwen2-72B-Instruct</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib3" title="">3</a>]</cite> through prompting, along with the classification fine-tuned LLMs on the new dataset, resulting in a robust and high-performing suicide classifier (Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS3" title="IV-C Ensemble Model for a robust and performant classifier ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-C</span></span></a>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Generating pseudo-labels for unlabeled data</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">Annotation with LLMs via prompting.</span>
Large language models (LLMs) have shown impressive semantic understanding capabilities&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib34" title="">34</a>]</cite>. Research suggests they could potentially replace human annotators in some tasks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib36" title="">36</a>]</cite>. In this study, we leverage LLMs with promoting to generate pseudo-labels for <math alttext="1{,}500" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.2"><semantics id="S4.SS1.p1.1.m1.2a"><mrow id="S4.SS1.p1.1.m1.2.3.2" xref="S4.SS1.p1.1.m1.2.3.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">1</mn><mo id="S4.SS1.p1.1.m1.2.3.2.1" xref="S4.SS1.p1.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS1.p1.1.m1.2.2" xref="S4.SS1.p1.1.m1.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.2b"><list id="S4.SS1.p1.1.m1.2.3.1.cmml" xref="S4.SS1.p1.1.m1.2.3.2"><cn id="S4.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1">1</cn><cn id="S4.SS1.p1.1.m1.2.2.cmml" type="integer" xref="S4.SS1.p1.1.m1.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.2c">1{,}500</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.2d">1 , 500</annotation></semantics></math> posts in the unlabeled dataset. We manually composed a set of six few-shot examples with Chain of Thought (CoT) for prompting, demonstrated in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.F2" title="Figure 2 ‣ IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">2</span></a>. Each example includes a user post, highlighted in green, followed by three questions corresponding to the three suicide risk levels: <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">Ideation</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.3">Behavior</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.4">Attempt</span>. Each question is accompanied by a response, starting with a “Yes” or “No,” followed by an explanation. The final part of the exemplar compiles these responses into a collective answer, consisting of the three “Yes/No” answers from the questions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">When a new post is introduced, which replaces the placeholder, highlighted in orange (as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.F2" title="Figure 2 ‣ IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">2</span></a>), the LLM is expected to generate a response in the same format as the exemplar, including three questions, three corresponding answers, and a compiled final answer, all within the dashed box (Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.F2" title="Figure 2 ‣ IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">2</span></a>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="846" id="S4.F2.g1" src="https://arxiv.org/html/2410.04501v1/x2.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.7.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F2.8.2" style="font-size:90%;">Prompt template with few-shot examples using Chain-of-Thought prompting.<span class="ltx_text ltx_font_medium" id="S4.F2.8.2.1"> Each example consists of a user post followed by three questions corresponding to the three suicide risk levels: <span class="ltx_text ltx_font_italic" id="S4.F2.8.2.1.1">Ideation</span>, <span class="ltx_text ltx_font_italic" id="S4.F2.8.2.1.2">Behavior</span>, and <span class="ltx_text ltx_font_italic" id="S4.F2.8.2.1.3">Attempt</span>. For each question in the example, a sample response is provided. The final part is used to collect the <span class="ltx_text ltx_font_italic" id="S4.F2.8.2.1.4">Yes/No</span> answers from the three responses.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">The final classification is determined by interpreting the compiled responses from the LLM, parsed in reverse order - from right to left. These answers correspond to <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.1">Attempt</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.2">Behavior</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.3">Ideation</span>, respectively. The classification is assigned based on the first “Yes” encountered. For example, if the collected answer is {<span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.4">Yes, Yes, No</span>}, the post is labeled as <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.5">Behavior</span>. If none of the responses in the collected answer is “Yes,” the post is classified as <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.6">Indicator</span> (<em class="ltx_emph ltx_font_italic" id="S4.SS1.p3.1.7">i.e</em>.<span class="ltx_text" id="S4.SS1.p3.1.8"></span>, indicating no explicit expression regarding suicide). One advantage of using prompting LLMs is that the labels are interpretable by humans. By prompting the LLM to answer smaller questions, we can verify the reasoning behind the model’s predictions. For example, in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.F2" title="Figure 2 ‣ IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">2</span></a>, the model believes that the writer has expressed explicit suicidal thoughts because of the phrase <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.9">“when my old high school found out I was suicidal.”</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">Through error analysis of the annotation results, we observed that some posts involved writers who had previously attempted suicide but then expressed a desire to continue living and move forward. LLMs may misinterpret the overall context of these posts, leading to incorrect annotations as <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.1">Attempts</span>. To address this issue, we introduced an additional prompt specifically for posts initially labeled as <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.2">Attempts</span> at the initial round. The prompt template is illustrated in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.F3" title="Figure 3 ‣ IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">3</span></a>. This prompt checks whether the writer mentions moving on from suicidal thoughts or attempts, such as feeling happy to be alive or having found a reason to live. If the answer generated by LLM is “Yes,” we modify the original answers by flipping the last answer corresponding to <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.3">Attempt</span> to “No.” For example, if LLMs initially predict a post as {<span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.4">Yes, No, Yes</span>} and the writer mentions moving on, we change the last “Yes” for <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.5">Attempts</span> to “No”. The refined answers then become {<span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.6">Yes, No, No</span>}, and the post would be re-annotated as <span class="ltx_text ltx_font_italic" id="S4.SS1.p4.1.7">Ideation</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="670" id="S4.F3.g1" src="https://arxiv.org/html/2410.04501v1/x3.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.3.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F3.4.2" style="font-size:90%;">Prompt template to assess whether the writer mentions moving on from suicide thoughts or attempts.<span class="ltx_text ltx_font_medium" id="S4.F3.4.2.1"> First, an instruction is provided to guide the LLM on the task, highlighted in blue. Following this, a set of few-shot exemplars is presented. Each exemplar includes a user post followed by the corresponding answer. When a new post, highlighted in orange, replaces the placeholder, the LLM is expected to generate an answer based on the context of the post, indicating whether the writer mentions moving on.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.2">We employ <span class="ltx_text ltx_font_italic" id="S4.SS1.p5.2.1">Qwen2-72B-Instruct</span>&nbsp;<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Qwen/Qwen2-72B-Instruct" title="">https://huggingface.co/Qwen/Qwen2-72B-Instruct</a></span></span></span> to generate pseudo-label for the unlabeled posts, as it is one of the performant open-source models with an extended context window of up to <math alttext="128K" class="ltx_Math" display="inline" id="S4.SS1.p5.1.m1.1"><semantics id="S4.SS1.p5.1.m1.1a"><mrow id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml"><mn id="S4.SS1.p5.1.m1.1.1.2" xref="S4.SS1.p5.1.m1.1.1.2.cmml">128</mn><mo id="S4.SS1.p5.1.m1.1.1.1" xref="S4.SS1.p5.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p5.1.m1.1.1.3" xref="S4.SS1.p5.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><apply id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1"><times id="S4.SS1.p5.1.m1.1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1.1"></times><cn id="S4.SS1.p5.1.m1.1.1.2.cmml" type="integer" xref="S4.SS1.p5.1.m1.1.1.2">128</cn><ci id="S4.SS1.p5.1.m1.1.1.3.cmml" xref="S4.SS1.p5.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">128K</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.1.m1.1d">128 italic_K</annotation></semantics></math> tokens&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib3" title="">3</a>]</cite>. We use greedy-decoding (<em class="ltx_emph ltx_font_italic" id="S4.SS1.p5.2.2">i.e</em>.<span class="ltx_text" id="S4.SS1.p5.2.3"></span>, choosing the highest probability output at each step of the sequence generation) and set the maximum length of the generated tokens to <math alttext="1024" class="ltx_Math" display="inline" id="S4.SS1.p5.2.m2.1"><semantics id="S4.SS1.p5.2.m2.1a"><mn id="S4.SS1.p5.2.m2.1.1" xref="S4.SS1.p5.2.m2.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.2.m2.1b"><cn id="S4.SS1.p5.2.m2.1.1.cmml" type="integer" xref="S4.SS1.p5.2.m2.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.2.m2.1c">1024</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.2.m2.1d">1024</annotation></semantics></math>. We also experiment with other LLMs, such as <span class="ltx_text ltx_font_italic" id="S4.SS1.p5.2.4">LLaMA3</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a>]</cite> and Mistral&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib38" title="">38</a>]</cite> family models, refer to Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.T7" title="TABLE VII ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">VII</span></a> and Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6" title="VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">VI</span></a> for further discussion.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p6.1.1">Annotation with classification fine-tuning.</span> To reduce noisy labels during the labeling process, we utilize multiple models for annotating the labels rather than relying solely on a single model. This ensures a more clean set of annotations, which is particularly important when dealing with complex and sensitive topics such as suicide risk.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p7">
<p class="ltx_p" id="S4.SS1.p7.1">To this end, we use <math alttext="500" class="ltx_Math" display="inline" id="S4.SS1.p7.1.m1.1"><semantics id="S4.SS1.p7.1.m1.1a"><mn id="S4.SS1.p7.1.m1.1.1" xref="S4.SS1.p7.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p7.1.m1.1b"><cn id="S4.SS1.p7.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p7.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p7.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p7.1.m1.1d">500</annotation></semantics></math> labeled posts to fine-tune two different classes of transformer-based models: an Encoder-only model and a Decoder-only model. For the former, we utilize <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.1">DepRoBERTa</span>, the winning solution for the Shared Task on Detecting Signs of Depression from Social Media Text at LT-EDI-ACL2022&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib5" title="">5</a>]</cite>. Based on <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.2">RoBERTa</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib24" title="">24</a>]</cite>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.3">DepRoBERTa</span> was further fine-tuned on user posts with different depression levels. Since depression and suicide are closely correlated, <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.4">DepRoBERTa</span> serves as a promising starting point for the suicide prediction task. For the latter, we fine-tune Llama3-8B&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a>]</cite>. More details on how these models are fine-tuned are discussed in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS2" title="IV-B Fine-tuning Large Language Models for suicide classification ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p8">
<p class="ltx_p" id="S4.SS1.p8.5"><span class="ltx_text ltx_font_bold" id="S4.SS1.p8.5.1">Combining models to generate training dataset.</span>
We use a combination of <span class="ltx_text ltx_font_italic" id="S4.SS1.p8.5.2">Qwen2-72B-Instruct</span>, along with fine-tuned <span class="ltx_text ltx_font_italic" id="S4.SS1.p8.5.3">DepRoBERTa</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p8.5.4">Llama3-8B</span> models on the <math alttext="500" class="ltx_Math" display="inline" id="S4.SS1.p8.1.m1.1"><semantics id="S4.SS1.p8.1.m1.1a"><mn id="S4.SS1.p8.1.m1.1.1" xref="S4.SS1.p8.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.1.m1.1b"><cn id="S4.SS1.p8.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p8.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p8.1.m1.1d">500</annotation></semantics></math> labeled posts to generate pseudo-labels for unlabeled data, as depicted in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S2.F1" title="Figure 1 ‣ II-A Datasets ‣ II Datasets and metrics ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">1</span></a>(a), rightmost. Specifically, we only kept posts for which all three models predicted the same labels, and discarded the rest in case of disagreement. By doing so, we retain only high-confidence pseudo-labels, which allow us to reduce model-specific biases, resulting in a cleaner dataset for fine-tuning later on. Refer to Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6" title="VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">VI</span></a> for more discussion.
After labeling <math alttext="1{,}500" class="ltx_Math" display="inline" id="S4.SS1.p8.2.m2.2"><semantics id="S4.SS1.p8.2.m2.2a"><mrow id="S4.SS1.p8.2.m2.2.3.2" xref="S4.SS1.p8.2.m2.2.3.1.cmml"><mn id="S4.SS1.p8.2.m2.1.1" xref="S4.SS1.p8.2.m2.1.1.cmml">1</mn><mo id="S4.SS1.p8.2.m2.2.3.2.1" xref="S4.SS1.p8.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS1.p8.2.m2.2.2" xref="S4.SS1.p8.2.m2.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.2.m2.2b"><list id="S4.SS1.p8.2.m2.2.3.1.cmml" xref="S4.SS1.p8.2.m2.2.3.2"><cn id="S4.SS1.p8.2.m2.1.1.cmml" type="integer" xref="S4.SS1.p8.2.m2.1.1">1</cn><cn id="S4.SS1.p8.2.m2.2.2.cmml" type="integer" xref="S4.SS1.p8.2.m2.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.2.m2.2c">1{,}500</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p8.2.m2.2d">1 , 500</annotation></semantics></math> posts, we keep only <math alttext="902" class="ltx_Math" display="inline" id="S4.SS1.p8.3.m3.1"><semantics id="S4.SS1.p8.3.m3.1a"><mn id="S4.SS1.p8.3.m3.1.1" xref="S4.SS1.p8.3.m3.1.1.cmml">902</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.3.m3.1b"><cn id="S4.SS1.p8.3.m3.1.1.cmml" type="integer" xref="S4.SS1.p8.3.m3.1.1">902</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.3.m3.1c">902</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p8.3.m3.1d">902</annotation></semantics></math> posts with pseudo-labels. These posts, combined with the <math alttext="500" class="ltx_Math" display="inline" id="S4.SS1.p8.4.m4.1"><semantics id="S4.SS1.p8.4.m4.1a"><mn id="S4.SS1.p8.4.m4.1.1" xref="S4.SS1.p8.4.m4.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.4.m4.1b"><cn id="S4.SS1.p8.4.m4.1.1.cmml" type="integer" xref="S4.SS1.p8.4.m4.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.4.m4.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p8.4.m4.1d">500</annotation></semantics></math> labeled dataset, form the training set of <math alttext="1{,}402" class="ltx_Math" display="inline" id="S4.SS1.p8.5.m5.2"><semantics id="S4.SS1.p8.5.m5.2a"><mrow id="S4.SS1.p8.5.m5.2.3.2" xref="S4.SS1.p8.5.m5.2.3.1.cmml"><mn id="S4.SS1.p8.5.m5.1.1" xref="S4.SS1.p8.5.m5.1.1.cmml">1</mn><mo id="S4.SS1.p8.5.m5.2.3.2.1" xref="S4.SS1.p8.5.m5.2.3.1.cmml">,</mo><mn id="S4.SS1.p8.5.m5.2.2" xref="S4.SS1.p8.5.m5.2.2.cmml">402</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.5.m5.2b"><list id="S4.SS1.p8.5.m5.2.3.1.cmml" xref="S4.SS1.p8.5.m5.2.3.2"><cn id="S4.SS1.p8.5.m5.1.1.cmml" type="integer" xref="S4.SS1.p8.5.m5.1.1">1</cn><cn id="S4.SS1.p8.5.m5.2.2.cmml" type="integer" xref="S4.SS1.p8.5.m5.2.2">402</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.5.m5.2c">1{,}402</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p8.5.m5.2d">1 , 402</annotation></semantics></math> posts. Statistics for the four annotated suicide risk labels from the combined dataset are outlined in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.T3" title="TABLE III ‣ IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">III</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE III: </span><span class="ltx_text ltx_font_bold" id="S4.T3.6.3">Distribution of suicide risk level annotation of <math alttext="\mathbf{1{,}402}" class="ltx_Math" display="inline" id="S4.T3.4.1.m1.2"><semantics id="S4.T3.4.1.m1.2b"><mrow id="S4.T3.4.1.m1.2.3.2" xref="S4.T3.4.1.m1.2.3.1.cmml"><mn id="S4.T3.4.1.m1.1.1" xref="S4.T3.4.1.m1.1.1.cmml">𝟏</mn><mo id="S4.T3.4.1.m1.2.3.2.1" xref="S4.T3.4.1.m1.2.3.1.cmml">,</mo><mn id="S4.T3.4.1.m1.2.2" xref="S4.T3.4.1.m1.2.2.cmml">𝟒𝟎𝟐</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.4.1.m1.2c"><list id="S4.T3.4.1.m1.2.3.1.cmml" xref="S4.T3.4.1.m1.2.3.2"><cn id="S4.T3.4.1.m1.1.1.cmml" type="integer" xref="S4.T3.4.1.m1.1.1">1</cn><cn id="S4.T3.4.1.m1.2.2.cmml" type="integer" xref="S4.T3.4.1.m1.2.2">402</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.1.m1.2d">\mathbf{1{,}402}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.1.m1.2e">bold_1 , bold_402</annotation></semantics></math> labeled training set, consisting of <math alttext="\mathbf{500}" class="ltx_Math" display="inline" id="S4.T3.5.2.m2.1"><semantics id="S4.T3.5.2.m2.1b"><mn id="S4.T3.5.2.m2.1.1" xref="S4.T3.5.2.m2.1.1.cmml">𝟓𝟎𝟎</mn><annotation-xml encoding="MathML-Content" id="S4.T3.5.2.m2.1c"><cn id="S4.T3.5.2.m2.1.1.cmml" type="integer" xref="S4.T3.5.2.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.2.m2.1d">\mathbf{500}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.2.m2.1e">bold_500</annotation></semantics></math> original labeled posts and <math alttext="\mathbf{902}" class="ltx_Math" display="inline" id="S4.T3.6.3.m3.1"><semantics id="S4.T3.6.3.m3.1b"><mn id="S4.T3.6.3.m3.1.1" xref="S4.T3.6.3.m3.1.1.cmml">𝟗𝟎𝟐</mn><annotation-xml encoding="MathML-Content" id="S4.T3.6.3.m3.1c"><cn id="S4.T3.6.3.m3.1.1.cmml" type="integer" xref="S4.T3.6.3.m3.1.1">902</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.3.m3.1d">\mathbf{902}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.3.m3.1e">bold_902</annotation></semantics></math> pseudo-labeled posts.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.9.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T3.9.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.9.1.1.1.1" style="font-size:90%;">Class</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.9.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.9.1.1.2.1" style="font-size:90%;">Number of posts</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.9.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.9.1.1.3.1" style="font-size:90%;">Percent Proportion (%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.9.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.9.2.1.1"><span class="ltx_text" id="S4.T3.9.2.1.1.1" style="font-size:90%;">Indicator</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.9.2.1.2"><span class="ltx_text" id="S4.T3.9.2.1.2.1" style="font-size:90%;">540</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.9.2.1.3"><span class="ltx_text" id="S4.T3.9.2.1.3.1" style="font-size:90%;">38.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.9.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.9.3.2.1"><span class="ltx_text" id="S4.T3.9.3.2.1.1" style="font-size:90%;">Ideation</span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.9.3.2.2"><span class="ltx_text" id="S4.T3.9.3.2.2.1" style="font-size:90%;">500</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.9.3.2.3"><span class="ltx_text" id="S4.T3.9.3.2.3.1" style="font-size:90%;">35.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.9.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.9.4.3.1"><span class="ltx_text" id="S4.T3.9.4.3.1.1" style="font-size:90%;">Behaviour</span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.9.4.3.2"><span class="ltx_text" id="S4.T3.9.4.3.2.1" style="font-size:90%;">286</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.9.4.3.3"><span class="ltx_text" id="S4.T3.9.4.3.3.1" style="font-size:90%;">20.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.9.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T3.9.5.4.1"><span class="ltx_text" id="S4.T3.9.5.4.1.1" style="font-size:90%;">Attempt</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.9.5.4.2"><span class="ltx_text" id="S4.T3.9.5.4.2.1" style="font-size:90%;">76</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.9.5.4.3"><span class="ltx_text" id="S4.T3.9.5.4.3.1" style="font-size:90%;">5.4</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Fine-tuning Large Language Models for suicide classification</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">After forming the new training set from Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS1" title="IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>, we fine-tune several LLMs on these <math alttext="1{,}402" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.2"><semantics id="S4.SS2.p1.1.m1.2a"><mrow id="S4.SS2.p1.1.m1.2.3.2" xref="S4.SS2.p1.1.m1.2.3.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">1</mn><mo id="S4.SS2.p1.1.m1.2.3.2.1" xref="S4.SS2.p1.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS2.p1.1.m1.2.2" xref="S4.SS2.p1.1.m1.2.2.cmml">402</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.2b"><list id="S4.SS2.p1.1.m1.2.3.1.cmml" xref="S4.SS2.p1.1.m1.2.3.2"><cn id="S4.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1">1</cn><cn id="S4.SS2.p1.1.m1.2.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.2.2">402</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.2c">1{,}402</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.2d">1 , 402</annotation></semantics></math> posts. From Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.SS1" title="IV-A Generating pseudo-labels for unlabeled data ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>, we observed that <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.2.1">LLaMA3</span> outperformed <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.2.2">DepRoBERTa</span> when fine-tuned on the <math alttext="500" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn id="S4.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">500</annotation></semantics></math> labeled posts. As a result, we decide to focus on fine-tuning LLaMA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a>]</cite> for this stage. To enhance the diversity of the results for the ensemble model later on, we also conduct fine-tuning on <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.2.3">Gemma2</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib32" title="">32</a>]</cite>. Specifically, we fine-tune three different models: <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS2.p1.2.4" style="color:#F28822;">Llama3-8B</span>, <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS2.p1.2.5" style="color:#EF42F5;">Llama3.1-8B</span>, and <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS2.p1.2.6" style="color:#00E6E6;">Gemma2-9B</span>, as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S2.F1" title="Figure 1 ‣ II-A Datasets ‣ II Datasets and metrics ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">1</span></a>(b).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.6"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Setting for <math alttext="\mathbf{5}" class="ltx_Math" display="inline" id="S4.SS2.p2.1.1.m1.1"><semantics id="S4.SS2.p2.1.1.m1.1a"><mn id="S4.SS2.p2.1.1.m1.1.1" xref="S4.SS2.p2.1.1.m1.1.1.cmml">𝟓</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.1.m1.1b"><cn id="S4.SS2.p2.1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p2.1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.1.m1.1c">\mathbf{5}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.1.m1.1d">bold_5</annotation></semantics></math>-fold cross-validation.</span> Although we have <math alttext="1{,}402" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m1.2"><semantics id="S4.SS2.p2.2.m1.2a"><mrow id="S4.SS2.p2.2.m1.2.3.2" xref="S4.SS2.p2.2.m1.2.3.1.cmml"><mn id="S4.SS2.p2.2.m1.1.1" xref="S4.SS2.p2.2.m1.1.1.cmml">1</mn><mo id="S4.SS2.p2.2.m1.2.3.2.1" xref="S4.SS2.p2.2.m1.2.3.1.cmml">,</mo><mn id="S4.SS2.p2.2.m1.2.2" xref="S4.SS2.p2.2.m1.2.2.cmml">402</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m1.2b"><list id="S4.SS2.p2.2.m1.2.3.1.cmml" xref="S4.SS2.p2.2.m1.2.3.2"><cn id="S4.SS2.p2.2.m1.1.1.cmml" type="integer" xref="S4.SS2.p2.2.m1.1.1">1</cn><cn id="S4.SS2.p2.2.m1.2.2.cmml" type="integer" xref="S4.SS2.p2.2.m1.2.2">402</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m1.2c">1{,}402</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m1.2d">1 , 402</annotation></semantics></math> labeled posts available, we only use <math alttext="500" class="ltx_Math" display="inline" id="S4.SS2.p2.3.m2.1"><semantics id="S4.SS2.p2.3.m2.1a"><mn id="S4.SS2.p2.3.m2.1.1" xref="S4.SS2.p2.3.m2.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m2.1b"><cn id="S4.SS2.p2.3.m2.1.1.cmml" type="integer" xref="S4.SS2.p2.3.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m2.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.3.m2.1d">500</annotation></semantics></math> original labeled data annotated by experts for validation to ensure accuracy. To utilize all <math alttext="500" class="ltx_Math" display="inline" id="S4.SS2.p2.4.m3.1"><semantics id="S4.SS2.p2.4.m3.1a"><mn id="S4.SS2.p2.4.m3.1.1" xref="S4.SS2.p2.4.m3.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m3.1b"><cn id="S4.SS2.p2.4.m3.1.1.cmml" type="integer" xref="S4.SS2.p2.4.m3.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m3.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.4.m3.1d">500</annotation></semantics></math> well-annotated posts, we use <math alttext="5" class="ltx_Math" display="inline" id="S4.SS2.p2.5.m4.1"><semantics id="S4.SS2.p2.5.m4.1a"><mn id="S4.SS2.p2.5.m4.1.1" xref="S4.SS2.p2.5.m4.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m4.1b"><cn id="S4.SS2.p2.5.m4.1.1.cmml" type="integer" xref="S4.SS2.p2.5.m4.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m4.1c">5</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.5.m4.1d">5</annotation></semantics></math>-fold cross-validation training. When one fold is used for evaluation, the remaining four folds, along with <math alttext="902" class="ltx_Math" display="inline" id="S4.SS2.p2.6.m5.1"><semantics id="S4.SS2.p2.6.m5.1a"><mn id="S4.SS2.p2.6.m5.1.1" xref="S4.SS2.p2.6.m5.1.1.cmml">902</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.6.m5.1b"><cn id="S4.SS2.p2.6.m5.1.1.cmml" type="integer" xref="S4.SS2.p2.6.m5.1.1">902</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.6.m5.1c">902</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.6.m5.1d">902</annotation></semantics></math> pseudo-labeled posts, are combined for training. These folds are stratified to maintain the initial suicide risk level proportions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.6">After training five cross-validation models, we collect the prediction for a new test set as follows. Let
<math alttext="c\in\{0,1,2,3\}" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.4"><semantics id="S4.SS2.p3.1.m1.4a"><mrow id="S4.SS2.p3.1.m1.4.5" xref="S4.SS2.p3.1.m1.4.5.cmml"><mi id="S4.SS2.p3.1.m1.4.5.2" xref="S4.SS2.p3.1.m1.4.5.2.cmml">c</mi><mo id="S4.SS2.p3.1.m1.4.5.1" xref="S4.SS2.p3.1.m1.4.5.1.cmml">∈</mo><mrow id="S4.SS2.p3.1.m1.4.5.3.2" xref="S4.SS2.p3.1.m1.4.5.3.1.cmml"><mo id="S4.SS2.p3.1.m1.4.5.3.2.1" stretchy="false" xref="S4.SS2.p3.1.m1.4.5.3.1.cmml">{</mo><mn id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">0</mn><mo id="S4.SS2.p3.1.m1.4.5.3.2.2" xref="S4.SS2.p3.1.m1.4.5.3.1.cmml">,</mo><mn id="S4.SS2.p3.1.m1.2.2" xref="S4.SS2.p3.1.m1.2.2.cmml">1</mn><mo id="S4.SS2.p3.1.m1.4.5.3.2.3" xref="S4.SS2.p3.1.m1.4.5.3.1.cmml">,</mo><mn id="S4.SS2.p3.1.m1.3.3" xref="S4.SS2.p3.1.m1.3.3.cmml">2</mn><mo id="S4.SS2.p3.1.m1.4.5.3.2.4" xref="S4.SS2.p3.1.m1.4.5.3.1.cmml">,</mo><mn id="S4.SS2.p3.1.m1.4.4" xref="S4.SS2.p3.1.m1.4.4.cmml">3</mn><mo id="S4.SS2.p3.1.m1.4.5.3.2.5" stretchy="false" xref="S4.SS2.p3.1.m1.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.4b"><apply id="S4.SS2.p3.1.m1.4.5.cmml" xref="S4.SS2.p3.1.m1.4.5"><in id="S4.SS2.p3.1.m1.4.5.1.cmml" xref="S4.SS2.p3.1.m1.4.5.1"></in><ci id="S4.SS2.p3.1.m1.4.5.2.cmml" xref="S4.SS2.p3.1.m1.4.5.2">𝑐</ci><set id="S4.SS2.p3.1.m1.4.5.3.1.cmml" xref="S4.SS2.p3.1.m1.4.5.3.2"><cn id="S4.SS2.p3.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p3.1.m1.1.1">0</cn><cn id="S4.SS2.p3.1.m1.2.2.cmml" type="integer" xref="S4.SS2.p3.1.m1.2.2">1</cn><cn id="S4.SS2.p3.1.m1.3.3.cmml" type="integer" xref="S4.SS2.p3.1.m1.3.3">2</cn><cn id="S4.SS2.p3.1.m1.4.4.cmml" type="integer" xref="S4.SS2.p3.1.m1.4.4">3</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.4c">c\in\{0,1,2,3\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.4d">italic_c ∈ { 0 , 1 , 2 , 3 }</annotation></semantics></math> represent the class index,
and <math alttext="\mathbf{m^{(i)}}\in\mathbb{R}^{4}" class="ltx_Math" display="inline" id="S4.SS2.p3.2.m2.1"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.2" xref="S4.SS2.p3.2.m2.1.2.cmml"><msup id="S4.SS2.p3.2.m2.1.2.2" xref="S4.SS2.p3.2.m2.1.2.2.cmml"><mi id="S4.SS2.p3.2.m2.1.2.2.2" xref="S4.SS2.p3.2.m2.1.2.2.2.cmml">𝐦</mi><mrow id="S4.SS2.p3.2.m2.1.1.1.3" xref="S4.SS2.p3.2.m2.1.2.2.cmml"><mo id="S4.SS2.p3.2.m2.1.1.1.3.1" stretchy="false" xref="S4.SS2.p3.2.m2.1.2.2.cmml">(</mo><mi id="S4.SS2.p3.2.m2.1.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.1.cmml">𝐢</mi><mo id="S4.SS2.p3.2.m2.1.1.1.3.2" stretchy="false" xref="S4.SS2.p3.2.m2.1.2.2.cmml">)</mo></mrow></msup><mo id="S4.SS2.p3.2.m2.1.2.1" xref="S4.SS2.p3.2.m2.1.2.1.cmml">∈</mo><msup id="S4.SS2.p3.2.m2.1.2.3" xref="S4.SS2.p3.2.m2.1.2.3.cmml"><mi id="S4.SS2.p3.2.m2.1.2.3.2" xref="S4.SS2.p3.2.m2.1.2.3.2.cmml">ℝ</mi><mn id="S4.SS2.p3.2.m2.1.2.3.3" xref="S4.SS2.p3.2.m2.1.2.3.3.cmml">4</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.2.cmml" xref="S4.SS2.p3.2.m2.1.2"><in id="S4.SS2.p3.2.m2.1.2.1.cmml" xref="S4.SS2.p3.2.m2.1.2.1"></in><apply id="S4.SS2.p3.2.m2.1.2.2.cmml" xref="S4.SS2.p3.2.m2.1.2.2"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.2.2.1.cmml" xref="S4.SS2.p3.2.m2.1.2.2">superscript</csymbol><ci id="S4.SS2.p3.2.m2.1.2.2.2.cmml" xref="S4.SS2.p3.2.m2.1.2.2.2">𝐦</ci><ci id="S4.SS2.p3.2.m2.1.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1">𝐢</ci></apply><apply id="S4.SS2.p3.2.m2.1.2.3.cmml" xref="S4.SS2.p3.2.m2.1.2.3"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.2.3.1.cmml" xref="S4.SS2.p3.2.m2.1.2.3">superscript</csymbol><ci id="S4.SS2.p3.2.m2.1.2.3.2.cmml" xref="S4.SS2.p3.2.m2.1.2.3.2">ℝ</ci><cn id="S4.SS2.p3.2.m2.1.2.3.3.cmml" type="integer" xref="S4.SS2.p3.2.m2.1.2.3.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">\mathbf{m^{(i)}}\in\mathbb{R}^{4}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.2.m2.1d">bold_m start_POSTSUPERSCRIPT ( bold_i ) end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT</annotation></semantics></math> be the probability output of the <math alttext="i" class="ltx_Math" display="inline" id="S4.SS2.p3.3.m3.1"><semantics id="S4.SS2.p3.3.m3.1a"><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.3.m3.1d">italic_i</annotation></semantics></math>-th cross-validation model given a user post <math alttext="T" class="ltx_Math" display="inline" id="S4.SS2.p3.4.m4.1"><semantics id="S4.SS2.p3.4.m4.1a"><mi id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><ci id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.4.m4.1d">italic_T</annotation></semantics></math>. We average the probability outputs of all five models to obtain the final probability output <math alttext="\mathbf{p}\in\mathbb{R}^{4}" class="ltx_Math" display="inline" id="S4.SS2.p3.5.m5.1"><semantics id="S4.SS2.p3.5.m5.1a"><mrow id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml"><mi id="S4.SS2.p3.5.m5.1.1.2" xref="S4.SS2.p3.5.m5.1.1.2.cmml">𝐩</mi><mo id="S4.SS2.p3.5.m5.1.1.1" xref="S4.SS2.p3.5.m5.1.1.1.cmml">∈</mo><msup id="S4.SS2.p3.5.m5.1.1.3" xref="S4.SS2.p3.5.m5.1.1.3.cmml"><mi id="S4.SS2.p3.5.m5.1.1.3.2" xref="S4.SS2.p3.5.m5.1.1.3.2.cmml">ℝ</mi><mn id="S4.SS2.p3.5.m5.1.1.3.3" xref="S4.SS2.p3.5.m5.1.1.3.3.cmml">4</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.1b"><apply id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1"><in id="S4.SS2.p3.5.m5.1.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1.1"></in><ci id="S4.SS2.p3.5.m5.1.1.2.cmml" xref="S4.SS2.p3.5.m5.1.1.2">𝐩</ci><apply id="S4.SS2.p3.5.m5.1.1.3.cmml" xref="S4.SS2.p3.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p3.5.m5.1.1.3.1.cmml" xref="S4.SS2.p3.5.m5.1.1.3">superscript</csymbol><ci id="S4.SS2.p3.5.m5.1.1.3.2.cmml" xref="S4.SS2.p3.5.m5.1.1.3.2">ℝ</ci><cn id="S4.SS2.p3.5.m5.1.1.3.3.cmml" type="integer" xref="S4.SS2.p3.5.m5.1.1.3.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.1c">\mathbf{p}\in\mathbb{R}^{4}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.5.m5.1d">bold_p ∈ blackboard_R start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT</annotation></semantics></math> (E.q&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.E2" title="In IV-B Fine-tuning Large Language Models for suicide classification ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">2</span></a>). Next, we select the class corresponding to the index with the highest probability, denoted as <math alttext="\mathrm{c}\ast" class="ltx_math_unparsed" display="inline" id="S4.SS2.p3.6.m6.1"><semantics id="S4.SS2.p3.6.m6.1a"><mrow id="S4.SS2.p3.6.m6.1b"><mi id="S4.SS2.p3.6.m6.1.1" mathvariant="normal">c</mi><mo id="S4.SS2.p3.6.m6.1.2" lspace="0.222em">∗</mo></mrow><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">\mathrm{c}\ast</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.6.m6.1d">roman_c ∗</annotation></semantics></math> (E.q&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.E3" title="In IV-B Fine-tuning Large Language Models for suicide classification ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">3</span></a>), as the final prediction.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{p}=\frac{1}{5}\sum_{i=1}^{5}\mathbf{m^{(i)}}" class="ltx_Math" display="block" id="S4.E2.m1.1"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.2" xref="S4.E2.m1.1.2.cmml"><mi id="S4.E2.m1.1.2.2" xref="S4.E2.m1.1.2.2.cmml">𝐩</mi><mo id="S4.E2.m1.1.2.1" xref="S4.E2.m1.1.2.1.cmml">=</mo><mrow id="S4.E2.m1.1.2.3" xref="S4.E2.m1.1.2.3.cmml"><mfrac id="S4.E2.m1.1.2.3.2" xref="S4.E2.m1.1.2.3.2.cmml"><mn id="S4.E2.m1.1.2.3.2.2" xref="S4.E2.m1.1.2.3.2.2.cmml">1</mn><mn id="S4.E2.m1.1.2.3.2.3" xref="S4.E2.m1.1.2.3.2.3.cmml">5</mn></mfrac><mo id="S4.E2.m1.1.2.3.1" xref="S4.E2.m1.1.2.3.1.cmml">⁢</mo><mrow id="S4.E2.m1.1.2.3.3" xref="S4.E2.m1.1.2.3.3.cmml"><munderover id="S4.E2.m1.1.2.3.3.1" xref="S4.E2.m1.1.2.3.3.1.cmml"><mo id="S4.E2.m1.1.2.3.3.1.2.2" movablelimits="false" xref="S4.E2.m1.1.2.3.3.1.2.2.cmml">∑</mo><mrow id="S4.E2.m1.1.2.3.3.1.2.3" xref="S4.E2.m1.1.2.3.3.1.2.3.cmml"><mi id="S4.E2.m1.1.2.3.3.1.2.3.2" xref="S4.E2.m1.1.2.3.3.1.2.3.2.cmml">i</mi><mo id="S4.E2.m1.1.2.3.3.1.2.3.1" xref="S4.E2.m1.1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S4.E2.m1.1.2.3.3.1.2.3.3" xref="S4.E2.m1.1.2.3.3.1.2.3.3.cmml">1</mn></mrow><mn id="S4.E2.m1.1.2.3.3.1.3" xref="S4.E2.m1.1.2.3.3.1.3.cmml">5</mn></munderover><msup id="S4.E2.m1.1.2.3.3.2" xref="S4.E2.m1.1.2.3.3.2.cmml"><mi id="S4.E2.m1.1.2.3.3.2.2" xref="S4.E2.m1.1.2.3.3.2.2.cmml">𝐦</mi><mrow id="S4.E2.m1.1.1.1.3" xref="S4.E2.m1.1.2.3.3.2.cmml"><mo id="S4.E2.m1.1.1.1.3.1" stretchy="false" xref="S4.E2.m1.1.2.3.3.2.cmml">(</mo><mi id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml">𝐢</mi><mo id="S4.E2.m1.1.1.1.3.2" stretchy="false" xref="S4.E2.m1.1.2.3.3.2.cmml">)</mo></mrow></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.2.cmml" xref="S4.E2.m1.1.2"><eq id="S4.E2.m1.1.2.1.cmml" xref="S4.E2.m1.1.2.1"></eq><ci id="S4.E2.m1.1.2.2.cmml" xref="S4.E2.m1.1.2.2">𝐩</ci><apply id="S4.E2.m1.1.2.3.cmml" xref="S4.E2.m1.1.2.3"><times id="S4.E2.m1.1.2.3.1.cmml" xref="S4.E2.m1.1.2.3.1"></times><apply id="S4.E2.m1.1.2.3.2.cmml" xref="S4.E2.m1.1.2.3.2"><divide id="S4.E2.m1.1.2.3.2.1.cmml" xref="S4.E2.m1.1.2.3.2"></divide><cn id="S4.E2.m1.1.2.3.2.2.cmml" type="integer" xref="S4.E2.m1.1.2.3.2.2">1</cn><cn id="S4.E2.m1.1.2.3.2.3.cmml" type="integer" xref="S4.E2.m1.1.2.3.2.3">5</cn></apply><apply id="S4.E2.m1.1.2.3.3.cmml" xref="S4.E2.m1.1.2.3.3"><apply id="S4.E2.m1.1.2.3.3.1.cmml" xref="S4.E2.m1.1.2.3.3.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.2.3.3.1.1.cmml" xref="S4.E2.m1.1.2.3.3.1">superscript</csymbol><apply id="S4.E2.m1.1.2.3.3.1.2.cmml" xref="S4.E2.m1.1.2.3.3.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.2.3.3.1.2.1.cmml" xref="S4.E2.m1.1.2.3.3.1">subscript</csymbol><sum id="S4.E2.m1.1.2.3.3.1.2.2.cmml" xref="S4.E2.m1.1.2.3.3.1.2.2"></sum><apply id="S4.E2.m1.1.2.3.3.1.2.3.cmml" xref="S4.E2.m1.1.2.3.3.1.2.3"><eq id="S4.E2.m1.1.2.3.3.1.2.3.1.cmml" xref="S4.E2.m1.1.2.3.3.1.2.3.1"></eq><ci id="S4.E2.m1.1.2.3.3.1.2.3.2.cmml" xref="S4.E2.m1.1.2.3.3.1.2.3.2">𝑖</ci><cn id="S4.E2.m1.1.2.3.3.1.2.3.3.cmml" type="integer" xref="S4.E2.m1.1.2.3.3.1.2.3.3">1</cn></apply></apply><cn id="S4.E2.m1.1.2.3.3.1.3.cmml" type="integer" xref="S4.E2.m1.1.2.3.3.1.3">5</cn></apply><apply id="S4.E2.m1.1.2.3.3.2.cmml" xref="S4.E2.m1.1.2.3.3.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.2.3.3.2.1.cmml" xref="S4.E2.m1.1.2.3.3.2">superscript</csymbol><ci id="S4.E2.m1.1.2.3.3.2.2.cmml" xref="S4.E2.m1.1.2.3.3.2.2">𝐦</ci><ci id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1">𝐢</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">\mathbf{p}=\frac{1}{5}\sum_{i=1}^{5}\mathbf{m^{(i)}}</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.1d">bold_p = divide start_ARG 1 end_ARG start_ARG 5 end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT bold_m start_POSTSUPERSCRIPT ( bold_i ) end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS2.p5">
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathrm{c}\ast=\arg\max_{c}\mathbf{p_{c}}" class="ltx_math_unparsed" display="block" id="S4.E3.m1.1"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1b"><mi id="S4.E3.m1.1.1" mathvariant="normal">c</mi><mo id="S4.E3.m1.1.2" lspace="0.222em" rspace="0em">∗</mo><mo id="S4.E3.m1.1.3" lspace="0em">=</mo><mi id="S4.E3.m1.1.4">arg</mi><munder id="S4.E3.m1.1.5"><mi id="S4.E3.m1.1.5.2">max</mi><mi id="S4.E3.m1.1.5.3">c</mi></munder><msub id="S4.E3.m1.1.6"><mi id="S4.E3.m1.1.6.2">𝐩</mi><mi id="S4.E3.m1.1.6.3">𝐜</mi></msub></mrow><annotation encoding="application/x-tex" id="S4.E3.m1.1c">\mathrm{c}\ast=\arg\max_{c}\mathbf{p_{c}}</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.1d">roman_c ∗ = roman_arg roman_max start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT bold_p start_POSTSUBSCRIPT bold_c end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.13"><span class="ltx_text ltx_font_bold" id="S4.SS2.p6.13.1">LoRA classification Fine-tuning.</span> In the fine-tuning process, the model’s weights are initialized with its pretrained weights. After that, the final layer is replaced with a new linear layer that is randomly initialized and maps the feature dimension to the number of classes, which is 4 in this case. We fine-tune each model using a single NVIDIA RTX with 48GB RAM for <math alttext="20" class="ltx_Math" display="inline" id="S4.SS2.p6.1.m1.1"><semantics id="S4.SS2.p6.1.m1.1a"><mn id="S4.SS2.p6.1.m1.1.1" xref="S4.SS2.p6.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.1.m1.1b"><cn id="S4.SS2.p6.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p6.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.1.m1.1c">20</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.1.m1.1d">20</annotation></semantics></math> epochs and a batch size of <math alttext="1" class="ltx_Math" display="inline" id="S4.SS2.p6.2.m2.1"><semantics id="S4.SS2.p6.2.m2.1a"><mn id="S4.SS2.p6.2.m2.1.1" xref="S4.SS2.p6.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.2.m2.1b"><cn id="S4.SS2.p6.2.m2.1.1.cmml" type="integer" xref="S4.SS2.p6.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.2.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.2.m2.1d">1</annotation></semantics></math>. To account for the small batch size, we set grad accumulation to <math alttext="16" class="ltx_Math" display="inline" id="S4.SS2.p6.3.m3.1"><semantics id="S4.SS2.p6.3.m3.1a"><mn id="S4.SS2.p6.3.m3.1.1" xref="S4.SS2.p6.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.3.m3.1b"><cn id="S4.SS2.p6.3.m3.1.1.cmml" type="integer" xref="S4.SS2.p6.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.3.m3.1c">16</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.3.m3.1d">16</annotation></semantics></math>. The AdamW optimizer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib39" title="">39</a>]</cite> is used to train the models. For the learning rate, we apply a random search in the range of <math alttext="1e\text{-}6" class="ltx_Math" display="inline" id="S4.SS2.p6.4.m4.1"><semantics id="S4.SS2.p6.4.m4.1a"><mrow id="S4.SS2.p6.4.m4.1.1" xref="S4.SS2.p6.4.m4.1.1.cmml"><mn id="S4.SS2.p6.4.m4.1.1.2" xref="S4.SS2.p6.4.m4.1.1.2.cmml">1</mn><mo id="S4.SS2.p6.4.m4.1.1.1" xref="S4.SS2.p6.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p6.4.m4.1.1.3" xref="S4.SS2.p6.4.m4.1.1.3.cmml">e</mi><mo id="S4.SS2.p6.4.m4.1.1.1a" xref="S4.SS2.p6.4.m4.1.1.1.cmml">⁢</mo><mtext id="S4.SS2.p6.4.m4.1.1.4" xref="S4.SS2.p6.4.m4.1.1.4a.cmml">-</mtext><mo id="S4.SS2.p6.4.m4.1.1.1b" xref="S4.SS2.p6.4.m4.1.1.1.cmml">⁢</mo><mn id="S4.SS2.p6.4.m4.1.1.5" xref="S4.SS2.p6.4.m4.1.1.5.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.4.m4.1b"><apply id="S4.SS2.p6.4.m4.1.1.cmml" xref="S4.SS2.p6.4.m4.1.1"><times id="S4.SS2.p6.4.m4.1.1.1.cmml" xref="S4.SS2.p6.4.m4.1.1.1"></times><cn id="S4.SS2.p6.4.m4.1.1.2.cmml" type="integer" xref="S4.SS2.p6.4.m4.1.1.2">1</cn><ci id="S4.SS2.p6.4.m4.1.1.3.cmml" xref="S4.SS2.p6.4.m4.1.1.3">𝑒</ci><ci id="S4.SS2.p6.4.m4.1.1.4a.cmml" xref="S4.SS2.p6.4.m4.1.1.4"><mtext id="S4.SS2.p6.4.m4.1.1.4.cmml" xref="S4.SS2.p6.4.m4.1.1.4">-</mtext></ci><cn id="S4.SS2.p6.4.m4.1.1.5.cmml" type="integer" xref="S4.SS2.p6.4.m4.1.1.5">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.4.m4.1c">1e\text{-}6</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.4.m4.1d">1 italic_e - 6</annotation></semantics></math> to <math alttext="1e\text{-}4" class="ltx_Math" display="inline" id="S4.SS2.p6.5.m5.1"><semantics id="S4.SS2.p6.5.m5.1a"><mrow id="S4.SS2.p6.5.m5.1.1" xref="S4.SS2.p6.5.m5.1.1.cmml"><mn id="S4.SS2.p6.5.m5.1.1.2" xref="S4.SS2.p6.5.m5.1.1.2.cmml">1</mn><mo id="S4.SS2.p6.5.m5.1.1.1" xref="S4.SS2.p6.5.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p6.5.m5.1.1.3" xref="S4.SS2.p6.5.m5.1.1.3.cmml">e</mi><mo id="S4.SS2.p6.5.m5.1.1.1a" xref="S4.SS2.p6.5.m5.1.1.1.cmml">⁢</mo><mtext id="S4.SS2.p6.5.m5.1.1.4" xref="S4.SS2.p6.5.m5.1.1.4a.cmml">-</mtext><mo id="S4.SS2.p6.5.m5.1.1.1b" xref="S4.SS2.p6.5.m5.1.1.1.cmml">⁢</mo><mn id="S4.SS2.p6.5.m5.1.1.5" xref="S4.SS2.p6.5.m5.1.1.5.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.5.m5.1b"><apply id="S4.SS2.p6.5.m5.1.1.cmml" xref="S4.SS2.p6.5.m5.1.1"><times id="S4.SS2.p6.5.m5.1.1.1.cmml" xref="S4.SS2.p6.5.m5.1.1.1"></times><cn id="S4.SS2.p6.5.m5.1.1.2.cmml" type="integer" xref="S4.SS2.p6.5.m5.1.1.2">1</cn><ci id="S4.SS2.p6.5.m5.1.1.3.cmml" xref="S4.SS2.p6.5.m5.1.1.3">𝑒</ci><ci id="S4.SS2.p6.5.m5.1.1.4a.cmml" xref="S4.SS2.p6.5.m5.1.1.4"><mtext id="S4.SS2.p6.5.m5.1.1.4.cmml" xref="S4.SS2.p6.5.m5.1.1.4">-</mtext></ci><cn id="S4.SS2.p6.5.m5.1.1.5.cmml" type="integer" xref="S4.SS2.p6.5.m5.1.1.5">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.5.m5.1c">1e\text{-}4</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.5.m5.1d">1 italic_e - 4</annotation></semantics></math>. Additionally, we use a weight decay of <math alttext="0.1" class="ltx_Math" display="inline" id="S4.SS2.p6.6.m6.1"><semantics id="S4.SS2.p6.6.m6.1a"><mn id="S4.SS2.p6.6.m6.1.1" xref="S4.SS2.p6.6.m6.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.6.m6.1b"><cn id="S4.SS2.p6.6.m6.1.1.cmml" type="float" xref="S4.SS2.p6.6.m6.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.6.m6.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.6.m6.1d">0.1</annotation></semantics></math> to the weight parameters to mitigate overfitting. To efficiently fine-tune large language models (LLMs), we employ LoRA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib18" title="">18</a>]</cite> to reduce the parameter count via low-rank matrices. The dimension of the low-rank matrices <math alttext="\mathrm{lora}_{r}" class="ltx_Math" display="inline" id="S4.SS2.p6.7.m7.1"><semantics id="S4.SS2.p6.7.m7.1a"><msub id="S4.SS2.p6.7.m7.1.1" xref="S4.SS2.p6.7.m7.1.1.cmml"><mi id="S4.SS2.p6.7.m7.1.1.2" xref="S4.SS2.p6.7.m7.1.1.2.cmml">lora</mi><mi id="S4.SS2.p6.7.m7.1.1.3" xref="S4.SS2.p6.7.m7.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.7.m7.1b"><apply id="S4.SS2.p6.7.m7.1.1.cmml" xref="S4.SS2.p6.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.7.m7.1.1.1.cmml" xref="S4.SS2.p6.7.m7.1.1">subscript</csymbol><ci id="S4.SS2.p6.7.m7.1.1.2.cmml" xref="S4.SS2.p6.7.m7.1.1.2">lora</ci><ci id="S4.SS2.p6.7.m7.1.1.3.cmml" xref="S4.SS2.p6.7.m7.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.7.m7.1c">\mathrm{lora}_{r}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.7.m7.1d">roman_lora start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> is set at <math alttext="16" class="ltx_Math" display="inline" id="S4.SS2.p6.8.m8.1"><semantics id="S4.SS2.p6.8.m8.1a"><mn id="S4.SS2.p6.8.m8.1.1" xref="S4.SS2.p6.8.m8.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.8.m8.1b"><cn id="S4.SS2.p6.8.m8.1.1.cmml" type="integer" xref="S4.SS2.p6.8.m8.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.8.m8.1c">16</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.8.m8.1d">16</annotation></semantics></math>, whereas <math alttext="\mathrm{lora}_{\alpha}" class="ltx_Math" display="inline" id="S4.SS2.p6.9.m9.1"><semantics id="S4.SS2.p6.9.m9.1a"><msub id="S4.SS2.p6.9.m9.1.1" xref="S4.SS2.p6.9.m9.1.1.cmml"><mi id="S4.SS2.p6.9.m9.1.1.2" xref="S4.SS2.p6.9.m9.1.1.2.cmml">lora</mi><mi id="S4.SS2.p6.9.m9.1.1.3" xref="S4.SS2.p6.9.m9.1.1.3.cmml">α</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.9.m9.1b"><apply id="S4.SS2.p6.9.m9.1.1.cmml" xref="S4.SS2.p6.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.9.m9.1.1.1.cmml" xref="S4.SS2.p6.9.m9.1.1">subscript</csymbol><ci id="S4.SS2.p6.9.m9.1.1.2.cmml" xref="S4.SS2.p6.9.m9.1.1.2">lora</ci><ci id="S4.SS2.p6.9.m9.1.1.3.cmml" xref="S4.SS2.p6.9.m9.1.1.3">𝛼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.9.m9.1c">\mathrm{lora}_{\alpha}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.9.m9.1d">roman_lora start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT</annotation></semantics></math> is set to <math alttext="8" class="ltx_Math" display="inline" id="S4.SS2.p6.10.m10.1"><semantics id="S4.SS2.p6.10.m10.1a"><mn id="S4.SS2.p6.10.m10.1.1" xref="S4.SS2.p6.10.m10.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.10.m10.1b"><cn id="S4.SS2.p6.10.m10.1.1.cmml" type="integer" xref="S4.SS2.p6.10.m10.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.10.m10.1c">8</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.10.m10.1d">8</annotation></semantics></math>. We only apply LoRA fine-tune on <math alttext="q_{\mathrm{proj}},k_{\mathrm{proj}},v_{\mathrm{proj}}" class="ltx_Math" display="inline" id="S4.SS2.p6.11.m11.3"><semantics id="S4.SS2.p6.11.m11.3a"><mrow id="S4.SS2.p6.11.m11.3.3.3" xref="S4.SS2.p6.11.m11.3.3.4.cmml"><msub id="S4.SS2.p6.11.m11.1.1.1.1" xref="S4.SS2.p6.11.m11.1.1.1.1.cmml"><mi id="S4.SS2.p6.11.m11.1.1.1.1.2" xref="S4.SS2.p6.11.m11.1.1.1.1.2.cmml">q</mi><mi id="S4.SS2.p6.11.m11.1.1.1.1.3" xref="S4.SS2.p6.11.m11.1.1.1.1.3.cmml">proj</mi></msub><mo id="S4.SS2.p6.11.m11.3.3.3.4" xref="S4.SS2.p6.11.m11.3.3.4.cmml">,</mo><msub id="S4.SS2.p6.11.m11.2.2.2.2" xref="S4.SS2.p6.11.m11.2.2.2.2.cmml"><mi id="S4.SS2.p6.11.m11.2.2.2.2.2" xref="S4.SS2.p6.11.m11.2.2.2.2.2.cmml">k</mi><mi id="S4.SS2.p6.11.m11.2.2.2.2.3" xref="S4.SS2.p6.11.m11.2.2.2.2.3.cmml">proj</mi></msub><mo id="S4.SS2.p6.11.m11.3.3.3.5" xref="S4.SS2.p6.11.m11.3.3.4.cmml">,</mo><msub id="S4.SS2.p6.11.m11.3.3.3.3" xref="S4.SS2.p6.11.m11.3.3.3.3.cmml"><mi id="S4.SS2.p6.11.m11.3.3.3.3.2" xref="S4.SS2.p6.11.m11.3.3.3.3.2.cmml">v</mi><mi id="S4.SS2.p6.11.m11.3.3.3.3.3" xref="S4.SS2.p6.11.m11.3.3.3.3.3.cmml">proj</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.11.m11.3b"><list id="S4.SS2.p6.11.m11.3.3.4.cmml" xref="S4.SS2.p6.11.m11.3.3.3"><apply id="S4.SS2.p6.11.m11.1.1.1.1.cmml" xref="S4.SS2.p6.11.m11.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.11.m11.1.1.1.1.1.cmml" xref="S4.SS2.p6.11.m11.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p6.11.m11.1.1.1.1.2.cmml" xref="S4.SS2.p6.11.m11.1.1.1.1.2">𝑞</ci><ci id="S4.SS2.p6.11.m11.1.1.1.1.3.cmml" xref="S4.SS2.p6.11.m11.1.1.1.1.3">proj</ci></apply><apply id="S4.SS2.p6.11.m11.2.2.2.2.cmml" xref="S4.SS2.p6.11.m11.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p6.11.m11.2.2.2.2.1.cmml" xref="S4.SS2.p6.11.m11.2.2.2.2">subscript</csymbol><ci id="S4.SS2.p6.11.m11.2.2.2.2.2.cmml" xref="S4.SS2.p6.11.m11.2.2.2.2.2">𝑘</ci><ci id="S4.SS2.p6.11.m11.2.2.2.2.3.cmml" xref="S4.SS2.p6.11.m11.2.2.2.2.3">proj</ci></apply><apply id="S4.SS2.p6.11.m11.3.3.3.3.cmml" xref="S4.SS2.p6.11.m11.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p6.11.m11.3.3.3.3.1.cmml" xref="S4.SS2.p6.11.m11.3.3.3.3">subscript</csymbol><ci id="S4.SS2.p6.11.m11.3.3.3.3.2.cmml" xref="S4.SS2.p6.11.m11.3.3.3.3.2">𝑣</ci><ci id="S4.SS2.p6.11.m11.3.3.3.3.3.cmml" xref="S4.SS2.p6.11.m11.3.3.3.3.3">proj</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.11.m11.3c">q_{\mathrm{proj}},k_{\mathrm{proj}},v_{\mathrm{proj}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.11.m11.3d">italic_q start_POSTSUBSCRIPT roman_proj end_POSTSUBSCRIPT , italic_k start_POSTSUBSCRIPT roman_proj end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT roman_proj end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="o_{\mathrm{proj}}" class="ltx_Math" display="inline" id="S4.SS2.p6.12.m12.1"><semantics id="S4.SS2.p6.12.m12.1a"><msub id="S4.SS2.p6.12.m12.1.1" xref="S4.SS2.p6.12.m12.1.1.cmml"><mi id="S4.SS2.p6.12.m12.1.1.2" xref="S4.SS2.p6.12.m12.1.1.2.cmml">o</mi><mi id="S4.SS2.p6.12.m12.1.1.3" xref="S4.SS2.p6.12.m12.1.1.3.cmml">proj</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.12.m12.1b"><apply id="S4.SS2.p6.12.m12.1.1.cmml" xref="S4.SS2.p6.12.m12.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.12.m12.1.1.1.cmml" xref="S4.SS2.p6.12.m12.1.1">subscript</csymbol><ci id="S4.SS2.p6.12.m12.1.1.2.cmml" xref="S4.SS2.p6.12.m12.1.1.2">𝑜</ci><ci id="S4.SS2.p6.12.m12.1.1.3.cmml" xref="S4.SS2.p6.12.m12.1.1.3">proj</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.12.m12.1c">o_{\mathrm{proj}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.12.m12.1d">italic_o start_POSTSUBSCRIPT roman_proj end_POSTSUBSCRIPT</annotation></semantics></math> layers, with a dropout of <math alttext="0.05" class="ltx_Math" display="inline" id="S4.SS2.p6.13.m13.1"><semantics id="S4.SS2.p6.13.m13.1a"><mn id="S4.SS2.p6.13.m13.1.1" xref="S4.SS2.p6.13.m13.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.13.m13.1b"><cn id="S4.SS2.p6.13.m13.1.1.cmml" type="float" xref="S4.SS2.p6.13.m13.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.13.m13.1c">0.05</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.13.m13.1d">0.05</annotation></semantics></math>. Besides LoRA, we employ other efficient training techniques such as Flash Attention&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib16" title="">16</a>]</cite> for faster attention computation with reduced memory requirements and Bitsandbytes&nbsp;<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/docs/transformers/v4.44.2/quantization/bitsandbytes" title="">https://huggingface.co/docs/transformers/v4.44.2/quantization/bitsandbytes</a></span></span></span> for quantization to decrease memory usage during training.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p7">
<p class="ltx_p" id="S4.SS2.p7.1">Due to computational constraints, we limit the maximum number of tokens for each post to <math alttext="2{,}500" class="ltx_Math" display="inline" id="S4.SS2.p7.1.m1.2"><semantics id="S4.SS2.p7.1.m1.2a"><mrow id="S4.SS2.p7.1.m1.2.3.2" xref="S4.SS2.p7.1.m1.2.3.1.cmml"><mn id="S4.SS2.p7.1.m1.1.1" xref="S4.SS2.p7.1.m1.1.1.cmml">2</mn><mo id="S4.SS2.p7.1.m1.2.3.2.1" xref="S4.SS2.p7.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS2.p7.1.m1.2.2" xref="S4.SS2.p7.1.m1.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.1.m1.2b"><list id="S4.SS2.p7.1.m1.2.3.1.cmml" xref="S4.SS2.p7.1.m1.2.3.2"><cn id="S4.SS2.p7.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p7.1.m1.1.1">2</cn><cn id="S4.SS2.p7.1.m1.2.2.cmml" type="integer" xref="S4.SS2.p7.1.m1.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.1.m1.2c">2{,}500</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p7.1.m1.2d">2 , 500</annotation></semantics></math> tokens. This is chosen to cover the majority of posts without losing significant information, as demonstrated in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.F7.sf2" title="In Figure 7 ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">7(b)</span></a> and Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.F7.sf3" title="In Figure 7 ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">7(c)</span></a>. If a post exceeds this limit, we remove the middle portion, as prior work observed that the beginning and end of posts usually contain important information for text analysis&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib41" title="">41</a>]</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p8">
<p class="ltx_p" id="S4.SS2.p8.1">After fine-tuning for <math alttext="20" class="ltx_Math" display="inline" id="S4.SS2.p8.1.m1.1"><semantics id="S4.SS2.p8.1.m1.1a"><mn id="S4.SS2.p8.1.m1.1.1" xref="S4.SS2.p8.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p8.1.m1.1b"><cn id="S4.SS2.p8.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p8.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p8.1.m1.1c">20</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p8.1.m1.1d">20</annotation></semantics></math> epochs, we select the model checkpoint with the highest F1 Score on the validation set as the final classifier.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p9">
<p class="ltx_p" id="S4.SS2.p9.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p9.1.1">Loss function.</span> Since F1 Score is computed via
precision and recall, it is not differentiable. To directly optimize the F1 score, we use Macro Double Soft F1, introduced by&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib33" title="">33</a>]</cite>, as our loss function. The idea is to make F1-score differentiable by modifying its computation. Specifically, <span class="ltx_text ltx_font_italic" id="S4.SS2.p9.1.2">True Positives, False Positives</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS2.p9.1.3">False Negatives</span> are derived from a continuous sum of likelihood values using probabilities, eliminating the need for thresholds. We found that optimizing with this loss function in our experiment data gains some performance boost compared with other common choices such as Cross Entropy (Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.T6" title="TABLE VI ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">VI</span></a>).
Algorithm&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#alg1" title="In IV-B Fine-tuning Large Language Models for suicide classification ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">1</span></a> shows the pseudo-code of the loss.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_float ltx_algorithm" id="alg1">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="alg1.2">
<div class="ltx_listingline" id="alg1.2.1">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.1.1" style="font-size:80%;color:#6E9A9B;"> <span class="ltx_text ltx_font_bold" id="alg1.2.1.1.1">Parameters</span>:</span>
</div>
<div class="ltx_listingline" id="alg1.2.2">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.2.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.2.2" style="font-size:80%;color:#6E9A9B;"> <span class="ltx_text ltx_font_italic" id="alg1.2.2.2.1">y</span>: one-hot vector of true labels, shape (batch size, num classes)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.2.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.3">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.3.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.3.2" style="font-size:80%;color:#6E9A9B;"> <span class="ltx_text ltx_font_italic" id="alg1.2.3.2.1">logits</span>: raw predictions, shape (batch size, num classes)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.3.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.4">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.4.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.4.2" style="font-size:80%;color:#6E9A9B;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.5">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.5.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.5.2" style="font-size:80%;color:#6E9A9B;"># Convert true labels to float</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.5.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.6">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.6.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.6.2" style="font-size:80%;color:#000000;">y = y.float()</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.6.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.7">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.7.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.7.2" style="font-size:80%;color:#6E9A9B;"># Pass logits to sigmoid</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.7.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.8">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.8.1" style="font-size:80%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.2.9">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.9.1" style="font-size:80%;color:#000000;">y_hat = F.sigmoid(logits.float())</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.9.2" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.10">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.10.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.10.2" style="font-size:80%;color:#6E9A9B;"># Compute true positives, false positives, false negatives, and true negatives</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.10.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.11">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.11.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.11.2" style="font-size:80%;color:#000000;">tp = torch.sum(y_hat * y, dim=0)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.11.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.12">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.12.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.12.2" style="font-size:80%;color:#000000;">fp = torch.sum(y_hat * (1 - y), dim=0)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.12.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.13">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.13.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.13.2" style="font-size:80%;color:#000000;">fn = torch.sum((1 - y_hat) * y, dim=0)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.13.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.14">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.14.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.14.2" style="font-size:80%;color:#000000;">tn = torch.sum((1 - y_hat) * (1 - y), dim=0)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.14.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.15">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.15.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.15.2" style="font-size:80%;color:#6E9A9B;"># Calculate soft F1 scores for class 1 and class 0, small epsilon prevents divided by zero</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.15.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.16">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.16.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.16.2" style="font-size:80%;color:#000000;">soft_f1_class1 = 2 * tp / (2 * tp + fn + fp + 1e-16)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.16.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.17">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.17.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.17.2" style="font-size:80%;color:#000000;">soft_f1_class0 = 2 * tn / (2 * tn + fn + fp + 1e-16)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.17.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.18">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.18.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.18.2" style="font-size:80%;color:#6E9A9B;"># Calculate losses for both classes</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.18.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.19">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.19.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.19.2" style="font-size:80%;color:#000000;">cost_class1 = 1 - soft_f1_class1</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.19.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.20">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.20.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.20.2" style="font-size:80%;color:#000000;">cost_class0 = 1 - soft_f1_class0</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.20.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.21">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.21.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.21.2" style="font-size:80%;color:#6E9A9B;"># Compute loss</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.21.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.22">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.22.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.22.2" style="font-size:80%;color:#000000;">cost = 0.5 * (cost_class1 + cost_class0)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.22.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.23">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.23.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.23.2" style="font-size:80%;color:#000000;">soft_f1_loss = torch.mean(cost)</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.23.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.24">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.24.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.24.2" style="font-size:80%;color:#6E9A9B;"># Return the f1 loss</span><span class="ltx_text ltx_font_typewriter" id="alg1.2.24.3" style="font-size:80%;"> </span>
</div>
<div class="ltx_listingline" id="alg1.2.25">
<span class="ltx_text ltx_font_typewriter" id="alg1.2.25.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="alg1.2.25.2" style="font-size:80%;color:#000000;">Return <span class="ltx_text ltx_font_medium" id="alg1.2.25.2.1"> soft_f1_loss</span></span><span class="ltx_text ltx_font_typewriter" id="alg1.2.25.3" style="font-size:80%;">
</span>
</div>
</div>
<figcaption class="ltx_caption ltx_font_typewriter" style="font-size:80%;"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_bold" id="alg1.8.1.1">Algorithm&nbsp;1</span> </span>Pseudo code of Macro Double Soft F1 Loss&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib33" title="">33</a>]</cite> in Pytorch</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.5.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.6.2">Ensemble Model for a robust and performant classifier</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.10">Ensemble modeling has been shown to significantly improve the accuracy and reliability of predictions (<em class="ltx_emph ltx_font_italic" id="S4.SS3.p1.10.1">e.g</em>.<span class="ltx_text" id="S4.SS3.p1.10.2"></span>, &nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib41" title="">41</a>]</cite>). In the same spirit, we create an ensemble model by using majority voting of class predictions from some individual models.
Let <math alttext="\mathrm{C}" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" mathvariant="normal" xref="S4.SS3.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">C</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\mathrm{C}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">roman_C</annotation></semantics></math> be the set of all classes (<math alttext="\mathrm{C}=" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi id="S4.SS3.p1.2.m2.1.1.2" mathvariant="normal" xref="S4.SS3.p1.2.m2.1.1.2.cmml">C</mi><mo id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml">=</mo><mi id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><eq id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1"></eq><ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">C</ci><csymbol cd="latexml" id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\mathrm{C}=</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.2.m2.1d">roman_C =</annotation></semantics></math>{<span class="ltx_text ltx_font_italic" id="S4.SS3.p1.10.3">Indicator</span>, <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.10.4">Ideation</span>, <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.10.5">Behaviour</span>, <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.10.6">Attempt</span>}), <math alttext="\mathrm{m}_{i}" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.1"><semantics id="S4.SS3.p1.3.m3.1a"><msub id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mi id="S4.SS3.p1.3.m3.1.1.2" mathvariant="normal" xref="S4.SS3.p1.3.m3.1.1.2.cmml">m</mi><mi id="S4.SS3.p1.3.m3.1.1.3" xref="S4.SS3.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.p1.3.m3.1.1.2">m</ci><ci id="S4.SS3.p1.3.m3.1.1.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">\mathrm{m}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.3.m3.1d">roman_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> be the class prediction of model <math alttext="i" class="ltx_Math" display="inline" id="S4.SS3.p1.4.m4.1"><semantics id="S4.SS3.p1.4.m4.1a"><mi id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><ci id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.4.m4.1d">italic_i</annotation></semantics></math> (<math alttext="\mathrm{m}_{i}\in\mathrm{C}" class="ltx_Math" display="inline" id="S4.SS3.p1.5.m5.1"><semantics id="S4.SS3.p1.5.m5.1a"><mrow id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><msub id="S4.SS3.p1.5.m5.1.1.2" xref="S4.SS3.p1.5.m5.1.1.2.cmml"><mi id="S4.SS3.p1.5.m5.1.1.2.2" mathvariant="normal" xref="S4.SS3.p1.5.m5.1.1.2.2.cmml">m</mi><mi id="S4.SS3.p1.5.m5.1.1.2.3" xref="S4.SS3.p1.5.m5.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS3.p1.5.m5.1.1.1" xref="S4.SS3.p1.5.m5.1.1.1.cmml">∈</mo><mi id="S4.SS3.p1.5.m5.1.1.3" mathvariant="normal" xref="S4.SS3.p1.5.m5.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><in id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1.1"></in><apply id="S4.SS3.p1.5.m5.1.1.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m5.1.1.2.1.cmml" xref="S4.SS3.p1.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.5.m5.1.1.2.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2.2">m</ci><ci id="S4.SS3.p1.5.m5.1.1.2.3.cmml" xref="S4.SS3.p1.5.m5.1.1.2.3">𝑖</ci></apply><ci id="S4.SS3.p1.5.m5.1.1.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3">C</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">\mathrm{m}_{i}\in\mathrm{C}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.5.m5.1d">roman_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ roman_C</annotation></semantics></math>), <math alttext="\mathrm{w}_{i}\in\mathbb{R}" class="ltx_Math" display="inline" id="S4.SS3.p1.6.m6.1"><semantics id="S4.SS3.p1.6.m6.1a"><mrow id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml"><msub id="S4.SS3.p1.6.m6.1.1.2" xref="S4.SS3.p1.6.m6.1.1.2.cmml"><mi id="S4.SS3.p1.6.m6.1.1.2.2" mathvariant="normal" xref="S4.SS3.p1.6.m6.1.1.2.2.cmml">w</mi><mi id="S4.SS3.p1.6.m6.1.1.2.3" xref="S4.SS3.p1.6.m6.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS3.p1.6.m6.1.1.1" xref="S4.SS3.p1.6.m6.1.1.1.cmml">∈</mo><mi id="S4.SS3.p1.6.m6.1.1.3" xref="S4.SS3.p1.6.m6.1.1.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><apply id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1"><in id="S4.SS3.p1.6.m6.1.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1.1"></in><apply id="S4.SS3.p1.6.m6.1.1.2.cmml" xref="S4.SS3.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.6.m6.1.1.2.1.cmml" xref="S4.SS3.p1.6.m6.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.6.m6.1.1.2.2.cmml" xref="S4.SS3.p1.6.m6.1.1.2.2">w</ci><ci id="S4.SS3.p1.6.m6.1.1.2.3.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3">𝑖</ci></apply><ci id="S4.SS3.p1.6.m6.1.1.3.cmml" xref="S4.SS3.p1.6.m6.1.1.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">\mathrm{w}_{i}\in\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.6.m6.1d">roman_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R</annotation></semantics></math> be the ensemble weight of model <math alttext="i" class="ltx_Math" display="inline" id="S4.SS3.p1.7.m7.1"><semantics id="S4.SS3.p1.7.m7.1a"><mi id="S4.SS3.p1.7.m7.1.1" xref="S4.SS3.p1.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m7.1b"><ci id="S4.SS3.p1.7.m7.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.7.m7.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.7.m7.1d">italic_i</annotation></semantics></math>, and <math alttext="n" class="ltx_Math" display="inline" id="S4.SS3.p1.8.m8.1"><semantics id="S4.SS3.p1.8.m8.1a"><mi id="S4.SS3.p1.8.m8.1.1" xref="S4.SS3.p1.8.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.8.m8.1b"><ci id="S4.SS3.p1.8.m8.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.8.m8.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.8.m8.1d">italic_n</annotation></semantics></math> denote the number of models to ensemble. The weighted majority voting <math alttext="\mathrm{p}" class="ltx_Math" display="inline" id="S4.SS3.p1.9.m9.1"><semantics id="S4.SS3.p1.9.m9.1a"><mi id="S4.SS3.p1.9.m9.1.1" mathvariant="normal" xref="S4.SS3.p1.9.m9.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.9.m9.1b"><ci id="S4.SS3.p1.9.m9.1.1.cmml" xref="S4.SS3.p1.9.m9.1.1">p</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.9.m9.1c">\mathrm{p}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.9.m9.1d">roman_p</annotation></semantics></math> over all prediction <math alttext="\mathrm{m}_{i}" class="ltx_Math" display="inline" id="S4.SS3.p1.10.m10.1"><semantics id="S4.SS3.p1.10.m10.1a"><msub id="S4.SS3.p1.10.m10.1.1" xref="S4.SS3.p1.10.m10.1.1.cmml"><mi id="S4.SS3.p1.10.m10.1.1.2" mathvariant="normal" xref="S4.SS3.p1.10.m10.1.1.2.cmml">m</mi><mi id="S4.SS3.p1.10.m10.1.1.3" xref="S4.SS3.p1.10.m10.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.10.m10.1b"><apply id="S4.SS3.p1.10.m10.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.10.m10.1.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1">subscript</csymbol><ci id="S4.SS3.p1.10.m10.1.1.2.cmml" xref="S4.SS3.p1.10.m10.1.1.2">m</ci><ci id="S4.SS3.p1.10.m10.1.1.3.cmml" xref="S4.SS3.p1.10.m10.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.10.m10.1c">\mathrm{m}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.10.m10.1d">roman_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is defined as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\arg\max_{\mathrm{p}}\sum_{i=1}^{n}\mathrm{w}_{i}\cdot\mathbb{1}\left(\mathrm{%
m}_{i}=\mathrm{p}\right)" class="ltx_Math" display="block" id="S4.E4.m1.1"><semantics id="S4.E4.m1.1a"><mrow id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml"><mrow id="S4.E4.m1.1.1.3" xref="S4.E4.m1.1.1.3.cmml"><mi id="S4.E4.m1.1.1.3.1" xref="S4.E4.m1.1.1.3.1.cmml">arg</mi><mo id="S4.E4.m1.1.1.3a" lspace="0.167em" xref="S4.E4.m1.1.1.3.cmml">⁡</mo><munder id="S4.E4.m1.1.1.3.2" xref="S4.E4.m1.1.1.3.2.cmml"><mi id="S4.E4.m1.1.1.3.2.2" xref="S4.E4.m1.1.1.3.2.2.cmml">max</mi><mi id="S4.E4.m1.1.1.3.2.3" mathvariant="normal" xref="S4.E4.m1.1.1.3.2.3.cmml">p</mi></munder></mrow><mo id="S4.E4.m1.1.1.2" xref="S4.E4.m1.1.1.2.cmml">⁢</mo><mrow id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.cmml"><munderover id="S4.E4.m1.1.1.1.2" xref="S4.E4.m1.1.1.1.2.cmml"><mo id="S4.E4.m1.1.1.1.2.2.2" movablelimits="false" xref="S4.E4.m1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S4.E4.m1.1.1.1.2.2.3" xref="S4.E4.m1.1.1.1.2.2.3.cmml"><mi id="S4.E4.m1.1.1.1.2.2.3.2" xref="S4.E4.m1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S4.E4.m1.1.1.1.2.2.3.1" xref="S4.E4.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E4.m1.1.1.1.2.2.3.3" xref="S4.E4.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E4.m1.1.1.1.2.3" xref="S4.E4.m1.1.1.1.2.3.cmml">n</mi></munderover><mrow id="S4.E4.m1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><mrow id="S4.E4.m1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.3.cmml"><msub id="S4.E4.m1.1.1.1.1.3.2" xref="S4.E4.m1.1.1.1.1.3.2.cmml"><mi id="S4.E4.m1.1.1.1.1.3.2.2" mathvariant="normal" xref="S4.E4.m1.1.1.1.1.3.2.2.cmml">w</mi><mi id="S4.E4.m1.1.1.1.1.3.2.3" xref="S4.E4.m1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo id="S4.E4.m1.1.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S4.E4.m1.1.1.1.1.3.1.cmml">⋅</mo><mn id="S4.E4.m1.1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.1.3.3.cmml">𝟙</mn></mrow><mo id="S4.E4.m1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E4.m1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml"><mo id="S4.E4.m1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml"><msub id="S4.E4.m1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.1.2.2" mathvariant="normal" xref="S4.E4.m1.1.1.1.1.1.1.1.2.2.cmml">m</mi><mi id="S4.E4.m1.1.1.1.1.1.1.1.2.3" xref="S4.E4.m1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.E4.m1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">=</mo><mi id="S4.E4.m1.1.1.1.1.1.1.1.3" mathvariant="normal" xref="S4.E4.m1.1.1.1.1.1.1.1.3.cmml">p</mi></mrow><mo id="S4.E4.m1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.1b"><apply id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1"><times id="S4.E4.m1.1.1.2.cmml" xref="S4.E4.m1.1.1.2"></times><apply id="S4.E4.m1.1.1.3.cmml" xref="S4.E4.m1.1.1.3"><arg id="S4.E4.m1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.3.1"></arg><apply id="S4.E4.m1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.3.2.1.cmml" xref="S4.E4.m1.1.1.3.2">subscript</csymbol><max id="S4.E4.m1.1.1.3.2.2.cmml" xref="S4.E4.m1.1.1.3.2.2"></max><ci id="S4.E4.m1.1.1.3.2.3.cmml" xref="S4.E4.m1.1.1.3.2.3">p</ci></apply></apply><apply id="S4.E4.m1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><apply id="S4.E4.m1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.2.1.cmml" xref="S4.E4.m1.1.1.1.2">superscript</csymbol><apply id="S4.E4.m1.1.1.1.2.2.cmml" xref="S4.E4.m1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.2.2.1.cmml" xref="S4.E4.m1.1.1.1.2">subscript</csymbol><sum id="S4.E4.m1.1.1.1.2.2.2.cmml" xref="S4.E4.m1.1.1.1.2.2.2"></sum><apply id="S4.E4.m1.1.1.1.2.2.3.cmml" xref="S4.E4.m1.1.1.1.2.2.3"><eq id="S4.E4.m1.1.1.1.2.2.3.1.cmml" xref="S4.E4.m1.1.1.1.2.2.3.1"></eq><ci id="S4.E4.m1.1.1.1.2.2.3.2.cmml" xref="S4.E4.m1.1.1.1.2.2.3.2">𝑖</ci><cn id="S4.E4.m1.1.1.1.2.2.3.3.cmml" type="integer" xref="S4.E4.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E4.m1.1.1.1.2.3.cmml" xref="S4.E4.m1.1.1.1.2.3">𝑛</ci></apply><apply id="S4.E4.m1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1"><times id="S4.E4.m1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.2"></times><apply id="S4.E4.m1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.3"><ci id="S4.E4.m1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.1.3.1">⋅</ci><apply id="S4.E4.m1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.3.2.1.cmml" xref="S4.E4.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.3.2.2.cmml" xref="S4.E4.m1.1.1.1.1.3.2.2">w</ci><ci id="S4.E4.m1.1.1.1.1.3.2.3.cmml" xref="S4.E4.m1.1.1.1.1.3.2.3">𝑖</ci></apply><cn id="S4.E4.m1.1.1.1.1.3.3.cmml" type="integer" xref="S4.E4.m1.1.1.1.1.3.3">1</cn></apply><apply id="S4.E4.m1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1"><eq id="S4.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1"></eq><apply id="S4.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2.2">m</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S4.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3">p</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.1c">\arg\max_{\mathrm{p}}\sum_{i=1}^{n}\mathrm{w}_{i}\cdot\mathbb{1}\left(\mathrm{%
m}_{i}=\mathrm{p}\right)</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.1d">roman_arg roman_max start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT roman_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ blackboard_1 ( roman_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = roman_p )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.5">Our ensemble model consisting of five individual models: <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS3.p3.5.1" style="color:#5844D0;">Qwen2-72B-Instruct</span> via prompting, and four fine-tuned large language models (LLMs) - <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS3.p3.5.2" style="color:#F28822;">Llama3-8B</span> (with two variants differing in hyperparameters, denoted as <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.5.3">Llama3-8B 1</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.5.4">Llama3-8B 2</span>), <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS3.p3.5.5" style="color:#EF42F5;">Llama3.1-8B</span>, and <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS3.p3.5.6" style="color:#00E6E6;">Gemma2-9B</span>, as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S2.F1" title="Figure 1 ‣ II-A Datasets ‣ II Datasets and metrics ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">1</span></a>(c). From <math alttext="500" class="ltx_Math" display="inline" id="S4.SS3.p3.1.m1.1"><semantics id="S4.SS3.p3.1.m1.1a"><mn id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><cn id="S4.SS3.p3.1.m1.1.1.cmml" type="integer" xref="S4.SS3.p3.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.1.m1.1d">500</annotation></semantics></math> labeled data, we assign the ensemble weight <math alttext="\mathrm{w}_{i}" class="ltx_Math" display="inline" id="S4.SS3.p3.2.m2.1"><semantics id="S4.SS3.p3.2.m2.1a"><msub id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml"><mi id="S4.SS3.p3.2.m2.1.1.2" mathvariant="normal" xref="S4.SS3.p3.2.m2.1.1.2.cmml">w</mi><mi id="S4.SS3.p3.2.m2.1.1.3" xref="S4.SS3.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.2.m2.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p3.2.m2.1.1.2.cmml" xref="S4.SS3.p3.2.m2.1.1.2">w</ci><ci id="S4.SS3.p3.2.m2.1.1.3.cmml" xref="S4.SS3.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">\mathrm{w}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.2.m2.1d">roman_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to the models, with a weight of <math alttext="2" class="ltx_Math" display="inline" id="S4.SS3.p3.3.m3.1"><semantics id="S4.SS3.p3.3.m3.1a"><mn id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><cn id="S4.SS3.p3.3.m3.1.1.cmml" type="integer" xref="S4.SS3.p3.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">2</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.3.m3.1d">2</annotation></semantics></math> for <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.5.7">Qwen2-72B-Instruct</span>, and a weight of <math alttext="1" class="ltx_Math" display="inline" id="S4.SS3.p3.4.m4.1"><semantics id="S4.SS3.p3.4.m4.1a"><mn id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><cn id="S4.SS3.p3.4.m4.1.1.cmml" type="integer" xref="S4.SS3.p3.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">1</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.4.m4.1d">1</annotation></semantics></math> for the other four models. This means that the prediction of <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.5.8">Qwen2-72B-Instruct</span> counts twice, whereas all other models count once. The final prediction <math alttext="\mathrm{p}" class="ltx_Math" display="inline" id="S4.SS3.p3.5.m5.1"><semantics id="S4.SS3.p3.5.m5.1a"><mi id="S4.SS3.p3.5.m5.1.1" mathvariant="normal" xref="S4.SS3.p3.5.m5.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.1b"><ci id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1">p</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.1c">\mathrm{p}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.5.m5.1d">roman_p</annotation></semantics></math> is determined through a weighted majority voting over the five models as illustrated in Eq.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S4.E4" title="In IV-C Ensemble Model for a robust and performant classifier ‣ IV Leveraging Large Language Models for suicide classification with limited labels ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">4</span></a>. This ensemble approach combines the strengths of each individual model to create a more performant and robust classifier, as demonstrated and discussed in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S5" title="V Results ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">V</span></a> and Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6" title="VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">VI</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Results</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="406" id="S5.F4.g1" src="https://arxiv.org/html/2410.04501v1/x4.png" width="789">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.3.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text ltx_font_bold" id="S5.F4.4.2" style="font-size:90%;">Comparison of F1 Scores for our models on the Public Board Test Set.<span class="ltx_text ltx_font_medium" id="S5.F4.4.2.1"> The ensemble model shows its robustness and significantly outperforms the individual models, demonstrating an improvement of approximately 5% points in the F1 Score on the new test set.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE IV: </span><span class="ltx_text ltx_font_bold" id="S5.T4.4.1">Comparison of Accuracy and F1 Scores for our models in the <math alttext="\mathbf{5}-" class="ltx_Math" display="inline" id="S5.T4.4.1.m1.1"><semantics id="S5.T4.4.1.m1.1b"><mrow id="S5.T4.4.1.m1.1.1" xref="S5.T4.4.1.m1.1.1.cmml"><mn id="S5.T4.4.1.m1.1.1.2" xref="S5.T4.4.1.m1.1.1.2.cmml">𝟓</mn><mo id="S5.T4.4.1.m1.1.1.3" xref="S5.T4.4.1.m1.1.1.3.cmml">−</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.4.1.m1.1c"><apply id="S5.T4.4.1.m1.1.1.cmml" xref="S5.T4.4.1.m1.1.1"><csymbol cd="latexml" id="S5.T4.4.1.m1.1.1.1.cmml" xref="S5.T4.4.1.m1.1.1">limit-from</csymbol><cn id="S5.T4.4.1.m1.1.1.2.cmml" type="integer" xref="S5.T4.4.1.m1.1.1.2">5</cn><minus id="S5.T4.4.1.m1.1.1.3.cmml" xref="S5.T4.4.1.m1.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.1.m1.1d">\mathbf{5}-</annotation><annotation encoding="application/x-llamapun" id="S5.T4.4.1.m1.1e">bold_5 -</annotation></semantics></math>fold cross-validation.</span> The ensemble model outperformed the individual models in both accuracy and F1 score, with improvements of around <math alttext="1-4" class="ltx_Math" display="inline" id="S5.T4.5.m1.1"><semantics id="S5.T4.5.m1.1b"><mrow id="S5.T4.5.m1.1.1" xref="S5.T4.5.m1.1.1.cmml"><mn id="S5.T4.5.m1.1.1.2" xref="S5.T4.5.m1.1.1.2.cmml">1</mn><mo id="S5.T4.5.m1.1.1.1" xref="S5.T4.5.m1.1.1.1.cmml">−</mo><mn id="S5.T4.5.m1.1.1.3" xref="S5.T4.5.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.5.m1.1c"><apply id="S5.T4.5.m1.1.1.cmml" xref="S5.T4.5.m1.1.1"><minus id="S5.T4.5.m1.1.1.1.cmml" xref="S5.T4.5.m1.1.1.1"></minus><cn id="S5.T4.5.m1.1.1.2.cmml" type="integer" xref="S5.T4.5.m1.1.1.2">1</cn><cn id="S5.T4.5.m1.1.1.3.cmml" type="integer" xref="S5.T4.5.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.m1.1d">1-4</annotation><annotation encoding="application/x-llamapun" id="S5.T4.5.m1.1e">1 - 4</annotation></semantics></math>% in accuracy and <math alttext="0.01-0.04" class="ltx_Math" display="inline" id="S5.T4.6.m2.1"><semantics id="S5.T4.6.m2.1b"><mrow id="S5.T4.6.m2.1.1" xref="S5.T4.6.m2.1.1.cmml"><mn id="S5.T4.6.m2.1.1.2" xref="S5.T4.6.m2.1.1.2.cmml">0.01</mn><mo id="S5.T4.6.m2.1.1.1" xref="S5.T4.6.m2.1.1.1.cmml">−</mo><mn id="S5.T4.6.m2.1.1.3" xref="S5.T4.6.m2.1.1.3.cmml">0.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.6.m2.1c"><apply id="S5.T4.6.m2.1.1.cmml" xref="S5.T4.6.m2.1.1"><minus id="S5.T4.6.m2.1.1.1.cmml" xref="S5.T4.6.m2.1.1.1"></minus><cn id="S5.T4.6.m2.1.1.2.cmml" type="float" xref="S5.T4.6.m2.1.1.2">0.01</cn><cn id="S5.T4.6.m2.1.1.3.cmml" type="float" xref="S5.T4.6.m2.1.1.3">0.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.m2.1d">0.01-0.04</annotation><annotation encoding="application/x-llamapun" id="S5.T4.6.m2.1e">0.01 - 0.04</annotation></semantics></math> in the F1 Score.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.18">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T4.18.13.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T4.18.13.1.1"><span class="ltx_text ltx_font_bold" id="S5.T4.18.13.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.18.13.1.2"><span class="ltx_text ltx_font_bold" id="S5.T4.18.13.1.2.1" style="font-size:90%;">Accuracy (%)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.18.13.1.3"><span class="ltx_text ltx_font_bold" id="S5.T4.18.13.1.3.1" style="font-size:90%;">F1 Score</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.8.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.8.2.3"><span class="ltx_text" id="S5.T4.8.2.3.1" style="font-size:90%;">Llama3-8B 1</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.7.1.1">
<span class="ltx_text" id="S5.T4.7.1.1.1" style="font-size:90%;">77.0 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.7.1.1.m1.1"><semantics id="S5.T4.7.1.1.m1.1a"><mo id="S5.T4.7.1.1.m1.1.1" mathsize="90%" xref="S5.T4.7.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.7.1.1.m1.1b"><csymbol cd="latexml" id="S5.T4.7.1.1.m1.1.1.cmml" xref="S5.T4.7.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.7.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.7.1.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.7.1.1.2" style="font-size:90%;"> 2.3</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.2.2">
<span class="ltx_text" id="S5.T4.8.2.2.1" style="font-size:90%;">0.762 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.8.2.2.m1.1"><semantics id="S5.T4.8.2.2.m1.1a"><mo id="S5.T4.8.2.2.m1.1.1" mathsize="90%" xref="S5.T4.8.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.8.2.2.m1.1b"><csymbol cd="latexml" id="S5.T4.8.2.2.m1.1.1.cmml" xref="S5.T4.8.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.8.2.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.8.2.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.8.2.2.2" style="font-size:90%;"> 0.030</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.10.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.10.4.3"><span class="ltx_text" id="S5.T4.10.4.3.1" style="font-size:90%;">Llama3-8B 2</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.9.3.1">
<span class="ltx_text" id="S5.T4.9.3.1.1" style="font-size:90%;">77.4 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.9.3.1.m1.1"><semantics id="S5.T4.9.3.1.m1.1a"><mo id="S5.T4.9.3.1.m1.1.1" mathsize="90%" xref="S5.T4.9.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.9.3.1.m1.1b"><csymbol cd="latexml" id="S5.T4.9.3.1.m1.1.1.cmml" xref="S5.T4.9.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.9.3.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.9.3.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.9.3.1.2" style="font-size:90%;"> 3.1</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.10.4.2">
<span class="ltx_text" id="S5.T4.10.4.2.1" style="font-size:90%;">0.771 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.10.4.2.m1.1"><semantics id="S5.T4.10.4.2.m1.1a"><mo id="S5.T4.10.4.2.m1.1.1" mathsize="90%" xref="S5.T4.10.4.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.10.4.2.m1.1b"><csymbol cd="latexml" id="S5.T4.10.4.2.m1.1.1.cmml" xref="S5.T4.10.4.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.10.4.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.10.4.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.10.4.2.2" style="font-size:90%;"> 0.032</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.12.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.12.6.3"><span class="ltx_text" id="S5.T4.12.6.3.1" style="font-size:90%;">Gemma2-9B</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.11.5.1">
<span class="ltx_text" id="S5.T4.11.5.1.1" style="font-size:90%;">80.6 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.11.5.1.m1.1"><semantics id="S5.T4.11.5.1.m1.1a"><mo id="S5.T4.11.5.1.m1.1.1" mathsize="90%" xref="S5.T4.11.5.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.11.5.1.m1.1b"><csymbol cd="latexml" id="S5.T4.11.5.1.m1.1.1.cmml" xref="S5.T4.11.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.11.5.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.11.5.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.11.5.1.2" style="font-size:90%;"> 2.1</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.12.6.2">
<span class="ltx_text" id="S5.T4.12.6.2.1" style="font-size:90%;">0.805 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.12.6.2.m1.1"><semantics id="S5.T4.12.6.2.m1.1a"><mo id="S5.T4.12.6.2.m1.1.1" mathsize="90%" xref="S5.T4.12.6.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.12.6.2.m1.1b"><csymbol cd="latexml" id="S5.T4.12.6.2.m1.1.1.cmml" xref="S5.T4.12.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.12.6.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.12.6.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.12.6.2.2" style="font-size:90%;"> 0.023</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.14.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.14.8.3"><span class="ltx_text" id="S5.T4.14.8.3.1" style="font-size:90%;">Llama3.1-8B</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.13.7.1">
<span class="ltx_text" id="S5.T4.13.7.1.1" style="font-size:90%;">79.0 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.13.7.1.m1.1"><semantics id="S5.T4.13.7.1.m1.1a"><mo id="S5.T4.13.7.1.m1.1.1" mathsize="90%" xref="S5.T4.13.7.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.13.7.1.m1.1b"><csymbol cd="latexml" id="S5.T4.13.7.1.m1.1.1.cmml" xref="S5.T4.13.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.13.7.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.13.7.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.13.7.1.2" style="font-size:90%;"> 2.4</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.14.8.2">
<span class="ltx_text" id="S5.T4.14.8.2.1" style="font-size:90%;">0.789 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.14.8.2.m1.1"><semantics id="S5.T4.14.8.2.m1.1a"><mo id="S5.T4.14.8.2.m1.1.1" mathsize="90%" xref="S5.T4.14.8.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.14.8.2.m1.1b"><csymbol cd="latexml" id="S5.T4.14.8.2.m1.1.1.cmml" xref="S5.T4.14.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.14.8.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.14.8.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.14.8.2.2" style="font-size:90%;"> 0.025</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.16.10.3"><span class="ltx_text" id="S5.T4.16.10.3.1" style="font-size:90%;">Qwen2-72B-Instruct</span></th>
<td class="ltx_td ltx_align_center" id="S5.T4.15.9.1">
<span class="ltx_text" id="S5.T4.15.9.1.1" style="font-size:90%;">77.4 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.15.9.1.m1.1"><semantics id="S5.T4.15.9.1.m1.1a"><mo id="S5.T4.15.9.1.m1.1.1" mathsize="90%" xref="S5.T4.15.9.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.15.9.1.m1.1b"><csymbol cd="latexml" id="S5.T4.15.9.1.m1.1.1.cmml" xref="S5.T4.15.9.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.15.9.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.15.9.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.15.9.1.2" style="font-size:90%;"> 2.9</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.16.10.2">
<span class="ltx_text" id="S5.T4.16.10.2.1" style="font-size:90%;">0.772 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.16.10.2.m1.1"><semantics id="S5.T4.16.10.2.m1.1a"><mo id="S5.T4.16.10.2.m1.1.1" mathsize="90%" xref="S5.T4.16.10.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.16.10.2.m1.1b"><csymbol cd="latexml" id="S5.T4.16.10.2.m1.1.1.cmml" xref="S5.T4.16.10.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.16.10.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.16.10.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T4.16.10.2.2" style="font-size:90%;"> 0.029</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.18.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T4.18.12.3"><span class="ltx_text ltx_font_bold" id="S5.T4.18.12.3.1" style="font-size:90%;">Ensemble</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.17.11.1"><span class="ltx_text ltx_font_bold" id="S5.T4.17.11.1.1" style="font-size:90%;">81.2 <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.17.11.1.1.m1.1"><semantics id="S5.T4.17.11.1.1.m1.1a"><mo id="S5.T4.17.11.1.1.m1.1.1" xref="S5.T4.17.11.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.17.11.1.1.m1.1b"><csymbol cd="latexml" id="S5.T4.17.11.1.1.m1.1.1.cmml" xref="S5.T4.17.11.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.17.11.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.17.11.1.1.m1.1d">±</annotation></semantics></math> 2.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.18.12.2"><span class="ltx_text ltx_font_bold" id="S5.T4.18.12.2.1" style="font-size:90%;">0.811 <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.18.12.2.1.m1.1"><semantics id="S5.T4.18.12.2.1.m1.1a"><mo id="S5.T4.18.12.2.1.m1.1.1" xref="S5.T4.18.12.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T4.18.12.2.1.m1.1b"><csymbol cd="latexml" id="S5.T4.18.12.2.1.m1.1.1.cmml" xref="S5.T4.18.12.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.18.12.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T4.18.12.2.1.m1.1d">±</annotation></semantics></math> 0.023</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.6">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S5.T4" title="TABLE IV ‣ V Results ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">IV</span></a> presents a comparison of the average accuracy and F1 scores, along with their standard deviations, for our models using <math alttext="5" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><mn id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><cn id="S5.p1.1.m1.1.1.cmml" type="integer" xref="S5.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">5</annotation></semantics></math>-fold cross-validation. We can observe the ensemble model outperforms the five individual models. Specifically, <span class="ltx_text ltx_font_italic" id="S5.p1.6.1">Llama3-8B</span> and <span class="ltx_text ltx_font_italic" id="S5.p1.6.2">Qwen2-72B-Instruct</span> achieve approximately <math alttext="77" class="ltx_Math" display="inline" id="S5.p1.2.m2.1"><semantics id="S5.p1.2.m2.1a"><mn id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">77</mn><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><cn id="S5.p1.2.m2.1.1.cmml" type="integer" xref="S5.p1.2.m2.1.1">77</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">77</annotation><annotation encoding="application/x-llamapun" id="S5.p1.2.m2.1d">77</annotation></semantics></math>% accuracy, while <span class="ltx_text ltx_font_italic" id="S5.p1.6.3">Gemma2-9B</span> and <span class="ltx_text ltx_font_italic" id="S5.p1.6.4">LLaMA3.1-8B</span> score <math alttext="79-80" class="ltx_Math" display="inline" id="S5.p1.3.m3.1"><semantics id="S5.p1.3.m3.1a"><mrow id="S5.p1.3.m3.1.1" xref="S5.p1.3.m3.1.1.cmml"><mn id="S5.p1.3.m3.1.1.2" xref="S5.p1.3.m3.1.1.2.cmml">79</mn><mo id="S5.p1.3.m3.1.1.1" xref="S5.p1.3.m3.1.1.1.cmml">−</mo><mn id="S5.p1.3.m3.1.1.3" xref="S5.p1.3.m3.1.1.3.cmml">80</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.3.m3.1b"><apply id="S5.p1.3.m3.1.1.cmml" xref="S5.p1.3.m3.1.1"><minus id="S5.p1.3.m3.1.1.1.cmml" xref="S5.p1.3.m3.1.1.1"></minus><cn id="S5.p1.3.m3.1.1.2.cmml" type="integer" xref="S5.p1.3.m3.1.1.2">79</cn><cn id="S5.p1.3.m3.1.1.3.cmml" type="integer" xref="S5.p1.3.m3.1.1.3">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.3.m3.1c">79-80</annotation><annotation encoding="application/x-llamapun" id="S5.p1.3.m3.1d">79 - 80</annotation></semantics></math>% accuracy. The ensemble model achieves the highest accuracy at <math alttext="81.2" class="ltx_Math" display="inline" id="S5.p1.4.m4.1"><semantics id="S5.p1.4.m4.1a"><mn id="S5.p1.4.m4.1.1" xref="S5.p1.4.m4.1.1.cmml">81.2</mn><annotation-xml encoding="MathML-Content" id="S5.p1.4.m4.1b"><cn id="S5.p1.4.m4.1.1.cmml" type="float" xref="S5.p1.4.m4.1.1">81.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.4.m4.1c">81.2</annotation><annotation encoding="application/x-llamapun" id="S5.p1.4.m4.1d">81.2</annotation></semantics></math>%. Similarly, the ensemble model also attained the highest F1 score of <math alttext="0.811" class="ltx_Math" display="inline" id="S5.p1.5.m5.1"><semantics id="S5.p1.5.m5.1a"><mn id="S5.p1.5.m5.1.1" xref="S5.p1.5.m5.1.1.cmml">0.811</mn><annotation-xml encoding="MathML-Content" id="S5.p1.5.m5.1b"><cn id="S5.p1.5.m5.1.1.cmml" type="float" xref="S5.p1.5.m5.1.1">0.811</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.5.m5.1c">0.811</annotation><annotation encoding="application/x-llamapun" id="S5.p1.5.m5.1d">0.811</annotation></semantics></math>, compared to <math alttext="0.76-0.80" class="ltx_Math" display="inline" id="S5.p1.6.m6.1"><semantics id="S5.p1.6.m6.1a"><mrow id="S5.p1.6.m6.1.1" xref="S5.p1.6.m6.1.1.cmml"><mn id="S5.p1.6.m6.1.1.2" xref="S5.p1.6.m6.1.1.2.cmml">0.76</mn><mo id="S5.p1.6.m6.1.1.1" xref="S5.p1.6.m6.1.1.1.cmml">−</mo><mn id="S5.p1.6.m6.1.1.3" xref="S5.p1.6.m6.1.1.3.cmml">0.80</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.6.m6.1b"><apply id="S5.p1.6.m6.1.1.cmml" xref="S5.p1.6.m6.1.1"><minus id="S5.p1.6.m6.1.1.1.cmml" xref="S5.p1.6.m6.1.1.1"></minus><cn id="S5.p1.6.m6.1.1.2.cmml" type="float" xref="S5.p1.6.m6.1.1.2">0.76</cn><cn id="S5.p1.6.m6.1.1.3.cmml" type="float" xref="S5.p1.6.m6.1.1.3">0.80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.6.m6.1c">0.76-0.80</annotation><annotation encoding="application/x-llamapun" id="S5.p1.6.m6.1d">0.76 - 0.80</annotation></semantics></math> for the individual models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.2">Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S5.F4" title="Figure 4 ‣ V Results ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">4</span></a> presents the comparison of F1 Scores for our models on the test set from the Public Board of the competition. It is noticeable that the F1 scores in the test set are lower than those in the validation set. This discrepancy may be attributed to the differences in label distribution between the two datasets. That said, the ensemble model demonstrates strong robustness and still performs well on the test set. Specifically, the ensemble model achieves the highest F1 score on the test set at <math alttext="0.770" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><mn id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">0.770</mn><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><cn id="S5.p2.1.m1.1.1.cmml" type="float" xref="S5.p2.1.m1.1.1">0.770</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">0.770</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">0.770</annotation></semantics></math>, significantly better than any individual model by <math alttext="5" class="ltx_Math" display="inline" id="S5.p2.2.m2.1"><semantics id="S5.p2.2.m2.1a"><mn id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><cn id="S5.p2.2.m2.1.1.cmml" type="integer" xref="S5.p2.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="S5.p2.2.m2.1d">5</annotation></semantics></math>% points.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Analysis and Discussion</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.5"><span class="ltx_text ltx_font_bold" id="S6.p1.5.1">Using model agreement in Stage 1 reduces the noise in the labeling process.</span> Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.T5" title="TABLE V ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">V</span></a> shows the accuracy of each model in <span class="ltx_text ltx_font_italic" id="S6.p1.5.2">Stage 1</span> when trained on <math alttext="5" class="ltx_Math" display="inline" id="S6.p1.1.m1.1"><semantics id="S6.p1.1.m1.1a"><mn id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><cn id="S6.p1.1.m1.1.1.cmml" type="integer" xref="S6.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="S6.p1.1.m1.1d">5</annotation></semantics></math>-fold cross-validation with <math alttext="500" class="ltx_Math" display="inline" id="S6.p1.2.m2.1"><semantics id="S6.p1.2.m2.1a"><mn id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><cn id="S6.p1.2.m2.1.1.cmml" type="integer" xref="S6.p1.2.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">500</annotation><annotation encoding="application/x-llamapun" id="S6.p1.2.m2.1d">500</annotation></semantics></math> labeled posts. Each individual model achieved an accuracy below <math alttext="78" class="ltx_Math" display="inline" id="S6.p1.3.m3.1"><semantics id="S6.p1.3.m3.1a"><mn id="S6.p1.3.m3.1.1" xref="S6.p1.3.m3.1.1.cmml">78</mn><annotation-xml encoding="MathML-Content" id="S6.p1.3.m3.1b"><cn id="S6.p1.3.m3.1.1.cmml" type="integer" xref="S6.p1.3.m3.1.1">78</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.3.m3.1c">78</annotation><annotation encoding="application/x-llamapun" id="S6.p1.3.m3.1d">78</annotation></semantics></math>%. Combining the agreement of all three models boosts the accuracy to <math alttext="88.5" class="ltx_Math" display="inline" id="S6.p1.4.m4.1"><semantics id="S6.p1.4.m4.1a"><mn id="S6.p1.4.m4.1.1" xref="S6.p1.4.m4.1.1.cmml">88.5</mn><annotation-xml encoding="MathML-Content" id="S6.p1.4.m4.1b"><cn id="S6.p1.4.m4.1.1.cmml" type="float" xref="S6.p1.4.m4.1.1">88.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.4.m4.1c">88.5</annotation><annotation encoding="application/x-llamapun" id="S6.p1.4.m4.1d">88.5</annotation></semantics></math>%, at the cost of smaller data coverage, with only <math alttext="64.6" class="ltx_Math" display="inline" id="S6.p1.5.m5.1"><semantics id="S6.p1.5.m5.1a"><mn id="S6.p1.5.m5.1.1" xref="S6.p1.5.m5.1.1.cmml">64.6</mn><annotation-xml encoding="MathML-Content" id="S6.p1.5.m5.1b"><cn id="S6.p1.5.m5.1.1.cmml" type="float" xref="S6.p1.5.m5.1.1">64.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.5.m5.1c">64.6</annotation><annotation encoding="application/x-llamapun" id="S6.p1.5.m5.1d">64.6</annotation></semantics></math>% of the posts being predicted. This demonstrates the effectiveness of using three models to reduce noise when generating pseudo-labels, illustrated in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S2.F1" title="Figure 1 ‣ II-A Datasets ‣ II Datasets and metrics ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">1</span></a>(a).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.4"><span class="ltx_text ltx_font_bold" id="S6.p2.4.1">Ablation on Loss functions</span>. Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.T6" title="TABLE VI ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">VI</span></a> compares the accuracy and F1 scores obtained from 5-fold cross-validation when training<span class="ltx_text ltx_font_italic" id="S6.p2.4.2"> Llama3-8B</span> (<span class="ltx_text ltx_font_italic" id="S6.p2.4.3">Stage 2)</span> using different loss functions. The results show that Macro Double Soft F1 outperforms Cross Entropy in accuracy and F1 score in this experiment. Specifically, Macro Double Soft F1 achieves a higher accuracy of <math alttext="77.4" class="ltx_Math" display="inline" id="S6.p2.1.m1.1"><semantics id="S6.p2.1.m1.1a"><mn id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml">77.4</mn><annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b"><cn id="S6.p2.1.m1.1.1.cmml" type="float" xref="S6.p2.1.m1.1.1">77.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">77.4</annotation><annotation encoding="application/x-llamapun" id="S6.p2.1.m1.1d">77.4</annotation></semantics></math>% and an F1 score of <math alttext="0.77" class="ltx_Math" display="inline" id="S6.p2.2.m2.1"><semantics id="S6.p2.2.m2.1a"><mn id="S6.p2.2.m2.1.1" xref="S6.p2.2.m2.1.1.cmml">0.77</mn><annotation-xml encoding="MathML-Content" id="S6.p2.2.m2.1b"><cn id="S6.p2.2.m2.1.1.cmml" type="float" xref="S6.p2.2.m2.1.1">0.77</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.2.m2.1c">0.77</annotation><annotation encoding="application/x-llamapun" id="S6.p2.2.m2.1d">0.77</annotation></semantics></math>1, while these metrics are lower for Cross Entropy, at <math alttext="76.0" class="ltx_Math" display="inline" id="S6.p2.3.m3.1"><semantics id="S6.p2.3.m3.1a"><mn id="S6.p2.3.m3.1.1" xref="S6.p2.3.m3.1.1.cmml">76.0</mn><annotation-xml encoding="MathML-Content" id="S6.p2.3.m3.1b"><cn id="S6.p2.3.m3.1.1.cmml" type="float" xref="S6.p2.3.m3.1.1">76.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.3.m3.1c">76.0</annotation><annotation encoding="application/x-llamapun" id="S6.p2.3.m3.1d">76.0</annotation></semantics></math>% and <math alttext="0.760" class="ltx_Math" display="inline" id="S6.p2.4.m4.1"><semantics id="S6.p2.4.m4.1a"><mn id="S6.p2.4.m4.1.1" xref="S6.p2.4.m4.1.1.cmml">0.760</mn><annotation-xml encoding="MathML-Content" id="S6.p2.4.m4.1b"><cn id="S6.p2.4.m4.1.1.cmml" type="float" xref="S6.p2.4.m4.1.1">0.760</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.4.m4.1c">0.760</annotation><annotation encoding="application/x-llamapun" id="S6.p2.4.m4.1d">0.760</annotation></semantics></math>, respectively.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S6.T5">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE V: </span><span class="ltx_text ltx_font_bold" id="S6.T5.6.2">Accuracy of each model in Stage 1 when trained on <math alttext="\mathbf{5}" class="ltx_Math" display="inline" id="S6.T5.5.1.m1.1"><semantics id="S6.T5.5.1.m1.1b"><mn id="S6.T5.5.1.m1.1.1" xref="S6.T5.5.1.m1.1.1.cmml">𝟓</mn><annotation-xml encoding="MathML-Content" id="S6.T5.5.1.m1.1c"><cn id="S6.T5.5.1.m1.1.1.cmml" type="integer" xref="S6.T5.5.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.5.1.m1.1d">\mathbf{5}</annotation><annotation encoding="application/x-llamapun" id="S6.T5.5.1.m1.1e">bold_5</annotation></semantics></math>-fold cross-validation on <math alttext="\mathbf{500}" class="ltx_Math" display="inline" id="S6.T5.6.2.m2.1"><semantics id="S6.T5.6.2.m2.1b"><mn id="S6.T5.6.2.m2.1.1" xref="S6.T5.6.2.m2.1.1.cmml">𝟓𝟎𝟎</mn><annotation-xml encoding="MathML-Content" id="S6.T5.6.2.m2.1c"><cn id="S6.T5.6.2.m2.1.1.cmml" type="integer" xref="S6.T5.6.2.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.6.2.m2.1d">\mathbf{500}</annotation><annotation encoding="application/x-llamapun" id="S6.T5.6.2.m2.1e">bold_500</annotation></semantics></math> labeled posts.</span> The combined agreement of all models (<span class="ltx_text ltx_font_italic" id="S6.T5.16.3">All agreement)</span> results in a higher accuracy of <math alttext="88.5" class="ltx_Math" display="inline" id="S6.T5.7.m1.1"><semantics id="S6.T5.7.m1.1b"><mn id="S6.T5.7.m1.1.1" xref="S6.T5.7.m1.1.1.cmml">88.5</mn><annotation-xml encoding="MathML-Content" id="S6.T5.7.m1.1c"><cn id="S6.T5.7.m1.1.1.cmml" type="float" xref="S6.T5.7.m1.1.1">88.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.7.m1.1d">88.5</annotation><annotation encoding="application/x-llamapun" id="S6.T5.7.m1.1e">88.5</annotation></semantics></math>%, showing its effectiveness in reducing the noise in the labeling process, at the cost of reduced data coverage of <math alttext="64.6" class="ltx_Math" display="inline" id="S6.T5.8.m2.1"><semantics id="S6.T5.8.m2.1b"><mn id="S6.T5.8.m2.1.1" xref="S6.T5.8.m2.1.1.cmml">64.6</mn><annotation-xml encoding="MathML-Content" id="S6.T5.8.m2.1c"><cn id="S6.T5.8.m2.1.1.cmml" type="float" xref="S6.T5.8.m2.1.1">64.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.8.m2.1d">64.6</annotation><annotation encoding="application/x-llamapun" id="S6.T5.8.m2.1e">64.6</annotation></semantics></math>%.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T5.17">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T5.17.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S6.T5.17.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T5.17.1.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T5.17.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T5.17.1.1.2.1" style="font-size:90%;">Accuracy (%)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T5.17.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T5.17.1.1.3.1" style="font-size:90%;">Data Cover (%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T5.17.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T5.17.2.1.1"><span class="ltx_text" id="S6.T5.17.2.1.1.1" style="font-size:90%;">Llama3-8B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.17.2.1.2"><span class="ltx_text" id="S6.T5.17.2.1.2.1" style="font-size:90%;">74.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.17.2.1.3"><span class="ltx_text" id="S6.T5.17.2.1.3.1" style="font-size:90%;">100.0</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.17.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T5.17.3.2.1"><span class="ltx_text" id="S6.T5.17.3.2.1.1" style="font-size:90%;">DepRoBERTa</span></th>
<td class="ltx_td ltx_align_center" id="S6.T5.17.3.2.2"><span class="ltx_text" id="S6.T5.17.3.2.2.1" style="font-size:90%;">69.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.17.3.2.3"><span class="ltx_text" id="S6.T5.17.3.2.3.1" style="font-size:90%;">100.0</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.17.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T5.17.4.3.1"><span class="ltx_text" id="S6.T5.17.4.3.1.1" style="font-size:90%;">Qwen2-72B-Instruct</span></th>
<td class="ltx_td ltx_align_center" id="S6.T5.17.4.3.2"><span class="ltx_text" id="S6.T5.17.4.3.2.1" style="font-size:90%;">77.4</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.17.4.3.3"><span class="ltx_text" id="S6.T5.17.4.3.3.1" style="font-size:90%;">100.0</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.17.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T5.17.5.4.1"><span class="ltx_text ltx_font_bold" id="S6.T5.17.5.4.1.1" style="font-size:90%;">All agreement</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.17.5.4.2"><span class="ltx_text ltx_font_bold" id="S6.T5.17.5.4.2.1" style="font-size:90%;">88.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.17.5.4.3"><span class="ltx_text ltx_font_bold" id="S6.T5.17.5.4.3.1" style="font-size:90%;">64.6</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T6">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE VI: </span><span class="ltx_text ltx_font_bold" id="S6.T6.13.1">Comparison of different choices of loss functions.</span> We report accuracy and F1 Scores on 5-fold cross-validation when training <span class="ltx_text ltx_font_italic" id="S6.T6.14.2">Llama3-8B</span> (<span class="ltx_text ltx_font_italic" id="S6.T6.15.3">Stage 2</span>).</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T6.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T6.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S6.T6.4.5.1.1"><span class="ltx_text ltx_font_bold" id="S6.T6.4.5.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.4.5.1.2">
<span class="ltx_text ltx_font_bold" id="S6.T6.4.5.1.2.1" style="font-size:90%;">Accuracy</span><span class="ltx_text" id="S6.T6.4.5.1.2.2" style="font-size:90%;"> (%)</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.4.5.1.3"><span class="ltx_text ltx_font_bold" id="S6.T6.4.5.1.3.1" style="font-size:90%;">F1 Score</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T6.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T6.2.2.3">
<span class="ltx_text ltx_font_bold" id="S6.T6.2.2.3.1" style="font-size:90%;">Macro Double Soft F1</span><span class="ltx_text" id="S6.T6.2.2.3.2" style="font-size:90%;">&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S6.T6.2.2.3.3.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib33" title="">33</a><span class="ltx_text" id="S6.T6.2.2.3.4.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.1.1" style="font-size:90%;">77.4 <math alttext="\pm" class="ltx_Math" display="inline" id="S6.T6.1.1.1.1.m1.1"><semantics id="S6.T6.1.1.1.1.m1.1a"><mo id="S6.T6.1.1.1.1.m1.1.1" xref="S6.T6.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T6.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T6.1.1.1.1.m1.1.1.cmml" xref="S6.T6.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S6.T6.1.1.1.1.m1.1d">±</annotation></semantics></math> 3.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.2.2.2"><span class="ltx_text ltx_font_bold" id="S6.T6.2.2.2.1" style="font-size:90%;">0.771 <math alttext="\pm" class="ltx_Math" display="inline" id="S6.T6.2.2.2.1.m1.1"><semantics id="S6.T6.2.2.2.1.m1.1a"><mo id="S6.T6.2.2.2.1.m1.1.1" xref="S6.T6.2.2.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T6.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S6.T6.2.2.2.1.m1.1.1.cmml" xref="S6.T6.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.2.2.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S6.T6.2.2.2.1.m1.1d">±</annotation></semantics></math> 0.032</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T6.4.4.3"><span class="ltx_text" id="S6.T6.4.4.3.1" style="font-size:90%;">Cross Entropy</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.3.1">
<span class="ltx_text" id="S6.T6.3.3.1.1" style="font-size:90%;">76.0 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S6.T6.3.3.1.m1.1"><semantics id="S6.T6.3.3.1.m1.1a"><mo id="S6.T6.3.3.1.m1.1.1" mathsize="90%" xref="S6.T6.3.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T6.3.3.1.m1.1b"><csymbol cd="latexml" id="S6.T6.3.3.1.m1.1.1.cmml" xref="S6.T6.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.3.3.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S6.T6.3.3.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S6.T6.3.3.1.2" style="font-size:90%;"> 2.7</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.4.4.2">
<span class="ltx_text" id="S6.T6.4.4.2.1" style="font-size:90%;">0.760 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S6.T6.4.4.2.m1.1"><semantics id="S6.T6.4.4.2.m1.1a"><mo id="S6.T6.4.4.2.m1.1.1" mathsize="90%" xref="S6.T6.4.4.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T6.4.4.2.m1.1b"><csymbol cd="latexml" id="S6.T6.4.4.2.m1.1.1.cmml" xref="S6.T6.4.4.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.4.4.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S6.T6.4.4.2.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S6.T6.4.4.2.2" style="font-size:90%;"> 0.029</span>
</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T7">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE VII: </span><span class="ltx_text ltx_font_bold" id="S6.T7.7.1">Comparison of LLMs with prompting on 500 labeled posts</span>. <span class="ltx_text ltx_font_italic" id="S6.T7.8.2">Qwen2-72B-Instruct</span>, the largest model evaluated, outperforms the smaller models.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T7.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T7.9.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S6.T7.9.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T7.9.1.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T7.9.1.1.2">
<span class="ltx_text ltx_font_bold" id="S6.T7.9.1.1.2.1" style="font-size:90%;">Accuracy</span><span class="ltx_text" id="S6.T7.9.1.1.2.2" style="font-size:90%;"> (%)</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T7.9.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T7.9.1.1.3.1" style="font-size:90%;">F1 Score</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T7.9.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T7.9.2.1.1">
<span class="ltx_text" id="S6.T7.9.2.1.1.1" style="font-size:90%;">Qwen2-7B-Instruct&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S6.T7.9.2.1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib3" title="">3</a><span class="ltx_text" id="S6.T7.9.2.1.1.3.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.9.2.1.2"><span class="ltx_text" id="S6.T7.9.2.1.2.1" style="font-size:90%;">50.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.9.2.1.3"><span class="ltx_text" id="S6.T7.9.2.1.3.1" style="font-size:90%;">0.469</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.9.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.9.3.2.1">
<span class="ltx_text" id="S6.T7.9.3.2.1.1" style="font-size:90%;">Mistral-7B-Instruct-v0.3&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S6.T7.9.3.2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib37" title="">37</a><span class="ltx_text" id="S6.T7.9.3.2.1.3.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S6.T7.9.3.2.2"><span class="ltx_text" id="S6.T7.9.3.2.2.1" style="font-size:90%;">57.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.9.3.2.3"><span class="ltx_text" id="S6.T7.9.3.2.3.1" style="font-size:90%;">0.591</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.9.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.9.4.3.1">
<span class="ltx_text" id="S6.T7.9.4.3.1.1" style="font-size:90%;">Llama3-8B&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S6.T7.9.4.3.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a><span class="ltx_text" id="S6.T7.9.4.3.1.3.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S6.T7.9.4.3.2"><span class="ltx_text" id="S6.T7.9.4.3.2.1" style="font-size:90%;">48.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.9.4.3.3"><span class="ltx_text" id="S6.T7.9.4.3.3.1" style="font-size:90%;">0.419</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.9.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.9.5.4.1">
<span class="ltx_text" id="S6.T7.9.5.4.1.1" style="font-size:90%;">Llama3-8B-Instruct&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S6.T7.9.5.4.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a><span class="ltx_text" id="S6.T7.9.5.4.1.3.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S6.T7.9.5.4.2"><span class="ltx_text" id="S6.T7.9.5.4.2.1" style="font-size:90%;">55.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.9.5.4.3"><span class="ltx_text" id="S6.T7.9.5.4.3.1" style="font-size:90%;">0.503</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.9.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.9.6.5.1">
<span class="ltx_text" id="S6.T7.9.6.5.1.1" style="font-size:90%;">Mixtral-8x22B&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S6.T7.9.6.5.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib38" title="">38</a><span class="ltx_text" id="S6.T7.9.6.5.1.3.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S6.T7.9.6.5.2"><span class="ltx_text" id="S6.T7.9.6.5.2.1" style="font-size:90%;">60.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.9.6.5.3"><span class="ltx_text" id="S6.T7.9.6.5.3.1" style="font-size:90%;">0.594</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.9.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.9.7.6.1">
<span class="ltx_text" id="S6.T7.9.7.6.1.1" style="font-size:90%;">Llama3-70B-Instruct&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S6.T7.9.7.6.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a><span class="ltx_text" id="S6.T7.9.7.6.1.3.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S6.T7.9.7.6.2"><span class="ltx_text" id="S6.T7.9.7.6.2.1" style="font-size:90%;">69.4</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.9.7.6.3"><span class="ltx_text" id="S6.T7.9.7.6.3.1" style="font-size:90%;">0.693</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.9.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.9.8.7.1">
<span class="ltx_text" id="S6.T7.9.8.7.1.1" style="font-size:90%;">Llama3-70B&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S6.T7.9.8.7.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib4" title="">4</a><span class="ltx_text" id="S6.T7.9.8.7.1.3.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S6.T7.9.8.7.2"><span class="ltx_text" id="S6.T7.9.8.7.2.1" style="font-size:90%;">74.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.9.8.7.3"><span class="ltx_text" id="S6.T7.9.8.7.3.1" style="font-size:90%;">0.741</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.9.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T7.9.9.8.1">
<span class="ltx_text ltx_font_bold" id="S6.T7.9.9.8.1.1" style="font-size:90%;">Qwen2-72B-Instruct</span><span class="ltx_text" id="S6.T7.9.9.8.1.2" style="font-size:90%;">&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S6.T7.9.9.8.1.3.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib3" title="">3</a><span class="ltx_text" id="S6.T7.9.9.8.1.4.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T7.9.9.8.2"><span class="ltx_text ltx_font_bold" id="S6.T7.9.9.8.2.1" style="font-size:90%;">77.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T7.9.9.8.3"><span class="ltx_text ltx_font_bold" id="S6.T7.9.9.8.3.1" style="font-size:90%;">0.772</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="805" id="S6.F5.sf1.g1" src="https://arxiv.org/html/2410.04501v1/x5.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S6.F5.sf1.3.2" style="font-size:90%;">Llama3-8B 1 </span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="805" id="S6.F5.sf2.g1" src="https://arxiv.org/html/2410.04501v1/x6.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S6.F5.sf2.3.2" style="font-size:90%;">Llama3-8B 2</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F5.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="805" id="S6.F5.sf3.g1" src="https://arxiv.org/html/2410.04501v1/x7.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S6.F5.sf3.3.2" style="font-size:90%;">Gemma2-9B</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F5.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="805" id="S6.F5.sf4.g1" src="https://arxiv.org/html/2410.04501v1/x8.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf4.2.1.1" style="font-size:90%;">(d)</span> </span><span class="ltx_text" id="S6.F5.sf4.3.2" style="font-size:90%;">Llama3.1-8B</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F5.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="805" id="S6.F5.sf5.g1" src="https://arxiv.org/html/2410.04501v1/x9.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf5.2.1.1" style="font-size:90%;">(e)</span> </span><span class="ltx_text" id="S6.F5.sf5.3.2" style="font-size:90%;">Qwen2-72B</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F5.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="805" id="S6.F5.sf6.g1" src="https://arxiv.org/html/2410.04501v1/x10.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf6.2.1.1" style="font-size:90%;">(f)</span> </span><span class="ltx_text" id="S6.F5.sf6.3.2" style="font-size:90%;">Ensemble</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.5.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text ltx_font_bold" id="S6.F5.6.2" style="font-size:90%;">Confusion Matrices of the models on 500 original labeled posts.<span class="ltx_text ltx_font_medium" id="S6.F5.6.2.1"> The matrices show that each of the models performs reasonably well. <span class="ltx_text ltx_font_italic" id="S6.F5.6.2.1.1">Ensemble</span> (f) outperforms individual models, with the main improvement coming from <span class="ltx_text ltx_font_italic" id="S6.F5.6.2.1.2">Ideation</span> class.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T8">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span><span class="ltx_text ltx_font_bold" id="S6.T8.8.1">Classification Report of the ensemble model.</span> The model achieves a weighted F1 Score of <math alttext="0.81" class="ltx_Math" display="inline" id="S6.T8.2.m1.1"><semantics id="S6.T8.2.m1.1b"><mn id="S6.T8.2.m1.1.1" xref="S6.T8.2.m1.1.1.cmml">0.81</mn><annotation-xml encoding="MathML-Content" id="S6.T8.2.m1.1c"><cn id="S6.T8.2.m1.1.1.cmml" type="float" xref="S6.T8.2.m1.1.1">0.81</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T8.2.m1.1d">0.81</annotation><annotation encoding="application/x-llamapun" id="S6.T8.2.m1.1e">0.81</annotation></semantics></math>, indicating consistent performance across all classes</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T8.9">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T8.9.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S6.T8.9.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T8.9.1.1.1.1" style="font-size:90%;">Class</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T8.9.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T8.9.1.1.2.1" style="font-size:90%;">Precision</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T8.9.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T8.9.1.1.3.1" style="font-size:90%;">Recall</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T8.9.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T8.9.1.1.4.1" style="font-size:90%;">F1 Score</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.9.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T8.9.2.2.1"><span class="ltx_text" id="S6.T8.9.2.2.1.1" style="font-size:90%;">Indicator</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.9.2.2.2"><span class="ltx_text" id="S6.T8.9.2.2.2.1" style="font-size:90%;">0.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.9.2.2.3"><span class="ltx_text" id="S6.T8.9.2.2.3.1" style="font-size:90%;">0.73</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.9.2.2.4"><span class="ltx_text" id="S6.T8.9.2.2.4.1" style="font-size:90%;">0.78</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.9.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.9.3.3.1"><span class="ltx_text" id="S6.T8.9.3.3.1.1" style="font-size:90%;">Ideation</span></th>
<td class="ltx_td ltx_align_center" id="S6.T8.9.3.3.2"><span class="ltx_text" id="S6.T8.9.3.3.2.1" style="font-size:90%;">0.81</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.9.3.3.3"><span class="ltx_text" id="S6.T8.9.3.3.3.1" style="font-size:90%;">0.86</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.9.3.3.4"><span class="ltx_text" id="S6.T8.9.3.3.4.1" style="font-size:90%;">0.84</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.9.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.9.4.4.1"><span class="ltx_text" id="S6.T8.9.4.4.1.1" style="font-size:90%;">Behavior</span></th>
<td class="ltx_td ltx_align_center" id="S6.T8.9.4.4.2"><span class="ltx_text" id="S6.T8.9.4.4.2.1" style="font-size:90%;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.9.4.4.3"><span class="ltx_text" id="S6.T8.9.4.4.3.1" style="font-size:90%;">0.83</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.9.4.4.4"><span class="ltx_text" id="S6.T8.9.4.4.4.1" style="font-size:90%;">0.81</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.9.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.9.5.5.1"><span class="ltx_text" id="S6.T8.9.5.5.1.1" style="font-size:90%;">Attempts</span></th>
<td class="ltx_td ltx_align_center" id="S6.T8.9.5.5.2"><span class="ltx_text" id="S6.T8.9.5.5.2.1" style="font-size:90%;">0.80</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.9.5.5.3"><span class="ltx_text" id="S6.T8.9.5.5.3.1" style="font-size:90%;">0.80</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.9.5.5.4"><span class="ltx_text" id="S6.T8.9.5.5.4.1" style="font-size:90%;">0.80</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.9.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T8.9.6.6.1"><span class="ltx_text" id="S6.T8.9.6.6.1.1" style="font-size:90%;">Accuracy</span></th>
<td class="ltx_td ltx_border_t" id="S6.T8.9.6.6.2"></td>
<td class="ltx_td ltx_border_t" id="S6.T8.9.6.6.3"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.9.6.6.4"><span class="ltx_text" id="S6.T8.9.6.6.4.1" style="font-size:90%;">0.81</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.9.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.9.7.7.1"><span class="ltx_text" id="S6.T8.9.7.7.1.1" style="font-size:90%;">Macro avg</span></th>
<td class="ltx_td ltx_align_center" id="S6.T8.9.7.7.2"><span class="ltx_text" id="S6.T8.9.7.7.2.1" style="font-size:90%;">0.81</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.9.7.7.3"><span class="ltx_text" id="S6.T8.9.7.7.3.1" style="font-size:90%;">0.81</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.9.7.7.4"><span class="ltx_text" id="S6.T8.9.7.7.4.1" style="font-size:90%;">0.81</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.9.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T8.9.8.8.1"><span class="ltx_text" id="S6.T8.9.8.8.1.1" style="font-size:90%;">Weighted avg</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T8.9.8.8.2"><span class="ltx_text" id="S6.T8.9.8.8.2.1" style="font-size:90%;">0.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T8.9.8.8.3"><span class="ltx_text" id="S6.T8.9.8.8.3.1" style="font-size:90%;">0.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T8.9.8.8.4"><span class="ltx_text ltx_font_bold" id="S6.T8.9.8.8.4.1" style="font-size:90%;">0.81</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="517" id="S6.F6.g1" src="https://arxiv.org/html/2410.04501v1/x11.png" width="623">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F6.3.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text ltx_font_bold" id="S6.F6.4.2" style="font-size:90%;">Correlation Between Model Predictions on 500 labeled Data.<span class="ltx_text ltx_font_medium" id="S6.F6.4.2.1"> The predictions of individual models show a relatively low correlation with each other. This low correlation is a desirable attribute, as it typically leads to improved performance and robustness for the ensemble model.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p3">
<p class="ltx_p" id="S6.p3.10"><span class="ltx_text ltx_font_bold" id="S6.p3.10.1">Impact of different LLMs on prompting performance.</span> Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.T7" title="TABLE VII ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">VII</span></a> presents a comparison of the accuracy and F1 scores across LLMs with prompting on <math alttext="500" class="ltx_Math" display="inline" id="S6.p3.1.m1.1"><semantics id="S6.p3.1.m1.1a"><mn id="S6.p3.1.m1.1.1" xref="S6.p3.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S6.p3.1.m1.1b"><cn id="S6.p3.1.m1.1.1.cmml" type="integer" xref="S6.p3.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S6.p3.1.m1.1d">500</annotation></semantics></math> labeled posts. We observe that larger models generally achieve higher performance metrics. Specifically, the largest model evaluated, <span class="ltx_text ltx_font_italic" id="S6.p3.10.2">Qwen2-72B-Instruct</span>, with <math alttext="72" class="ltx_Math" display="inline" id="S6.p3.2.m2.1"><semantics id="S6.p3.2.m2.1a"><mn id="S6.p3.2.m2.1.1" xref="S6.p3.2.m2.1.1.cmml">72</mn><annotation-xml encoding="MathML-Content" id="S6.p3.2.m2.1b"><cn id="S6.p3.2.m2.1.1.cmml" type="integer" xref="S6.p3.2.m2.1.1">72</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.2.m2.1c">72</annotation><annotation encoding="application/x-llamapun" id="S6.p3.2.m2.1d">72</annotation></semantics></math> billion parameters, attains the highest accuracy of <math alttext="77.4" class="ltx_Math" display="inline" id="S6.p3.3.m3.1"><semantics id="S6.p3.3.m3.1a"><mn id="S6.p3.3.m3.1.1" xref="S6.p3.3.m3.1.1.cmml">77.4</mn><annotation-xml encoding="MathML-Content" id="S6.p3.3.m3.1b"><cn id="S6.p3.3.m3.1.1.cmml" type="float" xref="S6.p3.3.m3.1.1">77.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.3.m3.1c">77.4</annotation><annotation encoding="application/x-llamapun" id="S6.p3.3.m3.1d">77.4</annotation></semantics></math>% and an F1 score of <math alttext="0.772" class="ltx_Math" display="inline" id="S6.p3.4.m4.1"><semantics id="S6.p3.4.m4.1a"><mn id="S6.p3.4.m4.1.1" xref="S6.p3.4.m4.1.1.cmml">0.772</mn><annotation-xml encoding="MathML-Content" id="S6.p3.4.m4.1b"><cn id="S6.p3.4.m4.1.1.cmml" type="float" xref="S6.p3.4.m4.1.1">0.772</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.4.m4.1c">0.772</annotation><annotation encoding="application/x-llamapun" id="S6.p3.4.m4.1d">0.772</annotation></semantics></math>, demonstrating superior understanding and classification capability compared to smaller models. Following closely are <span class="ltx_text ltx_font_italic" id="S6.p3.10.3">Llama3-70B</span> and <span class="ltx_text ltx_font_italic" id="S6.p3.10.4">Llama3-70B-Instruct</span>, with accuracies of <math alttext="74.2" class="ltx_Math" display="inline" id="S6.p3.5.m5.1"><semantics id="S6.p3.5.m5.1a"><mn id="S6.p3.5.m5.1.1" xref="S6.p3.5.m5.1.1.cmml">74.2</mn><annotation-xml encoding="MathML-Content" id="S6.p3.5.m5.1b"><cn id="S6.p3.5.m5.1.1.cmml" type="float" xref="S6.p3.5.m5.1.1">74.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.5.m5.1c">74.2</annotation><annotation encoding="application/x-llamapun" id="S6.p3.5.m5.1d">74.2</annotation></semantics></math>% and <math alttext="69.4" class="ltx_Math" display="inline" id="S6.p3.6.m6.1"><semantics id="S6.p3.6.m6.1a"><mn id="S6.p3.6.m6.1.1" xref="S6.p3.6.m6.1.1.cmml">69.4</mn><annotation-xml encoding="MathML-Content" id="S6.p3.6.m6.1b"><cn id="S6.p3.6.m6.1.1.cmml" type="float" xref="S6.p3.6.m6.1.1">69.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.6.m6.1c">69.4</annotation><annotation encoding="application/x-llamapun" id="S6.p3.6.m6.1d">69.4</annotation></semantics></math>% and F1 scores of <math alttext="0.741" class="ltx_Math" display="inline" id="S6.p3.7.m7.1"><semantics id="S6.p3.7.m7.1a"><mn id="S6.p3.7.m7.1.1" xref="S6.p3.7.m7.1.1.cmml">0.741</mn><annotation-xml encoding="MathML-Content" id="S6.p3.7.m7.1b"><cn id="S6.p3.7.m7.1.1.cmml" type="float" xref="S6.p3.7.m7.1.1">0.741</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.7.m7.1c">0.741</annotation><annotation encoding="application/x-llamapun" id="S6.p3.7.m7.1d">0.741</annotation></semantics></math> and <math alttext="0.693" class="ltx_Math" display="inline" id="S6.p3.8.m8.1"><semantics id="S6.p3.8.m8.1a"><mn id="S6.p3.8.m8.1.1" xref="S6.p3.8.m8.1.1.cmml">0.693</mn><annotation-xml encoding="MathML-Content" id="S6.p3.8.m8.1b"><cn id="S6.p3.8.m8.1.1.cmml" type="float" xref="S6.p3.8.m8.1.1">0.693</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.8.m8.1c">0.693</annotation><annotation encoding="application/x-llamapun" id="S6.p3.8.m8.1d">0.693</annotation></semantics></math>, respectively. Conversely, smaller models such as <span class="ltx_text ltx_font_italic" id="S6.p3.10.5">Qwen2-7B-Instruct</span> and <span class="ltx_text ltx_font_italic" id="S6.p3.10.6">Llama3-8B</span> demonstrate lower performance. Among relatively small models, <span class="ltx_text ltx_font_italic" id="S6.p3.10.7">Mistral-7B-Instruct-V03</span> exhibits the highest performance, nearly on par with <span class="ltx_text ltx_font_italic" id="S6.p3.10.8">Mixtral-8x22B</span>, a mixture of eight experts with <math alttext="39" class="ltx_Math" display="inline" id="S6.p3.9.m9.1"><semantics id="S6.p3.9.m9.1a"><mn id="S6.p3.9.m9.1.1" xref="S6.p3.9.m9.1.1.cmml">39</mn><annotation-xml encoding="MathML-Content" id="S6.p3.9.m9.1b"><cn id="S6.p3.9.m9.1.1.cmml" type="integer" xref="S6.p3.9.m9.1.1">39</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.9.m9.1c">39</annotation><annotation encoding="application/x-llamapun" id="S6.p3.9.m9.1d">39</annotation></semantics></math>B active parameters out of <math alttext="141" class="ltx_Math" display="inline" id="S6.p3.10.m10.1"><semantics id="S6.p3.10.m10.1a"><mn id="S6.p3.10.m10.1.1" xref="S6.p3.10.m10.1.1.cmml">141</mn><annotation-xml encoding="MathML-Content" id="S6.p3.10.m10.1b"><cn id="S6.p3.10.m10.1.1.cmml" type="integer" xref="S6.p3.10.m10.1.1">141</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.10.m10.1c">141</annotation><annotation encoding="application/x-llamapun" id="S6.p3.10.m10.1d">141</annotation></semantics></math>B parameters.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S6.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S6.F7.sf1.g1" src="https://arxiv.org/html/2410.04501v1/x12.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.sf1.3.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text ltx_font_bold" id="S6.F7.sf1.4.2" style="font-size:90%;">Number of words</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F7.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S6.F7.sf2.g1" src="https://arxiv.org/html/2410.04501v1/x13.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.sf2.3.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text ltx_font_bold" id="S6.F7.sf2.4.2" style="font-size:90%;">Llama3-8B</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F7.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S6.F7.sf3.g1" src="https://arxiv.org/html/2410.04501v1/x14.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.sf3.3.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text ltx_font_bold" id="S6.F7.sf3.4.2" style="font-size:90%;">Gemma2-9B</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.14.6.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text ltx_font_bold" id="S6.F7.10.5" style="font-size:90%;">Distribution of the number of words/tokens in a post for <math alttext="\mathbf{2{,}000}" class="ltx_Math" display="inline" id="S6.F7.6.1.m1.2"><semantics id="S6.F7.6.1.m1.2b"><mrow id="S6.F7.6.1.m1.2.3.2" xref="S6.F7.6.1.m1.2.3.1.cmml"><mn id="S6.F7.6.1.m1.1.1" xref="S6.F7.6.1.m1.1.1.cmml">𝟐</mn><mo id="S6.F7.6.1.m1.2.3.2.1" xref="S6.F7.6.1.m1.2.3.1.cmml">,</mo><mn id="S6.F7.6.1.m1.2.2" xref="S6.F7.6.1.m1.2.2.cmml">𝟎𝟎𝟎</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F7.6.1.m1.2c"><list id="S6.F7.6.1.m1.2.3.1.cmml" xref="S6.F7.6.1.m1.2.3.2"><cn id="S6.F7.6.1.m1.1.1.cmml" type="integer" xref="S6.F7.6.1.m1.1.1">2</cn><cn id="S6.F7.6.1.m1.2.2.cmml" type="integer" xref="S6.F7.6.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.6.1.m1.2d">\mathbf{2{,}000}</annotation><annotation encoding="application/x-llamapun" id="S6.F7.6.1.m1.2e">bold_2 , bold_000</annotation></semantics></math> posts in the dataset.<span class="ltx_text ltx_font_medium" id="S6.F7.10.5.5"> </span>(a) Distribution of the number of words in a post.<span class="ltx_text ltx_font_medium" id="S6.F7.10.5.6"> Most posts have fewer than 2000 words. </span>(b) and (c) Distribution of the number of tokens in a post for the Llama-8B and Gemma2-9B models.<span class="ltx_text ltx_font_medium" id="S6.F7.10.5.4"> In both models, only <math alttext="2" class="ltx_Math" display="inline" id="S6.F7.7.2.1.m1.1"><semantics id="S6.F7.7.2.1.m1.1b"><mn id="S6.F7.7.2.1.m1.1.1" xref="S6.F7.7.2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.F7.7.2.1.m1.1c"><cn id="S6.F7.7.2.1.m1.1.1.cmml" type="integer" xref="S6.F7.7.2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.7.2.1.m1.1d">2</annotation><annotation encoding="application/x-llamapun" id="S6.F7.7.2.1.m1.1e">2</annotation></semantics></math> out of <math alttext="2{,}000" class="ltx_Math" display="inline" id="S6.F7.8.3.2.m2.2"><semantics id="S6.F7.8.3.2.m2.2b"><mrow id="S6.F7.8.3.2.m2.2.3.2" xref="S6.F7.8.3.2.m2.2.3.1.cmml"><mn id="S6.F7.8.3.2.m2.1.1" xref="S6.F7.8.3.2.m2.1.1.cmml">2</mn><mo id="S6.F7.8.3.2.m2.2.3.2.1" xref="S6.F7.8.3.2.m2.2.3.1.cmml">,</mo><mn id="S6.F7.8.3.2.m2.2.2" xref="S6.F7.8.3.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F7.8.3.2.m2.2c"><list id="S6.F7.8.3.2.m2.2.3.1.cmml" xref="S6.F7.8.3.2.m2.2.3.2"><cn id="S6.F7.8.3.2.m2.1.1.cmml" type="integer" xref="S6.F7.8.3.2.m2.1.1">2</cn><cn id="S6.F7.8.3.2.m2.2.2.cmml" type="integer" xref="S6.F7.8.3.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.8.3.2.m2.2d">2{,}000</annotation><annotation encoding="application/x-llamapun" id="S6.F7.8.3.2.m2.2e">2 , 000</annotation></semantics></math> posts exceed <math alttext="2{,}500" class="ltx_Math" display="inline" id="S6.F7.9.4.3.m3.2"><semantics id="S6.F7.9.4.3.m3.2b"><mrow id="S6.F7.9.4.3.m3.2.3.2" xref="S6.F7.9.4.3.m3.2.3.1.cmml"><mn id="S6.F7.9.4.3.m3.1.1" xref="S6.F7.9.4.3.m3.1.1.cmml">2</mn><mo id="S6.F7.9.4.3.m3.2.3.2.1" xref="S6.F7.9.4.3.m3.2.3.1.cmml">,</mo><mn id="S6.F7.9.4.3.m3.2.2" xref="S6.F7.9.4.3.m3.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F7.9.4.3.m3.2c"><list id="S6.F7.9.4.3.m3.2.3.1.cmml" xref="S6.F7.9.4.3.m3.2.3.2"><cn id="S6.F7.9.4.3.m3.1.1.cmml" type="integer" xref="S6.F7.9.4.3.m3.1.1">2</cn><cn id="S6.F7.9.4.3.m3.2.2.cmml" type="integer" xref="S6.F7.9.4.3.m3.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.9.4.3.m3.2d">2{,}500</annotation><annotation encoding="application/x-llamapun" id="S6.F7.9.4.3.m3.2e">2 , 500</annotation></semantics></math> tokens. The red dashed line represents the <math alttext="2{,}500" class="ltx_Math" display="inline" id="S6.F7.10.5.4.m4.2"><semantics id="S6.F7.10.5.4.m4.2b"><mrow id="S6.F7.10.5.4.m4.2.3.2" xref="S6.F7.10.5.4.m4.2.3.1.cmml"><mn id="S6.F7.10.5.4.m4.1.1" xref="S6.F7.10.5.4.m4.1.1.cmml">2</mn><mo id="S6.F7.10.5.4.m4.2.3.2.1" xref="S6.F7.10.5.4.m4.2.3.1.cmml">,</mo><mn id="S6.F7.10.5.4.m4.2.2" xref="S6.F7.10.5.4.m4.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F7.10.5.4.m4.2c"><list id="S6.F7.10.5.4.m4.2.3.1.cmml" xref="S6.F7.10.5.4.m4.2.3.2"><cn id="S6.F7.10.5.4.m4.1.1.cmml" type="integer" xref="S6.F7.10.5.4.m4.1.1">2</cn><cn id="S6.F7.10.5.4.m4.2.2.cmml" type="integer" xref="S6.F7.10.5.4.m4.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.10.5.4.m4.2d">2{,}500</annotation><annotation encoding="application/x-llamapun" id="S6.F7.10.5.4.m4.2e">2 , 500</annotation></semantics></math>-token cut-off threshold.</span></span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p4">
<p class="ltx_p" id="S6.p4.1"><span class="ltx_text ltx_font_bold" id="S6.p4.1.1">Correlation Between Model Predictions.</span> As seen in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S5.F4" title="Figure 4 ‣ V Results ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">4</span></a>, the ensemble model shows its robustness when tested on a new dataset. To gain further insight, we compared the correlation between the predictions of the models, as illustrated in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.F6" title="Figure 6 ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">6</span></a>. Creating an effective ensemble model requires not only high performance, but also diversity in the individual models. When these models have low correlation, it helps to reduce the risk of overfitting some parts of the data, leading to better generalization. The results show that the individual models produce diverse predictions with relatively low correlation, contributing to better generalization in the ensemble’s performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.p5">
<p class="ltx_p" id="S6.p5.7"><span class="ltx_text ltx_font_bold" id="S6.p5.7.1">Confusion Matrices of the classification results</span>. Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.F5" title="Figure 5 ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">5</span></a> presents the confusion matrices for the individual and ensemble models’ classification of the <math alttext="500" class="ltx_Math" display="inline" id="S6.p5.1.m1.1"><semantics id="S6.p5.1.m1.1a"><mn id="S6.p5.1.m1.1.1" xref="S6.p5.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S6.p5.1.m1.1b"><cn id="S6.p5.1.m1.1.1.cmml" type="integer" xref="S6.p5.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S6.p5.1.m1.1d">500</annotation></semantics></math> labeled posts. We observe each of the individual models performs reasonably well. However, ensemble model outperforms individual models, achieving accuracies of <math alttext="72.9" class="ltx_Math" display="inline" id="S6.p5.2.m2.1"><semantics id="S6.p5.2.m2.1a"><mn id="S6.p5.2.m2.1.1" xref="S6.p5.2.m2.1.1.cmml">72.9</mn><annotation-xml encoding="MathML-Content" id="S6.p5.2.m2.1b"><cn id="S6.p5.2.m2.1.1.cmml" type="float" xref="S6.p5.2.m2.1.1">72.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.2.m2.1c">72.9</annotation><annotation encoding="application/x-llamapun" id="S6.p5.2.m2.1d">72.9</annotation></semantics></math>%, <math alttext="85.6" class="ltx_Math" display="inline" id="S6.p5.3.m3.1"><semantics id="S6.p5.3.m3.1a"><mn id="S6.p5.3.m3.1.1" xref="S6.p5.3.m3.1.1.cmml">85.6</mn><annotation-xml encoding="MathML-Content" id="S6.p5.3.m3.1b"><cn id="S6.p5.3.m3.1.1.cmml" type="float" xref="S6.p5.3.m3.1.1">85.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.3.m3.1c">85.6</annotation><annotation encoding="application/x-llamapun" id="S6.p5.3.m3.1d">85.6</annotation></semantics></math>%, <math alttext="82.9" class="ltx_Math" display="inline" id="S6.p5.4.m4.1"><semantics id="S6.p5.4.m4.1a"><mn id="S6.p5.4.m4.1.1" xref="S6.p5.4.m4.1.1.cmml">82.9</mn><annotation-xml encoding="MathML-Content" id="S6.p5.4.m4.1b"><cn id="S6.p5.4.m4.1.1.cmml" type="float" xref="S6.p5.4.m4.1.1">82.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.4.m4.1c">82.9</annotation><annotation encoding="application/x-llamapun" id="S6.p5.4.m4.1d">82.9</annotation></semantics></math>%, and <math alttext="80.5" class="ltx_Math" display="inline" id="S6.p5.5.m5.1"><semantics id="S6.p5.5.m5.1a"><mn id="S6.p5.5.m5.1.1" xref="S6.p5.5.m5.1.1.cmml">80.5</mn><annotation-xml encoding="MathML-Content" id="S6.p5.5.m5.1b"><cn id="S6.p5.5.m5.1.1.cmml" type="float" xref="S6.p5.5.m5.1.1">80.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.5.m5.1c">80.5</annotation><annotation encoding="application/x-llamapun" id="S6.p5.5.m5.1d">80.5</annotation></semantics></math>% for the <span class="ltx_text ltx_font_italic" id="S6.p5.7.2">Indicator</span>, <span class="ltx_text ltx_font_italic" id="S6.p5.7.3">Ideation</span>, <span class="ltx_text ltx_font_italic" id="S6.p5.7.4">Behavior</span>, and <span class="ltx_text ltx_font_italic" id="S6.p5.7.5">Attempt</span> categories, respectively, with the main improvement coming from <span class="ltx_text ltx_font_italic" id="S6.p5.7.6">Ideation</span> class. Despite these improvements, the ensemble model struggles with the <span class="ltx_text ltx_font_italic" id="S6.p5.7.7">Indicator</span> category, which has the highest rate of misclassification. Specifically, <math alttext="22" class="ltx_Math" display="inline" id="S6.p5.6.m6.1"><semantics id="S6.p5.6.m6.1a"><mn id="S6.p5.6.m6.1.1" xref="S6.p5.6.m6.1.1.cmml">22</mn><annotation-xml encoding="MathML-Content" id="S6.p5.6.m6.1b"><cn id="S6.p5.6.m6.1.1.cmml" type="integer" xref="S6.p5.6.m6.1.1">22</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.6.m6.1c">22</annotation><annotation encoding="application/x-llamapun" id="S6.p5.6.m6.1d">22</annotation></semantics></math> out of <math alttext="129" class="ltx_Math" display="inline" id="S6.p5.7.m7.1"><semantics id="S6.p5.7.m7.1a"><mn id="S6.p5.7.m7.1.1" xref="S6.p5.7.m7.1.1.cmml">129</mn><annotation-xml encoding="MathML-Content" id="S6.p5.7.m7.1b"><cn id="S6.p5.7.m7.1.1.cmml" type="integer" xref="S6.p5.7.m7.1.1">129</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.7.m7.1c">129</annotation><annotation encoding="application/x-llamapun" id="S6.p5.7.m7.1d">129</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S6.p5.7.8">Indicator</span> posts were incorrectly classified as <span class="ltx_text ltx_font_italic" id="S6.p5.7.9">Ideation</span>, likely due to an over-sensitivity to certain features in the individual models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.p6">
<p class="ltx_p" id="S6.p6.4"><span class="ltx_text ltx_font_bold" id="S6.p6.4.1">Classification Report of ensemble model</span>.
Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.T8" title="TABLE VIII ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">VIII</span></a> shows the precision, recall, and F1 Score of the ensemble model on the <math alttext="500" class="ltx_Math" display="inline" id="S6.p6.1.m1.1"><semantics id="S6.p6.1.m1.1a"><mn id="S6.p6.1.m1.1.1" xref="S6.p6.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S6.p6.1.m1.1b"><cn id="S6.p6.1.m1.1.1.cmml" type="integer" xref="S6.p6.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S6.p6.1.m1.1d">500</annotation></semantics></math> labeled posts. We can observe that the <span class="ltx_text ltx_font_italic" id="S6.p6.4.2">Ideation</span> category has the highest recall, at <math alttext="0.86" class="ltx_Math" display="inline" id="S6.p6.2.m2.1"><semantics id="S6.p6.2.m2.1a"><mn id="S6.p6.2.m2.1.1" xref="S6.p6.2.m2.1.1.cmml">0.86</mn><annotation-xml encoding="MathML-Content" id="S6.p6.2.m2.1b"><cn id="S6.p6.2.m2.1.1.cmml" type="float" xref="S6.p6.2.m2.1.1">0.86</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.2.m2.1c">0.86</annotation><annotation encoding="application/x-llamapun" id="S6.p6.2.m2.1d">0.86</annotation></semantics></math>. Both <span class="ltx_text ltx_font_italic" id="S6.p6.4.3">Behavior</span> and <span class="ltx_text ltx_font_italic" id="S6.p6.4.4">Attempts</span> show balanced precision and recall, with both around <math alttext="0.80" class="ltx_Math" display="inline" id="S6.p6.3.m3.1"><semantics id="S6.p6.3.m3.1a"><mn id="S6.p6.3.m3.1.1" xref="S6.p6.3.m3.1.1.cmml">0.80</mn><annotation-xml encoding="MathML-Content" id="S6.p6.3.m3.1b"><cn id="S6.p6.3.m3.1.1.cmml" type="float" xref="S6.p6.3.m3.1.1">0.80</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.3.m3.1c">0.80</annotation><annotation encoding="application/x-llamapun" id="S6.p6.3.m3.1d">0.80</annotation></semantics></math>. Overall, the model achieves a weighted F1 Score of <math alttext="0.81" class="ltx_Math" display="inline" id="S6.p6.4.m4.1"><semantics id="S6.p6.4.m4.1a"><mn id="S6.p6.4.m4.1.1" xref="S6.p6.4.m4.1.1.cmml">0.81</mn><annotation-xml encoding="MathML-Content" id="S6.p6.4.m4.1b"><cn id="S6.p6.4.m4.1.1.cmml" type="float" xref="S6.p6.4.m4.1.1">0.81</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.4.m4.1c">0.81</annotation><annotation encoding="application/x-llamapun" id="S6.p6.4.m4.1d">0.81</annotation></semantics></math>, indicating consistent performance across all classes.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.p7">
<p class="ltx_p" id="S6.p7.6"><span class="ltx_text ltx_font_bold" id="S6.p7.6.1">Distributions of the number of tokens in a post.</span> Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.F7" title="Figure 7 ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">7</span></a>(a) shows the distribution of the number of words in a post for <math alttext="2{,}000" class="ltx_Math" display="inline" id="S6.p7.1.m1.2"><semantics id="S6.p7.1.m1.2a"><mrow id="S6.p7.1.m1.2.3.2" xref="S6.p7.1.m1.2.3.1.cmml"><mn id="S6.p7.1.m1.1.1" xref="S6.p7.1.m1.1.1.cmml">2</mn><mo id="S6.p7.1.m1.2.3.2.1" xref="S6.p7.1.m1.2.3.1.cmml">,</mo><mn id="S6.p7.1.m1.2.2" xref="S6.p7.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p7.1.m1.2b"><list id="S6.p7.1.m1.2.3.1.cmml" xref="S6.p7.1.m1.2.3.2"><cn id="S6.p7.1.m1.1.1.cmml" type="integer" xref="S6.p7.1.m1.1.1">2</cn><cn id="S6.p7.1.m1.2.2.cmml" type="integer" xref="S6.p7.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.1.m1.2c">2{,}000</annotation><annotation encoding="application/x-llamapun" id="S6.p7.1.m1.2d">2 , 000</annotation></semantics></math> training data samples. We can see that most posts contain fewer than <math alttext="2{,}000" class="ltx_Math" display="inline" id="S6.p7.2.m2.2"><semantics id="S6.p7.2.m2.2a"><mrow id="S6.p7.2.m2.2.3.2" xref="S6.p7.2.m2.2.3.1.cmml"><mn id="S6.p7.2.m2.1.1" xref="S6.p7.2.m2.1.1.cmml">2</mn><mo id="S6.p7.2.m2.2.3.2.1" xref="S6.p7.2.m2.2.3.1.cmml">,</mo><mn id="S6.p7.2.m2.2.2" xref="S6.p7.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p7.2.m2.2b"><list id="S6.p7.2.m2.2.3.1.cmml" xref="S6.p7.2.m2.2.3.2"><cn id="S6.p7.2.m2.1.1.cmml" type="integer" xref="S6.p7.2.m2.1.1">2</cn><cn id="S6.p7.2.m2.2.2.cmml" type="integer" xref="S6.p7.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.2.m2.2c">2{,}000</annotation><annotation encoding="application/x-llamapun" id="S6.p7.2.m2.2d">2 , 000</annotation></semantics></math> words. Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.F7" title="Figure 7 ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">7</span></a>(b) and Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#S6.F7" title="Figure 7 ‣ VI Analysis and Discussion ‣ Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels"><span class="ltx_text ltx_ref_tag">7</span></a>(c) present the distribution of the number of tokens in a post for <span class="ltx_text ltx_font_italic" id="S6.p7.6.2">Llama3-8B</span> and <span class="ltx_text ltx_font_italic" id="S6.p7.6.3">Gemma2-9B</span>, respectively. The figures reveal that the majority of posts have fewer than <math alttext="2{,}500" class="ltx_Math" display="inline" id="S6.p7.3.m3.2"><semantics id="S6.p7.3.m3.2a"><mrow id="S6.p7.3.m3.2.3.2" xref="S6.p7.3.m3.2.3.1.cmml"><mn id="S6.p7.3.m3.1.1" xref="S6.p7.3.m3.1.1.cmml">2</mn><mo id="S6.p7.3.m3.2.3.2.1" xref="S6.p7.3.m3.2.3.1.cmml">,</mo><mn id="S6.p7.3.m3.2.2" xref="S6.p7.3.m3.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p7.3.m3.2b"><list id="S6.p7.3.m3.2.3.1.cmml" xref="S6.p7.3.m3.2.3.2"><cn id="S6.p7.3.m3.1.1.cmml" type="integer" xref="S6.p7.3.m3.1.1">2</cn><cn id="S6.p7.3.m3.2.2.cmml" type="integer" xref="S6.p7.3.m3.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.3.m3.2c">2{,}500</annotation><annotation encoding="application/x-llamapun" id="S6.p7.3.m3.2d">2 , 500</annotation></semantics></math> tokens. In both models, only <math alttext="2" class="ltx_Math" display="inline" id="S6.p7.4.m4.1"><semantics id="S6.p7.4.m4.1a"><mn id="S6.p7.4.m4.1.1" xref="S6.p7.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.p7.4.m4.1b"><cn id="S6.p7.4.m4.1.1.cmml" type="integer" xref="S6.p7.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.4.m4.1c">2</annotation><annotation encoding="application/x-llamapun" id="S6.p7.4.m4.1d">2</annotation></semantics></math> out of the <math alttext="2{,}000" class="ltx_Math" display="inline" id="S6.p7.5.m5.2"><semantics id="S6.p7.5.m5.2a"><mrow id="S6.p7.5.m5.2.3.2" xref="S6.p7.5.m5.2.3.1.cmml"><mn id="S6.p7.5.m5.1.1" xref="S6.p7.5.m5.1.1.cmml">2</mn><mo id="S6.p7.5.m5.2.3.2.1" xref="S6.p7.5.m5.2.3.1.cmml">,</mo><mn id="S6.p7.5.m5.2.2" xref="S6.p7.5.m5.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p7.5.m5.2b"><list id="S6.p7.5.m5.2.3.1.cmml" xref="S6.p7.5.m5.2.3.2"><cn id="S6.p7.5.m5.1.1.cmml" type="integer" xref="S6.p7.5.m5.1.1">2</cn><cn id="S6.p7.5.m5.2.2.cmml" type="integer" xref="S6.p7.5.m5.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.5.m5.2c">2{,}000</annotation><annotation encoding="application/x-llamapun" id="S6.p7.5.m5.2d">2 , 000</annotation></semantics></math> posts exceed <math alttext="2{,}500" class="ltx_Math" display="inline" id="S6.p7.6.m6.2"><semantics id="S6.p7.6.m6.2a"><mrow id="S6.p7.6.m6.2.3.2" xref="S6.p7.6.m6.2.3.1.cmml"><mn id="S6.p7.6.m6.1.1" xref="S6.p7.6.m6.1.1.cmml">2</mn><mo id="S6.p7.6.m6.2.3.2.1" xref="S6.p7.6.m6.2.3.1.cmml">,</mo><mn id="S6.p7.6.m6.2.2" xref="S6.p7.6.m6.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p7.6.m6.2b"><list id="S6.p7.6.m6.2.3.1.cmml" xref="S6.p7.6.m6.2.3.2"><cn id="S6.p7.6.m6.1.1.cmml" type="integer" xref="S6.p7.6.m6.1.1">2</cn><cn id="S6.p7.6.m6.2.2.cmml" type="integer" xref="S6.p7.6.m6.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.6.m6.2c">2{,}500</annotation><annotation encoding="application/x-llamapun" id="S6.p7.6.m6.2d">2 , 500</annotation></semantics></math> tokens.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.p8">
<p class="ltx_p" id="S6.p8.4">Among <math alttext="47" class="ltx_Math" display="inline" id="S6.p8.1.m1.1"><semantics id="S6.p8.1.m1.1a"><mn id="S6.p8.1.m1.1.1" xref="S6.p8.1.m1.1.1.cmml">47</mn><annotation-xml encoding="MathML-Content" id="S6.p8.1.m1.1b"><cn id="S6.p8.1.m1.1.1.cmml" type="integer" xref="S6.p8.1.m1.1.1">47</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p8.1.m1.1c">47</annotation><annotation encoding="application/x-llamapun" id="S6.p8.1.m1.1d">47</annotation></semantics></math> registered teams, our solution achieved a score of <math alttext="75.436" class="ltx_Math" display="inline" id="S6.p8.2.m2.1"><semantics id="S6.p8.2.m2.1a"><mn id="S6.p8.2.m2.1.1" xref="S6.p8.2.m2.1.1.cmml">75.436</mn><annotation-xml encoding="MathML-Content" id="S6.p8.2.m2.1b"><cn id="S6.p8.2.m2.1.1.cmml" type="float" xref="S6.p8.2.m2.1.1">75.436</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p8.2.m2.1c">75.436</annotation><annotation encoding="application/x-llamapun" id="S6.p8.2.m2.1d">75.436</annotation></semantics></math> - the highest score on overall evaluation, based on <span class="ltx_text ltx_font_italic" id="S6.p8.4.1">model performance</span> (<math alttext="6" class="ltx_Math" display="inline" id="S6.p8.3.m3.1"><semantics id="S6.p8.3.m3.1a"><mn id="S6.p8.3.m3.1.1" xref="S6.p8.3.m3.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S6.p8.3.m3.1b"><cn id="S6.p8.3.m3.1.1.cmml" type="integer" xref="S6.p8.3.m3.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p8.3.m3.1c">6</annotation><annotation encoding="application/x-llamapun" id="S6.p8.3.m3.1d">6</annotation></semantics></math>-th on the private board with an F1 score of <math alttext="0.7312" class="ltx_Math" display="inline" id="S6.p8.4.m4.1"><semantics id="S6.p8.4.m4.1a"><mn id="S6.p8.4.m4.1.1" xref="S6.p8.4.m4.1.1.cmml">0.7312</mn><annotation-xml encoding="MathML-Content" id="S6.p8.4.m4.1b"><cn id="S6.p8.4.m4.1.1.cmml" type="float" xref="S6.p8.4.m4.1.1">0.7312</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p8.4.m4.1c">0.7312</annotation><annotation encoding="application/x-llamapun" id="S6.p8.4.m4.1d">0.7312</annotation></semantics></math>), <span class="ltx_text ltx_font_italic" id="S6.p8.4.2">approach innovation</span>, and <span class="ltx_text ltx_font_italic" id="S6.p8.4.3">report quality</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Conclusion</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This study introduces a new method for identifying suicidal content on social media by using Large Language Models (LLMs) along with traditional fine-tuning techniques. By creating pseudo-labels through LLM prompting and fine-tuning models, we tackle the issue of having limited annotated datasets. We then build an ensemble method, utilizing models like prompting <span class="ltx_text ltx_font_italic" id="S7.p1.1.1">Qwen2-72B-Instruct</span>, and fine-tuned <span class="ltx_text ltx_font_italic" id="S7.p1.1.2">Llama3-8B</span> and <span class="ltx_text ltx_font_italic" id="S7.p1.1.3">Gemma2-9B</span>, which shows significant improvements in detection accuracy and robustness. The results from the Suicide Ideation Detection on Social Media Challenge validate the effectiveness of our approach, providing a promising solution for early suicide risk identification on social platforms.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">However, our work has some limitations. The ensemble model, particularly <span class="ltx_text ltx_font_italic" id="S7.p2.1.1">Qwen2-72B-Instruct</span>, requires a substantial amount of time for inference due to its large size, which poses challenges for real-time deployment. To mitigate this, smaller distillation models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04501v1#bib.bib44" title="">44</a>]</cite> could offer a more practical solution. Additionally, enhancing suicide detection using LLMs would benefit from better prompt engineering by domain experts. Breaking prompts into smaller, more detailed questions can help guide LLMs more effectively and interoperably. Another promising direction for future research is the integration of visual data (<em class="ltx_emph ltx_font_italic" id="S7.p2.1.2">i.e</em>.<span class="ltx_text" id="S7.p2.1.3"></span>, images and video), commonly found in user posts, which may require multimodal LLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
WHO, “Suicide,” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.who.int/news-room/fact-sheets/detail/suicide" title="">https://www.who.int/news-room/fact-sheets/detail/suicide</a>, 2023, accessed: 2024-08-22.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Li, X.&nbsp;Chen, Z.&nbsp;Lin, K.&nbsp;Yang, H.&nbsp;V. Leong, N.&nbsp;X. Yu, and Q.&nbsp;Li, “Suicide risk level prediction and suicide trigger detection: A benchmark dataset,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">HKIE Transactions Hong Kong Institution of Engineers</em>, vol.&nbsp;29, no.&nbsp;4, pp. 268–282, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Yang, B.&nbsp;Yang, B.&nbsp;Hui, B.&nbsp;Zheng, B.&nbsp;Yu, C.&nbsp;Zhou, C.&nbsp;Li, C.&nbsp;Li, D.&nbsp;Liu, F.&nbsp;Huang <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">et&nbsp;al.</em>, “Qwen2 technical report,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.2.2">arXiv preprint arXiv:2407.10671</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Dubey, A.&nbsp;Jauhri, A.&nbsp;Pandey, A.&nbsp;Kadian, A.&nbsp;Al-Dahle, A.&nbsp;Letman, A.&nbsp;Mathur, A.&nbsp;Schelten, A.&nbsp;Yang, A.&nbsp;Fan <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">et&nbsp;al.</em>, “The llama 3 herd of models,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.2.2">arXiv preprint arXiv:2407.21783</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
R.&nbsp;Poświata and M.&nbsp;Perełkiewicz, “OPI@LT-EDI-ACL2022: Detecting signs of depression from social media text using RoBERTa pre-trained language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion</em>.&nbsp;&nbsp;&nbsp;Dublin, Ireland: Association for Computational Linguistics, May 2022, pp. 276–282. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.ltedi-1.40" title="">https://aclanthology.org/2022.ltedi-1.40</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
T.&nbsp;Mikolov, “Efficient estimation of word representations in vector space,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:1301.3781</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Pennington, R.&nbsp;Socher, and C.&nbsp;Manning, “GloVe: Global vectors for word representation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.&nbsp;&nbsp;&nbsp;Doha, Qatar: Association for Computational Linguistics, Oct. 2014, pp. 1532–1543. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D14-1162" title="">https://aclanthology.org/D14-1162</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Devlin, M.-W. Chang, K.&nbsp;Lee, and K.&nbsp;Toutanova, “BERT: Pre-training of deep bidirectional transformers for language understanding,” in <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>.&nbsp;&nbsp;&nbsp;Minneapolis, Minnesota: Association for Computational Linguistics, Jun. 2019, pp. 4171–4186. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/N19-1423" title="">https://aclanthology.org/N19-1423</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI, “GPT-4 technical report,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2303.08774</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
N.&nbsp;Muennighoff, N.&nbsp;Tazi, L.&nbsp;Magne, and N.&nbsp;Reimers, “MTEB: Massive text embedding benchmark,” in <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</em>.&nbsp;&nbsp;&nbsp;Dubrovnik, Croatia: Association for Computational Linguistics, May 2023, pp. 2014–2037. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.eacl-main.148" title="">https://aclanthology.org/2023.eacl-main.148</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Vaswani, “Attention is all you need,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Advances in Neural Information Processing Systems</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
T.&nbsp;Chen and C.&nbsp;Guestrin, “Xgboost: A scalable tree boosting system,” in <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining</em>, 2016, pp. 785–794.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
V.&nbsp;B. Parthasarathy, A.&nbsp;Zafar, A.&nbsp;Khan, and A.&nbsp;Shahid, “The ultimate guide to fine-tuning llms from basics to breakthroughs: An exhaustive review of technologies, research, best practices, applied research challenges and opportunities,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2408.13296</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Howard and S.&nbsp;Ruder, “Universal language model fine-tuning for text classification,” in <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>.&nbsp;&nbsp;&nbsp;Melbourne, Australia: Association for Computational Linguistics, Jul. 2018, pp. 328–339. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/P18-1031" title="">https://aclanthology.org/P18-1031</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Lee, W.&nbsp;Yoon, S.&nbsp;Kim, D.&nbsp;Kim, S.&nbsp;Kim, C.&nbsp;H. So, and J.&nbsp;Kang, “Biobert: a pre-trained biomedical language representation model for biomedical text mining,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Bioinformatics</em>, no.&nbsp;4, pp. 1234–1240, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
T.&nbsp;Dao, D.&nbsp;Y. Fu, S.&nbsp;Ermon, A.&nbsp;Rudra, and C.&nbsp;Re, “Flashattention: Fast and memory-efficient exact attention with IO-awareness,” in <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Advances in Neural Information Processing Systems</em>, 2022. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=H4DqfPSibmx" title="">https://openreview.net/forum?id=H4DqfPSibmx</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
N.&nbsp;Houlsby, A.&nbsp;Giurgiu, S.&nbsp;Jastrzebski, B.&nbsp;Morrone, Q.&nbsp;De&nbsp;Laroussilhe, A.&nbsp;Gesmundo, M.&nbsp;Attariyan, and S.&nbsp;Gelly, “Parameter-efficient transfer learning for nlp,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">International conference on machine learning</em>.&nbsp;&nbsp;&nbsp;PMLR, 2019, pp. 2790–2799.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
E.&nbsp;J. Hu, Y.&nbsp;Shen, P.&nbsp;Wallis, Z.&nbsp;Allen-Zhu, Y.&nbsp;Li, S.&nbsp;Wang, L.&nbsp;Wang, and W.&nbsp;Chen, “LoRA: Low-rank adaptation of large language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">International Conference on Learning Representations</em>, 2022. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="">https://openreview.net/forum?id=nZeVKeeFYf9</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
P.&nbsp;Sahoo, A.&nbsp;K. Singh, S.&nbsp;Saha, V.&nbsp;Jain, S.&nbsp;Mondal, and A.&nbsp;Chadha, “A systematic survey of prompt engineering in large language models: Techniques and applications,” <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2402.07927</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
X.&nbsp;Wang, J.&nbsp;Wei, D.&nbsp;Schuurmans, Q.&nbsp;V. Le, E.&nbsp;H. Chi, S.&nbsp;Narang, A.&nbsp;Chowdhery, and D.&nbsp;Zhou, “Self-consistency improves chain of thought reasoning in language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">The Eleventh International Conference on Learning Representations</em>, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=1PL1NIMMrw" title="">https://openreview.net/forum?id=1PL1NIMMrw</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Y.&nbsp;Du, S.&nbsp;Li, A.&nbsp;Torralba, J.&nbsp;B. Tenenbaum, and I.&nbsp;Mordatch, “Improving factuality and reasoning in language models through multiagent debate,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2305.14325</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Pham, B.&nbsp;Liu, Y.&nbsp;Yang, Z.&nbsp;Chen, T.&nbsp;Liu, J.&nbsp;Yuan, B.&nbsp;A. Plummer, Z.&nbsp;Wang, and H.&nbsp;Yang, “Let models speak ciphers: Multiagent debate through embeddings,” in <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">International Conference on Learning Representations (ICLR)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
X.&nbsp;Lan, Y.&nbsp;Cheng, L.&nbsp;Sheng, C.&nbsp;Gao, and Y.&nbsp;Li, “Depression detection on social media with large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2403.10750</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Y.&nbsp;Liu, “Roberta: A robustly optimized bert pretraining approach,” <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:1907.11692</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
H.&nbsp;Touvron, L.&nbsp;Martin, K.&nbsp;Stone, P.&nbsp;Albert, A.&nbsp;Almahairi, Y.&nbsp;Babaei, N.&nbsp;Bashlykov, S.&nbsp;Batra, P.&nbsp;Bhargava, S.&nbsp;Bhosale <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">et&nbsp;al.</em>, “Llama 2: Open foundation and fine-tuned chat models,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.2.2">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
K.&nbsp;Yang, T.&nbsp;Zhang, Z.&nbsp;Kuang, Q.&nbsp;Xie, J.&nbsp;Huang, and S.&nbsp;Ananiadou, “Mentallama: interpretable mental health analysis on social media with large language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the ACM on Web Conference 2024</em>, 2024, pp. 4489–4500.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
M.&nbsp;Arcan, P.-D. Niland, and F.&nbsp;Delahunty, “An assessment on comprehending mental health through large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2401.04592</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Chim, A.&nbsp;Tsakalidis, D.&nbsp;Gkoumas, D.&nbsp;Atzil-Slonim, Y.&nbsp;Ophir, A.&nbsp;Zirikly, P.&nbsp;Resnik, and M.&nbsp;Liakata, “Overview of the clpsych 2024 shared task: Leveraging large language models to identify evidence of suicidality risk in online posts,” in <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 9th Workshop on Computational Linguistics and Clinical Psychology (CLPsych 2024)</em>, 2024, pp. 177–190.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
H.&nbsp;Qi, Q.&nbsp;Zhao, C.&nbsp;Song, W.&nbsp;Zhai, D.&nbsp;Luo, S.&nbsp;Liu, Y.&nbsp;J. Yu, F.&nbsp;Wang, H.&nbsp;Zou, B.&nbsp;X. Yang, J.&nbsp;Li, and G.&nbsp;Fu, “Evaluating the efficacy of supervised learning vs large language models for identifying cognitive distortions and suicidal risks in chinese social media,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Y.&nbsp;Cui, Z.&nbsp;Yang, and X.&nbsp;Yao, “Efficient and effective text encoding for chinese llama and alpaca,” <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2304.08177</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Wei, X.&nbsp;Wang, D.&nbsp;Schuurmans, M.&nbsp;Bosma, F.&nbsp;Xia, E.&nbsp;Chi, Q.&nbsp;V. Le, D.&nbsp;Zhou <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">et&nbsp;al.</em>, “Chain-of-thought prompting elicits reasoning in large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib31.2.2">Advances in Neural Information Processing Systems</em>, vol.&nbsp;35, pp. 24 824–24 837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
G.&nbsp;Team, M.&nbsp;Riviere, S.&nbsp;Pathak, P.&nbsp;G. Sessa, C.&nbsp;Hardin, S.&nbsp;Bhupatiraju, L.&nbsp;Hussenot, T.&nbsp;Mesnard, B.&nbsp;Shahriari, A.&nbsp;Ramé <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">et&nbsp;al.</em>, “Gemma 2: Improving open language models at a practical size,” <em class="ltx_emph ltx_font_italic" id="bib.bib32.2.2">arXiv preprint arXiv:2408.00118</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ashref Maiza, “Multi label soft f1,” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ashrefm/multi-label-soft-f1" title="">https://github.com/ashrefm/multi-label-soft-f1</a>, 2019, accessed: 2024-08-30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Achiam, S.&nbsp;Adler, S.&nbsp;Agarwal, L.&nbsp;Ahmad, I.&nbsp;Akkaya, F.&nbsp;L. Aleman, D.&nbsp;Almeida, J.&nbsp;Altenschmidt, S.&nbsp;Altman, S.&nbsp;Anadkat <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">et&nbsp;al.</em>, “Gpt-4 technical report,” <em class="ltx_emph ltx_font_italic" id="bib.bib34.2.2">arXiv preprint arXiv:2303.08774</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Ziems, W.&nbsp;Held, O.&nbsp;Shaikh, J.&nbsp;Chen, Z.&nbsp;Zhang, and D.&nbsp;Yang, “Can large language models transform computational social science?” <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Computational Linguistics</em>, vol.&nbsp;50, no.&nbsp;1, pp. 237–291, Mar. 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2024.cl-1.8" title="">https://aclanthology.org/2024.cl-1.8</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
B.&nbsp;Yuan, Y.&nbsp;Chen, Y.&nbsp;Zhang, and W.&nbsp;Jiang, “Hide and seek in noise labels: Noise-robust collaborative active learning with LLMs-powered assistance,” in <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>.&nbsp;&nbsp;&nbsp;Bangkok, Thailand: Association for Computational Linguistics, Aug. 2024, pp. 10 977–11 011. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2024.acl-long.592" title="">https://aclanthology.org/2024.acl-long.592</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Jiang, A.&nbsp;Sablayrolles, A.&nbsp;Mensch, C.&nbsp;Bamford, D.&nbsp;Chaplot, D.&nbsp;de&nbsp;las Casas, F.&nbsp;Bressand, G.&nbsp;Lengyel, G.&nbsp;Lample, L.&nbsp;Saulnier <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">et&nbsp;al.</em>, “Mistral 7b (2023),” <em class="ltx_emph ltx_font_italic" id="bib.bib37.2.2">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Q. Jiang, A.&nbsp;Sablayrolles, A.&nbsp;Roux, A.&nbsp;Mensch, B.&nbsp;Savary, C.&nbsp;Bamford, D.&nbsp;S. Chaplot, D.&nbsp;d.&nbsp;l. Casas, E.&nbsp;B. Hanna, F.&nbsp;Bressand <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">et&nbsp;al.</em>, “Mixtral of experts,” <em class="ltx_emph ltx_font_italic" id="bib.bib38.2.2">arXiv preprint arXiv:2401.04088</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
I.&nbsp;Loshchilov and F.&nbsp;Hutter, “Decoupled weight decay regularization,” in <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">International Conference on Learning Representations</em>, 2019. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=Bkg6RiCqY7" title="">https://openreview.net/forum?id=Bkg6RiCqY7</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Sun, X.&nbsp;Qiu, Y.&nbsp;Xu, and X.&nbsp;Huang, “How to fine-tune bert for text classification?” in <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Chinese computational linguistics: 18th China national conference, CCL 2019, Kunming, China, October 18–20, 2019, proceedings 18</em>.&nbsp;&nbsp;&nbsp;Springer, 2019, pp. 194–206.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
E.&nbsp;Garcia, J.&nbsp;Gomes, A.&nbsp;F. Barbosa&nbsp;Junior, C.&nbsp;H. B. d.&nbsp;A. Borges, and N.&nbsp;F.&nbsp;F. da&nbsp;Silva, “DeepLearningBrasil@LT-EDI-2023: Exploring deep learning techniques for detecting depression in social media text,” in <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the Third Workshop on Language Technology for Equality, Diversity and Inclusion</em>.&nbsp;&nbsp;&nbsp;Varna, Bulgaria: INCOMA Ltd., Shoumen, Bulgaria, Sep. 2023, pp. 272–278. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.ltedi-1.42" title="">https://aclanthology.org/2023.ltedi-1.42</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Pham, V.&nbsp;Pham, and T.&nbsp;Dang, “Solar flare prediction using two-tier ensemble with deep learning and gradient boosting machine,” in <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">2019 IEEE International Conference on Big Data (Big Data)</em>, 2019, pp. 5844–5853.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Pham, V.&nbsp;Pham, and T.&nbsp;Dang., “Graph adversarial attacks and defense: An empirical study on citation graph,” in <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">2020 IEEE International Conference on Big Data (Big Data)</em>, 2020, pp. 2553–2562.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
S.&nbsp;Muralidharan, S.&nbsp;T. Sreenivas, R.&nbsp;Joshi, M.&nbsp;Chochowski, M.&nbsp;Patwary, M.&nbsp;Shoeybi, B.&nbsp;Catanzaro, J.&nbsp;Kautz, and P.&nbsp;Molchanov, “Compact language models via pruning and knowledge distillation,” <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2407.14679</em>, 2024.

</span>
</li>
</ul>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body></html>