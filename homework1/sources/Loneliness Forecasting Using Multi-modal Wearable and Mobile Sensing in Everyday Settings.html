<!DOCTYPE html><html lang="en" data-theme="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings</title>
<!--Generated on Sun Sep 15 18:32:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">




<meta content="
Loneliness Forecasting,  Passive Sensing,  Wearable Devices,  Machine Learning,  Personal Models,  College Students
" lang="en" name="keywords">
<base href="https://arxiv.org/html/2410.00020v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2410.00020v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2410.00020v1/#myForm">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2410.00020v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2410.00020v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S1" title="In Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S2" title="In Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Loneliness Data Collection</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S2.SS1" title="In II Loneliness Data Collection ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">Participants</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S2.SS2" title="In II Loneliness Data Collection ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Recruitment</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3" title="In Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Method</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3.SS1" title="In III Method ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Feature Extraction</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3.SS1.SSS1" title="In III-A Feature Extraction ‣ III Method ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>1 </span>Physiological Features</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3.SS1.SSS2" title="In III-A Feature Extraction ‣ III Method ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>2 </span>Behavioral Features</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3.SS1.SSS3" title="In III-A Feature Extraction ‣ III Method ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>3 </span>Social Features</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3.SS1.SSS4" title="In III-A Feature Extraction ‣ III Method ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>4 </span>Contextual Features</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3.SS2" title="In III Method ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Feature Alignment</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3.SS3" title="In III Method ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Missing Data</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3.SS4" title="In III Method ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span> </span><span class="ltx_text ltx_font_italic">Classification Model</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S3.SS5" title="In III Method ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-E</span> </span><span class="ltx_text ltx_font_italic">Model Explainability</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S4" title="In Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S4.SS1" title="In IV Results ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Loneliness Forecasting Performance</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S4.SS2" title="In IV Results ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Model Explainability</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S5" title="In Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0</a><div id="watermark-tr">arXiv:2410.00020v1 [eess.SP] 15 Sep 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Zhongqi Yang<sup class="ltx_sup" id="id14.14.id1">1</sup>,
Iman Azimi<sup class="ltx_sup" id="id15.15.id2">1</sup>,
Salar Jafarlou<sup class="ltx_sup" id="id16.16.id3">1</sup>,
Sina Labbaf<sup class="ltx_sup" id="id17.17.id4">1</sup>,
Brenda Nguyen<sup class="ltx_sup" id="id18.18.id5">2</sup>,
Hana Qureshi<sup class="ltx_sup" id="id19.19.id6">2</sup>,
<br class="ltx_break">Christopher Marcotullio<sup class="ltx_sup" id="id20.20.id7">2</sup>,
Jessica L. Borelli<sup class="ltx_sup" id="id21.21.id8">2</sup>,
Nikil Dutt<sup class="ltx_sup" id="id22.22.id9">1</sup>,
and Amir M. Rahmani<sup class="ltx_sup" id="id23.23.id10"><span class="ltx_text ltx_font_italic" id="id23.23.id10.1">1,3</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><sup class="ltx_sup" id="id24.24.id1">1</sup><span class="ltx_text ltx_font_italic" id="id13.13.2">Department of Computer Science
<br class="ltx_break"><sup class="ltx_sup" id="id13.13.2.1"><span class="ltx_text ltx_font_upright" id="id13.13.2.1.1">2</span></sup>Department of Psychological Science
<br class="ltx_break"><sup class="ltx_sup" id="id13.13.2.2"><span class="ltx_text ltx_font_upright" id="id13.13.2.2.1">3</span></sup>School of Nursing
<br class="ltx_break">University of California, Irvine
<br class="ltx_break"></span>{zhongqy4, azimii, jafarlos, slabbaf, brendn3, hanaq, cmarcotu, jessica.borelli, dutt, a.rahmani}@uci.edu
</span></span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id25.id1">The adverse effects of loneliness on both physical and mental well-being are profound. Although previous research has utilized mobile sensing techniques to detect mental health issues,
few studies have utilized state-of-the-art wearable devices to forecast loneliness and estimate the physiological manifestations of loneliness and its predictive nature.
The primary objective of this study is to examine the feasibility of forecasting loneliness by employing wearable devices, such as smart rings and watches, to monitor early physiological indicators of loneliness. Furthermore, smartphones are employed to capture initial behavioral signs of loneliness.
To accomplish this, we employed personalized machine learning techniques, leveraging a comprehensive dataset comprising physiological and behavioral information obtained during our study involving the monitoring of college students. Through the development of personalized models, we achieved a notable accuracy of 0.82 and an F-1 score of 0.82 in forecasting loneliness levels seven days in advance. Additionally, the application of Shapley values facilitated model explainability.
The wealth of data provided by this study, coupled with the forecasting methodology employed, possesses the potential to augment interventions and facilitate the early identification of loneliness within populations at risk.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
Loneliness Forecasting, Passive Sensing, Wearable Devices, Machine Learning, Personal Models, College Students

</div>
<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Accepted to IEEE-EMBS International Conference on
Body Sensor Networks:
Sensor and Systems for Digital Health
(IEEE BSN 2023)
</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Loneliness is a negative feeling often related to loss and disappointment&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib1" title="">1</a>]</cite>.
It arises when individuals evaluate their existing relationships against their own wishes and societal expectations&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib2" title="">2</a>]</cite>.
Loneliness can have negative impacts on physical and mental health, leading to heightened rates of morbidity and mortality&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib3" title="">3</a>]</cite>.
Multiple studies, such as the research conducted by Park <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib4" title="">4</a>]</cite>, have provided compelling evidence establishing a connection between loneliness and adverse physiological and mental health outcomes. Notably, associations have been identified between loneliness and disturbances in sleep patterns, as well as diminished cardiac output.
Furthermore, the ongoing COVID-19 pandemic has amplified concerns surrounding loneliness, particularly among adolescents and young adults hailing from lower socioeconomic backgrounds &nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib5" title="">5</a>]</cite>. The profound implications for health underscore the imperative of comprehending the underlying factors contributing to the development of loneliness, as well as the optimal timing for its detection and forecasting.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Existing studies have capitalized on wearable and mobile sensing to detect loneliness.
Such works encompass the use of smartphones, wearable sensors, wearable activity trackers, and other technologies to collect information on environmental context, heart rate, activity, and sleep patterns.
For instance, Wu <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">et al.</span> utilize smartphones to collect geosocial data such as the individual’s location and social interaction to detect loneliness in real-time&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib6" title="">6</a>]</cite>.
Li <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">et al.</span> capture the app usage information as additional features to identify loneliness risk&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib7" title="">7</a>]</cite>.
Doryab <span class="ltx_text ltx_font_italic" id="S1.p2.1.3">et al.</span> employ smartphones to capture behavioral data, including locations, calls log, screen status, etc. as well the FitBit sensors to capture mobility and physical activity to detect loneliness&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib8" title="">8</a>]</cite>.
Besides loneliness, a few studies incorporate mobile sensing to identify other mental health outcomes such as stress, depression, and suicidal ideation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib11" title="">11</a>]</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Nevertheless, current studies predominantly concentrate on the immediate detection of loneliness or offline analysis, failing to account for temporal variations in time series data or explore the interplay between objective data and loneliness. This glaring gap in the literature pertains specifically to the forecasting of loneliness levels with a time interval between the predictive features and the target outcome.
More precisely, there exists a lack of research pertaining to the forecasting of loneliness over a defined period, leading to an insufficient availability of dedicated datasets for addressing this specific research inquiry.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Modern wearable devices (such as the Oura Ring and Samsung smartwatch) and mobile phones have demonstrated their capacity to assess a wide range of physiological, behavioral and contextual information. Their viability for integration into healthcare applications has been substantiated by previous research&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib13" title="">13</a>]</cite>.
The incorporation of such supplementary information holds promise as a prospective avenue for exploration in the modeling of loneliness.
Furthermore, with regard to the intricate relationship between loneliness and other health risks, the potential forecasting or early detection of feelings of loneliness presents novel opportunities for the development of targeted interventions aimed at alleviating loneliness and enhancing individual well-being.
By leveraging the ubiquitous sensing capabilities of modernized devices, it becomes possible to continuously gather an extensive array of physiological and behavioral data in tandem with self-reported levels of loneliness to build models.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this paper, we present a personalized machine-learning method to forecast levels of loneliness by leveraging longitudinal data encompassing physiological, behavioral, and contextual information collected from smart rings, watches, and smartphones. To achieve this, we conducted a two-month monitoring study involving a cohort of 29 college students, utilizing the Oura Ring, Samsung Smartwatch, and the AWARE app installed on smartphones.
In addition to capturing objective and passive data through these devices, we collected self-reported loneliness information from the participants, thereby generating detailed and granular labels for evaluation purposes.
The collected objective and subjective data were employed to train and assess the effectiveness of our proposed loneliness forecasting method. Moreover, we integrated SHAP (SHapley Additive exPlanations) to compute the Shapley values, allowing for a deeper understanding of the relationship between the temporal features derived from these time series data and the experience of loneliness&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib14" title="">14</a>]</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Loneliness Data Collection</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Our study employs a comprehensive approach to collecting data, including self-reported loneliness and related physiological and behavioral data. We utilized the ZotCare platform for efficient data collection and storage&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib15" title="">15</a>]</cite>.
The gathered data can be categorized into three types: objective physiological, objective behavioral, and subjective questionnaires. Objective physiological data were collected using the Oura ring and Samsung smartwatch.
The Oura ring assessed sleep patterns, while the Samsung smartwatch continuously monitored physiological parameters throughout the day.
Objective behavioral data were collected through the implementation of the AWARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib16" title="">16</a>]</cite> phone app, which captured mobile sensory data and recorded detailed information regarding participants’ phone usage patterns.
Subjective self-report data were gathered employing our custom mSavorUs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib17" title="">17</a>]</cite> phone app, specifically designed for the collection of subjective experiential data and the provision of interventions. The self-reported loneliness levels were measured on a scale ranging from 0 to 100, with 0 indicating “not feeling lonely at all” and 100 indicating “feeling extremely lonely.” These self-reported loneliness levels were further categorized as either ”Not Feel Lonely” or ”Feel Lonely,” based on whether they fell below or above the population median, respectively. All procedures were approved by the researchers’ academic institutional review board (#2019-5153).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.4.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.5.2">Participants</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">This study explores loneliness and mental health in 29 full-time college students from a Southern California university. Excluded are married students, those with children, returnees after a three-year hiatus, and severe psychopathology cases.
Participants needed fluent English and an Android smartphone compatible with Oura Ring and Samsung Active 2 watch for data collection. Recruitment involved faculty outreach, social media sharing, and screening surveys for depression/suicidal ideation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.4.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.5.2">Recruitment</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Participants meeting the inclusion criteria underwent a baseline assessment in a lab session and set up the devices under instruction.
During the monitoring phase for approximately 8 weeks, participants are asked to wear the devices continuously, except during charging or potentially damaging activities.
The watch app collected 12 minutes of photoplethysmogram (PPG) signals every 2 hours.
The AWARE app monitored phone usage, while the mSavorUs app prompted participants for brief surveys multiple times daily.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Method</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this study, we devised a loneliness forecasting model on predicting loneliness seven days in advance.
Given the complex nature of the multi-modal time series data, we employed machine learning models to perform feature extraction and classify the levels of loneliness.
Our methodology encompasses the extraction of physiological, behavioral, social, and contextual features.
We address challenges such as feature alignment, handling missing data, and the development of a classification model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Feature Extraction</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS1.4.1.1">III-A</span>1 </span>Physiological Features</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">We extract Heart Rate (HR) and Heart Rate Variability (HRV)-related features from the signal collected from smart rings and watches as the physiological features.
To this end, we extract the time-domain HRV characteristics (e.g. SDNN, RMSSD, AVNN), the frequency-domain HRV characteristics (e.g. LF, HF and LF / HF ratio) and the nonlinear HRV characteristics (e.g. SD1 and SD2) features&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib18" title="">18</a>]</cite>.
In ubiquitous monitoring settings, signal collection with PPG-based wearable devices can be affected by the presence of noise.
To overcome this issue, we implement the methods to extract HR and HRV features from raw collected PPG signals&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib21" title="">21</a>]</cite>.
We first conduct a signal quality assessment to classify PPG signals as clean or noisy, then reconstruct short-term noisy segments via a generative adversarial network.
Then the systolic peaks and inter-beat intervals are detected by a dilated Convolution Neural Network, from which HR and HRV-related features are extracted.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS2.4.1.1">III-A</span>2 </span>Behavioral Features</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">Behavioral features refer to the patterns and characteristics of subjects’ smartphone usage behavior.
They are extracted from participants’ smartphone usage.
We extract the smartphone usage features, including the number of battery charger plugins, screen off, screen on, screen locks, and screen unlocks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS3.4.1.1">III-A</span>3 </span>Social Features</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">The term “social features” pertains to the discernible patterns of social activity demonstrated by individuals through their smartphone usage. These features serve as valuable indicators that shed light on the nature of individuals’ interactions and engagements within their respective social networks. Examples of such social features encompass the quantity of messages and notifications within various categories, as well as the duration and frequency of phone calls within specific time windows.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS4.4.1.1">III-A</span>4 </span>Contextual Features</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS4.p1">
<p class="ltx_p" id="S3.SS1.SSS4.p1.1">Contextual features encompass the environmental information related to the subjects.
These features provide insights into the surrounding context in which individuals operate using GPS localization.
The contextual features include the variance of latitude, variance and mean of speed, number of places, duration at home, the mean and standard deviation of the duration outside, and the total travel distance within a given location time window.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Feature Alignment</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The dataset contains features collected at varying resolutions, with some features recorded once daily (e.g., sleep-related) and others, such as PPG-related features, captured multiple times a day.
To align the features with label, we average the values within a designated time window preceding the corresponding loneliness levels.
The selection of the optimal time window for each feature is based on the averaged feature’s correlation with the target loneliness levels.
Subsequently, the resulting data records were compiled using the aligned features corresponding to the optimal window lengths and the self-reported loneliness level.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.4.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.5.2">Missing Data</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">In our dataset, missing data may occur due to participants forgetting to wear or charge their devices.
We discovered that using the average of all valid values for each participant exhibited a strong correlation with the loneliness label for most features.
Therefore, we implement a single imputation method to address missing data across all features&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib22" title="">22</a>]</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS4.4.1.1">III-D</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS4.5.2">Classification Model</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">We define a binary classification task to forecast loneliness.
Each self-reported loneliness is associated with the aligned features within a 14-day time window, starting 3 weeks prior to the loneliness target.
There is a one-week interval between the available features and the target.
However, the number of aligned feature records within the time window may vary due to different self-report frequencies.
To maintain a consistent count for each loneliness target, we aggregate the data by calculating the daily average for each aligned feature.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">To forecast loneliness with the aggregated features, we employ Random Forests consisting of 400 trees with a maximum depth of 15.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS5.4.1.1">III-E</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS5.5.2">Model Explainability</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">We explore the model explainability by utilizing path-dependent feature perturbation algorithms&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#bib.bib23" title="">23</a>]</cite> to compute the Shapley values of the features.
Based on the Shapley values for each feature, we obtain a quantitative measure of their contributions to the predictions.
These values allow us to rank the features based on their relative importance and assess their effect on the output loneliness category.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Results</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Loneliness Forecasting Performance</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The models are trained and validated in a personalized manner on the data from a two-month study involving 29 participants.
Each participant’s data were divided into a test set and a train set. The test set contains the most recent 50% of the data in the monitoring.
However, the training set includes the first 50% data of the same person as well as data from all other participants.
Personalized models were then trained and tested using these training-testing set pairs from each participant.
This approach allows us to assess the model’s performance by simulating real-world scenarios while maintaining the integrity of individual participant data.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">After preprocessing, we obtained a total of 6212 data points, which were used to develop 29 personalized models to forecast loneliness 7 days ahead using the features from the past two weeks.
To assess the performance of our approach, we average the results across all the personal models.
The overall performance is summarized in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S4.T1" title="TABLE I ‣ IV-A Loneliness Forecasting Performance ‣ IV Results ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_tag">I</span></a>.
Our loneliness forecasting model achieves an accuracy of 0.823, recall of 0.905, precision of 0.750, F-1 score of 0.820, Cohen’s kappa of 0.648.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>The overall performance on loneliness forecasting.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1">Accuracy</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.2">Recall</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.3">Precision</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.4">F-1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.5">Cohen’s Kappa</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.2.2.1">0.823</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.2.2.2">0.905</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.2.2.3">0.750</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.2.2.4">0.820</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.2.2.5">0.648</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S4.T2" title="TABLE II ‣ IV-A Loneliness Forecasting Performance ‣ IV Results ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_tag">II</span></a> illustrates the confusion matrix of the loneliness detection models, derived from 3095 test samples.
This suggests that based on the physiological, behavioral, social, and contextual information, the model could forecast if the participant would feel lonely.
Note that the overall performance of our model is influenced by false negatives.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Confusion matrix</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1">
<th class="ltx_td ltx_nopad ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.1.1"><svg height="23.45" overflow="visible" version="1.1" width="169.12"><g transform="translate(0,23.45) scale(1,-1)"><path d="M 0,23.45 169.12,0" stroke="#000000" stroke-width="0.4"></path><g class="ltx_svg_fog" transform="translate(0,0)"><g transform="translate(0,13.84) scale(1, -1)"><foreignObject height="13.84" overflow="visible" width="84.56">
<span class="ltx_inline-block" id="S4.T2.1.1.1.pic1.1.1">
<span class="ltx_inline-block ltx_align_left" id="S4.T2.1.1.1.pic1.1.1.1">
<span class="ltx_p" id="S4.T2.1.1.1.pic1.1.1.1.1">Actual (label)</span>
</span>
</span></foreignObject></g></g><g class="ltx_svg_fog" transform="translate(106.62,13.84)"><g transform="translate(0,9.61) scale(1, -1)"><foreignObject height="9.61" overflow="visible" width="62.5">
<span class="ltx_inline-block" id="S4.T2.1.1.1.pic1.2.1">
<span class="ltx_inline-block ltx_align_right" id="S4.T2.1.1.1.pic1.2.1.1">
<span class="ltx_p" id="S4.T2.1.1.1.pic1.2.1.1.1">Prediction</span>
</span>
</span></foreignObject></g></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.1.1.2">Not Feel Lonely</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.1.1.3">Feel Lonely</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.2.1.1">Not Feel Lonely</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.2.1.2">1371</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.2.1.3">114</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.3.2.1">Feel Lonely</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.3.2.2">412</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.3.2.3">1198</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Model Explainability</span>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.00020v1#S4.F1" title="Figure 1 ‣ IV-B Model Explainability ‣ IV Results ‣ Loneliness Forecasting Using Multi-modal Wearable and Mobile Sensing in Everyday Settings"><span class="ltx_text ltx_ref_tag">1</span></a> presents the overall Shapley value across all test samples for the top 20 features.
The feature names are noted with the prefix ’day<math alttext="x" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_x</annotation></semantics></math>’ indicating the specific day within the time window from which each feature originates.
Each dot in the plot represents a feature value instance, with its horizontal position indicating its effect on the predicted loneliness category.
Dots positioned to the left suggest a higher probability of predicting “Not Feel Lonely” while dots positioned to the right indicate a higher probability of predicting “Feel Lonely”.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We observe that higher sleep restless scores are strongly associated with increased loneliness likelihood, making it the most influential feature.
Lower activity balance scores also contribute significantly, implying that lower activity levels are associated with an increased likelihood of feeling lonely.
Clinicians can address the fact that poor sleep and low levels of activity are connected to loneliness, by assisting clients in improving these aspects of their daily lives. Even though it might not be the initial line of treatment that clinicians consider for loneliness, it could hold substantial importance in addressing the issue.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="330" id="S4.F1.g1" src="https://arxiv.org/html/2410.00020v1/extracted/5854481/shapley.png" width="299">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Feature Importance Using Shapley Values Beeswarm Plot</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Conclusion</span>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This paper proposed a machine learning method for forecasting loneliness based on physiological, behavioral, and
contextual information collected from smart rings, watches, and smartphones
Our developed model achieved an accuracy of 0.823 and an F-1 score of 0.820 in forecasting loneliness levels 7 days ahead.
We incorporated Shapley values as explainability methods to gain insights into the relationship between the features and loneliness.
By extending beyond existing studies that focus on prompt loneliness detection, our approach offered the potential for clinical implementation in the early identification and addressing of loneliness among at-risk populations.
Further investigation into the utilization of deep learning models for predicting loneliness has the potential to improve performance by automatically extracting more robust features. Moreover, deep learning holds promise in forecasting loneliness in several weeks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
D.&nbsp;Perlman and L.&nbsp;A. Peplau, “Toward a social psychology of loneliness,” <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Personal relationships</span>, vol.&nbsp;3, pp.&nbsp;31–56, 1981.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
D.&nbsp;P. Perlman, “Personal relationships in disorder,” in <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Personal
Relationships</span> (S.&nbsp;Duck and R.&nbsp;Gilmour, eds.), San Diego, CA: Academic Press,
1981.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Holt-Lunstad, T.&nbsp;B. Smith, M.&nbsp;Baker, T.&nbsp;Harris, and D.&nbsp;Stephenson,
“Loneliness and social isolation as risk factors for mortality: a
meta-analytic review,” <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Perspectives on psychological science</span>, vol.&nbsp;10,
no.&nbsp;2, pp.&nbsp;227–237, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Park, A.&nbsp;Majeed, Gill, <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">et&nbsp;al.</span>, “The effect of loneliness on distinct
health outcomes: a comprehensive review and meta-analysis,” <span class="ltx_text ltx_font_italic" id="bib.bib4.2.2">Psychiatry
Research</span>, vol.&nbsp;294, p.&nbsp;113514, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
D.&nbsp;Banerjee and M.&nbsp;Rai, “Social isolation in covid-19: The impact of
loneliness,” 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Wu, A.&nbsp;N. Barczyk, R.&nbsp;C. Craddock, G.&nbsp;M. Harari, and the others, “Improving
prediction of real-time loneliness and companionship type using geosocial
features of personal smartphone data,” <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">Smart Health</span>, vol.&nbsp;20,
p.&nbsp;100180, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Z.&nbsp;Li, D.&nbsp;Shi, F.&nbsp;Wang, and F.&nbsp;Liu, “Loneliness recognition based on mobile
phone data,” in <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">2016 International Symposium on Advances in Electrical,
Electronics and Computer Engineering</span>, pp.&nbsp;165–172, Atlantis Press, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Doryab, D.&nbsp;K. Villalba, P.&nbsp;Chikersal, J.&nbsp;M. Dutcher, M.&nbsp;Tumminia, X.&nbsp;Liu,
S.&nbsp;Cohen, K.&nbsp;Creswell, <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">et&nbsp;al.</span>, “Identifying behavioral phenotypes of
loneliness and social isolation with passive sensing: statistical analysis,
data mining and machine learning of smartphone and fitbit data,” <span class="ltx_text ltx_font_italic" id="bib.bib8.2.2">JMIR
mHealth and uHealth</span>, vol.&nbsp;7, no.&nbsp;7, p.&nbsp;e13209, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Sano, S.&nbsp;Taylor, A.&nbsp;W. McHill, A.&nbsp;J. Phillips, L.&nbsp;K. Barger, E.&nbsp;Klerman, and
R.&nbsp;Picard, “Identifying objective physiological markers and modifiable
behaviors for self-reported stress and mental health status using wearable
sensors and mobile phones: observational study,” <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">Journal of medical
Internet research</span>, vol.&nbsp;20, no.&nbsp;6, p.&nbsp;e210, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Haines-Delmont, G.&nbsp;Chahal, A.&nbsp;J. Bruen, A.&nbsp;Wall, C.&nbsp;T. Khan, R.&nbsp;Sadashiv,
D.&nbsp;Fearnley, <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">et&nbsp;al.</span>, “Testing suicide risk prediction algorithms using
phone measurements with patients in acute mental health settings: feasibility
study,” <span class="ltx_text ltx_font_italic" id="bib.bib10.2.2">JMIR mHealth and uHealth</span>, vol.&nbsp;8, no.&nbsp;6, p.&nbsp;e15901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
N.&nbsp;Narziev, H.&nbsp;Goh, K.&nbsp;Toshnazarov, S.&nbsp;A. Lee, K.-M. Chung, and Y.&nbsp;Noh, “Stdd:
short-term depression detection with passive sensing,” <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Sensors</span>,
vol.&nbsp;20, no.&nbsp;5, p.&nbsp;1396, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
M.&nbsp;Nissen, S.&nbsp;Slim, K.&nbsp;Jäger, M.&nbsp;Flaucher, H.&nbsp;Huebner, N.&nbsp;Danzberger, P.&nbsp;A.
Fasching, M.&nbsp;W. Beckmann, S.&nbsp;Gradl, B.&nbsp;M. Eskofier, <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">et&nbsp;al.</span>, “Heart
rate measurement accuracy of fitbit charge 4 and samsung galaxy watch
active2: Device evaluation study,” <span class="ltx_text ltx_font_italic" id="bib.bib12.2.2">JMIR Formative Research</span>, vol.&nbsp;6,
no.&nbsp;3, p.&nbsp;e33635, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
R.&nbsp;Wang, F.&nbsp;Chen, Z.&nbsp;Chen, T.&nbsp;Li, G.&nbsp;Harari, S.&nbsp;Tignor, X.&nbsp;Zhou, D.&nbsp;Ben-Zeev,
and A.&nbsp;T. Campbell, “Studentlife: assessing mental health, academic
performance and behavioral trends of college students using smartphones,” in
<span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 2014 ACM international joint conference on pervasive
and ubiquitous computing</span>, pp.&nbsp;3–14, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
S.&nbsp;M. Lundberg and S.-I. Lee, “A unified approach to interpreting model
predictions,” <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Advances in neural information processing systems</span>,
vol.&nbsp;30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
S.&nbsp;Labbaf, M.&nbsp;Abbasian, I.&nbsp;Azimi, N.&nbsp;Dutt, and A.&nbsp;M. Rahmani, “Zotcare: A
flexible, personalizable, and affordable mhealth service provider,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
D.&nbsp;Ferreira, V.&nbsp;Kostakos, and A.&nbsp;K. Dey, “Aware: mobile context
instrumentation framework,” <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">Frontiers in ICT</span>, vol.&nbsp;2, p.&nbsp;6, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
HealthSciTech and DuttResearchGroup, “msavorus,” <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">https://play.google.com/store/apps/details?id=org.healthscitech.thrive&amp;pli=1</span>,
2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
F.&nbsp;Shaffer and J.&nbsp;P. Ginsberg, “An overview of heart rate variability metrics
and norms,” <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Frontiers in public health</span>, p.&nbsp;258, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
M.&nbsp;Feli, I.&nbsp;Azimi, A.&nbsp;Anzanpour, A.&nbsp;M. Rahmani, and P.&nbsp;Liljeberg, “An
energy-efficient semi-supervised approach for on-device photoplethysmogram
signal quality assessment,” <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">Smart Health</span>, vol.&nbsp;28, p.&nbsp;100390, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
K.&nbsp;Kazemi, J.&nbsp;Laitala, I.&nbsp;Azimi, P.&nbsp;Liljeberg, and A.&nbsp;M. Rahmani, “Robust ppg
peak detection using dilated convolutional neural networks,” <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">Sensors</span>,
vol.&nbsp;22, no.&nbsp;16, p.&nbsp;6054, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Y.&nbsp;Wang, I.&nbsp;Azimi, K.&nbsp;Kazemi, A.&nbsp;M. Rahmani, and P.&nbsp;Liljeberg, “Ppg signal
reconstruction using deep convolutional generative adversarial network,” in
<span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">2022 44th Annual International Conference of the IEEE Engineering in
Medicine &amp; Biology Society (EMBC)</span>, pp.&nbsp;3387–3391, IEEE, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;R.&nbsp;T. Donders, G.&nbsp;J. Van Der&nbsp;Heijden, T.&nbsp;Stijnen, and K.&nbsp;G. Moons, “A
gentle introduction to imputation of missing values,” <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">Journal of
clinical epidemiology</span>, vol.&nbsp;59, no.&nbsp;10, pp.&nbsp;1087–1091, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
S.&nbsp;M. Lundberg and S.-I. Lee, “A unified approach to interpreting model
predictions,” in <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">Advances in Neural Information Processing Systems 30</span>
(I.&nbsp;Guyon, U.&nbsp;V. Luxburg, S.&nbsp;Bengio, H.&nbsp;Wallach, R.&nbsp;Fergus, S.&nbsp;Vishwanathan,
and R.&nbsp;Garnett, eds.), pp.&nbsp;4765–4774, Curran Associates, Inc., 2017.

</span>
</li>
</ul>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body></html>