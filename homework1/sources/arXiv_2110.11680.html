<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2110.11680] Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation</title><meta property="og:description" content="Several video-based 3D pose and shape estimation algorithms have been proposed to resolve the temporal inconsistency of single-image-based methods. However it still remains challenging to have stable and accurate reconâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2110.11680">

<!--Generated on Sun Mar  3 23:19:18 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ziwen Li<sup id="id1.1.id1" class="ltx_sup">1</sup>, Bo Xu<sup id="id2.2.id2" class="ltx_sup">1</sup>, Han Huang<sup id="id3.3.id3" class="ltx_sup">1</sup>, Cheng Lu<sup id="id4.4.id4" class="ltx_sup">2</sup> and Yandong Guo<sup id="id5.5.id5" class="ltx_sup">1,*</sup>
<br class="ltx_break"><sup id="id6.6.id6" class="ltx_sup">1</sup>OPPO Research Institute, <sup id="id7.7.id7" class="ltx_sup">2</sup>Xmotors
<br class="ltx_break"><span id="id8.8.id8" class="ltx_text ltx_font_typewriter" style="font-size:90%;">yandong.guo@live.com</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">Several video-based 3D pose and shape estimation algorithms have been proposed to resolve the temporal inconsistency of single-image-based methods. However it still remains challenging to have stable and accurate reconstruction. In this paper, we propose a new framework Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation (DTS-VIBE), to generate 3D human pose and mesh from RGB videos. We reformulate the task as a multi-modality problem that fuses RGB and optical flow for more reliable estimation. In order to fully utilize both sensory modalities (RGB or optical flow), we train a two-stream temporal network based on transformer to predict SMPL parameters. The supplementary modality, optical flow, helps to maintain temporal consistency by leveraging motion knowledge between two consecutive frames. The proposed algorithm is extensively evaluated on the Human3.6 and 3DPW datasets. The experimental results show that it outperforms other state-of-the-art methods by a significant margin.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Considerable amount of research has been done on the 3D human pose and shape estimation from a single RGB imageÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. More recently, some methods try to improve 3D human reconstruction by exploiting temporal information from monocular videoÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. However, those methods still struggle to reconstruct accurate 3D human body when there is complex human joint movement or severe occlusion, largely because of limited sensory modality and training data.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S1.F1.2" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\animategraphics</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S1.F1.3" class="ltx_p ltx_figure_panel ltx_align_center">[width=8cm,height=4.5cm, autoplay, loop]15img_0009300159</p>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.5.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.6.2" class="ltx_text" style="font-size:90%;">DTS-VIBE learns the complementation of multiply sensory modalities for 3D human mesh reconstruction. Given a RGB video (a), we first estimate its optical flow (b) by auto encoder and predict the human mesh (c) by our two-stream temporal encoder-to-decoder network based on transformer. <em id="S1.F1.6.2.1" class="ltx_emph ltx_font_italic">We suggest readers view this animated figure by Adobe Reader.</em></span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To address this, we revisit the 3D human reconstruction from video with the following two beliefs. First, we argue that RGB feature alone is insufficient to interpret the high degree of freedom of human behavior, and additional sensory information is needed. Second, we argue that a much stronger temporal network should be introduced into 3D human reconstruction, considering the diverse and complex human motion.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Consequently, we design our reconstruction pipeline with careful reconsideration in the following three ways.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">First, we propose a new two-stream architecture named <span id="S1.p4.1.1" class="ltx_text ltx_font_bold">D</span>eep <span id="S1.p4.1.2" class="ltx_text ltx_font_bold">T</span>wo-<span id="S1.p4.1.3" class="ltx_text ltx_font_bold">S</span>tream <span id="S1.p4.1.4" class="ltx_text ltx_font_bold">V</span>ideo <span id="S1.p4.1.5" class="ltx_text ltx_font_bold">I</span>nference for Human <span id="S1.p4.1.6" class="ltx_text ltx_font_bold">B</span>ody Pose and Shape <span id="S1.p4.1.7" class="ltx_text ltx_font_bold">E</span>stimation (DTS-VIBE), which allows multi-modality fusion for 3D human reconstruction. With this new architecture, we can supplement other sensory modalities, including but not limited to depth, optical flow or other motion cues, to extend RGB feature space for better 3D human pose and shape estimation. To the best of our knowledge, this is the first time such multi-modal architecture is introduced into this area to simultaneously compensate motion instability and improve temporal consistency. This architecture is highly modularized and each of its component is interchangeable, so it can easily accommodate other modalities and their own optimal seq2seq encoder/decoder.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Second, we select optical flow among those candidate modalities to fit the above architecture. The optical flow has proven to be highly effective to understand human behaviourÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> because it can, intuitively, help the two-stream network to bridge each two adjacent frames by understanding the motion. It is worth noting that our optical flow input does not require actual physical sensor such as event camera, which causes extra cost on data collection, labelling and synchronization with RGB image. Instead, we estimate the optical flow from RGB image sequence as a virtual sensory modality to provide an applicable and inexpensive solution. In other words, optical flow is directly estimated from RGB images without any additional labels.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Third, to correlate video frames in a way that best serves the pose and shape estimation, we build our temporal encoder based on transformerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> instead of Gated Recurrent Units (GRU)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> which is used as the temporal network in the state-of-the-art method <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">VIBE</em>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Despite being widely applied on various temporal tasks, GRU has its shortcomings that the temporal information is inevitably lost during the recursion. For example, when human body is partially occluded in the leading frames of a sequence, GRU cannot effectively provide reliable temporal information to those frames because referring to prior frames are impossible. However, transformer can alleviate this situation by applying global multi-head attention, particularly to the latter frames that are highly correlated to those leading frames in this case, to better estimate shapes and poses. Similarly, when human body is occluded in the middle of a sequence, transformer can combine short-term and long-term attentions simultaneously to better infer and regularize the motion in the middle. To fully exploit the proposed transformer network, we introduce a new loss named <math id="S1.p6.1.m1.1" class="ltx_Math" alttext="L_{flow}" display="inline"><semantics id="S1.p6.1.m1.1a"><msub id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml"><mi id="S1.p6.1.m1.1.1.2" xref="S1.p6.1.m1.1.1.2.cmml">L</mi><mrow id="S1.p6.1.m1.1.1.3" xref="S1.p6.1.m1.1.1.3.cmml"><mi id="S1.p6.1.m1.1.1.3.2" xref="S1.p6.1.m1.1.1.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S1.p6.1.m1.1.1.3.1" xref="S1.p6.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S1.p6.1.m1.1.1.3.3" xref="S1.p6.1.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S1.p6.1.m1.1.1.3.1a" xref="S1.p6.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S1.p6.1.m1.1.1.3.4" xref="S1.p6.1.m1.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S1.p6.1.m1.1.1.3.1b" xref="S1.p6.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S1.p6.1.m1.1.1.3.5" xref="S1.p6.1.m1.1.1.3.5.cmml">w</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><apply id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p6.1.m1.1.1.1.cmml" xref="S1.p6.1.m1.1.1">subscript</csymbol><ci id="S1.p6.1.m1.1.1.2.cmml" xref="S1.p6.1.m1.1.1.2">ğ¿</ci><apply id="S1.p6.1.m1.1.1.3.cmml" xref="S1.p6.1.m1.1.1.3"><times id="S1.p6.1.m1.1.1.3.1.cmml" xref="S1.p6.1.m1.1.1.3.1"></times><ci id="S1.p6.1.m1.1.1.3.2.cmml" xref="S1.p6.1.m1.1.1.3.2">ğ‘“</ci><ci id="S1.p6.1.m1.1.1.3.3.cmml" xref="S1.p6.1.m1.1.1.3.3">ğ‘™</ci><ci id="S1.p6.1.m1.1.1.3.4.cmml" xref="S1.p6.1.m1.1.1.3.4">ğ‘œ</ci><ci id="S1.p6.1.m1.1.1.3.5.cmml" xref="S1.p6.1.m1.1.1.3.5">ğ‘¤</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">L_{flow}</annotation></semantics></math> which is inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. The loss is designed so that optical flow information is used to regularize the estimated pose by enforcing the trajectory of certain motion. We experimentally show that the combination of transformer network and flow loss significantly improves both accuracy and stability.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Overall, we employ dual convolutional neural networks (CNN) to extract two feature streams from RGB image/video sequence and its optical flows. The extracted image feature streams are fed into a transformer-based temporal encoder, and then combined with the corresponding optical flow streams by late fusion. The fused feature will be finally fed into a transformer-based regressorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Then, we followÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> to add a discriminator that tries to distinguish between the regressed body poses and samples from the AMASSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> dataset, which can provide a real/fake label for each sequence.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2110.11680/assets/x1.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="205" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Architecture of the DTS-VIBE<span id="S1.F2.4.2.1" class="ltx_text ltx_font_medium">. The sequence of images and its corresponding flow are sent to the CNN to extract features. The transformer encoder extract temporal features and adds it with the flow feature. A fully connected layer is used to predict coarse SMPL parameters, which is processed by transformer regressor, providing final SMPL parameters. The whole network is trained with a discriminator similar to VIBE.</span></span></figcaption>
</figure>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">To justify our solutions, we conduct extensive experiments on multiple datasets. The experimental results show that our proposed method surpasses all state-of-the-art video-based and single-image-based approaches. Overall, the contributions of this paper are:
</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">To our best knowledge, this is the first end-to-end two-stream architecture which allows multi-modality fusion for video 3D human reconstruction.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We introduce virtual optical flow which can supplement the corresponding motion information for the RGB domain to predict more accurate pose and shape.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We propose a transformer-based temporal network to establish more robust temporal correlations and a transformer-based SMPL regressor for better body shape parameterization.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We introduce a flow loss to regularize the predicted keypoints and reduce the acceleration error.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related works</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Single image-based human reconstruction</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Parametric human modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> are widely used in many prior studies. Pre-trained parametric models such as SMPLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, STARÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, SMPL-XÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> are able to recover a human mesh with a few coefficients. Bogo<em id="S2.SS1.p1.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS1.p1.1.2" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> propose SMPLify, which first uses CNN to detect the 2D keypoints from a given image, then fits SMPL model to the predicted keypoints. Because of the high cost of 3D human data collection and annotation, people tend to use projected 2D keypoints loss as the less ideal supervision. HMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> directly regresses SMPL parameters given an input image and projects 3D joints to 2D using the estimated camera parameters to match the ground truth 2D keypoints. It also proposes a discriminator network to distinguish the predicted and ground truth parameters, generating a more plausible mesh. Kolotouros<em id="S2.SS1.p1.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS1.p1.1.4" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> proposed SPIN that interatively fits the SMPL model to 2D joint and use the current estimation to supervise the network in the next iteration.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Meanwhile, some methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> also use intermediate output to help reconstruct human mesh. Pavlako<em id="S2.SS1.p2.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS1.p2.1.2" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> first generates 2D joint heatmap and mask, then combines them with input image to predict SMPL parameters. Pengfei<em id="S2.SS1.p2.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS1.p2.1.4" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> aligns 3D mesh to 2D image and use UV map to represent the 3D human mesh and uses encoder-decoder model to predict the UV map. Besides, there are plenty of other approaches which directly regress 3D human mesh from a given still imageÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Gyeongsik<em id="S2.SS1.p2.1.5" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS1.p2.1.6" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> proposed an Image-to-Lixel network that directly predict three 1D-heatmaps of xyz coordinates of the human mesh veitices. Varol<em id="S2.SS1.p2.1.7" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS1.p2.1.8" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> proposes BodyNet, which estimates voxels of human shape in the 3D volumetric space.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Video-based 3D human reconstruction</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Despite the progress of 3D human pose and shape estimation from single image, there are some video based methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> which take advantage of temporal information and subsequently achieve impressive outcomes. Hossain<em id="S2.SS2.p1.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS2.p1.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> propose a LSTM model to predict a squence of 3D joints from given 2D joints. Pavllo<em id="S2.SS2.p1.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS2.p1.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> use a fully-convolutional network to process a sequence of 2D joints to estimate its 3D location, and these predicted 3D joints are used to self-supervise the network on the original 2D joints. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> first predict 2D joints and SMPL parameters for each frame, then jointly optimize them to reduce the error. KanazawaÂ <em id="S2.SS2.p1.1.5" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.SS2.p1.1.6" class="ltx_text"></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> propose HMMR, which uses 1D CNN as temporal encoder to find features from sequence of images. It predicts 3D poses not only for the target frame but also past and future frames. Such strategy guarantees the smooth estimation. VIBEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> utilize GRU to encode features from single image into temporal feature and regress SMPL parameters. It also introduces a motion discriminator to guide the generator and encourage it to predict more reasonable poses when compared to the labels in auxiliary dataset. All of them prove to be great success, yet they still lack of temporal consistency in certain degree. In this regard, MEVAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> feed a sequence of human motion into an auto-encoder framework to first get coarse motion with VME, then refine it with MRR. Its network with encoder-decoder architecture learns the motion of human pose from AMASS<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, which helps to smooth pose estimation at inference.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Two Stream</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Two stream architecture is widely adopted in video action recognitionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. The feature obtained from optical flow is intuitively helpful when trying to learn the motion of people. Simonyan<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> propose to extract spatial feature from images and extract temporal feature from dense optimal flow. The two types of features are combined by late fusion and sent to the classification module. Meanwhile, optical flow is also used to help 3D reconstruction. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> combine flow and 2D keypoints to predict poses over the input video and achieve decent performance under occluded scenarios. Similarly, our approach leverages the optical flow to enhance the temporal feature.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Architecture</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe the deep two-stream video inference network for human body pose and shape estimation (DTS-VIBE). As summarized in FigureÂ <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the DTS-VIBE model consists of two-stream encoder, transformer-based regressor and motion discriminator.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Two-stream encoder</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The intuition behind using a two-stream encoder to process RGB and optical flow separately is that optical flow can provide additional sensory information of human motion. This is particularly useful for difficult occasions when human is severely occluded or the pose of human is irregular. Optical flow information can also help to maintain the smoothness of human prediction.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.7" class="ltx_p">Given a sequence of continuous RGB frames <math id="S3.SS1.p2.1.m1.3" class="ltx_Math" alttext="v_{1},...,v_{T}" display="inline"><semantics id="S3.SS1.p2.1.m1.3a"><mrow id="S3.SS1.p2.1.m1.3.3.2" xref="S3.SS1.p2.1.m1.3.3.3.cmml"><msub id="S3.SS1.p2.1.m1.2.2.1.1" xref="S3.SS1.p2.1.m1.2.2.1.1.cmml"><mi id="S3.SS1.p2.1.m1.2.2.1.1.2" xref="S3.SS1.p2.1.m1.2.2.1.1.2.cmml">v</mi><mn id="S3.SS1.p2.1.m1.2.2.1.1.3" xref="S3.SS1.p2.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.1.m1.3.3.2.3" xref="S3.SS1.p2.1.m1.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">â€¦</mi><mo id="S3.SS1.p2.1.m1.3.3.2.4" xref="S3.SS1.p2.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS1.p2.1.m1.3.3.2.2" xref="S3.SS1.p2.1.m1.3.3.2.2.cmml"><mi id="S3.SS1.p2.1.m1.3.3.2.2.2" xref="S3.SS1.p2.1.m1.3.3.2.2.2.cmml">v</mi><mi id="S3.SS1.p2.1.m1.3.3.2.2.3" xref="S3.SS1.p2.1.m1.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.3b"><list id="S3.SS1.p2.1.m1.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.2"><apply id="S3.SS1.p2.1.m1.2.2.1.1.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1.2">ğ‘£</ci><cn type="integer" id="S3.SS1.p2.1.m1.2.2.1.1.3.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">â€¦</ci><apply id="S3.SS1.p2.1.m1.3.3.2.2.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.3.3.2.2.1.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2.2">ğ‘£</ci><ci id="S3.SS1.p2.1.m1.3.3.2.2.3.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2.3">ğ‘‡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.3c">v_{1},...,v_{T}</annotation></semantics></math>, we first group every two consecutive video frames to obtain estimated optical flow <math id="S3.SS1.p2.2.m2.3" class="ltx_Math" alttext="o_{1},...,o_{T}" display="inline"><semantics id="S3.SS1.p2.2.m2.3a"><mrow id="S3.SS1.p2.2.m2.3.3.2" xref="S3.SS1.p2.2.m2.3.3.3.cmml"><msub id="S3.SS1.p2.2.m2.2.2.1.1" xref="S3.SS1.p2.2.m2.2.2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.2.2.1.1.2" xref="S3.SS1.p2.2.m2.2.2.1.1.2.cmml">o</mi><mn id="S3.SS1.p2.2.m2.2.2.1.1.3" xref="S3.SS1.p2.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.2.m2.3.3.2.3" xref="S3.SS1.p2.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">â€¦</mi><mo id="S3.SS1.p2.2.m2.3.3.2.4" xref="S3.SS1.p2.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS1.p2.2.m2.3.3.2.2" xref="S3.SS1.p2.2.m2.3.3.2.2.cmml"><mi id="S3.SS1.p2.2.m2.3.3.2.2.2" xref="S3.SS1.p2.2.m2.3.3.2.2.2.cmml">o</mi><mi id="S3.SS1.p2.2.m2.3.3.2.2.3" xref="S3.SS1.p2.2.m2.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.3b"><list id="S3.SS1.p2.2.m2.3.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2"><apply id="S3.SS1.p2.2.m2.2.2.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.2">ğ‘œ</ci><cn type="integer" id="S3.SS1.p2.2.m2.2.2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">â€¦</ci><apply id="S3.SS1.p2.2.m2.3.3.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.3.3.2.2.1.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2">ğ‘œ</ci><ci id="S3.SS1.p2.2.m2.3.3.2.2.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.3">ğ‘‡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.3c">o_{1},...,o_{T}</annotation></semantics></math> using an auto encoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. The RGB stream <math id="S3.SS1.p2.3.m3.3" class="ltx_Math" alttext="v_{1},...,v_{T}" display="inline"><semantics id="S3.SS1.p2.3.m3.3a"><mrow id="S3.SS1.p2.3.m3.3.3.2" xref="S3.SS1.p2.3.m3.3.3.3.cmml"><msub id="S3.SS1.p2.3.m3.2.2.1.1" xref="S3.SS1.p2.3.m3.2.2.1.1.cmml"><mi id="S3.SS1.p2.3.m3.2.2.1.1.2" xref="S3.SS1.p2.3.m3.2.2.1.1.2.cmml">v</mi><mn id="S3.SS1.p2.3.m3.2.2.1.1.3" xref="S3.SS1.p2.3.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.3.m3.3.3.2.3" xref="S3.SS1.p2.3.m3.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">â€¦</mi><mo id="S3.SS1.p2.3.m3.3.3.2.4" xref="S3.SS1.p2.3.m3.3.3.3.cmml">,</mo><msub id="S3.SS1.p2.3.m3.3.3.2.2" xref="S3.SS1.p2.3.m3.3.3.2.2.cmml"><mi id="S3.SS1.p2.3.m3.3.3.2.2.2" xref="S3.SS1.p2.3.m3.3.3.2.2.2.cmml">v</mi><mi id="S3.SS1.p2.3.m3.3.3.2.2.3" xref="S3.SS1.p2.3.m3.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.3b"><list id="S3.SS1.p2.3.m3.3.3.3.cmml" xref="S3.SS1.p2.3.m3.3.3.2"><apply id="S3.SS1.p2.3.m3.2.2.1.1.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.2.2.1.1.1.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.2.2.1.1.2.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1.2">ğ‘£</ci><cn type="integer" id="S3.SS1.p2.3.m3.2.2.1.1.3.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">â€¦</ci><apply id="S3.SS1.p2.3.m3.3.3.2.2.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.3.3.2.2.1.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.3.3.2.2.2.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2.2">ğ‘£</ci><ci id="S3.SS1.p2.3.m3.3.3.2.2.3.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2.3">ğ‘‡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.3c">v_{1},...,v_{T}</annotation></semantics></math> and optical-flow stream <math id="S3.SS1.p2.4.m4.3" class="ltx_Math" alttext="o_{1},...,o_{T}" display="inline"><semantics id="S3.SS1.p2.4.m4.3a"><mrow id="S3.SS1.p2.4.m4.3.3.2" xref="S3.SS1.p2.4.m4.3.3.3.cmml"><msub id="S3.SS1.p2.4.m4.2.2.1.1" xref="S3.SS1.p2.4.m4.2.2.1.1.cmml"><mi id="S3.SS1.p2.4.m4.2.2.1.1.2" xref="S3.SS1.p2.4.m4.2.2.1.1.2.cmml">o</mi><mn id="S3.SS1.p2.4.m4.2.2.1.1.3" xref="S3.SS1.p2.4.m4.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.4.m4.3.3.2.3" xref="S3.SS1.p2.4.m4.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">â€¦</mi><mo id="S3.SS1.p2.4.m4.3.3.2.4" xref="S3.SS1.p2.4.m4.3.3.3.cmml">,</mo><msub id="S3.SS1.p2.4.m4.3.3.2.2" xref="S3.SS1.p2.4.m4.3.3.2.2.cmml"><mi id="S3.SS1.p2.4.m4.3.3.2.2.2" xref="S3.SS1.p2.4.m4.3.3.2.2.2.cmml">o</mi><mi id="S3.SS1.p2.4.m4.3.3.2.2.3" xref="S3.SS1.p2.4.m4.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.3b"><list id="S3.SS1.p2.4.m4.3.3.3.cmml" xref="S3.SS1.p2.4.m4.3.3.2"><apply id="S3.SS1.p2.4.m4.2.2.1.1.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.2.2.1.1.1.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.2.2.1.1.2.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1.2">ğ‘œ</ci><cn type="integer" id="S3.SS1.p2.4.m4.2.2.1.1.3.cmml" xref="S3.SS1.p2.4.m4.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">â€¦</ci><apply id="S3.SS1.p2.4.m4.3.3.2.2.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.3.3.2.2.1.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.4.m4.3.3.2.2.2.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2.2">ğ‘œ</ci><ci id="S3.SS1.p2.4.m4.3.3.2.2.3.cmml" xref="S3.SS1.p2.4.m4.3.3.2.2.3">ğ‘‡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.3c">o_{1},...,o_{T}</annotation></semantics></math> are fed into a dual CNNs (V-CNN and O-CNN), which outputs two-stream feature vectors <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="f^{v}_{i}\in\mathbb{R}^{2048}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mrow id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><msubsup id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2.2.2" xref="S3.SS1.p2.5.m5.1.1.2.2.2.cmml">f</mi><mi id="S3.SS1.p2.5.m5.1.1.2.3" xref="S3.SS1.p2.5.m5.1.1.2.3.cmml">i</mi><mi id="S3.SS1.p2.5.m5.1.1.2.2.3" xref="S3.SS1.p2.5.m5.1.1.2.2.3.cmml">v</mi></msubsup><mo id="S3.SS1.p2.5.m5.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml"><mi id="S3.SS1.p2.5.m5.1.1.3.2" xref="S3.SS1.p2.5.m5.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.5.m5.1.1.3.3" xref="S3.SS1.p2.5.m5.1.1.3.3.cmml">2048</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><in id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1"></in><apply id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.2.1.cmml" xref="S3.SS1.p2.5.m5.1.1.2">subscript</csymbol><apply id="S3.SS1.p2.5.m5.1.1.2.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.2.2.1.cmml" xref="S3.SS1.p2.5.m5.1.1.2">superscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.2.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2.2.2">ğ‘“</ci><ci id="S3.SS1.p2.5.m5.1.1.2.2.3.cmml" xref="S3.SS1.p2.5.m5.1.1.2.2.3">ğ‘£</ci></apply><ci id="S3.SS1.p2.5.m5.1.1.2.3.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.3.1.cmml" xref="S3.SS1.p2.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.3.2.cmml" xref="S3.SS1.p2.5.m5.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.5.m5.1.1.3.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3.3">2048</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">f^{v}_{i}\in\mathbb{R}^{2048}</annotation></semantics></math> and <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="f^{o}_{i}\in\mathbb{R}^{2048}" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mrow id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><msubsup id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2.2.2" xref="S3.SS1.p2.6.m6.1.1.2.2.2.cmml">f</mi><mi id="S3.SS1.p2.6.m6.1.1.2.3" xref="S3.SS1.p2.6.m6.1.1.2.3.cmml">i</mi><mi id="S3.SS1.p2.6.m6.1.1.2.2.3" xref="S3.SS1.p2.6.m6.1.1.2.2.3.cmml">o</mi></msubsup><mo id="S3.SS1.p2.6.m6.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml"><mi id="S3.SS1.p2.6.m6.1.1.3.2" xref="S3.SS1.p2.6.m6.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.6.m6.1.1.3.3" xref="S3.SS1.p2.6.m6.1.1.3.3.cmml">2048</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><in id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1"></in><apply id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.2.1.cmml" xref="S3.SS1.p2.6.m6.1.1.2">subscript</csymbol><apply id="S3.SS1.p2.6.m6.1.1.2.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.2.2.1.cmml" xref="S3.SS1.p2.6.m6.1.1.2">superscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.2.2.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2.2.2">ğ‘“</ci><ci id="S3.SS1.p2.6.m6.1.1.2.2.3.cmml" xref="S3.SS1.p2.6.m6.1.1.2.2.3">ğ‘œ</ci></apply><ci id="S3.SS1.p2.6.m6.1.1.2.3.cmml" xref="S3.SS1.p2.6.m6.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.3.1.cmml" xref="S3.SS1.p2.6.m6.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.3.2.cmml" xref="S3.SS1.p2.6.m6.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.6.m6.1.1.3.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3.3">2048</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">f^{o}_{i}\in\mathbb{R}^{2048}</annotation></semantics></math>, <math id="S3.SS1.p2.7.m7.2" class="ltx_Math" alttext="i\in(1,T)" display="inline"><semantics id="S3.SS1.p2.7.m7.2a"><mrow id="S3.SS1.p2.7.m7.2.3" xref="S3.SS1.p2.7.m7.2.3.cmml"><mi id="S3.SS1.p2.7.m7.2.3.2" xref="S3.SS1.p2.7.m7.2.3.2.cmml">i</mi><mo id="S3.SS1.p2.7.m7.2.3.1" xref="S3.SS1.p2.7.m7.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.p2.7.m7.2.3.3.2" xref="S3.SS1.p2.7.m7.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.7.m7.2.3.3.2.1" xref="S3.SS1.p2.7.m7.2.3.3.1.cmml">(</mo><mn id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">1</mn><mo id="S3.SS1.p2.7.m7.2.3.3.2.2" xref="S3.SS1.p2.7.m7.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p2.7.m7.2.2" xref="S3.SS1.p2.7.m7.2.2.cmml">T</mi><mo stretchy="false" id="S3.SS1.p2.7.m7.2.3.3.2.3" xref="S3.SS1.p2.7.m7.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.2b"><apply id="S3.SS1.p2.7.m7.2.3.cmml" xref="S3.SS1.p2.7.m7.2.3"><in id="S3.SS1.p2.7.m7.2.3.1.cmml" xref="S3.SS1.p2.7.m7.2.3.1"></in><ci id="S3.SS1.p2.7.m7.2.3.2.cmml" xref="S3.SS1.p2.7.m7.2.3.2">ğ‘–</ci><interval closure="open" id="S3.SS1.p2.7.m7.2.3.3.1.cmml" xref="S3.SS1.p2.7.m7.2.3.3.2"><cn type="integer" id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">1</cn><ci id="S3.SS1.p2.7.m7.2.2.cmml" xref="S3.SS1.p2.7.m7.2.2">ğ‘‡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.2c">i\in(1,T)</annotation></semantics></math>. We adopt ResNet-50Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> as the backbone network of V-CNN and O-CNN, followed by the fully connected layers to reduce the dimensions from 2048 to 512. Instead of using Gated Recurrent Units (GRU), which demonstrates decent performance on video-based 3D human reconstructionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, our temporal network is instead built on transformerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Although GRU is widely applied in various temporal tasks, it shows disadvantages that the temporal information is inevitably lost during the recursion. Transformer can alleviate this situation, because it directly works on every feature simultaneously with global multihead attention.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.6" class="ltx_p">The sequence of RGB feature vectors <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="f^{v}_{i}\in\mathbb{R}^{512}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><msubsup id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2.2.2" xref="S3.SS1.p3.1.m1.1.1.2.2.2.cmml">f</mi><mi id="S3.SS1.p3.1.m1.1.1.2.3" xref="S3.SS1.p3.1.m1.1.1.2.3.cmml">i</mi><mi id="S3.SS1.p3.1.m1.1.1.2.2.3" xref="S3.SS1.p3.1.m1.1.1.2.2.3.cmml">v</mi></msubsup><mo id="S3.SS1.p3.1.m1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml"><mi id="S3.SS1.p3.1.m1.1.1.3.2" xref="S3.SS1.p3.1.m1.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p3.1.m1.1.1.3.3" xref="S3.SS1.p3.1.m1.1.1.3.3.cmml">512</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><in id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1"></in><apply id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.2.1.cmml" xref="S3.SS1.p3.1.m1.1.1.2">subscript</csymbol><apply id="S3.SS1.p3.1.m1.1.1.2.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.2.2.1.cmml" xref="S3.SS1.p3.1.m1.1.1.2">superscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.2.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2.2.2">ğ‘“</ci><ci id="S3.SS1.p3.1.m1.1.1.2.2.3.cmml" xref="S3.SS1.p3.1.m1.1.1.2.2.3">ğ‘£</ci></apply><ci id="S3.SS1.p3.1.m1.1.1.2.3.cmml" xref="S3.SS1.p3.1.m1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.3.1.cmml" xref="S3.SS1.p3.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.3.2.cmml" xref="S3.SS1.p3.1.m1.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p3.1.m1.1.1.3.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3.3">512</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">f^{v}_{i}\in\mathbb{R}^{512}</annotation></semantics></math> are fed into our transformerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>-based temporal encoder that yields latent RGB feature vectors <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="g^{v}_{i}\in\mathbb{R}^{512}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mrow id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><msubsup id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2.2.2" xref="S3.SS1.p3.2.m2.1.1.2.2.2.cmml">g</mi><mi id="S3.SS1.p3.2.m2.1.1.2.3" xref="S3.SS1.p3.2.m2.1.1.2.3.cmml">i</mi><mi id="S3.SS1.p3.2.m2.1.1.2.2.3" xref="S3.SS1.p3.2.m2.1.1.2.2.3.cmml">v</mi></msubsup><mo id="S3.SS1.p3.2.m2.1.1.1" xref="S3.SS1.p3.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml"><mi id="S3.SS1.p3.2.m2.1.1.3.2" xref="S3.SS1.p3.2.m2.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p3.2.m2.1.1.3.3" xref="S3.SS1.p3.2.m2.1.1.3.3.cmml">512</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><in id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1.1"></in><apply id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.2.1.cmml" xref="S3.SS1.p3.2.m2.1.1.2">subscript</csymbol><apply id="S3.SS1.p3.2.m2.1.1.2.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.2.2.1.cmml" xref="S3.SS1.p3.2.m2.1.1.2">superscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.2.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2.2.2">ğ‘”</ci><ci id="S3.SS1.p3.2.m2.1.1.2.2.3.cmml" xref="S3.SS1.p3.2.m2.1.1.2.2.3">ğ‘£</ci></apply><ci id="S3.SS1.p3.2.m2.1.1.2.3.cmml" xref="S3.SS1.p3.2.m2.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.3.1.cmml" xref="S3.SS1.p3.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.3.2.cmml" xref="S3.SS1.p3.2.m2.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p3.2.m2.1.1.3.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3">512</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">g^{v}_{i}\in\mathbb{R}^{512}</annotation></semantics></math>. Then the optical-flow feature vectors <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="f^{o}_{i}\in\mathbb{R}^{512}" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mrow id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><msubsup id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2.2.2" xref="S3.SS1.p3.3.m3.1.1.2.2.2.cmml">f</mi><mi id="S3.SS1.p3.3.m3.1.1.2.3" xref="S3.SS1.p3.3.m3.1.1.2.3.cmml">i</mi><mi id="S3.SS1.p3.3.m3.1.1.2.2.3" xref="S3.SS1.p3.3.m3.1.1.2.2.3.cmml">o</mi></msubsup><mo id="S3.SS1.p3.3.m3.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml"><mi id="S3.SS1.p3.3.m3.1.1.3.2" xref="S3.SS1.p3.3.m3.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p3.3.m3.1.1.3.3" xref="S3.SS1.p3.3.m3.1.1.3.3.cmml">512</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><in id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1"></in><apply id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.2.1.cmml" xref="S3.SS1.p3.3.m3.1.1.2">subscript</csymbol><apply id="S3.SS1.p3.3.m3.1.1.2.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.2.2.1.cmml" xref="S3.SS1.p3.3.m3.1.1.2">superscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.2.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2.2.2">ğ‘“</ci><ci id="S3.SS1.p3.3.m3.1.1.2.2.3.cmml" xref="S3.SS1.p3.3.m3.1.1.2.2.3">ğ‘œ</ci></apply><ci id="S3.SS1.p3.3.m3.1.1.2.3.cmml" xref="S3.SS1.p3.3.m3.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.3.1.cmml" xref="S3.SS1.p3.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.3.2.cmml" xref="S3.SS1.p3.3.m3.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p3.3.m3.1.1.3.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3">512</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">f^{o}_{i}\in\mathbb{R}^{512}</annotation></semantics></math> are added on <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="g^{v}_{i}" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><msubsup id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2.2" xref="S3.SS1.p3.4.m4.1.1.2.2.cmml">g</mi><mi id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml">i</mi><mi id="S3.SS1.p3.4.m4.1.1.2.3" xref="S3.SS1.p3.4.m4.1.1.2.3.cmml">v</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">subscript</csymbol><apply id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.2.1.cmml" xref="S3.SS1.p3.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.2.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2.2">ğ‘”</ci><ci id="S3.SS1.p3.4.m4.1.1.2.3.cmml" xref="S3.SS1.p3.4.m4.1.1.2.3">ğ‘£</ci></apply><ci id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">g^{v}_{i}</annotation></semantics></math> and sent to a transformer-based regressorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> to predict the per-frame SMPL parameters and corresponding camera parameters.
Our transformer-based temporal encoder consists of <math id="S3.SS1.p3.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p3.5.m5.1a"><mi id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><ci id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">N</annotation></semantics></math> layers, each of which contains two sub-layers: a multi-head attention layer and a feed forward layer. As shown in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3.1 Two-stream encoder â€£ 3 Architecture â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, given a sequence of input features <math id="S3.SS1.p3.6.m6.3" class="ltx_Math" alttext="x_{1},...,x_{T}" display="inline"><semantics id="S3.SS1.p3.6.m6.3a"><mrow id="S3.SS1.p3.6.m6.3.3.2" xref="S3.SS1.p3.6.m6.3.3.3.cmml"><msub id="S3.SS1.p3.6.m6.2.2.1.1" xref="S3.SS1.p3.6.m6.2.2.1.1.cmml"><mi id="S3.SS1.p3.6.m6.2.2.1.1.2" xref="S3.SS1.p3.6.m6.2.2.1.1.2.cmml">x</mi><mn id="S3.SS1.p3.6.m6.2.2.1.1.3" xref="S3.SS1.p3.6.m6.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p3.6.m6.3.3.2.3" xref="S3.SS1.p3.6.m6.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml">â€¦</mi><mo id="S3.SS1.p3.6.m6.3.3.2.4" xref="S3.SS1.p3.6.m6.3.3.3.cmml">,</mo><msub id="S3.SS1.p3.6.m6.3.3.2.2" xref="S3.SS1.p3.6.m6.3.3.2.2.cmml"><mi id="S3.SS1.p3.6.m6.3.3.2.2.2" xref="S3.SS1.p3.6.m6.3.3.2.2.2.cmml">x</mi><mi id="S3.SS1.p3.6.m6.3.3.2.2.3" xref="S3.SS1.p3.6.m6.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.3b"><list id="S3.SS1.p3.6.m6.3.3.3.cmml" xref="S3.SS1.p3.6.m6.3.3.2"><apply id="S3.SS1.p3.6.m6.2.2.1.1.cmml" xref="S3.SS1.p3.6.m6.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.6.m6.2.2.1.1.1.cmml" xref="S3.SS1.p3.6.m6.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p3.6.m6.2.2.1.1.2.cmml" xref="S3.SS1.p3.6.m6.2.2.1.1.2">ğ‘¥</ci><cn type="integer" id="S3.SS1.p3.6.m6.2.2.1.1.3.cmml" xref="S3.SS1.p3.6.m6.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">â€¦</ci><apply id="S3.SS1.p3.6.m6.3.3.2.2.cmml" xref="S3.SS1.p3.6.m6.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.6.m6.3.3.2.2.1.cmml" xref="S3.SS1.p3.6.m6.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p3.6.m6.3.3.2.2.2.cmml" xref="S3.SS1.p3.6.m6.3.3.2.2.2">ğ‘¥</ci><ci id="S3.SS1.p3.6.m6.3.3.2.2.3.cmml" xref="S3.SS1.p3.6.m6.3.3.2.2.3">ğ‘‡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.3c">x_{1},...,x_{T}</annotation></semantics></math>, the multi-head attention layer first gets the <span id="S3.SS1.p3.6.1" class="ltx_text ltx_font_italic">query</span> (Q), <span id="S3.SS1.p3.6.2" class="ltx_text ltx_font_italic">key</span>(K), and <span id="S3.SS1.p3.6.3" class="ltx_text ltx_font_italic">value</span>(V) by using fully connected layer:</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="Q=W^{Q}X,K=W^{K}X,V=W^{V}X" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.3.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">Q</mi><mo id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><msup id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml">W</mi><mi id="S3.E1.m1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.3.2.3.cmml">Q</mi></msup><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml">X</mi></mrow></mrow><mo id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.3a.cmml">,</mo><mrow id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.3.cmml"><mrow id="S3.E1.m1.2.2.2.2.1.1" xref="S3.E1.m1.2.2.2.2.1.1.cmml"><mi id="S3.E1.m1.2.2.2.2.1.1.2" xref="S3.E1.m1.2.2.2.2.1.1.2.cmml">K</mi><mo id="S3.E1.m1.2.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.2.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.2.2.2.2.1.1.3" xref="S3.E1.m1.2.2.2.2.1.1.3.cmml"><msup id="S3.E1.m1.2.2.2.2.1.1.3.2" xref="S3.E1.m1.2.2.2.2.1.1.3.2.cmml"><mi id="S3.E1.m1.2.2.2.2.1.1.3.2.2" xref="S3.E1.m1.2.2.2.2.1.1.3.2.2.cmml">W</mi><mi id="S3.E1.m1.2.2.2.2.1.1.3.2.3" xref="S3.E1.m1.2.2.2.2.1.1.3.2.3.cmml">K</mi></msup><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.1.1.3.1" xref="S3.E1.m1.2.2.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.1.1.3.3" xref="S3.E1.m1.2.2.2.2.1.1.3.3.cmml">X</mi></mrow></mrow><mo id="S3.E1.m1.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.3a.cmml">,</mo><mrow id="S3.E1.m1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.cmml">V</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml">=</mo><mrow id="S3.E1.m1.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.3.cmml"><msup id="S3.E1.m1.2.2.2.2.2.2.3.2" xref="S3.E1.m1.2.2.2.2.2.2.3.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.3.2.2" xref="S3.E1.m1.2.2.2.2.2.2.3.2.2.cmml">W</mi><mi id="S3.E1.m1.2.2.2.2.2.2.3.2.3" xref="S3.E1.m1.2.2.2.2.2.2.3.2.3.cmml">V</mi></msup><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.2.3.1" xref="S3.E1.m1.2.2.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.2.3.3" xref="S3.E1.m1.2.2.2.2.2.2.3.3.cmml">X</mi></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.3a.cmml" xref="S3.E1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></eq><ci id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2">ğ‘„</ci><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1"></times><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">ğ‘Š</ci><ci id="S3.E1.m1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3">ğ‘„</ci></apply><ci id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3">ğ‘‹</ci></apply></apply><apply id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.3a.cmml" xref="S3.E1.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.2.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1"><eq id="S3.E1.m1.2.2.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1"></eq><ci id="S3.E1.m1.2.2.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2">ğ¾</ci><apply id="S3.E1.m1.2.2.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.3"><times id="S3.E1.m1.2.2.2.2.1.1.3.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.3.1"></times><apply id="S3.E1.m1.2.2.2.2.1.1.3.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.3.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.3.2">superscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.1.3.2.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.3.2.2">ğ‘Š</ci><ci id="S3.E1.m1.2.2.2.2.1.1.3.2.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.3.2.3">ğ¾</ci></apply><ci id="S3.E1.m1.2.2.2.2.1.1.3.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.3.3">ğ‘‹</ci></apply></apply><apply id="S3.E1.m1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2"><eq id="S3.E1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1"></eq><ci id="S3.E1.m1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2">ğ‘‰</ci><apply id="S3.E1.m1.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3"><times id="S3.E1.m1.2.2.2.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3.1"></times><apply id="S3.E1.m1.2.2.2.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.3.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3.2">superscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.3.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3.2.2">ğ‘Š</ci><ci id="S3.E1.m1.2.2.2.2.2.2.3.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3.2.3">ğ‘‰</ci></apply><ci id="S3.E1.m1.2.2.2.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3.3">ğ‘‹</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">Q=W^{Q}X,K=W^{K}X,V=W^{V}X</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.3" class="ltx_p">Then the output is computed as</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\ a=softmax(\frac{QK^{T}}{\sqrt{d}})V," display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">a</mi><mo id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1" xref="S3.E2.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1a" xref="S3.E2.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.3.4" xref="S3.E2.m1.2.2.1.1.3.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1b" xref="S3.E2.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.3.5" xref="S3.E2.m1.2.2.1.1.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1c" xref="S3.E2.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.3.6" xref="S3.E2.m1.2.2.1.1.3.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1d" xref="S3.E2.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.3.7" xref="S3.E2.m1.2.2.1.1.3.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1e" xref="S3.E2.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.3.8" xref="S3.E2.m1.2.2.1.1.3.8.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1f" xref="S3.E2.m1.2.2.1.1.3.1.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.1.1.3.9.2" xref="S3.E2.m1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.3.9.2.1" xref="S3.E2.m1.1.1.cmml">(</mo><mfrac id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mrow id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.2.2" xref="S3.E2.m1.1.1.2.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.2.1" xref="S3.E2.m1.1.1.2.1.cmml">â€‹</mo><msup id="S3.E2.m1.1.1.2.3" xref="S3.E2.m1.1.1.2.3.cmml"><mi id="S3.E2.m1.1.1.2.3.2" xref="S3.E2.m1.1.1.2.3.2.cmml">K</mi><mi id="S3.E2.m1.1.1.2.3.3" xref="S3.E2.m1.1.1.2.3.3.cmml">T</mi></msup></mrow><msqrt id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml">d</mi></msqrt></mfrac><mo stretchy="false" id="S3.E2.m1.2.2.1.1.3.9.2.2" xref="S3.E2.m1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1g" xref="S3.E2.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.3.10" xref="S3.E2.m1.2.2.1.1.3.10.cmml">V</mi></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"></eq><ci id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2">ğ‘</ci><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><times id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.1"></times><ci id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2">ğ‘ </ci><ci id="S3.E2.m1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3">ğ‘œ</ci><ci id="S3.E2.m1.2.2.1.1.3.4.cmml" xref="S3.E2.m1.2.2.1.1.3.4">ğ‘“</ci><ci id="S3.E2.m1.2.2.1.1.3.5.cmml" xref="S3.E2.m1.2.2.1.1.3.5">ğ‘¡</ci><ci id="S3.E2.m1.2.2.1.1.3.6.cmml" xref="S3.E2.m1.2.2.1.1.3.6">ğ‘š</ci><ci id="S3.E2.m1.2.2.1.1.3.7.cmml" xref="S3.E2.m1.2.2.1.1.3.7">ğ‘</ci><ci id="S3.E2.m1.2.2.1.1.3.8.cmml" xref="S3.E2.m1.2.2.1.1.3.8">ğ‘¥</ci><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.3.9.2"><divide id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.3.9.2"></divide><apply id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"><times id="S3.E2.m1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.2.1"></times><ci id="S3.E2.m1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.2.2">ğ‘„</ci><apply id="S3.E2.m1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.2.3">superscript</csymbol><ci id="S3.E2.m1.1.1.2.3.2.cmml" xref="S3.E2.m1.1.1.2.3.2">ğ¾</ci><ci id="S3.E2.m1.1.1.2.3.3.cmml" xref="S3.E2.m1.1.1.2.3.3">ğ‘‡</ci></apply></apply><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><root id="S3.E2.m1.1.1.3a.cmml" xref="S3.E2.m1.1.1.3"></root><ci id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2">ğ‘‘</ci></apply></apply><ci id="S3.E2.m1.2.2.1.1.3.10.cmml" xref="S3.E2.m1.2.2.1.1.3.10">ğ‘‰</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\ a=softmax(\frac{QK^{T}}{\sqrt{d}})V,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p5.2" class="ltx_p">where <math id="S3.SS1.p5.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS1.p5.1.m1.1a"><mi id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">d</annotation></semantics></math> is the dimension of key. The feed forward layer consists of 2 fully connected layer and dropout.
The output of transformer is then added with the output of O-CNN, which contains the temporal information between each two frames, followed by a fully connected layer to reduce feature dimension from 512 to 157. The transformer regressor takes the low-dimension feature as input and outputs accurate SMPL parameters <math id="S3.SS1.p5.2.m2.3" class="ltx_Math" alttext="\hat{\Theta}_{1},...,\hat{\Theta}_{T}" display="inline"><semantics id="S3.SS1.p5.2.m2.3a"><mrow id="S3.SS1.p5.2.m2.3.3.2" xref="S3.SS1.p5.2.m2.3.3.3.cmml"><msub id="S3.SS1.p5.2.m2.2.2.1.1" xref="S3.SS1.p5.2.m2.2.2.1.1.cmml"><mover accent="true" id="S3.SS1.p5.2.m2.2.2.1.1.2" xref="S3.SS1.p5.2.m2.2.2.1.1.2.cmml"><mi mathvariant="normal" id="S3.SS1.p5.2.m2.2.2.1.1.2.2" xref="S3.SS1.p5.2.m2.2.2.1.1.2.2.cmml">Î˜</mi><mo id="S3.SS1.p5.2.m2.2.2.1.1.2.1" xref="S3.SS1.p5.2.m2.2.2.1.1.2.1.cmml">^</mo></mover><mn id="S3.SS1.p5.2.m2.2.2.1.1.3" xref="S3.SS1.p5.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p5.2.m2.3.3.2.3" xref="S3.SS1.p5.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml">â€¦</mi><mo id="S3.SS1.p5.2.m2.3.3.2.4" xref="S3.SS1.p5.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS1.p5.2.m2.3.3.2.2" xref="S3.SS1.p5.2.m2.3.3.2.2.cmml"><mover accent="true" id="S3.SS1.p5.2.m2.3.3.2.2.2" xref="S3.SS1.p5.2.m2.3.3.2.2.2.cmml"><mi mathvariant="normal" id="S3.SS1.p5.2.m2.3.3.2.2.2.2" xref="S3.SS1.p5.2.m2.3.3.2.2.2.2.cmml">Î˜</mi><mo id="S3.SS1.p5.2.m2.3.3.2.2.2.1" xref="S3.SS1.p5.2.m2.3.3.2.2.2.1.cmml">^</mo></mover><mi id="S3.SS1.p5.2.m2.3.3.2.2.3" xref="S3.SS1.p5.2.m2.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.3b"><list id="S3.SS1.p5.2.m2.3.3.3.cmml" xref="S3.SS1.p5.2.m2.3.3.2"><apply id="S3.SS1.p5.2.m2.2.2.1.1.cmml" xref="S3.SS1.p5.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p5.2.m2.2.2.1.1">subscript</csymbol><apply id="S3.SS1.p5.2.m2.2.2.1.1.2.cmml" xref="S3.SS1.p5.2.m2.2.2.1.1.2"><ci id="S3.SS1.p5.2.m2.2.2.1.1.2.1.cmml" xref="S3.SS1.p5.2.m2.2.2.1.1.2.1">^</ci><ci id="S3.SS1.p5.2.m2.2.2.1.1.2.2.cmml" xref="S3.SS1.p5.2.m2.2.2.1.1.2.2">Î˜</ci></apply><cn type="integer" id="S3.SS1.p5.2.m2.2.2.1.1.3.cmml" xref="S3.SS1.p5.2.m2.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1">â€¦</ci><apply id="S3.SS1.p5.2.m2.3.3.2.2.cmml" xref="S3.SS1.p5.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.3.3.2.2.1.cmml" xref="S3.SS1.p5.2.m2.3.3.2.2">subscript</csymbol><apply id="S3.SS1.p5.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p5.2.m2.3.3.2.2.2"><ci id="S3.SS1.p5.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS1.p5.2.m2.3.3.2.2.2.1">^</ci><ci id="S3.SS1.p5.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS1.p5.2.m2.3.3.2.2.2.2">Î˜</ci></apply><ci id="S3.SS1.p5.2.m2.3.3.2.2.3.cmml" xref="S3.SS1.p5.2.m2.3.3.2.2.3">ğ‘‡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.3c">\hat{\Theta}_{1},...,\hat{\Theta}_{T}</annotation></semantics></math>
The overall loss of our module is:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="L_{total}=\lambda_{1}L_{3D}+\lambda_{2}L_{2D}+\lambda_{3}L_{smpl}+\lambda_{4}L_{adv}" display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><msub id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml"><mi id="S3.E3.m1.1.1.2.2" xref="S3.E3.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E3.m1.1.1.2.3" xref="S3.E3.m1.1.1.2.3.cmml"><mi id="S3.E3.m1.1.1.2.3.2" xref="S3.E3.m1.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.2.3.1" xref="S3.E3.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.2.3.3" xref="S3.E3.m1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.2.3.1a" xref="S3.E3.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.2.3.4" xref="S3.E3.m1.1.1.2.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.2.3.1b" xref="S3.E3.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.2.3.5" xref="S3.E3.m1.1.1.2.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.2.3.1c" xref="S3.E3.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.2.3.6" xref="S3.E3.m1.1.1.2.3.6.cmml">l</mi></mrow></msub><mo id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml">=</mo><mrow id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml"><mrow id="S3.E3.m1.1.1.3.2" xref="S3.E3.m1.1.1.3.2.cmml"><msub id="S3.E3.m1.1.1.3.2.2" xref="S3.E3.m1.1.1.3.2.2.cmml"><mi id="S3.E3.m1.1.1.3.2.2.2" xref="S3.E3.m1.1.1.3.2.2.2.cmml">Î»</mi><mn id="S3.E3.m1.1.1.3.2.2.3" xref="S3.E3.m1.1.1.3.2.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.2.1" xref="S3.E3.m1.1.1.3.2.1.cmml">â€‹</mo><msub id="S3.E3.m1.1.1.3.2.3" xref="S3.E3.m1.1.1.3.2.3.cmml"><mi id="S3.E3.m1.1.1.3.2.3.2" xref="S3.E3.m1.1.1.3.2.3.2.cmml">L</mi><mrow id="S3.E3.m1.1.1.3.2.3.3" xref="S3.E3.m1.1.1.3.2.3.3.cmml"><mn id="S3.E3.m1.1.1.3.2.3.3.2" xref="S3.E3.m1.1.1.3.2.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.2.3.3.1" xref="S3.E3.m1.1.1.3.2.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.3.2.3.3.3" xref="S3.E3.m1.1.1.3.2.3.3.3.cmml">D</mi></mrow></msub></mrow><mo id="S3.E3.m1.1.1.3.1" xref="S3.E3.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E3.m1.1.1.3.3" xref="S3.E3.m1.1.1.3.3.cmml"><msub id="S3.E3.m1.1.1.3.3.2" xref="S3.E3.m1.1.1.3.3.2.cmml"><mi id="S3.E3.m1.1.1.3.3.2.2" xref="S3.E3.m1.1.1.3.3.2.2.cmml">Î»</mi><mn id="S3.E3.m1.1.1.3.3.2.3" xref="S3.E3.m1.1.1.3.3.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.3.1" xref="S3.E3.m1.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.E3.m1.1.1.3.3.3" xref="S3.E3.m1.1.1.3.3.3.cmml"><mi id="S3.E3.m1.1.1.3.3.3.2" xref="S3.E3.m1.1.1.3.3.3.2.cmml">L</mi><mrow id="S3.E3.m1.1.1.3.3.3.3" xref="S3.E3.m1.1.1.3.3.3.3.cmml"><mn id="S3.E3.m1.1.1.3.3.3.3.2" xref="S3.E3.m1.1.1.3.3.3.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.3.3.3.1" xref="S3.E3.m1.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.3.3.3.3.3" xref="S3.E3.m1.1.1.3.3.3.3.3.cmml">D</mi></mrow></msub></mrow><mo id="S3.E3.m1.1.1.3.1a" xref="S3.E3.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E3.m1.1.1.3.4" xref="S3.E3.m1.1.1.3.4.cmml"><msub id="S3.E3.m1.1.1.3.4.2" xref="S3.E3.m1.1.1.3.4.2.cmml"><mi id="S3.E3.m1.1.1.3.4.2.2" xref="S3.E3.m1.1.1.3.4.2.2.cmml">Î»</mi><mn id="S3.E3.m1.1.1.3.4.2.3" xref="S3.E3.m1.1.1.3.4.2.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.4.1" xref="S3.E3.m1.1.1.3.4.1.cmml">â€‹</mo><msub id="S3.E3.m1.1.1.3.4.3" xref="S3.E3.m1.1.1.3.4.3.cmml"><mi id="S3.E3.m1.1.1.3.4.3.2" xref="S3.E3.m1.1.1.3.4.3.2.cmml">L</mi><mrow id="S3.E3.m1.1.1.3.4.3.3" xref="S3.E3.m1.1.1.3.4.3.3.cmml"><mi id="S3.E3.m1.1.1.3.4.3.3.2" xref="S3.E3.m1.1.1.3.4.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.4.3.3.1" xref="S3.E3.m1.1.1.3.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.3.4.3.3.3" xref="S3.E3.m1.1.1.3.4.3.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.4.3.3.1a" xref="S3.E3.m1.1.1.3.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.3.4.3.3.4" xref="S3.E3.m1.1.1.3.4.3.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.4.3.3.1b" xref="S3.E3.m1.1.1.3.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.3.4.3.3.5" xref="S3.E3.m1.1.1.3.4.3.3.5.cmml">l</mi></mrow></msub></mrow><mo id="S3.E3.m1.1.1.3.1b" xref="S3.E3.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E3.m1.1.1.3.5" xref="S3.E3.m1.1.1.3.5.cmml"><msub id="S3.E3.m1.1.1.3.5.2" xref="S3.E3.m1.1.1.3.5.2.cmml"><mi id="S3.E3.m1.1.1.3.5.2.2" xref="S3.E3.m1.1.1.3.5.2.2.cmml">Î»</mi><mn id="S3.E3.m1.1.1.3.5.2.3" xref="S3.E3.m1.1.1.3.5.2.3.cmml">4</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.5.1" xref="S3.E3.m1.1.1.3.5.1.cmml">â€‹</mo><msub id="S3.E3.m1.1.1.3.5.3" xref="S3.E3.m1.1.1.3.5.3.cmml"><mi id="S3.E3.m1.1.1.3.5.3.2" xref="S3.E3.m1.1.1.3.5.3.2.cmml">L</mi><mrow id="S3.E3.m1.1.1.3.5.3.3" xref="S3.E3.m1.1.1.3.5.3.3.cmml"><mi id="S3.E3.m1.1.1.3.5.3.3.2" xref="S3.E3.m1.1.1.3.5.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.5.3.3.1" xref="S3.E3.m1.1.1.3.5.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.3.5.3.3.3" xref="S3.E3.m1.1.1.3.5.3.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.3.5.3.3.1a" xref="S3.E3.m1.1.1.3.5.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.3.5.3.3.4" xref="S3.E3.m1.1.1.3.5.3.3.4.cmml">v</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><eq id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"></eq><apply id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.2.2">ğ¿</ci><apply id="S3.E3.m1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.2.3"><times id="S3.E3.m1.1.1.2.3.1.cmml" xref="S3.E3.m1.1.1.2.3.1"></times><ci id="S3.E3.m1.1.1.2.3.2.cmml" xref="S3.E3.m1.1.1.2.3.2">ğ‘¡</ci><ci id="S3.E3.m1.1.1.2.3.3.cmml" xref="S3.E3.m1.1.1.2.3.3">ğ‘œ</ci><ci id="S3.E3.m1.1.1.2.3.4.cmml" xref="S3.E3.m1.1.1.2.3.4">ğ‘¡</ci><ci id="S3.E3.m1.1.1.2.3.5.cmml" xref="S3.E3.m1.1.1.2.3.5">ğ‘</ci><ci id="S3.E3.m1.1.1.2.3.6.cmml" xref="S3.E3.m1.1.1.2.3.6">ğ‘™</ci></apply></apply><apply id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3"><plus id="S3.E3.m1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.3.1"></plus><apply id="S3.E3.m1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.3.2"><times id="S3.E3.m1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.3.2.1"></times><apply id="S3.E3.m1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.2.2.1.cmml" xref="S3.E3.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E3.m1.1.1.3.2.2.2.cmml" xref="S3.E3.m1.1.1.3.2.2.2">ğœ†</ci><cn type="integer" id="S3.E3.m1.1.1.3.2.2.3.cmml" xref="S3.E3.m1.1.1.3.2.2.3">1</cn></apply><apply id="S3.E3.m1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.2.3.1.cmml" xref="S3.E3.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E3.m1.1.1.3.2.3.2.cmml" xref="S3.E3.m1.1.1.3.2.3.2">ğ¿</ci><apply id="S3.E3.m1.1.1.3.2.3.3.cmml" xref="S3.E3.m1.1.1.3.2.3.3"><times id="S3.E3.m1.1.1.3.2.3.3.1.cmml" xref="S3.E3.m1.1.1.3.2.3.3.1"></times><cn type="integer" id="S3.E3.m1.1.1.3.2.3.3.2.cmml" xref="S3.E3.m1.1.1.3.2.3.3.2">3</cn><ci id="S3.E3.m1.1.1.3.2.3.3.3.cmml" xref="S3.E3.m1.1.1.3.2.3.3.3">ğ·</ci></apply></apply></apply><apply id="S3.E3.m1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.3.3"><times id="S3.E3.m1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.3.3.1"></times><apply id="S3.E3.m1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.3.2.1.cmml" xref="S3.E3.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.3.3.2.2.cmml" xref="S3.E3.m1.1.1.3.3.2.2">ğœ†</ci><cn type="integer" id="S3.E3.m1.1.1.3.3.2.3.cmml" xref="S3.E3.m1.1.1.3.3.2.3">2</cn></apply><apply id="S3.E3.m1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.3.3.1.cmml" xref="S3.E3.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E3.m1.1.1.3.3.3.2.cmml" xref="S3.E3.m1.1.1.3.3.3.2">ğ¿</ci><apply id="S3.E3.m1.1.1.3.3.3.3.cmml" xref="S3.E3.m1.1.1.3.3.3.3"><times id="S3.E3.m1.1.1.3.3.3.3.1.cmml" xref="S3.E3.m1.1.1.3.3.3.3.1"></times><cn type="integer" id="S3.E3.m1.1.1.3.3.3.3.2.cmml" xref="S3.E3.m1.1.1.3.3.3.3.2">2</cn><ci id="S3.E3.m1.1.1.3.3.3.3.3.cmml" xref="S3.E3.m1.1.1.3.3.3.3.3">ğ·</ci></apply></apply></apply><apply id="S3.E3.m1.1.1.3.4.cmml" xref="S3.E3.m1.1.1.3.4"><times id="S3.E3.m1.1.1.3.4.1.cmml" xref="S3.E3.m1.1.1.3.4.1"></times><apply id="S3.E3.m1.1.1.3.4.2.cmml" xref="S3.E3.m1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.4.2.1.cmml" xref="S3.E3.m1.1.1.3.4.2">subscript</csymbol><ci id="S3.E3.m1.1.1.3.4.2.2.cmml" xref="S3.E3.m1.1.1.3.4.2.2">ğœ†</ci><cn type="integer" id="S3.E3.m1.1.1.3.4.2.3.cmml" xref="S3.E3.m1.1.1.3.4.2.3">3</cn></apply><apply id="S3.E3.m1.1.1.3.4.3.cmml" xref="S3.E3.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.4.3.1.cmml" xref="S3.E3.m1.1.1.3.4.3">subscript</csymbol><ci id="S3.E3.m1.1.1.3.4.3.2.cmml" xref="S3.E3.m1.1.1.3.4.3.2">ğ¿</ci><apply id="S3.E3.m1.1.1.3.4.3.3.cmml" xref="S3.E3.m1.1.1.3.4.3.3"><times id="S3.E3.m1.1.1.3.4.3.3.1.cmml" xref="S3.E3.m1.1.1.3.4.3.3.1"></times><ci id="S3.E3.m1.1.1.3.4.3.3.2.cmml" xref="S3.E3.m1.1.1.3.4.3.3.2">ğ‘ </ci><ci id="S3.E3.m1.1.1.3.4.3.3.3.cmml" xref="S3.E3.m1.1.1.3.4.3.3.3">ğ‘š</ci><ci id="S3.E3.m1.1.1.3.4.3.3.4.cmml" xref="S3.E3.m1.1.1.3.4.3.3.4">ğ‘</ci><ci id="S3.E3.m1.1.1.3.4.3.3.5.cmml" xref="S3.E3.m1.1.1.3.4.3.3.5">ğ‘™</ci></apply></apply></apply><apply id="S3.E3.m1.1.1.3.5.cmml" xref="S3.E3.m1.1.1.3.5"><times id="S3.E3.m1.1.1.3.5.1.cmml" xref="S3.E3.m1.1.1.3.5.1"></times><apply id="S3.E3.m1.1.1.3.5.2.cmml" xref="S3.E3.m1.1.1.3.5.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.5.2.1.cmml" xref="S3.E3.m1.1.1.3.5.2">subscript</csymbol><ci id="S3.E3.m1.1.1.3.5.2.2.cmml" xref="S3.E3.m1.1.1.3.5.2.2">ğœ†</ci><cn type="integer" id="S3.E3.m1.1.1.3.5.2.3.cmml" xref="S3.E3.m1.1.1.3.5.2.3">4</cn></apply><apply id="S3.E3.m1.1.1.3.5.3.cmml" xref="S3.E3.m1.1.1.3.5.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.5.3.1.cmml" xref="S3.E3.m1.1.1.3.5.3">subscript</csymbol><ci id="S3.E3.m1.1.1.3.5.3.2.cmml" xref="S3.E3.m1.1.1.3.5.3.2">ğ¿</ci><apply id="S3.E3.m1.1.1.3.5.3.3.cmml" xref="S3.E3.m1.1.1.3.5.3.3"><times id="S3.E3.m1.1.1.3.5.3.3.1.cmml" xref="S3.E3.m1.1.1.3.5.3.3.1"></times><ci id="S3.E3.m1.1.1.3.5.3.3.2.cmml" xref="S3.E3.m1.1.1.3.5.3.3.2">ğ‘</ci><ci id="S3.E3.m1.1.1.3.5.3.3.3.cmml" xref="S3.E3.m1.1.1.3.5.3.3.3">ğ‘‘</ci><ci id="S3.E3.m1.1.1.3.5.3.3.4.cmml" xref="S3.E3.m1.1.1.3.5.3.3.4">ğ‘£</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">L_{total}=\lambda_{1}L_{3D}+\lambda_{2}L_{2D}+\lambda_{3}L_{smpl}+\lambda_{4}L_{adv}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2110.11680/assets/x2.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="184" height="495" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Architecture of Transformer.<span id="S3.F3.4.2.1" class="ltx_text ltx_font_medium"> Our temporal encoder use the same transformer structure but with different number of layers or heads.</span></span></figcaption>
</figure>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.8" class="ltx_p">where <math id="S3.SS1.p6.1.m1.1" class="ltx_Math" alttext="\lambda_{1}" display="inline"><semantics id="S3.SS1.p6.1.m1.1a"><msub id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml"><mi id="S3.SS1.p6.1.m1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.2.cmml">Î»</mi><mn id="S3.SS1.p6.1.m1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">\lambda_{1}</annotation></semantics></math>,<math id="S3.SS1.p6.2.m2.1" class="ltx_Math" alttext="\lambda_{2}" display="inline"><semantics id="S3.SS1.p6.2.m2.1a"><msub id="S3.SS1.p6.2.m2.1.1" xref="S3.SS1.p6.2.m2.1.1.cmml"><mi id="S3.SS1.p6.2.m2.1.1.2" xref="S3.SS1.p6.2.m2.1.1.2.cmml">Î»</mi><mn id="S3.SS1.p6.2.m2.1.1.3" xref="S3.SS1.p6.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m2.1b"><apply id="S3.SS1.p6.2.m2.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.1.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p6.2.m2.1.1.2.cmml" xref="S3.SS1.p6.2.m2.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS1.p6.2.m2.1.1.3.cmml" xref="S3.SS1.p6.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.2.m2.1c">\lambda_{2}</annotation></semantics></math>,<math id="S3.SS1.p6.3.m3.1" class="ltx_Math" alttext="\lambda_{3}" display="inline"><semantics id="S3.SS1.p6.3.m3.1a"><msub id="S3.SS1.p6.3.m3.1.1" xref="S3.SS1.p6.3.m3.1.1.cmml"><mi id="S3.SS1.p6.3.m3.1.1.2" xref="S3.SS1.p6.3.m3.1.1.2.cmml">Î»</mi><mn id="S3.SS1.p6.3.m3.1.1.3" xref="S3.SS1.p6.3.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.3.m3.1b"><apply id="S3.SS1.p6.3.m3.1.1.cmml" xref="S3.SS1.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.3.m3.1.1.1.cmml" xref="S3.SS1.p6.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p6.3.m3.1.1.2.cmml" xref="S3.SS1.p6.3.m3.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS1.p6.3.m3.1.1.3.cmml" xref="S3.SS1.p6.3.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.3.m3.1c">\lambda_{3}</annotation></semantics></math>,<math id="S3.SS1.p6.4.m4.1" class="ltx_Math" alttext="\lambda_{4}" display="inline"><semantics id="S3.SS1.p6.4.m4.1a"><msub id="S3.SS1.p6.4.m4.1.1" xref="S3.SS1.p6.4.m4.1.1.cmml"><mi id="S3.SS1.p6.4.m4.1.1.2" xref="S3.SS1.p6.4.m4.1.1.2.cmml">Î»</mi><mn id="S3.SS1.p6.4.m4.1.1.3" xref="S3.SS1.p6.4.m4.1.1.3.cmml">4</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.4.m4.1b"><apply id="S3.SS1.p6.4.m4.1.1.cmml" xref="S3.SS1.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.4.m4.1.1.1.cmml" xref="S3.SS1.p6.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p6.4.m4.1.1.2.cmml" xref="S3.SS1.p6.4.m4.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS1.p6.4.m4.1.1.3.cmml" xref="S3.SS1.p6.4.m4.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.4.m4.1c">\lambda_{4}</annotation></semantics></math> are weighted coefficients for each loss.
Specifically, <math id="S3.SS1.p6.5.m5.1" class="ltx_Math" alttext="L_{3D}" display="inline"><semantics id="S3.SS1.p6.5.m5.1a"><msub id="S3.SS1.p6.5.m5.1.1" xref="S3.SS1.p6.5.m5.1.1.cmml"><mi id="S3.SS1.p6.5.m5.1.1.2" xref="S3.SS1.p6.5.m5.1.1.2.cmml">L</mi><mrow id="S3.SS1.p6.5.m5.1.1.3" xref="S3.SS1.p6.5.m5.1.1.3.cmml"><mn id="S3.SS1.p6.5.m5.1.1.3.2" xref="S3.SS1.p6.5.m5.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p6.5.m5.1.1.3.1" xref="S3.SS1.p6.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p6.5.m5.1.1.3.3" xref="S3.SS1.p6.5.m5.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.5.m5.1b"><apply id="S3.SS1.p6.5.m5.1.1.cmml" xref="S3.SS1.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.5.m5.1.1.1.cmml" xref="S3.SS1.p6.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p6.5.m5.1.1.2.cmml" xref="S3.SS1.p6.5.m5.1.1.2">ğ¿</ci><apply id="S3.SS1.p6.5.m5.1.1.3.cmml" xref="S3.SS1.p6.5.m5.1.1.3"><times id="S3.SS1.p6.5.m5.1.1.3.1.cmml" xref="S3.SS1.p6.5.m5.1.1.3.1"></times><cn type="integer" id="S3.SS1.p6.5.m5.1.1.3.2.cmml" xref="S3.SS1.p6.5.m5.1.1.3.2">3</cn><ci id="S3.SS1.p6.5.m5.1.1.3.3.cmml" xref="S3.SS1.p6.5.m5.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.5.m5.1c">L_{3D}</annotation></semantics></math> is the <math id="S3.SS1.p6.6.m6.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S3.SS1.p6.6.m6.1a"><msub id="S3.SS1.p6.6.m6.1.1" xref="S3.SS1.p6.6.m6.1.1.cmml"><mi id="S3.SS1.p6.6.m6.1.1.2" xref="S3.SS1.p6.6.m6.1.1.2.cmml">L</mi><mn id="S3.SS1.p6.6.m6.1.1.3" xref="S3.SS1.p6.6.m6.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.6.m6.1b"><apply id="S3.SS1.p6.6.m6.1.1.cmml" xref="S3.SS1.p6.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.6.m6.1.1.1.cmml" xref="S3.SS1.p6.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p6.6.m6.1.1.2.cmml" xref="S3.SS1.p6.6.m6.1.1.2">ğ¿</ci><cn type="integer" id="S3.SS1.p6.6.m6.1.1.3.cmml" xref="S3.SS1.p6.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.6.m6.1c">L_{2}</annotation></semantics></math> distance between ground truth 3D joints location <math id="S3.SS1.p6.7.m7.2" class="ltx_Math" alttext="X_{i,3D}" display="inline"><semantics id="S3.SS1.p6.7.m7.2a"><msub id="S3.SS1.p6.7.m7.2.3" xref="S3.SS1.p6.7.m7.2.3.cmml"><mi id="S3.SS1.p6.7.m7.2.3.2" xref="S3.SS1.p6.7.m7.2.3.2.cmml">X</mi><mrow id="S3.SS1.p6.7.m7.2.2.2.2" xref="S3.SS1.p6.7.m7.2.2.2.3.cmml"><mi id="S3.SS1.p6.7.m7.1.1.1.1" xref="S3.SS1.p6.7.m7.1.1.1.1.cmml">i</mi><mo id="S3.SS1.p6.7.m7.2.2.2.2.2" xref="S3.SS1.p6.7.m7.2.2.2.3.cmml">,</mo><mrow id="S3.SS1.p6.7.m7.2.2.2.2.1" xref="S3.SS1.p6.7.m7.2.2.2.2.1.cmml"><mn id="S3.SS1.p6.7.m7.2.2.2.2.1.2" xref="S3.SS1.p6.7.m7.2.2.2.2.1.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p6.7.m7.2.2.2.2.1.1" xref="S3.SS1.p6.7.m7.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.SS1.p6.7.m7.2.2.2.2.1.3" xref="S3.SS1.p6.7.m7.2.2.2.2.1.3.cmml">D</mi></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.7.m7.2b"><apply id="S3.SS1.p6.7.m7.2.3.cmml" xref="S3.SS1.p6.7.m7.2.3"><csymbol cd="ambiguous" id="S3.SS1.p6.7.m7.2.3.1.cmml" xref="S3.SS1.p6.7.m7.2.3">subscript</csymbol><ci id="S3.SS1.p6.7.m7.2.3.2.cmml" xref="S3.SS1.p6.7.m7.2.3.2">ğ‘‹</ci><list id="S3.SS1.p6.7.m7.2.2.2.3.cmml" xref="S3.SS1.p6.7.m7.2.2.2.2"><ci id="S3.SS1.p6.7.m7.1.1.1.1.cmml" xref="S3.SS1.p6.7.m7.1.1.1.1">ğ‘–</ci><apply id="S3.SS1.p6.7.m7.2.2.2.2.1.cmml" xref="S3.SS1.p6.7.m7.2.2.2.2.1"><times id="S3.SS1.p6.7.m7.2.2.2.2.1.1.cmml" xref="S3.SS1.p6.7.m7.2.2.2.2.1.1"></times><cn type="integer" id="S3.SS1.p6.7.m7.2.2.2.2.1.2.cmml" xref="S3.SS1.p6.7.m7.2.2.2.2.1.2">3</cn><ci id="S3.SS1.p6.7.m7.2.2.2.2.1.3.cmml" xref="S3.SS1.p6.7.m7.2.2.2.2.1.3">ğ·</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.7.m7.2c">X_{i,3D}</annotation></semantics></math> and 3D joints location <math id="S3.SS1.p6.8.m8.2" class="ltx_Math" alttext="\hat{X}_{i,3D}" display="inline"><semantics id="S3.SS1.p6.8.m8.2a"><msub id="S3.SS1.p6.8.m8.2.3" xref="S3.SS1.p6.8.m8.2.3.cmml"><mover accent="true" id="S3.SS1.p6.8.m8.2.3.2" xref="S3.SS1.p6.8.m8.2.3.2.cmml"><mi id="S3.SS1.p6.8.m8.2.3.2.2" xref="S3.SS1.p6.8.m8.2.3.2.2.cmml">X</mi><mo id="S3.SS1.p6.8.m8.2.3.2.1" xref="S3.SS1.p6.8.m8.2.3.2.1.cmml">^</mo></mover><mrow id="S3.SS1.p6.8.m8.2.2.2.2" xref="S3.SS1.p6.8.m8.2.2.2.3.cmml"><mi id="S3.SS1.p6.8.m8.1.1.1.1" xref="S3.SS1.p6.8.m8.1.1.1.1.cmml">i</mi><mo id="S3.SS1.p6.8.m8.2.2.2.2.2" xref="S3.SS1.p6.8.m8.2.2.2.3.cmml">,</mo><mrow id="S3.SS1.p6.8.m8.2.2.2.2.1" xref="S3.SS1.p6.8.m8.2.2.2.2.1.cmml"><mn id="S3.SS1.p6.8.m8.2.2.2.2.1.2" xref="S3.SS1.p6.8.m8.2.2.2.2.1.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p6.8.m8.2.2.2.2.1.1" xref="S3.SS1.p6.8.m8.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.SS1.p6.8.m8.2.2.2.2.1.3" xref="S3.SS1.p6.8.m8.2.2.2.2.1.3.cmml">D</mi></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.8.m8.2b"><apply id="S3.SS1.p6.8.m8.2.3.cmml" xref="S3.SS1.p6.8.m8.2.3"><csymbol cd="ambiguous" id="S3.SS1.p6.8.m8.2.3.1.cmml" xref="S3.SS1.p6.8.m8.2.3">subscript</csymbol><apply id="S3.SS1.p6.8.m8.2.3.2.cmml" xref="S3.SS1.p6.8.m8.2.3.2"><ci id="S3.SS1.p6.8.m8.2.3.2.1.cmml" xref="S3.SS1.p6.8.m8.2.3.2.1">^</ci><ci id="S3.SS1.p6.8.m8.2.3.2.2.cmml" xref="S3.SS1.p6.8.m8.2.3.2.2">ğ‘‹</ci></apply><list id="S3.SS1.p6.8.m8.2.2.2.3.cmml" xref="S3.SS1.p6.8.m8.2.2.2.2"><ci id="S3.SS1.p6.8.m8.1.1.1.1.cmml" xref="S3.SS1.p6.8.m8.1.1.1.1">ğ‘–</ci><apply id="S3.SS1.p6.8.m8.2.2.2.2.1.cmml" xref="S3.SS1.p6.8.m8.2.2.2.2.1"><times id="S3.SS1.p6.8.m8.2.2.2.2.1.1.cmml" xref="S3.SS1.p6.8.m8.2.2.2.2.1.1"></times><cn type="integer" id="S3.SS1.p6.8.m8.2.2.2.2.1.2.cmml" xref="S3.SS1.p6.8.m8.2.2.2.2.1.2">3</cn><ci id="S3.SS1.p6.8.m8.2.2.2.2.1.3.cmml" xref="S3.SS1.p6.8.m8.2.2.2.2.1.3">ğ·</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.8.m8.2c">\hat{X}_{i,3D}</annotation></semantics></math> from predicted SMPL model:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.5" class="ltx_Math" alttext="\ L_{3D}=\sum_{i=1}^{T}||X_{i,3D}-\hat{X}_{i,3D}||_{2}^{2}" display="block"><semantics id="S3.E4.m1.5a"><mrow id="S3.E4.m1.5.5" xref="S3.E4.m1.5.5.cmml"><msub id="S3.E4.m1.5.5.3" xref="S3.E4.m1.5.5.3.cmml"><mi id="S3.E4.m1.5.5.3.2" xref="S3.E4.m1.5.5.3.2.cmml">L</mi><mrow id="S3.E4.m1.5.5.3.3" xref="S3.E4.m1.5.5.3.3.cmml"><mn id="S3.E4.m1.5.5.3.3.2" xref="S3.E4.m1.5.5.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E4.m1.5.5.3.3.1" xref="S3.E4.m1.5.5.3.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.5.5.3.3.3" xref="S3.E4.m1.5.5.3.3.3.cmml">D</mi></mrow></msub><mo rspace="0.111em" id="S3.E4.m1.5.5.2" xref="S3.E4.m1.5.5.2.cmml">=</mo><mrow id="S3.E4.m1.5.5.1" xref="S3.E4.m1.5.5.1.cmml"><munderover id="S3.E4.m1.5.5.1.2" xref="S3.E4.m1.5.5.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E4.m1.5.5.1.2.2.2" xref="S3.E4.m1.5.5.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E4.m1.5.5.1.2.2.3" xref="S3.E4.m1.5.5.1.2.2.3.cmml"><mi id="S3.E4.m1.5.5.1.2.2.3.2" xref="S3.E4.m1.5.5.1.2.2.3.2.cmml">i</mi><mo id="S3.E4.m1.5.5.1.2.2.3.1" xref="S3.E4.m1.5.5.1.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.5.5.1.2.2.3.3" xref="S3.E4.m1.5.5.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.5.5.1.2.3" xref="S3.E4.m1.5.5.1.2.3.cmml">T</mi></munderover><msubsup id="S3.E4.m1.5.5.1.1" xref="S3.E4.m1.5.5.1.1.cmml"><mrow id="S3.E4.m1.5.5.1.1.1.1.1" xref="S3.E4.m1.5.5.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.5.5.1.1.1.1.1.2" xref="S3.E4.m1.5.5.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E4.m1.5.5.1.1.1.1.1.1" xref="S3.E4.m1.5.5.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.5.5.1.1.1.1.1.1.2" xref="S3.E4.m1.5.5.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.5.5.1.1.1.1.1.1.2.2" xref="S3.E4.m1.5.5.1.1.1.1.1.1.2.2.cmml">X</mi><mrow id="S3.E4.m1.2.2.2.2" xref="S3.E4.m1.2.2.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml">i</mi><mo id="S3.E4.m1.2.2.2.2.2" xref="S3.E4.m1.2.2.2.3.cmml">,</mo><mrow id="S3.E4.m1.2.2.2.2.1" xref="S3.E4.m1.2.2.2.2.1.cmml"><mn id="S3.E4.m1.2.2.2.2.1.2" xref="S3.E4.m1.2.2.2.2.1.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.2.1.1" xref="S3.E4.m1.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.E4.m1.2.2.2.2.1.3" xref="S3.E4.m1.2.2.2.2.1.3.cmml">D</mi></mrow></mrow></msub><mo id="S3.E4.m1.5.5.1.1.1.1.1.1.1" xref="S3.E4.m1.5.5.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E4.m1.5.5.1.1.1.1.1.1.3" xref="S3.E4.m1.5.5.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E4.m1.5.5.1.1.1.1.1.1.3.2" xref="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.2" xref="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.2.cmml">X</mi><mo id="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.1" xref="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mrow id="S3.E4.m1.4.4.2.2" xref="S3.E4.m1.4.4.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml">i</mi><mo id="S3.E4.m1.4.4.2.2.2" xref="S3.E4.m1.4.4.2.3.cmml">,</mo><mrow id="S3.E4.m1.4.4.2.2.1" xref="S3.E4.m1.4.4.2.2.1.cmml"><mn id="S3.E4.m1.4.4.2.2.1.2" xref="S3.E4.m1.4.4.2.2.1.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.2.2.1.1" xref="S3.E4.m1.4.4.2.2.1.1.cmml">â€‹</mo><mi id="S3.E4.m1.4.4.2.2.1.3" xref="S3.E4.m1.4.4.2.2.1.3.cmml">D</mi></mrow></mrow></msub></mrow><mo stretchy="false" id="S3.E4.m1.5.5.1.1.1.1.1.3" xref="S3.E4.m1.5.5.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E4.m1.5.5.1.1.1.3" xref="S3.E4.m1.5.5.1.1.1.3.cmml">2</mn><mn id="S3.E4.m1.5.5.1.1.3" xref="S3.E4.m1.5.5.1.1.3.cmml">2</mn></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.5b"><apply id="S3.E4.m1.5.5.cmml" xref="S3.E4.m1.5.5"><eq id="S3.E4.m1.5.5.2.cmml" xref="S3.E4.m1.5.5.2"></eq><apply id="S3.E4.m1.5.5.3.cmml" xref="S3.E4.m1.5.5.3"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.3.1.cmml" xref="S3.E4.m1.5.5.3">subscript</csymbol><ci id="S3.E4.m1.5.5.3.2.cmml" xref="S3.E4.m1.5.5.3.2">ğ¿</ci><apply id="S3.E4.m1.5.5.3.3.cmml" xref="S3.E4.m1.5.5.3.3"><times id="S3.E4.m1.5.5.3.3.1.cmml" xref="S3.E4.m1.5.5.3.3.1"></times><cn type="integer" id="S3.E4.m1.5.5.3.3.2.cmml" xref="S3.E4.m1.5.5.3.3.2">3</cn><ci id="S3.E4.m1.5.5.3.3.3.cmml" xref="S3.E4.m1.5.5.3.3.3">ğ·</ci></apply></apply><apply id="S3.E4.m1.5.5.1.cmml" xref="S3.E4.m1.5.5.1"><apply id="S3.E4.m1.5.5.1.2.cmml" xref="S3.E4.m1.5.5.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.2.1.cmml" xref="S3.E4.m1.5.5.1.2">superscript</csymbol><apply id="S3.E4.m1.5.5.1.2.2.cmml" xref="S3.E4.m1.5.5.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.2.2.1.cmml" xref="S3.E4.m1.5.5.1.2">subscript</csymbol><sum id="S3.E4.m1.5.5.1.2.2.2.cmml" xref="S3.E4.m1.5.5.1.2.2.2"></sum><apply id="S3.E4.m1.5.5.1.2.2.3.cmml" xref="S3.E4.m1.5.5.1.2.2.3"><eq id="S3.E4.m1.5.5.1.2.2.3.1.cmml" xref="S3.E4.m1.5.5.1.2.2.3.1"></eq><ci id="S3.E4.m1.5.5.1.2.2.3.2.cmml" xref="S3.E4.m1.5.5.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E4.m1.5.5.1.2.2.3.3.cmml" xref="S3.E4.m1.5.5.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.5.5.1.2.3.cmml" xref="S3.E4.m1.5.5.1.2.3">ğ‘‡</ci></apply><apply id="S3.E4.m1.5.5.1.1.cmml" xref="S3.E4.m1.5.5.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.2.cmml" xref="S3.E4.m1.5.5.1.1">superscript</csymbol><apply id="S3.E4.m1.5.5.1.1.1.cmml" xref="S3.E4.m1.5.5.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.1.2.cmml" xref="S3.E4.m1.5.5.1.1">subscript</csymbol><apply id="S3.E4.m1.5.5.1.1.1.1.2.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.5.5.1.1.1.1.2.1.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.2">norm</csymbol><apply id="S3.E4.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1"><minus id="S3.E4.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1.1"></minus><apply id="S3.E4.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1.2.2">ğ‘‹</ci><list id="S3.E4.m1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2"><ci id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1">ğ‘–</ci><apply id="S3.E4.m1.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.1"><times id="S3.E4.m1.2.2.2.2.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1"></times><cn type="integer" id="S3.E4.m1.2.2.2.2.1.2.cmml" xref="S3.E4.m1.2.2.2.2.1.2">3</cn><ci id="S3.E4.m1.2.2.2.2.1.3.cmml" xref="S3.E4.m1.2.2.2.2.1.3">ğ·</ci></apply></list></apply><apply id="S3.E4.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1.3.2"><ci id="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.1">^</ci><ci id="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.5.5.1.1.1.1.1.1.3.2.2">ğ‘‹</ci></apply><list id="S3.E4.m1.4.4.2.3.cmml" xref="S3.E4.m1.4.4.2.2"><ci id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1.1">ğ‘–</ci><apply id="S3.E4.m1.4.4.2.2.1.cmml" xref="S3.E4.m1.4.4.2.2.1"><times id="S3.E4.m1.4.4.2.2.1.1.cmml" xref="S3.E4.m1.4.4.2.2.1.1"></times><cn type="integer" id="S3.E4.m1.4.4.2.2.1.2.cmml" xref="S3.E4.m1.4.4.2.2.1.2">3</cn><ci id="S3.E4.m1.4.4.2.2.1.3.cmml" xref="S3.E4.m1.4.4.2.2.1.3">ğ·</ci></apply></list></apply></apply></apply><cn type="integer" id="S3.E4.m1.5.5.1.1.1.3.cmml" xref="S3.E4.m1.5.5.1.1.1.3">2</cn></apply><cn type="integer" id="S3.E4.m1.5.5.1.1.3.cmml" xref="S3.E4.m1.5.5.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.5c">\ L_{3D}=\sum_{i=1}^{T}||X_{i,3D}-\hat{X}_{i,3D}||_{2}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p6.10" class="ltx_p">where <math id="S3.SS1.p6.9.m1.1" class="ltx_Math" alttext="L_{2D}" display="inline"><semantics id="S3.SS1.p6.9.m1.1a"><msub id="S3.SS1.p6.9.m1.1.1" xref="S3.SS1.p6.9.m1.1.1.cmml"><mi id="S3.SS1.p6.9.m1.1.1.2" xref="S3.SS1.p6.9.m1.1.1.2.cmml">L</mi><mrow id="S3.SS1.p6.9.m1.1.1.3" xref="S3.SS1.p6.9.m1.1.1.3.cmml"><mn id="S3.SS1.p6.9.m1.1.1.3.2" xref="S3.SS1.p6.9.m1.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p6.9.m1.1.1.3.1" xref="S3.SS1.p6.9.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p6.9.m1.1.1.3.3" xref="S3.SS1.p6.9.m1.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.9.m1.1b"><apply id="S3.SS1.p6.9.m1.1.1.cmml" xref="S3.SS1.p6.9.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.9.m1.1.1.1.cmml" xref="S3.SS1.p6.9.m1.1.1">subscript</csymbol><ci id="S3.SS1.p6.9.m1.1.1.2.cmml" xref="S3.SS1.p6.9.m1.1.1.2">ğ¿</ci><apply id="S3.SS1.p6.9.m1.1.1.3.cmml" xref="S3.SS1.p6.9.m1.1.1.3"><times id="S3.SS1.p6.9.m1.1.1.3.1.cmml" xref="S3.SS1.p6.9.m1.1.1.3.1"></times><cn type="integer" id="S3.SS1.p6.9.m1.1.1.3.2.cmml" xref="S3.SS1.p6.9.m1.1.1.3.2">2</cn><ci id="S3.SS1.p6.9.m1.1.1.3.3.cmml" xref="S3.SS1.p6.9.m1.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.9.m1.1c">L_{2D}</annotation></semantics></math> is the <math id="S3.SS1.p6.10.m2.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S3.SS1.p6.10.m2.1a"><msub id="S3.SS1.p6.10.m2.1.1" xref="S3.SS1.p6.10.m2.1.1.cmml"><mi id="S3.SS1.p6.10.m2.1.1.2" xref="S3.SS1.p6.10.m2.1.1.2.cmml">L</mi><mn id="S3.SS1.p6.10.m2.1.1.3" xref="S3.SS1.p6.10.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.10.m2.1b"><apply id="S3.SS1.p6.10.m2.1.1.cmml" xref="S3.SS1.p6.10.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.10.m2.1.1.1.cmml" xref="S3.SS1.p6.10.m2.1.1">subscript</csymbol><ci id="S3.SS1.p6.10.m2.1.1.2.cmml" xref="S3.SS1.p6.10.m2.1.1.2">ğ¿</ci><cn type="integer" id="S3.SS1.p6.10.m2.1.1.3.cmml" xref="S3.SS1.p6.10.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.10.m2.1c">L_{2}</annotation></semantics></math> distance between ground truth 2D joints location and the weak-perspective projection of predicted 3D joints using corresponding camera parameters:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.5" class="ltx_Math" alttext="\ L_{2D}=\sum_{i=1}^{T}||X_{i,2D}-\hat{X}_{i,2D}||_{2}^{2}" display="block"><semantics id="S3.E5.m1.5a"><mrow id="S3.E5.m1.5.5" xref="S3.E5.m1.5.5.cmml"><msub id="S3.E5.m1.5.5.3" xref="S3.E5.m1.5.5.3.cmml"><mi id="S3.E5.m1.5.5.3.2" xref="S3.E5.m1.5.5.3.2.cmml">L</mi><mrow id="S3.E5.m1.5.5.3.3" xref="S3.E5.m1.5.5.3.3.cmml"><mn id="S3.E5.m1.5.5.3.3.2" xref="S3.E5.m1.5.5.3.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.3.3.1" xref="S3.E5.m1.5.5.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.3.3.3" xref="S3.E5.m1.5.5.3.3.3.cmml">D</mi></mrow></msub><mo rspace="0.111em" id="S3.E5.m1.5.5.2" xref="S3.E5.m1.5.5.2.cmml">=</mo><mrow id="S3.E5.m1.5.5.1" xref="S3.E5.m1.5.5.1.cmml"><munderover id="S3.E5.m1.5.5.1.2" xref="S3.E5.m1.5.5.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E5.m1.5.5.1.2.2.2" xref="S3.E5.m1.5.5.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E5.m1.5.5.1.2.2.3" xref="S3.E5.m1.5.5.1.2.2.3.cmml"><mi id="S3.E5.m1.5.5.1.2.2.3.2" xref="S3.E5.m1.5.5.1.2.2.3.2.cmml">i</mi><mo id="S3.E5.m1.5.5.1.2.2.3.1" xref="S3.E5.m1.5.5.1.2.2.3.1.cmml">=</mo><mn id="S3.E5.m1.5.5.1.2.2.3.3" xref="S3.E5.m1.5.5.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E5.m1.5.5.1.2.3" xref="S3.E5.m1.5.5.1.2.3.cmml">T</mi></munderover><msubsup id="S3.E5.m1.5.5.1.1" xref="S3.E5.m1.5.5.1.1.cmml"><mrow id="S3.E5.m1.5.5.1.1.1.1.1" xref="S3.E5.m1.5.5.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.5.5.1.1.1.1.1.2" xref="S3.E5.m1.5.5.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E5.m1.5.5.1.1.1.1.1.1" xref="S3.E5.m1.5.5.1.1.1.1.1.1.cmml"><msub id="S3.E5.m1.5.5.1.1.1.1.1.1.2" xref="S3.E5.m1.5.5.1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.5.5.1.1.1.1.1.1.2.2" xref="S3.E5.m1.5.5.1.1.1.1.1.1.2.2.cmml">X</mi><mrow id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">i</mi><mo id="S3.E5.m1.2.2.2.2.2" xref="S3.E5.m1.2.2.2.3.cmml">,</mo><mrow id="S3.E5.m1.2.2.2.2.1" xref="S3.E5.m1.2.2.2.2.1.cmml"><mn id="S3.E5.m1.2.2.2.2.1.2" xref="S3.E5.m1.2.2.2.2.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.2.1.1" xref="S3.E5.m1.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.E5.m1.2.2.2.2.1.3" xref="S3.E5.m1.2.2.2.2.1.3.cmml">D</mi></mrow></mrow></msub><mo id="S3.E5.m1.5.5.1.1.1.1.1.1.1" xref="S3.E5.m1.5.5.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E5.m1.5.5.1.1.1.1.1.1.3" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E5.m1.5.5.1.1.1.1.1.1.3.2" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.2" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.2.cmml">X</mi><mo id="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.1" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mrow id="S3.E5.m1.4.4.2.2" xref="S3.E5.m1.4.4.2.3.cmml"><mi id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.1.cmml">i</mi><mo id="S3.E5.m1.4.4.2.2.2" xref="S3.E5.m1.4.4.2.3.cmml">,</mo><mrow id="S3.E5.m1.4.4.2.2.1" xref="S3.E5.m1.4.4.2.2.1.cmml"><mn id="S3.E5.m1.4.4.2.2.1.2" xref="S3.E5.m1.4.4.2.2.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.2.2.1.1" xref="S3.E5.m1.4.4.2.2.1.1.cmml">â€‹</mo><mi id="S3.E5.m1.4.4.2.2.1.3" xref="S3.E5.m1.4.4.2.2.1.3.cmml">D</mi></mrow></mrow></msub></mrow><mo stretchy="false" id="S3.E5.m1.5.5.1.1.1.1.1.3" xref="S3.E5.m1.5.5.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E5.m1.5.5.1.1.1.3" xref="S3.E5.m1.5.5.1.1.1.3.cmml">2</mn><mn id="S3.E5.m1.5.5.1.1.3" xref="S3.E5.m1.5.5.1.1.3.cmml">2</mn></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.5b"><apply id="S3.E5.m1.5.5.cmml" xref="S3.E5.m1.5.5"><eq id="S3.E5.m1.5.5.2.cmml" xref="S3.E5.m1.5.5.2"></eq><apply id="S3.E5.m1.5.5.3.cmml" xref="S3.E5.m1.5.5.3"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.3.1.cmml" xref="S3.E5.m1.5.5.3">subscript</csymbol><ci id="S3.E5.m1.5.5.3.2.cmml" xref="S3.E5.m1.5.5.3.2">ğ¿</ci><apply id="S3.E5.m1.5.5.3.3.cmml" xref="S3.E5.m1.5.5.3.3"><times id="S3.E5.m1.5.5.3.3.1.cmml" xref="S3.E5.m1.5.5.3.3.1"></times><cn type="integer" id="S3.E5.m1.5.5.3.3.2.cmml" xref="S3.E5.m1.5.5.3.3.2">2</cn><ci id="S3.E5.m1.5.5.3.3.3.cmml" xref="S3.E5.m1.5.5.3.3.3">ğ·</ci></apply></apply><apply id="S3.E5.m1.5.5.1.cmml" xref="S3.E5.m1.5.5.1"><apply id="S3.E5.m1.5.5.1.2.cmml" xref="S3.E5.m1.5.5.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.2.1.cmml" xref="S3.E5.m1.5.5.1.2">superscript</csymbol><apply id="S3.E5.m1.5.5.1.2.2.cmml" xref="S3.E5.m1.5.5.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.2.2.1.cmml" xref="S3.E5.m1.5.5.1.2">subscript</csymbol><sum id="S3.E5.m1.5.5.1.2.2.2.cmml" xref="S3.E5.m1.5.5.1.2.2.2"></sum><apply id="S3.E5.m1.5.5.1.2.2.3.cmml" xref="S3.E5.m1.5.5.1.2.2.3"><eq id="S3.E5.m1.5.5.1.2.2.3.1.cmml" xref="S3.E5.m1.5.5.1.2.2.3.1"></eq><ci id="S3.E5.m1.5.5.1.2.2.3.2.cmml" xref="S3.E5.m1.5.5.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E5.m1.5.5.1.2.2.3.3.cmml" xref="S3.E5.m1.5.5.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E5.m1.5.5.1.2.3.cmml" xref="S3.E5.m1.5.5.1.2.3">ğ‘‡</ci></apply><apply id="S3.E5.m1.5.5.1.1.cmml" xref="S3.E5.m1.5.5.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.2.cmml" xref="S3.E5.m1.5.5.1.1">superscript</csymbol><apply id="S3.E5.m1.5.5.1.1.1.cmml" xref="S3.E5.m1.5.5.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.1.2.cmml" xref="S3.E5.m1.5.5.1.1">subscript</csymbol><apply id="S3.E5.m1.5.5.1.1.1.1.2.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.5.5.1.1.1.1.2.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.2">norm</csymbol><apply id="S3.E5.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1"><minus id="S3.E5.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.1"></minus><apply id="S3.E5.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.2.2">ğ‘‹</ci><list id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2"><ci id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">ğ‘–</ci><apply id="S3.E5.m1.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2.1"><times id="S3.E5.m1.2.2.2.2.1.1.cmml" xref="S3.E5.m1.2.2.2.2.1.1"></times><cn type="integer" id="S3.E5.m1.2.2.2.2.1.2.cmml" xref="S3.E5.m1.2.2.2.2.1.2">2</cn><ci id="S3.E5.m1.2.2.2.2.1.3.cmml" xref="S3.E5.m1.2.2.2.2.1.3">ğ·</ci></apply></list></apply><apply id="S3.E5.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3.2"><ci id="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.1">^</ci><ci id="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3.2.2">ğ‘‹</ci></apply><list id="S3.E5.m1.4.4.2.3.cmml" xref="S3.E5.m1.4.4.2.2"><ci id="S3.E5.m1.3.3.1.1.cmml" xref="S3.E5.m1.3.3.1.1">ğ‘–</ci><apply id="S3.E5.m1.4.4.2.2.1.cmml" xref="S3.E5.m1.4.4.2.2.1"><times id="S3.E5.m1.4.4.2.2.1.1.cmml" xref="S3.E5.m1.4.4.2.2.1.1"></times><cn type="integer" id="S3.E5.m1.4.4.2.2.1.2.cmml" xref="S3.E5.m1.4.4.2.2.1.2">2</cn><ci id="S3.E5.m1.4.4.2.2.1.3.cmml" xref="S3.E5.m1.4.4.2.2.1.3">ğ·</ci></apply></list></apply></apply></apply><cn type="integer" id="S3.E5.m1.5.5.1.1.1.3.cmml" xref="S3.E5.m1.5.5.1.1.1.3">2</cn></apply><cn type="integer" id="S3.E5.m1.5.5.1.1.3.cmml" xref="S3.E5.m1.5.5.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.5c">\ L_{2D}=\sum_{i=1}^{T}||X_{i,2D}-\hat{X}_{i,2D}||_{2}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p6.11" class="ltx_p">where <math id="S3.SS1.p6.11.m1.1" class="ltx_Math" alttext="L_{smpl}" display="inline"><semantics id="S3.SS1.p6.11.m1.1a"><msub id="S3.SS1.p6.11.m1.1.1" xref="S3.SS1.p6.11.m1.1.1.cmml"><mi id="S3.SS1.p6.11.m1.1.1.2" xref="S3.SS1.p6.11.m1.1.1.2.cmml">L</mi><mrow id="S3.SS1.p6.11.m1.1.1.3" xref="S3.SS1.p6.11.m1.1.1.3.cmml"><mi id="S3.SS1.p6.11.m1.1.1.3.2" xref="S3.SS1.p6.11.m1.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p6.11.m1.1.1.3.1" xref="S3.SS1.p6.11.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p6.11.m1.1.1.3.3" xref="S3.SS1.p6.11.m1.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p6.11.m1.1.1.3.1a" xref="S3.SS1.p6.11.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p6.11.m1.1.1.3.4" xref="S3.SS1.p6.11.m1.1.1.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p6.11.m1.1.1.3.1b" xref="S3.SS1.p6.11.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p6.11.m1.1.1.3.5" xref="S3.SS1.p6.11.m1.1.1.3.5.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.11.m1.1b"><apply id="S3.SS1.p6.11.m1.1.1.cmml" xref="S3.SS1.p6.11.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.11.m1.1.1.1.cmml" xref="S3.SS1.p6.11.m1.1.1">subscript</csymbol><ci id="S3.SS1.p6.11.m1.1.1.2.cmml" xref="S3.SS1.p6.11.m1.1.1.2">ğ¿</ci><apply id="S3.SS1.p6.11.m1.1.1.3.cmml" xref="S3.SS1.p6.11.m1.1.1.3"><times id="S3.SS1.p6.11.m1.1.1.3.1.cmml" xref="S3.SS1.p6.11.m1.1.1.3.1"></times><ci id="S3.SS1.p6.11.m1.1.1.3.2.cmml" xref="S3.SS1.p6.11.m1.1.1.3.2">ğ‘ </ci><ci id="S3.SS1.p6.11.m1.1.1.3.3.cmml" xref="S3.SS1.p6.11.m1.1.1.3.3">ğ‘š</ci><ci id="S3.SS1.p6.11.m1.1.1.3.4.cmml" xref="S3.SS1.p6.11.m1.1.1.3.4">ğ‘</ci><ci id="S3.SS1.p6.11.m1.1.1.3.5.cmml" xref="S3.SS1.p6.11.m1.1.1.3.5">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.11.m1.1c">L_{smpl}</annotation></semantics></math> is the L2 distance between ground truth and predicted SMPL parameters:</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.2" class="ltx_Math" alttext="\ L_{smpl}=\sum_{i=1}^{T}||\theta_{i}-\hat{\theta}_{i}||_{2}^{2}+||\beta_{i}-\hat{\beta}_{i}||_{2}^{2}" display="block"><semantics id="S3.E6.m1.2a"><mrow id="S3.E6.m1.2.2" xref="S3.E6.m1.2.2.cmml"><msub id="S3.E6.m1.2.2.4" xref="S3.E6.m1.2.2.4.cmml"><mi id="S3.E6.m1.2.2.4.2" xref="S3.E6.m1.2.2.4.2.cmml">L</mi><mrow id="S3.E6.m1.2.2.4.3" xref="S3.E6.m1.2.2.4.3.cmml"><mi id="S3.E6.m1.2.2.4.3.2" xref="S3.E6.m1.2.2.4.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.4.3.1" xref="S3.E6.m1.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.4.3.3" xref="S3.E6.m1.2.2.4.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.4.3.1a" xref="S3.E6.m1.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.4.3.4" xref="S3.E6.m1.2.2.4.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.4.3.1b" xref="S3.E6.m1.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.4.3.5" xref="S3.E6.m1.2.2.4.3.5.cmml">l</mi></mrow></msub><mo rspace="0.111em" id="S3.E6.m1.2.2.3" xref="S3.E6.m1.2.2.3.cmml">=</mo><mrow id="S3.E6.m1.2.2.2" xref="S3.E6.m1.2.2.2.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><munderover id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E6.m1.1.1.1.1.2.2.2" xref="S3.E6.m1.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E6.m1.1.1.1.1.2.2.3" xref="S3.E6.m1.1.1.1.1.2.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.2.2.3.2" xref="S3.E6.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E6.m1.1.1.1.1.2.2.3.1" xref="S3.E6.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E6.m1.1.1.1.1.2.2.3.3" xref="S3.E6.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E6.m1.1.1.1.1.2.3" xref="S3.E6.m1.1.1.1.1.2.3.cmml">T</mi></munderover><msubsup id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">Î¸</mi><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">Î¸</mi><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E6.m1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.3.cmml">2</mn><mn id="S3.E6.m1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.3.cmml">2</mn></msubsup></mrow><mo id="S3.E6.m1.2.2.2.3" xref="S3.E6.m1.2.2.2.3.cmml">+</mo><msubsup id="S3.E6.m1.2.2.2.2" xref="S3.E6.m1.2.2.2.2.cmml"><mrow id="S3.E6.m1.2.2.2.2.1.1.1" xref="S3.E6.m1.2.2.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.2.2.1.1.1.2" xref="S3.E6.m1.2.2.2.2.1.1.2.1.cmml">â€–</mo><mrow id="S3.E6.m1.2.2.2.2.1.1.1.1" xref="S3.E6.m1.2.2.2.2.1.1.1.1.cmml"><msub id="S3.E6.m1.2.2.2.2.1.1.1.1.2" xref="S3.E6.m1.2.2.2.2.1.1.1.1.2.cmml"><mi id="S3.E6.m1.2.2.2.2.1.1.1.1.2.2" xref="S3.E6.m1.2.2.2.2.1.1.1.1.2.2.cmml">Î²</mi><mi id="S3.E6.m1.2.2.2.2.1.1.1.1.2.3" xref="S3.E6.m1.2.2.2.2.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E6.m1.2.2.2.2.1.1.1.1.1" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E6.m1.2.2.2.2.1.1.1.1.3" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3.cmml"><mover accent="true" id="S3.E6.m1.2.2.2.2.1.1.1.1.3.2" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.cmml"><mi id="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.2" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.2.cmml">Î²</mi><mo id="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.1" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.E6.m1.2.2.2.2.1.1.1.1.3.3" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E6.m1.2.2.2.2.1.1.1.3" xref="S3.E6.m1.2.2.2.2.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E6.m1.2.2.2.2.1.3" xref="S3.E6.m1.2.2.2.2.1.3.cmml">2</mn><mn id="S3.E6.m1.2.2.2.2.3" xref="S3.E6.m1.2.2.2.2.3.cmml">2</mn></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.2b"><apply id="S3.E6.m1.2.2.cmml" xref="S3.E6.m1.2.2"><eq id="S3.E6.m1.2.2.3.cmml" xref="S3.E6.m1.2.2.3"></eq><apply id="S3.E6.m1.2.2.4.cmml" xref="S3.E6.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.4.1.cmml" xref="S3.E6.m1.2.2.4">subscript</csymbol><ci id="S3.E6.m1.2.2.4.2.cmml" xref="S3.E6.m1.2.2.4.2">ğ¿</ci><apply id="S3.E6.m1.2.2.4.3.cmml" xref="S3.E6.m1.2.2.4.3"><times id="S3.E6.m1.2.2.4.3.1.cmml" xref="S3.E6.m1.2.2.4.3.1"></times><ci id="S3.E6.m1.2.2.4.3.2.cmml" xref="S3.E6.m1.2.2.4.3.2">ğ‘ </ci><ci id="S3.E6.m1.2.2.4.3.3.cmml" xref="S3.E6.m1.2.2.4.3.3">ğ‘š</ci><ci id="S3.E6.m1.2.2.4.3.4.cmml" xref="S3.E6.m1.2.2.4.3.4">ğ‘</ci><ci id="S3.E6.m1.2.2.4.3.5.cmml" xref="S3.E6.m1.2.2.4.3.5">ğ‘™</ci></apply></apply><apply id="S3.E6.m1.2.2.2.cmml" xref="S3.E6.m1.2.2.2"><plus id="S3.E6.m1.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.3"></plus><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1"><apply id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.2">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.2">subscript</csymbol><sum id="S3.E6.m1.1.1.1.1.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.2.2.2"></sum><apply id="S3.E6.m1.1.1.1.1.2.2.3.cmml" xref="S3.E6.m1.1.1.1.1.2.2.3"><eq id="S3.E6.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E6.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E6.m1.1.1.1.1.2.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E6.m1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.2.3">ğ‘‡</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1">subscript</csymbol><apply id="S3.E6.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1"><minus id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.2">ğœƒ</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.1">^</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.2.2">ğœƒ</ci></apply><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><cn type="integer" id="S3.E6.m1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.3">2</cn></apply><cn type="integer" id="S3.E6.m1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.3">2</cn></apply></apply><apply id="S3.E6.m1.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2">superscript</csymbol><apply id="S3.E6.m1.2.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.1.2.cmml" xref="S3.E6.m1.2.2.2.2">subscript</csymbol><apply id="S3.E6.m1.2.2.2.2.1.1.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.2.2.2.2.1.1.2.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.2">norm</csymbol><apply id="S3.E6.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1"><minus id="S3.E6.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1"></minus><apply id="S3.E6.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.1.1.1.1.2.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.2.2.2.2.1.1.1.1.2.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.2.2">ğ›½</ci><ci id="S3.E6.m1.2.2.2.2.1.1.1.1.2.3.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E6.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.1.1.1.1.3.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3">subscript</csymbol><apply id="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3.2"><ci id="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.1">^</ci><ci id="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3.2.2">ğ›½</ci></apply><ci id="S3.E6.m1.2.2.2.2.1.1.1.1.3.3.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><cn type="integer" id="S3.E6.m1.2.2.2.2.1.3.cmml" xref="S3.E6.m1.2.2.2.2.1.3">2</cn></apply><cn type="integer" id="S3.E6.m1.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.2c">\ L_{smpl}=\sum_{i=1}^{T}||\theta_{i}-\hat{\theta}_{i}||_{2}^{2}+||\beta_{i}-\hat{\beta}_{i}||_{2}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Motion discriminator and flow supervision</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.3" class="ltx_p"><span id="S3.SS2.p1.3.1" class="ltx_text ltx_font_bold">Motion discriminator.</span> FollowÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, we use a motion discriminator <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="D_{M}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">D</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">M</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ·</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">D_{M}</annotation></semantics></math> to distinguish the predicted SMPL parameters <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\theta</annotation></semantics></math>(fake) and the real SMPL parameters <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\hat{\theta}" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mover accent="true" id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">Î¸</mi><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><ci id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1">^</ci><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\hat{\theta}</annotation></semantics></math>(real) from AMASSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Motion discriminator helps to produce more feasible real world poses that are aligned with 2D joint locations:</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.2" class="ltx_Math" alttext="\ L_{adv}=E_{\Theta\sim p_{G}}[(D_{M}(\hat{\Theta})-1)^{2}]" display="block"><semantics id="S3.E7.m1.2a"><mrow id="S3.E7.m1.2.2" xref="S3.E7.m1.2.2.cmml"><msub id="S3.E7.m1.2.2.3" xref="S3.E7.m1.2.2.3.cmml"><mi id="S3.E7.m1.2.2.3.2" xref="S3.E7.m1.2.2.3.2.cmml">L</mi><mrow id="S3.E7.m1.2.2.3.3" xref="S3.E7.m1.2.2.3.3.cmml"><mi id="S3.E7.m1.2.2.3.3.2" xref="S3.E7.m1.2.2.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.3.3.1" xref="S3.E7.m1.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.2.2.3.3.3" xref="S3.E7.m1.2.2.3.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.3.3.1a" xref="S3.E7.m1.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.2.2.3.3.4" xref="S3.E7.m1.2.2.3.3.4.cmml">v</mi></mrow></msub><mo id="S3.E7.m1.2.2.2" xref="S3.E7.m1.2.2.2.cmml">=</mo><mrow id="S3.E7.m1.2.2.1" xref="S3.E7.m1.2.2.1.cmml"><msub id="S3.E7.m1.2.2.1.3" xref="S3.E7.m1.2.2.1.3.cmml"><mi id="S3.E7.m1.2.2.1.3.2" xref="S3.E7.m1.2.2.1.3.2.cmml">E</mi><mrow id="S3.E7.m1.2.2.1.3.3" xref="S3.E7.m1.2.2.1.3.3.cmml"><mi mathvariant="normal" id="S3.E7.m1.2.2.1.3.3.2" xref="S3.E7.m1.2.2.1.3.3.2.cmml">Î˜</mi><mo id="S3.E7.m1.2.2.1.3.3.1" xref="S3.E7.m1.2.2.1.3.3.1.cmml">âˆ¼</mo><msub id="S3.E7.m1.2.2.1.3.3.3" xref="S3.E7.m1.2.2.1.3.3.3.cmml"><mi id="S3.E7.m1.2.2.1.3.3.3.2" xref="S3.E7.m1.2.2.1.3.3.3.2.cmml">p</mi><mi id="S3.E7.m1.2.2.1.3.3.3.3" xref="S3.E7.m1.2.2.1.3.3.3.3.cmml">G</mi></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.1.2" xref="S3.E7.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S3.E7.m1.2.2.1.1.1" xref="S3.E7.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.E7.m1.2.2.1.1.1.2" xref="S3.E7.m1.2.2.1.1.2.1.cmml">[</mo><msup id="S3.E7.m1.2.2.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.2.2.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml"><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.cmml"><msub id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.2.cmml">D</mi><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.3.cmml">M</mi></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.3.2" xref="S3.E7.m1.1.1.cmml"><mo stretchy="false" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.3.2.1" xref="S3.E7.m1.1.1.cmml">(</mo><mover accent="true" id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml"><mi mathvariant="normal" id="S3.E7.m1.1.1.2" xref="S3.E7.m1.1.1.2.cmml">Î˜</mi><mo id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.3.2.2" xref="S3.E7.m1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.E7.m1.2.2.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S3.E7.m1.2.2.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S3.E7.m1.2.2.1.1.1.3" xref="S3.E7.m1.2.2.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.2b"><apply id="S3.E7.m1.2.2.cmml" xref="S3.E7.m1.2.2"><eq id="S3.E7.m1.2.2.2.cmml" xref="S3.E7.m1.2.2.2"></eq><apply id="S3.E7.m1.2.2.3.cmml" xref="S3.E7.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.3.1.cmml" xref="S3.E7.m1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.2.2.3.2.cmml" xref="S3.E7.m1.2.2.3.2">ğ¿</ci><apply id="S3.E7.m1.2.2.3.3.cmml" xref="S3.E7.m1.2.2.3.3"><times id="S3.E7.m1.2.2.3.3.1.cmml" xref="S3.E7.m1.2.2.3.3.1"></times><ci id="S3.E7.m1.2.2.3.3.2.cmml" xref="S3.E7.m1.2.2.3.3.2">ğ‘</ci><ci id="S3.E7.m1.2.2.3.3.3.cmml" xref="S3.E7.m1.2.2.3.3.3">ğ‘‘</ci><ci id="S3.E7.m1.2.2.3.3.4.cmml" xref="S3.E7.m1.2.2.3.3.4">ğ‘£</ci></apply></apply><apply id="S3.E7.m1.2.2.1.cmml" xref="S3.E7.m1.2.2.1"><times id="S3.E7.m1.2.2.1.2.cmml" xref="S3.E7.m1.2.2.1.2"></times><apply id="S3.E7.m1.2.2.1.3.cmml" xref="S3.E7.m1.2.2.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.3.1.cmml" xref="S3.E7.m1.2.2.1.3">subscript</csymbol><ci id="S3.E7.m1.2.2.1.3.2.cmml" xref="S3.E7.m1.2.2.1.3.2">ğ¸</ci><apply id="S3.E7.m1.2.2.1.3.3.cmml" xref="S3.E7.m1.2.2.1.3.3"><csymbol cd="latexml" id="S3.E7.m1.2.2.1.3.3.1.cmml" xref="S3.E7.m1.2.2.1.3.3.1">similar-to</csymbol><ci id="S3.E7.m1.2.2.1.3.3.2.cmml" xref="S3.E7.m1.2.2.1.3.3.2">Î˜</ci><apply id="S3.E7.m1.2.2.1.3.3.3.cmml" xref="S3.E7.m1.2.2.1.3.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.3.3.3.1.cmml" xref="S3.E7.m1.2.2.1.3.3.3">subscript</csymbol><ci id="S3.E7.m1.2.2.1.3.3.3.2.cmml" xref="S3.E7.m1.2.2.1.3.3.3.2">ğ‘</ci><ci id="S3.E7.m1.2.2.1.3.3.3.3.cmml" xref="S3.E7.m1.2.2.1.3.3.3.3">ğº</ci></apply></apply></apply><apply id="S3.E7.m1.2.2.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.2.2.1.1.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.2">delimited-[]</csymbol><apply id="S3.E7.m1.2.2.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1">superscript</csymbol><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1"><minus id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1"></minus><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2"><times id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.1"></times><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.2">ğ·</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.2.3">ğ‘€</ci></apply><apply id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.3.2"><ci id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1.1">^</ci><ci id="S3.E7.m1.1.1.2.cmml" xref="S3.E7.m1.1.1.2">Î˜</ci></apply></apply><cn type="integer" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3">1</cn></apply><cn type="integer" id="S3.E7.m1.2.2.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.2c">\ L_{adv}=E_{\Theta\sim p_{G}}[(D_{M}(\hat{\Theta})-1)^{2}]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.3" class="ltx_p">The objective for the discriminator is:</p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.2" class="ltx_math_unparsed" alttext="L_{D}=E_{\Theta\sim p_{R}}[(D_{M}(\Theta)-1)^{2}+E_{\Theta\sim p_{G}}[D_{M}(\hat{\Theta})^{2}]" display="block"><semantics id="S3.E8.m1.2a"><mrow id="S3.E8.m1.2b"><msub id="S3.E8.m1.2.3"><mi id="S3.E8.m1.2.3.2">L</mi><mi id="S3.E8.m1.2.3.3">D</mi></msub><mo id="S3.E8.m1.2.4">=</mo><msub id="S3.E8.m1.2.5"><mi id="S3.E8.m1.2.5.2">E</mi><mrow id="S3.E8.m1.2.5.3"><mi mathvariant="normal" id="S3.E8.m1.2.5.3.2">Î˜</mi><mo id="S3.E8.m1.2.5.3.1">âˆ¼</mo><msub id="S3.E8.m1.2.5.3.3"><mi id="S3.E8.m1.2.5.3.3.2">p</mi><mi id="S3.E8.m1.2.5.3.3.3">R</mi></msub></mrow></msub><mrow id="S3.E8.m1.2.6"><mo stretchy="false" id="S3.E8.m1.2.6.1">[</mo><msup id="S3.E8.m1.2.6.2"><mrow id="S3.E8.m1.2.6.2.2"><mo stretchy="false" id="S3.E8.m1.2.6.2.2.1">(</mo><msub id="S3.E8.m1.2.6.2.2.2"><mi id="S3.E8.m1.2.6.2.2.2.2">D</mi><mi id="S3.E8.m1.2.6.2.2.2.3">M</mi></msub><mrow id="S3.E8.m1.2.6.2.2.3"><mo stretchy="false" id="S3.E8.m1.2.6.2.2.3.1">(</mo><mi mathvariant="normal" id="S3.E8.m1.1.1">Î˜</mi><mo stretchy="false" id="S3.E8.m1.2.6.2.2.3.2">)</mo></mrow><mo id="S3.E8.m1.2.6.2.2.4">âˆ’</mo><mn id="S3.E8.m1.2.6.2.2.5">1</mn><mo stretchy="false" id="S3.E8.m1.2.6.2.2.6">)</mo></mrow><mn id="S3.E8.m1.2.6.2.3">2</mn></msup><mo id="S3.E8.m1.2.6.3">+</mo><msub id="S3.E8.m1.2.6.4"><mi id="S3.E8.m1.2.6.4.2">E</mi><mrow id="S3.E8.m1.2.6.4.3"><mi mathvariant="normal" id="S3.E8.m1.2.6.4.3.2">Î˜</mi><mo id="S3.E8.m1.2.6.4.3.1">âˆ¼</mo><msub id="S3.E8.m1.2.6.4.3.3"><mi id="S3.E8.m1.2.6.4.3.3.2">p</mi><mi id="S3.E8.m1.2.6.4.3.3.3">G</mi></msub></mrow></msub><mrow id="S3.E8.m1.2.6.5"><mo stretchy="false" id="S3.E8.m1.2.6.5.1">[</mo><msub id="S3.E8.m1.2.6.5.2"><mi id="S3.E8.m1.2.6.5.2.2">D</mi><mi id="S3.E8.m1.2.6.5.2.3">M</mi></msub><msup id="S3.E8.m1.2.6.5.3"><mrow id="S3.E8.m1.2.6.5.3.2"><mo stretchy="false" id="S3.E8.m1.2.6.5.3.2.1">(</mo><mover accent="true" id="S3.E8.m1.2.2"><mi mathvariant="normal" id="S3.E8.m1.2.2.2">Î˜</mi><mo id="S3.E8.m1.2.2.1">^</mo></mover><mo stretchy="false" id="S3.E8.m1.2.6.5.3.2.2">)</mo></mrow><mn id="S3.E8.m1.2.6.5.3.3">2</mn></msup><mo stretchy="false" id="S3.E8.m1.2.6.5.4">]</mo></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S3.E8.m1.2c">L_{D}=E_{\Theta\sim p_{R}}[(D_{M}(\Theta)-1)^{2}+E_{\Theta\sim p_{G}}[D_{M}(\hat{\Theta})^{2}]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.2" class="ltx_p">where <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="p_{G}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><msub id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">p</mi><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">G</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ğ‘</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">ğº</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">p_{G}</annotation></semantics></math> is a generated motion sequence and <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="p_{R}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">p</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">ğ‘</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">ğ‘…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">p_{R}</annotation></semantics></math> is a real motion sequence from the AMASS dataset.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<p id="S3.T1.2" class="ltx_p ltx_align_center"><span id="S3.T1.2.1" class="ltx_text">


<span id="S3.T1.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:531.0pt;height:222.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.0pt,5.9pt) scale(0.95,0.95) ;">
<span id="S3.T1.2.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S3.T1.2.1.1.1.1.1" class="ltx_tr">
<span id="S3.T1.2.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt ltx_rowspan ltx_rowspan_2 ltx_colspan ltx_colspan_2" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></span>
<span id="S3.T1.2.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_4" style="padding-left:2.8pt;padding-right:2.8pt;">3DPW</span>
<span id="S3.T1.2.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_3" style="padding-left:2.8pt;padding-right:2.8pt;">MPI-INF-3DHP</span>
<span id="S3.T1.2.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_3" style="padding-left:2.8pt;padding-right:2.8pt;">Human3.6</span></span>
<span id="S3.T1.2.1.1.1.2.2" class="ltx_tr">
<span id="S3.T1.2.1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">PA-MPJPEâ†“</span>
<span id="S3.T1.2.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">MPJPEâ†“</span>
<span id="S3.T1.2.1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">PVEâ†“</span>
<span id="S3.T1.2.1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">Accelâ†“</span>
<span id="S3.T1.2.1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">PA-MPJPEâ†“</span>
<span id="S3.T1.2.1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">MPJPEâ†“</span>
<span id="S3.T1.2.1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">Accelâ†“</span>
<span id="S3.T1.2.1.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">PA-MPJPEâ†“</span>
<span id="S3.T1.2.1.1.1.2.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">MPJPEâ†“</span>
<span id="S3.T1.2.1.1.1.2.2.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">Accelâ†“</span></span>
<span id="S3.T1.2.1.1.1.3.3" class="ltx_tr">
<span id="S3.T1.2.1.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t ltx_rowspan ltx_rowspan_5" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.3.3.1.1" class="ltx_text">
<span id="S3.T1.2.1.1.1.3.3.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:55pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:55.0pt;transform:translate(-23.06pt,-22.08pt) rotate(-90deg) ;">
<span id="S3.T1.2.1.1.1.3.3.1.1.1.1" class="ltx_p"><span id="S3.T1.2.1.1.1.3.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Single image</span></span>
</span></span></span></span>
<span id="S3.T1.2.1.1.1.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">HMR</span>
<span id="S3.T1.2.1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">76.7</span>
<span id="S3.T1.2.1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">130.0</span>
<span id="S3.T1.2.1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">37.4</span>
<span id="S3.T1.2.1.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">89.8</span>
<span id="S3.T1.2.1.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">124.2</span>
<span id="S3.T1.2.1.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.3.3.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">56.8</span>
<span id="S3.T1.2.1.1.1.3.3.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">88.0</span>
<span id="S3.T1.2.1.1.1.3.3.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">-</span></span>
<span id="S3.T1.2.1.1.1.4.4" class="ltx_tr">
<span id="S3.T1.2.1.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">GraphCMR</span>
<span id="S3.T1.2.1.1.1.4.4.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">70.2</span>
<span id="S3.T1.2.1.1.1.4.4.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.4.4.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.4.4.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.4.4.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.4.4.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">50.1</span>
<span id="S3.T1.2.1.1.1.4.4.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.4.4.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span></span>
<span id="S3.T1.2.1.1.1.5.5" class="ltx_tr">
<span id="S3.T1.2.1.1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">SPIN</span>
<span id="S3.T1.2.1.1.1.5.5.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">59.2</span>
<span id="S3.T1.2.1.1.1.5.5.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">96.9</span>
<span id="S3.T1.2.1.1.1.5.5.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">116.4</span>
<span id="S3.T1.2.1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">29.8</span>
<span id="S3.T1.2.1.1.1.5.5.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">67.5</span>
<span id="S3.T1.2.1.1.1.5.5.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">105.2</span>
<span id="S3.T1.2.1.1.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.5.5.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">41.1</span>
<span id="S3.T1.2.1.1.1.5.5.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.5.5.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">18.3</span></span>
<span id="S3.T1.2.1.1.1.6.6" class="ltx_tr">
<span id="S3.T1.2.1.1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">I2L-MeshNet</span>
<span id="S3.T1.2.1.1.1.6.6.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">57.7</span>
<span id="S3.T1.2.1.1.1.6.6.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">93.2</span>
<span id="S3.T1.2.1.1.1.6.6.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">110.1</span>
<span id="S3.T1.2.1.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">30.9</span>
<span id="S3.T1.2.1.1.1.6.6.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.6.6.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.6.6.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">41.1</span>
<span id="S3.T1.2.1.1.1.6.6.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">55.7</span>
<span id="S3.T1.2.1.1.1.6.6.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">13.4</span></span>
<span id="S3.T1.2.1.1.1.7.7" class="ltx_tr">
<span id="S3.T1.2.1.1.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">Pose2Mesh</span>
<span id="S3.T1.2.1.1.1.7.7.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">58.3</span>
<span id="S3.T1.2.1.1.1.7.7.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">88.9</span>
<span id="S3.T1.2.1.1.1.7.7.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">106.3</span>
<span id="S3.T1.2.1.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">22.6</span>
<span id="S3.T1.2.1.1.1.7.7.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.7.7.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.7.7.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">46.3</span>
<span id="S3.T1.2.1.1.1.7.7.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">64.9</span>
<span id="S3.T1.2.1.1.1.7.7.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">23.9</span></span>
<span id="S3.T1.2.1.1.1.8.8" class="ltx_tr">
<span id="S3.T1.2.1.1.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t ltx_rowspan ltx_rowspan_6" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.8.8.1.1" class="ltx_text">
<span id="S3.T1.2.1.1.1.8.8.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:25.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:25.3pt;transform:translate(-9.17pt,-9.17pt) rotate(-90deg) ;">
<span id="S3.T1.2.1.1.1.8.8.1.1.1.1" class="ltx_p"><span id="S3.T1.2.1.1.1.8.8.1.1.1.1.1" class="ltx_text ltx_font_bold">Video</span></span>
</span></span></span></span>
<span id="S3.T1.2.1.1.1.8.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">HMMR</span>
<span id="S3.T1.2.1.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">72.6</span>
<span id="S3.T1.2.1.1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">116.5</span>
<span id="S3.T1.2.1.1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">139.3</span>
<span id="S3.T1.2.1.1.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">15.2</span>
<span id="S3.T1.2.1.1.1.8.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.8.8.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.8.8.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.8.8.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">56.9</span>
<span id="S3.T1.2.1.1.1.8.8.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.8.8.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">-</span></span>
<span id="S3.T1.2.1.1.1.9.9" class="ltx_tr">
<span id="S3.T1.2.1.1.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">Sun et al.</span>
<span id="S3.T1.2.1.1.1.9.9.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">69.5</span>
<span id="S3.T1.2.1.1.1.9.9.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.9.9.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.9.9.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.9.9.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.9.9.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">42.4</span>
<span id="S3.T1.2.1.1.1.9.9.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">59.1</span>
<span id="S3.T1.2.1.1.1.9.9.11" class="ltx_td" style="padding-left:2.8pt;padding-right:2.8pt;"></span></span>
<span id="S3.T1.2.1.1.1.10.10" class="ltx_tr">
<span id="S3.T1.2.1.1.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">SPIN</span>
<span id="S3.T1.2.1.1.1.10.10.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">59.2</span>
<span id="S3.T1.2.1.1.1.10.10.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">96.9</span>
<span id="S3.T1.2.1.1.1.10.10.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">116.4</span>
<span id="S3.T1.2.1.1.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">29.8</span>
<span id="S3.T1.2.1.1.1.10.10.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">67.5</span>
<span id="S3.T1.2.1.1.1.10.10.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">105.2</span>
<span id="S3.T1.2.1.1.1.10.10.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.10.10.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">41.1</span>
<span id="S3.T1.2.1.1.1.10.10.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.10.10.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">18.3</span></span>
<span id="S3.T1.2.1.1.1.11.11" class="ltx_tr">
<span id="S3.T1.2.1.1.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">MEVA</span>
<span id="S3.T1.2.1.1.1.11.11.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">54.7</span>
<span id="S3.T1.2.1.1.1.11.11.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">86.9</span>
<span id="S3.T1.2.1.1.1.11.11.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">-</span>
<span id="S3.T1.2.1.1.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">11.6</span>
<span id="S3.T1.2.1.1.1.11.11.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">65.4</span>
<span id="S3.T1.2.1.1.1.11.11.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">96.4</span>
<span id="S3.T1.2.1.1.1.11.11.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.11.11.8.1" class="ltx_text ltx_font_bold">11.1</span></span>
<span id="S3.T1.2.1.1.1.11.11.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">53.2</span>
<span id="S3.T1.2.1.1.1.11.11.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">76.0</span>
<span id="S3.T1.2.1.1.1.11.11.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">15.3</span></span>
<span id="S3.T1.2.1.1.1.12.12" class="ltx_tr">
<span id="S3.T1.2.1.1.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">VIBE</span>
<span id="S3.T1.2.1.1.1.12.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">51.9</span>
<span id="S3.T1.2.1.1.1.12.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">82.9</span>
<span id="S3.T1.2.1.1.1.12.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">99.1</span>
<span id="S3.T1.2.1.1.1.12.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">23.4</span>
<span id="S3.T1.2.1.1.1.12.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">64.6</span>
<span id="S3.T1.2.1.1.1.12.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">96.6</span>
<span id="S3.T1.2.1.1.1.12.12.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">27.3</span>
<span id="S3.T1.2.1.1.1.12.12.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">41.4</span>
<span id="S3.T1.2.1.1.1.12.12.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">65.6</span>
<span id="S3.T1.2.1.1.1.12.12.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">-</span></span>
<span id="S3.T1.2.1.1.1.13.13" class="ltx_tr">
<span id="S3.T1.2.1.1.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">DST-VIBE(Ours)</span>
<span id="S3.T1.2.1.1.1.13.13.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.13.13.2.1" class="ltx_text ltx_font_bold">50.3</span></span>
<span id="S3.T1.2.1.1.1.13.13.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.13.13.3.1" class="ltx_text ltx_font_bold">76.7</span></span>
<span id="S3.T1.2.1.1.1.13.13.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.13.13.4.1" class="ltx_text ltx_font_bold">93.5</span></span>
<span id="S3.T1.2.1.1.1.13.13.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.13.13.5.1" class="ltx_text ltx_font_bold">11.0</span></span>
<span id="S3.T1.2.1.1.1.13.13.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.13.13.6.1" class="ltx_text ltx_font_bold">62.2</span></span>
<span id="S3.T1.2.1.1.1.13.13.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.13.13.7.1" class="ltx_text ltx_font_bold">93.4</span></span>
<span id="S3.T1.2.1.1.1.13.13.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">11.9</span>
<span id="S3.T1.2.1.1.1.13.13.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.13.13.9.1" class="ltx_text ltx_font_bold">39.3</span></span>
<span id="S3.T1.2.1.1.1.13.13.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.13.13.10.1" class="ltx_text ltx_font_bold">60.5</span></span>
<span id="S3.T1.2.1.1.1.13.13.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S3.T1.2.1.1.1.13.13.11.1" class="ltx_text ltx_font_bold">5.0</span></span></span>
</span>
</span>
</span></span></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.4.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Evaluation of state-of-the-art methods on 3DPW, MPI-INF-3DHP, and Human3.6M datasets.<span id="S3.T1.5.2.1" class="ltx_text ltx_font_medium"> Models of VIBE,MEVA and DST-VIBE use 3DPW train set. And all methods except MEVA use Human3.6 for training. So the most fair comparison is between VIBE and ours. DST-VIBE achieves state-of-the-art results with almost all the metrics.</span></span></figcaption>
</figure>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.5" class="ltx_p"><span id="S3.SS2.p4.5.1" class="ltx_text ltx_font_bold">Flow supervision.</span> Inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, we introduce a new flow loss to refine our DTS-VIBE network. Since optical flow represents the motion of two adjacent frames, the 2D joints location should move following its corresponding flow. So we use our flow sequence <math id="S3.SS2.p4.1.m1.3" class="ltx_Math" alttext="o_{1},...,o_{T}" display="inline"><semantics id="S3.SS2.p4.1.m1.3a"><mrow id="S3.SS2.p4.1.m1.3.3.2" xref="S3.SS2.p4.1.m1.3.3.3.cmml"><msub id="S3.SS2.p4.1.m1.2.2.1.1" xref="S3.SS2.p4.1.m1.2.2.1.1.cmml"><mi id="S3.SS2.p4.1.m1.2.2.1.1.2" xref="S3.SS2.p4.1.m1.2.2.1.1.2.cmml">o</mi><mn id="S3.SS2.p4.1.m1.2.2.1.1.3" xref="S3.SS2.p4.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p4.1.m1.3.3.2.3" xref="S3.SS2.p4.1.m1.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">â€¦</mi><mo id="S3.SS2.p4.1.m1.3.3.2.4" xref="S3.SS2.p4.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS2.p4.1.m1.3.3.2.2" xref="S3.SS2.p4.1.m1.3.3.2.2.cmml"><mi id="S3.SS2.p4.1.m1.3.3.2.2.2" xref="S3.SS2.p4.1.m1.3.3.2.2.2.cmml">o</mi><mi id="S3.SS2.p4.1.m1.3.3.2.2.3" xref="S3.SS2.p4.1.m1.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.3b"><list id="S3.SS2.p4.1.m1.3.3.3.cmml" xref="S3.SS2.p4.1.m1.3.3.2"><apply id="S3.SS2.p4.1.m1.2.2.1.1.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS2.p4.1.m1.2.2.1.1.2.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.2">ğ‘œ</ci><cn type="integer" id="S3.SS2.p4.1.m1.2.2.1.1.3.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.3">1</cn></apply><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">â€¦</ci><apply id="S3.SS2.p4.1.m1.3.3.2.2.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.3.3.2.2.1.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS2.p4.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2">ğ‘œ</ci><ci id="S3.SS2.p4.1.m1.3.3.2.2.3.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.3">ğ‘‡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.3c">o_{1},...,o_{T}</annotation></semantics></math> to supervise the movement of 2D joints location.We back trace the previous frame 2d joint position <math id="S3.SS2.p4.2.m2.2" class="ltx_Math" alttext="X^{f}_{i-1,2D}" display="inline"><semantics id="S3.SS2.p4.2.m2.2a"><msubsup id="S3.SS2.p4.2.m2.2.3" xref="S3.SS2.p4.2.m2.2.3.cmml"><mi id="S3.SS2.p4.2.m2.2.3.2.2" xref="S3.SS2.p4.2.m2.2.3.2.2.cmml">X</mi><mrow id="S3.SS2.p4.2.m2.2.2.2.2" xref="S3.SS2.p4.2.m2.2.2.2.3.cmml"><mrow id="S3.SS2.p4.2.m2.1.1.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.1.1.1.2" xref="S3.SS2.p4.2.m2.1.1.1.1.1.2.cmml">i</mi><mo id="S3.SS2.p4.2.m2.1.1.1.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S3.SS2.p4.2.m2.1.1.1.1.1.3" xref="S3.SS2.p4.2.m2.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS2.p4.2.m2.2.2.2.2.3" xref="S3.SS2.p4.2.m2.2.2.2.3.cmml">,</mo><mrow id="S3.SS2.p4.2.m2.2.2.2.2.2" xref="S3.SS2.p4.2.m2.2.2.2.2.2.cmml"><mn id="S3.SS2.p4.2.m2.2.2.2.2.2.2" xref="S3.SS2.p4.2.m2.2.2.2.2.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p4.2.m2.2.2.2.2.2.1" xref="S3.SS2.p4.2.m2.2.2.2.2.2.1.cmml">â€‹</mo><mi id="S3.SS2.p4.2.m2.2.2.2.2.2.3" xref="S3.SS2.p4.2.m2.2.2.2.2.2.3.cmml">D</mi></mrow></mrow><mi id="S3.SS2.p4.2.m2.2.3.2.3" xref="S3.SS2.p4.2.m2.2.3.2.3.cmml">f</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.2b"><apply id="S3.SS2.p4.2.m2.2.3.cmml" xref="S3.SS2.p4.2.m2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.2.3.1.cmml" xref="S3.SS2.p4.2.m2.2.3">subscript</csymbol><apply id="S3.SS2.p4.2.m2.2.3.2.cmml" xref="S3.SS2.p4.2.m2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.2.3.2.1.cmml" xref="S3.SS2.p4.2.m2.2.3">superscript</csymbol><ci id="S3.SS2.p4.2.m2.2.3.2.2.cmml" xref="S3.SS2.p4.2.m2.2.3.2.2">ğ‘‹</ci><ci id="S3.SS2.p4.2.m2.2.3.2.3.cmml" xref="S3.SS2.p4.2.m2.2.3.2.3">ğ‘“</ci></apply><list id="S3.SS2.p4.2.m2.2.2.2.3.cmml" xref="S3.SS2.p4.2.m2.2.2.2.2"><apply id="S3.SS2.p4.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1.1.1"><minus id="S3.SS2.p4.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1.1.1.1"></minus><ci id="S3.SS2.p4.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.1.1.1.2">ğ‘–</ci><cn type="integer" id="S3.SS2.p4.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p4.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.p4.2.m2.2.2.2.2.2"><times id="S3.SS2.p4.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS2.p4.2.m2.2.2.2.2.2.1"></times><cn type="integer" id="S3.SS2.p4.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS2.p4.2.m2.2.2.2.2.2.2">2</cn><ci id="S3.SS2.p4.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS2.p4.2.m2.2.2.2.2.2.3">ğ·</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.2c">X^{f}_{i-1,2D}</annotation></semantics></math> using optical flow <math id="S3.SS2.p4.3.m3.1" class="ltx_Math" alttext="o_{i}" display="inline"><semantics id="S3.SS2.p4.3.m3.1a"><msub id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.p4.3.m3.1.1.2" xref="S3.SS2.p4.3.m3.1.1.2.cmml">o</mi><mi id="S3.SS2.p4.3.m3.1.1.3" xref="S3.SS2.p4.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><apply id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.p4.3.m3.1.1.2">ğ‘œ</ci><ci id="S3.SS2.p4.3.m3.1.1.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">o_{i}</annotation></semantics></math> and current 2d joint position <math id="S3.SS2.p4.4.m4.2" class="ltx_Math" alttext="X_{i,2D}" display="inline"><semantics id="S3.SS2.p4.4.m4.2a"><msub id="S3.SS2.p4.4.m4.2.3" xref="S3.SS2.p4.4.m4.2.3.cmml"><mi id="S3.SS2.p4.4.m4.2.3.2" xref="S3.SS2.p4.4.m4.2.3.2.cmml">X</mi><mrow id="S3.SS2.p4.4.m4.2.2.2.2" xref="S3.SS2.p4.4.m4.2.2.2.3.cmml"><mi id="S3.SS2.p4.4.m4.1.1.1.1" xref="S3.SS2.p4.4.m4.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p4.4.m4.2.2.2.2.2" xref="S3.SS2.p4.4.m4.2.2.2.3.cmml">,</mo><mrow id="S3.SS2.p4.4.m4.2.2.2.2.1" xref="S3.SS2.p4.4.m4.2.2.2.2.1.cmml"><mn id="S3.SS2.p4.4.m4.2.2.2.2.1.2" xref="S3.SS2.p4.4.m4.2.2.2.2.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p4.4.m4.2.2.2.2.1.1" xref="S3.SS2.p4.4.m4.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.SS2.p4.4.m4.2.2.2.2.1.3" xref="S3.SS2.p4.4.m4.2.2.2.2.1.3.cmml">D</mi></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.2b"><apply id="S3.SS2.p4.4.m4.2.3.cmml" xref="S3.SS2.p4.4.m4.2.3"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.2.3.1.cmml" xref="S3.SS2.p4.4.m4.2.3">subscript</csymbol><ci id="S3.SS2.p4.4.m4.2.3.2.cmml" xref="S3.SS2.p4.4.m4.2.3.2">ğ‘‹</ci><list id="S3.SS2.p4.4.m4.2.2.2.3.cmml" xref="S3.SS2.p4.4.m4.2.2.2.2"><ci id="S3.SS2.p4.4.m4.1.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1.1.1">ğ‘–</ci><apply id="S3.SS2.p4.4.m4.2.2.2.2.1.cmml" xref="S3.SS2.p4.4.m4.2.2.2.2.1"><times id="S3.SS2.p4.4.m4.2.2.2.2.1.1.cmml" xref="S3.SS2.p4.4.m4.2.2.2.2.1.1"></times><cn type="integer" id="S3.SS2.p4.4.m4.2.2.2.2.1.2.cmml" xref="S3.SS2.p4.4.m4.2.2.2.2.1.2">2</cn><ci id="S3.SS2.p4.4.m4.2.2.2.2.1.3.cmml" xref="S3.SS2.p4.4.m4.2.2.2.2.1.3">ğ·</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.2c">X_{i,2D}</annotation></semantics></math>, the flow loss is calculated as <math id="S3.SS2.p4.5.m5.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S3.SS2.p4.5.m5.1a"><msub id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml"><mi id="S3.SS2.p4.5.m5.1.1.2" xref="S3.SS2.p4.5.m5.1.1.2.cmml">L</mi><mn id="S3.SS2.p4.5.m5.1.1.3" xref="S3.SS2.p4.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><apply id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m5.1.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p4.5.m5.1.1.2.cmml" xref="S3.SS2.p4.5.m5.1.1.2">ğ¿</ci><cn type="integer" id="S3.SS2.p4.5.m5.1.1.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">L_{2}</annotation></semantics></math> distance between backward 2D joints and original 2D joints:</p>
<table id="S3.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E9.m1.5" class="ltx_Math" alttext="\ L_{flow}=\sum_{i=2}^{T}||X_{i-1,2D}-X_{i-1,2D}^{f}||_{2}^{2}" display="block"><semantics id="S3.E9.m1.5a"><mrow id="S3.E9.m1.5.5" xref="S3.E9.m1.5.5.cmml"><msub id="S3.E9.m1.5.5.3" xref="S3.E9.m1.5.5.3.cmml"><mi id="S3.E9.m1.5.5.3.2" xref="S3.E9.m1.5.5.3.2.cmml">L</mi><mrow id="S3.E9.m1.5.5.3.3" xref="S3.E9.m1.5.5.3.3.cmml"><mi id="S3.E9.m1.5.5.3.3.2" xref="S3.E9.m1.5.5.3.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.5.5.3.3.1" xref="S3.E9.m1.5.5.3.3.1.cmml">â€‹</mo><mi id="S3.E9.m1.5.5.3.3.3" xref="S3.E9.m1.5.5.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.5.5.3.3.1a" xref="S3.E9.m1.5.5.3.3.1.cmml">â€‹</mo><mi id="S3.E9.m1.5.5.3.3.4" xref="S3.E9.m1.5.5.3.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.5.5.3.3.1b" xref="S3.E9.m1.5.5.3.3.1.cmml">â€‹</mo><mi id="S3.E9.m1.5.5.3.3.5" xref="S3.E9.m1.5.5.3.3.5.cmml">w</mi></mrow></msub><mo rspace="0.111em" id="S3.E9.m1.5.5.2" xref="S3.E9.m1.5.5.2.cmml">=</mo><mrow id="S3.E9.m1.5.5.1" xref="S3.E9.m1.5.5.1.cmml"><munderover id="S3.E9.m1.5.5.1.2" xref="S3.E9.m1.5.5.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E9.m1.5.5.1.2.2.2" xref="S3.E9.m1.5.5.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E9.m1.5.5.1.2.2.3" xref="S3.E9.m1.5.5.1.2.2.3.cmml"><mi id="S3.E9.m1.5.5.1.2.2.3.2" xref="S3.E9.m1.5.5.1.2.2.3.2.cmml">i</mi><mo id="S3.E9.m1.5.5.1.2.2.3.1" xref="S3.E9.m1.5.5.1.2.2.3.1.cmml">=</mo><mn id="S3.E9.m1.5.5.1.2.2.3.3" xref="S3.E9.m1.5.5.1.2.2.3.3.cmml">2</mn></mrow><mi id="S3.E9.m1.5.5.1.2.3" xref="S3.E9.m1.5.5.1.2.3.cmml">T</mi></munderover><msubsup id="S3.E9.m1.5.5.1.1" xref="S3.E9.m1.5.5.1.1.cmml"><mrow id="S3.E9.m1.5.5.1.1.1.1.1" xref="S3.E9.m1.5.5.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E9.m1.5.5.1.1.1.1.1.2" xref="S3.E9.m1.5.5.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E9.m1.5.5.1.1.1.1.1.1" xref="S3.E9.m1.5.5.1.1.1.1.1.1.cmml"><msub id="S3.E9.m1.5.5.1.1.1.1.1.1.2" xref="S3.E9.m1.5.5.1.1.1.1.1.1.2.cmml"><mi id="S3.E9.m1.5.5.1.1.1.1.1.1.2.2" xref="S3.E9.m1.5.5.1.1.1.1.1.1.2.2.cmml">X</mi><mrow id="S3.E9.m1.2.2.2.2" xref="S3.E9.m1.2.2.2.3.cmml"><mrow id="S3.E9.m1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.cmml"><mi id="S3.E9.m1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.2.cmml">i</mi><mo id="S3.E9.m1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S3.E9.m1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.E9.m1.2.2.2.2.3" xref="S3.E9.m1.2.2.2.3.cmml">,</mo><mrow id="S3.E9.m1.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.cmml"><mn id="S3.E9.m1.2.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E9.m1.2.2.2.2.2.1" xref="S3.E9.m1.2.2.2.2.2.1.cmml">â€‹</mo><mi id="S3.E9.m1.2.2.2.2.2.3" xref="S3.E9.m1.2.2.2.2.2.3.cmml">D</mi></mrow></mrow></msub><mo id="S3.E9.m1.5.5.1.1.1.1.1.1.1" xref="S3.E9.m1.5.5.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.E9.m1.5.5.1.1.1.1.1.1.3" xref="S3.E9.m1.5.5.1.1.1.1.1.1.3.cmml"><mi id="S3.E9.m1.5.5.1.1.1.1.1.1.3.2.2" xref="S3.E9.m1.5.5.1.1.1.1.1.1.3.2.2.cmml">X</mi><mrow id="S3.E9.m1.4.4.2.2" xref="S3.E9.m1.4.4.2.3.cmml"><mrow id="S3.E9.m1.3.3.1.1.1" xref="S3.E9.m1.3.3.1.1.1.cmml"><mi id="S3.E9.m1.3.3.1.1.1.2" xref="S3.E9.m1.3.3.1.1.1.2.cmml">i</mi><mo id="S3.E9.m1.3.3.1.1.1.1" xref="S3.E9.m1.3.3.1.1.1.1.cmml">âˆ’</mo><mn id="S3.E9.m1.3.3.1.1.1.3" xref="S3.E9.m1.3.3.1.1.1.3.cmml">1</mn></mrow><mo id="S3.E9.m1.4.4.2.2.3" xref="S3.E9.m1.4.4.2.3.cmml">,</mo><mrow id="S3.E9.m1.4.4.2.2.2" xref="S3.E9.m1.4.4.2.2.2.cmml"><mn id="S3.E9.m1.4.4.2.2.2.2" xref="S3.E9.m1.4.4.2.2.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E9.m1.4.4.2.2.2.1" xref="S3.E9.m1.4.4.2.2.2.1.cmml">â€‹</mo><mi id="S3.E9.m1.4.4.2.2.2.3" xref="S3.E9.m1.4.4.2.2.2.3.cmml">D</mi></mrow></mrow><mi id="S3.E9.m1.5.5.1.1.1.1.1.1.3.3" xref="S3.E9.m1.5.5.1.1.1.1.1.1.3.3.cmml">f</mi></msubsup></mrow><mo stretchy="false" id="S3.E9.m1.5.5.1.1.1.1.1.3" xref="S3.E9.m1.5.5.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E9.m1.5.5.1.1.1.3" xref="S3.E9.m1.5.5.1.1.1.3.cmml">2</mn><mn id="S3.E9.m1.5.5.1.1.3" xref="S3.E9.m1.5.5.1.1.3.cmml">2</mn></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.5b"><apply id="S3.E9.m1.5.5.cmml" xref="S3.E9.m1.5.5"><eq id="S3.E9.m1.5.5.2.cmml" xref="S3.E9.m1.5.5.2"></eq><apply id="S3.E9.m1.5.5.3.cmml" xref="S3.E9.m1.5.5.3"><csymbol cd="ambiguous" id="S3.E9.m1.5.5.3.1.cmml" xref="S3.E9.m1.5.5.3">subscript</csymbol><ci id="S3.E9.m1.5.5.3.2.cmml" xref="S3.E9.m1.5.5.3.2">ğ¿</ci><apply id="S3.E9.m1.5.5.3.3.cmml" xref="S3.E9.m1.5.5.3.3"><times id="S3.E9.m1.5.5.3.3.1.cmml" xref="S3.E9.m1.5.5.3.3.1"></times><ci id="S3.E9.m1.5.5.3.3.2.cmml" xref="S3.E9.m1.5.5.3.3.2">ğ‘“</ci><ci id="S3.E9.m1.5.5.3.3.3.cmml" xref="S3.E9.m1.5.5.3.3.3">ğ‘™</ci><ci id="S3.E9.m1.5.5.3.3.4.cmml" xref="S3.E9.m1.5.5.3.3.4">ğ‘œ</ci><ci id="S3.E9.m1.5.5.3.3.5.cmml" xref="S3.E9.m1.5.5.3.3.5">ğ‘¤</ci></apply></apply><apply id="S3.E9.m1.5.5.1.cmml" xref="S3.E9.m1.5.5.1"><apply id="S3.E9.m1.5.5.1.2.cmml" xref="S3.E9.m1.5.5.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.5.5.1.2.1.cmml" xref="S3.E9.m1.5.5.1.2">superscript</csymbol><apply id="S3.E9.m1.5.5.1.2.2.cmml" xref="S3.E9.m1.5.5.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.5.5.1.2.2.1.cmml" xref="S3.E9.m1.5.5.1.2">subscript</csymbol><sum id="S3.E9.m1.5.5.1.2.2.2.cmml" xref="S3.E9.m1.5.5.1.2.2.2"></sum><apply id="S3.E9.m1.5.5.1.2.2.3.cmml" xref="S3.E9.m1.5.5.1.2.2.3"><eq id="S3.E9.m1.5.5.1.2.2.3.1.cmml" xref="S3.E9.m1.5.5.1.2.2.3.1"></eq><ci id="S3.E9.m1.5.5.1.2.2.3.2.cmml" xref="S3.E9.m1.5.5.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E9.m1.5.5.1.2.2.3.3.cmml" xref="S3.E9.m1.5.5.1.2.2.3.3">2</cn></apply></apply><ci id="S3.E9.m1.5.5.1.2.3.cmml" xref="S3.E9.m1.5.5.1.2.3">ğ‘‡</ci></apply><apply id="S3.E9.m1.5.5.1.1.cmml" xref="S3.E9.m1.5.5.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.5.5.1.1.2.cmml" xref="S3.E9.m1.5.5.1.1">superscript</csymbol><apply id="S3.E9.m1.5.5.1.1.1.cmml" xref="S3.E9.m1.5.5.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.5.5.1.1.1.2.cmml" xref="S3.E9.m1.5.5.1.1">subscript</csymbol><apply id="S3.E9.m1.5.5.1.1.1.1.2.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1"><csymbol cd="latexml" id="S3.E9.m1.5.5.1.1.1.1.2.1.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.2">norm</csymbol><apply id="S3.E9.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1"><minus id="S3.E9.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.1"></minus><apply id="S3.E9.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E9.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.2.2">ğ‘‹</ci><list id="S3.E9.m1.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.2"><apply id="S3.E9.m1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1"><minus id="S3.E9.m1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1"></minus><ci id="S3.E9.m1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.2">ğ‘–</ci><cn type="integer" id="S3.E9.m1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.E9.m1.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2"><times id="S3.E9.m1.2.2.2.2.2.1.cmml" xref="S3.E9.m1.2.2.2.2.2.1"></times><cn type="integer" id="S3.E9.m1.2.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2.2">2</cn><ci id="S3.E9.m1.2.2.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.2.2.3">ğ·</ci></apply></list></apply><apply id="S3.E9.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.5.5.1.1.1.1.1.1.3.1.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E9.m1.5.5.1.1.1.1.1.1.3.2.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.5.5.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E9.m1.5.5.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.3.2.2">ğ‘‹</ci><list id="S3.E9.m1.4.4.2.3.cmml" xref="S3.E9.m1.4.4.2.2"><apply id="S3.E9.m1.3.3.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1"><minus id="S3.E9.m1.3.3.1.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1.1"></minus><ci id="S3.E9.m1.3.3.1.1.1.2.cmml" xref="S3.E9.m1.3.3.1.1.1.2">ğ‘–</ci><cn type="integer" id="S3.E9.m1.3.3.1.1.1.3.cmml" xref="S3.E9.m1.3.3.1.1.1.3">1</cn></apply><apply id="S3.E9.m1.4.4.2.2.2.cmml" xref="S3.E9.m1.4.4.2.2.2"><times id="S3.E9.m1.4.4.2.2.2.1.cmml" xref="S3.E9.m1.4.4.2.2.2.1"></times><cn type="integer" id="S3.E9.m1.4.4.2.2.2.2.cmml" xref="S3.E9.m1.4.4.2.2.2.2">2</cn><ci id="S3.E9.m1.4.4.2.2.2.3.cmml" xref="S3.E9.m1.4.4.2.2.2.3">ğ·</ci></apply></list></apply><ci id="S3.E9.m1.5.5.1.1.1.1.1.1.3.3.cmml" xref="S3.E9.m1.5.5.1.1.1.1.1.1.3.3">ğ‘“</ci></apply></apply></apply><cn type="integer" id="S3.E9.m1.5.5.1.1.1.3.cmml" xref="S3.E9.m1.5.5.1.1.1.3">2</cn></apply><cn type="integer" id="S3.E9.m1.5.5.1.1.3.cmml" xref="S3.E9.m1.5.5.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.5c">\ L_{flow}=\sum_{i=2}^{T}||X_{i-1,2D}-X_{i-1,2D}^{f}||_{2}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p4.6" class="ltx_p">Note that we do not add flow loss at the beginning of the training, we only use it as supervision during refinement.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.7" class="ltx_p">Among the dual convolutional network we use, the V-CNN is pre-trained on frame-based pose and shape estimation taskÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, while the O-CNN is pre-trained on the ImageNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> dataset. Similar toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, we choose sequence length <math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="T=16" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><mrow id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml"><mi id="S3.SS2.p5.1.m1.1.1.2" xref="S3.SS2.p5.1.m1.1.1.2.cmml">T</mi><mo id="S3.SS2.p5.1.m1.1.1.1" xref="S3.SS2.p5.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p5.1.m1.1.1.3" xref="S3.SS2.p5.1.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><apply id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1"><eq id="S3.SS2.p5.1.m1.1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1.1"></eq><ci id="S3.SS2.p5.1.m1.1.1.2.cmml" xref="S3.SS2.p5.1.m1.1.1.2">ğ‘‡</ci><cn type="integer" id="S3.SS2.p5.1.m1.1.1.3.cmml" xref="S3.SS2.p5.1.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">T=16</annotation></semantics></math>, which also leads to the best results compared with other alternative ones <math id="S3.SS2.p5.2.m2.3" class="ltx_Math" alttext="i.e." display="inline"><semantics id="S3.SS2.p5.2.m2.3a"><mrow id="S3.SS2.p5.2.m2.3.3.1"><mrow id="S3.SS2.p5.2.m2.3.3.1.1.2" xref="S3.SS2.p5.2.m2.3.3.1.1.1.cmml"><mi id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml">i</mi><mo lspace="0em" rspace="0.167em" id="S3.SS2.p5.2.m2.3.3.1.1.2.1" xref="S3.SS2.p5.2.m2.3.3.1.1.1a.cmml">.</mo><mi id="S3.SS2.p5.2.m2.2.2" xref="S3.SS2.p5.2.m2.2.2.cmml">e</mi></mrow><mo lspace="0em" id="S3.SS2.p5.2.m2.3.3.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.3b"><apply id="S3.SS2.p5.2.m2.3.3.1.1.1.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.3.3.1.1.1a.cmml" xref="S3.SS2.p5.2.m2.3.3.1.1.2.1">formulae-sequence</csymbol><ci id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1">ğ‘–</ci><ci id="S3.SS2.p5.2.m2.2.2.cmml" xref="S3.SS2.p5.2.m2.2.2">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.3c">i.e.</annotation></semantics></math> 8, 32, 64 and 128. For the transformer-based temporal encoder, we choose the number of layers to be 6 and number of head to be 8. The transformer-based regressor has 3 layers with 4 heads. We set the four loss term <math id="S3.SS2.p5.3.m3.4" class="ltx_Math" alttext="\lambda_{1},\lambda_{2},\lambda_{3},\lambda_{4}" display="inline"><semantics id="S3.SS2.p5.3.m3.4a"><mrow id="S3.SS2.p5.3.m3.4.4.4" xref="S3.SS2.p5.3.m3.4.4.5.cmml"><msub id="S3.SS2.p5.3.m3.1.1.1.1" xref="S3.SS2.p5.3.m3.1.1.1.1.cmml"><mi id="S3.SS2.p5.3.m3.1.1.1.1.2" xref="S3.SS2.p5.3.m3.1.1.1.1.2.cmml">Î»</mi><mn id="S3.SS2.p5.3.m3.1.1.1.1.3" xref="S3.SS2.p5.3.m3.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p5.3.m3.4.4.4.5" xref="S3.SS2.p5.3.m3.4.4.5.cmml">,</mo><msub id="S3.SS2.p5.3.m3.2.2.2.2" xref="S3.SS2.p5.3.m3.2.2.2.2.cmml"><mi id="S3.SS2.p5.3.m3.2.2.2.2.2" xref="S3.SS2.p5.3.m3.2.2.2.2.2.cmml">Î»</mi><mn id="S3.SS2.p5.3.m3.2.2.2.2.3" xref="S3.SS2.p5.3.m3.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p5.3.m3.4.4.4.6" xref="S3.SS2.p5.3.m3.4.4.5.cmml">,</mo><msub id="S3.SS2.p5.3.m3.3.3.3.3" xref="S3.SS2.p5.3.m3.3.3.3.3.cmml"><mi id="S3.SS2.p5.3.m3.3.3.3.3.2" xref="S3.SS2.p5.3.m3.3.3.3.3.2.cmml">Î»</mi><mn id="S3.SS2.p5.3.m3.3.3.3.3.3" xref="S3.SS2.p5.3.m3.3.3.3.3.3.cmml">3</mn></msub><mo id="S3.SS2.p5.3.m3.4.4.4.7" xref="S3.SS2.p5.3.m3.4.4.5.cmml">,</mo><msub id="S3.SS2.p5.3.m3.4.4.4.4" xref="S3.SS2.p5.3.m3.4.4.4.4.cmml"><mi id="S3.SS2.p5.3.m3.4.4.4.4.2" xref="S3.SS2.p5.3.m3.4.4.4.4.2.cmml">Î»</mi><mn id="S3.SS2.p5.3.m3.4.4.4.4.3" xref="S3.SS2.p5.3.m3.4.4.4.4.3.cmml">4</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.4b"><list id="S3.SS2.p5.3.m3.4.4.5.cmml" xref="S3.SS2.p5.3.m3.4.4.4"><apply id="S3.SS2.p5.3.m3.1.1.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p5.3.m3.1.1.1.1.2.cmml" xref="S3.SS2.p5.3.m3.1.1.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS2.p5.3.m3.1.1.1.1.3.cmml" xref="S3.SS2.p5.3.m3.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p5.3.m3.2.2.2.2.cmml" xref="S3.SS2.p5.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.2.2.2.2.1.cmml" xref="S3.SS2.p5.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p5.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.p5.3.m3.2.2.2.2.2">ğœ†</ci><cn type="integer" id="S3.SS2.p5.3.m3.2.2.2.2.3.cmml" xref="S3.SS2.p5.3.m3.2.2.2.2.3">2</cn></apply><apply id="S3.SS2.p5.3.m3.3.3.3.3.cmml" xref="S3.SS2.p5.3.m3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.3.3.3.3.1.cmml" xref="S3.SS2.p5.3.m3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p5.3.m3.3.3.3.3.2.cmml" xref="S3.SS2.p5.3.m3.3.3.3.3.2">ğœ†</ci><cn type="integer" id="S3.SS2.p5.3.m3.3.3.3.3.3.cmml" xref="S3.SS2.p5.3.m3.3.3.3.3.3">3</cn></apply><apply id="S3.SS2.p5.3.m3.4.4.4.4.cmml" xref="S3.SS2.p5.3.m3.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.4.4.4.4.1.cmml" xref="S3.SS2.p5.3.m3.4.4.4.4">subscript</csymbol><ci id="S3.SS2.p5.3.m3.4.4.4.4.2.cmml" xref="S3.SS2.p5.3.m3.4.4.4.4.2">ğœ†</ci><cn type="integer" id="S3.SS2.p5.3.m3.4.4.4.4.3.cmml" xref="S3.SS2.p5.3.m3.4.4.4.4.3">4</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.4c">\lambda_{1},\lambda_{2},\lambda_{3},\lambda_{4}</annotation></semantics></math> in Eq.Â <a href="#S3.E3" title="In 3.1 Two-stream encoder â€£ 3 Architecture â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> to 300, 200, 120 and 60 respectively. We use Adam optimizerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> with learning rate 5 <math id="S3.SS2.p5.4.m4.1" class="ltx_Math" alttext="\times 10^{-5}" display="inline"><semantics id="S3.SS2.p5.4.m4.1a"><mrow id="S3.SS2.p5.4.m4.1.1" xref="S3.SS2.p5.4.m4.1.1.cmml"><mi id="S3.SS2.p5.4.m4.1.1.2" xref="S3.SS2.p5.4.m4.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p5.4.m4.1.1.1" xref="S3.SS2.p5.4.m4.1.1.1.cmml">Ã—</mo><msup id="S3.SS2.p5.4.m4.1.1.3" xref="S3.SS2.p5.4.m4.1.1.3.cmml"><mn id="S3.SS2.p5.4.m4.1.1.3.2" xref="S3.SS2.p5.4.m4.1.1.3.2.cmml">10</mn><mrow id="S3.SS2.p5.4.m4.1.1.3.3" xref="S3.SS2.p5.4.m4.1.1.3.3.cmml"><mo id="S3.SS2.p5.4.m4.1.1.3.3a" xref="S3.SS2.p5.4.m4.1.1.3.3.cmml">âˆ’</mo><mn id="S3.SS2.p5.4.m4.1.1.3.3.2" xref="S3.SS2.p5.4.m4.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.1b"><apply id="S3.SS2.p5.4.m4.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1"><times id="S3.SS2.p5.4.m4.1.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1.1"></times><csymbol cd="latexml" id="S3.SS2.p5.4.m4.1.1.2.cmml" xref="S3.SS2.p5.4.m4.1.1.2">absent</csymbol><apply id="S3.SS2.p5.4.m4.1.1.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p5.4.m4.1.1.3.1.cmml" xref="S3.SS2.p5.4.m4.1.1.3">superscript</csymbol><cn type="integer" id="S3.SS2.p5.4.m4.1.1.3.2.cmml" xref="S3.SS2.p5.4.m4.1.1.3.2">10</cn><apply id="S3.SS2.p5.4.m4.1.1.3.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3"><minus id="S3.SS2.p5.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3"></minus><cn type="integer" id="S3.SS2.p5.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.1c">\times 10^{-5}</annotation></semantics></math> for the generator and 5 <math id="S3.SS2.p5.5.m5.1" class="ltx_Math" alttext="\times 10^{-4}" display="inline"><semantics id="S3.SS2.p5.5.m5.1a"><mrow id="S3.SS2.p5.5.m5.1.1" xref="S3.SS2.p5.5.m5.1.1.cmml"><mi id="S3.SS2.p5.5.m5.1.1.2" xref="S3.SS2.p5.5.m5.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p5.5.m5.1.1.1" xref="S3.SS2.p5.5.m5.1.1.1.cmml">Ã—</mo><msup id="S3.SS2.p5.5.m5.1.1.3" xref="S3.SS2.p5.5.m5.1.1.3.cmml"><mn id="S3.SS2.p5.5.m5.1.1.3.2" xref="S3.SS2.p5.5.m5.1.1.3.2.cmml">10</mn><mrow id="S3.SS2.p5.5.m5.1.1.3.3" xref="S3.SS2.p5.5.m5.1.1.3.3.cmml"><mo id="S3.SS2.p5.5.m5.1.1.3.3a" xref="S3.SS2.p5.5.m5.1.1.3.3.cmml">âˆ’</mo><mn id="S3.SS2.p5.5.m5.1.1.3.3.2" xref="S3.SS2.p5.5.m5.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.5.m5.1b"><apply id="S3.SS2.p5.5.m5.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1"><times id="S3.SS2.p5.5.m5.1.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1.1"></times><csymbol cd="latexml" id="S3.SS2.p5.5.m5.1.1.2.cmml" xref="S3.SS2.p5.5.m5.1.1.2">absent</csymbol><apply id="S3.SS2.p5.5.m5.1.1.3.cmml" xref="S3.SS2.p5.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p5.5.m5.1.1.3.1.cmml" xref="S3.SS2.p5.5.m5.1.1.3">superscript</csymbol><cn type="integer" id="S3.SS2.p5.5.m5.1.1.3.2.cmml" xref="S3.SS2.p5.5.m5.1.1.3.2">10</cn><apply id="S3.SS2.p5.5.m5.1.1.3.3.cmml" xref="S3.SS2.p5.5.m5.1.1.3.3"><minus id="S3.SS2.p5.5.m5.1.1.3.3.1.cmml" xref="S3.SS2.p5.5.m5.1.1.3.3"></minus><cn type="integer" id="S3.SS2.p5.5.m5.1.1.3.3.2.cmml" xref="S3.SS2.p5.5.m5.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.5.m5.1c">\times 10^{-4}</annotation></semantics></math> for the motion discriminator. During the refinement with the flow loss <math id="S3.SS2.p5.6.m6.1" class="ltx_Math" alttext="L_{flow}" display="inline"><semantics id="S3.SS2.p5.6.m6.1a"><msub id="S3.SS2.p5.6.m6.1.1" xref="S3.SS2.p5.6.m6.1.1.cmml"><mi id="S3.SS2.p5.6.m6.1.1.2" xref="S3.SS2.p5.6.m6.1.1.2.cmml">L</mi><mrow id="S3.SS2.p5.6.m6.1.1.3" xref="S3.SS2.p5.6.m6.1.1.3.cmml"><mi id="S3.SS2.p5.6.m6.1.1.3.2" xref="S3.SS2.p5.6.m6.1.1.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.6.m6.1.1.3.1" xref="S3.SS2.p5.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p5.6.m6.1.1.3.3" xref="S3.SS2.p5.6.m6.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.6.m6.1.1.3.1a" xref="S3.SS2.p5.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p5.6.m6.1.1.3.4" xref="S3.SS2.p5.6.m6.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.6.m6.1.1.3.1b" xref="S3.SS2.p5.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p5.6.m6.1.1.3.5" xref="S3.SS2.p5.6.m6.1.1.3.5.cmml">w</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.6.m6.1b"><apply id="S3.SS2.p5.6.m6.1.1.cmml" xref="S3.SS2.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.6.m6.1.1.1.cmml" xref="S3.SS2.p5.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p5.6.m6.1.1.2.cmml" xref="S3.SS2.p5.6.m6.1.1.2">ğ¿</ci><apply id="S3.SS2.p5.6.m6.1.1.3.cmml" xref="S3.SS2.p5.6.m6.1.1.3"><times id="S3.SS2.p5.6.m6.1.1.3.1.cmml" xref="S3.SS2.p5.6.m6.1.1.3.1"></times><ci id="S3.SS2.p5.6.m6.1.1.3.2.cmml" xref="S3.SS2.p5.6.m6.1.1.3.2">ğ‘“</ci><ci id="S3.SS2.p5.6.m6.1.1.3.3.cmml" xref="S3.SS2.p5.6.m6.1.1.3.3">ğ‘™</ci><ci id="S3.SS2.p5.6.m6.1.1.3.4.cmml" xref="S3.SS2.p5.6.m6.1.1.3.4">ğ‘œ</ci><ci id="S3.SS2.p5.6.m6.1.1.3.5.cmml" xref="S3.SS2.p5.6.m6.1.1.3.5">ğ‘¤</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.6.m6.1c">L_{flow}</annotation></semantics></math> as supervision, we remove the discriminator and use Adam optimizerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> with learning rate 1 <math id="S3.SS2.p5.7.m7.1" class="ltx_Math" alttext="\times 10^{-5}" display="inline"><semantics id="S3.SS2.p5.7.m7.1a"><mrow id="S3.SS2.p5.7.m7.1.1" xref="S3.SS2.p5.7.m7.1.1.cmml"><mi id="S3.SS2.p5.7.m7.1.1.2" xref="S3.SS2.p5.7.m7.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p5.7.m7.1.1.1" xref="S3.SS2.p5.7.m7.1.1.1.cmml">Ã—</mo><msup id="S3.SS2.p5.7.m7.1.1.3" xref="S3.SS2.p5.7.m7.1.1.3.cmml"><mn id="S3.SS2.p5.7.m7.1.1.3.2" xref="S3.SS2.p5.7.m7.1.1.3.2.cmml">10</mn><mrow id="S3.SS2.p5.7.m7.1.1.3.3" xref="S3.SS2.p5.7.m7.1.1.3.3.cmml"><mo id="S3.SS2.p5.7.m7.1.1.3.3a" xref="S3.SS2.p5.7.m7.1.1.3.3.cmml">âˆ’</mo><mn id="S3.SS2.p5.7.m7.1.1.3.3.2" xref="S3.SS2.p5.7.m7.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.7.m7.1b"><apply id="S3.SS2.p5.7.m7.1.1.cmml" xref="S3.SS2.p5.7.m7.1.1"><times id="S3.SS2.p5.7.m7.1.1.1.cmml" xref="S3.SS2.p5.7.m7.1.1.1"></times><csymbol cd="latexml" id="S3.SS2.p5.7.m7.1.1.2.cmml" xref="S3.SS2.p5.7.m7.1.1.2">absent</csymbol><apply id="S3.SS2.p5.7.m7.1.1.3.cmml" xref="S3.SS2.p5.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p5.7.m7.1.1.3.1.cmml" xref="S3.SS2.p5.7.m7.1.1.3">superscript</csymbol><cn type="integer" id="S3.SS2.p5.7.m7.1.1.3.2.cmml" xref="S3.SS2.p5.7.m7.1.1.3.2">10</cn><apply id="S3.SS2.p5.7.m7.1.1.3.3.cmml" xref="S3.SS2.p5.7.m7.1.1.3.3"><minus id="S3.SS2.p5.7.m7.1.1.3.3.1.cmml" xref="S3.SS2.p5.7.m7.1.1.3.3"></minus><cn type="integer" id="S3.SS2.p5.7.m7.1.1.3.3.2.cmml" xref="S3.SS2.p5.7.m7.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.7.m7.1c">\times 10^{-5}</annotation></semantics></math>.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2110.11680/assets/x3.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="205" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">Attention maps. Visualization of attention values among different attention heads. The x-axis and y-axis correspond to input and target frames respectively. We visualize the attention matrix value of the eight attention head of the first transformer encoder layer.(a) to (h) represent the attention value of eight attention heads separately. Lighter color indicates stronger attention value.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we first list the training/testing datasets and evaluation metrics we use for comparison. Then we compare our method with other state of the art frame-based and video-based methods. We also conduct multiple experiments to illustrate the influence of each component in our model. We provide both qualitative and quantitative results.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">As we all know, 2D datasets (annotated by 2D joint labels) contain a large amount of in-the-wild videos and their labels are easy to obtain. 3D datasets (annotated by 3D joint labels) contain less in-the-wild videos and their labels are more difficult to acquire, but can better supervise the 3D construction model than 2D ones. Therefore we conduct hybrid-training to leverage both 2D and 3D datasets. We use InstaVariety<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, Penn ActionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> and PoseTrackÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> as 2D datasets and 3DPWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, MPI-INF-3DHPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and Human3.6MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> as 3D datasets for training and evaluation.
Human3.6M is a large scale indoor dataset with 2D and 3D annotations. We use subjects S1, S5, S6, S7 and S8 as training data, and test our models on subjects S9 and S11.
3DPW is an outdoor dataset with 2D and 3D annotations. Following previous method, we also train our model on the 3DPW training set before evaluating on 3DPW test set. We also use AMASSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> dataset for adversarial training to discriminate a real/fake label for each sequence.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Evaluation Metrics</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We use three image-based metrics: Mean per joint position error (MPJPE), Procrustes-aligned mean per joint position error (PA-MPJPE) and per vertex error
(PVE). Additionally, we report acceleration errorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, which computes the average difference between the predicted and ground truth acceleration of each joint in <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="mm/s^{2}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mrow id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2.2" xref="S4.SS2.p1.1.m1.1.1.2.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.2.1" xref="S4.SS2.p1.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S4.SS2.p1.1.m1.1.1.2.3" xref="S4.SS2.p1.1.m1.1.1.2.3.cmml">m</mi></mrow><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">/</mo><msup id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.3.2.cmml">s</mi><mn id="S4.SS2.p1.1.m1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><divide id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></divide><apply id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2"><times id="S4.SS2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.2.1"></times><ci id="S4.SS2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2">ğ‘š</ci><ci id="S4.SS2.p1.1.m1.1.1.2.3.cmml" xref="S4.SS2.p1.1.m1.1.1.2.3">ğ‘š</ci></apply><apply id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.3.2">ğ‘ </ci><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">mm/s^{2}</annotation></semantics></math>. We use acceleration error as smooth indicator of temporal methods. A lower image-based metric error means a better performance in terms of accuracy of a model. And lower acceleration error means smoother results.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Comparison results</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">As shown in TableÂ <a href="#S3.T1" title="Table 1 â€£ 3.2 Motion discriminator and flow supervision â€£ 3 Architecture â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we compare our result with previous state-of-the-art methods. Our method outperforms VIBE in all image-based metrics on 3DPW and Human3.6M by a large margin. Besides, we achieve comparable result on MPI-INF-3DHP. Meanwhile, our result significantly outperforms all the image-based and video-based 3D reconstruction methods. The improvement of our model indicates that our two stream network helps to fuse spatial and temporal information, leading to more accurate and smoother 3D reconstruction. It also demonstrates that our transformer encoder and regressor are better at capturing temporal human motion information and predicting plausible SMPL parameters.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">TableÂ <a href="#S3.T1" title="Table 1 â€£ 3.2 Motion discriminator and flow supervision â€£ 3 Architecture â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the comparison on temporal smoothness between DTS-VIBE and state-of-the-arts video-based methods. We present some visualization results in FigureÂ <a href="#S4.F6" title="Figure 6 â€£ 4.4 Ablation study â€£ 4 Experiments â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> which demonstrates that our model is better than VIBE when part of the body is self-occluded. The acceleration error of DTS-VIBE is lower than VIBE. As shown in TableÂ <a href="#S3.T1" title="Table 1 â€£ 3.2 Motion discriminator and flow supervision â€£ 3 Architecture â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we produce smoother result than MEVA, which is state-of-the-art model on temporal smoothness, in terms of the acceleration error. We reduce the acceleration error by 67.3% on Human3.6M, while maintaining the comparable result on 3DPW and MPI-INF-3DHP. FigureÂ <a href="#S4.F5" title="Figure 5 â€£ 4.3 Comparison results â€£ 4 Experiments â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the acceleration error comparison between other methods and ours measured on a sample of 3DPW test set. Compared with VIBE, our model keeps acceleration error at lower level. And our result is slightly better than MEVA except some rare spikes.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.2.1.1" class="ltx_tr">
<th id="S4.T2.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;">model</th>
<th id="S4.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;">PA-MPJPE</th>
<th id="S4.T2.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;">Accel</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.2.2.1" class="ltx_tr">
<td id="S4.T2.2.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">GRU + TR</td>
<td id="S4.T2.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">51.1</td>
<td id="S4.T2.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">31.6</td>
</tr>
<tr id="S4.T2.2.3.2" class="ltx_tr">
<td id="S4.T2.2.3.2.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">TE + HR</td>
<td id="S4.T2.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">50.6</td>
<td id="S4.T2.2.3.2.3" class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">17.6</td>
</tr>
<tr id="S4.T2.2.4.3" class="ltx_tr">
<td id="S4.T2.2.4.3.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">TE + TR(ours)</td>
<td id="S4.T2.2.4.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span id="S4.T2.2.4.3.2.1" class="ltx_text ltx_font_bold">50.3</span></td>
<td id="S4.T2.2.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:14.2pt;padding-right:14.2pt;"><span id="S4.T2.2.4.3.3.1" class="ltx_text ltx_font_bold">11.0</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.4.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Ablation study on transformer.<span id="S4.T2.5.2.1" class="ltx_text ltx_font_medium"> We replace our transformer encoder (TE) with GRU and replace Transformer Regressor with HMR regressor</span></span></figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.2.1.1" class="ltx_tr">
<th id="S4.T3.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;">model</th>
<th id="S4.T3.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;">PA-MPJPE</th>
<th id="S4.T3.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;">Accel</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.2.2.1" class="ltx_tr">
<td id="S4.T3.2.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">w/o flow</td>
<td id="S4.T3.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">54.7</td>
<td id="S4.T3.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">12.9</td>
</tr>
<tr id="S4.T3.2.3.2" class="ltx_tr">
<td id="S4.T3.2.3.2.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">w/ flow</td>
<td id="S4.T3.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">52.7</td>
<td id="S4.T3.2.3.2.3" class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">13.2</td>
</tr>
<tr id="S4.T3.2.4.3" class="ltx_tr">
<td id="S4.T3.2.4.3.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">w/ flow + flow loss</td>
<td id="S4.T3.2.4.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span id="S4.T3.2.4.3.2.1" class="ltx_text ltx_font_bold">52.9</span></td>
<td id="S4.T3.2.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:14.2pt;padding-right:14.2pt;"><span id="S4.T3.2.4.3.3.1" class="ltx_text ltx_font_bold">12.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.4.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Ablation study on flow.<span id="S4.T3.5.2.1" class="ltx_text ltx_font_medium"> We conduct experiments that removes flow feature and flow loss from our model.</span></span></figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2110.11680/assets/x4.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="206" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Comparison of acceleration errors between VIBE, MEVA and our method.<span id="S4.F5.4.2.1" class="ltx_text ltx_font_medium"> The top of the figure shows some samples from test images and the bottom graph is the acceleration error along the timeline for three models. Overall, our result is slightly smoother than MEVA and significantly better than VIBE.</span></span></figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation study</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.3 Comparison results â€£ 4 Experiments â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.3 Comparison results â€£ 4 Experiments â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show the ablation study results with and without each component. For each experiment, we use 3DPW, MPI-INF-3DHP and Human3.6M for training, and 3DPW for evaluation.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p"><span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_bold">Effectiveness of Transformer</span>. To single out the improvement introduced by our transformer based temporal encoder, we revert the temporal encoder into GRU and compare it with our model. Similarly, we also use regressor from Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> and our transformer-based regressor to prove the effectiveness of our transformer regressor. TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.3 Comparison results â€£ 4 Experiments â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that the use of transformer as temporal encoder not only improves the accuracy of reconstruction but also provides smoother results. It indicates that transformer can better understand the complexity and variability of real human motion.
In addition, our transformer-based regressor significantly outperforms HMR regressor by 0.6% on PA-MPJPE and 37.5% on acceleration error. This demonstrates that our transformer regressor is able to predict more reasonable SMPL parameters.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">Effectiveness of optical flow</span>. We perform additional experiments to demonstrate the benefit of dense motion cues - optical flow. Here we remove human3.6M from training set. We also remove the flow-CNN feature and only use image feature to predict SMPL parameters. TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.3 Comparison results â€£ 4 Experiments â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the comparison between our model with and without flow feature. The accuracy of our model increases after adding optical flow features while maintaining high degree of smoothness.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p"><span id="S4.SS4.p4.1.1" class="ltx_text ltx_font_bold">Effectiveness of flow loss</span>. We report the results with and without flow loss in TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.3 Comparison results â€£ 4 Experiments â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. It demonstrates that our acceleration error is reduced after using flow loss. Overall, the optical flow and flow loss together enhance the performance of model not only on the accuracy but also on the consistency.</p>
</div>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.1" class="ltx_p"><span id="S4.SS4.p5.1.1" class="ltx_text ltx_font_bold">Non-local Temporal Interaction.</span> To further understand the effectiveness of our DTS-VIBE model on temporal interaction, we visualize the attention map of transformer encoder. Non-local temporal information from input video are required to stabilize pose estimation while achieving high accuracy. Self attention mechanism of transformer can catch both long-term and short-term temporal information while GRU model from VIBE<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> focuses more on catching short term temporal information.</p>
</div>
<div id="S4.SS4.p6" class="ltx_para">
<p id="S4.SS4.p6.1" class="ltx_p">FigureÂ <a href="#S3.F4" title="Figure 4 â€£ 3.2 Motion discriminator and flow supervision â€£ 3 Architecture â€£ Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the average attention value of eight attention head of the first transformer encoder layer. We sample 1000 video sequences from 3DPW test set and visualize its self-attention map. Each pixel indicates the self attention value of the target frame with respect to the input frame. Note that different attention head focuses on different input frames. For instance, attention head (d) and (h) tend to catch information from frames far apart while (c) and (g) tend to catch information within nearby frames.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2110.11680/assets/x5.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="424" height="500" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Comparison visualization.<span id="S4.F6.4.2.1" class="ltx_text ltx_font_medium"> The first row corresponds to the origin video. The second row is the ground truth body mesh. The third and forth rows are our predicted results from camera view and alternate view. The fifth and sixth rows are VIBE results from camera view and alternate view.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we introduce a two-stream 3D human reconstruction model named Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation (DTS-VIBE), which consists of two-stream encoder, transformer-based regressor and motion discriminator. DTS-VIBE avoids extra inputs other than RGB. Additionally, we introduce a new flow loss to refine our model. Extensive experiments demonstrate the necessity and effectiveness of virtual multi-modality fusion in 3D human reconstruction. Furthermore, our model outperforms current state-of-the-art algorithms on 3D human reconstruction by a signiï¬cant margin.
</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
M.Â Andriluka, U.Â Iqbal, E.Â Insafutdinov, L.Â Pishchulin, A.Â Milan, J.Â Gall, and
B.Â Schiele.

</span>
<span class="ltx_bibblock">Posetrack: A benchmark for human pose estimation and tracking.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 5167â€“5176, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
D.Â Anguelov, P.Â Srinivasan, D.Â Koller, S.Â Thrun, J.Â Rodgers, and J.Â Davis.

</span>
<span class="ltx_bibblock">Scape: shape completion and animation of people.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">ACM SIGGRAPH 2005 Papers</span>, pages 408â€“416. 2005.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A.Â Arnab, C.Â Doersch, and A.Â Zisserman.

</span>
<span class="ltx_bibblock">Exploiting temporal context for 3d human pose estimation in the wild.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 3395â€“3404, 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
F.Â Bogo, A.Â Kanazawa, C.Â Lassner, P.Â Gehler, J.Â Romero, and M.Â J. Black.

</span>
<span class="ltx_bibblock">Keep it smpl: Automatic estimation of 3d human pose and shape from a
single image.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">European conference on computer vision</span>, pages 561â€“578.
Springer, 2016.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
K.Â Cho, B.Â VanÂ MerriÃ«nboer, C.Â Gulcehre, D.Â Bahdanau, F.Â Bougares,
H.Â Schwenk, and Y.Â Bengio.

</span>
<span class="ltx_bibblock">Learning phrase representations using rnn encoder-decoder for
statistical machine translation.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1406.1078</span>, 2014.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
H.Â Choi, G.Â Moon, and K.Â M. Lee.

</span>
<span class="ltx_bibblock">Pose2mesh: Graph convolutional network for 3d human pose and mesh
recovery from a 2d human pose.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">European Conference on Computer Vision</span>, pages 769â€“787.
Springer, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
R.Â Christoph and F.Â A. Pinz.

</span>
<span class="ltx_bibblock">Spatiotemporal residual networks for video action recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, pages
3468â€“3476, 2016.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
R.Â Dabral, A.Â Mundhada, U.Â Kusupati, S.Â Afaque, A.Â Sharma, and A.Â Jain.

</span>
<span class="ltx_bibblock">Learning 3d human pose from structure and motion.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proceedings of the European Conference on Computer Vision
(ECCV)</span>, pages 668â€“683, 2018.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
A.Â Diba, V.Â Sharma, and L.Â VanÂ Gool.

</span>
<span class="ltx_bibblock">Deep temporal linear encoding networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on Computer Vision and
Pattern Recognition</span>, pages 2329â€“2338, 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
C.Â Doersch and A.Â Zisserman.

</span>
<span class="ltx_bibblock">Sim2real transfer learning for 3d human pose estimation: motion to
the rescue.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1907.02499</span>, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
X.Â Dong, S.-I. Yu, X.Â Weng, S.-E. Wei, Y.Â Yang, and Y.Â Sheikh.

</span>
<span class="ltx_bibblock">Supervision-by-registration: An unsupervised approach to improve the
precision of facial landmark detectors.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 360â€“368, 2018.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M.Â R.Â I. Hossain and J.Â J. Little.

</span>
<span class="ltx_bibblock">Exploiting temporal information for 3d human pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the European Conference on Computer Vision
(ECCV)</span>, pages 68â€“84, 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
C.Â Ionescu, D.Â Papava, V.Â Olaru, and C.Â Sminchisescu.

</span>
<span class="ltx_bibblock">Human3. 6m: Large scale datasets and predictive methods for 3d human
sensing in natural environments.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</span>,
36(7):1325â€“1339, 2013.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A.Â Kanazawa, M.Â J. Black, D.Â W. Jacobs, and J.Â Malik.

</span>
<span class="ltx_bibblock">End-to-end recovery of human shape and pose.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 7122â€“7131, 2018.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A.Â Kanazawa, J.Â Y. Zhang, P.Â Felsen, and J.Â Malik.

</span>
<span class="ltx_bibblock">Learning 3d human dynamics from video.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 5614â€“5623, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
D.Â P. Kingma and J.Â Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1412.6980</span>, 2014.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
M.Â Kocabas, N.Â Athanasiou, and M.Â J. Black.

</span>
<span class="ltx_bibblock">Vibe: Video inference for human body pose and shape estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 5253â€“5263, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
N.Â Kolotouros, G.Â Pavlakos, M.Â J. Black, and K.Â Daniilidis.

</span>
<span class="ltx_bibblock">Learning to reconstruct 3d human pose and shape via model-fitting in
the loop.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span>, pages 2252â€“2261, 2019.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
N.Â Kolotouros, G.Â Pavlakos, and K.Â Daniilidis.

</span>
<span class="ltx_bibblock">Convolutional mesh regression for single-image human shape
reconstruction.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 4501â€“4510, 2019.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Z.Â Lan, Y.Â Zhu, A.Â G. Hauptmann, and S.Â Newsam.

</span>
<span class="ltx_bibblock">Deep local video feature for action recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition workshops</span>, pages 1â€“7, 2017.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
P.Â Liu, M.Â Lyu, I.Â King, and J.Â Xu.

</span>
<span class="ltx_bibblock">Selflow: Self-supervised learning of optical flow.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span>, June 2019.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
M.Â Loper, N.Â Mahmood, J.Â Romero, G.Â Pons-Moll, and M.Â J. Black.

</span>
<span class="ltx_bibblock">Smpl: A skinned multi-person linear model.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">ACM transactions on graphics (TOG)</span>, 34(6):1â€“16, 2015.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Z.Â Luo, S.Â A. Golestaneh, and K.Â M. Kitani.

</span>
<span class="ltx_bibblock">3d human motion estimation via motion compression and refinement.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Proceedings of the Asian Conference on Computer Vision</span>,
2020.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
N.Â Mahmood, N.Â Ghorbani, N.Â F. Troje, G.Â Pons-Moll, and M.Â J. Black.

</span>
<span class="ltx_bibblock">Amass: Archive of motion capture as surface shapes.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span>, pages 5442â€“5451, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
D.Â Mehta, H.Â Rhodin, D.Â Casas, P.Â Fua, O.Â Sotnychenko, W.Â Xu, and C.Â Theobalt.

</span>
<span class="ltx_bibblock">Monocular 3d human pose estimation in the wild using improved cnn
supervision.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">2017 international conference on 3D vision (3DV)</span>, pages
506â€“516. IEEE, 2017.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
D.Â Mehta, O.Â Sotnychenko, F.Â Mueller, W.Â Xu, S.Â Sridhar, G.Â Pons-Moll, and
C.Â Theobalt.

</span>
<span class="ltx_bibblock">Single-shot multi-person 3d pose estimation from monocular rgb.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">2018 International Conference on 3D Vision (3DV)</span>, pages
120â€“130. IEEE, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
G.Â Moon and K.Â M. Lee.

</span>
<span class="ltx_bibblock">I2l-meshnet: Image-to-lixel prediction network for accurate 3d human
pose and mesh estimation from a single rgb image.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2008.03713</span>, 2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
A.Â A. Osman, T.Â Bolkart, and M.Â J. Black.

</span>
<span class="ltx_bibblock">Star: Sparse trained articulated human body regressor.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2008.08535</span>, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
G.Â Pavlakos, V.Â Choutas, N.Â Ghorbani, T.Â Bolkart, A.Â A. Osman, D.Â Tzionas, and
M.Â J. Black.

</span>
<span class="ltx_bibblock">Expressive body capture: 3d hands, face, and body from a single
image.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 10975â€“10985, 2019.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
D.Â Pavllo, C.Â Feichtenhofer, D.Â Grangier, and M.Â Auli.

</span>
<span class="ltx_bibblock">3d human pose estimation in video with temporal convolutions and
semi-supervised training.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 7753â€“7762, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
O.Â Russakovsky, J.Â Deng, H.Â Su, J.Â Krause, S.Â Satheesh, S.Â Ma, Z.Â Huang,
A.Â Karpathy, A.Â Khosla, M.Â Bernstein, etÂ al.

</span>
<span class="ltx_bibblock">Imagenet large scale visual recognition challenge.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">International journal of computer vision</span>, 115(3):211â€“252,
2015.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S.Â Saito, Z.Â Huang, R.Â Natsume, S.Â Morishima, A.Â Kanazawa, and H.Â Li.

</span>
<span class="ltx_bibblock">Pifu: Pixel-aligned implicit function for high-resolution clothed
human digitization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</span>, pages 2304â€“2314, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
K.Â Simonyan and A.Â Zisserman.

</span>
<span class="ltx_bibblock">Two-stream convolutional networks for action recognition in videos.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1406.2199</span>, 2014.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
G.Â Varol, D.Â Ceylan, B.Â Russell, J.Â Yang, E.Â Yumer, I.Â Laptev, and C.Â Schmid.

</span>
<span class="ltx_bibblock">Bodynet: Volumetric inference of 3d human body shapes.

</span>
<span class="ltx_bibblock">In <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Proceedings of the European Conference on Computer Vision
(ECCV)</span>, pages 20â€“36, 2018.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
A.Â Vaswani, N.Â Shazeer, N.Â Parmar, J.Â Uszkoreit, L.Â Jones, A.Â N. Gomez,
L.Â Kaiser, and I.Â Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1706.03762</span>, 2017.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
T.Â von Marcard, R.Â Henschel, M.Â J. Black, B.Â Rosenhahn, and G.Â Pons-Moll.

</span>
<span class="ltx_bibblock">Recovering accurate 3d human pose in the wild using imus and a moving
camera.

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Proceedings of the European Conference on Computer Vision
(ECCV)</span>, pages 601â€“617, 2018.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
P.Â Yao, Z.Â Fang, F.Â Wu, Y.Â Feng, and J.Â Li.

</span>
<span class="ltx_bibblock">Densebody: Directly regressing dense 3d human pose and shape from a
single color image.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1903.10153</span>, 2019.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
W.Â Zhang, M.Â Zhu, and K.Â G. Derpanis.

</span>
<span class="ltx_bibblock">From actemes to action: A strongly-supervised representation for
detailed action understanding.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision</span>, pages 2248â€“2255, 2013.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2110.11679" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2110.11680" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2110.11680">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2110.11680" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2110.11681" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar  3 23:19:18 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
