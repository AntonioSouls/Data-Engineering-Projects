<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2101.01659] Spatial Attention Improves Iterative 6D Object Pose Estimation</title><meta property="og:description" content="The task of estimating the 6D pose of an object from RGB images can be broken down into two main steps: an initial pose estimation step, followed by a refinement procedure to correctly register the object and its obserâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spatial Attention Improves Iterative 6D Object Pose Estimation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Spatial Attention Improves Iterative 6D Object Pose Estimation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2101.01659">

<!--Generated on Wed Mar 13 11:05:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Spatial Attention Improves Iterative 6D Object Pose Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Stefan StevÅ¡iÄ‡ â€ƒOtmar Hilliges
<br class="ltx_break">Department of Computer Science, ETH ZÃ¼rich, Switzerland
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{stefan.stevsic, otmar.hilliges}@inf.ethz.ch</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">The task of estimating the 6D pose of an object from RGB images can be broken down into two main steps: an initial pose estimation step, followed by a refinement procedure to correctly register the object and its observation.
In this paper, we propose a new method for 6D pose estimation refinement from RGB images.
To achieve high accuracy of the final estimate, the observation and a rendered model need to be aligned.
Our main insight is that after the initial pose estimate, it is important to pay attention to distinct spatial features of the object in order to improve the estimation accuracy during alignment.
Furthermore, parts of the object that are occluded in the image should be given less weight during the alignment process.
Most state-of-the-art refinement approaches do not allow for this fine-grained reasoning and can not fully leverage the structure of the problem.
In contrast, we propose a novel neural network architecture built around a spatial attention mechanism that identifies and leverages information about spatial details during pose refinement. We experimentally show that this approach learns to attend to salient spatial features and learns to ignore occluded parts of the object, leading to better pose estimation across datasets.
We conduct experiments on standard benchmark datasets for 6D pose estimation (LineMOD and Occlusion LineMOD) and outperform previous state-of-the-art methods.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Detecting objects in images and estimating their pose from 2D images is one of the core problems in computer vision and has many applications in downstream tasks.
With the advent of deep learning approaches, rapid progress on the task of object detection has been achieved (e.g., YOLO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, Fast R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, and Mask R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>).
However, for applications such as robotic manipulation, augmented reality and autonomous driving, it is essential to recover the full 6D pose of the object.
To solve this challenging task, a variety of methods such as BB8 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, PoseCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, PVNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> and DPOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> have been proposed recently. The 6D pose estimation task is typically separated into two subtasks: initial detection and pose estimation of objects from raw images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and subsequent pose refinement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. With modern CNN architectures, the one-shot pose estimation sub-task has saturated somewhat <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> but such methods have not yet been able to precisely align spatial details, leaving much room for improvement via iterative pose refinement, which is the focus of our work.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Traditionally initial pose estimation and refinement, often via the iterative closest point (ICP) algorithm, have been treated separately.
More recently, several methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> address the refinement problem using deep learning approaches, leading to superior performance compared to ICP refinement.
The DPOD refiner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> leverages a pre-trained ResNet model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and leverages it for 6D pose refinement in a non-iterative fashion.
DeepIM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> utilizes an iterative strategy to refine the prediction through several stages.
While achieving good accuracy neither of these methods explicitly leverages existing structure of the alignment process. For example, accurate alignment of 3D model and 2D image observation requires consideration of high-frequency spatial features. It has also been shown that excluding occlusions from the input data leads to more accurate predictions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. However, existing pose refinement approaches do not explicitly take this into consideration.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2101.01659/assets/figures/teaser_fig_with_in.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="672" height="139" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Iterative pose refinement. The goal of the refinement process is to align the model and the input image. At each iteration stage, we focus on aligning a different feature. At the first iteration, we align top edges; at the second, we align the front point of the driller; at the third, we scale the model to cover non-overlapping details. This results in perfect alignment.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To address this issue we propose a novel deep neural network architecture that learns to consider fine-grained spatial details and learns to reason about occlusions in the scene.
An important insight is that a small number of pixels are sufficient to align the model to the input image. Humans would perform this task by first aligning some characteristic feature, for example, corners of the object. Then, geometric detail is leveraged to adjust for scale and the entire process would be repeated iteratively, by focusing on details that most reliably show the displacement (see Fig. <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
Inspired by this scheme, SoA methods for one-shot pose estimation rely on RANSAC to extract the most reliable points for prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.
We also leverage the idea that a small number of specific features is important for alignment, but we use an attention mechanism to learn to identify these automatically. We introduce an attention model that isolates reliable features, while rejecting the clutter. This makes the entire pipeline differentiable and allows for application of the inlier features to direct pose refinement which would not be possible via RANSAC. Furthermore, a fully differentiable approach allows for fine-tuning of the pose estimator for a given downstream task.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">When overlaying the image and the rendered prediction, similar points from real and rendered images lie nearby. Therefore, a spatial attention mechanism can be learned to identify the details which give the best position estimation if the final registration error is backpropagated through the entire network. As we experimentally show in Sec.Â <a href="#S5.SS6" title="5.6 Analysis of the Attention Model â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.6</span></a>, the attention mechanism focuses on object outlines, which contain a lot of discriminative details. Outline edges are a common choice for ICP-based refinement from RGB images. We use a soft attention mechanism, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, which results in a fully differentiable approach that can be trained using standard loss functions. As a feature extracting backbone, we use U-shaped DenseNet from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. DenseNet produces good results even when trained on small datasets and its U-shaped variant shows excellent performance on the semantic segmentation task. This task requires correctly classifying small details, which is also useful in our task because the attention needs to detect particular details. We test our approach in the single-stage and iterative approach settings. The iterative approach enables the attention to specialize for specific details in each iteration. This leads to state-of-the-art performance on the standard datasets for 6D pose estimation.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">More specifically, we make the following contributions:

<span id="S1.I1" class="ltx_inline-enumerate">
<span id="S1.I1.i1" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span id="S1.I1.i1.1" class="ltx_text">We introduce a new neural network model for 6D pose refinement that leverages an attention mechanism.
</span></span>
<span id="S1.I1.i2" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span id="S1.I1.i2.1" class="ltx_text">We provide a detailed experimental evaluation of our model on standard datasets for 6D pose estimation in single-stage and multi-stage settings. We show that our model leads to state-of-the-art performance on these datasets.
</span></span>
<span id="S1.I1.i3" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span id="S1.I1.i3.1" class="ltx_text">We experimentally show that attention mechanism enables the network to isolate the distinctive object details and exclude occlusions from the prediction.
</span></span>
</span></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The task of 6D pose estimation has been a long-standing problem in Computer Vision. Early methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> mostly rely on RGB-D images because it is possible to recover scale via depth information. The most popular dataset for evaluation of methods has been LineMOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. However, the LineMOD dataset does not contain occluded test objects. When the object is occluded, it is much harder to distinguish between the object of interest and occlusions. Thus, the accuracy of estimation on occlusion data is far below the non-occluded case <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. The most popular dataset for evaluation on the occlusion task has been Occlusion LineMOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Depth information is crucial to recover the scale of the object since the scale is hard to recover from RGB images due to perspective projection. Therefore, 6D pose estimation from RGB images is an even more challenging problem. With the advent of deep learning approaches, 6D pose estimation purely from RGB images got more attention. The majority of the methods focus on initial detection and pose estimation. Some methods such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> rely on end-to-end approach, while other leverage the object detection pipelines <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. However, more accurate approaches rely on keypoint prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and compute pose via PnP algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. State-of-the-art methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> do not use hand-designed keypoints. They predict a correspondence map for every object pixel. Then the best minimal set of points is selected via the RANSAC algorithm. The 6D pose is computed via the PnP algorithm form the best set of points. It is essential to notice that selecting a specific set of points is more beneficial than using all available points. Methods that focus on the occlusion task, such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, explicitly select regions that are not occluded via segmentation mask. Excluding pixels that are not part of the object of interest always results in higher accuracy.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">In the domain of pose refinement, the most common method is ICP. It is an optimization-based method that iteratively improves the position by minimizing the distance between the model features and image data. Usually, the cost function minimizes the distance between the point cloud generated from the depth channel and 3D points of the object model. In the case of RGB data, the cost function minimizes the distance between the edges in the image and that of the model. Recently, few deep learning approaches such as DeepIM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and DPOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> tackle the refinement task. Both approaches rely on pretrained models. DeepIM uses FlowNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> as the base model, which is designed for two image inputs. DPOD modifies the ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> architecture to feed in two images. Furthermore, DeepIM boosts the performance by iteratively improving the prediction. The main idea of both papers is to reuse the weights trained on big datasets and transfer it to the 6D pose estimation task. However, these methods do not leverage the structure of the problem. Contrary, papers for initial pose estimation use advanced techniques, such as RANSAC for keypoint selection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> or masking for removing occlusions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">It has been shown that attention mechanisms improve the performance of deep neural network models in different domains such as machine translation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, visual recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, object segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, tracking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and generative models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. The goal of attention mechanism is to extract the most relevant information form the feature vector. In the case of image data, a different attention map is applied for every query pixel separately <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, or the single attention map is used to extract global information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Although all these attention mechanisms bear similarity, the attention mechanism dramatically depends on the domain where it is applied. For example, using the attention model to establish a connection between each pixel and the rest of the image shows the best results on image segmentation task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, while using a single attention map performs better on visual recognition tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. In the 6D pose estimation area, the use of attention mechanisms has not been explored.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2101.01659/assets/figures/model_2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="583" height="221" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Architecture overview. Left: The network takes two input images and produces a set of relative pose update parameters (<math id="S3.F2.4.m1.2" class="ltx_Math" alttext="x,y" display="inline"><semantics id="S3.F2.4.m1.2b"><mrow id="S3.F2.4.m1.2.3.2" xref="S3.F2.4.m1.2.3.1.cmml"><mi id="S3.F2.4.m1.1.1" xref="S3.F2.4.m1.1.1.cmml">x</mi><mo id="S3.F2.4.m1.2.3.2.1" xref="S3.F2.4.m1.2.3.1.cmml">,</mo><mi id="S3.F2.4.m1.2.2" xref="S3.F2.4.m1.2.2.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.4.m1.2c"><list id="S3.F2.4.m1.2.3.1.cmml" xref="S3.F2.4.m1.2.3.2"><ci id="S3.F2.4.m1.1.1.cmml" xref="S3.F2.4.m1.1.1">ğ‘¥</ci><ci id="S3.F2.4.m1.2.2.cmml" xref="S3.F2.4.m1.2.2">ğ‘¦</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.4.m1.2d">x,y</annotation></semantics></math> translation, scale <math id="S3.F2.5.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.F2.5.m2.1b"><mi id="S3.F2.5.m2.1.1" xref="S3.F2.5.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.F2.5.m2.1c"><ci id="S3.F2.5.m2.1.1.cmml" xref="S3.F2.5.m2.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.5.m2.1d">s</annotation></semantics></math> and rotation <math id="S3.F2.6.m3.1" class="ltx_Math" alttext="\mathbf{R}_{\Delta}" display="inline"><semantics id="S3.F2.6.m3.1b"><msub id="S3.F2.6.m3.1.1" xref="S3.F2.6.m3.1.1.cmml"><mi id="S3.F2.6.m3.1.1.2" xref="S3.F2.6.m3.1.1.2.cmml">ğ‘</mi><mi mathvariant="normal" id="S3.F2.6.m3.1.1.3" xref="S3.F2.6.m3.1.1.3.cmml">Î”</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.6.m3.1c"><apply id="S3.F2.6.m3.1.1.cmml" xref="S3.F2.6.m3.1.1"><csymbol cd="ambiguous" id="S3.F2.6.m3.1.1.1.cmml" xref="S3.F2.6.m3.1.1">subscript</csymbol><ci id="S3.F2.6.m3.1.1.2.cmml" xref="S3.F2.6.m3.1.1.2">ğ‘</ci><ci id="S3.F2.6.m3.1.1.3.cmml" xref="S3.F2.6.m3.1.1.3">Î”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.m3.1d">\mathbf{R}_{\Delta}</annotation></semantics></math>). Right: Details of the attention mechanism used in our model.</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We propose a novel neural network model for 6D pose refinement. Inspired by attention models in object detection and tracking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, we leverage an attention mechanism to improve the refinement of 6D pose estimation.
We show that the spatial attention mechanism leads to the rejection of pixels from occluded object parts. Furthermore, the attention focuses only on a few sub-regions with discriminative details, which leads to better pose estimation overall. Importantly, we train the model for the downstream task of 6D pose estimation and do not use any specific loss terms to train the attention mechanism.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Neural Network Model</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">At the initial step, we obtain the object pose from an existing one-shot pose estimation algorithm, such as PVNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Our goal is to refine this initial object pose. The inputs to our network are two RGB images: the image crop around the object of interest, and the object rendered at the initial pose estimate (see Fig. <a href="#S3.F2" title="Figure 2 â€£ 3 Method â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). To crop the image around the object, we project the object position to the image plane and select the crop area around the projection point. The rendered image provides initial pose information to the network. The main idea behind this setup is that the network learns to align these two images incrementally.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">As the backbone of our model, we use DenseNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> (see Fig. <a href="#S3.F2" title="Figure 2 â€£ 3 Method â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). More precisely, we leverage DenseNet variant designed for semantic segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. The model uses skip connections to preserve detailed information in the up-stream. In our case, this is important since the attention model needs to detect fine spatial details. We use the full down-stream of the model from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and the first three blocks of the up-stream. Since the attention mechanism needs to identify image regions, we do not need the full resolution at the output. By using fewer layers we gain computational efficiency. Our backbone model already attains reasonable performance even when trained on the relatively small pose estimation datasets. This is due to the smaller number of parameters compared to ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> or VGG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.3" class="ltx_p">We separate the output into three streams: x-y displacement in the image plane <math id="S3.SS1.p3.1.m1.2" class="ltx_Math" alttext="v_{x},v_{y}" display="inline"><semantics id="S3.SS1.p3.1.m1.2a"><mrow id="S3.SS1.p3.1.m1.2.2.2" xref="S3.SS1.p3.1.m1.2.2.3.cmml"><msub id="S3.SS1.p3.1.m1.1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.1.1.2.cmml">v</mi><mi id="S3.SS1.p3.1.m1.1.1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.1.1.3.cmml">x</mi></msub><mo id="S3.SS1.p3.1.m1.2.2.2.3" xref="S3.SS1.p3.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS1.p3.1.m1.2.2.2.2" xref="S3.SS1.p3.1.m1.2.2.2.2.cmml"><mi id="S3.SS1.p3.1.m1.2.2.2.2.2" xref="S3.SS1.p3.1.m1.2.2.2.2.2.cmml">v</mi><mi id="S3.SS1.p3.1.m1.2.2.2.2.3" xref="S3.SS1.p3.1.m1.2.2.2.2.3.cmml">y</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.2b"><list id="S3.SS1.p3.1.m1.2.2.3.cmml" xref="S3.SS1.p3.1.m1.2.2.2"><apply id="S3.SS1.p3.1.m1.1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.1.1.2">ğ‘£</ci><ci id="S3.SS1.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.1.1.3">ğ‘¥</ci></apply><apply id="S3.SS1.p3.1.m1.2.2.2.2.cmml" xref="S3.SS1.p3.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.2.2.2.2.1.cmml" xref="S3.SS1.p3.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS1.p3.1.m1.2.2.2.2.2">ğ‘£</ci><ci id="S3.SS1.p3.1.m1.2.2.2.2.3.cmml" xref="S3.SS1.p3.1.m1.2.2.2.2.3">ğ‘¦</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.2c">v_{x},v_{y}</annotation></semantics></math>, scaling <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">s</annotation></semantics></math>, and rotation increments <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{R}_{\Delta}" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">ğ‘</mi><mi mathvariant="normal" id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">Î”</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">ğ‘</ci><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">Î”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\mathbf{R}_{\Delta}</annotation></semantics></math> (see Fig. <a href="#S3.F2" title="Figure 2 â€£ 3 Method â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). As these values relies on different kinds of information, it is advantageous to keep them separate. For example, x-y displacement requires only one point for perfect alignment, while scaling requires at least two points. For each stream we apply separate attention blocks, allowing each attention map to identify the most relevant features for their respective output.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.12" class="ltx_p">Our intention is to have an attention mechanism that can extract the discriminative details and reject the clutter, which is crucial for the 6D pose estimation task.
Each attention block takes the output <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="\textbf{l}_{in}\in\mathbb{R}^{H\times W\times d_{in}}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mrow id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><msub id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.1.m1.1.1.2.2" xref="S3.SS1.p4.1.m1.1.1.2.2a.cmml">l</mtext><mrow id="S3.SS1.p4.1.m1.1.1.2.3" xref="S3.SS1.p4.1.m1.1.1.2.3.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2.3.2" xref="S3.SS1.p4.1.m1.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.1.m1.1.1.2.3.1" xref="S3.SS1.p4.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.1.m1.1.1.2.3.3" xref="S3.SS1.p4.1.m1.1.1.2.3.3.cmml">n</mi></mrow></msub><mo id="S3.SS1.p4.1.m1.1.1.1" xref="S3.SS1.p4.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml"><mi id="S3.SS1.p4.1.m1.1.1.3.2" xref="S3.SS1.p4.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p4.1.m1.1.1.3.3" xref="S3.SS1.p4.1.m1.1.1.3.3.cmml"><mi id="S3.SS1.p4.1.m1.1.1.3.3.2" xref="S3.SS1.p4.1.m1.1.1.3.3.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.1.m1.1.1.3.3.1" xref="S3.SS1.p4.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p4.1.m1.1.1.3.3.3" xref="S3.SS1.p4.1.m1.1.1.3.3.3.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.1.m1.1.1.3.3.1a" xref="S3.SS1.p4.1.m1.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS1.p4.1.m1.1.1.3.3.4" xref="S3.SS1.p4.1.m1.1.1.3.3.4.cmml"><mi id="S3.SS1.p4.1.m1.1.1.3.3.4.2" xref="S3.SS1.p4.1.m1.1.1.3.3.4.2.cmml">d</mi><mrow id="S3.SS1.p4.1.m1.1.1.3.3.4.3" xref="S3.SS1.p4.1.m1.1.1.3.3.4.3.cmml"><mi id="S3.SS1.p4.1.m1.1.1.3.3.4.3.2" xref="S3.SS1.p4.1.m1.1.1.3.3.4.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.1.m1.1.1.3.3.4.3.1" xref="S3.SS1.p4.1.m1.1.1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.1.m1.1.1.3.3.4.3.3" xref="S3.SS1.p4.1.m1.1.1.3.3.4.3.3.cmml">n</mi></mrow></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><in id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1.1"></in><apply id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.2.1.cmml" xref="S3.SS1.p4.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.2a.cmml" xref="S3.SS1.p4.1.m1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.1.m1.1.1.2.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2.2">l</mtext></ci><apply id="S3.SS1.p4.1.m1.1.1.2.3.cmml" xref="S3.SS1.p4.1.m1.1.1.2.3"><times id="S3.SS1.p4.1.m1.1.1.2.3.1.cmml" xref="S3.SS1.p4.1.m1.1.1.2.3.1"></times><ci id="S3.SS1.p4.1.m1.1.1.2.3.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2.3.2">ğ‘–</ci><ci id="S3.SS1.p4.1.m1.1.1.2.3.3.cmml" xref="S3.SS1.p4.1.m1.1.1.2.3.3">ğ‘›</ci></apply></apply><apply id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.3.1.cmml" xref="S3.SS1.p4.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.3.2.cmml" xref="S3.SS1.p4.1.m1.1.1.3.2">â„</ci><apply id="S3.SS1.p4.1.m1.1.1.3.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3"><times id="S3.SS1.p4.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.1"></times><ci id="S3.SS1.p4.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.2">ğ»</ci><ci id="S3.SS1.p4.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.3">ğ‘Š</ci><apply id="S3.SS1.p4.1.m1.1.1.3.3.4.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.3.3.4.1.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.4">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.3.3.4.2.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.4.2">ğ‘‘</ci><apply id="S3.SS1.p4.1.m1.1.1.3.3.4.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.4.3"><times id="S3.SS1.p4.1.m1.1.1.3.3.4.3.1.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.4.3.1"></times><ci id="S3.SS1.p4.1.m1.1.1.3.3.4.3.2.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.4.3.2">ğ‘–</ci><ci id="S3.SS1.p4.1.m1.1.1.3.3.4.3.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.4.3.3">ğ‘›</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\textbf{l}_{in}\in\mathbb{R}^{H\times W\times d_{in}}</annotation></semantics></math> of the backbone and produces the output vector <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="\textbf{l}_{out}\in\mathbb{R}^{d_{out}}" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mrow id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><msub id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.2.m2.1.1.2.2" xref="S3.SS1.p4.2.m2.1.1.2.2a.cmml">l</mtext><mrow id="S3.SS1.p4.2.m2.1.1.2.3" xref="S3.SS1.p4.2.m2.1.1.2.3.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2.3.2" xref="S3.SS1.p4.2.m2.1.1.2.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.2.m2.1.1.2.3.1" xref="S3.SS1.p4.2.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.2.m2.1.1.2.3.3" xref="S3.SS1.p4.2.m2.1.1.2.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.2.m2.1.1.2.3.1a" xref="S3.SS1.p4.2.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.2.m2.1.1.2.3.4" xref="S3.SS1.p4.2.m2.1.1.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS1.p4.2.m2.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml"><mi id="S3.SS1.p4.2.m2.1.1.3.2" xref="S3.SS1.p4.2.m2.1.1.3.2.cmml">â„</mi><msub id="S3.SS1.p4.2.m2.1.1.3.3" xref="S3.SS1.p4.2.m2.1.1.3.3.cmml"><mi id="S3.SS1.p4.2.m2.1.1.3.3.2" xref="S3.SS1.p4.2.m2.1.1.3.3.2.cmml">d</mi><mrow id="S3.SS1.p4.2.m2.1.1.3.3.3" xref="S3.SS1.p4.2.m2.1.1.3.3.3.cmml"><mi id="S3.SS1.p4.2.m2.1.1.3.3.3.2" xref="S3.SS1.p4.2.m2.1.1.3.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.2.m2.1.1.3.3.3.1" xref="S3.SS1.p4.2.m2.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.2.m2.1.1.3.3.3.3" xref="S3.SS1.p4.2.m2.1.1.3.3.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.2.m2.1.1.3.3.3.1a" xref="S3.SS1.p4.2.m2.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.2.m2.1.1.3.3.3.4" xref="S3.SS1.p4.2.m2.1.1.3.3.3.4.cmml">t</mi></mrow></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><in id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1"></in><apply id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.2.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.2.2a.cmml" xref="S3.SS1.p4.2.m2.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.2.m2.1.1.2.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.2">l</mtext></ci><apply id="S3.SS1.p4.2.m2.1.1.2.3.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3"><times id="S3.SS1.p4.2.m2.1.1.2.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.1"></times><ci id="S3.SS1.p4.2.m2.1.1.2.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.2">ğ‘œ</ci><ci id="S3.SS1.p4.2.m2.1.1.2.3.3.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.3">ğ‘¢</ci><ci id="S3.SS1.p4.2.m2.1.1.2.3.4.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3.4">ğ‘¡</ci></apply></apply><apply id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p4.2.m2.1.1.3.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3.2">ğ‘‘</ci><apply id="S3.SS1.p4.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3.3"><times id="S3.SS1.p4.2.m2.1.1.3.3.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3.3.1"></times><ci id="S3.SS1.p4.2.m2.1.1.3.3.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3.3.2">ğ‘œ</ci><ci id="S3.SS1.p4.2.m2.1.1.3.3.3.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3.3.3">ğ‘¢</ci><ci id="S3.SS1.p4.2.m2.1.1.3.3.3.4.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3.3.4">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">\textbf{l}_{out}\in\mathbb{R}^{d_{out}}</annotation></semantics></math>.
In the attention block, the backbone output <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="\textbf{l}_{in}\in\mathbb{R}^{H\times W\times d_{in}}" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mrow id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml"><msub id="S3.SS1.p4.3.m3.1.1.2" xref="S3.SS1.p4.3.m3.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.3.m3.1.1.2.2" xref="S3.SS1.p4.3.m3.1.1.2.2a.cmml">l</mtext><mrow id="S3.SS1.p4.3.m3.1.1.2.3" xref="S3.SS1.p4.3.m3.1.1.2.3.cmml"><mi id="S3.SS1.p4.3.m3.1.1.2.3.2" xref="S3.SS1.p4.3.m3.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.3.m3.1.1.2.3.1" xref="S3.SS1.p4.3.m3.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.3.m3.1.1.2.3.3" xref="S3.SS1.p4.3.m3.1.1.2.3.3.cmml">n</mi></mrow></msub><mo id="S3.SS1.p4.3.m3.1.1.1" xref="S3.SS1.p4.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p4.3.m3.1.1.3" xref="S3.SS1.p4.3.m3.1.1.3.cmml"><mi id="S3.SS1.p4.3.m3.1.1.3.2" xref="S3.SS1.p4.3.m3.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p4.3.m3.1.1.3.3" xref="S3.SS1.p4.3.m3.1.1.3.3.cmml"><mi id="S3.SS1.p4.3.m3.1.1.3.3.2" xref="S3.SS1.p4.3.m3.1.1.3.3.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.3.m3.1.1.3.3.1" xref="S3.SS1.p4.3.m3.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p4.3.m3.1.1.3.3.3" xref="S3.SS1.p4.3.m3.1.1.3.3.3.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.3.m3.1.1.3.3.1a" xref="S3.SS1.p4.3.m3.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS1.p4.3.m3.1.1.3.3.4" xref="S3.SS1.p4.3.m3.1.1.3.3.4.cmml"><mi id="S3.SS1.p4.3.m3.1.1.3.3.4.2" xref="S3.SS1.p4.3.m3.1.1.3.3.4.2.cmml">d</mi><mrow id="S3.SS1.p4.3.m3.1.1.3.3.4.3" xref="S3.SS1.p4.3.m3.1.1.3.3.4.3.cmml"><mi id="S3.SS1.p4.3.m3.1.1.3.3.4.3.2" xref="S3.SS1.p4.3.m3.1.1.3.3.4.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.3.m3.1.1.3.3.4.3.1" xref="S3.SS1.p4.3.m3.1.1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.3.m3.1.1.3.3.4.3.3" xref="S3.SS1.p4.3.m3.1.1.3.3.4.3.3.cmml">n</mi></mrow></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1"><in id="S3.SS1.p4.3.m3.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1"></in><apply id="S3.SS1.p4.3.m3.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.2.1.cmml" xref="S3.SS1.p4.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.2.2a.cmml" xref="S3.SS1.p4.3.m3.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.3.m3.1.1.2.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2.2">l</mtext></ci><apply id="S3.SS1.p4.3.m3.1.1.2.3.cmml" xref="S3.SS1.p4.3.m3.1.1.2.3"><times id="S3.SS1.p4.3.m3.1.1.2.3.1.cmml" xref="S3.SS1.p4.3.m3.1.1.2.3.1"></times><ci id="S3.SS1.p4.3.m3.1.1.2.3.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2.3.2">ğ‘–</ci><ci id="S3.SS1.p4.3.m3.1.1.2.3.3.cmml" xref="S3.SS1.p4.3.m3.1.1.2.3.3">ğ‘›</ci></apply></apply><apply id="S3.SS1.p4.3.m3.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.3.1.cmml" xref="S3.SS1.p4.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.3.2.cmml" xref="S3.SS1.p4.3.m3.1.1.3.2">â„</ci><apply id="S3.SS1.p4.3.m3.1.1.3.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3"><times id="S3.SS1.p4.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.1"></times><ci id="S3.SS1.p4.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.2">ğ»</ci><ci id="S3.SS1.p4.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.3">ğ‘Š</ci><apply id="S3.SS1.p4.3.m3.1.1.3.3.4.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.3.3.4.1.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.4">subscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.3.3.4.2.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.4.2">ğ‘‘</ci><apply id="S3.SS1.p4.3.m3.1.1.3.3.4.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.4.3"><times id="S3.SS1.p4.3.m3.1.1.3.3.4.3.1.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.4.3.1"></times><ci id="S3.SS1.p4.3.m3.1.1.3.3.4.3.2.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.4.3.2">ğ‘–</ci><ci id="S3.SS1.p4.3.m3.1.1.3.3.4.3.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3.3.4.3.3">ğ‘›</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">\textbf{l}_{in}\in\mathbb{R}^{H\times W\times d_{in}}</annotation></semantics></math> is processed in two streams. The first stream produces the attention tensor <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="\textbf{a}\in\mathbb{R}^{H\times W\times 1}" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><mrow id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.4.m4.1.1.2" xref="S3.SS1.p4.4.m4.1.1.2a.cmml">a</mtext><mo id="S3.SS1.p4.4.m4.1.1.1" xref="S3.SS1.p4.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p4.4.m4.1.1.3" xref="S3.SS1.p4.4.m4.1.1.3.cmml"><mi id="S3.SS1.p4.4.m4.1.1.3.2" xref="S3.SS1.p4.4.m4.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p4.4.m4.1.1.3.3" xref="S3.SS1.p4.4.m4.1.1.3.3.cmml"><mi id="S3.SS1.p4.4.m4.1.1.3.3.2" xref="S3.SS1.p4.4.m4.1.1.3.3.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.4.m4.1.1.3.3.1" xref="S3.SS1.p4.4.m4.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p4.4.m4.1.1.3.3.3" xref="S3.SS1.p4.4.m4.1.1.3.3.3.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.4.m4.1.1.3.3.1a" xref="S3.SS1.p4.4.m4.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p4.4.m4.1.1.3.3.4" xref="S3.SS1.p4.4.m4.1.1.3.3.4.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><apply id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1"><in id="S3.SS1.p4.4.m4.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1.1"></in><ci id="S3.SS1.p4.4.m4.1.1.2a.cmml" xref="S3.SS1.p4.4.m4.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.4.m4.1.1.2.cmml" xref="S3.SS1.p4.4.m4.1.1.2">a</mtext></ci><apply id="S3.SS1.p4.4.m4.1.1.3.cmml" xref="S3.SS1.p4.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.1.1.3.1.cmml" xref="S3.SS1.p4.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.4.m4.1.1.3.2.cmml" xref="S3.SS1.p4.4.m4.1.1.3.2">â„</ci><apply id="S3.SS1.p4.4.m4.1.1.3.3.cmml" xref="S3.SS1.p4.4.m4.1.1.3.3"><times id="S3.SS1.p4.4.m4.1.1.3.3.1.cmml" xref="S3.SS1.p4.4.m4.1.1.3.3.1"></times><ci id="S3.SS1.p4.4.m4.1.1.3.3.2.cmml" xref="S3.SS1.p4.4.m4.1.1.3.3.2">ğ»</ci><ci id="S3.SS1.p4.4.m4.1.1.3.3.3.cmml" xref="S3.SS1.p4.4.m4.1.1.3.3.3">ğ‘Š</ci><cn type="integer" id="S3.SS1.p4.4.m4.1.1.3.3.4.cmml" xref="S3.SS1.p4.4.m4.1.1.3.3.4">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">\textbf{a}\in\mathbb{R}^{H\times W\times 1}</annotation></semantics></math> whereas the second produces a feature tensor <math id="S3.SS1.p4.5.m5.1" class="ltx_Math" alttext="\textbf{l}_{f}\in\mathbb{R}^{H\times W\times d_{f}}" display="inline"><semantics id="S3.SS1.p4.5.m5.1a"><mrow id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml"><msub id="S3.SS1.p4.5.m5.1.1.2" xref="S3.SS1.p4.5.m5.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.5.m5.1.1.2.2" xref="S3.SS1.p4.5.m5.1.1.2.2a.cmml">l</mtext><mi id="S3.SS1.p4.5.m5.1.1.2.3" xref="S3.SS1.p4.5.m5.1.1.2.3.cmml">f</mi></msub><mo id="S3.SS1.p4.5.m5.1.1.1" xref="S3.SS1.p4.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p4.5.m5.1.1.3" xref="S3.SS1.p4.5.m5.1.1.3.cmml"><mi id="S3.SS1.p4.5.m5.1.1.3.2" xref="S3.SS1.p4.5.m5.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p4.5.m5.1.1.3.3" xref="S3.SS1.p4.5.m5.1.1.3.3.cmml"><mi id="S3.SS1.p4.5.m5.1.1.3.3.2" xref="S3.SS1.p4.5.m5.1.1.3.3.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.5.m5.1.1.3.3.1" xref="S3.SS1.p4.5.m5.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p4.5.m5.1.1.3.3.3" xref="S3.SS1.p4.5.m5.1.1.3.3.3.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.5.m5.1.1.3.3.1a" xref="S3.SS1.p4.5.m5.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS1.p4.5.m5.1.1.3.3.4" xref="S3.SS1.p4.5.m5.1.1.3.3.4.cmml"><mi id="S3.SS1.p4.5.m5.1.1.3.3.4.2" xref="S3.SS1.p4.5.m5.1.1.3.3.4.2.cmml">d</mi><mi id="S3.SS1.p4.5.m5.1.1.3.3.4.3" xref="S3.SS1.p4.5.m5.1.1.3.3.4.3.cmml">f</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1"><in id="S3.SS1.p4.5.m5.1.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1.1"></in><apply id="S3.SS1.p4.5.m5.1.1.2.cmml" xref="S3.SS1.p4.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.1.2.1.cmml" xref="S3.SS1.p4.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.5.m5.1.1.2.2a.cmml" xref="S3.SS1.p4.5.m5.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.5.m5.1.1.2.2.cmml" xref="S3.SS1.p4.5.m5.1.1.2.2">l</mtext></ci><ci id="S3.SS1.p4.5.m5.1.1.2.3.cmml" xref="S3.SS1.p4.5.m5.1.1.2.3">ğ‘“</ci></apply><apply id="S3.SS1.p4.5.m5.1.1.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.1.3.1.cmml" xref="S3.SS1.p4.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.5.m5.1.1.3.2.cmml" xref="S3.SS1.p4.5.m5.1.1.3.2">â„</ci><apply id="S3.SS1.p4.5.m5.1.1.3.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3.3"><times id="S3.SS1.p4.5.m5.1.1.3.3.1.cmml" xref="S3.SS1.p4.5.m5.1.1.3.3.1"></times><ci id="S3.SS1.p4.5.m5.1.1.3.3.2.cmml" xref="S3.SS1.p4.5.m5.1.1.3.3.2">ğ»</ci><ci id="S3.SS1.p4.5.m5.1.1.3.3.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3.3.3">ğ‘Š</ci><apply id="S3.SS1.p4.5.m5.1.1.3.3.4.cmml" xref="S3.SS1.p4.5.m5.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.1.3.3.4.1.cmml" xref="S3.SS1.p4.5.m5.1.1.3.3.4">subscript</csymbol><ci id="S3.SS1.p4.5.m5.1.1.3.3.4.2.cmml" xref="S3.SS1.p4.5.m5.1.1.3.3.4.2">ğ‘‘</ci><ci id="S3.SS1.p4.5.m5.1.1.3.3.4.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3.3.4.3">ğ‘“</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">\textbf{l}_{f}\in\mathbb{R}^{H\times W\times d_{f}}</annotation></semantics></math>. We apply a softmax activation function to the attention map <span id="S3.SS1.p4.12.1" class="ltx_text ltx_markedasmath ltx_font_bold">a</span> which results in a 2D map of probabilities <math id="S3.SS1.p4.7.m7.1" class="ltx_Math" alttext="\textbf{p}\in\mathbb{R}^{H\times W}" display="inline"><semantics id="S3.SS1.p4.7.m7.1a"><mrow id="S3.SS1.p4.7.m7.1.1" xref="S3.SS1.p4.7.m7.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.7.m7.1.1.2" xref="S3.SS1.p4.7.m7.1.1.2a.cmml">p</mtext><mo id="S3.SS1.p4.7.m7.1.1.1" xref="S3.SS1.p4.7.m7.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p4.7.m7.1.1.3" xref="S3.SS1.p4.7.m7.1.1.3.cmml"><mi id="S3.SS1.p4.7.m7.1.1.3.2" xref="S3.SS1.p4.7.m7.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p4.7.m7.1.1.3.3" xref="S3.SS1.p4.7.m7.1.1.3.3.cmml"><mi id="S3.SS1.p4.7.m7.1.1.3.3.2" xref="S3.SS1.p4.7.m7.1.1.3.3.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.7.m7.1.1.3.3.1" xref="S3.SS1.p4.7.m7.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p4.7.m7.1.1.3.3.3" xref="S3.SS1.p4.7.m7.1.1.3.3.3.cmml">W</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m7.1b"><apply id="S3.SS1.p4.7.m7.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1"><in id="S3.SS1.p4.7.m7.1.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1.1"></in><ci id="S3.SS1.p4.7.m7.1.1.2a.cmml" xref="S3.SS1.p4.7.m7.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.7.m7.1.1.2.cmml" xref="S3.SS1.p4.7.m7.1.1.2">p</mtext></ci><apply id="S3.SS1.p4.7.m7.1.1.3.cmml" xref="S3.SS1.p4.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.7.m7.1.1.3.1.cmml" xref="S3.SS1.p4.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.7.m7.1.1.3.2.cmml" xref="S3.SS1.p4.7.m7.1.1.3.2">â„</ci><apply id="S3.SS1.p4.7.m7.1.1.3.3.cmml" xref="S3.SS1.p4.7.m7.1.1.3.3"><times id="S3.SS1.p4.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.p4.7.m7.1.1.3.3.1"></times><ci id="S3.SS1.p4.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.p4.7.m7.1.1.3.3.2">ğ»</ci><ci id="S3.SS1.p4.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.p4.7.m7.1.1.3.3.3">ğ‘Š</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m7.1c">\textbf{p}\in\mathbb{R}^{H\times W}</annotation></semantics></math>.
This probability map <span id="S3.SS1.p4.12.2" class="ltx_text ltx_markedasmath ltx_font_bold">p</span> encodes the probability of a pixel in the input image being of high importance to the registration task.
To extract these regions, we multiply <span id="S3.SS1.p4.12.3" class="ltx_text ltx_markedasmath ltx_font_bold">p</span> element-wise with each slice <math id="S3.SS1.p4.10.m10.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p4.10.m10.1a"><mi id="S3.SS1.p4.10.m10.1.1" xref="S3.SS1.p4.10.m10.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.10.m10.1b"><ci id="S3.SS1.p4.10.m10.1.1.cmml" xref="S3.SS1.p4.10.m10.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.10.m10.1c">i</annotation></semantics></math> of the tensor <math id="S3.SS1.p4.11.m11.1" class="ltx_Math" alttext="\textbf{l}_{f}" display="inline"><semantics id="S3.SS1.p4.11.m11.1a"><msub id="S3.SS1.p4.11.m11.1.1" xref="S3.SS1.p4.11.m11.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.11.m11.1.1.2" xref="S3.SS1.p4.11.m11.1.1.2a.cmml">l</mtext><mi id="S3.SS1.p4.11.m11.1.1.3" xref="S3.SS1.p4.11.m11.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.11.m11.1b"><apply id="S3.SS1.p4.11.m11.1.1.cmml" xref="S3.SS1.p4.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.11.m11.1.1.1.cmml" xref="S3.SS1.p4.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p4.11.m11.1.1.2a.cmml" xref="S3.SS1.p4.11.m11.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.11.m11.1.1.2.cmml" xref="S3.SS1.p4.11.m11.1.1.2">l</mtext></ci><ci id="S3.SS1.p4.11.m11.1.1.3.cmml" xref="S3.SS1.p4.11.m11.1.1.3">ğ‘“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.11.m11.1c">\textbf{l}_{f}</annotation></semantics></math> along the dimension <math id="S3.SS1.p4.12.m12.1" class="ltx_Math" alttext="d_{f}" display="inline"><semantics id="S3.SS1.p4.12.m12.1a"><msub id="S3.SS1.p4.12.m12.1.1" xref="S3.SS1.p4.12.m12.1.1.cmml"><mi id="S3.SS1.p4.12.m12.1.1.2" xref="S3.SS1.p4.12.m12.1.1.2.cmml">d</mi><mi id="S3.SS1.p4.12.m12.1.1.3" xref="S3.SS1.p4.12.m12.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.12.m12.1b"><apply id="S3.SS1.p4.12.m12.1.1.cmml" xref="S3.SS1.p4.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.12.m12.1.1.1.cmml" xref="S3.SS1.p4.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.p4.12.m12.1.1.2.cmml" xref="S3.SS1.p4.12.m12.1.1.2">ğ‘‘</ci><ci id="S3.SS1.p4.12.m12.1.1.3.cmml" xref="S3.SS1.p4.12.m12.1.1.3">ğ‘“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.12.m12.1c">d_{f}</annotation></semantics></math> and sum over the image dimensions:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="\textbf{l}^{i}=\sum_{W,H}\textbf{l}_{f}^{i}\cdot\textbf{p}\quad," display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><msup id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.3.3.1.1.2.2" xref="S3.E1.m1.3.3.1.1.2.2a.cmml">l</mtext><mi id="S3.E1.m1.3.3.1.1.2.3" xref="S3.E1.m1.3.3.1.1.2.3.cmml">i</mi></msup><mo rspace="0.111em" id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml"><munder id="S3.E1.m1.3.3.1.1.3.1" xref="S3.E1.m1.3.3.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E1.m1.3.3.1.1.3.1.2" xref="S3.E1.m1.3.3.1.1.3.1.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">W</mi><mo id="S3.E1.m1.2.2.2.4.1" xref="S3.E1.m1.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">H</mi></mrow></munder><mrow id="S3.E1.m1.3.3.1.1.3.2" xref="S3.E1.m1.3.3.1.1.3.2.cmml"><msubsup id="S3.E1.m1.3.3.1.1.3.2.2" xref="S3.E1.m1.3.3.1.1.3.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.3.3.1.1.3.2.2.2.2" xref="S3.E1.m1.3.3.1.1.3.2.2.2.2a.cmml">l</mtext><mi id="S3.E1.m1.3.3.1.1.3.2.2.2.3" xref="S3.E1.m1.3.3.1.1.3.2.2.2.3.cmml">f</mi><mi id="S3.E1.m1.3.3.1.1.3.2.2.3" xref="S3.E1.m1.3.3.1.1.3.2.2.3.cmml">i</mi></msubsup><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.3.3.1.1.3.2.1" xref="S3.E1.m1.3.3.1.1.3.2.1.cmml">â‹…</mo><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.3.3.1.1.3.2.3" xref="S3.E1.m1.3.3.1.1.3.2.3a.cmml">p</mtext></mrow></mrow></mrow><mspace width="1em" id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.1.cmml"></mspace><mo id="S3.E1.m1.3.3.1.3" xref="S3.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><eq id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"></eq><apply id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.2.1.cmml" xref="S3.E1.m1.3.3.1.1.2">superscript</csymbol><ci id="S3.E1.m1.3.3.1.1.2.2a.cmml" xref="S3.E1.m1.3.3.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.3.3.1.1.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2">l</mtext></ci><ci id="S3.E1.m1.3.3.1.1.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.3"><apply id="S3.E1.m1.3.3.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1.3.1">subscript</csymbol><sum id="S3.E1.m1.3.3.1.1.3.1.2.cmml" xref="S3.E1.m1.3.3.1.1.3.1.2"></sum><list id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">ğ‘Š</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">ğ»</ci></list></apply><apply id="S3.E1.m1.3.3.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2"><ci id="S3.E1.m1.3.3.1.1.3.2.1.cmml" xref="S3.E1.m1.3.3.1.1.3.2.1">â‹…</ci><apply id="S3.E1.m1.3.3.1.1.3.2.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.3.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.3.2.2">superscript</csymbol><apply id="S3.E1.m1.3.3.1.1.3.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.3.2.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.3.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.3.2.2.2.2a.cmml" xref="S3.E1.m1.3.3.1.1.3.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.3.3.1.1.3.2.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2.2.2.2">l</mtext></ci><ci id="S3.E1.m1.3.3.1.1.3.2.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.3.2.2.2.3">ğ‘“</ci></apply><ci id="S3.E1.m1.3.3.1.1.3.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.3.2.2.3">ğ‘–</ci></apply><ci id="S3.E1.m1.3.3.1.1.3.2.3a.cmml" xref="S3.E1.m1.3.3.1.1.3.2.3"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.3.3.1.1.3.2.3.cmml" xref="S3.E1.m1.3.3.1.1.3.2.3">p</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\textbf{l}^{i}=\sum_{W,H}\textbf{l}_{f}^{i}\cdot\textbf{p}\quad,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p4.15" class="ltx_p">which produces a vector <math id="S3.SS1.p4.13.m1.1" class="ltx_Math" alttext="\textbf{l}\in\mathbb{R}^{d_{f}}" display="inline"><semantics id="S3.SS1.p4.13.m1.1a"><mrow id="S3.SS1.p4.13.m1.1.1" xref="S3.SS1.p4.13.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.13.m1.1.1.2" xref="S3.SS1.p4.13.m1.1.1.2a.cmml">l</mtext><mo id="S3.SS1.p4.13.m1.1.1.1" xref="S3.SS1.p4.13.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p4.13.m1.1.1.3" xref="S3.SS1.p4.13.m1.1.1.3.cmml"><mi id="S3.SS1.p4.13.m1.1.1.3.2" xref="S3.SS1.p4.13.m1.1.1.3.2.cmml">â„</mi><msub id="S3.SS1.p4.13.m1.1.1.3.3" xref="S3.SS1.p4.13.m1.1.1.3.3.cmml"><mi id="S3.SS1.p4.13.m1.1.1.3.3.2" xref="S3.SS1.p4.13.m1.1.1.3.3.2.cmml">d</mi><mi id="S3.SS1.p4.13.m1.1.1.3.3.3" xref="S3.SS1.p4.13.m1.1.1.3.3.3.cmml">f</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.13.m1.1b"><apply id="S3.SS1.p4.13.m1.1.1.cmml" xref="S3.SS1.p4.13.m1.1.1"><in id="S3.SS1.p4.13.m1.1.1.1.cmml" xref="S3.SS1.p4.13.m1.1.1.1"></in><ci id="S3.SS1.p4.13.m1.1.1.2a.cmml" xref="S3.SS1.p4.13.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.13.m1.1.1.2.cmml" xref="S3.SS1.p4.13.m1.1.1.2">l</mtext></ci><apply id="S3.SS1.p4.13.m1.1.1.3.cmml" xref="S3.SS1.p4.13.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.13.m1.1.1.3.1.cmml" xref="S3.SS1.p4.13.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.13.m1.1.1.3.2.cmml" xref="S3.SS1.p4.13.m1.1.1.3.2">â„</ci><apply id="S3.SS1.p4.13.m1.1.1.3.3.cmml" xref="S3.SS1.p4.13.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p4.13.m1.1.1.3.3.1.cmml" xref="S3.SS1.p4.13.m1.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p4.13.m1.1.1.3.3.2.cmml" xref="S3.SS1.p4.13.m1.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS1.p4.13.m1.1.1.3.3.3.cmml" xref="S3.SS1.p4.13.m1.1.1.3.3.3">ğ‘“</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.13.m1.1c">\textbf{l}\in\mathbb{R}^{d_{f}}</annotation></semantics></math>. We feed the vector <span id="S3.SS1.p4.15.1" class="ltx_text ltx_markedasmath ltx_font_bold">l</span> to the fully connected linear layer. The output of the linear layer gives the final attention output <math id="S3.SS1.p4.15.m3.1" class="ltx_Math" alttext="\textbf{l}_{out}" display="inline"><semantics id="S3.SS1.p4.15.m3.1a"><msub id="S3.SS1.p4.15.m3.1.1" xref="S3.SS1.p4.15.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.15.m3.1.1.2" xref="S3.SS1.p4.15.m3.1.1.2a.cmml">l</mtext><mrow id="S3.SS1.p4.15.m3.1.1.3" xref="S3.SS1.p4.15.m3.1.1.3.cmml"><mi id="S3.SS1.p4.15.m3.1.1.3.2" xref="S3.SS1.p4.15.m3.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.15.m3.1.1.3.1" xref="S3.SS1.p4.15.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.15.m3.1.1.3.3" xref="S3.SS1.p4.15.m3.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.15.m3.1.1.3.1a" xref="S3.SS1.p4.15.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p4.15.m3.1.1.3.4" xref="S3.SS1.p4.15.m3.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.15.m3.1b"><apply id="S3.SS1.p4.15.m3.1.1.cmml" xref="S3.SS1.p4.15.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.15.m3.1.1.1.cmml" xref="S3.SS1.p4.15.m3.1.1">subscript</csymbol><ci id="S3.SS1.p4.15.m3.1.1.2a.cmml" xref="S3.SS1.p4.15.m3.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p4.15.m3.1.1.2.cmml" xref="S3.SS1.p4.15.m3.1.1.2">l</mtext></ci><apply id="S3.SS1.p4.15.m3.1.1.3.cmml" xref="S3.SS1.p4.15.m3.1.1.3"><times id="S3.SS1.p4.15.m3.1.1.3.1.cmml" xref="S3.SS1.p4.15.m3.1.1.3.1"></times><ci id="S3.SS1.p4.15.m3.1.1.3.2.cmml" xref="S3.SS1.p4.15.m3.1.1.3.2">ğ‘œ</ci><ci id="S3.SS1.p4.15.m3.1.1.3.3.cmml" xref="S3.SS1.p4.15.m3.1.1.3.3">ğ‘¢</ci><ci id="S3.SS1.p4.15.m3.1.1.3.4.cmml" xref="S3.SS1.p4.15.m3.1.1.3.4">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.15.m3.1c">\textbf{l}_{out}</annotation></semantics></math> vector. The attention output is fed to a fully connected layer, which produces the network outputs (see Fig. <a href="#S3.F2" title="Figure 2 â€£ 3 Method â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">Since our starting point is an initial pose guess, the images of rendered and real objects typically already lie close to each other in the image plane. Thus, related details are relatively close but are not yet aligned. Our goal is to perfectly align all details. However, not all object parts contribute equal amounts of information. For example, homogeneous surfaces do not provide useful information for alignment. Leveraging spatial attention allows the network to identify those areas in the image that, with high probability, contribute meaningfully to the alignment. In other words, it identifies salient details, while rejecting clutter, occluded parts of the object and non-informative uniformly textured parts of the object.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">We evaluate our approach in a single-stage and multi-stage settings. The single-stage setting takes the output of the network described above as a final result. In the multi-stage setting, we take the output of the network and update the object pose in each stage. The new object pose is used as input to the next stage. Therefore, we stack four modules shown in Fig. <a href="#S3.F2" title="Figure 2 â€£ 3 Method â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> into a sequence, which enables us to train the network for iterative refinement. In both settings, our network performs better than state-of-the-art.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Prediction Calculation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.5" class="ltx_p">To compute the prediction, we use the procedure from DeepIM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. The input to our model is the initial pose <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="[\mathbf{R_{i}}|\mathbf{t_{i}}]" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.1.m1.1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.1.cmml">[</mo><mrow id="S3.SS2.p1.1.m1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.cmml"><msub id="S3.SS2.p1.1.m1.1.1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.1.1.2.cmml"><mi id="S3.SS2.p1.1.m1.1.1.1.1.2.2" xref="S3.SS2.p1.1.m1.1.1.1.1.2.2.cmml">ğ‘</mi><mi id="S3.SS2.p1.1.m1.1.1.1.1.2.3" xref="S3.SS2.p1.1.m1.1.1.1.1.2.3.cmml">ğ¢</mi></msub><mo fence="false" id="S3.SS2.p1.1.m1.1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS2.p1.1.m1.1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.1.1.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.1.1.3.2.cmml">ğ­</mi><mi id="S3.SS2.p1.1.m1.1.1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.1.1.3.3.cmml">ğ¢</mi></msub></mrow><mo stretchy="false" id="S3.SS2.p1.1.m1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS2.p1.1.m1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p1.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.2.3">ğ¢</ci></apply><apply id="S3.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.3.2">ğ­</ci><ci id="S3.SS2.p1.1.m1.1.1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.3.3">ğ¢</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">[\mathbf{R_{i}}|\mathbf{t_{i}}]</annotation></semantics></math>, where <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{R_{i}}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">ğ‘</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">ğ¢</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ‘</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">ğ¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathbf{R_{i}}</annotation></semantics></math> is the initial object rotation matrix and <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{t_{i}}" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><msub id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">ğ­</mi><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">ğ¢</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ğ­</ci><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">ğ¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\mathbf{t_{i}}</annotation></semantics></math> is the initial translation vector. We compute the pose increment <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="[\mathbf{R}_{\Delta}|\mathbf{t}_{\Delta}]" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mrow id="S3.SS2.p1.4.m4.1.1.1" xref="S3.SS2.p1.4.m4.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.4.m4.1.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.1.cmml">[</mo><mrow id="S3.SS2.p1.4.m4.1.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.1.cmml"><msub id="S3.SS2.p1.4.m4.1.1.1.1.2" xref="S3.SS2.p1.4.m4.1.1.1.1.2.cmml"><mi id="S3.SS2.p1.4.m4.1.1.1.1.2.2" xref="S3.SS2.p1.4.m4.1.1.1.1.2.2.cmml">ğ‘</mi><mi mathvariant="normal" id="S3.SS2.p1.4.m4.1.1.1.1.2.3" xref="S3.SS2.p1.4.m4.1.1.1.1.2.3.cmml">Î”</mi></msub><mo fence="false" id="S3.SS2.p1.4.m4.1.1.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.1.1.cmml">|</mo><msub id="S3.SS2.p1.4.m4.1.1.1.1.3" xref="S3.SS2.p1.4.m4.1.1.1.1.3.cmml"><mi id="S3.SS2.p1.4.m4.1.1.1.1.3.2" xref="S3.SS2.p1.4.m4.1.1.1.1.3.2.cmml">ğ­</mi><mi mathvariant="normal" id="S3.SS2.p1.4.m4.1.1.1.1.3.3" xref="S3.SS2.p1.4.m4.1.1.1.1.3.3.cmml">Î”</mi></msub></mrow><mo stretchy="false" id="S3.SS2.p1.4.m4.1.1.1.3" xref="S3.SS2.p1.4.m4.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.4.m4.1.1.2.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS2.p1.4.m4.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.1">conditional</csymbol><apply id="S3.SS2.p1.4.m4.1.1.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p1.4.m4.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.2.3">Î”</ci></apply><apply id="S3.SS2.p1.4.m4.1.1.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.1.3.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.1.1.3.2.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.3.2">ğ­</ci><ci id="S3.SS2.p1.4.m4.1.1.1.1.3.3.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.3.3">Î”</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">[\mathbf{R}_{\Delta}|\mathbf{t}_{\Delta}]</annotation></semantics></math> from our network outputs. The final pose is obtained by applying pose increments to the initial pose <math id="S3.SS2.p1.5.m5.2" class="ltx_Math" alttext="[\mathbf{R_{f}}|\mathbf{t_{f}}]=[\mathbf{R}_{\Delta}\mathbf{R_{i}}|\mathbf{t_{i}}+\mathbf{t}_{\Delta}]" display="inline"><semantics id="S3.SS2.p1.5.m5.2a"><mrow id="S3.SS2.p1.5.m5.2.2" xref="S3.SS2.p1.5.m5.2.2.cmml"><mrow id="S3.SS2.p1.5.m5.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.5.m5.1.1.1.1.2" xref="S3.SS2.p1.5.m5.1.1.1.2.1.cmml">[</mo><mrow id="S3.SS2.p1.5.m5.1.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.1.cmml"><msub id="S3.SS2.p1.5.m5.1.1.1.1.1.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.cmml"><mi id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.cmml">ğ‘</mi><mi id="S3.SS2.p1.5.m5.1.1.1.1.1.2.3" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.3.cmml">ğŸ</mi></msub><mo fence="false" id="S3.SS2.p1.5.m5.1.1.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS2.p1.5.m5.1.1.1.1.1.3" xref="S3.SS2.p1.5.m5.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p1.5.m5.1.1.1.1.1.3.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.3.2.cmml">ğ­</mi><mi id="S3.SS2.p1.5.m5.1.1.1.1.1.3.3" xref="S3.SS2.p1.5.m5.1.1.1.1.1.3.3.cmml">ğŸ</mi></msub></mrow><mo stretchy="false" id="S3.SS2.p1.5.m5.1.1.1.1.3" xref="S3.SS2.p1.5.m5.1.1.1.2.1.cmml">]</mo></mrow><mo id="S3.SS2.p1.5.m5.2.2.3" xref="S3.SS2.p1.5.m5.2.2.3.cmml">=</mo><mrow id="S3.SS2.p1.5.m5.2.2.2.1" xref="S3.SS2.p1.5.m5.2.2.2.2.cmml"><mo stretchy="false" id="S3.SS2.p1.5.m5.2.2.2.1.2" xref="S3.SS2.p1.5.m5.2.2.2.2.1.cmml">[</mo><mrow id="S3.SS2.p1.5.m5.2.2.2.1.1" xref="S3.SS2.p1.5.m5.2.2.2.1.1.cmml"><mrow id="S3.SS2.p1.5.m5.2.2.2.1.1.2" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.cmml"><msub id="S3.SS2.p1.5.m5.2.2.2.1.1.2.2" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.cmml"><mi id="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.2" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.2.cmml">ğ‘</mi><mi mathvariant="normal" id="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.3" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.3.cmml">Î”</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p1.5.m5.2.2.2.1.1.2.1" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.1.cmml">â€‹</mo><msub id="S3.SS2.p1.5.m5.2.2.2.1.1.2.3" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.cmml"><mi id="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.2" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.2.cmml">ğ‘</mi><mi id="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.3" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.3.cmml">ğ¢</mi></msub></mrow><mo fence="false" id="S3.SS2.p1.5.m5.2.2.2.1.1.1" xref="S3.SS2.p1.5.m5.2.2.2.1.1.1.cmml">|</mo><mrow id="S3.SS2.p1.5.m5.2.2.2.1.1.3" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.cmml"><msub id="S3.SS2.p1.5.m5.2.2.2.1.1.3.2" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.cmml"><mi id="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.2" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.2.cmml">ğ­</mi><mi id="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.3" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.3.cmml">ğ¢</mi></msub><mo id="S3.SS2.p1.5.m5.2.2.2.1.1.3.1" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.1.cmml">+</mo><msub id="S3.SS2.p1.5.m5.2.2.2.1.1.3.3" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.cmml"><mi id="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.2" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.2.cmml">ğ­</mi><mi mathvariant="normal" id="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.3" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.3.cmml">Î”</mi></msub></mrow></mrow><mo stretchy="false" id="S3.SS2.p1.5.m5.2.2.2.1.3" xref="S3.SS2.p1.5.m5.2.2.2.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.2b"><apply id="S3.SS2.p1.5.m5.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2"><eq id="S3.SS2.p1.5.m5.2.2.3.cmml" xref="S3.SS2.p1.5.m5.2.2.3"></eq><apply id="S3.SS2.p1.5.m5.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.5.m5.1.1.1.2.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.3">ğŸ</ci></apply><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.3.2">ğ­</ci><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.3.3">ğŸ</ci></apply></apply></apply><apply id="S3.SS2.p1.5.m5.2.2.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1"><csymbol cd="latexml" id="S3.SS2.p1.5.m5.2.2.2.2.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.2">delimited-[]</csymbol><apply id="S3.SS2.p1.5.m5.2.2.2.1.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1"><csymbol cd="latexml" id="S3.SS2.p1.5.m5.2.2.2.1.1.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.1">conditional</csymbol><apply id="S3.SS2.p1.5.m5.2.2.2.1.1.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2"><times id="S3.SS2.p1.5.m5.2.2.2.1.1.2.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.1"></times><apply id="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.2">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.2">ğ‘</ci><ci id="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.2.3">Î”</ci></apply><apply id="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.3">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.2">ğ‘</ci><ci id="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.2.3.3">ğ¢</ci></apply></apply><apply id="S3.SS2.p1.5.m5.2.2.2.1.1.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3"><plus id="S3.SS2.p1.5.m5.2.2.2.1.1.3.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.1"></plus><apply id="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.2">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.2">ğ­</ci><ci id="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.2.3">ğ¢</ci></apply><apply id="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.3">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.2">ğ­</ci><ci id="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.1.1.3.3.3">Î”</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.2c">[\mathbf{R_{f}}|\mathbf{t_{f}}]=[\mathbf{R}_{\Delta}\mathbf{R_{i}}|\mathbf{t_{i}}+\mathbf{t}_{\Delta}]</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.7" class="ltx_p">The network directly outputs the rotation update <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{R}_{\Delta}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">ğ‘</mi><mi mathvariant="normal" id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">Î”</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">ğ‘</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">Î”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathbf{R}_{\Delta}</annotation></semantics></math> (see Fig. <a href="#S3.F2" title="Figure 2 â€£ 3 Method â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). In our case, the network predicts quaternions, which are then converted into a rotation matrix. To compute the translation increment <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{t}_{\Delta}" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">ğ­</mi><mi mathvariant="normal" id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">Î”</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">ğ­</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">Î”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\mathbf{t}_{\Delta}</annotation></semantics></math>, we combine the two other outputs of the network. As suggested by DeepIM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, the network predicts the translation update in the image plane <math id="S3.SS2.p2.3.m3.2" class="ltx_Math" alttext="(v_{x},v_{y})" display="inline"><semantics id="S3.SS2.p2.3.m3.2a"><mrow id="S3.SS2.p2.3.m3.2.2.2" xref="S3.SS2.p2.3.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.p2.3.m3.2.2.2.3" xref="S3.SS2.p2.3.m3.2.2.3.cmml">(</mo><msub id="S3.SS2.p2.3.m3.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.2.cmml">v</mi><mi id="S3.SS2.p2.3.m3.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.3.cmml">x</mi></msub><mo id="S3.SS2.p2.3.m3.2.2.2.4" xref="S3.SS2.p2.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS2.p2.3.m3.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.cmml"><mi id="S3.SS2.p2.3.m3.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.cmml">v</mi><mi id="S3.SS2.p2.3.m3.2.2.2.2.3" xref="S3.SS2.p2.3.m3.2.2.2.2.3.cmml">y</mi></msub><mo stretchy="false" id="S3.SS2.p2.3.m3.2.2.2.5" xref="S3.SS2.p2.3.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.2b"><interval closure="open" id="S3.SS2.p2.3.m3.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2"><apply id="S3.SS2.p2.3.m3.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.2">ğ‘£</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.3">ğ‘¥</ci></apply><apply id="S3.SS2.p2.3.m3.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.2.2.2.2.1.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2">ğ‘£</ci><ci id="S3.SS2.p2.3.m3.2.2.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.3">ğ‘¦</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.2c">(v_{x},v_{y})</annotation></semantics></math> and image scaling factor <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">s</annotation></semantics></math> separately. The translation update vector <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{t}_{\Delta}" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><msub id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">ğ­</mi><mi mathvariant="normal" id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml">Î”</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">ğ­</ci><ci id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3">Î”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">\mathbf{t}_{\Delta}</annotation></semantics></math> is the difference between the final translation vector <math id="S3.SS2.p2.6.m6.3" class="ltx_Math" alttext="\mathbf{t_{f}}=[x_{f},y_{f},z_{f}]" display="inline"><semantics id="S3.SS2.p2.6.m6.3a"><mrow id="S3.SS2.p2.6.m6.3.3" xref="S3.SS2.p2.6.m6.3.3.cmml"><msub id="S3.SS2.p2.6.m6.3.3.5" xref="S3.SS2.p2.6.m6.3.3.5.cmml"><mi id="S3.SS2.p2.6.m6.3.3.5.2" xref="S3.SS2.p2.6.m6.3.3.5.2.cmml">ğ­</mi><mi id="S3.SS2.p2.6.m6.3.3.5.3" xref="S3.SS2.p2.6.m6.3.3.5.3.cmml">ğŸ</mi></msub><mo id="S3.SS2.p2.6.m6.3.3.4" xref="S3.SS2.p2.6.m6.3.3.4.cmml">=</mo><mrow id="S3.SS2.p2.6.m6.3.3.3.3" xref="S3.SS2.p2.6.m6.3.3.3.4.cmml"><mo stretchy="false" id="S3.SS2.p2.6.m6.3.3.3.3.4" xref="S3.SS2.p2.6.m6.3.3.3.4.cmml">[</mo><msub id="S3.SS2.p2.6.m6.1.1.1.1.1" xref="S3.SS2.p2.6.m6.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.6.m6.1.1.1.1.1.2" xref="S3.SS2.p2.6.m6.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS2.p2.6.m6.1.1.1.1.1.3" xref="S3.SS2.p2.6.m6.1.1.1.1.1.3.cmml">f</mi></msub><mo id="S3.SS2.p2.6.m6.3.3.3.3.5" xref="S3.SS2.p2.6.m6.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p2.6.m6.2.2.2.2.2" xref="S3.SS2.p2.6.m6.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.6.m6.2.2.2.2.2.2" xref="S3.SS2.p2.6.m6.2.2.2.2.2.2.cmml">y</mi><mi id="S3.SS2.p2.6.m6.2.2.2.2.2.3" xref="S3.SS2.p2.6.m6.2.2.2.2.2.3.cmml">f</mi></msub><mo id="S3.SS2.p2.6.m6.3.3.3.3.6" xref="S3.SS2.p2.6.m6.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p2.6.m6.3.3.3.3.3" xref="S3.SS2.p2.6.m6.3.3.3.3.3.cmml"><mi id="S3.SS2.p2.6.m6.3.3.3.3.3.2" xref="S3.SS2.p2.6.m6.3.3.3.3.3.2.cmml">z</mi><mi id="S3.SS2.p2.6.m6.3.3.3.3.3.3" xref="S3.SS2.p2.6.m6.3.3.3.3.3.3.cmml">f</mi></msub><mo stretchy="false" id="S3.SS2.p2.6.m6.3.3.3.3.7" xref="S3.SS2.p2.6.m6.3.3.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.3b"><apply id="S3.SS2.p2.6.m6.3.3.cmml" xref="S3.SS2.p2.6.m6.3.3"><eq id="S3.SS2.p2.6.m6.3.3.4.cmml" xref="S3.SS2.p2.6.m6.3.3.4"></eq><apply id="S3.SS2.p2.6.m6.3.3.5.cmml" xref="S3.SS2.p2.6.m6.3.3.5"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.3.3.5.1.cmml" xref="S3.SS2.p2.6.m6.3.3.5">subscript</csymbol><ci id="S3.SS2.p2.6.m6.3.3.5.2.cmml" xref="S3.SS2.p2.6.m6.3.3.5.2">ğ­</ci><ci id="S3.SS2.p2.6.m6.3.3.5.3.cmml" xref="S3.SS2.p2.6.m6.3.3.5.3">ğŸ</ci></apply><list id="S3.SS2.p2.6.m6.3.3.3.4.cmml" xref="S3.SS2.p2.6.m6.3.3.3.3"><apply id="S3.SS2.p2.6.m6.1.1.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS2.p2.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.1.1.1.3">ğ‘“</ci></apply><apply id="S3.SS2.p2.6.m6.2.2.2.2.2.cmml" xref="S3.SS2.p2.6.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.6.m6.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.6.m6.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.6.m6.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.SS2.p2.6.m6.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.6.m6.2.2.2.2.2.3">ğ‘“</ci></apply><apply id="S3.SS2.p2.6.m6.3.3.3.3.3.cmml" xref="S3.SS2.p2.6.m6.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.3.3.3.3.3.1.cmml" xref="S3.SS2.p2.6.m6.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.6.m6.3.3.3.3.3.2.cmml" xref="S3.SS2.p2.6.m6.3.3.3.3.3.2">ğ‘§</ci><ci id="S3.SS2.p2.6.m6.3.3.3.3.3.3.cmml" xref="S3.SS2.p2.6.m6.3.3.3.3.3.3">ğ‘“</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.3c">\mathbf{t_{f}}=[x_{f},y_{f},z_{f}]</annotation></semantics></math> and the initial translation vector <math id="S3.SS2.p2.7.m7.3" class="ltx_Math" alttext="\mathbf{t_{i}}=[x_{i},y_{i},z_{i}]" display="inline"><semantics id="S3.SS2.p2.7.m7.3a"><mrow id="S3.SS2.p2.7.m7.3.3" xref="S3.SS2.p2.7.m7.3.3.cmml"><msub id="S3.SS2.p2.7.m7.3.3.5" xref="S3.SS2.p2.7.m7.3.3.5.cmml"><mi id="S3.SS2.p2.7.m7.3.3.5.2" xref="S3.SS2.p2.7.m7.3.3.5.2.cmml">ğ­</mi><mi id="S3.SS2.p2.7.m7.3.3.5.3" xref="S3.SS2.p2.7.m7.3.3.5.3.cmml">ğ¢</mi></msub><mo id="S3.SS2.p2.7.m7.3.3.4" xref="S3.SS2.p2.7.m7.3.3.4.cmml">=</mo><mrow id="S3.SS2.p2.7.m7.3.3.3.3" xref="S3.SS2.p2.7.m7.3.3.3.4.cmml"><mo stretchy="false" id="S3.SS2.p2.7.m7.3.3.3.3.4" xref="S3.SS2.p2.7.m7.3.3.3.4.cmml">[</mo><msub id="S3.SS2.p2.7.m7.1.1.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.7.m7.1.1.1.1.1.2" xref="S3.SS2.p2.7.m7.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS2.p2.7.m7.1.1.1.1.1.3" xref="S3.SS2.p2.7.m7.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p2.7.m7.3.3.3.3.5" xref="S3.SS2.p2.7.m7.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p2.7.m7.2.2.2.2.2" xref="S3.SS2.p2.7.m7.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.7.m7.2.2.2.2.2.2" xref="S3.SS2.p2.7.m7.2.2.2.2.2.2.cmml">y</mi><mi id="S3.SS2.p2.7.m7.2.2.2.2.2.3" xref="S3.SS2.p2.7.m7.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS2.p2.7.m7.3.3.3.3.6" xref="S3.SS2.p2.7.m7.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p2.7.m7.3.3.3.3.3" xref="S3.SS2.p2.7.m7.3.3.3.3.3.cmml"><mi id="S3.SS2.p2.7.m7.3.3.3.3.3.2" xref="S3.SS2.p2.7.m7.3.3.3.3.3.2.cmml">z</mi><mi id="S3.SS2.p2.7.m7.3.3.3.3.3.3" xref="S3.SS2.p2.7.m7.3.3.3.3.3.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p2.7.m7.3.3.3.3.7" xref="S3.SS2.p2.7.m7.3.3.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.3b"><apply id="S3.SS2.p2.7.m7.3.3.cmml" xref="S3.SS2.p2.7.m7.3.3"><eq id="S3.SS2.p2.7.m7.3.3.4.cmml" xref="S3.SS2.p2.7.m7.3.3.4"></eq><apply id="S3.SS2.p2.7.m7.3.3.5.cmml" xref="S3.SS2.p2.7.m7.3.3.5"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.3.3.5.1.cmml" xref="S3.SS2.p2.7.m7.3.3.5">subscript</csymbol><ci id="S3.SS2.p2.7.m7.3.3.5.2.cmml" xref="S3.SS2.p2.7.m7.3.3.5.2">ğ­</ci><ci id="S3.SS2.p2.7.m7.3.3.5.3.cmml" xref="S3.SS2.p2.7.m7.3.3.5.3">ğ¢</ci></apply><list id="S3.SS2.p2.7.m7.3.3.3.4.cmml" xref="S3.SS2.p2.7.m7.3.3.3.3"><apply id="S3.SS2.p2.7.m7.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS2.p2.7.m7.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.7.m7.2.2.2.2.2.cmml" xref="S3.SS2.p2.7.m7.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.7.m7.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.7.m7.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.7.m7.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.SS2.p2.7.m7.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.7.m7.2.2.2.2.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.7.m7.3.3.3.3.3.cmml" xref="S3.SS2.p2.7.m7.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.3.3.3.3.3.1.cmml" xref="S3.SS2.p2.7.m7.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.7.m7.3.3.3.3.3.2.cmml" xref="S3.SS2.p2.7.m7.3.3.3.3.3.2">ğ‘§</ci><ci id="S3.SS2.p2.7.m7.3.3.3.3.3.3.cmml" xref="S3.SS2.p2.7.m7.3.3.3.3.3.3">ğ‘–</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.3c">\mathbf{t_{i}}=[x_{i},y_{i},z_{i}]</annotation></semantics></math>. The relation between these two vectors is given with the following equations:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.53" class="ltx_Math" alttext="\begin{split}v_{x}&amp;=f_{x}(x_{f}/z_{f}-x_{i}/z_{i}),\\
v_{y}&amp;=f_{y}(y_{f}/z_{f}-y_{i}/z_{i}),\\
s&amp;=\log(z_{i}/z_{f}),\\
\end{split}" display="block"><semantics id="S3.E2.m1.53a"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S3.E2.m1.53.53.4"><mtr id="S3.E2.m1.53.53.4a"><mtd class="ltx_align_right" columnalign="right" id="S3.E2.m1.53.53.4b"><msub id="S3.E2.m1.2.2.2.2.2"><mi id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml">v</mi><mi id="S3.E2.m1.2.2.2.2.2.2.1" xref="S3.E2.m1.2.2.2.2.2.2.1.cmml">x</mi></msub></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E2.m1.53.53.4c"><mrow id="S3.E2.m1.51.51.2.50.20.18.18"><mrow id="S3.E2.m1.51.51.2.50.20.18.18.1"><mi id="S3.E2.m1.51.51.2.50.20.18.18.1.2"></mi><mo id="S3.E2.m1.3.3.3.3.1.1" xref="S3.E2.m1.3.3.3.3.1.1.cmml">=</mo><mrow id="S3.E2.m1.51.51.2.50.20.18.18.1.1"><msub id="S3.E2.m1.51.51.2.50.20.18.18.1.1.3"><mi id="S3.E2.m1.4.4.4.4.2.2" xref="S3.E2.m1.4.4.4.4.2.2.cmml">f</mi><mi id="S3.E2.m1.5.5.5.5.3.3.1" xref="S3.E2.m1.5.5.5.5.3.3.1.cmml">x</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.51.51.2.50.20.18.18.1.1.2">â€‹</mo><mrow id="S3.E2.m1.51.51.2.50.20.18.18.1.1.1.1"><mo stretchy="false" id="S3.E2.m1.6.6.6.6.4.4">(</mo><mrow id="S3.E2.m1.51.51.2.50.20.18.18.1.1.1.1.1"><mrow id="S3.E2.m1.51.51.2.50.20.18.18.1.1.1.1.1.1"><msub id="S3.E2.m1.51.51.2.50.20.18.18.1.1.1.1.1.1.1"><mi id="S3.E2.m1.7.7.7.7.5.5" xref="S3.E2.m1.7.7.7.7.5.5.cmml">x</mi><mi id="S3.E2.m1.8.8.8.8.6.6.1" xref="S3.E2.m1.8.8.8.8.6.6.1.cmml">f</mi></msub><mo id="S3.E2.m1.9.9.9.9.7.7" xref="S3.E2.m1.9.9.9.9.7.7.cmml">/</mo><msub id="S3.E2.m1.51.51.2.50.20.18.18.1.1.1.1.1.1.2"><mi id="S3.E2.m1.10.10.10.10.8.8" xref="S3.E2.m1.10.10.10.10.8.8.cmml">z</mi><mi id="S3.E2.m1.11.11.11.11.9.9.1" xref="S3.E2.m1.11.11.11.11.9.9.1.cmml">f</mi></msub></mrow><mo id="S3.E2.m1.12.12.12.12.10.10" xref="S3.E2.m1.12.12.12.12.10.10.cmml">âˆ’</mo><mrow id="S3.E2.m1.51.51.2.50.20.18.18.1.1.1.1.1.2"><msub id="S3.E2.m1.51.51.2.50.20.18.18.1.1.1.1.1.2.1"><mi id="S3.E2.m1.13.13.13.13.11.11" xref="S3.E2.m1.13.13.13.13.11.11.cmml">x</mi><mi id="S3.E2.m1.14.14.14.14.12.12.1" xref="S3.E2.m1.14.14.14.14.12.12.1.cmml">i</mi></msub><mo id="S3.E2.m1.15.15.15.15.13.13" xref="S3.E2.m1.15.15.15.15.13.13.cmml">/</mo><msub id="S3.E2.m1.51.51.2.50.20.18.18.1.1.1.1.1.2.2"><mi id="S3.E2.m1.16.16.16.16.14.14" xref="S3.E2.m1.16.16.16.16.14.14.cmml">z</mi><mi id="S3.E2.m1.17.17.17.17.15.15.1" xref="S3.E2.m1.17.17.17.17.15.15.1.cmml">i</mi></msub></mrow></mrow><mo stretchy="false" id="S3.E2.m1.18.18.18.18.16.16">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.19.19.19.19.17.17">,</mo></mrow></mtd></mtr><mtr id="S3.E2.m1.53.53.4d"><mtd class="ltx_align_right" columnalign="right" id="S3.E2.m1.53.53.4e"><msub id="S3.E2.m1.21.21.21.2.2"><mi id="S3.E2.m1.20.20.20.1.1.1" xref="S3.E2.m1.20.20.20.1.1.1.cmml">v</mi><mi id="S3.E2.m1.21.21.21.2.2.2.1" xref="S3.E2.m1.21.21.21.2.2.2.1.cmml">y</mi></msub></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E2.m1.53.53.4f"><mrow id="S3.E2.m1.52.52.3.51.20.18.18"><mrow id="S3.E2.m1.52.52.3.51.20.18.18.1"><mi id="S3.E2.m1.52.52.3.51.20.18.18.1.2"></mi><mo id="S3.E2.m1.22.22.22.3.1.1" xref="S3.E2.m1.22.22.22.3.1.1.cmml">=</mo><mrow id="S3.E2.m1.52.52.3.51.20.18.18.1.1"><msub id="S3.E2.m1.52.52.3.51.20.18.18.1.1.3"><mi id="S3.E2.m1.23.23.23.4.2.2" xref="S3.E2.m1.23.23.23.4.2.2.cmml">f</mi><mi id="S3.E2.m1.24.24.24.5.3.3.1" xref="S3.E2.m1.24.24.24.5.3.3.1.cmml">y</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.52.52.3.51.20.18.18.1.1.2">â€‹</mo><mrow id="S3.E2.m1.52.52.3.51.20.18.18.1.1.1.1"><mo stretchy="false" id="S3.E2.m1.25.25.25.6.4.4">(</mo><mrow id="S3.E2.m1.52.52.3.51.20.18.18.1.1.1.1.1"><mrow id="S3.E2.m1.52.52.3.51.20.18.18.1.1.1.1.1.1"><msub id="S3.E2.m1.52.52.3.51.20.18.18.1.1.1.1.1.1.1"><mi id="S3.E2.m1.26.26.26.7.5.5" xref="S3.E2.m1.26.26.26.7.5.5.cmml">y</mi><mi id="S3.E2.m1.27.27.27.8.6.6.1" xref="S3.E2.m1.27.27.27.8.6.6.1.cmml">f</mi></msub><mo id="S3.E2.m1.28.28.28.9.7.7" xref="S3.E2.m1.28.28.28.9.7.7.cmml">/</mo><msub id="S3.E2.m1.52.52.3.51.20.18.18.1.1.1.1.1.1.2"><mi id="S3.E2.m1.29.29.29.10.8.8" xref="S3.E2.m1.29.29.29.10.8.8.cmml">z</mi><mi id="S3.E2.m1.30.30.30.11.9.9.1" xref="S3.E2.m1.30.30.30.11.9.9.1.cmml">f</mi></msub></mrow><mo id="S3.E2.m1.31.31.31.12.10.10" xref="S3.E2.m1.31.31.31.12.10.10.cmml">âˆ’</mo><mrow id="S3.E2.m1.52.52.3.51.20.18.18.1.1.1.1.1.2"><msub id="S3.E2.m1.52.52.3.51.20.18.18.1.1.1.1.1.2.1"><mi id="S3.E2.m1.32.32.32.13.11.11" xref="S3.E2.m1.32.32.32.13.11.11.cmml">y</mi><mi id="S3.E2.m1.33.33.33.14.12.12.1" xref="S3.E2.m1.33.33.33.14.12.12.1.cmml">i</mi></msub><mo id="S3.E2.m1.34.34.34.15.13.13" xref="S3.E2.m1.34.34.34.15.13.13.cmml">/</mo><msub id="S3.E2.m1.52.52.3.51.20.18.18.1.1.1.1.1.2.2"><mi id="S3.E2.m1.35.35.35.16.14.14" xref="S3.E2.m1.35.35.35.16.14.14.cmml">z</mi><mi id="S3.E2.m1.36.36.36.17.15.15.1" xref="S3.E2.m1.36.36.36.17.15.15.1.cmml">i</mi></msub></mrow></mrow><mo stretchy="false" id="S3.E2.m1.37.37.37.18.16.16">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.38.38.38.19.17.17">,</mo></mrow></mtd></mtr><mtr id="S3.E2.m1.53.53.4g"><mtd class="ltx_align_right" columnalign="right" id="S3.E2.m1.53.53.4h"><mi id="S3.E2.m1.39.39.39.1.1.1" xref="S3.E2.m1.39.39.39.1.1.1.cmml">s</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E2.m1.53.53.4i"><mrow id="S3.E2.m1.53.53.4.52.12.11.11"><mrow id="S3.E2.m1.53.53.4.52.12.11.11.1"><mi id="S3.E2.m1.53.53.4.52.12.11.11.1.2"></mi><mo id="S3.E2.m1.40.40.40.2.1.1" xref="S3.E2.m1.40.40.40.2.1.1.cmml">=</mo><mrow id="S3.E2.m1.53.53.4.52.12.11.11.1.1.1"><mi id="S3.E2.m1.41.41.41.3.2.2" xref="S3.E2.m1.41.41.41.3.2.2.cmml">log</mi><mo id="S3.E2.m1.53.53.4.52.12.11.11.1.1.1a">â¡</mo><mrow id="S3.E2.m1.53.53.4.52.12.11.11.1.1.1.1"><mo stretchy="false" id="S3.E2.m1.42.42.42.4.3.3">(</mo><mrow id="S3.E2.m1.53.53.4.52.12.11.11.1.1.1.1.1"><msub id="S3.E2.m1.53.53.4.52.12.11.11.1.1.1.1.1.1"><mi id="S3.E2.m1.43.43.43.5.4.4" xref="S3.E2.m1.43.43.43.5.4.4.cmml">z</mi><mi id="S3.E2.m1.44.44.44.6.5.5.1" xref="S3.E2.m1.44.44.44.6.5.5.1.cmml">i</mi></msub><mo id="S3.E2.m1.45.45.45.7.6.6" xref="S3.E2.m1.45.45.45.7.6.6.cmml">/</mo><msub id="S3.E2.m1.53.53.4.52.12.11.11.1.1.1.1.1.2"><mi id="S3.E2.m1.46.46.46.8.7.7" xref="S3.E2.m1.46.46.46.8.7.7.cmml">z</mi><mi id="S3.E2.m1.47.47.47.9.8.8.1" xref="S3.E2.m1.47.47.47.9.8.8.1.cmml">f</mi></msub></mrow><mo stretchy="false" id="S3.E2.m1.48.48.48.10.9.9">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.49.49.49.11.10.10">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E2.m1.53b"><apply id="S3.E2.m1.50.50.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.3a.cmml">formulae-sequence</csymbol><apply id="S3.E2.m1.50.50.1.1.1.1.1.cmml"><eq id="S3.E2.m1.3.3.3.3.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1"></eq><apply id="S3.E2.m1.50.50.1.1.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.1.1.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1">ğ‘£</ci><ci id="S3.E2.m1.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2.1">ğ‘¥</ci></apply><apply id="S3.E2.m1.50.50.1.1.1.1.1.1.cmml"><times id="S3.E2.m1.50.50.1.1.1.1.1.1.2.cmml"></times><apply id="S3.E2.m1.50.50.1.1.1.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.1.1.1.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.4.4.4.4.2.2.cmml" xref="S3.E2.m1.4.4.4.4.2.2">ğ‘“</ci><ci id="S3.E2.m1.5.5.5.5.3.3.1.cmml" xref="S3.E2.m1.5.5.5.5.3.3.1">ğ‘¥</ci></apply><apply id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.cmml"><minus id="S3.E2.m1.12.12.12.12.10.10.cmml" xref="S3.E2.m1.12.12.12.12.10.10"></minus><apply id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.2.cmml"><divide id="S3.E2.m1.9.9.9.9.7.7.cmml" xref="S3.E2.m1.9.9.9.9.7.7"></divide><apply id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.2.2.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.2.2.1.cmml">subscript</csymbol><ci id="S3.E2.m1.7.7.7.7.5.5.cmml" xref="S3.E2.m1.7.7.7.7.5.5">ğ‘¥</ci><ci id="S3.E2.m1.8.8.8.8.6.6.1.cmml" xref="S3.E2.m1.8.8.8.8.6.6.1">ğ‘“</ci></apply><apply id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.2.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.2.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.10.10.10.10.8.8.cmml" xref="S3.E2.m1.10.10.10.10.8.8">ğ‘§</ci><ci id="S3.E2.m1.11.11.11.11.9.9.1.cmml" xref="S3.E2.m1.11.11.11.11.9.9.1">ğ‘“</ci></apply></apply><apply id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.3.cmml"><divide id="S3.E2.m1.15.15.15.15.13.13.cmml" xref="S3.E2.m1.15.15.15.15.13.13"></divide><apply id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.3.2.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.3.2.1.cmml">subscript</csymbol><ci id="S3.E2.m1.13.13.13.13.11.11.cmml" xref="S3.E2.m1.13.13.13.13.11.11">ğ‘¥</ci><ci id="S3.E2.m1.14.14.14.14.12.12.1.cmml" xref="S3.E2.m1.14.14.14.14.12.12.1">ğ‘–</ci></apply><apply id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.3.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.1.1.1.1.1.1.3.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.16.16.16.16.14.14.cmml" xref="S3.E2.m1.16.16.16.16.14.14">ğ‘§</ci><ci id="S3.E2.m1.17.17.17.17.15.15.1.cmml" xref="S3.E2.m1.17.17.17.17.15.15.1">ğ‘–</ci></apply></apply></apply></apply></apply><apply id="S3.E2.m1.50.50.1.1.1.2.2.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.2.2.3a.cmml">formulae-sequence</csymbol><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.cmml"><eq id="S3.E2.m1.22.22.22.3.1.1.cmml" xref="S3.E2.m1.22.22.22.3.1.1"></eq><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.2.2.1.1.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.20.20.20.1.1.1.cmml" xref="S3.E2.m1.20.20.20.1.1.1">ğ‘£</ci><ci id="S3.E2.m1.21.21.21.2.2.2.1.cmml" xref="S3.E2.m1.21.21.21.2.2.2.1">ğ‘¦</ci></apply><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.cmml"><times id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.2.cmml"></times><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.23.23.23.4.2.2.cmml" xref="S3.E2.m1.23.23.23.4.2.2">ğ‘“</ci><ci id="S3.E2.m1.24.24.24.5.3.3.1.cmml" xref="S3.E2.m1.24.24.24.5.3.3.1">ğ‘¦</ci></apply><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.cmml"><minus id="S3.E2.m1.31.31.31.12.10.10.cmml" xref="S3.E2.m1.31.31.31.12.10.10"></minus><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.2.cmml"><divide id="S3.E2.m1.28.28.28.9.7.7.cmml" xref="S3.E2.m1.28.28.28.9.7.7"></divide><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.2.2.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.2.2.1.cmml">subscript</csymbol><ci id="S3.E2.m1.26.26.26.7.5.5.cmml" xref="S3.E2.m1.26.26.26.7.5.5">ğ‘¦</ci><ci id="S3.E2.m1.27.27.27.8.6.6.1.cmml" xref="S3.E2.m1.27.27.27.8.6.6.1">ğ‘“</ci></apply><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.2.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.2.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.29.29.29.10.8.8.cmml" xref="S3.E2.m1.29.29.29.10.8.8">ğ‘§</ci><ci id="S3.E2.m1.30.30.30.11.9.9.1.cmml" xref="S3.E2.m1.30.30.30.11.9.9.1">ğ‘“</ci></apply></apply><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.3.cmml"><divide id="S3.E2.m1.34.34.34.15.13.13.cmml" xref="S3.E2.m1.34.34.34.15.13.13"></divide><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.3.2.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.3.2.1.cmml">subscript</csymbol><ci id="S3.E2.m1.32.32.32.13.11.11.cmml" xref="S3.E2.m1.32.32.32.13.11.11">ğ‘¦</ci><ci id="S3.E2.m1.33.33.33.14.12.12.1.cmml" xref="S3.E2.m1.33.33.33.14.12.12.1">ğ‘–</ci></apply><apply id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.3.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.2.2.1.1.1.1.1.1.3.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.35.35.35.16.14.14.cmml" xref="S3.E2.m1.35.35.35.16.14.14">ğ‘§</ci><ci id="S3.E2.m1.36.36.36.17.15.15.1.cmml" xref="S3.E2.m1.36.36.36.17.15.15.1">ğ‘–</ci></apply></apply></apply></apply></apply><apply id="S3.E2.m1.50.50.1.1.1.2.2.2.2.cmml"><eq id="S3.E2.m1.40.40.40.2.1.1.cmml" xref="S3.E2.m1.40.40.40.2.1.1"></eq><ci id="S3.E2.m1.39.39.39.1.1.1.cmml" xref="S3.E2.m1.39.39.39.1.1.1">ğ‘ </ci><apply id="S3.E2.m1.50.50.1.1.1.2.2.2.2.1.2.cmml"><log id="S3.E2.m1.41.41.41.3.2.2.cmml" xref="S3.E2.m1.41.41.41.3.2.2"></log><apply id="S3.E2.m1.50.50.1.1.1.2.2.2.2.1.1.1.1.cmml"><divide id="S3.E2.m1.45.45.45.7.6.6.cmml" xref="S3.E2.m1.45.45.45.7.6.6"></divide><apply id="S3.E2.m1.50.50.1.1.1.2.2.2.2.1.1.1.1.2.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.2.2.2.2.1.1.1.1.2.1.cmml">subscript</csymbol><ci id="S3.E2.m1.43.43.43.5.4.4.cmml" xref="S3.E2.m1.43.43.43.5.4.4">ğ‘§</ci><ci id="S3.E2.m1.44.44.44.6.5.5.1.cmml" xref="S3.E2.m1.44.44.44.6.5.5.1">ğ‘–</ci></apply><apply id="S3.E2.m1.50.50.1.1.1.2.2.2.2.1.1.1.1.3.cmml"><csymbol cd="ambiguous" id="S3.E2.m1.50.50.1.1.1.2.2.2.2.1.1.1.1.3.1.cmml">subscript</csymbol><ci id="S3.E2.m1.46.46.46.8.7.7.cmml" xref="S3.E2.m1.46.46.46.8.7.7">ğ‘§</ci><ci id="S3.E2.m1.47.47.47.9.8.8.1.cmml" xref="S3.E2.m1.47.47.47.9.8.8.1">ğ‘“</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.53c">\begin{split}v_{x}&amp;=f_{x}(x_{f}/z_{f}-x_{i}/z_{i}),\\
v_{y}&amp;=f_{y}(y_{f}/z_{f}-y_{i}/z_{i}),\\
s&amp;=\log(z_{i}/z_{f}),\\
\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.10" class="ltx_p">where <math id="S3.SS2.p2.8.m1.1" class="ltx_Math" alttext="f_{x}" display="inline"><semantics id="S3.SS2.p2.8.m1.1a"><msub id="S3.SS2.p2.8.m1.1.1" xref="S3.SS2.p2.8.m1.1.1.cmml"><mi id="S3.SS2.p2.8.m1.1.1.2" xref="S3.SS2.p2.8.m1.1.1.2.cmml">f</mi><mi id="S3.SS2.p2.8.m1.1.1.3" xref="S3.SS2.p2.8.m1.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m1.1b"><apply id="S3.SS2.p2.8.m1.1.1.cmml" xref="S3.SS2.p2.8.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m1.1.1.1.cmml" xref="S3.SS2.p2.8.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.8.m1.1.1.2.cmml" xref="S3.SS2.p2.8.m1.1.1.2">ğ‘“</ci><ci id="S3.SS2.p2.8.m1.1.1.3.cmml" xref="S3.SS2.p2.8.m1.1.1.3">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m1.1c">f_{x}</annotation></semantics></math> and <math id="S3.SS2.p2.9.m2.1" class="ltx_Math" alttext="f_{y}" display="inline"><semantics id="S3.SS2.p2.9.m2.1a"><msub id="S3.SS2.p2.9.m2.1.1" xref="S3.SS2.p2.9.m2.1.1.cmml"><mi id="S3.SS2.p2.9.m2.1.1.2" xref="S3.SS2.p2.9.m2.1.1.2.cmml">f</mi><mi id="S3.SS2.p2.9.m2.1.1.3" xref="S3.SS2.p2.9.m2.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m2.1b"><apply id="S3.SS2.p2.9.m2.1.1.cmml" xref="S3.SS2.p2.9.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m2.1.1.1.cmml" xref="S3.SS2.p2.9.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.9.m2.1.1.2.cmml" xref="S3.SS2.p2.9.m2.1.1.2">ğ‘“</ci><ci id="S3.SS2.p2.9.m2.1.1.3.cmml" xref="S3.SS2.p2.9.m2.1.1.3">ğ‘¦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m2.1c">f_{y}</annotation></semantics></math> are focal lengths defined by the intrinsic camera matrix. Using these relations, the final translation vector <math id="S3.SS2.p2.10.m3.1" class="ltx_Math" alttext="\mathbf{t_{f}}" display="inline"><semantics id="S3.SS2.p2.10.m3.1a"><msub id="S3.SS2.p2.10.m3.1.1" xref="S3.SS2.p2.10.m3.1.1.cmml"><mi id="S3.SS2.p2.10.m3.1.1.2" xref="S3.SS2.p2.10.m3.1.1.2.cmml">ğ­</mi><mi id="S3.SS2.p2.10.m3.1.1.3" xref="S3.SS2.p2.10.m3.1.1.3.cmml">ğŸ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m3.1b"><apply id="S3.SS2.p2.10.m3.1.1.cmml" xref="S3.SS2.p2.10.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m3.1.1.1.cmml" xref="S3.SS2.p2.10.m3.1.1">subscript</csymbol><ci id="S3.SS2.p2.10.m3.1.1.2.cmml" xref="S3.SS2.p2.10.m3.1.1.2">ğ­</ci><ci id="S3.SS2.p2.10.m3.1.1.3.cmml" xref="S3.SS2.p2.10.m3.1.1.3">ğŸ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m3.1c">\mathbf{t_{f}}</annotation></semantics></math> can be computed.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Training Loss</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.2" class="ltx_p">Same as in other 6D pose refinement papers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, we use a training loss that computes the average euclidean distance between the object points transformed by ground truth transformation <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="[\mathbf{R}|\mathbf{t}]" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p1.1.m1.1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.1.cmml">[</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.1.1.2.cmml">ğ‘</mi><mo fence="false" id="S3.SS3.p1.1.m1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS3.p1.1.m1.1.1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.1.1.3.cmml">ğ­</mi></mrow><mo stretchy="false" id="S3.SS3.p1.1.m1.1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS3.p1.1.m1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.2">ğ‘</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.3">ğ­</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">[\mathbf{R}|\mathbf{t}]</annotation></semantics></math> and predicted transformation <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="[\mathbf{R_{f}}|\mathbf{t_{f}}]" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1.1" xref="S3.SS3.p1.2.m2.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p1.2.m2.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.1.cmml">[</mo><mrow id="S3.SS3.p1.2.m2.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.cmml"><msub id="S3.SS3.p1.2.m2.1.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.1.2.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.2.2" xref="S3.SS3.p1.2.m2.1.1.1.1.2.2.cmml">ğ‘</mi><mi id="S3.SS3.p1.2.m2.1.1.1.1.2.3" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.cmml">ğŸ</mi></msub><mo fence="false" id="S3.SS3.p1.2.m2.1.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p1.2.m2.1.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.1.1.3.2.cmml">ğ­</mi><mi id="S3.SS3.p1.2.m2.1.1.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.1.1.3.3.cmml">ğŸ</mi></msub></mrow><mo stretchy="false" id="S3.SS3.p1.2.m2.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.2.m2.1.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS3.p1.2.m2.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p1.2.m2.1.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3">ğŸ</ci></apply><apply id="S3.SS3.p1.2.m2.1.1.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.3.2">ğ­</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.3.3">ğŸ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">[\mathbf{R_{f}}|\mathbf{t_{f}}]</annotation></semantics></math>:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="L_{1}=\frac{1}{m}\sum_{\mathbf{x}\in\mathcal{M}}{||(\mathbf{R}\mathbf{x}+\mathbf{t})-(\mathbf{R_{f}}\mathbf{x}+\mathbf{t_{f}})||}_{2}\quad," display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml">L</mi><mn id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3.cmml">1</mn></msub><mo id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mfrac id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml"><mn id="S3.E3.m1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.3.2.cmml">1</mn><mi id="S3.E3.m1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.3.3.cmml">m</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><munder id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E3.m1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2.3.2" xref="S3.E3.m1.1.1.1.1.1.1.2.3.2.cmml">ğ±</mi><mo id="S3.E3.m1.1.1.1.1.1.1.2.3.1" xref="S3.E3.m1.1.1.1.1.1.1.2.3.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.1.1.2.3.3" xref="S3.E3.m1.1.1.1.1.1.1.2.3.3.cmml">â„³</mi></mrow></munder><msub id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">ğ‘ğ±</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">ğ­</mi></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">âˆ’</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.cmml"><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml">ğ‘</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.3.cmml">ğŸ</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.3.cmml">ğ±</mi></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml">+</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.2.cmml">ğ­</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.3.cmml">ğŸ</mi></msub></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow></mrow><mspace width="1em" id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml"></mspace><mo id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"></eq><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2">ğ¿</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3">1</cn></apply><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3"><divide id="S3.E3.m1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3"></divide><cn type="integer" id="S3.E3.m1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2">1</cn><ci id="S3.E3.m1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3">ğ‘š</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><apply id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2">subscript</csymbol><sum id="S3.E3.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.2"></sum><apply id="S3.E3.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.3"><in id="S3.E3.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.3.1"></in><ci id="S3.E3.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.3.2">ğ±</ci><ci id="S3.E3.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.3.3">â„³</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3"></minus><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1"><plus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"></plus><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘ğ±</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ­</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1"><plus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.1"></plus><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2"><times id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.1"></times><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.2">ğ‘</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.3">ğŸ</ci></apply><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.2.3">ğ±</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.2">ğ­</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.1.3.3">ğŸ</ci></apply></apply></apply></apply><cn type="integer" id="S3.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">L_{1}=\frac{1}{m}\sum_{\mathbf{x}\in\mathcal{M}}{||(\mathbf{R}\mathbf{x}+\mathbf{t})-(\mathbf{R_{f}}\mathbf{x}+\mathbf{t_{f}})||}_{2}\quad,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.5" class="ltx_p">where <math id="S3.SS3.p1.3.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS3.p1.3.m1.1a"><mi id="S3.SS3.p1.3.m1.1.1" xref="S3.SS3.p1.3.m1.1.1.cmml">ğ±</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m1.1b"><ci id="S3.SS3.p1.3.m1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1">ğ±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m1.1c">\mathbf{x}</annotation></semantics></math> are the model points in the set <math id="S3.SS3.p1.4.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS3.p1.4.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.4.m2.1.1" xref="S3.SS3.p1.4.m2.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m2.1b"><ci id="S3.SS3.p1.4.m2.1.1.cmml" xref="S3.SS3.p1.4.m2.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m2.1c">\mathcal{M}</annotation></semantics></math>, which is a subset of CAD model vertices. The total number of points is <math id="S3.SS3.p1.5.m3.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS3.p1.5.m3.1a"><mi id="S3.SS3.p1.5.m3.1.1" xref="S3.SS3.p1.5.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m3.1b"><ci id="S3.SS3.p1.5.m3.1.1.cmml" xref="S3.SS3.p1.5.m3.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m3.1c">m</annotation></semantics></math>. In the refinement methods, the initial poses during training are generated by adding random noise to the ground truth pose. The separate training loss for symmetric objects is not used because the initial pose is closest to the ground truth pose among all symmetric poses. In the case of multi-stage prediction, we compute the loss after each stage. The final loss is the average loss over the four stages.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Implementation Details</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The original image is cropped around the center of the initial pose projection. As suggested in DeepIM, we crop the area <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="1.4" display="inline"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">1.4</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn type="float" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">1.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">1.4</annotation></semantics></math> times the size of the image object. It is then resized to 152x152 before being input into our refinement network. To generate the initial pose image, we use a differentiable render from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. However, we do not use differentiable renderer functionality to backpropagate the gradients through the renderer. We tested this option, but there was no difference compared to the case when the gradients were blocked.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.10" class="ltx_p">We train our network on a Pascal Titan X GPU and use the Stochastic Gradient Descent (SGD) optimizer. We train our single-stage model for <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="150" display="inline"><semantics id="S4.p2.1.m1.1a"><mn id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">150</mn><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><cn type="integer" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">150</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">150</annotation></semantics></math> epoch with learning rate <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="1\times 10^{-2}" display="inline"><semantics id="S4.p2.2.m2.1a"><mrow id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mn id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.p2.2.m2.1.1.1" xref="S4.p2.2.m2.1.1.1.cmml">Ã—</mo><msup id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml"><mn id="S4.p2.2.m2.1.1.3.2" xref="S4.p2.2.m2.1.1.3.2.cmml">10</mn><mrow id="S4.p2.2.m2.1.1.3.3" xref="S4.p2.2.m2.1.1.3.3.cmml"><mo id="S4.p2.2.m2.1.1.3.3a" xref="S4.p2.2.m2.1.1.3.3.cmml">âˆ’</mo><mn id="S4.p2.2.m2.1.1.3.3.2" xref="S4.p2.2.m2.1.1.3.3.2.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><times id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1"></times><cn type="integer" id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">1</cn><apply id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.3.1.cmml" xref="S4.p2.2.m2.1.1.3">superscript</csymbol><cn type="integer" id="S4.p2.2.m2.1.1.3.2.cmml" xref="S4.p2.2.m2.1.1.3.2">10</cn><apply id="S4.p2.2.m2.1.1.3.3.cmml" xref="S4.p2.2.m2.1.1.3.3"><minus id="S4.p2.2.m2.1.1.3.3.1.cmml" xref="S4.p2.2.m2.1.1.3.3"></minus><cn type="integer" id="S4.p2.2.m2.1.1.3.3.2.cmml" xref="S4.p2.2.m2.1.1.3.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">1\times 10^{-2}</annotation></semantics></math>. The learning rate is then decreased to <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="1\times 10^{-3}" display="inline"><semantics id="S4.p2.3.m3.1a"><mrow id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mn id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.p2.3.m3.1.1.1" xref="S4.p2.3.m3.1.1.1.cmml">Ã—</mo><msup id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml"><mn id="S4.p2.3.m3.1.1.3.2" xref="S4.p2.3.m3.1.1.3.2.cmml">10</mn><mrow id="S4.p2.3.m3.1.1.3.3" xref="S4.p2.3.m3.1.1.3.3.cmml"><mo id="S4.p2.3.m3.1.1.3.3a" xref="S4.p2.3.m3.1.1.3.3.cmml">âˆ’</mo><mn id="S4.p2.3.m3.1.1.3.3.2" xref="S4.p2.3.m3.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><times id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1"></times><cn type="integer" id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">1</cn><apply id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.3.1.cmml" xref="S4.p2.3.m3.1.1.3">superscript</csymbol><cn type="integer" id="S4.p2.3.m3.1.1.3.2.cmml" xref="S4.p2.3.m3.1.1.3.2">10</cn><apply id="S4.p2.3.m3.1.1.3.3.cmml" xref="S4.p2.3.m3.1.1.3.3"><minus id="S4.p2.3.m3.1.1.3.3.1.cmml" xref="S4.p2.3.m3.1.1.3.3"></minus><cn type="integer" id="S4.p2.3.m3.1.1.3.3.2.cmml" xref="S4.p2.3.m3.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">1\times 10^{-3}</annotation></semantics></math> over next <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.p2.4.m4.1a"><mn id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><cn type="integer" id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">50</annotation></semantics></math> epochs. Further weight decay did not result in any improvement. We train the single-stage network from scratch with a batch size of <math id="S4.p2.5.m5.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.p2.5.m5.1a"><mn id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><cn type="integer" id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">32</annotation></semantics></math>. To train the multi-stage network, we initialize each stage of the network with the weights from the single-stage model. We perform a warm-up to speed up the training time. In multi-stage setting, we use four stages of our model. We use batch size of <math id="S4.p2.6.m6.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.p2.6.m6.1a"><mn id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.1b"><cn type="integer" id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.1c">8</annotation></semantics></math> due to GPU memory limitation. We train our multi-stage model for <math id="S4.p2.7.m7.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.p2.7.m7.1a"><mn id="S4.p2.7.m7.1.1" xref="S4.p2.7.m7.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.p2.7.m7.1b"><cn type="integer" id="S4.p2.7.m7.1.1.cmml" xref="S4.p2.7.m7.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.7.m7.1c">50</annotation></semantics></math> epoch with learning rate <math id="S4.p2.8.m8.1" class="ltx_Math" alttext="7\times 10^{-3}" display="inline"><semantics id="S4.p2.8.m8.1a"><mrow id="S4.p2.8.m8.1.1" xref="S4.p2.8.m8.1.1.cmml"><mn id="S4.p2.8.m8.1.1.2" xref="S4.p2.8.m8.1.1.2.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="S4.p2.8.m8.1.1.1" xref="S4.p2.8.m8.1.1.1.cmml">Ã—</mo><msup id="S4.p2.8.m8.1.1.3" xref="S4.p2.8.m8.1.1.3.cmml"><mn id="S4.p2.8.m8.1.1.3.2" xref="S4.p2.8.m8.1.1.3.2.cmml">10</mn><mrow id="S4.p2.8.m8.1.1.3.3" xref="S4.p2.8.m8.1.1.3.3.cmml"><mo id="S4.p2.8.m8.1.1.3.3a" xref="S4.p2.8.m8.1.1.3.3.cmml">âˆ’</mo><mn id="S4.p2.8.m8.1.1.3.3.2" xref="S4.p2.8.m8.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.8.m8.1b"><apply id="S4.p2.8.m8.1.1.cmml" xref="S4.p2.8.m8.1.1"><times id="S4.p2.8.m8.1.1.1.cmml" xref="S4.p2.8.m8.1.1.1"></times><cn type="integer" id="S4.p2.8.m8.1.1.2.cmml" xref="S4.p2.8.m8.1.1.2">7</cn><apply id="S4.p2.8.m8.1.1.3.cmml" xref="S4.p2.8.m8.1.1.3"><csymbol cd="ambiguous" id="S4.p2.8.m8.1.1.3.1.cmml" xref="S4.p2.8.m8.1.1.3">superscript</csymbol><cn type="integer" id="S4.p2.8.m8.1.1.3.2.cmml" xref="S4.p2.8.m8.1.1.3.2">10</cn><apply id="S4.p2.8.m8.1.1.3.3.cmml" xref="S4.p2.8.m8.1.1.3.3"><minus id="S4.p2.8.m8.1.1.3.3.1.cmml" xref="S4.p2.8.m8.1.1.3.3"></minus><cn type="integer" id="S4.p2.8.m8.1.1.3.3.2.cmml" xref="S4.p2.8.m8.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.8.m8.1c">7\times 10^{-3}</annotation></semantics></math>, when learning rate is decreased to <math id="S4.p2.9.m9.1" class="ltx_Math" alttext="7\times 10^{-4}" display="inline"><semantics id="S4.p2.9.m9.1a"><mrow id="S4.p2.9.m9.1.1" xref="S4.p2.9.m9.1.1.cmml"><mn id="S4.p2.9.m9.1.1.2" xref="S4.p2.9.m9.1.1.2.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="S4.p2.9.m9.1.1.1" xref="S4.p2.9.m9.1.1.1.cmml">Ã—</mo><msup id="S4.p2.9.m9.1.1.3" xref="S4.p2.9.m9.1.1.3.cmml"><mn id="S4.p2.9.m9.1.1.3.2" xref="S4.p2.9.m9.1.1.3.2.cmml">10</mn><mrow id="S4.p2.9.m9.1.1.3.3" xref="S4.p2.9.m9.1.1.3.3.cmml"><mo id="S4.p2.9.m9.1.1.3.3a" xref="S4.p2.9.m9.1.1.3.3.cmml">âˆ’</mo><mn id="S4.p2.9.m9.1.1.3.3.2" xref="S4.p2.9.m9.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.9.m9.1b"><apply id="S4.p2.9.m9.1.1.cmml" xref="S4.p2.9.m9.1.1"><times id="S4.p2.9.m9.1.1.1.cmml" xref="S4.p2.9.m9.1.1.1"></times><cn type="integer" id="S4.p2.9.m9.1.1.2.cmml" xref="S4.p2.9.m9.1.1.2">7</cn><apply id="S4.p2.9.m9.1.1.3.cmml" xref="S4.p2.9.m9.1.1.3"><csymbol cd="ambiguous" id="S4.p2.9.m9.1.1.3.1.cmml" xref="S4.p2.9.m9.1.1.3">superscript</csymbol><cn type="integer" id="S4.p2.9.m9.1.1.3.2.cmml" xref="S4.p2.9.m9.1.1.3.2">10</cn><apply id="S4.p2.9.m9.1.1.3.3.cmml" xref="S4.p2.9.m9.1.1.3.3"><minus id="S4.p2.9.m9.1.1.3.3.1.cmml" xref="S4.p2.9.m9.1.1.3.3"></minus><cn type="integer" id="S4.p2.9.m9.1.1.3.3.2.cmml" xref="S4.p2.9.m9.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.9.m9.1c">7\times 10^{-4}</annotation></semantics></math> and the model is trained for another <math id="S4.p2.10.m10.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.p2.10.m10.1a"><mn id="S4.p2.10.m10.1.1" xref="S4.p2.10.m10.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.p2.10.m10.1b"><cn type="integer" id="S4.p2.10.m10.1.1.cmml" xref="S4.p2.10.m10.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.10.m10.1c">20</annotation></semantics></math> epochs.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Training Data</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We use the training data provided by the authors of PVNet, which consists of three datasets with objects from the LineMOD dataset. The first dataset contains real training data provided by the LineMOD dataset. The small number, roughly 1000 of images are sampled from the LineMOD sequences and are provided for training. The remainder of the dataset, around 13000 images, is used for testing only. However, this training dataset is too small to train deep neural networks. The second dataset contains 13000 synthetic images, 1000 for each object. To synthesize images, CAD models are rendered at different spatial positions, and the background and light sources are randomized. In this dataset, only a single object appears in the image without any occluders. The third dataset crops patches of LineMOD objects from real training data. These patches are then pasted over random backgrounds. When generating this dataset, multiple objects are placed in the same image, which can generate occlusions. This dataset contains 10000 images.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">The task of the refiner is to improve the pose that is already close to the ground truth pose. The examples of initialization poses are shown in Fig. <a href="#S5.F3" title="Figure 3 â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Thus, we can simulate the test scenario by adding random noise to ground truth poses. To generate the second input to the network at training time, we render the object at a randomized initial position. The rendered images are generated on the fly via a differentiable renderer. We generate randomized initial positions by adding noise to the ground truth position and feed them to the differentiable renderer.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<figure id="S5.F3" class="ltx_figure"><img src="/html/2101.01659/assets/figures/examples.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="651" height="320" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Examples of the object pose estimation. The red object outlines show the initial pose obtained from PVNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. The green outlines indicate the pose obtained via our refiner.</figcaption>
</figure>
<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we evaluate our approach in a series of experiments. We compare our approach with state-of-the-art methods and provide experimental evidence that the attention mechanism helps in the 6D pose refinement task.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Test Datasets</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Inline with previous work, in our experiments we use two datasets, namely LineMOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> and Occlusion LineMOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. The LineMOD dataset is a standard dataset for the evaluation of 6D pose estimation methods. The dataset contains 13 sequences of 13 different objects recorded in a cluttered environment. In this dataset, objects are fully visible. To test 6D pose estimation in the presence of occlusions, the Occlusion LineMOD has been introduced <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. This dataset contains 8 LineMOD objects that appear under occlusions.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Evaluation Metric</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">For evaluation, we use the standard ADD(-S) evaluation metric as is done in most 6D pose estimation papers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. ADD measures the average distance between the model points transformed by ground truth and the estimated poses. For symmetric objects, we use ADD-S, which is a modification of ADD that takes the symmetries of objects into account. In ADD-S the distance between the two closest points is used rather then measuring the euclidean distance between the all model points. In most of our results, we use a success rate threshold of <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="0.1d" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">0.1</mn><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><times id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1"></times><cn type="float" id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">0.1</cn><ci id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">0.1d</annotation></semantics></math> for ADD(-S), following related work.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Baselines</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We compare our modelâ€™s performance with the SoA 6D pose refiners DeepIM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and DPOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. For DeepIM, we use the implementation provided by the authors. Since no publicly available implementation of DPOD exists, we use our own re-implementation, trained using the same data and randomization parameters as in our method. Moreover, we perform an ablation study to showcase the effect of the proposed attention model. To attain a baseline for the ablation, we train an additional model consisting of our backbone model, i.e., DenseNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, and three output streams. In each output stream, we use two fully connected layers instead of the attention block. Since the ablation baseline does not predict attention maps, we use standard DenseNet instead of DenseNet for semantic segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Standard DenseNet has the optimal structure for regression tasks. The ablation baseline has the same number of parameters as our model. For more details about our baseline model, please refer to supplementary materials.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Clearly, the final pose estimate depends on the initial pose prediction. We use the SoA in the one-shot setting, PVNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, for initialization. This allows for a comparison of refiners independently of the initialization method. Note that the settings reported in DPOD and DeepIM are incompatible (wrt to initialization), and hence we provide a new, directly comparable setting. The final performance of a refiner depends on the initialization (e.g., from PVNet). Thus, similar but not identical results, as reported in respective papers, are to be expected. On the LineMOD dataset, our baselines reach similar scores to ones reported in the original papers suggesting that our implementations are well tuned. On the Occlusion LineMOD dataset, the DPOD refiner performs slightly worse than reported in the paper. This is because in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, a part of the test sequence is used as training data, which makes the task easier. In the original Occlusion LineMOD settings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, the test sequence is not used for training. Both DeepIM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and our work uses the original setting.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.3.1.1" class="ltx_tr">
<th id="S5.T1.3.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_tt"></th>
<th id="S5.T1.3.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S5.T1.3.1.1.3" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S5.T1.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T1.3.1.1.4.1" class="ltx_text" style="font-size:70%;">Single stage</span></th>
<th id="S5.T1.3.1.1.5" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="S5.T1.3.1.1.6" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="S5.T1.3.1.1.7" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S5.T1.3.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T1.3.1.1.8.1" class="ltx_text" style="font-size:70%;">Multi stage</span></th>
<th id="S5.T1.3.1.1.9" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
</tr>
<tr id="S5.T1.3.2.2" class="ltx_tr">
<th id="S5.T1.3.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l"></th>
<th id="S5.T1.3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S5.T1.3.2.2.2.1" class="ltx_text" style="font-size:70%;">PVNet init</span></th>
<th id="S5.T1.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.2.2.3.1" class="ltx_text" style="font-size:70%;">DPOD</span></th>
<th id="S5.T1.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.2.2.4.1" class="ltx_text" style="font-size:70%;">DenseNet</span></th>
<th id="S5.T1.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T1.3.2.2.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ours</span></th>
<th id="S5.T1.3.2.2.6" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S5.T1.3.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.2.2.7.1" class="ltx_text" style="font-size:70%;">DeepIM</span></th>
<th id="S5.T1.3.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.2.2.8.1" class="ltx_text" style="font-size:70%;">DenseNet</span></th>
<th id="S5.T1.3.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T1.3.2.2.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ours</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.3.3.1" class="ltx_tr">
<th id="S5.T1.3.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t"><span id="S5.T1.3.3.1.1.1" class="ltx_text" style="font-size:70%;">ape</span></th>
<th id="S5.T1.3.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T1.3.3.1.2.1" class="ltx_text" style="font-size:70%;">48.76</span></th>
<td id="S5.T1.3.3.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.3.3.1.3.1" class="ltx_text" style="font-size:70%;">70.67</span></td>
<td id="S5.T1.3.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.3.3.1.4.1" class="ltx_text" style="font-size:70%;">76.10</span></td>
<td id="S5.T1.3.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T1.3.3.1.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">78.57</span></td>
<td id="S5.T1.3.3.1.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T1.3.3.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.3.3.1.7.1" class="ltx_text" style="font-size:70%;">78.10</span></td>
<td id="S5.T1.3.3.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.3.3.1.8.1" class="ltx_text" style="font-size:70%;">76.95</span></td>
<td id="S5.T1.3.3.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T1.3.3.1.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">80.76</span></td>
</tr>
<tr id="S5.T1.3.4.2" class="ltx_tr">
<th id="S5.T1.3.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.4.2.1.1" class="ltx_text" style="font-size:70%;">benchvise</span></th>
<th id="S5.T1.3.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.4.2.2.1" class="ltx_text" style="font-size:70%;">99.03</span></th>
<td id="S5.T1.3.4.2.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.4.2.3.1" class="ltx_text" style="font-size:70%;">99.42</span></td>
<td id="S5.T1.3.4.2.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.4.2.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.52</span></td>
<td id="S5.T1.3.4.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.4.2.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.52</span></td>
<td id="S5.T1.3.4.2.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.4.2.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.4.2.7.1" class="ltx_text" style="font-size:70%;">98.16</span></td>
<td id="S5.T1.3.4.2.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.4.2.8.1" class="ltx_text" style="font-size:70%;">99.32</span></td>
<td id="S5.T1.3.4.2.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.4.2.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.61</span></td>
</tr>
<tr id="S5.T1.3.5.3" class="ltx_tr">
<th id="S5.T1.3.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.5.3.1.1" class="ltx_text" style="font-size:70%;">cam</span></th>
<th id="S5.T1.3.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.5.3.2.1" class="ltx_text" style="font-size:70%;">87.06</span></th>
<td id="S5.T1.3.5.3.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.5.3.3.1" class="ltx_text" style="font-size:70%;">95.20</span></td>
<td id="S5.T1.3.5.3.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.5.3.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">95.29</span></td>
<td id="S5.T1.3.5.3.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.5.3.5.1" class="ltx_text" style="font-size:70%;">93.73</span></td>
<td id="S5.T1.3.5.3.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.5.3.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.5.3.7.1" class="ltx_text" style="font-size:70%;">95.49</span></td>
<td id="S5.T1.3.5.3.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.5.3.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">97.16</span></td>
<td id="S5.T1.3.5.3.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.5.3.9.1" class="ltx_text" style="font-size:70%;">95.88</span></td>
</tr>
<tr id="S5.T1.3.6.4" class="ltx_tr">
<th id="S5.T1.3.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.6.4.1.1" class="ltx_text" style="font-size:70%;">can</span></th>
<th id="S5.T1.3.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.6.4.2.1" class="ltx_text" style="font-size:70%;">96.85</span></th>
<td id="S5.T1.3.6.4.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.6.4.3.1" class="ltx_text" style="font-size:70%;">98.92</span></td>
<td id="S5.T1.3.6.4.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.6.4.4.1" class="ltx_text" style="font-size:70%;">98.92</span></td>
<td id="S5.T1.3.6.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.6.4.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.41</span></td>
<td id="S5.T1.3.6.4.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.6.4.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.6.4.7.1" class="ltx_text" style="font-size:70%;">98.03</span></td>
<td id="S5.T1.3.6.4.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.6.4.8.1" class="ltx_text" style="font-size:70%;">99.61</span></td>
<td id="S5.T1.3.6.4.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.6.4.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.80</span></td>
</tr>
<tr id="S5.T1.3.7.5" class="ltx_tr">
<th id="S5.T1.3.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.7.5.1.1" class="ltx_text" style="font-size:70%;">cat</span></th>
<th id="S5.T1.3.7.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.7.5.2.1" class="ltx_text" style="font-size:70%;">77.94</span></th>
<td id="S5.T1.3.7.5.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.7.5.3.1" class="ltx_text" style="font-size:70%;">90.92</span></td>
<td id="S5.T1.3.7.5.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.7.5.4.1" class="ltx_text" style="font-size:70%;">92.51</span></td>
<td id="S5.T1.3.7.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.7.5.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">93.11</span></td>
<td id="S5.T1.3.7.5.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.7.5.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.7.5.7.1" class="ltx_text" style="font-size:70%;">83.93</span></td>
<td id="S5.T1.3.7.5.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.7.5.8.1" class="ltx_text" style="font-size:70%;">93.41</span></td>
<td id="S5.T1.3.7.5.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.7.5.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">94.31</span></td>
</tr>
<tr id="S5.T1.3.8.6" class="ltx_tr">
<th id="S5.T1.3.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.8.6.1.1" class="ltx_text" style="font-size:70%;">driller</span></th>
<th id="S5.T1.3.8.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.8.6.2.1" class="ltx_text" style="font-size:70%;">96.53</span></th>
<td id="S5.T1.3.8.6.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.8.6.3.1" class="ltx_text" style="font-size:70%;">98.51</span></td>
<td id="S5.T1.3.8.6.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.8.6.4.1" class="ltx_text" style="font-size:70%;">98.32</span></td>
<td id="S5.T1.3.8.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.8.6.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">98.71</span></td>
<td id="S5.T1.3.8.6.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.8.6.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.8.6.7.1" class="ltx_text" style="font-size:70%;">95.44</span></td>
<td id="S5.T1.3.8.6.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.8.6.8.1" class="ltx_text" style="font-size:70%;">98.41</span></td>
<td id="S5.T1.3.8.6.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.8.6.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">98.81</span></td>
</tr>
<tr id="S5.T1.3.9.7" class="ltx_tr">
<th id="S5.T1.3.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.9.7.1.1" class="ltx_text" style="font-size:70%;">duck</span></th>
<th id="S5.T1.3.9.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.9.7.2.1" class="ltx_text" style="font-size:70%;">55.40</span></th>
<td id="S5.T1.3.9.7.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.9.7.3.1" class="ltx_text" style="font-size:70%;">76.90</span></td>
<td id="S5.T1.3.9.7.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.9.7.4.1" class="ltx_text" style="font-size:70%;">79.62</span></td>
<td id="S5.T1.3.9.7.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.9.7.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">81.78</span></td>
<td id="S5.T1.3.9.7.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.9.7.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.9.7.7.1" class="ltx_text" style="font-size:70%;">79.91</span></td>
<td id="S5.T1.3.9.7.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.9.7.8.1" class="ltx_text" style="font-size:70%;">82.25</span></td>
<td id="S5.T1.3.9.7.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.9.7.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">85.26</span></td>
</tr>
<tr id="S5.T1.3.10.8" class="ltx_tr">
<th id="S5.T1.3.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.10.8.1.1" class="ltx_text" style="font-size:70%;">eggbox</span></th>
<th id="S5.T1.3.10.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.10.8.2.1" class="ltx_text" style="font-size:70%;">99.72</span></th>
<td id="S5.T1.3.10.8.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.10.8.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">100.00</span></td>
<td id="S5.T1.3.10.8.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.10.8.4.1" class="ltx_text" style="font-size:70%;">99.81</span></td>
<td id="S5.T1.3.10.8.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.10.8.5.1" class="ltx_text" style="font-size:70%;">99.81</span></td>
<td id="S5.T1.3.10.8.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.10.8.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.10.8.7.1" class="ltx_text" style="font-size:70%;">90.80</span></td>
<td id="S5.T1.3.10.8.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.10.8.8.1" class="ltx_text" style="font-size:70%;">99.81</span></td>
<td id="S5.T1.3.10.8.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.10.8.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">100.00</span></td>
</tr>
<tr id="S5.T1.3.11.9" class="ltx_tr">
<th id="S5.T1.3.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.11.9.1.1" class="ltx_text" style="font-size:70%;">glue</span></th>
<th id="S5.T1.3.11.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.11.9.2.1" class="ltx_text" style="font-size:70%;">82.24</span></th>
<td id="S5.T1.3.11.9.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.11.9.3.1" class="ltx_text" style="font-size:70%;">83.59</span></td>
<td id="S5.T1.3.11.9.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.11.9.4.1" class="ltx_text" style="font-size:70%;">83.59</span></td>
<td id="S5.T1.3.11.9.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.11.9.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">83.69</span></td>
<td id="S5.T1.3.11.9.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.11.9.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.11.9.7.1" class="ltx_text" style="font-size:70%;">78.47</span></td>
<td id="S5.T1.3.11.9.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.11.9.8.1" class="ltx_text" style="font-size:70%;">83.49</span></td>
<td id="S5.T1.3.11.9.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.11.9.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">83.78</span></td>
</tr>
<tr id="S5.T1.3.12.10" class="ltx_tr">
<th id="S5.T1.3.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.12.10.1.1" class="ltx_text" style="font-size:70%;">holepuncher</span></th>
<th id="S5.T1.3.12.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.12.10.2.1" class="ltx_text" style="font-size:70%;">79.64</span></th>
<td id="S5.T1.3.12.10.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.12.10.3.1" class="ltx_text" style="font-size:70%;">87.73</span></td>
<td id="S5.T1.3.12.10.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.12.10.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">91.53</span></td>
<td id="S5.T1.3.12.10.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.12.10.5.1" class="ltx_text" style="font-size:70%;">90.58</span></td>
<td id="S5.T1.3.12.10.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.12.10.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.12.10.7.1" class="ltx_text" style="font-size:70%;">46.81</span></td>
<td id="S5.T1.3.12.10.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.12.10.8.1" class="ltx_text" style="font-size:70%;">89.34</span></td>
<td id="S5.T1.3.12.10.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.12.10.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">90.10</span></td>
</tr>
<tr id="S5.T1.3.13.11" class="ltx_tr">
<th id="S5.T1.3.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.13.11.1.1" class="ltx_text" style="font-size:70%;">iron</span></th>
<th id="S5.T1.3.13.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.13.11.2.1" class="ltx_text" style="font-size:70%;">98.37</span></th>
<td id="S5.T1.3.13.11.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.13.11.3.1" class="ltx_text" style="font-size:70%;">98.98</span></td>
<td id="S5.T1.3.13.11.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.13.11.4.1" class="ltx_text" style="font-size:70%;">98.77</span></td>
<td id="S5.T1.3.13.11.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.13.11.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.08</span></td>
<td id="S5.T1.3.13.11.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.13.11.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.13.11.7.1" class="ltx_text" style="font-size:70%;">99.18</span></td>
<td id="S5.T1.3.13.11.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.13.11.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.59</span></td>
<td id="S5.T1.3.13.11.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.13.11.9.1" class="ltx_text" style="font-size:70%;">98.77</span></td>
</tr>
<tr id="S5.T1.3.14.12" class="ltx_tr">
<th id="S5.T1.3.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.14.12.1.1" class="ltx_text" style="font-size:70%;">lamp</span></th>
<th id="S5.T1.3.14.12.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.14.12.2.1" class="ltx_text" style="font-size:70%;">99.33</span></th>
<td id="S5.T1.3.14.12.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.14.12.3.1" class="ltx_text" style="font-size:70%;">99.90</span></td>
<td id="S5.T1.3.14.12.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.14.12.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">100.00</span></td>
<td id="S5.T1.3.14.12.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.14.12.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">100.00</span></td>
<td id="S5.T1.3.14.12.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.14.12.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.14.12.7.1" class="ltx_text" style="font-size:70%;">98.46</span></td>
<td id="S5.T1.3.14.12.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.14.12.8.1" class="ltx_text" style="font-size:70%;">99.90</span></td>
<td id="S5.T1.3.14.12.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.14.12.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">100.00</span></td>
</tr>
<tr id="S5.T1.3.15.13" class="ltx_tr">
<th id="S5.T1.3.15.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T1.3.15.13.1.1" class="ltx_text" style="font-size:70%;">phone</span></th>
<th id="S5.T1.3.15.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.3.15.13.2.1" class="ltx_text" style="font-size:70%;">91.45</span></th>
<td id="S5.T1.3.15.13.3" class="ltx_td ltx_align_center"><span id="S5.T1.3.15.13.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">97.60</span></td>
<td id="S5.T1.3.15.13.4" class="ltx_td ltx_align_center"><span id="S5.T1.3.15.13.4.1" class="ltx_text" style="font-size:70%;">97.31</span></td>
<td id="S5.T1.3.15.13.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.15.13.5.1" class="ltx_text" style="font-size:70%;">97.12</span></td>
<td id="S5.T1.3.15.13.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T1.3.15.13.7" class="ltx_td ltx_align_center"><span id="S5.T1.3.15.13.7.1" class="ltx_text" style="font-size:70%;">89.91</span></td>
<td id="S5.T1.3.15.13.8" class="ltx_td ltx_align_center"><span id="S5.T1.3.15.13.8.1" class="ltx_text" style="font-size:70%;">97.98</span></td>
<td id="S5.T1.3.15.13.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.3.15.13.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">98.56</span></td>
</tr>
<tr id="S5.T1.3.16.14" class="ltx_tr">
<th id="S5.T1.3.16.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_t"><span id="S5.T1.3.16.14.1.1" class="ltx_text" style="font-size:70%;">MEAN</span></th>
<th id="S5.T1.3.16.14.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T1.3.16.14.2.1" class="ltx_text" style="font-size:70%;">85.56</span></th>
<td id="S5.T1.3.16.14.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T1.3.16.14.3.1" class="ltx_text" style="font-size:70%;">92.18</span></td>
<td id="S5.T1.3.16.14.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T1.3.16.14.4.1" class="ltx_text" style="font-size:70%;">93.18</span></td>
<td id="S5.T1.3.16.14.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T1.3.16.14.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">93.47</span></td>
<td id="S5.T1.3.16.14.6" class="ltx_td ltx_border_bb ltx_border_r ltx_border_t"></td>
<td id="S5.T1.3.16.14.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T1.3.16.14.7.1" class="ltx_text" style="font-size:70%;">87.13</span></td>
<td id="S5.T1.3.16.14.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T1.3.16.14.8.1" class="ltx_text" style="font-size:70%;">93.63</span></td>
<td id="S5.T1.3.16.14.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T1.3.16.14.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">94.28</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Pose estimation performance on the LineMOD dataset. The table shows percentage of correctly estimated poses using <math id="S5.T1.2.m1.1" class="ltx_Math" alttext="0.1d" display="inline"><semantics id="S5.T1.2.m1.1b"><mrow id="S5.T1.2.m1.1.1" xref="S5.T1.2.m1.1.1.cmml"><mn id="S5.T1.2.m1.1.1.2" xref="S5.T1.2.m1.1.1.2.cmml">0.1</mn><mo lspace="0em" rspace="0em" id="S5.T1.2.m1.1.1.1" xref="S5.T1.2.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T1.2.m1.1.1.3" xref="S5.T1.2.m1.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.m1.1c"><apply id="S5.T1.2.m1.1.1.cmml" xref="S5.T1.2.m1.1.1"><times id="S5.T1.2.m1.1.1.1.cmml" xref="S5.T1.2.m1.1.1.1"></times><cn type="float" id="S5.T1.2.m1.1.1.2.cmml" xref="S5.T1.2.m1.1.1.2">0.1</cn><ci id="S5.T1.2.m1.1.1.3.cmml" xref="S5.T1.2.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.m1.1d">0.1d</annotation></semantics></math> ADD(-S) threshold (higher is better). For initialization, we use 6D poses obtained from PVNet (the performance of the initial poses is shown in the left-most column). Since the initialization points are different compared to the original papers, similar but not identical results are to be expected. Our method performs comparable or better than prior work and our DenseNet baseline for most objects and outperforms the SoA on average.</figcaption>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>LineMOD Results</h3>

<figure id="S5.T2" class="ltx_table">
<div id="S5.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:411.9pt;height:459.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(76.9pt,-85.8pt) scale(1.59586659761446,1.59586659761446) ;">
<table id="S5.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T2.1.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S5.T2.1.1.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S5.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.1.1.1.1.3.1" class="ltx_text" style="font-size:70%;">DenseNet</span></th>
<th id="S5.T2.1.1.1.1.4" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S5.T2.1.1.1.1.5" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S5.T2.1.1.1.1.6" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S5.T2.1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.1.1.1.1.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ours</span></th>
<td id="S5.T2.1.1.1.1.8" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S5.T2.1.1.2.2" class="ltx_tr">
<th id="S5.T2.1.1.2.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S5.T2.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.1.1.2.2.2.1" class="ltx_text" style="font-size:70%;">0.1 d</span></th>
<th id="S5.T2.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.1.1.2.2.3.1" class="ltx_text" style="font-size:70%;">0.05 d</span></th>
<th id="S5.T2.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.1.1.2.2.4.1" class="ltx_text" style="font-size:70%;">0.02 d</span></th>
<th id="S5.T2.1.1.2.2.5" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S5.T2.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.1.1.2.2.6.1" class="ltx_text" style="font-size:70%;">0.1 d</span></th>
<th id="S5.T2.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.1.1.2.2.7.1" class="ltx_text" style="font-size:70%;">0.05 d</span></th>
<th id="S5.T2.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.1.1.2.2.8.1" class="ltx_text" style="font-size:70%;">0.02 d</span></th>
</tr>
<tr id="S5.T2.1.1.3.3" class="ltx_tr">
<th id="S5.T2.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S5.T2.1.1.3.3.1.1" class="ltx_text" style="font-size:70%;">ape</span></th>
<td id="S5.T2.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.1.1.3.3.2.1" class="ltx_text" style="font-size:70%;">76.95</span></td>
<td id="S5.T2.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.1.1.3.3.3.1" class="ltx_text" style="font-size:70%;">48.00</span></td>
<td id="S5.T2.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.1.1.3.3.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">11.62</span></td>
<td id="S5.T2.1.1.3.3.5" class="ltx_td ltx_border_t"></td>
<td id="S5.T2.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.1.1.3.3.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">80.76</span></td>
<td id="S5.T2.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.1.1.3.3.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">50.76</span></td>
<td id="S5.T2.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.1.1.3.3.8.1" class="ltx_text" style="font-size:70%;">8.57</span></td>
</tr>
<tr id="S5.T2.1.1.4.4" class="ltx_tr">
<th id="S5.T2.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.4.4.1.1" class="ltx_text" style="font-size:70%;">benchvise</span></th>
<td id="S5.T2.1.1.4.4.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.4.4.2.1" class="ltx_text" style="font-size:70%;">99.32</span></td>
<td id="S5.T2.1.1.4.4.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.4.4.3.1" class="ltx_text" style="font-size:70%;">88.28</span></td>
<td id="S5.T2.1.1.4.4.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.4.4.4.1" class="ltx_text" style="font-size:70%;">41.18</span></td>
<td id="S5.T2.1.1.4.4.5" class="ltx_td"></td>
<td id="S5.T2.1.1.4.4.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.4.4.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.61</span></td>
<td id="S5.T2.1.1.4.4.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.4.4.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">91.18</span></td>
<td id="S5.T2.1.1.4.4.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.4.4.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">46.12</span></td>
</tr>
<tr id="S5.T2.1.1.5.5" class="ltx_tr">
<th id="S5.T2.1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.5.5.1.1" class="ltx_text" style="font-size:70%;">cam</span></th>
<td id="S5.T2.1.1.5.5.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.5.5.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">97.16</span></td>
<td id="S5.T2.1.1.5.5.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.5.5.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">77.94</span></td>
<td id="S5.T2.1.1.5.5.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.5.5.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">25.29</span></td>
<td id="S5.T2.1.1.5.5.5" class="ltx_td"></td>
<td id="S5.T2.1.1.5.5.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.5.5.6.1" class="ltx_text" style="font-size:70%;">95.88</span></td>
<td id="S5.T2.1.1.5.5.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.5.5.7.1" class="ltx_text" style="font-size:70%;">76.57</span></td>
<td id="S5.T2.1.1.5.5.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.5.5.8.1" class="ltx_text" style="font-size:70%;">24.51</span></td>
</tr>
<tr id="S5.T2.1.1.6.6" class="ltx_tr">
<th id="S5.T2.1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.6.6.1.1" class="ltx_text" style="font-size:70%;">can</span></th>
<td id="S5.T2.1.1.6.6.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.6.6.2.1" class="ltx_text" style="font-size:70%;">99.61</span></td>
<td id="S5.T2.1.1.6.6.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.6.6.3.1" class="ltx_text" style="font-size:70%;">88.88</span></td>
<td id="S5.T2.1.1.6.6.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.6.6.4.1" class="ltx_text" style="font-size:70%;">39.67</span></td>
<td id="S5.T2.1.1.6.6.5" class="ltx_td"></td>
<td id="S5.T2.1.1.6.6.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.6.6.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.80</span></td>
<td id="S5.T2.1.1.6.6.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.6.6.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">89.27</span></td>
<td id="S5.T2.1.1.6.6.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.6.6.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">40.55</span></td>
</tr>
<tr id="S5.T2.1.1.7.7" class="ltx_tr">
<th id="S5.T2.1.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.7.7.1.1" class="ltx_text" style="font-size:70%;">cat</span></th>
<td id="S5.T2.1.1.7.7.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.7.7.2.1" class="ltx_text" style="font-size:70%;">93.41</span></td>
<td id="S5.T2.1.1.7.7.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.7.7.3.1" class="ltx_text" style="font-size:70%;">70.86</span></td>
<td id="S5.T2.1.1.7.7.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.7.7.4.1" class="ltx_text" style="font-size:70%;">25.65</span></td>
<td id="S5.T2.1.1.7.7.5" class="ltx_td"></td>
<td id="S5.T2.1.1.7.7.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.7.7.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">94.31</span></td>
<td id="S5.T2.1.1.7.7.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.7.7.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">71.36</span></td>
<td id="S5.T2.1.1.7.7.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.7.7.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">26.75</span></td>
</tr>
<tr id="S5.T2.1.1.8.8" class="ltx_tr">
<th id="S5.T2.1.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.8.8.1.1" class="ltx_text" style="font-size:70%;">driller</span></th>
<td id="S5.T2.1.1.8.8.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.8.8.2.1" class="ltx_text" style="font-size:70%;">98.41</span></td>
<td id="S5.T2.1.1.8.8.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.8.8.3.1" class="ltx_text" style="font-size:70%;">87.91</span></td>
<td id="S5.T2.1.1.8.8.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.8.8.4.1" class="ltx_text" style="font-size:70%;">43.31</span></td>
<td id="S5.T2.1.1.8.8.5" class="ltx_td"></td>
<td id="S5.T2.1.1.8.8.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.8.8.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">98.81</span></td>
<td id="S5.T2.1.1.8.8.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.8.8.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">92.67</span></td>
<td id="S5.T2.1.1.8.8.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.8.8.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">49.45</span></td>
</tr>
<tr id="S5.T2.1.1.9.9" class="ltx_tr">
<th id="S5.T2.1.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.9.9.1.1" class="ltx_text" style="font-size:70%;">duck</span></th>
<td id="S5.T2.1.1.9.9.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.9.9.2.1" class="ltx_text" style="font-size:70%;">82.25</span></td>
<td id="S5.T2.1.1.9.9.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.9.9.3.1" class="ltx_text" style="font-size:70%;">51.64</span></td>
<td id="S5.T2.1.1.9.9.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.9.9.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">12.39</span></td>
<td id="S5.T2.1.1.9.9.5" class="ltx_td"></td>
<td id="S5.T2.1.1.9.9.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.9.9.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">85.26</span></td>
<td id="S5.T2.1.1.9.9.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.9.9.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">55.40</span></td>
<td id="S5.T2.1.1.9.9.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.9.9.8.1" class="ltx_text" style="font-size:70%;">12.11</span></td>
</tr>
<tr id="S5.T2.1.1.10.10" class="ltx_tr">
<th id="S5.T2.1.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.10.10.1.1" class="ltx_text" style="font-size:70%;">eggbox</span></th>
<td id="S5.T2.1.1.10.10.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.10.10.2.1" class="ltx_text" style="font-size:70%;">99.81</span></td>
<td id="S5.T2.1.1.10.10.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.10.10.3.1" class="ltx_text" style="font-size:70%;">90.23</span></td>
<td id="S5.T2.1.1.10.10.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.10.10.4.1" class="ltx_text" style="font-size:70%;">30.05</span></td>
<td id="S5.T2.1.1.10.10.5" class="ltx_td"></td>
<td id="S5.T2.1.1.10.10.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.10.10.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">100.00</span></td>
<td id="S5.T2.1.1.10.10.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.10.10.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">93.15</span></td>
<td id="S5.T2.1.1.10.10.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.10.10.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">40.19</span></td>
</tr>
<tr id="S5.T2.1.1.11.11" class="ltx_tr">
<th id="S5.T2.1.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.11.11.1.1" class="ltx_text" style="font-size:70%;">glue</span></th>
<td id="S5.T2.1.1.11.11.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.11.11.2.1" class="ltx_text" style="font-size:70%;">83.49</span></td>
<td id="S5.T2.1.1.11.11.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.11.11.3.1" class="ltx_text" style="font-size:70%;">75.87</span></td>
<td id="S5.T2.1.1.11.11.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.11.11.4.1" class="ltx_text" style="font-size:70%;">34.85</span></td>
<td id="S5.T2.1.1.11.11.5" class="ltx_td"></td>
<td id="S5.T2.1.1.11.11.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.11.11.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">83.78</span></td>
<td id="S5.T2.1.1.11.11.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.11.11.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">76.64</span></td>
<td id="S5.T2.1.1.11.11.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.11.11.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">38.22</span></td>
</tr>
<tr id="S5.T2.1.1.12.12" class="ltx_tr">
<th id="S5.T2.1.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.12.12.1.1" class="ltx_text" style="font-size:70%;">holepuncher</span></th>
<td id="S5.T2.1.1.12.12.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.12.12.2.1" class="ltx_text" style="font-size:70%;">89.34</span></td>
<td id="S5.T2.1.1.12.12.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.12.12.3.1" class="ltx_text" style="font-size:70%;">54.23</span></td>
<td id="S5.T2.1.1.12.12.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.12.12.4.1" class="ltx_text" style="font-size:70%;">5.04</span></td>
<td id="S5.T2.1.1.12.12.5" class="ltx_td"></td>
<td id="S5.T2.1.1.12.12.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.12.12.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">90.10</span></td>
<td id="S5.T2.1.1.12.12.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.12.12.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">58.04</span></td>
<td id="S5.T2.1.1.12.12.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.12.12.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">13.23</span></td>
</tr>
<tr id="S5.T2.1.1.13.13" class="ltx_tr">
<th id="S5.T2.1.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.13.13.1.1" class="ltx_text" style="font-size:70%;">iron</span></th>
<td id="S5.T2.1.1.13.13.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.13.13.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">99.59</span></td>
<td id="S5.T2.1.1.13.13.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.13.13.3.1" class="ltx_text" style="font-size:70%;">88.25</span></td>
<td id="S5.T2.1.1.13.13.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.13.13.4.1" class="ltx_text" style="font-size:70%;">42.08</span></td>
<td id="S5.T2.1.1.13.13.5" class="ltx_td"></td>
<td id="S5.T2.1.1.13.13.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.13.13.6.1" class="ltx_text" style="font-size:70%;">98.77</span></td>
<td id="S5.T2.1.1.13.13.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.13.13.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">89.17</span></td>
<td id="S5.T2.1.1.13.13.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.13.13.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">44.33</span></td>
</tr>
<tr id="S5.T2.1.1.14.14" class="ltx_tr">
<th id="S5.T2.1.1.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.14.14.1.1" class="ltx_text" style="font-size:70%;">lamp</span></th>
<td id="S5.T2.1.1.14.14.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.14.14.2.1" class="ltx_text" style="font-size:70%;">99.90</span></td>
<td id="S5.T2.1.1.14.14.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.14.14.3.1" class="ltx_text" style="font-size:70%;">90.31</span></td>
<td id="S5.T2.1.1.14.14.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.14.14.4.1" class="ltx_text" style="font-size:70%;">30.04</span></td>
<td id="S5.T2.1.1.14.14.5" class="ltx_td"></td>
<td id="S5.T2.1.1.14.14.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.14.14.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">100.00</span></td>
<td id="S5.T2.1.1.14.14.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.14.14.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">95.01</span></td>
<td id="S5.T2.1.1.14.14.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.14.14.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">48.18</span></td>
</tr>
<tr id="S5.T2.1.1.15.15" class="ltx_tr">
<th id="S5.T2.1.1.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T2.1.1.15.15.1.1" class="ltx_text" style="font-size:70%;">phone</span></th>
<td id="S5.T2.1.1.15.15.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.15.15.2.1" class="ltx_text" style="font-size:70%;">97.98</span></td>
<td id="S5.T2.1.1.15.15.3" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.15.15.3.1" class="ltx_text" style="font-size:70%;">78.19</span></td>
<td id="S5.T2.1.1.15.15.4" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.15.15.4.1" class="ltx_text" style="font-size:70%;">30.26</span></td>
<td id="S5.T2.1.1.15.15.5" class="ltx_td"></td>
<td id="S5.T2.1.1.15.15.6" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.15.15.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">98.56</span></td>
<td id="S5.T2.1.1.15.15.7" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.15.15.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">80.50</span></td>
<td id="S5.T2.1.1.15.15.8" class="ltx_td ltx_align_center"><span id="S5.T2.1.1.15.15.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">34.39</span></td>
</tr>
<tr id="S5.T2.1.1.16.16" class="ltx_tr">
<th id="S5.T2.1.1.16.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S5.T2.1.1.16.16.1.1" class="ltx_text" style="font-size:70%;">MEAN</span></th>
<td id="S5.T2.1.1.16.16.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T2.1.1.16.16.2.1" class="ltx_text" style="font-size:70%;">93.63</span></td>
<td id="S5.T2.1.1.16.16.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T2.1.1.16.16.3.1" class="ltx_text" style="font-size:70%;">76.20</span></td>
<td id="S5.T2.1.1.16.16.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T2.1.1.16.16.4.1" class="ltx_text" style="font-size:70%;">28.57</span></td>
<td id="S5.T2.1.1.16.16.5" class="ltx_td ltx_border_bb ltx_border_t"></td>
<td id="S5.T2.1.1.16.16.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T2.1.1.16.16.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">94.28</span></td>
<td id="S5.T2.1.1.16.16.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T2.1.1.16.16.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">78.44</span></td>
<td id="S5.T2.1.1.16.16.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T2.1.1.16.16.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">32.82</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>ADD(-S) scores for various thresholds on the LineMOD dataset (higher is better). We compare the multi-stage variant of our approach to the best baseline by tightening the success rate threshold. Our method predicts poses that are closer to the ground truth pose and the gap to the baseline increases for lower thresholds.</figcaption>
</figure>
<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">We first evaluate our approach on the LineMOD dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. The results are shown in Table <a href="#S5.T1" title="Table 1 â€£ 5.3 Baselines â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For each of the objects in the LineMOD dataset, we compute the ADD(-S) scores. The DPOD method is a single-stage refiner, while the DeepIM uses multiple stages. Thus, we train our model and the DenseNet baseline in both configurations. We show qualitative results of our method in Fig.Â <a href="#S5.F3" title="Figure 3 â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">As presented in Table <a href="#S5.T1" title="Table 1 â€£ 5.3 Baselines â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, our approach shows the best performance in both of the settings. Furthermore, the vanilla DenseNet performs better than both SoA refiners. This confirms our hypothesis that the DenseNet backbone is an effective substitute for the ResNet based architectures used in prior work, despite a much smaller footprint in terms of parameters. Finally, adding our proposed attention mechanism shows a consistent increase in performance over DenseNet, which confirms the effectiveness of the attention mechanism.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.2" class="ltx_p">To further evaluate the influence of our contribution, we provide the ADD(-S) score for thresholds <math id="S5.SS4.p3.1.m1.1" class="ltx_Math" alttext="0.05d" display="inline"><semantics id="S5.SS4.p3.1.m1.1a"><mrow id="S5.SS4.p3.1.m1.1.1" xref="S5.SS4.p3.1.m1.1.1.cmml"><mn id="S5.SS4.p3.1.m1.1.1.2" xref="S5.SS4.p3.1.m1.1.1.2.cmml">0.05</mn><mo lspace="0em" rspace="0em" id="S5.SS4.p3.1.m1.1.1.1" xref="S5.SS4.p3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS4.p3.1.m1.1.1.3" xref="S5.SS4.p3.1.m1.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.1.m1.1b"><apply id="S5.SS4.p3.1.m1.1.1.cmml" xref="S5.SS4.p3.1.m1.1.1"><times id="S5.SS4.p3.1.m1.1.1.1.cmml" xref="S5.SS4.p3.1.m1.1.1.1"></times><cn type="float" id="S5.SS4.p3.1.m1.1.1.2.cmml" xref="S5.SS4.p3.1.m1.1.1.2">0.05</cn><ci id="S5.SS4.p3.1.m1.1.1.3.cmml" xref="S5.SS4.p3.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.1.m1.1c">0.05d</annotation></semantics></math> and <math id="S5.SS4.p3.2.m2.1" class="ltx_Math" alttext="0.02d" display="inline"><semantics id="S5.SS4.p3.2.m2.1a"><mrow id="S5.SS4.p3.2.m2.1.1" xref="S5.SS4.p3.2.m2.1.1.cmml"><mn id="S5.SS4.p3.2.m2.1.1.2" xref="S5.SS4.p3.2.m2.1.1.2.cmml">0.02</mn><mo lspace="0em" rspace="0em" id="S5.SS4.p3.2.m2.1.1.1" xref="S5.SS4.p3.2.m2.1.1.1.cmml">â€‹</mo><mi id="S5.SS4.p3.2.m2.1.1.3" xref="S5.SS4.p3.2.m2.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.2.m2.1b"><apply id="S5.SS4.p3.2.m2.1.1.cmml" xref="S5.SS4.p3.2.m2.1.1"><times id="S5.SS4.p3.2.m2.1.1.1.cmml" xref="S5.SS4.p3.2.m2.1.1.1"></times><cn type="float" id="S5.SS4.p3.2.m2.1.1.2.cmml" xref="S5.SS4.p3.2.m2.1.1.2">0.02</cn><ci id="S5.SS4.p3.2.m2.1.1.3.cmml" xref="S5.SS4.p3.2.m2.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.2.m2.1c">0.02d</annotation></semantics></math>, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, which makes the task increasingly harder. The results are presented in Table <a href="#S5.T2" title="Table 2 â€£ 5.4 LineMOD Results â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. As the threshold goes down, the difference between our approach and the DenseNet baseline becomes more evident. The attention blocks helps to isolate the most salient features for matching, which allows the refinement network to achieve higher accuracy.</p>
</div>
<div id="S5.SS4.p4" class="ltx_para">
<p id="S5.SS4.p4.1" class="ltx_p">To verify that these results are not only a side-effect of our experimental setting we also provide results using the initial pose estimates used in DeepIM. Note that here the accuracy of the initialization method is significantly lower than PVNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> which implies that some initial estimates maybe outside of the distribution used during training of our method. The results in Table <a href="#S5.T3" title="Table 3 â€£ 5.5 Occlusion LineMOD Results â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> again show that our method significantly improves over DeepIM, indicating that the performance increase is a direct result of the proposed attention mechanism.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Occlusion LineMOD Results</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">To evaluate our approach in settings that contain occlusions, we perform a similar experiment on the Occlusion LineMOD dataset. The results are presented in Table <a href="#S5.T4" title="Table 4 â€£ 5.5 Occlusion LineMOD Results â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We use PVNet to obtain initial positions and evaluate our approach using ADD(-S) metric. We show the performance of DPOD and DeepIM refiners as well using the same initial positions. For qualitative results refer to Fig.Â <a href="#S5.F3" title="Figure 3 â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">Table <a href="#S5.T4" title="Table 4 â€£ 5.5 Occlusion LineMOD Results â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that our approach performs better than the baselines. The single-stage variant achieves a significant improvement over DenseNet. This is due to the attention map being shaped such that pixels of the occluder are ignored, which has been shown to improve accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. The difference is more pronounced in the multi-stage case.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.1.1.1" class="ltx_tr">
<th id="S5.T3.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S5.T3.1.1.1.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T3.1.1.1.2.1" class="ltx_text" style="font-size:70%;">Init</span></td>
<td id="S5.T3.1.1.1.3" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T3.1.1.1.3.1" class="ltx_text" style="font-size:70%;">DeepIM</span></td>
<td id="S5.T3.1.1.1.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T3.1.1.1.4.1" class="ltx_text" style="font-size:70%;">DenseNet</span></td>
<td id="S5.T3.1.1.1.5" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T3.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ours</span></td>
</tr>
<tr id="S5.T3.1.2.2" class="ltx_tr">
<th id="S5.T3.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S5.T3.1.2.2.1.1" class="ltx_text" style="font-size:70%;">MEAN</span></th>
<td id="S5.T3.1.2.2.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S5.T3.1.2.2.2.1" class="ltx_text" style="font-size:70%;">62.7</span></td>
<td id="S5.T3.1.2.2.3" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S5.T3.1.2.2.3.1" class="ltx_text" style="font-size:70%;">88.6</span></td>
<td id="S5.T3.1.2.2.4" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S5.T3.1.2.2.4.1" class="ltx_text" style="font-size:70%;">85.17</span></td>
<td id="S5.T3.1.2.2.5" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S5.T3.1.2.2.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">92.02</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>ADD(-S) scores for initialization points used in DeepIM on the LineMOD dataset (higher is better). We compare all multi-stage methods. The DeepIM performance is the same as reported in the DeepIM paper since we use the original initialization points. Ours outperforms the SoA on average.</figcaption>
</figure>
<figure id="S5.T4" class="ltx_table">
<table id="S5.T4.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.3.1.1" class="ltx_tr">
<th id="S5.T4.3.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_tt"></th>
<th id="S5.T4.3.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S5.T4.3.1.1.3" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S5.T4.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T4.3.1.1.4.1" class="ltx_text" style="font-size:70%;">Single stage</span></th>
<th id="S5.T4.3.1.1.5" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="S5.T4.3.1.1.6" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="S5.T4.3.1.1.7" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S5.T4.3.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T4.3.1.1.8.1" class="ltx_text" style="font-size:70%;">Multi stage</span></th>
<th id="S5.T4.3.1.1.9" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
</tr>
<tr id="S5.T4.3.2.2" class="ltx_tr">
<th id="S5.T4.3.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l"></th>
<th id="S5.T4.3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S5.T4.3.2.2.2.1" class="ltx_text" style="font-size:70%;">PVNet init</span></th>
<th id="S5.T4.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T4.3.2.2.3.1" class="ltx_text" style="font-size:70%;">DPOD</span></th>
<th id="S5.T4.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T4.3.2.2.4.1" class="ltx_text" style="font-size:70%;">DenseNet</span></th>
<th id="S5.T4.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T4.3.2.2.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ours</span></th>
<th id="S5.T4.3.2.2.6" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S5.T4.3.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T4.3.2.2.7.1" class="ltx_text" style="font-size:70%;">DeepIM</span></th>
<th id="S5.T4.3.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T4.3.2.2.8.1" class="ltx_text" style="font-size:70%;">DenseNet</span></th>
<th id="S5.T4.3.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T4.3.2.2.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ours</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.3.3.1" class="ltx_tr">
<th id="S5.T4.3.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t"><span id="S5.T4.3.3.1.1.1" class="ltx_text" style="font-size:70%;">ape</span></th>
<th id="S5.T4.3.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T4.3.3.1.2.1" class="ltx_text" style="font-size:70%;">15.98</span></th>
<td id="S5.T4.3.3.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.1.3.1" class="ltx_text" style="font-size:70%;">19.91</span></td>
<td id="S5.T4.3.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.1.4.1" class="ltx_text" style="font-size:70%;">28.29</span></td>
<td id="S5.T4.3.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.3.1.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">28.72</span></td>
<td id="S5.T4.3.3.1.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T4.3.3.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.1.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">41.71</span></td>
<td id="S5.T4.3.3.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.1.8.1" class="ltx_text" style="font-size:70%;">33.68</span></td>
<td id="S5.T4.3.3.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.3.1.9.1" class="ltx_text" style="font-size:70%;">38.29</span></td>
</tr>
<tr id="S5.T4.3.4.2" class="ltx_tr">
<th id="S5.T4.3.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T4.3.4.2.1.1" class="ltx_text" style="font-size:70%;">can</span></th>
<th id="S5.T4.3.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.3.4.2.2.1" class="ltx_text" style="font-size:70%;">63.79</span></th>
<td id="S5.T4.3.4.2.3" class="ltx_td ltx_align_center"><span id="S5.T4.3.4.2.3.1" class="ltx_text" style="font-size:70%;">51.86</span></td>
<td id="S5.T4.3.4.2.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.4.2.4.1" class="ltx_text" style="font-size:70%;">52.44</span></td>
<td id="S5.T4.3.4.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.4.2.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">55.34</span></td>
<td id="S5.T4.3.4.2.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T4.3.4.2.7" class="ltx_td ltx_align_center"><span id="S5.T4.3.4.2.7.1" class="ltx_text" style="font-size:70%;">62.30</span></td>
<td id="S5.T4.3.4.2.8" class="ltx_td ltx_align_center"><span id="S5.T4.3.4.2.8.1" class="ltx_text" style="font-size:70%;">68.43</span></td>
<td id="S5.T4.3.4.2.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.4.2.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">75.39</span></td>
</tr>
<tr id="S5.T4.3.5.3" class="ltx_tr">
<th id="S5.T4.3.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T4.3.5.3.1.1" class="ltx_text" style="font-size:70%;">cat</span></th>
<th id="S5.T4.3.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.3.5.3.2.1" class="ltx_text" style="font-size:70%;">19.38</span></th>
<td id="S5.T4.3.5.3.3" class="ltx_td ltx_align_center"><span id="S5.T4.3.5.3.3.1" class="ltx_text" style="font-size:70%;">16.76</span></td>
<td id="S5.T4.3.5.3.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.5.3.4.1" class="ltx_text" style="font-size:70%;">15.75</span></td>
<td id="S5.T4.3.5.3.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.5.3.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">21.65</span></td>
<td id="S5.T4.3.5.3.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T4.3.5.3.7" class="ltx_td ltx_align_center"><span id="S5.T4.3.5.3.7.1" class="ltx_text" style="font-size:70%;">24.94</span></td>
<td id="S5.T4.3.5.3.8" class="ltx_td ltx_align_center"><span id="S5.T4.3.5.3.8.1" class="ltx_text" style="font-size:70%;">23.42</span></td>
<td id="S5.T4.3.5.3.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.5.3.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">25.27</span></td>
</tr>
<tr id="S5.T4.3.6.4" class="ltx_tr">
<th id="S5.T4.3.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T4.3.6.4.1.1" class="ltx_text" style="font-size:70%;">driller</span></th>
<th id="S5.T4.3.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.3.6.4.2.1" class="ltx_text" style="font-size:70%;">64.25</span></th>
<td id="S5.T4.3.6.4.3" class="ltx_td ltx_align_center"><span id="S5.T4.3.6.4.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">71.58</span></td>
<td id="S5.T4.3.6.4.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.6.4.4.1" class="ltx_text" style="font-size:70%;">64.42</span></td>
<td id="S5.T4.3.6.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.6.4.5.1" class="ltx_text" style="font-size:70%;">66.14</span></td>
<td id="S5.T4.3.6.4.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T4.3.6.4.7" class="ltx_td ltx_align_center"><span id="S5.T4.3.6.4.7.1" class="ltx_text" style="font-size:70%;">59.06</span></td>
<td id="S5.T4.3.6.4.8" class="ltx_td ltx_align_center"><span id="S5.T4.3.6.4.8.1" class="ltx_text" style="font-size:70%;">72.16</span></td>
<td id="S5.T4.3.6.4.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.6.4.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">77.18</span></td>
</tr>
<tr id="S5.T4.3.7.5" class="ltx_tr">
<th id="S5.T4.3.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T4.3.7.5.1.1" class="ltx_text" style="font-size:70%;">duck</span></th>
<th id="S5.T4.3.7.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.3.7.5.2.1" class="ltx_text" style="font-size:70%;">31.81</span></th>
<td id="S5.T4.3.7.5.3" class="ltx_td ltx_align_center"><span id="S5.T4.3.7.5.3.1" class="ltx_text" style="font-size:70%;">40.32</span></td>
<td id="S5.T4.3.7.5.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.7.5.4.1" class="ltx_text" style="font-size:70%;">40.23</span></td>
<td id="S5.T4.3.7.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.7.5.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">44.17</span></td>
<td id="S5.T4.3.7.5.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T4.3.7.5.7" class="ltx_td ltx_align_center"><span id="S5.T4.3.7.5.7.1" class="ltx_text" style="font-size:70%;">41.64</span></td>
<td id="S5.T4.3.7.5.8" class="ltx_td ltx_align_center"><span id="S5.T4.3.7.5.8.1" class="ltx_text" style="font-size:70%;">44.26</span></td>
<td id="S5.T4.3.7.5.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.7.5.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">47.33</span></td>
</tr>
<tr id="S5.T4.3.8.6" class="ltx_tr">
<th id="S5.T4.3.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T4.3.8.6.1.1" class="ltx_text" style="font-size:70%;">eggbox</span></th>
<th id="S5.T4.3.8.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.3.8.6.2.1" class="ltx_text" style="font-size:70%;">41.02</span></th>
<td id="S5.T4.3.8.6.3" class="ltx_td ltx_align_center"><span id="S5.T4.3.8.6.3.1" class="ltx_text" style="font-size:70%;">44.34</span></td>
<td id="S5.T4.3.8.6.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.8.6.4.1" class="ltx_text" style="font-size:70%;">43.91</span></td>
<td id="S5.T4.3.8.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.8.6.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">44.77</span></td>
<td id="S5.T4.3.8.6.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T4.3.8.6.7" class="ltx_td ltx_align_center"><span id="S5.T4.3.8.6.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">50.21</span></td>
<td id="S5.T4.3.8.6.8" class="ltx_td ltx_align_center"><span id="S5.T4.3.8.6.8.1" class="ltx_text" style="font-size:70%;">48.34</span></td>
<td id="S5.T4.3.8.6.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.8.6.9.1" class="ltx_text" style="font-size:70%;">49.36</span></td>
</tr>
<tr id="S5.T4.3.9.7" class="ltx_tr">
<th id="S5.T4.3.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T4.3.9.7.1.1" class="ltx_text" style="font-size:70%;">glue</span></th>
<th id="S5.T4.3.9.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.3.9.7.2.1" class="ltx_text" style="font-size:70%;">41.42</span></th>
<td id="S5.T4.3.9.7.3" class="ltx_td ltx_align_center"><span id="S5.T4.3.9.7.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">47.84</span></td>
<td id="S5.T4.3.9.7.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.9.7.4.1" class="ltx_text" style="font-size:70%;">43.63</span></td>
<td id="S5.T4.3.9.7.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.9.7.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">47.84</span></td>
<td id="S5.T4.3.9.7.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T4.3.9.7.7" class="ltx_td ltx_align_center"><span id="S5.T4.3.9.7.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">55.59</span></td>
<td id="S5.T4.3.9.7.8" class="ltx_td ltx_align_center"><span id="S5.T4.3.9.7.8.1" class="ltx_text" style="font-size:70%;">48.06</span></td>
<td id="S5.T4.3.9.7.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.9.7.9.1" class="ltx_text" style="font-size:70%;">51.38</span></td>
</tr>
<tr id="S5.T4.3.10.8" class="ltx_tr">
<th id="S5.T4.3.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l"><span id="S5.T4.3.10.8.1.1" class="ltx_text" style="font-size:70%;">holepuncher</span></th>
<th id="S5.T4.3.10.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.3.10.8.2.1" class="ltx_text" style="font-size:70%;">39.08</span></th>
<td id="S5.T4.3.10.8.3" class="ltx_td ltx_align_center"><span id="S5.T4.3.10.8.3.1" class="ltx_text" style="font-size:70%;">37.15</span></td>
<td id="S5.T4.3.10.8.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.10.8.4.1" class="ltx_text" style="font-size:70%;">43.85</span></td>
<td id="S5.T4.3.10.8.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.10.8.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">45.61</span></td>
<td id="S5.T4.3.10.8.6" class="ltx_td ltx_border_r"></td>
<td id="S5.T4.3.10.8.7" class="ltx_td ltx_align_center"><span id="S5.T4.3.10.8.7.1" class="ltx_text" style="font-size:70%;">43.14</span></td>
<td id="S5.T4.3.10.8.8" class="ltx_td ltx_align_center"><span id="S5.T4.3.10.8.8.1" class="ltx_text" style="font-size:70%;">45.77</span></td>
<td id="S5.T4.3.10.8.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.10.8.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">48.79</span></td>
</tr>
<tr id="S5.T4.3.11.9" class="ltx_tr">
<th id="S5.T4.3.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_t"><span id="S5.T4.3.11.9.1.1" class="ltx_text" style="font-size:70%;">MEAN</span></th>
<th id="S5.T4.3.11.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T4.3.11.9.2.1" class="ltx_text" style="font-size:70%;">39.59</span></th>
<td id="S5.T4.3.11.9.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.3.11.9.3.1" class="ltx_text" style="font-size:70%;">41.22</span></td>
<td id="S5.T4.3.11.9.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.3.11.9.4.1" class="ltx_text" style="font-size:70%;">41.57</span></td>
<td id="S5.T4.3.11.9.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T4.3.11.9.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">44.28</span></td>
<td id="S5.T4.3.11.9.6" class="ltx_td ltx_border_bb ltx_border_r ltx_border_t"></td>
<td id="S5.T4.3.11.9.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.3.11.9.7.1" class="ltx_text" style="font-size:70%;">47.33</span></td>
<td id="S5.T4.3.11.9.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.3.11.9.8.1" class="ltx_text" style="font-size:70%;">48.02</span></td>
<td id="S5.T4.3.11.9.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T4.3.11.9.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">51.63</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Pose estimation performance on the Occlusion LineMOD dataset. The table shows percent of correctly estimated poses using <math id="S5.T4.2.m1.1" class="ltx_Math" alttext="0.1d" display="inline"><semantics id="S5.T4.2.m1.1b"><mrow id="S5.T4.2.m1.1.1" xref="S5.T4.2.m1.1.1.cmml"><mn id="S5.T4.2.m1.1.1.2" xref="S5.T4.2.m1.1.1.2.cmml">0.1</mn><mo lspace="0em" rspace="0em" id="S5.T4.2.m1.1.1.1" xref="S5.T4.2.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T4.2.m1.1.1.3" xref="S5.T4.2.m1.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.2.m1.1c"><apply id="S5.T4.2.m1.1.1.cmml" xref="S5.T4.2.m1.1.1"><times id="S5.T4.2.m1.1.1.1.cmml" xref="S5.T4.2.m1.1.1.1"></times><cn type="float" id="S5.T4.2.m1.1.1.2.cmml" xref="S5.T4.2.m1.1.1.2">0.1</cn><ci id="S5.T4.2.m1.1.1.3.cmml" xref="S5.T4.2.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.m1.1d">0.1d</annotation></semantics></math> ADD(-S) threshold (higher is better). As initialization points, we use 6D poses obtained from PVNet (the performance of the initial poses is shown in the left-most column). Since the initialization points are different compared to the original papers, similar but not identical results are to be expected. The performance of DPOD method is slightly worse compared to the results reported in the paper due to the different training settings used in the DPOD paper (refer to Sec.Â <a href="#S5.SS3" title="5.3 Baselines â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a> for more details). Ours significantly outperforms the previous SoA.</figcaption>
</figure>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Analysis of the Attention Model</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">To better understand the effectiveness of our approach, we analyze the outputs of the attention model. We generate a heatmap based on the predicted attention map and overlay it over the input image, some examples are shown in Fig.Â <a href="#S5.F4" title="Figure 4 â€£ 5.6 Analysis of the Attention Model â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2101.01659/assets/figures/att_figure_heatmap_2.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="651" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>We overlay the attention probability map over the input image to show which details the attention focuses on. We plot the probability map at each stage of our model. The attention isolates increasingly specific features in the later stages. For example, the object parts that overlap with the white background are avoided on the glue example (bottom left). Furthermore, the attention avoids occlusions (e.g., the rubber duck, bottom right).</figcaption>
</figure>
<div id="S5.SS6.p2" class="ltx_para">
<p id="S5.SS6.p2.1" class="ltx_p">First, Fig.Â <a href="#S5.F4" title="Figure 4 â€£ 5.6 Analysis of the Attention Model â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates that the attention mostly focuses on the outline of the object. The refiner does not need to consider global features because the initial object pose is close to the ground truth pose. Global features need to be considered only in cases where initial displacement is significant. For example, if the initial rotation is around 180 degrees, the network needs to distinguish between the front and back of the object. Since the initial displacement is small, the network focuses on overlaying the characteristic features, which are usually located on the outline of the object. This is a somewhat expected result, since object outline edges are also a common choice for ICP-based refinement from RGB images.</p>
</div>
<div id="S5.SS6.p3" class="ltx_para">
<p id="S5.SS6.p3.1" class="ltx_p">Second, we observe that the attention maps tend to get even more focused on specific regions in the later stages of refinement. As the pose estimate converges to the real image, only a few spatial features need to be considered to improve the prediction. Finally, we notice that the attention map avoids occluded object parts (see Fig. <a href="#S5.F4" title="Figure 4 â€£ 5.6 Analysis of the Attention Model â€£ 5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, right). Please keep in mind that the attention map is learned without any direct supervision and is shaped only via directly optimizing the pose estimation task.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we present a novel attention-based model method for 6D pose refinement. Our model uses an attention mechanism to recognize the regions containing details that give more accurate pose estimation. For the refinement task, details are more important than high-level features since the rendered model is already close to the goal pose. Thus, the network can focus on small pose increments by matching details of the model and input image. We experimentally show that the attention focuses on the outline regions, which contains plenty of discriminative details. In the ablation study, we demonstrate that the attention mechanism leads to performance improvement on different evaluation datasets and using different initialization poses. We experimentally show that our method leads to a significant improvement over SoA results.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">To the best of our knowledge, this is the first time the attention mechanism is used for the 6D pose estimation task. Based on our experiments, we believe that the attention mechanism has particular importance for the task of 6D pose estimation. We hope that our insights will facilitate research in this direction. For example, one possibility is to use the attention mechanism for feature selection instead of the RANSAC algorithm. Furthermore, one can use attention to eliminate the influence of the occlusion object even in cases when the segmentation labels are not provided.</p>
</div>
<section id="S6.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Acknowledgments</h4>

<div id="S6.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p1.1" class="ltx_p">We thank the NVIDIA Corporation for the donation of GPUs used in this work.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
E.Â Brachmann, A.Â Krull, F.Â Michel, S.Â Gumhold, J.Â Shotton, and C.Â Rother.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Learning 6d object pose estimation using 3d object coordinates.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European conference on computer vision</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, pages 536â€“551.
Springer, 2014.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Y.Â Cao, J.Â Xu, S.Â Lin, F.Â Wei, and H.Â Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Gcnet: Non-local networks meet squeeze-excitation networks and
beyond.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision Workshops</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 0â€“0, 2019.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
P.Â Fischer, A.Â Dosovitskiy, E.Â Ilg, P.Â HÃ¤usser, C.Â HazÄ±rbaÅŸ,
V.Â Golkov, P.Â VanÂ der Smagt, D.Â Cremers, and T.Â Brox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Flownet: Learning optical flow with convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1504.06852</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
J.Â Gehring, M.Â Auli, D.Â Grangier, D.Â Yarats, and Y.Â N. Dauphin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Convolutional sequence to sequence learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1705.03122</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
R.Â Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Fast r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, pages 1440â€“1448, 2015.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
K.Â He, G.Â Gkioxari, P.Â DollÃ¡r, and R.Â Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Mask r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 2961â€“2969, 2017.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
K.Â He, X.Â Zhang, S.Â Ren, and J.Â Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 770â€“778, 2016.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
P.Â Henderson and V.Â Ferrari.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Learning single-image 3d reconstruction by generative modelling of
shape, pose and shading.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International Journal of Computer Vision</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, pages 1â€“20, 2019.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
S.Â Hinterstoisser, C.Â Cagniart, S.Â Ilic, P.Â Sturm, N.Â Navab, P.Â Fua, and
V.Â Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Gradient response maps for real-time detection of textureless
objects.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine intelligence</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">,
34(5):876â€“888, 2011.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
S.Â Hinterstoisser, S.Â Holzer, C.Â Cagniart, S.Â Ilic, K.Â Konolige, N.Â Navab, and
V.Â Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Multimodal templates for real-time detection of texture-less objects
in heavily cluttered scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2011 international conference on computer vision</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, pages
858â€“865. IEEE, 2011.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
S.Â Hinterstoisser, V.Â Lepetit, S.Â Ilic, S.Â Holzer, G.Â Bradski, K.Â Konolige, and
N.Â Navab.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Model based training, detection and pose estimation of texture-less
3d objects in heavily cluttered scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Asian conference on computer vision</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 548â€“562.
Springer, 2012.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Y.Â Hu, J.Â Hugonot, P.Â Fua, and M.Â Salzmann.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Segmentation-driven 6d object pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages 3385â€“3394, 2019.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
G.Â Huang, Z.Â Liu, L.Â Van DerÂ Maaten, and K.Â Q. Weinberger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Densely connected convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 4700â€“4708, 2017.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Z.Â Huang, X.Â Wang, L.Â Huang, C.Â Huang, Y.Â Wei, and W.Â Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Ccnet: Criss-cross attention for semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 603â€“612, 2019.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
S.Â JÃ©gou, M.Â Drozdzal, D.Â Vazquez, A.Â Romero, and Y.Â Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">The one hundred layers tiramisu: Fully convolutional densenets for
semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition workshops</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, pages 11â€“19, 2017.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
S.Â Jetley, N.Â A. Lord, N.Â Lee, and P.Â H. Torr.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Learn to pay attention.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1804.02391</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
W.Â Kehl, F.Â Manhardt, F.Â Tombari, S.Â Ilic, and N.Â Navab.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Ssd-6d: Making rgb-based 3d detection and 6d pose estimation great
again.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Computer Vision</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages
1521â€“1529, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
A.Â Kosiorek, A.Â Bewley, and I.Â Posner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Hierarchical attentive recurrent tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages
3053â€“3061, 2017.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
V.Â Lepetit, F.Â Moreno-Noguer, and P.Â Fua.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Epnp: An accurate o (n) solution to the pnp problem.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International journal of computer vision</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, 81(2):155, 2009.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Y.Â Li, G.Â Wang, X.Â Ji, Y.Â Xiang, and D.Â Fox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Deepim: Deep iterative matching for 6d pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 683â€“698, 2018.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
S.Â Peng, Y.Â Liu, Q.Â Huang, X.Â Zhou, and H.Â Bao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Pvnet: Pixel-wise voting network for 6dof pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 4561â€“4570, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
M.Â Rad and V.Â Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Bb8: A scalable, accurate, robust to partial occlusion method for
predicting the 3d poses of challenging objects without using depth.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, pages 3828â€“3836, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
J.Â Redmon, S.Â Divvala, R.Â Girshick, and A.Â Farhadi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">You only look once: Unified, real-time object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 779â€“788, 2016.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
R.Â Rios-Cabrera and T.Â Tuytelaars.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Discriminatively trained templates for 3d object detection: A real
time scalable approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, pages 2048â€“2055, 2013.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
K.Â Simonyan and A.Â Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Very deep convolutional networks for large-scale image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1409.1556</span><span id="bib.bib25.4.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
A.Â Vaswani, N.Â Shazeer, N.Â Parmar, J.Â Uszkoreit, L.Â Jones, A.Â N. Gomez,
Å.Â Kaiser, and I.Â Polosukhin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Attention is all you need.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages
5998â€“6008, 2017.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
X.Â Wang, R.Â Girshick, A.Â Gupta, and K.Â He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Non-local neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, pages 7794â€“7803, 2018.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Y.Â Xiang, T.Â Schmidt, V.Â Narayanan, and D.Â Fox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Posecnn: A convolutional neural network for 6d object pose estimation
in cluttered scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1711.00199</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
S.Â Zakharov, I.Â Shugurov, and S.Â Ilic.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Dpod: 6d pose object detector and refiner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, pages 1941â€“1950, 2019.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
H.Â Zhang, I.Â Goodfellow, D.Â Metaxas, and A.Â Odena.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Self-attention generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages
7354â€“7363, 2019.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Appendix</h2>

<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Model Details</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">Here we describe the architecture of our model and the DenseNet baseline in more details. The core of the DenseNet architecture is a Dense block <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The block uses convolutional layers of size 3x3. The input to the convolutional layer is first processed via batch normalization and ReLU activation. The main characteristic of the Dense block is that new features obtained from the latest convolutional layer are concatenated to the layer input and propagated further. As a result, DenseNet keeps the original features and only adds new features to the feature stack. Besides the Dense block, DenseNet has transition layers to reduce the resolution of the input features. We use a 2x2 max pooling layer with stride 2 as a transition layer.</p>
</div>
<figure id="S7.T5" class="ltx_table">
<table id="S7.T5.12" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T5.12.13.1" class="ltx_tr">
<th id="S7.T5.12.13.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Ours</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T5.1.1" class="ltx_tr">
<td id="S7.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">Input, <math id="S7.T5.1.1.1.m1.1" class="ltx_Math" alttext="m=3" display="inline"><semantics id="S7.T5.1.1.1.m1.1a"><mrow id="S7.T5.1.1.1.m1.1.1" xref="S7.T5.1.1.1.m1.1.1.cmml"><mi id="S7.T5.1.1.1.m1.1.1.2" xref="S7.T5.1.1.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.1.1.1.m1.1.1.1" xref="S7.T5.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.1.1.1.m1.1.1.3" xref="S7.T5.1.1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.1.1.1.m1.1b"><apply id="S7.T5.1.1.1.m1.1.1.cmml" xref="S7.T5.1.1.1.m1.1.1"><eq id="S7.T5.1.1.1.m1.1.1.1.cmml" xref="S7.T5.1.1.1.m1.1.1.1"></eq><ci id="S7.T5.1.1.1.m1.1.1.2.cmml" xref="S7.T5.1.1.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.1.1.1.m1.1.1.3.cmml" xref="S7.T5.1.1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.1.1.1.m1.1c">m=3</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.2.2" class="ltx_tr">
<td id="S7.T5.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">3 x 3 Convolution, <math id="S7.T5.2.2.1.m1.1" class="ltx_Math" alttext="m=48" display="inline"><semantics id="S7.T5.2.2.1.m1.1a"><mrow id="S7.T5.2.2.1.m1.1.1" xref="S7.T5.2.2.1.m1.1.1.cmml"><mi id="S7.T5.2.2.1.m1.1.1.2" xref="S7.T5.2.2.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.2.2.1.m1.1.1.1" xref="S7.T5.2.2.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.2.2.1.m1.1.1.3" xref="S7.T5.2.2.1.m1.1.1.3.cmml">48</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.2.2.1.m1.1b"><apply id="S7.T5.2.2.1.m1.1.1.cmml" xref="S7.T5.2.2.1.m1.1.1"><eq id="S7.T5.2.2.1.m1.1.1.1.cmml" xref="S7.T5.2.2.1.m1.1.1.1"></eq><ci id="S7.T5.2.2.1.m1.1.1.2.cmml" xref="S7.T5.2.2.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.2.2.1.m1.1.1.3.cmml" xref="S7.T5.2.2.1.m1.1.1.3">48</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.2.2.1.m1.1c">m=48</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.3.3" class="ltx_tr">
<td id="S7.T5.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (4 layers) + TD, <math id="S7.T5.3.3.1.m1.1" class="ltx_Math" alttext="m=112" display="inline"><semantics id="S7.T5.3.3.1.m1.1a"><mrow id="S7.T5.3.3.1.m1.1.1" xref="S7.T5.3.3.1.m1.1.1.cmml"><mi id="S7.T5.3.3.1.m1.1.1.2" xref="S7.T5.3.3.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.3.3.1.m1.1.1.1" xref="S7.T5.3.3.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.3.3.1.m1.1.1.3" xref="S7.T5.3.3.1.m1.1.1.3.cmml">112</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.3.3.1.m1.1b"><apply id="S7.T5.3.3.1.m1.1.1.cmml" xref="S7.T5.3.3.1.m1.1.1"><eq id="S7.T5.3.3.1.m1.1.1.1.cmml" xref="S7.T5.3.3.1.m1.1.1.1"></eq><ci id="S7.T5.3.3.1.m1.1.1.2.cmml" xref="S7.T5.3.3.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.3.3.1.m1.1.1.3.cmml" xref="S7.T5.3.3.1.m1.1.1.3">112</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.3.3.1.m1.1c">m=112</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.4.4" class="ltx_tr">
<td id="S7.T5.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (5 layers) + TD, <math id="S7.T5.4.4.1.m1.1" class="ltx_Math" alttext="m=192" display="inline"><semantics id="S7.T5.4.4.1.m1.1a"><mrow id="S7.T5.4.4.1.m1.1.1" xref="S7.T5.4.4.1.m1.1.1.cmml"><mi id="S7.T5.4.4.1.m1.1.1.2" xref="S7.T5.4.4.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.4.4.1.m1.1.1.1" xref="S7.T5.4.4.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.4.4.1.m1.1.1.3" xref="S7.T5.4.4.1.m1.1.1.3.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.4.4.1.m1.1b"><apply id="S7.T5.4.4.1.m1.1.1.cmml" xref="S7.T5.4.4.1.m1.1.1"><eq id="S7.T5.4.4.1.m1.1.1.1.cmml" xref="S7.T5.4.4.1.m1.1.1.1"></eq><ci id="S7.T5.4.4.1.m1.1.1.2.cmml" xref="S7.T5.4.4.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.4.4.1.m1.1.1.3.cmml" xref="S7.T5.4.4.1.m1.1.1.3">192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.4.4.1.m1.1c">m=192</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.5.5" class="ltx_tr">
<td id="S7.T5.5.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (7 layers) + TD, <math id="S7.T5.5.5.1.m1.1" class="ltx_Math" alttext="m=304" display="inline"><semantics id="S7.T5.5.5.1.m1.1a"><mrow id="S7.T5.5.5.1.m1.1.1" xref="S7.T5.5.5.1.m1.1.1.cmml"><mi id="S7.T5.5.5.1.m1.1.1.2" xref="S7.T5.5.5.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.5.5.1.m1.1.1.1" xref="S7.T5.5.5.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.5.5.1.m1.1.1.3" xref="S7.T5.5.5.1.m1.1.1.3.cmml">304</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.5.5.1.m1.1b"><apply id="S7.T5.5.5.1.m1.1.1.cmml" xref="S7.T5.5.5.1.m1.1.1"><eq id="S7.T5.5.5.1.m1.1.1.1.cmml" xref="S7.T5.5.5.1.m1.1.1.1"></eq><ci id="S7.T5.5.5.1.m1.1.1.2.cmml" xref="S7.T5.5.5.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.5.5.1.m1.1.1.3.cmml" xref="S7.T5.5.5.1.m1.1.1.3">304</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.5.5.1.m1.1c">m=304</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.6.6" class="ltx_tr">
<td id="S7.T5.6.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (10 layers) + TD, <math id="S7.T5.6.6.1.m1.1" class="ltx_Math" alttext="m=464" display="inline"><semantics id="S7.T5.6.6.1.m1.1a"><mrow id="S7.T5.6.6.1.m1.1.1" xref="S7.T5.6.6.1.m1.1.1.cmml"><mi id="S7.T5.6.6.1.m1.1.1.2" xref="S7.T5.6.6.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.6.6.1.m1.1.1.1" xref="S7.T5.6.6.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.6.6.1.m1.1.1.3" xref="S7.T5.6.6.1.m1.1.1.3.cmml">464</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.6.6.1.m1.1b"><apply id="S7.T5.6.6.1.m1.1.1.cmml" xref="S7.T5.6.6.1.m1.1.1"><eq id="S7.T5.6.6.1.m1.1.1.1.cmml" xref="S7.T5.6.6.1.m1.1.1.1"></eq><ci id="S7.T5.6.6.1.m1.1.1.2.cmml" xref="S7.T5.6.6.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.6.6.1.m1.1.1.3.cmml" xref="S7.T5.6.6.1.m1.1.1.3">464</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.6.6.1.m1.1c">m=464</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.7.7" class="ltx_tr">
<td id="S7.T5.7.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (12 layers) + TD, <math id="S7.T5.7.7.1.m1.1" class="ltx_Math" alttext="m=656" display="inline"><semantics id="S7.T5.7.7.1.m1.1a"><mrow id="S7.T5.7.7.1.m1.1.1" xref="S7.T5.7.7.1.m1.1.1.cmml"><mi id="S7.T5.7.7.1.m1.1.1.2" xref="S7.T5.7.7.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.7.7.1.m1.1.1.1" xref="S7.T5.7.7.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.7.7.1.m1.1.1.3" xref="S7.T5.7.7.1.m1.1.1.3.cmml">656</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.7.7.1.m1.1b"><apply id="S7.T5.7.7.1.m1.1.1.cmml" xref="S7.T5.7.7.1.m1.1.1"><eq id="S7.T5.7.7.1.m1.1.1.1.cmml" xref="S7.T5.7.7.1.m1.1.1.1"></eq><ci id="S7.T5.7.7.1.m1.1.1.2.cmml" xref="S7.T5.7.7.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.7.7.1.m1.1.1.3.cmml" xref="S7.T5.7.7.1.m1.1.1.3">656</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.7.7.1.m1.1c">m=656</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.8.8" class="ltx_tr">
<td id="S7.T5.8.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB-up (15 layers), <math id="S7.T5.8.8.1.m1.1" class="ltx_Math" alttext="m=896" display="inline"><semantics id="S7.T5.8.8.1.m1.1a"><mrow id="S7.T5.8.8.1.m1.1.1" xref="S7.T5.8.8.1.m1.1.1.cmml"><mi id="S7.T5.8.8.1.m1.1.1.2" xref="S7.T5.8.8.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.8.8.1.m1.1.1.1" xref="S7.T5.8.8.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.8.8.1.m1.1.1.3" xref="S7.T5.8.8.1.m1.1.1.3.cmml">896</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.8.8.1.m1.1b"><apply id="S7.T5.8.8.1.m1.1.1.cmml" xref="S7.T5.8.8.1.m1.1.1"><eq id="S7.T5.8.8.1.m1.1.1.1.cmml" xref="S7.T5.8.8.1.m1.1.1.1"></eq><ci id="S7.T5.8.8.1.m1.1.1.2.cmml" xref="S7.T5.8.8.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.8.8.1.m1.1.1.3.cmml" xref="S7.T5.8.8.1.m1.1.1.3">896</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.8.8.1.m1.1c">m=896</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.9.9" class="ltx_tr">
<td id="S7.T5.9.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">TU + DB-up (12 layers), <math id="S7.T5.9.9.1.m1.1" class="ltx_Math" alttext="m=1088" display="inline"><semantics id="S7.T5.9.9.1.m1.1a"><mrow id="S7.T5.9.9.1.m1.1.1" xref="S7.T5.9.9.1.m1.1.1.cmml"><mi id="S7.T5.9.9.1.m1.1.1.2" xref="S7.T5.9.9.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.9.9.1.m1.1.1.1" xref="S7.T5.9.9.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.9.9.1.m1.1.1.3" xref="S7.T5.9.9.1.m1.1.1.3.cmml">1088</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.9.9.1.m1.1b"><apply id="S7.T5.9.9.1.m1.1.1.cmml" xref="S7.T5.9.9.1.m1.1.1"><eq id="S7.T5.9.9.1.m1.1.1.1.cmml" xref="S7.T5.9.9.1.m1.1.1.1"></eq><ci id="S7.T5.9.9.1.m1.1.1.2.cmml" xref="S7.T5.9.9.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.9.9.1.m1.1.1.3.cmml" xref="S7.T5.9.9.1.m1.1.1.3">1088</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.9.9.1.m1.1c">m=1088</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.10.10" class="ltx_tr">
<td id="S7.T5.10.10.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">TU + DB-up (10 layers), <math id="S7.T5.10.10.1.m1.1" class="ltx_Math" alttext="m=816" display="inline"><semantics id="S7.T5.10.10.1.m1.1a"><mrow id="S7.T5.10.10.1.m1.1.1" xref="S7.T5.10.10.1.m1.1.1.cmml"><mi id="S7.T5.10.10.1.m1.1.1.2" xref="S7.T5.10.10.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.10.10.1.m1.1.1.1" xref="S7.T5.10.10.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.10.10.1.m1.1.1.3" xref="S7.T5.10.10.1.m1.1.1.3.cmml">816</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.10.10.1.m1.1b"><apply id="S7.T5.10.10.1.m1.1.1.cmml" xref="S7.T5.10.10.1.m1.1.1"><eq id="S7.T5.10.10.1.m1.1.1.1.cmml" xref="S7.T5.10.10.1.m1.1.1.1"></eq><ci id="S7.T5.10.10.1.m1.1.1.2.cmml" xref="S7.T5.10.10.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.10.10.1.m1.1.1.3.cmml" xref="S7.T5.10.10.1.m1.1.1.3">816</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.10.10.1.m1.1c">m=816</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.11.11" class="ltx_tr">
<td id="S7.T5.11.11.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">TU + DB (7 layers), <math id="S7.T5.11.11.1.m1.1" class="ltx_Math" alttext="m=578" display="inline"><semantics id="S7.T5.11.11.1.m1.1a"><mrow id="S7.T5.11.11.1.m1.1.1" xref="S7.T5.11.11.1.m1.1.1.cmml"><mi id="S7.T5.11.11.1.m1.1.1.2" xref="S7.T5.11.11.1.m1.1.1.2.cmml">m</mi><mo id="S7.T5.11.11.1.m1.1.1.1" xref="S7.T5.11.11.1.m1.1.1.1.cmml">=</mo><mn id="S7.T5.11.11.1.m1.1.1.3" xref="S7.T5.11.11.1.m1.1.1.3.cmml">578</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T5.11.11.1.m1.1b"><apply id="S7.T5.11.11.1.m1.1.1.cmml" xref="S7.T5.11.11.1.m1.1.1"><eq id="S7.T5.11.11.1.m1.1.1.1.cmml" xref="S7.T5.11.11.1.m1.1.1.1"></eq><ci id="S7.T5.11.11.1.m1.1.1.2.cmml" xref="S7.T5.11.11.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T5.11.11.1.m1.1.1.3.cmml" xref="S7.T5.11.11.1.m1.1.1.3">578</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.11.11.1.m1.1c">m=578</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T5.12.14.1" class="ltx_tr">
<td id="S7.T5.12.14.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Attention block (3 streams)</td>
</tr>
<tr id="S7.T5.12.12" class="ltx_tr">
<td id="S7.T5.12.12.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">FC (<math id="S7.T5.12.12.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S7.T5.12.12.1.m1.1a"><mi id="S7.T5.12.12.1.m1.1.1" xref="S7.T5.12.12.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S7.T5.12.12.1.m1.1b"><ci id="S7.T5.12.12.1.m1.1.1.cmml" xref="S7.T5.12.12.1.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.12.12.1.m1.1c">d</annotation></semantics></math> = Out dimension) (3 streams)</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>
The architecture details of our model. DB is Dense Block, TD is Transition Down block, TU is Transition Up block, DB-up is modified Dense Block used in up-stream, and FC is a fully-connected layer. Each layer in DB and DB-up increases the number of features by 16. The number <math id="S7.T5.15.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S7.T5.15.m1.1b"><mi id="S7.T5.15.m1.1.1" xref="S7.T5.15.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S7.T5.15.m1.1c"><ci id="S7.T5.15.m1.1.1.cmml" xref="S7.T5.15.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.15.m1.1d">m</annotation></semantics></math> is the total number of features used in the DB and DP-up blocks. <math id="S7.T5.16.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S7.T5.16.m2.1b"><mi id="S7.T5.16.m2.1.1" xref="S7.T5.16.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S7.T5.16.m2.1c"><ci id="S7.T5.16.m2.1.1.cmml" xref="S7.T5.16.m2.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.16.m2.1d">d</annotation></semantics></math> is the dimension of the fully connected layers. </figcaption>
</figure>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p">DenseNet for semantic segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> uses the DenseNet architecture in the down-stream, but modifies the architecture slightly in the up-stream. First, the features are upsampled in the up-stream via the transition layer that uses 3x3 transposed convolutions with stride 2. The network uses the skip connections to add features with the same spatial resolution from the down-stream to the upsampled features from the previous layer. These features are inputs to the up-stream Dense block. Since the spatial resolution increases, the network will require too much memory if we continue to concatenate the feature vectors. Thus, the output of the Dense block in the up-stream is modified (DB-up in Table <a href="#S7.T5" title="Table 5 â€£ 7.1 Model Details â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). The block output consists only of the features created in the current Dense block, i.e., the new features are not concatenated to the input features. In the up-stream, we can access upsampled features, down-stream features with the same resolution, and newly generated features. We use all these features as the input to the attention block. We show details of our model in Table <a href="#S7.T5" title="Table 5 â€£ 7.1 Model Details â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="S7.T6" class="ltx_table">
<table id="S7.T6.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T6.10.11.1" class="ltx_tr">
<th id="S7.T6.10.11.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">DenseNet</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T6.1.1" class="ltx_tr">
<td id="S7.T6.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">Input, <math id="S7.T6.1.1.1.m1.1" class="ltx_Math" alttext="m=3" display="inline"><semantics id="S7.T6.1.1.1.m1.1a"><mrow id="S7.T6.1.1.1.m1.1.1" xref="S7.T6.1.1.1.m1.1.1.cmml"><mi id="S7.T6.1.1.1.m1.1.1.2" xref="S7.T6.1.1.1.m1.1.1.2.cmml">m</mi><mo id="S7.T6.1.1.1.m1.1.1.1" xref="S7.T6.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S7.T6.1.1.1.m1.1.1.3" xref="S7.T6.1.1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.1.1.1.m1.1b"><apply id="S7.T6.1.1.1.m1.1.1.cmml" xref="S7.T6.1.1.1.m1.1.1"><eq id="S7.T6.1.1.1.m1.1.1.1.cmml" xref="S7.T6.1.1.1.m1.1.1.1"></eq><ci id="S7.T6.1.1.1.m1.1.1.2.cmml" xref="S7.T6.1.1.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T6.1.1.1.m1.1.1.3.cmml" xref="S7.T6.1.1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.1.1.1.m1.1c">m=3</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T6.2.2" class="ltx_tr">
<td id="S7.T6.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">3 x 3 Convolution, <math id="S7.T6.2.2.1.m1.1" class="ltx_Math" alttext="m=48" display="inline"><semantics id="S7.T6.2.2.1.m1.1a"><mrow id="S7.T6.2.2.1.m1.1.1" xref="S7.T6.2.2.1.m1.1.1.cmml"><mi id="S7.T6.2.2.1.m1.1.1.2" xref="S7.T6.2.2.1.m1.1.1.2.cmml">m</mi><mo id="S7.T6.2.2.1.m1.1.1.1" xref="S7.T6.2.2.1.m1.1.1.1.cmml">=</mo><mn id="S7.T6.2.2.1.m1.1.1.3" xref="S7.T6.2.2.1.m1.1.1.3.cmml">48</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.2.2.1.m1.1b"><apply id="S7.T6.2.2.1.m1.1.1.cmml" xref="S7.T6.2.2.1.m1.1.1"><eq id="S7.T6.2.2.1.m1.1.1.1.cmml" xref="S7.T6.2.2.1.m1.1.1.1"></eq><ci id="S7.T6.2.2.1.m1.1.1.2.cmml" xref="S7.T6.2.2.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T6.2.2.1.m1.1.1.3.cmml" xref="S7.T6.2.2.1.m1.1.1.3">48</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.2.2.1.m1.1c">m=48</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T6.3.3" class="ltx_tr">
<td id="S7.T6.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (4 layers) + TD, <math id="S7.T6.3.3.1.m1.1" class="ltx_Math" alttext="m=112" display="inline"><semantics id="S7.T6.3.3.1.m1.1a"><mrow id="S7.T6.3.3.1.m1.1.1" xref="S7.T6.3.3.1.m1.1.1.cmml"><mi id="S7.T6.3.3.1.m1.1.1.2" xref="S7.T6.3.3.1.m1.1.1.2.cmml">m</mi><mo id="S7.T6.3.3.1.m1.1.1.1" xref="S7.T6.3.3.1.m1.1.1.1.cmml">=</mo><mn id="S7.T6.3.3.1.m1.1.1.3" xref="S7.T6.3.3.1.m1.1.1.3.cmml">112</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.3.3.1.m1.1b"><apply id="S7.T6.3.3.1.m1.1.1.cmml" xref="S7.T6.3.3.1.m1.1.1"><eq id="S7.T6.3.3.1.m1.1.1.1.cmml" xref="S7.T6.3.3.1.m1.1.1.1"></eq><ci id="S7.T6.3.3.1.m1.1.1.2.cmml" xref="S7.T6.3.3.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T6.3.3.1.m1.1.1.3.cmml" xref="S7.T6.3.3.1.m1.1.1.3">112</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.3.3.1.m1.1c">m=112</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T6.4.4" class="ltx_tr">
<td id="S7.T6.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (5 layers) + TD, <math id="S7.T6.4.4.1.m1.1" class="ltx_Math" alttext="m=192" display="inline"><semantics id="S7.T6.4.4.1.m1.1a"><mrow id="S7.T6.4.4.1.m1.1.1" xref="S7.T6.4.4.1.m1.1.1.cmml"><mi id="S7.T6.4.4.1.m1.1.1.2" xref="S7.T6.4.4.1.m1.1.1.2.cmml">m</mi><mo id="S7.T6.4.4.1.m1.1.1.1" xref="S7.T6.4.4.1.m1.1.1.1.cmml">=</mo><mn id="S7.T6.4.4.1.m1.1.1.3" xref="S7.T6.4.4.1.m1.1.1.3.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.4.4.1.m1.1b"><apply id="S7.T6.4.4.1.m1.1.1.cmml" xref="S7.T6.4.4.1.m1.1.1"><eq id="S7.T6.4.4.1.m1.1.1.1.cmml" xref="S7.T6.4.4.1.m1.1.1.1"></eq><ci id="S7.T6.4.4.1.m1.1.1.2.cmml" xref="S7.T6.4.4.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T6.4.4.1.m1.1.1.3.cmml" xref="S7.T6.4.4.1.m1.1.1.3">192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.4.4.1.m1.1c">m=192</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T6.5.5" class="ltx_tr">
<td id="S7.T6.5.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (14 layers) + TD, <math id="S7.T6.5.5.1.m1.1" class="ltx_Math" alttext="m=416" display="inline"><semantics id="S7.T6.5.5.1.m1.1a"><mrow id="S7.T6.5.5.1.m1.1.1" xref="S7.T6.5.5.1.m1.1.1.cmml"><mi id="S7.T6.5.5.1.m1.1.1.2" xref="S7.T6.5.5.1.m1.1.1.2.cmml">m</mi><mo id="S7.T6.5.5.1.m1.1.1.1" xref="S7.T6.5.5.1.m1.1.1.1.cmml">=</mo><mn id="S7.T6.5.5.1.m1.1.1.3" xref="S7.T6.5.5.1.m1.1.1.3.cmml">416</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.5.5.1.m1.1b"><apply id="S7.T6.5.5.1.m1.1.1.cmml" xref="S7.T6.5.5.1.m1.1.1"><eq id="S7.T6.5.5.1.m1.1.1.1.cmml" xref="S7.T6.5.5.1.m1.1.1.1"></eq><ci id="S7.T6.5.5.1.m1.1.1.2.cmml" xref="S7.T6.5.5.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T6.5.5.1.m1.1.1.3.cmml" xref="S7.T6.5.5.1.m1.1.1.3">416</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.5.5.1.m1.1c">m=416</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T6.6.6" class="ltx_tr">
<td id="S7.T6.6.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (20 layers) + TD, <math id="S7.T6.6.6.1.m1.1" class="ltx_Math" alttext="m=736" display="inline"><semantics id="S7.T6.6.6.1.m1.1a"><mrow id="S7.T6.6.6.1.m1.1.1" xref="S7.T6.6.6.1.m1.1.1.cmml"><mi id="S7.T6.6.6.1.m1.1.1.2" xref="S7.T6.6.6.1.m1.1.1.2.cmml">m</mi><mo id="S7.T6.6.6.1.m1.1.1.1" xref="S7.T6.6.6.1.m1.1.1.1.cmml">=</mo><mn id="S7.T6.6.6.1.m1.1.1.3" xref="S7.T6.6.6.1.m1.1.1.3.cmml">736</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.6.6.1.m1.1b"><apply id="S7.T6.6.6.1.m1.1.1.cmml" xref="S7.T6.6.6.1.m1.1.1"><eq id="S7.T6.6.6.1.m1.1.1.1.cmml" xref="S7.T6.6.6.1.m1.1.1.1"></eq><ci id="S7.T6.6.6.1.m1.1.1.2.cmml" xref="S7.T6.6.6.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T6.6.6.1.m1.1.1.3.cmml" xref="S7.T6.6.6.1.m1.1.1.3">736</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.6.6.1.m1.1c">m=736</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T6.7.7" class="ltx_tr">
<td id="S7.T6.7.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (21 layers) + TD, <math id="S7.T6.7.7.1.m1.1" class="ltx_Math" alttext="m=1056" display="inline"><semantics id="S7.T6.7.7.1.m1.1a"><mrow id="S7.T6.7.7.1.m1.1.1" xref="S7.T6.7.7.1.m1.1.1.cmml"><mi id="S7.T6.7.7.1.m1.1.1.2" xref="S7.T6.7.7.1.m1.1.1.2.cmml">m</mi><mo id="S7.T6.7.7.1.m1.1.1.1" xref="S7.T6.7.7.1.m1.1.1.1.cmml">=</mo><mn id="S7.T6.7.7.1.m1.1.1.3" xref="S7.T6.7.7.1.m1.1.1.3.cmml">1056</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.7.7.1.m1.1b"><apply id="S7.T6.7.7.1.m1.1.1.cmml" xref="S7.T6.7.7.1.m1.1.1"><eq id="S7.T6.7.7.1.m1.1.1.1.cmml" xref="S7.T6.7.7.1.m1.1.1.1"></eq><ci id="S7.T6.7.7.1.m1.1.1.2.cmml" xref="S7.T6.7.7.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T6.7.7.1.m1.1.1.3.cmml" xref="S7.T6.7.7.1.m1.1.1.3">1056</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.7.7.1.m1.1c">m=1056</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T6.8.8" class="ltx_tr">
<td id="S7.T6.8.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DB (15 layers), <math id="S7.T6.8.8.1.m1.1" class="ltx_Math" alttext="m=1296" display="inline"><semantics id="S7.T6.8.8.1.m1.1a"><mrow id="S7.T6.8.8.1.m1.1.1" xref="S7.T6.8.8.1.m1.1.1.cmml"><mi id="S7.T6.8.8.1.m1.1.1.2" xref="S7.T6.8.8.1.m1.1.1.2.cmml">m</mi><mo id="S7.T6.8.8.1.m1.1.1.1" xref="S7.T6.8.8.1.m1.1.1.1.cmml">=</mo><mn id="S7.T6.8.8.1.m1.1.1.3" xref="S7.T6.8.8.1.m1.1.1.3.cmml">1296</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.8.8.1.m1.1b"><apply id="S7.T6.8.8.1.m1.1.1.cmml" xref="S7.T6.8.8.1.m1.1.1"><eq id="S7.T6.8.8.1.m1.1.1.1.cmml" xref="S7.T6.8.8.1.m1.1.1.1"></eq><ci id="S7.T6.8.8.1.m1.1.1.2.cmml" xref="S7.T6.8.8.1.m1.1.1.2">ğ‘š</ci><cn type="integer" id="S7.T6.8.8.1.m1.1.1.3.cmml" xref="S7.T6.8.8.1.m1.1.1.3">1296</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.8.8.1.m1.1c">m=1296</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T6.10.12.1" class="ltx_tr">
<td id="S7.T6.10.12.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Global average pooling</td>
</tr>
<tr id="S7.T6.9.9" class="ltx_tr">
<td id="S7.T6.9.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">FC (<math id="S7.T6.9.9.1.m1.1" class="ltx_Math" alttext="d=512" display="inline"><semantics id="S7.T6.9.9.1.m1.1a"><mrow id="S7.T6.9.9.1.m1.1.1" xref="S7.T6.9.9.1.m1.1.1.cmml"><mi id="S7.T6.9.9.1.m1.1.1.2" xref="S7.T6.9.9.1.m1.1.1.2.cmml">d</mi><mo id="S7.T6.9.9.1.m1.1.1.1" xref="S7.T6.9.9.1.m1.1.1.1.cmml">=</mo><mn id="S7.T6.9.9.1.m1.1.1.3" xref="S7.T6.9.9.1.m1.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.9.9.1.m1.1b"><apply id="S7.T6.9.9.1.m1.1.1.cmml" xref="S7.T6.9.9.1.m1.1.1"><eq id="S7.T6.9.9.1.m1.1.1.1.cmml" xref="S7.T6.9.9.1.m1.1.1.1"></eq><ci id="S7.T6.9.9.1.m1.1.1.2.cmml" xref="S7.T6.9.9.1.m1.1.1.2">ğ‘‘</ci><cn type="integer" id="S7.T6.9.9.1.m1.1.1.3.cmml" xref="S7.T6.9.9.1.m1.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.9.9.1.m1.1c">d=512</annotation></semantics></math>) + Batch Norm + ReLU (3 streams)</td>
</tr>
<tr id="S7.T6.10.10" class="ltx_tr">
<td id="S7.T6.10.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">FC (<math id="S7.T6.10.10.1.m1.1" class="ltx_Math" alttext="d=" display="inline"><semantics id="S7.T6.10.10.1.m1.1a"><mrow id="S7.T6.10.10.1.m1.1.1" xref="S7.T6.10.10.1.m1.1.1.cmml"><mi id="S7.T6.10.10.1.m1.1.1.2" xref="S7.T6.10.10.1.m1.1.1.2.cmml">d</mi><mo id="S7.T6.10.10.1.m1.1.1.1" xref="S7.T6.10.10.1.m1.1.1.1.cmml">=</mo><mi id="S7.T6.10.10.1.m1.1.1.3" xref="S7.T6.10.10.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S7.T6.10.10.1.m1.1b"><apply id="S7.T6.10.10.1.m1.1.1.cmml" xref="S7.T6.10.10.1.m1.1.1"><eq id="S7.T6.10.10.1.m1.1.1.1.cmml" xref="S7.T6.10.10.1.m1.1.1.1"></eq><ci id="S7.T6.10.10.1.m1.1.1.2.cmml" xref="S7.T6.10.10.1.m1.1.1.2">ğ‘‘</ci><csymbol cd="latexml" id="S7.T6.10.10.1.m1.1.1.3.cmml" xref="S7.T6.10.10.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.10.10.1.m1.1c">d=</annotation></semantics></math> Out dimension) (3 streams)</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>The architecture details of our ablation baseline DenseNet. DB is Dense Block, TD is Transition Down block, and FC is a fully-connected layer. Each layer in DB increases the number of features by 16. The number <math id="S7.T6.13.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S7.T6.13.m1.1b"><mi id="S7.T6.13.m1.1.1" xref="S7.T6.13.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S7.T6.13.m1.1c"><ci id="S7.T6.13.m1.1.1.cmml" xref="S7.T6.13.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.13.m1.1d">m</annotation></semantics></math> is the total number of features used in the DB blocks. <math id="S7.T6.14.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S7.T6.14.m2.1b"><mi id="S7.T6.14.m2.1.1" xref="S7.T6.14.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S7.T6.14.m2.1c"><ci id="S7.T6.14.m2.1.1.cmml" xref="S7.T6.14.m2.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T6.14.m2.1d">d</annotation></semantics></math> is the dimension of the fully connected layers.</figcaption>
</figure>
<figure id="S7.T7" class="ltx_table">
<table id="S7.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S7.T7.1.1.1" class="ltx_tr">
<th id="S7.T7.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"></th>
<td id="S7.T7.1.1.1.2" class="ltx_td ltx_border_tt"></td>
<td id="S7.T7.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S7.T7.1.1.1.3.1" class="ltx_text" style="font-size:70%;">Single stage</span></td>
<td id="S7.T7.1.1.1.4" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S7.T7.1.1.1.5" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S7.T7.1.1.1.6" class="ltx_td ltx_border_tt"></td>
<td id="S7.T7.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S7.T7.1.1.1.7.1" class="ltx_text" style="font-size:70%;">Multi stage</span></td>
<td id="S7.T7.1.1.1.8" class="ltx_td ltx_border_r ltx_border_tt"></td>
</tr>
<tr id="S7.T7.1.2.2" class="ltx_tr">
<th id="S7.T7.1.2.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="S7.T7.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T7.1.2.2.2.1" class="ltx_text" style="font-size:70%;">DPOD</span></td>
<td id="S7.T7.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T7.1.2.2.3.1" class="ltx_text" style="font-size:70%;">DenseNet</span></td>
<td id="S7.T7.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.1.2.2.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ours</span></td>
<td id="S7.T7.1.2.2.5" class="ltx_td ltx_border_r"></td>
<td id="S7.T7.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T7.1.2.2.6.1" class="ltx_text" style="font-size:70%;">DeepIM</span></td>
<td id="S7.T7.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T7.1.2.2.7.1" class="ltx_text" style="font-size:70%;">DenseNet</span></td>
<td id="S7.T7.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.1.2.2.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ours</span></td>
</tr>
<tr id="S7.T7.1.3.3" class="ltx_tr">
<th id="S7.T7.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r ltx_border_tt"><span id="S7.T7.1.3.3.1.1" class="ltx_text" style="font-size:70%;">fps</span></th>
<td id="S7.T7.1.3.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt"><span id="S7.T7.1.3.3.2.1" class="ltx_text" style="font-size:70%;">80</span></td>
<td id="S7.T7.1.3.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt"><span id="S7.T7.1.3.3.3.1" class="ltx_text" style="font-size:70%;">50</span></td>
<td id="S7.T7.1.3.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt"><span id="S7.T7.1.3.3.4.1" class="ltx_text" style="font-size:70%;">35</span></td>
<td id="S7.T7.1.3.3.5" class="ltx_td ltx_border_bb ltx_border_r ltx_border_tt"></td>
<td id="S7.T7.1.3.3.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt"><span id="S7.T7.1.3.3.6.1" class="ltx_text" style="font-size:70%;">9</span></td>
<td id="S7.T7.1.3.3.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt"><span id="S7.T7.1.3.3.7.1" class="ltx_text" style="font-size:70%;">17</span></td>
<td id="S7.T7.1.3.3.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt"><span id="S7.T7.1.3.3.8.1" class="ltx_text" style="font-size:70%;">13</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 7: </span>Results of the runtime experiment. We compare the running times of our methods in the single-stage and multi-stage settings. All experiments are done on a Pascal Titan X GPU.</figcaption>
</figure>
<figure id="S7.F5" class="ltx_figure"><img src="/html/2101.01659/assets/figures/att_vs_activation.png" id="S7.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="617" height="226" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>In this figure, we compare our modelâ€™s attention map to the average feature activation from the third DenseNet block (the block with 14 layers in Table <a href="#S7.T6" title="Table 6 â€£ 7.1 Model Details â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>). We use results from the first stages. The feature activations look very similar in later stages. Red and yellow colors indicate regions with higher activation and attention values, while blue represents regions with low values. Feature activations have high values at outlines, but also in other regions of the input image. The attention helps to isolate the regions that are relevant to the target object and reject the clutter.</figcaption>
</figure>
<div id="S7.SS1.p3" class="ltx_para">
<p id="S7.SS1.p3.1" class="ltx_p">Our ablation baseline is shown in Table <a href="#S7.T6" title="Table 6 â€£ 7.1 Model Details â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. We use regular DenseNet since the baseline directly predicts the rotation and translation parameters, and hence does not need to upscale feature vectors.
To have the same number of parameters in both models, we increase the number of layers Dense blocks 3, 4, and 5 (the Dense blocks with 14, 20, and 21 layers in Table <a href="#S7.T6" title="Table 6 â€£ 7.1 Model Details â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>). We choose these blocks since our model has more capacity at these resolutions. To obtain the strong ablation baseline, we experimented with the number and size of fully connected layers at the end of the networks. There was no improvement when we added more fully connected units or additional layers.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Runtime Experiment</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">We compared the runtime of our method to all baseline models. We present the results in Table <a href="#S7.T7" title="Table 7 â€£ 7.1 Model Details â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. Since all models are fully differentiable, the computation time depends on the neural network size. In single-stage settings, all methods run faster than 30 fps. Most of the modern cameras operate at 30 fps, and hence we can say that all methods operate in real-time. In the multi-stage setting, all methods operate at a similar frame rate. However, we show in the paper that our method outperforms all baseline methods. In conclusion, our method performs better without sacrificing computational time.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span>Attention vs. Activation Experiment</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p">In Fig. <a href="#S7.F5" title="Figure 5 â€£ 7.1 Model Details â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we compare the attention maps of our model to the average feature activation of the DenseNet baseline. The resolution of our attention maps is the same as the resolution of the features in the Dense block with 14 layers in Table <a href="#S7.T6" title="Table 6 â€£ 7.1 Model Details â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Thus, we use the features at the output of this block. We compute per-pixel average values. DenseNet activation maps look very similar in all four stages of the multi-stage model. We show results from the first stages, but we can reach the same conclusions by comparing any of the stages.</p>
</div>
<div id="S7.SS3.p2" class="ltx_para">
<p id="S7.SS3.p2.1" class="ltx_p">Similarly to the attention model, features activations have high values at object outlines. However, these are not the only regions where activations have high values. The activations are high at the background regions and even at the uniformly colored parts of the object (see driller example in Fig. <a href="#S7.F5" title="Figure 5 â€£ 7.1 Model Details â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). One can argue that deeper layers of DenseNet can potentially reject some of the clutter. However, deeper layers have lower resolutions, which prevents them from isolating fine-grained details. The attention network resolves this issue by enabling our model to isolate discriminative details at the high resolution. This leads to accuracy improvement, as we show in our paper.</p>
</div>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4 </span>U-DenseNet Ablation Baseline Experiment</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.1" class="ltx_p">In this experiment, we compare our results to an additional ablation baseline. In the Sec.Â <a href="#S5" title="5 Results â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we use DenseNet as our ablation baseline because the downstream type of architecture is the most typical choice for a regression task. The features need to be squeezed into a one-dimensional vector to perform regression in the final part of the network. If we do not need access to low-level features, there is no reason to use the up-stream part of the network. In our model, we apply a spatial attention mechanism for feature selection, and thus we need the up-stream architecture. To confirm that the specific backbone details are not the main cause for performance improvement, we conduct an additional experiment. We trained a new ablation model, where we use the same U-DenseNet backbone as in our model. To obtain the new ablation baseline, we replace the attention block with fully connected layers. We use global average pooling to compute one-dimensional feature vectors for regression.</p>
</div>
<figure id="S7.T8" class="ltx_table">
<table id="S7.T8.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S7.T8.3.1.1" class="ltx_tr">
<th id="S7.T8.3.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S7.T8.3.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S7.T8.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S7.T8.3.1.1.3.1" class="ltx_text" style="font-size:70%;">LineMOD</span></th>
<th id="S7.T8.3.1.1.4" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S7.T8.3.1.1.5" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S7.T8.3.1.1.6" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S7.T8.3.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S7.T8.3.1.1.7.1" class="ltx_text" style="font-size:70%;">Occlusion LineMOD</span></th>
<td id="S7.T8.3.1.1.8" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S7.T8.3.2.2" class="ltx_tr">
<th id="S7.T8.3.2.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S7.T8.3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T8.3.2.2.2.1" class="ltx_text" style="font-size:70%;">U-DenseNet</span></th>
<th id="S7.T8.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T8.3.2.2.3.1" class="ltx_text" style="font-size:70%;">DenseNet</span></th>
<th id="S7.T8.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T8.3.2.2.4.1" class="ltx_text" style="font-size:70%;">Ours</span></th>
<th id="S7.T8.3.2.2.5" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S7.T8.3.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T8.3.2.2.6.1" class="ltx_text" style="font-size:70%;">U-DenseNet</span></th>
<th id="S7.T8.3.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T8.3.2.2.7.1" class="ltx_text" style="font-size:70%;">DenseNet</span></th>
<th id="S7.T8.3.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T8.3.2.2.8.1" class="ltx_text" style="font-size:70%;">Ours</span></th>
</tr>
<tr id="S7.T8.3.3.3" class="ltx_tr">
<th id="S7.T8.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S7.T8.3.3.3.1.1" class="ltx_text" style="font-size:70%;">Single-stage</span></th>
<td id="S7.T8.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T8.3.3.3.2.1" class="ltx_text" style="font-size:70%;">92.77</span></td>
<td id="S7.T8.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T8.3.3.3.3.1" class="ltx_text" style="font-size:70%;">93.18</span></td>
<td id="S7.T8.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T8.3.3.3.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">93.47</span></td>
<td id="S7.T8.3.3.3.5" class="ltx_td ltx_border_t"></td>
<td id="S7.T8.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T8.3.3.3.6.1" class="ltx_text" style="font-size:70%;">42.04</span></td>
<td id="S7.T8.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T8.3.3.3.7.1" class="ltx_text" style="font-size:70%;">41.57</span></td>
<td id="S7.T8.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T8.3.3.3.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">44.28</span></td>
</tr>
<tr id="S7.T8.3.4.4" class="ltx_tr">
<th id="S7.T8.3.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S7.T8.3.4.4.1.1" class="ltx_text" style="font-size:70%;">Multi-stage</span></th>
<td id="S7.T8.3.4.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T8.3.4.4.2.1" class="ltx_text" style="font-size:70%;">93.70</span></td>
<td id="S7.T8.3.4.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T8.3.4.4.3.1" class="ltx_text" style="font-size:70%;">93.63</span></td>
<td id="S7.T8.3.4.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T8.3.4.4.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">94.28</span></td>
<td id="S7.T8.3.4.4.5" class="ltx_td ltx_border_bb"></td>
<td id="S7.T8.3.4.4.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T8.3.4.4.6.1" class="ltx_text" style="font-size:70%;">49.27</span></td>
<td id="S7.T8.3.4.4.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T8.3.4.4.7.1" class="ltx_text" style="font-size:70%;">48.02</span></td>
<td id="S7.T8.3.4.4.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T8.3.4.4.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">51.63</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 8: </span>Average ADD(-S) scores of our approach compared to DenseNet and U-DenseNet ablation baselines on LineMOD and Occlusion LineMOD datasets. The table shows the percentage of correctly estimated poses using <math id="S7.T8.2.m1.1" class="ltx_Math" alttext="0.1d" display="inline"><semantics id="S7.T8.2.m1.1b"><mrow id="S7.T8.2.m1.1.1" xref="S7.T8.2.m1.1.1.cmml"><mn id="S7.T8.2.m1.1.1.2" xref="S7.T8.2.m1.1.1.2.cmml">0.1</mn><mo lspace="0em" rspace="0em" id="S7.T8.2.m1.1.1.1" xref="S7.T8.2.m1.1.1.1.cmml">â€‹</mo><mi id="S7.T8.2.m1.1.1.3" xref="S7.T8.2.m1.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S7.T8.2.m1.1c"><apply id="S7.T8.2.m1.1.1.cmml" xref="S7.T8.2.m1.1.1"><times id="S7.T8.2.m1.1.1.1.cmml" xref="S7.T8.2.m1.1.1.1"></times><cn type="float" id="S7.T8.2.m1.1.1.2.cmml" xref="S7.T8.2.m1.1.1.2">0.1</cn><ci id="S7.T8.2.m1.1.1.3.cmml" xref="S7.T8.2.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T8.2.m1.1d">0.1d</annotation></semantics></math> ADD(-S) threshold (higher is better). Our method performs better than both baselines. </figcaption>
</figure>
<figure id="S7.T9" class="ltx_table">
<table id="S7.T9.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T9.3.1.1" class="ltx_tr">
<th id="S7.T9.3.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S7.T9.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S7.T9.3.1.1.2.1" class="ltx_text" style="font-size:70%;">PVNet init</span></th>
<th id="S7.T9.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S7.T9.3.1.1.3.1" class="ltx_text" style="font-size:70%;">One Stage</span></th>
<th id="S7.T9.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S7.T9.3.1.1.4.1" class="ltx_text" style="font-size:70%;">Two Stages</span></th>
<th id="S7.T9.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S7.T9.3.1.1.5.1" class="ltx_text" style="font-size:70%;">Three Stages</span></th>
<th id="S7.T9.3.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S7.T9.3.1.1.6.1" class="ltx_text" style="font-size:70%;">Four Stages</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T9.3.2.1" class="ltx_tr">
<th id="S7.T9.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S7.T9.3.2.1.1.1" class="ltx_text" style="font-size:70%;">LineMOD</span></th>
<td id="S7.T9.3.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T9.3.2.1.2.1" class="ltx_text" style="font-size:70%;">85.56</span></td>
<td id="S7.T9.3.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T9.3.2.1.3.1" class="ltx_text" style="font-size:70%;">93.47</span></td>
<td id="S7.T9.3.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T9.3.2.1.4.1" class="ltx_text" style="font-size:70%;">94.15</span></td>
<td id="S7.T9.3.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T9.3.2.1.5.1" class="ltx_text" style="font-size:70%;">94.19</span></td>
<td id="S7.T9.3.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T9.3.2.1.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">94.28</span></td>
</tr>
<tr id="S7.T9.3.3.2" class="ltx_tr">
<th id="S7.T9.3.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S7.T9.3.3.2.1.1" class="ltx_text" style="font-size:70%;">Occlusion LineMOD</span></th>
<td id="S7.T9.3.3.2.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T9.3.3.2.2.1" class="ltx_text" style="font-size:70%;">39.59</span></td>
<td id="S7.T9.3.3.2.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T9.3.3.2.3.1" class="ltx_text" style="font-size:70%;">44.28</span></td>
<td id="S7.T9.3.3.2.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T9.3.3.2.4.1" class="ltx_text" style="font-size:70%;">49.89</span></td>
<td id="S7.T9.3.3.2.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T9.3.3.2.5.1" class="ltx_text" style="font-size:70%;">51.21</span></td>
<td id="S7.T9.3.3.2.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T9.3.3.2.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">51.63</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 9: </span>Average ADD(-S) scores of our approach for a different number of stages. The table shows the percentage of correctly estimated poses using <math id="S7.T9.2.m1.1" class="ltx_Math" alttext="0.1d" display="inline"><semantics id="S7.T9.2.m1.1b"><mrow id="S7.T9.2.m1.1.1" xref="S7.T9.2.m1.1.1.cmml"><mn id="S7.T9.2.m1.1.1.2" xref="S7.T9.2.m1.1.1.2.cmml">0.1</mn><mo lspace="0em" rspace="0em" id="S7.T9.2.m1.1.1.1" xref="S7.T9.2.m1.1.1.1.cmml">â€‹</mo><mi id="S7.T9.2.m1.1.1.3" xref="S7.T9.2.m1.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S7.T9.2.m1.1c"><apply id="S7.T9.2.m1.1.1.cmml" xref="S7.T9.2.m1.1.1"><times id="S7.T9.2.m1.1.1.1.cmml" xref="S7.T9.2.m1.1.1.1"></times><cn type="float" id="S7.T9.2.m1.1.1.2.cmml" xref="S7.T9.2.m1.1.1.2">0.1</cn><ci id="S7.T9.2.m1.1.1.3.cmml" xref="S7.T9.2.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T9.2.m1.1d">0.1d</annotation></semantics></math> ADD(-S) threshold (higher is better). We present average scores on the LineMOD and Occlusion LineMOD datasets.</figcaption>
</figure>
<div id="S7.SS4.p2" class="ltx_para">
<p id="S7.SS4.p2.1" class="ltx_p">We present results in Table <a href="#S7.T8" title="Table 8 â€£ 7.4 U-DenseNet Ablation Baseline Experiment â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, where U-DenseNet represents the new baseline. By comparing the accuracies of the ablation baselines, i.e., the U-DenseNet and DenseNet baselines, we conclude that both models perform similarly. U-DenseNet performs slightly better compared to the DenseNet on the Occlusion LineMOD dataset. U-DenseNet has direct access to the not occluded low-level features, which is probably the cause of this difference. However, our approach performs significantly better compared to both ablation baselines, which confirms that the performance improvement is due to the attention module.</p>
</div>
</section>
<section id="S7.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.5 </span>Influence of Stages Number</h3>

<div id="S7.SS5.p1" class="ltx_para">
<p id="S7.SS5.p1.1" class="ltx_p">The multi-stage variant of our approach uses four stages. We follow the DeepIM paper in this regard. For a fair comparison, we use the same number of stages as the multi-stage baseline. To evaluate how our method performs with a different number of stages, we conduct additional experiments. In this experiment, we train our model using two and three stages and compare to the models evaluated in the main paper, i.e., the single-stage and four-stage models. We present the results in TableÂ <a href="#S7.T9" title="Table 9 â€£ 7.4 U-DenseNet Ablation Baseline Experiment â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<div id="S7.SS5.p2" class="ltx_para">
<p id="S7.SS5.p2.1" class="ltx_p">TableÂ <a href="#S7.T9" title="Table 9 â€£ 7.4 U-DenseNet Ablation Baseline Experiment â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows that adding each stage benefits the refinement procedure. The models with one and two stages give the most significant improvements. The later stages still improve the results, but the relative improvement is smaller compared to the first two stages. From the improvement trend in Table <a href="#S7.T9" title="Table 9 â€£ 7.4 U-DenseNet Ablation Baseline Experiment â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, we can conclude that adding more than four stages would improve the results but not significantly. It would be interesting to increase the number of stages to find the saturation point. However, this is not possible due to hardware limitations. We leave this for future work.</p>
</div>
</section>
<section id="S7.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.6 </span>Attention Model Experiment</h3>

<div id="S7.SS6.p1" class="ltx_para">
<p id="S7.SS6.p1.1" class="ltx_p">In this section, we provide additional results to evaluate our attention model. Same as in Sec. 5.6 in our paper, we plot attention maps over the real-world image. We show attention maps after each stage in Fig.Â <a href="#S7.F6" title="Figure 6 â€£ 7.7 Iterative Refinement Qualitative Experiment â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, Fig.Â <a href="#S7.F7" title="Figure 7 â€£ 7.7 Iterative Refinement Qualitative Experiment â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, Fig.Â <a href="#S7.F8" title="Figure 8 â€£ 7.7 Iterative Refinement Qualitative Experiment â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. Here we confirm that the attention focuses on the object outline while avoiding the occlusions. Furthermore, the attention isolates more specific details in the later stages. We confirm our conclusion from Sec. 5.6 in the paper on the larger set of test images.</p>
</div>
</section>
<section id="S7.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.7 </span>Iterative Refinement Qualitative Experiment</h3>

<div id="S7.SS7.p1" class="ltx_para">
<p id="S7.SS7.p1.1" class="ltx_p">In this experiment, we provide a qualitative evaluation of our refiner. On a set of different examples, we show the initial 6D pose estimation and the predicted 6D pose after each stage of our model. We illustrate the poses in Fig.Â <a href="#S7.F9" title="Figure 9 â€£ 7.7 Iterative Refinement Qualitative Experiment â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and Fig.Â <a href="#S7.F10" title="Figure 10 â€£ 7.7 Iterative Refinement Qualitative Experiment â€£ 7 Appendix â€£ Spatial Attention Improves Iterative 6D Object Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> by plotting the outline of the object at the predicted pose. We can notice that initial outlines are not matching the real object outlines. After each stage iteration, the outlines of the objects are closer and closer to the real object outlines. This experiment confirms the numerical results presented in the paper.</p>
</div>
<figure id="S7.F6" class="ltx_figure"><img src="/html/2101.01659/assets/figures/fig_1_sup.png" id="S7.F6.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="548" height="850" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>We overlay the attention map on the input image to indicate the regions that the attention model extracts. We plot the attention map after each stage of our model. The attention focuses on discriminative details and avoids occlusions. In later stages of the network, the attention isolates increasingly specific features. </figcaption>
</figure>
<figure id="S7.F7" class="ltx_figure"><img src="/html/2101.01659/assets/figures/fig_2_sup.png" id="S7.F7.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="548" height="849" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>We overlay the attention map on the input image to indicate the regions that the attention model extracts. We plot the attention map after each stage of our model. The attention focuses on discriminative details and avoids occlusions. In later stages of the network, the attention isolates increasingly specific features. </figcaption>
</figure>
<figure id="S7.F8" class="ltx_figure"><img src="/html/2101.01659/assets/figures/fig_3_sup.png" id="S7.F8.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="548" height="851" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>We overlay the attention map on the input image to indicate the regions that the attention model extracts. We plot the attention map after each stage of our model. The attention focuses on discriminative details and avoids occlusions. In later stages of the network, the attention isolates increasingly specific features. </figcaption>
</figure>
<figure id="S7.F9" class="ltx_figure"><img src="/html/2101.01659/assets/figures/fig_4_sup.png" id="S7.F9.g1" class="ltx_graphics ltx_centering ltx_img_square" width="617" height="763" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Iterative refinement results. For initialization, we use PVNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. The red object outlines show the initial poses. The green outlines indicate the pose obtained via our refiner. We show the pose obtained after each step of the refiner. Notice that after each iteration, the rendered outline is closer to the real object outline.
</figcaption>
</figure>
<figure id="S7.F10" class="ltx_figure"><img src="/html/2101.01659/assets/figures/fig_5_sup.png" id="S7.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="617" height="764" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Iterative refinement results. For initialization, we use PVNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. The red object outlines show the initial poses. The green outlines indicate the pose obtained via our refiner. We show the pose obtained after each step of the refiner. Notice that after each iteration, the rendered outline is closer to the real object outline.
</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2101.01657" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2101.01659" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2101.01659">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2101.01659" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2101.01660" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 11:05:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
