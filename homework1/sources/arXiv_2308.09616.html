<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2308.09616] Far3D: Expanding the Horizon for Surround-view 3D Object Detection</title><meta property="og:description" content="Recently 3D object detection from surround-view images has made notable advancements with its low deployment cost. However, most works have primarily focused on close perception range while leaving long-range detectionâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Far3D: Expanding the Horizon for Surround-view 3D Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Far3D: Expanding the Horizon for Surround-view 3D Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2308.09616">

<!--Generated on Wed Feb 28 10:18:23 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Far3D: Expanding the Horizon for Surround-view 3D Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Xiaohui Jiang <sup id="id9.9.id1" class="ltx_sup"><span id="id9.9.id1.1" class="ltx_text ltx_font_italic">âˆ—1â€ </span></sup> Â Â Â  Shuailin Li <sup id="id10.10.id2" class="ltx_sup"><span id="id10.10.id2.1" class="ltx_text ltx_font_italic">âˆ—2</span></sup> Â Â Â  Yingfei Liu<sup id="id11.11.id3" class="ltx_sup">2</sup> Â Â Â  Shihao Wang<sup id="id12.12.id4" class="ltx_sup"><span id="id12.12.id4.1" class="ltx_text ltx_font_italic">1â€ </span></sup> Â Â Â  Fan Jia<sup id="id13.13.id5" class="ltx_sup">2</sup> Â Â Â  Tiancai Wang<sup id="id14.14.id6" class="ltx_sup">2</sup> Â Â Â  Lijin Han<sup id="id15.15.id7" class="ltx_sup"><span id="id15.15.id7.1" class="ltx_text ltx_font_italic">1</span></sup> Â Â Â  Xiangyu Zhang<sup id="id16.16.id8" class="ltx_sup">2</sup> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id17.id1" class="ltx_p">Recently 3D object detection from surround-view images has made notable advancements with its low deployment cost. However, most works have primarily focused on close perception range while leaving long-range detection less explored.
Expanding existing methods directly to cover long distances poses challenges such as heavy computation costs and unstable convergence.
To address these limitations, this paper proposes a novel sparse query-based framework, dubbed Far3D. By utilizing high-quality 2D object priors, we generate 3D adaptive queries that complement the 3D global queries.
To efficiently capture discriminative features across different views and scales for long-range objects, we introduce a perspective-aware aggregation module. Additionally, we propose a range-modulated 3D denoising approach to address query error propagation and mitigate convergence issues in long-range tasks.
Significantly, Far3D demonstrates SoTA performance on the challenging Argoverse 2 dataset, covering a wide range of 150 meters, surpassing several LiDAR-based approaches.
The code is available at https://github.com/megvii-research/Far3D.
</p>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">footnotetext: </span>* Equal contribution.</span></span></span><span id="footnotex2" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">footnotetext: </span><math id="footnotex2.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="footnotex2.m1.1b"><mo id="footnotex2.m1.1.1" xref="footnotex2.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="footnotex2.m1.1c"><ci id="footnotex2.m1.1.1.cmml" xref="footnotex2.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="footnotex2.m1.1d">\dagger</annotation></semantics></math> Work done during the internship at MEGVII Technology. </span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">3D object detection plays an important role in understanding 3D scenes for autonomous driving, aiming to provide accurate object localization and category around the ego vehicle. Surround-view methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Huang and Huang <a href="#bib.bib9" title="" class="ltx_ref">2022</a>; Li etÂ al. <a href="#bib.bib15" title="" class="ltx_ref">2023</a>; Liu etÂ al. <a href="#bib.bib23" title="" class="ltx_ref">2022b</a>; Li etÂ al. <a href="#bib.bib16" title="" class="ltx_ref">2022c</a>; Yang etÂ al. <a href="#bib.bib37" title="" class="ltx_ref">2023</a>; Park etÂ al. <a href="#bib.bib25" title="" class="ltx_ref">2022</a>; Wang etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023a</a>)</cite>,
with their advantages of low cost and wide applicability, have achieved remarkable progress.
However, most of them focus on close-range perception (e.g., <math id="S1.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p1.1.m1.1a"><mo id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><csymbol cd="latexml" id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">\sim</annotation></semantics></math>50 meters on nuScenesÂ <cite class="ltx_cite ltx_citemacro_citep">(Caesar etÂ al. <a href="#bib.bib1" title="" class="ltx_ref">2020</a>)</cite>), leaving the long-range detection field less explored. Detecting distant objects is essential for real-world driving to maintain a safe distance, especially at high speeds or complex road conditions.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2308.09616/assets/figures/intro1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="342" height="283" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Peformance comparisons on Argoverse 2 between 3D detection and 2D detection. (a) and (b) demonstrate predicted boxes of StreamPETR and YOLOX, respectively. (c) imply that 2D recall is notably better than 3D recall and can act as a bridge to achieve high-quality 3D detection. Note that 2D recall does not represent 3D upper bound due to different recall criteria.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Existing surround-view methods can be broadly categorized into two groups based on the intermediate representation, dense Birdâ€™s-Eye-ViewÂ (BEV) based methods and sparse query-based methods. BEV based methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Huang etÂ al. <a href="#bib.bib10" title="" class="ltx_ref">2021</a>; Huang and Huang <a href="#bib.bib9" title="" class="ltx_ref">2022</a>; Li etÂ al. <a href="#bib.bib15" title="" class="ltx_ref">2023</a>, <a href="#bib.bib16" title="" class="ltx_ref">2022c</a>; Yang etÂ al. <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite> usually convert perspective features to BEV features by employing a view transformerÂ <cite class="ltx_cite ltx_citemacro_citep">(Philion and Fidler <a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite>, then utilizing a 3D detector head to produce the 3D bounding boxes. However, dense BEV features come at the cost of high computation even for the close-range perception, making it more difficult to scale up to long-range perception.
Instead, following DETRÂ <cite class="ltx_cite ltx_citemacro_citep">(Carion etÂ al. <a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite> style, sparse query-based methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib33" title="" class="ltx_ref">2022</a>; Liu etÂ al. <a href="#bib.bib22" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib23" title="" class="ltx_ref">b</a>; Wang etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023a</a>)</cite> adopt learnable global queries to represent 3D objects, and interact with surround-view image features to update queries.
Although sparse design can avoid the squared growth of query numbers, its global fixed queries cannot adapt to dynamic scenarios and usually miss targets in long-range detection.
We adopt the sparse query design to maintain detection efficiency and introduce 3D adaptive queries to address the inflexibility weaknesses.
</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To employ the sparse query-based paradigm for long-range detection, the primary challenge lies in poor recall performance. Due to the query sparsity in 3D space, assignments between predictions and ground-truth objects are affected, generating only a small amount of matched positive queries.
As illustrated in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, 3D detector recalls are pretty low, yet recalls from the existing 2D detector are much higher, showing a significant performance gap between them. Motivated by this, leveraging high-quality 2D object priors to improve 3D proposals is a promising approach, for enabling accurate localization and comprehensive coverage. Although previous methods like SimMODÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al. <a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite> and MV2DÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib34" title="" class="ltx_ref">2023b</a>)</cite> have explored using 2D predictions to initialize 3D object proposals, they primarily focus on close-range tasks and discard learnable object queries.
Moreover, as depicted in Fig.Â <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, directly introducing 3D queries derived from 2D proposals for long-range tasks encounters two issues: 1) inferior redundant predictions due to uncertain depth distribution along the object rays, and 2) larger deviations in 3D space as the range increases due to frustum transformation. These noisy queries can impact the training stability, requiring effective denoising ways to optimize. Furthermore, within the training process, the model exhibits a tendency to overfit on densely populated close objects while disregarding sparsely distributed distant objects.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2308.09616/assets/x1.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="182" height="75" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Different cases of transformimg 2D points into 3D space. The blue dots indicate the centers of 3D objects in images. (a) shows the redundant prediction with the wrong depth, which is in yellow. (b) illustrates the error propagation problem dominated by different ranges.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To address the aforementioned challenges, we design a novel 3D detection paradigm to expand the perception horizon. Despite the 3D global query that was learned from the dataset, our approach also incorporates auxiliary 2D proposals into 3D adaptive query generation.
Specifically, we first produce reliable pairs of 2D object proposals and corresponding depths then project them to 3D proposals via spatial transformation. We compose 3D adaptive queries with the projected positional embedding and semantic context, which would be refined in the subsequent decoder.
In the decoder layers, perspective-aware aggregation is employed across different image scales and views. It learns sampling offsets for each query and dynamically enables interactions with favorable features. For instance, distant object queries are beneficial to attend large-resolution features, while the opposite is better for close objects in order to capture high-level context.
Lastly, we design a range-modulated 3D denoising technique to mitigate query error propagation and slow convergence. Considering the different regression difficulties for various ranges, noisy queries are constructed based on ground-truth (GT) as well as referring to their distances and scales. Our method feeds multi-group noisy proposals around GT into the decoder and trains the model to a) recover 3D GT for positive ones and b) reject negative ones, respectively. The inclusion of query denoising also alleviates the problem of range-level unbalanced distribution.
</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Our proposed method achieves remarkable performance advancements over state-of-the-art (SoTA) approaches in the challenging long-range Argoverse 2 dataset, as well as surpassing the prior arts of LiDAR-based methods. To evaluate the generalization capability, we further validate its results on nuScenes dataset and demonstrate SoTA metrics.
</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In summary, our contributions are:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose a novel sparse query-based framework to expand the perception range in 3D detection, by incorporating high-quality 2D object priors into 3D adaptive queries.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We develop perspective-aware aggregation that captures informative features from diverse scales and views, as well as a range-modulated 3D denoising technique to address query error propagation and convergence problems.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">On the challenging long-range Argoverse 2 datasets, our method surpasses surround-view methods and
outperforms several LiDAR-based methods. The generalization of our method is validated on the nuScenes dataset.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Surround-view 3D Object Detection</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Recently 3D object detection from surround-view images has attracted much attention and achieved great progress, due to its advantages of low deployment cost and rich semantic information.
Based on feature representation, existing methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib32" title="" class="ltx_ref">2021</a>, <a href="#bib.bib33" title="" class="ltx_ref">2022</a>; Liu etÂ al. <a href="#bib.bib22" title="" class="ltx_ref">2022a</a>; Huang and Huang <a href="#bib.bib9" title="" class="ltx_ref">2022</a>; Li etÂ al. <a href="#bib.bib15" title="" class="ltx_ref">2023</a>, <a href="#bib.bib14" title="" class="ltx_ref">2022b</a>; Jiang etÂ al. <a href="#bib.bib11" title="" class="ltx_ref">2023</a>; Liu etÂ al. <a href="#bib.bib23" title="" class="ltx_ref">2022b</a>; Li etÂ al. <a href="#bib.bib16" title="" class="ltx_ref">2022c</a>; Yang etÂ al. <a href="#bib.bib37" title="" class="ltx_ref">2023</a>; Park etÂ al. <a href="#bib.bib25" title="" class="ltx_ref">2022</a>; Wang etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023a</a>; Zong etÂ al. <a href="#bib.bib42" title="" class="ltx_ref">2023</a>; Liu etÂ al. <a href="#bib.bib21" title="" class="ltx_ref">2023</a>)</cite> can be largely classified into BEV-based methods and sparse-query based methods.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2308.09616/assets/x2.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="371" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The overview of our proposed Far3D.
Feeding surround-view images into the backbone and FPN neck, we obtain 2D image features and encode them with camera parameters for perspective-aware transformation.
Utilizing a 2D detector and DepthNet, we generate reliable 2D box proposals and their corresponding depths, which are then concatenated and projected into 3D space.
The generated 3D adaptive queries, combined with the initial 3D global queries, are iteratively refined by the decoder layers to predict 3D bounding boxes. Furthermore, temporal modeling is equipped through long-term query propagation.
</figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Extracting image features from surround views, BEV-based methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Huang etÂ al. <a href="#bib.bib10" title="" class="ltx_ref">2021</a>; Huang and Huang <a href="#bib.bib9" title="" class="ltx_ref">2022</a>; Li etÂ al. <a href="#bib.bib15" title="" class="ltx_ref">2023</a>, <a href="#bib.bib16" title="" class="ltx_ref">2022c</a>)</cite> transform features into BEV space by leveraging estimated depths or attention layers, then a 3D detector head is employed to predict localization and other properties of 3D objects.
For instance,
BEVFormerÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al. <a href="#bib.bib16" title="" class="ltx_ref">2022c</a>)</cite> leverages both spatial and temporal
features by interacting with spatial and temporal space through predefined grid-shaped BEV queries.
BEVDepthÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al. <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> propose a 3D detector with a trustworthy depth estimation, by introducing a camera-aware depth estimation module.
On the other hand, sparse query-based paradigmsÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib33" title="" class="ltx_ref">2022</a>; Liu etÂ al. <a href="#bib.bib22" title="" class="ltx_ref">2022a</a>)</cite> learn global object queries from the representative data, then feed them into the decoder to predict 3D bounding boxes during inference. This line of work has the advantage of lightweight computing.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Furthermore, temporal modeling for surround-view 3D detection can improve detection performance and decrease velocity errors significantly, and many worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Huang and Huang <a href="#bib.bib9" title="" class="ltx_ref">2022</a>; Liu etÂ al. <a href="#bib.bib23" title="" class="ltx_ref">2022b</a>; Park etÂ al. <a href="#bib.bib25" title="" class="ltx_ref">2022</a>; Wang etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023a</a>; Lin etÂ al. <a href="#bib.bib19" title="" class="ltx_ref">2022</a>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> aim to extend a single-frame framework to multi-frame design.
BEVDet4DÂ <cite class="ltx_cite ltx_citemacro_citep">(Huang and Huang <a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite> lifts the BEVDet paradigm from the spatial-only 3D space to the spatial-temporal 4D space, via fusing features with the previous frame.
PETRv2Â <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al. <a href="#bib.bib23" title="" class="ltx_ref">2022b</a>)</cite> extends the 3D position embedding in PETR for temporal modeling through the temporal alignment of different frames.
However, they use only limited history.
To leverage both short-term and long-term history, SOLOFusionÂ <cite class="ltx_cite ltx_citemacro_citep">(Park etÂ al. <a href="#bib.bib25" title="" class="ltx_ref">2022</a>)</cite> balances the impacts of spatial resolution and temporal difference on localization potential, then use it to design a powerful temporal 3D detector.
StreamPETRÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023a</a>)</cite> develops an object-centric temporal mechanism in an online manner, where long-term historical information is propagated through object queries.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>2D Auxiliary Tasks for 3D Detection</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">3D detection from surround-view images can be improved through 2D auxiliary tasks, and some worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Xie etÂ al. <a href="#bib.bib36" title="" class="ltx_ref">2022</a>; Zhang etÂ al. <a href="#bib.bib40" title="" class="ltx_ref">2023</a>; Wang, Jiang, and Li <a href="#bib.bib30" title="" class="ltx_ref">2022</a>; Yang etÂ al. <a href="#bib.bib37" title="" class="ltx_ref">2023</a>; Wang etÂ al. <a href="#bib.bib34" title="" class="ltx_ref">2023b</a>)</cite> aim to exploit its potential. There are several approaches including 2D pertaining, auxiliary supervision, and proposal generation.
SimMODÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al. <a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite> exploits sample-wise object proposals and designs a two-stage training manner, where perspective object proposals are generated and followed by iterative refinement in DETR3D-style.
Focal-PETRÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang, Jiang, and Li <a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite> performs 2D object supervision to adaptively focus the attention of 3D queries on discriminative foreground regions.
BEVFormerV2Â <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al. <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite> presents a two-stage BEV detector where perspective proposals are fed into the BEV head for final predictions.
MV2DÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib34" title="" class="ltx_ref">2023b</a>)</cite> designs a 3D detector head that is initialized by RoI regions of 2D predicted proposals.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Compared to the above methods, our framework differs in the following aspects. Firstly, we aim to resolve the challenges of long-range detection with surrounding views, which are less explored in previous methods.
Besides learning 3D global queries, we explicitly leverage 2D predicted boxes and depths to build 3D adaptive queries, utilizing positional prior and semantic context simultaneously. Furthermore, the designs of perspective-aware aggregation and 3D denoising are integrated to address task issues.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Overview</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.2" class="ltx_p">Fig.Â <a href="#S2.F3" title="Figure 3 â€£ 2.1 Surround-view 3D Object Detection â€£ 2 Related Work â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the overall pipeline of our sparse query-based framework.
Feeding surround-view images <math id="S3.SS1.p1.1.m1.3" class="ltx_Math" alttext="\mathbf{I}=\{\mathbf{I^{1},...,I^{n}}\}" display="inline"><semantics id="S3.SS1.p1.1.m1.3a"><mrow id="S3.SS1.p1.1.m1.3.3" xref="S3.SS1.p1.1.m1.3.3.cmml"><mi id="S3.SS1.p1.1.m1.3.3.4" xref="S3.SS1.p1.1.m1.3.3.4.cmml">ğˆ</mi><mo id="S3.SS1.p1.1.m1.3.3.3" xref="S3.SS1.p1.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.3.3.2.2" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.3.3.2.2.3" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">{</mo><msup id="S3.SS1.p1.1.m1.2.2.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml">ğˆ</mi><mn id="S3.SS1.p1.1.m1.2.2.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.cmml">ğŸ</mn></msup><mo id="S3.SS1.p1.1.m1.3.3.2.2.4" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">â€¦</mi><mo id="S3.SS1.p1.1.m1.3.3.2.2.5" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">,</mo><msup id="S3.SS1.p1.1.m1.3.3.2.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.1.m1.3.3.2.2.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml">ğˆ</mi><mi id="S3.SS1.p1.1.m1.3.3.2.2.2.3" xref="S3.SS1.p1.1.m1.3.3.2.2.2.3.cmml">ğ§</mi></msup><mo stretchy="false" id="S3.SS1.p1.1.m1.3.3.2.2.6" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.3b"><apply id="S3.SS1.p1.1.m1.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3"><eq id="S3.SS1.p1.1.m1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3.3"></eq><ci id="S3.SS1.p1.1.m1.3.3.4.cmml" xref="S3.SS1.p1.1.m1.3.3.4">ğˆ</ci><set id="S3.SS1.p1.1.m1.3.3.2.3.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2"><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1">superscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2">ğˆ</ci><cn type="integer" id="S3.SS1.p1.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">â€¦</ci><apply id="S3.SS1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2">superscript</csymbol><ci id="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2">ğˆ</ci><ci id="S3.SS1.p1.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.3">ğ§</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.3c">\mathbf{I}=\{\mathbf{I^{1},...,I^{n}}\}</annotation></semantics></math>, we extract multi-level images features <math id="S3.SS1.p1.2.m2.3" class="ltx_Math" alttext="\mathbf{F}=\{\mathbf{F^{1},...,F^{n}}\}" display="inline"><semantics id="S3.SS1.p1.2.m2.3a"><mrow id="S3.SS1.p1.2.m2.3.3" xref="S3.SS1.p1.2.m2.3.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.4" xref="S3.SS1.p1.2.m2.3.3.4.cmml">ğ…</mi><mo id="S3.SS1.p1.2.m2.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.cmml">=</mo><mrow id="S3.SS1.p1.2.m2.3.3.2.2" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.2.2.3" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml">{</mo><msup id="S3.SS1.p1.2.m2.2.2.1.1.1" xref="S3.SS1.p1.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.2.2.1.1.1.2" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.cmml">ğ…</mi><mn id="S3.SS1.p1.2.m2.2.2.1.1.1.3" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml">ğŸ</mn></msup><mo id="S3.SS1.p1.2.m2.3.3.2.2.4" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">â€¦</mi><mo id="S3.SS1.p1.2.m2.3.3.2.2.5" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml">,</mo><msup id="S3.SS1.p1.2.m2.3.3.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.2.m2.3.3.2.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.cmml">ğ…</mi><mi id="S3.SS1.p1.2.m2.3.3.2.2.2.3" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml">ğ§</mi></msup><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.2.2.6" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.3b"><apply id="S3.SS1.p1.2.m2.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3"><eq id="S3.SS1.p1.2.m2.3.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.3"></eq><ci id="S3.SS1.p1.2.m2.3.3.4.cmml" xref="S3.SS1.p1.2.m2.3.3.4">ğ…</ci><set id="S3.SS1.p1.2.m2.3.3.2.3.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2"><apply id="S3.SS1.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1">superscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2">ğ…</ci><cn type="integer" id="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">â€¦</ci><apply id="S3.SS1.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2">superscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2">ğ…</ci><ci id="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3">ğ§</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.3c">\mathbf{F}=\{\mathbf{F^{1},...,F^{n}}\}</annotation></semantics></math> by using the backbone networkÂ (e.g. ResNet, ViT) and a FPNÂ <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al. <a href="#bib.bib17" title="" class="ltx_ref">2017</a>)</cite> neck.
To generate 3D adaptive queries, we first obtain 2D proposals and depths using a 2D detector head and depth network, then filter reliable ones and transform them into 3D space to generate 3D object queries. In this way, informative object priors from 2D detections are encoded into the 3D adaptive queries.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In the 3D detector head, we concatenate 3D adaptive queries and 3D global queries, then input them to transformer decoder layers including self-attention among queries and perspective-aware aggregation between queries and features. We propose perspective-aware aggregation to efficiently capture rich features in multiple views and scales by considering the projection of 3D objects. Besides, range-modulated 3D denoising is introduced to alleviate query error propagation and stabilize the convergence, when training with long-range and imbalanced distributed objects. SecÂ <a href="#S3.SS4" title="3.4 Range-modulated 3D Denoising â€£ 3 Method â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a> depicts the denoising technique in detail.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Adaptive Query Generation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Directly extend existing 3D detectors from short range (e.g. ~50m) to long range (e.g. ~150m) suffers from several problems: heavy computation costs, inefficient convergence and declining localization ability. For instance, the query number is supposed to grow at least squarely to cover possible objects in a larger range, yet such a computing disaster is unacceptable in realistic scenarios. Besides that, small and sparse distant objects would hinder the convergence and even hurt the localization of close objects.
Motivated by the high performance of 2D proposals, we propose to generate adaptive queries as objects prior to assist 3D localization. This paradigm compensates for the weakness of global fixed query design and allows the detector to generate adaptive queries near the ground-truth (GT) boxes for different images. In this way, the model is equipped with better generalization and practicality.
</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.5" class="ltx_p">Specifically, given image features after FPN neck, we feed them into the anchor-free detector head from YOLOXÂ <cite class="ltx_cite ltx_citemacro_citep">(Ge etÂ al. <a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite> and a light-weighted depth estimation net, outputting 2D box coordinates, scores and depth map.
2D detector head follows the original design, while the depth estimation is regarded as a classification task by discretizing the depth into binsÂ <cite class="ltx_cite ltx_citemacro_citep">(Reading etÂ al. <a href="#bib.bib27" title="" class="ltx_ref">2021</a>; Zhang etÂ al. <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>.
We then make pairs of 2D boxes and corresponding depths. To avoid the interference of low-quality proposals, we set a score threshold <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\tau</annotation></semantics></math>Â (e.g. 0.1) to leave only reliable ones. For each view <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">i</annotation></semantics></math>, box centers <math id="S3.SS2.p2.3.m3.2" class="ltx_Math" alttext="(\mathbf{c}_{w},\mathbf{c}_{h})" display="inline"><semantics id="S3.SS2.p2.3.m3.2a"><mrow id="S3.SS2.p2.3.m3.2.2.2" xref="S3.SS2.p2.3.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.p2.3.m3.2.2.2.3" xref="S3.SS2.p2.3.m3.2.2.3.cmml">(</mo><msub id="S3.SS2.p2.3.m3.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.2.cmml">ğœ</mi><mi id="S3.SS2.p2.3.m3.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.3.cmml">w</mi></msub><mo id="S3.SS2.p2.3.m3.2.2.2.4" xref="S3.SS2.p2.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS2.p2.3.m3.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.cmml"><mi id="S3.SS2.p2.3.m3.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.cmml">ğœ</mi><mi id="S3.SS2.p2.3.m3.2.2.2.2.3" xref="S3.SS2.p2.3.m3.2.2.2.2.3.cmml">h</mi></msub><mo stretchy="false" id="S3.SS2.p2.3.m3.2.2.2.5" xref="S3.SS2.p2.3.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.2b"><interval closure="open" id="S3.SS2.p2.3.m3.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2"><apply id="S3.SS2.p2.3.m3.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.2">ğœ</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.3">ğ‘¤</ci></apply><apply id="S3.SS2.p2.3.m3.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.2.2.2.2.1.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2">ğœ</ci><ci id="S3.SS2.p2.3.m3.2.2.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.3">â„</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.2c">(\mathbf{c}_{w},\mathbf{c}_{h})</annotation></semantics></math> from 2D predictions and depth <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{d}_{wh}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><msub id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">ğ</mi><mrow id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml"><mi id="S3.SS2.p2.4.m4.1.1.3.2" xref="S3.SS2.p2.4.m4.1.1.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.4.m4.1.1.3.1" xref="S3.SS2.p2.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.4.m4.1.1.3.3" xref="S3.SS2.p2.4.m4.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ğ</ci><apply id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3"><times id="S3.SS2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.1"></times><ci id="S3.SS2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2">ğ‘¤</ci><ci id="S3.SS2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\mathbf{d}_{wh}</annotation></semantics></math> from depth map are combined and projected to 3D proposal centers <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{c}_{3d}" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><msub id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">ğœ</mi><mrow id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml"><mn id="S3.SS2.p2.5.m5.1.1.3.2" xref="S3.SS2.p2.5.m5.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p2.5.m5.1.1.3.1" xref="S3.SS2.p2.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.5.m5.1.1.3.3" xref="S3.SS2.p2.5.m5.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">ğœ</ci><apply id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3"><times id="S3.SS2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.1"></times><cn type="integer" id="S3.SS2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2">3</cn><ci id="S3.SS2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">\mathbf{c}_{3d}</annotation></semantics></math>.</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="\mathbf{c_{3d}}=\mathit{K_{i}^{-1}I_{i}^{-1}}[\mathbf{c}_{w}*\mathbf{d}_{wh},\mathbf{c}_{h}*\mathbf{d}_{wh},\mathbf{d}_{wh},\mathbf{1}]^{T}" display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml"><msub id="S3.E1.m1.4.4.5" xref="S3.E1.m1.4.4.5.cmml"><mi id="S3.E1.m1.4.4.5.2" xref="S3.E1.m1.4.4.5.2.cmml">ğœ</mi><mrow id="S3.E1.m1.4.4.5.3" xref="S3.E1.m1.4.4.5.3.cmml"><mn id="S3.E1.m1.4.4.5.3.2" xref="S3.E1.m1.4.4.5.3.2.cmml">ğŸ‘</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.5.3.1" xref="S3.E1.m1.4.4.5.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.4.4.5.3.3" xref="S3.E1.m1.4.4.5.3.3.cmml">ğ</mi></mrow></msub><mo id="S3.E1.m1.4.4.4" xref="S3.E1.m1.4.4.4.cmml">=</mo><mrow id="S3.E1.m1.4.4.3" xref="S3.E1.m1.4.4.3.cmml"><msubsup id="S3.E1.m1.4.4.3.5" xref="S3.E1.m1.4.4.3.5.cmml"><mi id="S3.E1.m1.4.4.3.5.2.2" xref="S3.E1.m1.4.4.3.5.2.2.cmml">K</mi><mi id="S3.E1.m1.4.4.3.5.2.3" xref="S3.E1.m1.4.4.3.5.2.3.cmml">i</mi><mrow id="S3.E1.m1.4.4.3.5.3" xref="S3.E1.m1.4.4.3.5.3.cmml"><mo id="S3.E1.m1.4.4.3.5.3a" xref="S3.E1.m1.4.4.3.5.3.cmml">âˆ’</mo><mn class="ltx_mathvariant_italic" mathvariant="italic" id="S3.E1.m1.4.4.3.5.3.2" xref="S3.E1.m1.4.4.3.5.3.2.cmml">1</mn></mrow></msubsup><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.3.4" xref="S3.E1.m1.4.4.3.4.cmml">â€‹</mo><msubsup id="S3.E1.m1.4.4.3.6" xref="S3.E1.m1.4.4.3.6.cmml"><mi id="S3.E1.m1.4.4.3.6.2.2" xref="S3.E1.m1.4.4.3.6.2.2.cmml">I</mi><mi id="S3.E1.m1.4.4.3.6.2.3" xref="S3.E1.m1.4.4.3.6.2.3.cmml">i</mi><mrow id="S3.E1.m1.4.4.3.6.3" xref="S3.E1.m1.4.4.3.6.3.cmml"><mo id="S3.E1.m1.4.4.3.6.3a" xref="S3.E1.m1.4.4.3.6.3.cmml">âˆ’</mo><mn class="ltx_mathvariant_italic" mathvariant="italic" id="S3.E1.m1.4.4.3.6.3.2" xref="S3.E1.m1.4.4.3.6.3.2.cmml">1</mn></mrow></msubsup><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.3.4a" xref="S3.E1.m1.4.4.3.4.cmml">â€‹</mo><msup id="S3.E1.m1.4.4.3.3" xref="S3.E1.m1.4.4.3.3.cmml"><mrow id="S3.E1.m1.4.4.3.3.3.3" xref="S3.E1.m1.4.4.3.3.3.4.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.3.3.3.3.4" xref="S3.E1.m1.4.4.3.3.3.4.cmml">[</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.cmml"><msub id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.cmml">ğœ</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.cmml">w</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.2.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml">âˆ—</mo><msub id="S3.E1.m1.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.cmml">ğ</mi><mrow id="S3.E1.m1.2.2.1.1.1.1.1.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.3.3.1" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.cmml">h</mi></mrow></msub></mrow><mo id="S3.E1.m1.4.4.3.3.3.3.5" xref="S3.E1.m1.4.4.3.3.3.4.cmml">,</mo><mrow id="S3.E1.m1.3.3.2.2.2.2.2" xref="S3.E1.m1.3.3.2.2.2.2.2.cmml"><msub id="S3.E1.m1.3.3.2.2.2.2.2.2" xref="S3.E1.m1.3.3.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.3.3.2.2.2.2.2.2.2" xref="S3.E1.m1.3.3.2.2.2.2.2.2.2.cmml">ğœ</mi><mi id="S3.E1.m1.3.3.2.2.2.2.2.2.3" xref="S3.E1.m1.3.3.2.2.2.2.2.2.3.cmml">h</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.3.3.2.2.2.2.2.1" xref="S3.E1.m1.3.3.2.2.2.2.2.1.cmml">âˆ—</mo><msub id="S3.E1.m1.3.3.2.2.2.2.2.3" xref="S3.E1.m1.3.3.2.2.2.2.2.3.cmml"><mi id="S3.E1.m1.3.3.2.2.2.2.2.3.2" xref="S3.E1.m1.3.3.2.2.2.2.2.3.2.cmml">ğ</mi><mrow id="S3.E1.m1.3.3.2.2.2.2.2.3.3" xref="S3.E1.m1.3.3.2.2.2.2.2.3.3.cmml"><mi id="S3.E1.m1.3.3.2.2.2.2.2.3.3.2" xref="S3.E1.m1.3.3.2.2.2.2.2.3.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.2.2.2.2.2.3.3.1" xref="S3.E1.m1.3.3.2.2.2.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.2.2.2.2.2.3.3.3" xref="S3.E1.m1.3.3.2.2.2.2.2.3.3.3.cmml">h</mi></mrow></msub></mrow><mo id="S3.E1.m1.4.4.3.3.3.3.6" xref="S3.E1.m1.4.4.3.3.3.4.cmml">,</mo><msub id="S3.E1.m1.4.4.3.3.3.3.3" xref="S3.E1.m1.4.4.3.3.3.3.3.cmml"><mi id="S3.E1.m1.4.4.3.3.3.3.3.2" xref="S3.E1.m1.4.4.3.3.3.3.3.2.cmml">ğ</mi><mrow id="S3.E1.m1.4.4.3.3.3.3.3.3" xref="S3.E1.m1.4.4.3.3.3.3.3.3.cmml"><mi id="S3.E1.m1.4.4.3.3.3.3.3.3.2" xref="S3.E1.m1.4.4.3.3.3.3.3.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.3.3.3.3.3.3.1" xref="S3.E1.m1.4.4.3.3.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.4.4.3.3.3.3.3.3.3" xref="S3.E1.m1.4.4.3.3.3.3.3.3.3.cmml">h</mi></mrow></msub><mo id="S3.E1.m1.4.4.3.3.3.3.7" xref="S3.E1.m1.4.4.3.3.3.4.cmml">,</mo><mn id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">ğŸ</mn><mo stretchy="false" id="S3.E1.m1.4.4.3.3.3.3.8" xref="S3.E1.m1.4.4.3.3.3.4.cmml">]</mo></mrow><mi id="S3.E1.m1.4.4.3.3.5" xref="S3.E1.m1.4.4.3.3.5.cmml">T</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4"><eq id="S3.E1.m1.4.4.4.cmml" xref="S3.E1.m1.4.4.4"></eq><apply id="S3.E1.m1.4.4.5.cmml" xref="S3.E1.m1.4.4.5"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.5.1.cmml" xref="S3.E1.m1.4.4.5">subscript</csymbol><ci id="S3.E1.m1.4.4.5.2.cmml" xref="S3.E1.m1.4.4.5.2">ğœ</ci><apply id="S3.E1.m1.4.4.5.3.cmml" xref="S3.E1.m1.4.4.5.3"><times id="S3.E1.m1.4.4.5.3.1.cmml" xref="S3.E1.m1.4.4.5.3.1"></times><cn type="integer" id="S3.E1.m1.4.4.5.3.2.cmml" xref="S3.E1.m1.4.4.5.3.2">3</cn><ci id="S3.E1.m1.4.4.5.3.3.cmml" xref="S3.E1.m1.4.4.5.3.3">ğ</ci></apply></apply><apply id="S3.E1.m1.4.4.3.cmml" xref="S3.E1.m1.4.4.3"><times id="S3.E1.m1.4.4.3.4.cmml" xref="S3.E1.m1.4.4.3.4"></times><apply id="S3.E1.m1.4.4.3.5.cmml" xref="S3.E1.m1.4.4.3.5"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.5.1.cmml" xref="S3.E1.m1.4.4.3.5">superscript</csymbol><apply id="S3.E1.m1.4.4.3.5.2.cmml" xref="S3.E1.m1.4.4.3.5"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.5.2.1.cmml" xref="S3.E1.m1.4.4.3.5">subscript</csymbol><ci id="S3.E1.m1.4.4.3.5.2.2.cmml" xref="S3.E1.m1.4.4.3.5.2.2">ğ¾</ci><ci id="S3.E1.m1.4.4.3.5.2.3.cmml" xref="S3.E1.m1.4.4.3.5.2.3">ğ‘–</ci></apply><apply id="S3.E1.m1.4.4.3.5.3.cmml" xref="S3.E1.m1.4.4.3.5.3"><minus id="S3.E1.m1.4.4.3.5.3.1.cmml" xref="S3.E1.m1.4.4.3.5.3"></minus><cn type="integer" id="S3.E1.m1.4.4.3.5.3.2.cmml" xref="S3.E1.m1.4.4.3.5.3.2">1</cn></apply></apply><apply id="S3.E1.m1.4.4.3.6.cmml" xref="S3.E1.m1.4.4.3.6"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.6.1.cmml" xref="S3.E1.m1.4.4.3.6">superscript</csymbol><apply id="S3.E1.m1.4.4.3.6.2.cmml" xref="S3.E1.m1.4.4.3.6"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.6.2.1.cmml" xref="S3.E1.m1.4.4.3.6">subscript</csymbol><ci id="S3.E1.m1.4.4.3.6.2.2.cmml" xref="S3.E1.m1.4.4.3.6.2.2">ğ¼</ci><ci id="S3.E1.m1.4.4.3.6.2.3.cmml" xref="S3.E1.m1.4.4.3.6.2.3">ğ‘–</ci></apply><apply id="S3.E1.m1.4.4.3.6.3.cmml" xref="S3.E1.m1.4.4.3.6.3"><minus id="S3.E1.m1.4.4.3.6.3.1.cmml" xref="S3.E1.m1.4.4.3.6.3"></minus><cn type="integer" id="S3.E1.m1.4.4.3.6.3.2.cmml" xref="S3.E1.m1.4.4.3.6.3.2">1</cn></apply></apply><apply id="S3.E1.m1.4.4.3.3.cmml" xref="S3.E1.m1.4.4.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.3.4.cmml" xref="S3.E1.m1.4.4.3.3">superscript</csymbol><list id="S3.E1.m1.4.4.3.3.3.4.cmml" xref="S3.E1.m1.4.4.3.3.3.3"><apply id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1"></times><apply id="S3.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2">ğœ</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3">ğ‘¤</ci></apply><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2">ğ</ci><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3"><times id="S3.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.1"></times><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.2">ğ‘¤</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.3">â„</ci></apply></apply></apply><apply id="S3.E1.m1.3.3.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2"><times id="S3.E1.m1.3.3.2.2.2.2.2.1.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.1"></times><apply id="S3.E1.m1.3.3.2.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.2.2">ğœ</ci><ci id="S3.E1.m1.3.3.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.2.3">â„</ci></apply><apply id="S3.E1.m1.3.3.2.2.2.2.2.3.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.2.2.2.2.3.1.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.3">subscript</csymbol><ci id="S3.E1.m1.3.3.2.2.2.2.2.3.2.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.3.2">ğ</ci><apply id="S3.E1.m1.3.3.2.2.2.2.2.3.3.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.3.3"><times id="S3.E1.m1.3.3.2.2.2.2.2.3.3.1.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.3.3.1"></times><ci id="S3.E1.m1.3.3.2.2.2.2.2.3.3.2.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.3.3.2">ğ‘¤</ci><ci id="S3.E1.m1.3.3.2.2.2.2.2.3.3.3.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2.3.3.3">â„</ci></apply></apply></apply><apply id="S3.E1.m1.4.4.3.3.3.3.3.cmml" xref="S3.E1.m1.4.4.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.3.3.3.3.1.cmml" xref="S3.E1.m1.4.4.3.3.3.3.3">subscript</csymbol><ci id="S3.E1.m1.4.4.3.3.3.3.3.2.cmml" xref="S3.E1.m1.4.4.3.3.3.3.3.2">ğ</ci><apply id="S3.E1.m1.4.4.3.3.3.3.3.3.cmml" xref="S3.E1.m1.4.4.3.3.3.3.3.3"><times id="S3.E1.m1.4.4.3.3.3.3.3.3.1.cmml" xref="S3.E1.m1.4.4.3.3.3.3.3.3.1"></times><ci id="S3.E1.m1.4.4.3.3.3.3.3.3.2.cmml" xref="S3.E1.m1.4.4.3.3.3.3.3.3.2">ğ‘¤</ci><ci id="S3.E1.m1.4.4.3.3.3.3.3.3.3.cmml" xref="S3.E1.m1.4.4.3.3.3.3.3.3.3">â„</ci></apply></apply><cn type="integer" id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">1</cn></list><ci id="S3.E1.m1.4.4.3.3.5.cmml" xref="S3.E1.m1.4.4.3.3.5">ğ‘‡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">\mathbf{c_{3d}}=\mathit{K_{i}^{-1}I_{i}^{-1}}[\mathbf{c}_{w}*\mathbf{d}_{wh},\mathbf{c}_{h}*\mathbf{d}_{wh},\mathbf{d}_{wh},\mathbf{1}]^{T}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.6" class="ltx_p">where <math id="S3.SS2.p2.6.m1.2" class="ltx_Math" alttext="\mathit{K_{i},I_{i}}" display="inline"><semantics id="S3.SS2.p2.6.m1.2a"><mrow id="S3.SS2.p2.6.m1.2.2.2" xref="S3.SS2.p2.6.m1.2.2.3.cmml"><msub id="S3.SS2.p2.6.m1.1.1.1.1" xref="S3.SS2.p2.6.m1.1.1.1.1.cmml"><mi id="S3.SS2.p2.6.m1.1.1.1.1.2" xref="S3.SS2.p2.6.m1.1.1.1.1.2.cmml">K</mi><mi id="S3.SS2.p2.6.m1.1.1.1.1.3" xref="S3.SS2.p2.6.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p2.6.m1.2.2.2.3" xref="S3.SS2.p2.6.m1.2.2.3.cmml">,</mo><msub id="S3.SS2.p2.6.m1.2.2.2.2" xref="S3.SS2.p2.6.m1.2.2.2.2.cmml"><mi id="S3.SS2.p2.6.m1.2.2.2.2.2" xref="S3.SS2.p2.6.m1.2.2.2.2.2.cmml">I</mi><mi id="S3.SS2.p2.6.m1.2.2.2.2.3" xref="S3.SS2.p2.6.m1.2.2.2.2.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m1.2b"><list id="S3.SS2.p2.6.m1.2.2.3.cmml" xref="S3.SS2.p2.6.m1.2.2.2"><apply id="S3.SS2.p2.6.m1.1.1.1.1.cmml" xref="S3.SS2.p2.6.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m1.1.1.1.1.1.cmml" xref="S3.SS2.p2.6.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.6.m1.1.1.1.1.2.cmml" xref="S3.SS2.p2.6.m1.1.1.1.1.2">ğ¾</ci><ci id="S3.SS2.p2.6.m1.1.1.1.1.3.cmml" xref="S3.SS2.p2.6.m1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.6.m1.2.2.2.2.cmml" xref="S3.SS2.p2.6.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m1.2.2.2.2.1.cmml" xref="S3.SS2.p2.6.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.6.m1.2.2.2.2.2.cmml" xref="S3.SS2.p2.6.m1.2.2.2.2.2">ğ¼</ci><ci id="S3.SS2.p2.6.m1.2.2.2.2.3.cmml" xref="S3.SS2.p2.6.m1.2.2.2.2.3">ğ‘–</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m1.2c">\mathit{K_{i},I_{i}}</annotation></semantics></math> denote camera extrinsic and intrinsic matrices.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.8" class="ltx_p">After obtaining projected 3D proposals, we encode them into 3D adaptive queries as follows,</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\mathbf{Q}_{pos}=\mathit{PosEmbed}(\mathbf{c}_{3d})" display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><msub id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml">ğ</mi><mrow id="S3.E2.m1.1.1.3.3" xref="S3.E2.m1.1.1.3.3.cmml"><mi id="S3.E2.m1.1.1.3.3.2" xref="S3.E2.m1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.3.1" xref="S3.E2.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.1.1.3.3.3" xref="S3.E2.m1.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.3.1a" xref="S3.E2.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.1.1.3.3.4" xref="S3.E2.m1.1.1.3.3.4.cmml">s</mi></mrow></msub><mo id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">ğ‘ƒğ‘œğ‘ ğ¸ğ‘šğ‘ğ‘’ğ‘‘</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml">ğœ</mi><mrow id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml"><mn id="S3.E2.m1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.cmml">d</mi></mrow></msub><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"></eq><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2">ğ</ci><apply id="S3.E2.m1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.3.3"><times id="S3.E2.m1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.3.3.1"></times><ci id="S3.E2.m1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.3.3.2">ğ‘</ci><ci id="S3.E2.m1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.3.3.3">ğ‘œ</ci><ci id="S3.E2.m1.1.1.3.3.4.cmml" xref="S3.E2.m1.1.1.3.3.4">ğ‘ </ci></apply></apply><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">ğ‘ƒğ‘œğ‘ ğ¸ğ‘šğ‘ğ‘’ğ‘‘</ci><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">ğœ</ci><apply id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><times id="S3.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.1"></times><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2">3</cn><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3">ğ‘‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\mathbf{Q}_{pos}=\mathit{PosEmbed}(\mathbf{c}_{3d})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="\mathbf{Q}_{sem}=\mathit{SemEmbed}(\mathbf{z}_{2d},\mathbf{s}_{2d})" display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><msub id="S3.E3.m1.2.2.4" xref="S3.E3.m1.2.2.4.cmml"><mi id="S3.E3.m1.2.2.4.2" xref="S3.E3.m1.2.2.4.2.cmml">ğ</mi><mrow id="S3.E3.m1.2.2.4.3" xref="S3.E3.m1.2.2.4.3.cmml"><mi id="S3.E3.m1.2.2.4.3.2" xref="S3.E3.m1.2.2.4.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.4.3.1" xref="S3.E3.m1.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.4.3.3" xref="S3.E3.m1.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.4.3.1a" xref="S3.E3.m1.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.4.3.4" xref="S3.E3.m1.2.2.4.3.4.cmml">m</mi></mrow></msub><mo id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">=</mo><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><mi id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.4.cmml">ğ‘†ğ‘’ğ‘šğ¸ğ‘šğ‘ğ‘’ğ‘‘</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.3" xref="S3.E3.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">ğ³</mi><mrow id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml"><mn id="S3.E3.m1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.3.3.cmml">d</mi></mrow></msub><mo id="S3.E3.m1.2.2.2.2.2.4" xref="S3.E3.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.2.cmml">ğ¬</mi><mrow id="S3.E3.m1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.2.3.cmml"><mn id="S3.E3.m1.2.2.2.2.2.2.3.2" xref="S3.E3.m1.2.2.2.2.2.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.2.3.1" xref="S3.E3.m1.2.2.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.2.2.2.2.3.3" xref="S3.E3.m1.2.2.2.2.2.2.3.3.cmml">d</mi></mrow></msub><mo stretchy="false" id="S3.E3.m1.2.2.2.2.2.5" xref="S3.E3.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3"></eq><apply id="S3.E3.m1.2.2.4.cmml" xref="S3.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.4.2">ğ</ci><apply id="S3.E3.m1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.4.3"><times id="S3.E3.m1.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.4.3.1"></times><ci id="S3.E3.m1.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.4.3.2">ğ‘ </ci><ci id="S3.E3.m1.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.4.3.3">ğ‘’</ci><ci id="S3.E3.m1.2.2.4.3.4.cmml" xref="S3.E3.m1.2.2.4.3.4">ğ‘š</ci></apply></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><times id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"></times><ci id="S3.E3.m1.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.4">ğ‘†ğ‘’ğ‘šğ¸ğ‘šğ‘ğ‘’ğ‘‘</ci><interval closure="open" id="S3.E3.m1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2"><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2">ğ³</ci><apply id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3"><times id="S3.E3.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.1"></times><cn type="integer" id="S3.E3.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.2">2</cn><ci id="S3.E3.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.3">ğ‘‘</ci></apply></apply><apply id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2">ğ¬</ci><apply id="S3.E3.m1.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3"><times id="S3.E3.m1.2.2.2.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.1"></times><cn type="integer" id="S3.E3.m1.2.2.2.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2">2</cn><ci id="S3.E3.m1.2.2.2.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.3">ğ‘‘</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">\mathbf{Q}_{sem}=\mathit{SemEmbed}(\mathbf{z}_{2d},\mathbf{s}_{2d})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\mathbf{Q}=\mathbf{Q}_{pos}+\mathbf{Q}_{sem}" display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><mi id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">ğ</mi><mo id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><msub id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml"><mi id="S3.E4.m1.1.1.3.2.2" xref="S3.E4.m1.1.1.3.2.2.cmml">ğ</mi><mrow id="S3.E4.m1.1.1.3.2.3" xref="S3.E4.m1.1.1.3.2.3.cmml"><mi id="S3.E4.m1.1.1.3.2.3.2" xref="S3.E4.m1.1.1.3.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.2.3.1" xref="S3.E4.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.1.1.3.2.3.3" xref="S3.E4.m1.1.1.3.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.2.3.1a" xref="S3.E4.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.1.1.3.2.3.4" xref="S3.E4.m1.1.1.3.2.3.4.cmml">s</mi></mrow></msub><mo id="S3.E4.m1.1.1.3.1" xref="S3.E4.m1.1.1.3.1.cmml">+</mo><msub id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3.cmml"><mi id="S3.E4.m1.1.1.3.3.2" xref="S3.E4.m1.1.1.3.3.2.cmml">ğ</mi><mrow id="S3.E4.m1.1.1.3.3.3" xref="S3.E4.m1.1.1.3.3.3.cmml"><mi id="S3.E4.m1.1.1.3.3.3.2" xref="S3.E4.m1.1.1.3.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.3.3.1" xref="S3.E4.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.1.1.3.3.3.3" xref="S3.E4.m1.1.1.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.3.3.1a" xref="S3.E4.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.1.1.3.3.3.4" xref="S3.E4.m1.1.1.3.3.3.4.cmml">m</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"></eq><ci id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2">ğ</ci><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><plus id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3.1"></plus><apply id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2">ğ</ci><apply id="S3.E4.m1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.3.2.3"><times id="S3.E4.m1.1.1.3.2.3.1.cmml" xref="S3.E4.m1.1.1.3.2.3.1"></times><ci id="S3.E4.m1.1.1.3.2.3.2.cmml" xref="S3.E4.m1.1.1.3.2.3.2">ğ‘</ci><ci id="S3.E4.m1.1.1.3.2.3.3.cmml" xref="S3.E4.m1.1.1.3.2.3.3">ğ‘œ</ci><ci id="S3.E4.m1.1.1.3.2.3.4.cmml" xref="S3.E4.m1.1.1.3.2.3.4">ğ‘ </ci></apply></apply><apply id="S3.E4.m1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.3.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.3.3.2">ğ</ci><apply id="S3.E4.m1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.3.3.3"><times id="S3.E4.m1.1.1.3.3.3.1.cmml" xref="S3.E4.m1.1.1.3.3.3.1"></times><ci id="S3.E4.m1.1.1.3.3.3.2.cmml" xref="S3.E4.m1.1.1.3.3.3.2">ğ‘ </ci><ci id="S3.E4.m1.1.1.3.3.3.3.cmml" xref="S3.E4.m1.1.1.3.3.3.3">ğ‘’</ci><ci id="S3.E4.m1.1.1.3.3.3.4.cmml" xref="S3.E4.m1.1.1.3.3.3.4">ğ‘š</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\mathbf{Q}=\mathbf{Q}_{pos}+\mathbf{Q}_{sem}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.7" class="ltx_p">where <math id="S3.SS2.p3.1.m1.2" class="ltx_Math" alttext="\mathbf{Q}_{pos},\mathbf{Q}_{sem}" display="inline"><semantics id="S3.SS2.p3.1.m1.2a"><mrow id="S3.SS2.p3.1.m1.2.2.2" xref="S3.SS2.p3.1.m1.2.2.3.cmml"><msub id="S3.SS2.p3.1.m1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.2.cmml">ğ</mi><mrow id="S3.SS2.p3.1.m1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.3.2" xref="S3.SS2.p3.1.m1.1.1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.1.1.1.1.3.1" xref="S3.SS2.p3.1.m1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.1.m1.1.1.1.1.3.3" xref="S3.SS2.p3.1.m1.1.1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.1.1.1.1.3.1a" xref="S3.SS2.p3.1.m1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.1.m1.1.1.1.1.3.4" xref="S3.SS2.p3.1.m1.1.1.1.1.3.4.cmml">s</mi></mrow></msub><mo id="S3.SS2.p3.1.m1.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.1.m1.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.cmml"><mi id="S3.SS2.p3.1.m1.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.cmml">ğ</mi><mrow id="S3.SS2.p3.1.m1.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.2.3.cmml"><mi id="S3.SS2.p3.1.m1.2.2.2.2.3.2" xref="S3.SS2.p3.1.m1.2.2.2.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.2.2.2.2.3.1" xref="S3.SS2.p3.1.m1.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.1.m1.2.2.2.2.3.3" xref="S3.SS2.p3.1.m1.2.2.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.2.2.2.2.3.1a" xref="S3.SS2.p3.1.m1.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.1.m1.2.2.2.2.3.4" xref="S3.SS2.p3.1.m1.2.2.2.2.3.4.cmml">m</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.2b"><list id="S3.SS2.p3.1.m1.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2"><apply id="S3.SS2.p3.1.m1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.2">ğ</ci><apply id="S3.SS2.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3"><times id="S3.SS2.p3.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3.1"></times><ci id="S3.SS2.p3.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3.2">ğ‘</ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3.3">ğ‘œ</ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.3.4.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3.4">ğ‘ </ci></apply></apply><apply id="S3.SS2.p3.1.m1.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2">ğ</ci><apply id="S3.SS2.p3.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3"><times id="S3.SS2.p3.1.m1.2.2.2.2.3.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3.1"></times><ci id="S3.SS2.p3.1.m1.2.2.2.2.3.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3.2">ğ‘ </ci><ci id="S3.SS2.p3.1.m1.2.2.2.2.3.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3.3">ğ‘’</ci><ci id="S3.SS2.p3.1.m1.2.2.2.2.3.4.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3.4">ğ‘š</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.2c">\mathbf{Q}_{pos},\mathbf{Q}_{sem}</annotation></semantics></math> denote positional embedding and semantic embedding, respectively. <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\mathbf{z}_{2d}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">ğ³</mi><mrow id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml"><mn id="S3.SS2.p3.2.m2.1.1.3.2" xref="S3.SS2.p3.2.m2.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.1.3.1" xref="S3.SS2.p3.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.2.m2.1.1.3.3" xref="S3.SS2.p3.2.m2.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">ğ³</ci><apply id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3"><times id="S3.SS2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS2.p3.2.m2.1.1.3.1"></times><cn type="integer" id="S3.SS2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS2.p3.2.m2.1.1.3.2">2</cn><ci id="S3.SS2.p3.2.m2.1.1.3.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\mathbf{z}_{2d}</annotation></semantics></math> sampled from <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{F}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">ğ…</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">ğ…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathbf{F}</annotation></semantics></math> corresponds to the semantic context of position <math id="S3.SS2.p3.4.m4.2" class="ltx_Math" alttext="(\mathbf{c}_{w},\mathbf{c}_{h})" display="inline"><semantics id="S3.SS2.p3.4.m4.2a"><mrow id="S3.SS2.p3.4.m4.2.2.2" xref="S3.SS2.p3.4.m4.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.p3.4.m4.2.2.2.3" xref="S3.SS2.p3.4.m4.2.2.3.cmml">(</mo><msub id="S3.SS2.p3.4.m4.1.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.1.1.2" xref="S3.SS2.p3.4.m4.1.1.1.1.2.cmml">ğœ</mi><mi id="S3.SS2.p3.4.m4.1.1.1.1.3" xref="S3.SS2.p3.4.m4.1.1.1.1.3.cmml">w</mi></msub><mo id="S3.SS2.p3.4.m4.2.2.2.4" xref="S3.SS2.p3.4.m4.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.4.m4.2.2.2.2" xref="S3.SS2.p3.4.m4.2.2.2.2.cmml"><mi id="S3.SS2.p3.4.m4.2.2.2.2.2" xref="S3.SS2.p3.4.m4.2.2.2.2.2.cmml">ğœ</mi><mi id="S3.SS2.p3.4.m4.2.2.2.2.3" xref="S3.SS2.p3.4.m4.2.2.2.2.3.cmml">h</mi></msub><mo stretchy="false" id="S3.SS2.p3.4.m4.2.2.2.5" xref="S3.SS2.p3.4.m4.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.2b"><interval closure="open" id="S3.SS2.p3.4.m4.2.2.3.cmml" xref="S3.SS2.p3.4.m4.2.2.2"><apply id="S3.SS2.p3.4.m4.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.2">ğœ</ci><ci id="S3.SS2.p3.4.m4.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.3">ğ‘¤</ci></apply><apply id="S3.SS2.p3.4.m4.2.2.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.2.2.2.2.1.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.4.m4.2.2.2.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.2">ğœ</ci><ci id="S3.SS2.p3.4.m4.2.2.2.2.3.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.3">â„</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.2c">(\mathbf{c}_{w},\mathbf{c}_{h})</annotation></semantics></math>, and <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="\mathbf{s}_{2d}" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><msub id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">ğ¬</mi><mrow id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml"><mn id="S3.SS2.p3.5.m5.1.1.3.2" xref="S3.SS2.p3.5.m5.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.1.1.3.1" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.5.m5.1.1.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2">ğ¬</ci><apply id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3"><times id="S3.SS2.p3.5.m5.1.1.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3.1"></times><cn type="integer" id="S3.SS2.p3.5.m5.1.1.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.2">2</cn><ci id="S3.SS2.p3.5.m5.1.1.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\mathbf{s}_{2d}</annotation></semantics></math> is the confidence score of 2D boxes. <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="\mathit{PosEmbed(\cdot)}" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><mrow id="S3.SS2.p3.6.m6.1.2" xref="S3.SS2.p3.6.m6.1.2.cmml"><mi id="S3.SS2.p3.6.m6.1.2.2" xref="S3.SS2.p3.6.m6.1.2.2.cmml">ğ‘ƒğ‘œğ‘ ğ¸ğ‘šğ‘ğ‘’ğ‘‘</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m6.1.2.1" xref="S3.SS2.p3.6.m6.1.2.1.cmml">â€‹</mo><mrow id="S3.SS2.p3.6.m6.1.2.3.2" xref="S3.SS2.p3.6.m6.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.6.m6.1.2.3.2.1" xref="S3.SS2.p3.6.m6.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">â‹…</mo><mo stretchy="false" id="S3.SS2.p3.6.m6.1.2.3.2.2" xref="S3.SS2.p3.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.2.cmml" xref="S3.SS2.p3.6.m6.1.2"><times id="S3.SS2.p3.6.m6.1.2.1.cmml" xref="S3.SS2.p3.6.m6.1.2.1"></times><ci id="S3.SS2.p3.6.m6.1.2.2.cmml" xref="S3.SS2.p3.6.m6.1.2.2">ğ‘ƒğ‘œğ‘ ğ¸ğ‘šğ‘ğ‘’ğ‘‘</ci><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">\mathit{PosEmbed(\cdot)}</annotation></semantics></math> consists of a sinusoidal transformationÂ <cite class="ltx_cite ltx_citemacro_citep">(Vaswani etÂ al. <a href="#bib.bib29" title="" class="ltx_ref">2017</a>)</cite> and a MLP, while <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="\mathit{SemEmbed(\cdot)}" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><mrow id="S3.SS2.p3.7.m7.1.2" xref="S3.SS2.p3.7.m7.1.2.cmml"><mi id="S3.SS2.p3.7.m7.1.2.2" xref="S3.SS2.p3.7.m7.1.2.2.cmml">ğ‘†ğ‘’ğ‘šğ¸ğ‘šğ‘ğ‘’ğ‘‘</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.2.1" xref="S3.SS2.p3.7.m7.1.2.1.cmml">â€‹</mo><mrow id="S3.SS2.p3.7.m7.1.2.3.2" xref="S3.SS2.p3.7.m7.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.7.m7.1.2.3.2.1" xref="S3.SS2.p3.7.m7.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml">â‹…</mo><mo stretchy="false" id="S3.SS2.p3.7.m7.1.2.3.2.2" xref="S3.SS2.p3.7.m7.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.2.cmml" xref="S3.SS2.p3.7.m7.1.2"><times id="S3.SS2.p3.7.m7.1.2.1.cmml" xref="S3.SS2.p3.7.m7.1.2.1"></times><ci id="S3.SS2.p3.7.m7.1.2.2.cmml" xref="S3.SS2.p3.7.m7.1.2.2">ğ‘†ğ‘’ğ‘šğ¸ğ‘šğ‘ğ‘’ğ‘‘</ci><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">\mathit{SemEmbed(\cdot)}</annotation></semantics></math> is another MLP.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Lastly, the proposed 3D adaptive queries are concatenated with initialized global queries, and fed to subsequent transformer layers in the decoder.
</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Perspective-aware Aggregation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Existing sparse query-based approaches usually adopt one single-level feature map for computation effectiveness (e.g. StreamPETR). However, the single feature level is not optimal for all object queries of different ranges. For example, small distant objects require large-resolution features for precise localization, while high-level features are better suited for large close objects.
To overcome the limitation, we propose perspective-aware aggregation, enabling efficient feature interactions on different scales and views.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.5" class="ltx_p">Inspired by the deformable attention mechanismÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhu etÂ al. <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>, we apply a 3D spatial deformable attention consisting of 3D offsets sampling followed by view transformation. Formally, we first equip image features <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{F}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">ğ…</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">ğ…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\mathbf{F}</annotation></semantics></math> with the camera information including intrinsic <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{I}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">ğˆ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">ğˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">\mathbf{I}</annotation></semantics></math> and extrinsic parameters <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{K}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">ğŠ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">ğŠ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">\mathbf{K}</annotation></semantics></math>.
A squeeze-and-excitation blockÂ <cite class="ltx_cite ltx_citemacro_citep">(Hu, Shen, and Sun <a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite> is used to explicitly enrich the features.
Given enhanced feature <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{F^{\prime}}" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><msup id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">ğ…</mi><mo id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">ğ…</ci><ci id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\mathbf{F^{\prime}}</annotation></semantics></math>, we employ 3D deformable attention instead of global attention in PETR seriesÂ <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al. <a href="#bib.bib22" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib23" title="" class="ltx_ref">b</a>; Wang etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023a</a>)</cite>. For each query reference point in 3D space, the model learns <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mi id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><ci id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">M</annotation></semantics></math> sampling offsets around and projects these references into different 2D scales and views.</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="\mathbf{P}_{q}^{2d}=\mathbf{I\cdot K\cdot(P}_{q}^{3d}+\Delta\mathbf{P}_{q}^{3d})" display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><msubsup id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml"><mi id="S3.E5.m1.1.1.3.2.2" xref="S3.E5.m1.1.1.3.2.2.cmml">ğ</mi><mi id="S3.E5.m1.1.1.3.2.3" xref="S3.E5.m1.1.1.3.2.3.cmml">q</mi><mrow id="S3.E5.m1.1.1.3.3" xref="S3.E5.m1.1.1.3.3.cmml"><mn id="S3.E5.m1.1.1.3.3.2" xref="S3.E5.m1.1.1.3.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.1" xref="S3.E5.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.1.1.3.3.3" xref="S3.E5.m1.1.1.3.3.3.cmml">d</mi></mrow></msubsup><mo id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.3" xref="S3.E5.m1.1.1.1.3.cmml">ğˆ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.2.cmml">â‹…</mo><mi id="S3.E5.m1.1.1.1.4" xref="S3.E5.m1.1.1.1.4.cmml">ğŠ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.2a" xref="S3.E5.m1.1.1.1.2.cmml">â‹…</mo><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><msubsup id="S3.E5.m1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.2.2.2" xref="S3.E5.m1.1.1.1.1.1.1.2.2.2.cmml">ğ</mi><mi id="S3.E5.m1.1.1.1.1.1.1.2.2.3" xref="S3.E5.m1.1.1.1.1.1.1.2.2.3.cmml">q</mi><mrow id="S3.E5.m1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.1.1.2.3.cmml"><mn id="S3.E5.m1.1.1.1.1.1.1.2.3.2" xref="S3.E5.m1.1.1.1.1.1.1.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.1.1.1.2.3.1" xref="S3.E5.m1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.1.1.1.1.1.1.2.3.3" xref="S3.E5.m1.1.1.1.1.1.1.2.3.3.cmml">d</mi></mrow></msubsup><mo id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S3.E5.m1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.1.1.3.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.1.1.1.3.1" xref="S3.E5.m1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><msubsup id="S3.E5.m1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.3.3.2.2" xref="S3.E5.m1.1.1.1.1.1.1.3.3.2.2.cmml">ğ</mi><mi id="S3.E5.m1.1.1.1.1.1.1.3.3.2.3" xref="S3.E5.m1.1.1.1.1.1.1.3.3.2.3.cmml">q</mi><mrow id="S3.E5.m1.1.1.1.1.1.1.3.3.3" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3.cmml"><mn id="S3.E5.m1.1.1.1.1.1.1.3.3.3.2" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.1.1.1.3.3.3.1" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.1.1.1.1.1.1.3.3.3.3" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3.3.cmml">d</mi></mrow></msubsup></mrow></mrow><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"></eq><apply id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.3">superscript</csymbol><apply id="S3.E5.m1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2">ğ</ci><ci id="S3.E5.m1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.3.2.3">ğ‘</ci></apply><apply id="S3.E5.m1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.3.3"><times id="S3.E5.m1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3.1"></times><cn type="integer" id="S3.E5.m1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.2">2</cn><ci id="S3.E5.m1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3">ğ‘‘</ci></apply></apply><apply id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><ci id="S3.E5.m1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.2">â‹…</ci><ci id="S3.E5.m1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.3">ğˆ</ci><ci id="S3.E5.m1.1.1.1.4.cmml" xref="S3.E5.m1.1.1.1.4">ğŠ</ci><apply id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><plus id="S3.E5.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"></plus><apply id="S3.E5.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2.2.2">ğ</ci><ci id="S3.E5.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2.2.3">ğ‘</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2.3"><times id="S3.E5.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2.3.1"></times><cn type="integer" id="S3.E5.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2.3.2">3</cn><ci id="S3.E5.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2.3.3">ğ‘‘</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3"><times id="S3.E5.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.1"></times><ci id="S3.E5.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2">Î”</ci><apply id="S3.E5.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.3.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.3.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.2.2">ğ</ci><ci id="S3.E5.m1.1.1.1.1.1.1.3.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.2.3">ğ‘</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3"><times id="S3.E5.m1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3.1"></times><cn type="integer" id="S3.E5.m1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3.2">3</cn><ci id="S3.E5.m1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3.3">ğ‘‘</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">\mathbf{P}_{q}^{2d}=\mathbf{I\cdot K\cdot(P}_{q}^{3d}+\Delta\mathbf{P}_{q}^{3d})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.8" class="ltx_p">where <math id="S3.SS3.p2.6.m1.2" class="ltx_Math" alttext="\mathbf{P}_{q}^{3d},\Delta\mathbf{P}_{q}^{3d}" display="inline"><semantics id="S3.SS3.p2.6.m1.2a"><mrow id="S3.SS3.p2.6.m1.2.2.2" xref="S3.SS3.p2.6.m1.2.2.3.cmml"><msubsup id="S3.SS3.p2.6.m1.1.1.1.1" xref="S3.SS3.p2.6.m1.1.1.1.1.cmml"><mi id="S3.SS3.p2.6.m1.1.1.1.1.2.2" xref="S3.SS3.p2.6.m1.1.1.1.1.2.2.cmml">ğ</mi><mi id="S3.SS3.p2.6.m1.1.1.1.1.2.3" xref="S3.SS3.p2.6.m1.1.1.1.1.2.3.cmml">q</mi><mrow id="S3.SS3.p2.6.m1.1.1.1.1.3" xref="S3.SS3.p2.6.m1.1.1.1.1.3.cmml"><mn id="S3.SS3.p2.6.m1.1.1.1.1.3.2" xref="S3.SS3.p2.6.m1.1.1.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m1.1.1.1.1.3.1" xref="S3.SS3.p2.6.m1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.6.m1.1.1.1.1.3.3" xref="S3.SS3.p2.6.m1.1.1.1.1.3.3.cmml">d</mi></mrow></msubsup><mo id="S3.SS3.p2.6.m1.2.2.2.3" xref="S3.SS3.p2.6.m1.2.2.3.cmml">,</mo><mrow id="S3.SS3.p2.6.m1.2.2.2.2" xref="S3.SS3.p2.6.m1.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.SS3.p2.6.m1.2.2.2.2.2" xref="S3.SS3.p2.6.m1.2.2.2.2.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m1.2.2.2.2.1" xref="S3.SS3.p2.6.m1.2.2.2.2.1.cmml">â€‹</mo><msubsup id="S3.SS3.p2.6.m1.2.2.2.2.3" xref="S3.SS3.p2.6.m1.2.2.2.2.3.cmml"><mi id="S3.SS3.p2.6.m1.2.2.2.2.3.2.2" xref="S3.SS3.p2.6.m1.2.2.2.2.3.2.2.cmml">ğ</mi><mi id="S3.SS3.p2.6.m1.2.2.2.2.3.2.3" xref="S3.SS3.p2.6.m1.2.2.2.2.3.2.3.cmml">q</mi><mrow id="S3.SS3.p2.6.m1.2.2.2.2.3.3" xref="S3.SS3.p2.6.m1.2.2.2.2.3.3.cmml"><mn id="S3.SS3.p2.6.m1.2.2.2.2.3.3.2" xref="S3.SS3.p2.6.m1.2.2.2.2.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m1.2.2.2.2.3.3.1" xref="S3.SS3.p2.6.m1.2.2.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.6.m1.2.2.2.2.3.3.3" xref="S3.SS3.p2.6.m1.2.2.2.2.3.3.3.cmml">d</mi></mrow></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m1.2b"><list id="S3.SS3.p2.6.m1.2.2.3.cmml" xref="S3.SS3.p2.6.m1.2.2.2"><apply id="S3.SS3.p2.6.m1.1.1.1.1.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m1.1.1.1.1.1.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1">superscript</csymbol><apply id="S3.SS3.p2.6.m1.1.1.1.1.2.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m1.1.1.1.1.2.1.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p2.6.m1.1.1.1.1.2.2.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1.2.2">ğ</ci><ci id="S3.SS3.p2.6.m1.1.1.1.1.2.3.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS3.p2.6.m1.1.1.1.1.3.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1.3"><times id="S3.SS3.p2.6.m1.1.1.1.1.3.1.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1.3.1"></times><cn type="integer" id="S3.SS3.p2.6.m1.1.1.1.1.3.2.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1.3.2">3</cn><ci id="S3.SS3.p2.6.m1.1.1.1.1.3.3.cmml" xref="S3.SS3.p2.6.m1.1.1.1.1.3.3">ğ‘‘</ci></apply></apply><apply id="S3.SS3.p2.6.m1.2.2.2.2.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2"><times id="S3.SS3.p2.6.m1.2.2.2.2.1.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.1"></times><ci id="S3.SS3.p2.6.m1.2.2.2.2.2.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.2">Î”</ci><apply id="S3.SS3.p2.6.m1.2.2.2.2.3.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m1.2.2.2.2.3.1.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3">superscript</csymbol><apply id="S3.SS3.p2.6.m1.2.2.2.2.3.2.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m1.2.2.2.2.3.2.1.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3">subscript</csymbol><ci id="S3.SS3.p2.6.m1.2.2.2.2.3.2.2.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3.2.2">ğ</ci><ci id="S3.SS3.p2.6.m1.2.2.2.2.3.2.3.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3.2.3">ğ‘</ci></apply><apply id="S3.SS3.p2.6.m1.2.2.2.2.3.3.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3.3"><times id="S3.SS3.p2.6.m1.2.2.2.2.3.3.1.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3.3.1"></times><cn type="integer" id="S3.SS3.p2.6.m1.2.2.2.2.3.3.2.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3.3.2">3</cn><ci id="S3.SS3.p2.6.m1.2.2.2.2.3.3.3.cmml" xref="S3.SS3.p2.6.m1.2.2.2.2.3.3.3">ğ‘‘</ci></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m1.2c">\mathbf{P}_{q}^{3d},\Delta\mathbf{P}_{q}^{3d}</annotation></semantics></math> are 3D reference point and learned offsets for query <math id="S3.SS3.p2.7.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS3.p2.7.m2.1a"><mi id="S3.SS3.p2.7.m2.1.1" xref="S3.SS3.p2.7.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m2.1b"><ci id="S3.SS3.p2.7.m2.1.1.cmml" xref="S3.SS3.p2.7.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m2.1c">q</annotation></semantics></math>, respectively. <math id="S3.SS3.p2.8.m3.1" class="ltx_Math" alttext="\mathbf{P}_{q}^{2d}" display="inline"><semantics id="S3.SS3.p2.8.m3.1a"><msubsup id="S3.SS3.p2.8.m3.1.1" xref="S3.SS3.p2.8.m3.1.1.cmml"><mi id="S3.SS3.p2.8.m3.1.1.2.2" xref="S3.SS3.p2.8.m3.1.1.2.2.cmml">ğ</mi><mi id="S3.SS3.p2.8.m3.1.1.2.3" xref="S3.SS3.p2.8.m3.1.1.2.3.cmml">q</mi><mrow id="S3.SS3.p2.8.m3.1.1.3" xref="S3.SS3.p2.8.m3.1.1.3.cmml"><mn id="S3.SS3.p2.8.m3.1.1.3.2" xref="S3.SS3.p2.8.m3.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p2.8.m3.1.1.3.1" xref="S3.SS3.p2.8.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.8.m3.1.1.3.3" xref="S3.SS3.p2.8.m3.1.1.3.3.cmml">d</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m3.1b"><apply id="S3.SS3.p2.8.m3.1.1.cmml" xref="S3.SS3.p2.8.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m3.1.1.1.cmml" xref="S3.SS3.p2.8.m3.1.1">superscript</csymbol><apply id="S3.SS3.p2.8.m3.1.1.2.cmml" xref="S3.SS3.p2.8.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m3.1.1.2.1.cmml" xref="S3.SS3.p2.8.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.8.m3.1.1.2.2.cmml" xref="S3.SS3.p2.8.m3.1.1.2.2">ğ</ci><ci id="S3.SS3.p2.8.m3.1.1.2.3.cmml" xref="S3.SS3.p2.8.m3.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS3.p2.8.m3.1.1.3.cmml" xref="S3.SS3.p2.8.m3.1.1.3"><times id="S3.SS3.p2.8.m3.1.1.3.1.cmml" xref="S3.SS3.p2.8.m3.1.1.3.1"></times><cn type="integer" id="S3.SS3.p2.8.m3.1.1.3.2.cmml" xref="S3.SS3.p2.8.m3.1.1.3.2">2</cn><ci id="S3.SS3.p2.8.m3.1.1.3.3.cmml" xref="S3.SS3.p2.8.m3.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m3.1c">\mathbf{P}_{q}^{2d}</annotation></semantics></math> stands for the projected 2d reference point of different scales and views. For simplicity, we omit the subscripts of scales and views.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparisons on the Argoverse 2 <span id="S3.T1.19.1" class="ltx_text ltx_font_typewriter">val</span> set. We evaluate 26 object categories with a range of 150 meters. Far3D outperform previous surround-view methods with a large margin, and surpass several SoTA LiDAR-based methods.
Surround-view methods except for PETR are with temporal modeling.
<sup id="S3.T1.20.2" class="ltx_sup">â€¡</sup> are reproduced by ourselves.
</figcaption>
<div id="S3.T1.16" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:455.3pt;height:204.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(7.7pt,-3.5pt) scale(1.03503528743469,1.03503528743469) ;">
<table id="S3.T1.16.14" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.7.5.5" class="ltx_tr">
<td id="S3.T1.7.5.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.7.5.5.6.1" class="ltx_text ltx_font_bold">Methods</span></td>
<td id="S3.T1.7.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.7.5.5.7.1" class="ltx_text ltx_font_bold">Backbone</span></td>
<td id="S3.T1.7.5.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.7.5.5.8.1" class="ltx_text ltx_font_bold">Modality</span></td>
<td id="S3.T1.7.5.5.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.7.5.5.9.1" class="ltx_text ltx_font_bold">Image/Voxel Size</span></td>
<td id="S3.T1.3.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.3.1.1.1.1" class="ltx_text ltx_font_bold">mAP<math id="S3.T1.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.3.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T1.3.1.1.1.1.m1.1.1" xref="S3.T1.3.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.1.1.1.1.m1.1b"><ci id="S3.T1.3.1.1.1.1.m1.1.1.cmml" xref="S3.T1.3.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S3.T1.4.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.4.2.2.2.1" class="ltx_text ltx_font_bold">CDS<math id="S3.T1.4.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.4.2.2.2.1.m1.1a"><mo stretchy="false" id="S3.T1.4.2.2.2.1.m1.1.1" xref="S3.T1.4.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.2.2.2.1.m1.1b"><ci id="S3.T1.4.2.2.2.1.m1.1.1.cmml" xref="S3.T1.4.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S3.T1.5.3.3.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.5.3.3.3.1" class="ltx_text ltx_font_bold">mATE<math id="S3.T1.5.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.5.3.3.3.1.m1.1a"><mo stretchy="false" id="S3.T1.5.3.3.3.1.m1.1.1" xref="S3.T1.5.3.3.3.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.3.3.3.1.m1.1b"><ci id="S3.T1.5.3.3.3.1.m1.1.1.cmml" xref="S3.T1.5.3.3.3.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S3.T1.6.4.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.6.4.4.4.1" class="ltx_text ltx_font_bold">mASE<math id="S3.T1.6.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.6.4.4.4.1.m1.1a"><mo stretchy="false" id="S3.T1.6.4.4.4.1.m1.1.1" xref="S3.T1.6.4.4.4.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.4.4.4.1.m1.1b"><ci id="S3.T1.6.4.4.4.1.m1.1.1.cmml" xref="S3.T1.6.4.4.4.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S3.T1.7.5.5.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.7.5.5.5.1" class="ltx_text ltx_font_bold">mAOE<math id="S3.T1.7.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.7.5.5.5.1.m1.1a"><mo stretchy="false" id="S3.T1.7.5.5.5.1.m1.1.1" xref="S3.T1.7.5.5.5.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T1.7.5.5.5.1.m1.1b"><ci id="S3.T1.7.5.5.5.1.m1.1.1.cmml" xref="S3.T1.7.5.5.5.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S3.T1.9.7.7" class="ltx_tr">
<td id="S3.T1.8.6.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">BEVStereo<sup id="S3.T1.8.6.6.1.1" class="ltx_sup">â€¡</sup>
</td>
<td id="S3.T1.9.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">VoV-99</td>
<td id="S3.T1.9.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">Camera</td>
<td id="S3.T1.9.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">960 <math id="S3.T1.9.7.7.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.9.7.7.2.m1.1a"><mo id="S3.T1.9.7.7.2.m1.1.1" xref="S3.T1.9.7.7.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.9.7.7.2.m1.1b"><times id="S3.T1.9.7.7.2.m1.1.1.cmml" xref="S3.T1.9.7.7.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.7.7.2.m1.1c">\times</annotation></semantics></math> 640</td>
<td id="S3.T1.9.7.7.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.146</td>
<td id="S3.T1.9.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.104</td>
<td id="S3.T1.9.7.7.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.847</td>
<td id="S3.T1.9.7.7.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.397</td>
<td id="S3.T1.9.7.7.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.901</td>
</tr>
<tr id="S3.T1.11.9.9" class="ltx_tr">
<td id="S3.T1.10.8.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">SOLOFusion<sup id="S3.T1.10.8.8.1.1" class="ltx_sup">â€¡</sup>
</td>
<td id="S3.T1.11.9.9.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">VoV-99</td>
<td id="S3.T1.11.9.9.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Camera</td>
<td id="S3.T1.11.9.9.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">960 <math id="S3.T1.11.9.9.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.11.9.9.2.m1.1a"><mo id="S3.T1.11.9.9.2.m1.1.1" xref="S3.T1.11.9.9.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.11.9.9.2.m1.1b"><times id="S3.T1.11.9.9.2.m1.1.1.cmml" xref="S3.T1.11.9.9.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.9.9.2.m1.1c">\times</annotation></semantics></math> 640</td>
<td id="S3.T1.11.9.9.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.149</td>
<td id="S3.T1.11.9.9.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.106</td>
<td id="S3.T1.11.9.9.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.934</td>
<td id="S3.T1.11.9.9.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.425</td>
<td id="S3.T1.11.9.9.9" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.779</td>
</tr>
<tr id="S3.T1.12.10.10" class="ltx_tr">
<td id="S3.T1.12.10.10.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">PETR</td>
<td id="S3.T1.12.10.10.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">VoV-99</td>
<td id="S3.T1.12.10.10.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Camera</td>
<td id="S3.T1.12.10.10.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">960 <math id="S3.T1.12.10.10.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.12.10.10.1.m1.1a"><mo id="S3.T1.12.10.10.1.m1.1.1" xref="S3.T1.12.10.10.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.12.10.10.1.m1.1b"><times id="S3.T1.12.10.10.1.m1.1.1.cmml" xref="S3.T1.12.10.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.10.10.1.m1.1c">\times</annotation></semantics></math> 640</td>
<td id="S3.T1.12.10.10.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.176</td>
<td id="S3.T1.12.10.10.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.122</td>
<td id="S3.T1.12.10.10.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.911</td>
<td id="S3.T1.12.10.10.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.339</td>
<td id="S3.T1.12.10.10.9" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.819</td>
</tr>
<tr id="S3.T1.13.11.11" class="ltx_tr">
<td id="S3.T1.13.11.11.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Sparse4Dv2</td>
<td id="S3.T1.13.11.11.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">VoV-99</td>
<td id="S3.T1.13.11.11.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Camera</td>
<td id="S3.T1.13.11.11.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">960 <math id="S3.T1.13.11.11.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.13.11.11.1.m1.1a"><mo id="S3.T1.13.11.11.1.m1.1.1" xref="S3.T1.13.11.11.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.13.11.11.1.m1.1b"><times id="S3.T1.13.11.11.1.m1.1.1.cmml" xref="S3.T1.13.11.11.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.11.11.1.m1.1c">\times</annotation></semantics></math> 640</td>
<td id="S3.T1.13.11.11.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.189</td>
<td id="S3.T1.13.11.11.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.134</td>
<td id="S3.T1.13.11.11.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.832</td>
<td id="S3.T1.13.11.11.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.343</td>
<td id="S3.T1.13.11.11.9" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.723</td>
</tr>
<tr id="S3.T1.14.12.12" class="ltx_tr">
<td id="S3.T1.14.12.12.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">StreamPETR</td>
<td id="S3.T1.14.12.12.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">VoV-99</td>
<td id="S3.T1.14.12.12.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Camera</td>
<td id="S3.T1.14.12.12.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">960 <math id="S3.T1.14.12.12.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.14.12.12.1.m1.1a"><mo id="S3.T1.14.12.12.1.m1.1.1" xref="S3.T1.14.12.12.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.14.12.12.1.m1.1b"><times id="S3.T1.14.12.12.1.m1.1.1.cmml" xref="S3.T1.14.12.12.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.12.12.1.m1.1c">\times</annotation></semantics></math> 640</td>
<td id="S3.T1.14.12.12.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.203</td>
<td id="S3.T1.14.12.12.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.146</td>
<td id="S3.T1.14.12.12.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.843</td>
<td id="S3.T1.14.12.12.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.321</td>
<td id="S3.T1.14.12.12.9" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.650</td>
</tr>
<tr id="S3.T1.15.13.13" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T1.15.13.13.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.15.13.13.2.1" class="ltx_text" style="background-color:#E6E6E6;">Far3DÂ (Ours)</span></td>
<td id="S3.T1.15.13.13.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.15.13.13.3.1" class="ltx_text" style="background-color:#E6E6E6;">VoV-99</span></td>
<td id="S3.T1.15.13.13.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.15.13.13.4.1" class="ltx_text" style="background-color:#E6E6E6;">Camera</span></td>
<td id="S3.T1.15.13.13.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.15.13.13.1.1" class="ltx_text" style="background-color:#E6E6E6;">960 <math id="S3.T1.15.13.13.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.15.13.13.1.1.m1.1a"><mo mathbackground="#E6E6E6" id="S3.T1.15.13.13.1.1.m1.1.1" xref="S3.T1.15.13.13.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.15.13.13.1.1.m1.1b"><times id="S3.T1.15.13.13.1.1.m1.1.1.cmml" xref="S3.T1.15.13.13.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.13.13.1.1.m1.1c">\times</annotation></semantics></math> 640</span></td>
<td id="S3.T1.15.13.13.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.15.13.13.5.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.244</span></td>
<td id="S3.T1.15.13.13.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.15.13.13.6.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.181</span></td>
<td id="S3.T1.15.13.13.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.15.13.13.7.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.796</span></td>
<td id="S3.T1.15.13.13.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.15.13.13.8.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.304</span></td>
<td id="S3.T1.15.13.13.9" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.15.13.13.9.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.538</span></td>
</tr>
<tr id="S3.T1.16.14.15.1" class="ltx_tr">
<td id="S3.T1.16.14.15.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">CenterPoint</td>
<td id="S3.T1.16.14.15.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">-</td>
<td id="S3.T1.16.14.15.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">Lidar</td>
<td id="S3.T1.16.14.15.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">(0.2, 0.2, 0.2)</td>
<td id="S3.T1.16.14.15.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.274</td>
<td id="S3.T1.16.14.15.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.210</td>
<td id="S3.T1.16.14.15.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.548</td>
<td id="S3.T1.16.14.15.1.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.362</td>
<td id="S3.T1.16.14.15.1.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.781</td>
</tr>
<tr id="S3.T1.16.14.16.2" class="ltx_tr">
<td id="S3.T1.16.14.16.2.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">FSD</td>
<td id="S3.T1.16.14.16.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">-</td>
<td id="S3.T1.16.14.16.2.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Lidar</td>
<td id="S3.T1.16.14.16.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">(0.2, 0.2, 0.2)</td>
<td id="S3.T1.16.14.16.2.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.291</td>
<td id="S3.T1.16.14.16.2.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.233</td>
<td id="S3.T1.16.14.16.2.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.16.2.7.1" class="ltx_text ltx_font_bold">0.468</span></td>
<td id="S3.T1.16.14.16.2.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.16.2.8.1" class="ltx_text ltx_font_bold">0.299</span></td>
<td id="S3.T1.16.14.16.2.9" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.740</td>
</tr>
<tr id="S3.T1.16.14.17.3" class="ltx_tr">
<td id="S3.T1.16.14.17.3.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">VoxelNeXt</td>
<td id="S3.T1.16.14.17.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">-</td>
<td id="S3.T1.16.14.17.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Lidar</td>
<td id="S3.T1.16.14.17.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">(0.1, 0.1, 0.2)</td>
<td id="S3.T1.16.14.17.3.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.307</td>
<td id="S3.T1.16.14.17.3.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.225</td>
<td id="S3.T1.16.14.17.3.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.431</td>
<td id="S3.T1.16.14.17.3.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.291</td>
<td id="S3.T1.16.14.17.3.9" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">1.157</td>
</tr>
<tr id="S3.T1.16.14.14" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T1.16.14.14.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.14.2.1" class="ltx_text" style="background-color:#E6E6E6;">Far3DÂ (Ours)</span></td>
<td id="S3.T1.16.14.14.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.14.3.1" class="ltx_text" style="background-color:#E6E6E6;">ViT-L</span></td>
<td id="S3.T1.16.14.14.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.14.4.1" class="ltx_text" style="background-color:#E6E6E6;">Camera</span></td>
<td id="S3.T1.16.14.14.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.14.1.1" class="ltx_text" style="background-color:#E6E6E6;">1536 <math id="S3.T1.16.14.14.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.16.14.14.1.1.m1.1a"><mo mathbackground="#E6E6E6" id="S3.T1.16.14.14.1.1.m1.1.1" xref="S3.T1.16.14.14.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.16.14.14.1.1.m1.1b"><times id="S3.T1.16.14.14.1.1.m1.1.1.cmml" xref="S3.T1.16.14.14.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.14.14.1.1.m1.1c">\times</annotation></semantics></math> 1536</span></td>
<td id="S3.T1.16.14.14.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.14.5.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.316</span></td>
<td id="S3.T1.16.14.14.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.14.6.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.239</span></td>
<td id="S3.T1.16.14.14.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.14.7.1" class="ltx_text" style="background-color:#E6E6E6;">0.732</span></td>
<td id="S3.T1.16.14.14.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.14.8.1" class="ltx_text" style="background-color:#E6E6E6;">0.303</span></td>
<td id="S3.T1.16.14.14.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T1.16.14.14.9.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.459</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison on the nuScenes <span id="S3.T2.22.1" class="ltx_text ltx_font_typewriter">val</span> and <span id="S3.T2.23.2" class="ltx_text ltx_font_typewriter">test</span> splits. Far3D achieves the highest performance compared to prior-arts, validating its generalization ability. <sup id="S3.T2.24.3" class="ltx_sup">âˆ—</sup>Benefited from the perspective-view pre-training. We employ the resolution 512 <math id="S3.T2.5.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T2.5.m2.1b"><mo id="S3.T2.5.m2.1.1" xref="S3.T2.5.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.m2.1c"><times id="S3.T2.5.m2.1.1.cmml" xref="S3.T2.5.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.m2.1d">\times</annotation></semantics></math> 1408 for <span id="S3.T2.25.4" class="ltx_text ltx_font_typewriter">val</span> and 1536 <math id="S3.T2.6.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T2.6.m3.1b"><mo id="S3.T2.6.m3.1.1" xref="S3.T2.6.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T2.6.m3.1c"><times id="S3.T2.6.m3.1.1.cmml" xref="S3.T2.6.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.m3.1d">\times</annotation></semantics></math> 1536 for <span id="S3.T2.26.5" class="ltx_text ltx_font_typewriter">test</span> split.
</figcaption>
<div id="S3.T2.16" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:455.3pt;height:184.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(5.6pt,-2.3pt) scale(1.02540022045223,1.02540022045223) ;">
<table id="S3.T2.16.10" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.13.7.7" class="ltx_tr">
<th id="S3.T2.13.7.7.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.13.7.7.8.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="S3.T2.13.7.7.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.13.7.7.9.1" class="ltx_text ltx_font_bold">Backbone</span></th>
<th id="S3.T2.13.7.7.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.13.7.7.10.1" class="ltx_text ltx_font_bold">Split</span></th>
<th id="S3.T2.7.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.7.1.1.1.1" class="ltx_text ltx_font_bold">mAP<math id="S3.T2.7.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.7.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T2.7.1.1.1.1.m1.1.1" xref="S3.T2.7.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S3.T2.7.1.1.1.1.m1.1b"><ci id="S3.T2.7.1.1.1.1.m1.1.1.cmml" xref="S3.T2.7.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S3.T2.8.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.8.2.2.2.1" class="ltx_text ltx_font_bold">NDS<math id="S3.T2.8.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.8.2.2.2.1.m1.1a"><mo stretchy="false" id="S3.T2.8.2.2.2.1.m1.1.1" xref="S3.T2.8.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S3.T2.8.2.2.2.1.m1.1b"><ci id="S3.T2.8.2.2.2.1.m1.1.1.cmml" xref="S3.T2.8.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S3.T2.9.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.9.3.3.3.1" class="ltx_text ltx_font_bold">mATE<math id="S3.T2.9.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T2.9.3.3.3.1.m1.1a"><mo stretchy="false" id="S3.T2.9.3.3.3.1.m1.1.1" xref="S3.T2.9.3.3.3.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T2.9.3.3.3.1.m1.1b"><ci id="S3.T2.9.3.3.3.1.m1.1.1.cmml" xref="S3.T2.9.3.3.3.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S3.T2.10.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.10.4.4.4.1" class="ltx_text ltx_font_bold">mASE<math id="S3.T2.10.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T2.10.4.4.4.1.m1.1a"><mo stretchy="false" id="S3.T2.10.4.4.4.1.m1.1.1" xref="S3.T2.10.4.4.4.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T2.10.4.4.4.1.m1.1b"><ci id="S3.T2.10.4.4.4.1.m1.1.1.cmml" xref="S3.T2.10.4.4.4.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S3.T2.11.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.11.5.5.5.1" class="ltx_text ltx_font_bold">mAOE<math id="S3.T2.11.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T2.11.5.5.5.1.m1.1a"><mo stretchy="false" id="S3.T2.11.5.5.5.1.m1.1.1" xref="S3.T2.11.5.5.5.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T2.11.5.5.5.1.m1.1b"><ci id="S3.T2.11.5.5.5.1.m1.1.1.cmml" xref="S3.T2.11.5.5.5.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S3.T2.12.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.12.6.6.6.1" class="ltx_text ltx_font_bold">mAVE<math id="S3.T2.12.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T2.12.6.6.6.1.m1.1a"><mo stretchy="false" id="S3.T2.12.6.6.6.1.m1.1.1" xref="S3.T2.12.6.6.6.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T2.12.6.6.6.1.m1.1b"><ci id="S3.T2.12.6.6.6.1.m1.1.1.cmml" xref="S3.T2.12.6.6.6.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S3.T2.13.7.7.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.13.7.7.7.1" class="ltx_text ltx_font_bold">mAAE<math id="S3.T2.13.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T2.13.7.7.7.1.m1.1a"><mo stretchy="false" id="S3.T2.13.7.7.7.1.m1.1.1" xref="S3.T2.13.7.7.7.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T2.13.7.7.7.1.m1.1b"><ci id="S3.T2.13.7.7.7.1.m1.1.1.cmml" xref="S3.T2.13.7.7.7.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.16.10.11.1" class="ltx_tr">
<td id="S3.T2.16.10.11.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">PETR</td>
<td id="S3.T2.16.10.11.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet101</td>
<td id="S3.T2.16.10.11.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.11.1.3.1" class="ltx_text ltx_font_typewriter">val</span></td>
<td id="S3.T2.16.10.11.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.366</td>
<td id="S3.T2.16.10.11.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.441</td>
<td id="S3.T2.16.10.11.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.717</td>
<td id="S3.T2.16.10.11.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.261</td>
<td id="S3.T2.16.10.11.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.412</td>
<td id="S3.T2.16.10.11.1.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.834</td>
<td id="S3.T2.16.10.11.1.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">0.190</td>
</tr>
<tr id="S3.T2.16.10.12.2" class="ltx_tr">
<td id="S3.T2.16.10.12.2.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">SOLOFusion</td>
<td id="S3.T2.16.10.12.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet101</td>
<td id="S3.T2.16.10.12.2.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.12.2.3.1" class="ltx_text ltx_font_typewriter">val</span></td>
<td id="S3.T2.16.10.12.2.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.483</td>
<td id="S3.T2.16.10.12.2.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.582</td>
<td id="S3.T2.16.10.12.2.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.12.2.6.1" class="ltx_text ltx_font_bold">0.503</span></td>
<td id="S3.T2.16.10.12.2.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.264</td>
<td id="S3.T2.16.10.12.2.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.381</td>
<td id="S3.T2.16.10.12.2.9" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.246</td>
<td id="S3.T2.16.10.12.2.10" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.207</td>
</tr>
<tr id="S3.T2.14.8.8" class="ltx_tr">
<td id="S3.T2.14.8.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">StreamPETR<sup id="S3.T2.14.8.8.1.1" class="ltx_sup">âˆ—</sup>
</td>
<td id="S3.T2.14.8.8.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet101</td>
<td id="S3.T2.14.8.8.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.14.8.8.3.1" class="ltx_text ltx_font_typewriter">val</span></td>
<td id="S3.T2.14.8.8.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.504</td>
<td id="S3.T2.14.8.8.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.592</td>
<td id="S3.T2.14.8.8.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.569</td>
<td id="S3.T2.14.8.8.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.262</td>
<td id="S3.T2.14.8.8.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.14.8.8.8.1" class="ltx_text ltx_font_bold">0.315</span></td>
<td id="S3.T2.14.8.8.9" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.257</td>
<td id="S3.T2.14.8.8.10" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.199</td>
</tr>
<tr id="S3.T2.15.9.9" class="ltx_tr">
<td id="S3.T2.15.9.9.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Sparse4Dv2<sup id="S3.T2.15.9.9.1.1" class="ltx_sup">âˆ—</sup>
</td>
<td id="S3.T2.15.9.9.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet101</td>
<td id="S3.T2.15.9.9.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.15.9.9.3.1" class="ltx_text ltx_font_typewriter">val</span></td>
<td id="S3.T2.15.9.9.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.505</td>
<td id="S3.T2.15.9.9.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.594</td>
<td id="S3.T2.15.9.9.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.548</td>
<td id="S3.T2.15.9.9.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.268</td>
<td id="S3.T2.15.9.9.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.348</td>
<td id="S3.T2.15.9.9.9" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.239</td>
<td id="S3.T2.15.9.9.10" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.15.9.9.10.1" class="ltx_text ltx_font_bold">0.184</span></td>
</tr>
<tr id="S3.T2.16.10.10" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T2.16.10.10.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.1.1" class="ltx_text" style="background-color:#E6E6E6;">Far3DÂ (Ours)<sup id="S3.T2.16.10.10.1.1.1" class="ltx_sup">âˆ—</sup></span></td>
<td id="S3.T2.16.10.10.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.2.1" class="ltx_text" style="background-color:#E6E6E6;">ResNet101</span></td>
<td id="S3.T2.16.10.10.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.3.1" class="ltx_text ltx_font_typewriter" style="background-color:#E6E6E6;">val</span></td>
<td id="S3.T2.16.10.10.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.4.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.510</span></td>
<td id="S3.T2.16.10.10.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.5.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.594</span></td>
<td id="S3.T2.16.10.10.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.6.1" class="ltx_text" style="background-color:#E6E6E6;">0.551</span></td>
<td id="S3.T2.16.10.10.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.7.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.258</span></td>
<td id="S3.T2.16.10.10.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.8.1" class="ltx_text" style="background-color:#E6E6E6;">0.372</span></td>
<td id="S3.T2.16.10.10.9" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.9.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.238</span></td>
<td id="S3.T2.16.10.10.10" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.10.10.1" class="ltx_text" style="background-color:#E6E6E6;">0.195</span></td>
</tr>
<tr id="S3.T2.16.10.13.3" class="ltx_tr">
<td id="S3.T2.16.10.13.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">SOLOFusion</td>
<td id="S3.T2.16.10.13.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">ConvNeXt-B</td>
<td id="S3.T2.16.10.13.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.13.3.3.1" class="ltx_text ltx_font_typewriter">test</span></td>
<td id="S3.T2.16.10.13.3.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.540</td>
<td id="S3.T2.16.10.13.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.619</td>
<td id="S3.T2.16.10.13.3.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.453</td>
<td id="S3.T2.16.10.13.3.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.257</td>
<td id="S3.T2.16.10.13.3.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.376</td>
<td id="S3.T2.16.10.13.3.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.267</td>
<td id="S3.T2.16.10.13.3.10" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">0.148</td>
</tr>
<tr id="S3.T2.16.10.14.4" class="ltx_tr">
<td id="S3.T2.16.10.14.4.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Sparse4Dv2</td>
<td id="S3.T2.16.10.14.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">VoV-99</td>
<td id="S3.T2.16.10.14.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.14.4.3.1" class="ltx_text ltx_font_typewriter">test</span></td>
<td id="S3.T2.16.10.14.4.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.556</td>
<td id="S3.T2.16.10.14.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.638</td>
<td id="S3.T2.16.10.14.4.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.462</td>
<td id="S3.T2.16.10.14.4.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.238</td>
<td id="S3.T2.16.10.14.4.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.328</td>
<td id="S3.T2.16.10.14.4.9" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.264</td>
<td id="S3.T2.16.10.14.4.10" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.14.4.10.1" class="ltx_text ltx_font_bold">0.115</span></td>
</tr>
<tr id="S3.T2.16.10.15.5" class="ltx_tr">
<td id="S3.T2.16.10.15.5.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">StreamPETR</td>
<td id="S3.T2.16.10.15.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ViT-L</td>
<td id="S3.T2.16.10.15.5.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.15.5.3.1" class="ltx_text ltx_font_typewriter">test</span></td>
<td id="S3.T2.16.10.15.5.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.620</td>
<td id="S3.T2.16.10.15.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">0.676</td>
<td id="S3.T2.16.10.15.5.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.470</td>
<td id="S3.T2.16.10.15.5.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.241</td>
<td id="S3.T2.16.10.15.5.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.15.5.8.1" class="ltx_text ltx_font_bold">0.258</span></td>
<td id="S3.T2.16.10.15.5.9" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.236</td>
<td id="S3.T2.16.10.15.5.10" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.134</td>
</tr>
<tr id="S3.T2.16.10.16.6" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T2.16.10.16.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.1.1" class="ltx_text" style="background-color:#E6E6E6;">Far3DÂ (Ours)</span></td>
<td id="S3.T2.16.10.16.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.2.1" class="ltx_text" style="background-color:#E6E6E6;">ViT-L</span></td>
<td id="S3.T2.16.10.16.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.3.1" class="ltx_text ltx_font_typewriter" style="background-color:#E6E6E6;">test</span></td>
<td id="S3.T2.16.10.16.6.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.4.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.635</span></td>
<td id="S3.T2.16.10.16.6.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.5.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.687</span></td>
<td id="S3.T2.16.10.16.6.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.6.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.432</span></td>
<td id="S3.T2.16.10.16.6.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.7.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.237</span></td>
<td id="S3.T2.16.10.16.6.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.8.1" class="ltx_text" style="background-color:#E6E6E6;">0.278</span></td>
<td id="S3.T2.16.10.16.6.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.9.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.227</span></td>
<td id="S3.T2.16.10.16.6.10" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.10.16.6.10.1" class="ltx_text" style="background-color:#E6E6E6;">0.130</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.2" class="ltx_p">Next, 3D object queries interact with multi-scale sampled features from <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{F^{{}^{\prime}}}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msup id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">ğ…</mi><msup id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml"><mi id="S3.SS3.p3.1.m1.1.1.3a" xref="S3.SS3.p3.1.m1.1.1.3.cmml"></mi><mo id="S3.SS3.p3.1.m1.1.1.3.1" xref="S3.SS3.p3.1.m1.1.1.3.1.cmml">â€²</mo></msup></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">ğ…</ci><apply id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3"><ci id="S3.SS3.p3.1.m1.1.1.3.1.cmml" xref="S3.SS3.p3.1.m1.1.1.3.1">â€²</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\mathbf{F^{{}^{\prime}}}</annotation></semantics></math>, according to the above 2D reference points <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="\mathbf{P}_{q}^{2d}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><msubsup id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2.2" xref="S3.SS3.p3.2.m2.1.1.2.2.cmml">ğ</mi><mi id="S3.SS3.p3.2.m2.1.1.2.3" xref="S3.SS3.p3.2.m2.1.1.2.3.cmml">q</mi><mrow id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml"><mn id="S3.SS3.p3.2.m2.1.1.3.2" xref="S3.SS3.p3.2.m2.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.3.1" xref="S3.SS3.p3.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p3.2.m2.1.1.3.3" xref="S3.SS3.p3.2.m2.1.1.3.3.cmml">d</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.2.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2.2">ğ</ci><ci id="S3.SS3.p3.2.m2.1.1.2.3.cmml" xref="S3.SS3.p3.2.m2.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3"><times id="S3.SS3.p3.2.m2.1.1.3.1.cmml" xref="S3.SS3.p3.2.m2.1.1.3.1"></times><cn type="integer" id="S3.SS3.p3.2.m2.1.1.3.2.cmml" xref="S3.SS3.p3.2.m2.1.1.3.2">2</cn><ci id="S3.SS3.p3.2.m2.1.1.3.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">\mathbf{P}_{q}^{2d}</annotation></semantics></math>. In this way, diverse features from various vis and scales are aggregated into 3D queries by considering their relative importance.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Range-modulated 3D Denoising</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">3D object queries at different distances have different regression difficulties, which is different from 2D queries that are usually treated equally for existing 2D denoising methods such as DN-DETRÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al. <a href="#bib.bib13" title="" class="ltx_ref">2022a</a>)</cite>.
The difficulty discrepancy comes from query density and error propagation. On the one hand, queries corresponding to distant objects are less matched compared to close ones. On the other hand, small errors of 2D proposals can be amplified when introducing 2D priors to 3D adaptive queries, illustrated in Fig.Â <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, not to mention which effect increases along with object distance.
As a result, some query proposals near GT boxes can be regarded as noisy candidates, whereas others with notable deviation should be negative ones.
Therefore we aim to recall those potential positive ones and directly reject solid negative ones, by developing a method called range-modulated 3D denoising.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.8" class="ltx_p">Concretely, we construct noisy queries based on GT objects by simultaneously adding positive and negative groups. For both types, random noises are applied according to object positions and sizes to facilitate denoising learning in long-range perception. Formally, we define the position of noisy queries as:
</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.3" class="ltx_Math" alttext="\mathbf{\tilde{P}}=\mathbf{P}_{GT}+\alpha f_{p}(\mathbf{S}_{GT})+(1-\alpha)f_{n}(\mathbf{P}_{GT})" display="block"><semantics id="S3.E6.m1.3a"><mrow id="S3.E6.m1.3.3" xref="S3.E6.m1.3.3.cmml"><mover accent="true" id="S3.E6.m1.3.3.5" xref="S3.E6.m1.3.3.5.cmml"><mi id="S3.E6.m1.3.3.5.2" xref="S3.E6.m1.3.3.5.2.cmml">ğ</mi><mo id="S3.E6.m1.3.3.5.1" xref="S3.E6.m1.3.3.5.1.cmml">~</mo></mover><mo id="S3.E6.m1.3.3.4" xref="S3.E6.m1.3.3.4.cmml">=</mo><mrow id="S3.E6.m1.3.3.3" xref="S3.E6.m1.3.3.3.cmml"><msub id="S3.E6.m1.3.3.3.5" xref="S3.E6.m1.3.3.3.5.cmml"><mi id="S3.E6.m1.3.3.3.5.2" xref="S3.E6.m1.3.3.3.5.2.cmml">ğ</mi><mrow id="S3.E6.m1.3.3.3.5.3" xref="S3.E6.m1.3.3.3.5.3.cmml"><mi id="S3.E6.m1.3.3.3.5.3.2" xref="S3.E6.m1.3.3.3.5.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.3.5.3.1" xref="S3.E6.m1.3.3.3.5.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.3.3.3.5.3.3" xref="S3.E6.m1.3.3.3.5.3.3.cmml">T</mi></mrow></msub><mo id="S3.E6.m1.3.3.3.4" xref="S3.E6.m1.3.3.3.4.cmml">+</mo><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml">Î±</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml">â€‹</mo><msub id="S3.E6.m1.1.1.1.1.4" xref="S3.E6.m1.1.1.1.1.4.cmml"><mi id="S3.E6.m1.1.1.1.1.4.2" xref="S3.E6.m1.1.1.1.1.4.2.cmml">f</mi><mi id="S3.E6.m1.1.1.1.1.4.3" xref="S3.E6.m1.1.1.1.1.4.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.2a" xref="S3.E6.m1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E6.m1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.2.cmml">ğ’</mi><mrow id="S3.E6.m1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.3.1" xref="S3.E6.m1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.1.1.1.3.3.cmml">T</mi></mrow></msub><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.3.3.3.4a" xref="S3.E6.m1.3.3.3.4.cmml">+</mo><mrow id="S3.E6.m1.3.3.3.3" xref="S3.E6.m1.3.3.3.3.cmml"><mrow id="S3.E6.m1.2.2.2.2.1.1" xref="S3.E6.m1.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.2.2.1.1.2" xref="S3.E6.m1.2.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.2.2.2.2.1.1.1" xref="S3.E6.m1.2.2.2.2.1.1.1.cmml"><mn id="S3.E6.m1.2.2.2.2.1.1.1.2" xref="S3.E6.m1.2.2.2.2.1.1.1.2.cmml">1</mn><mo id="S3.E6.m1.2.2.2.2.1.1.1.1" xref="S3.E6.m1.2.2.2.2.1.1.1.1.cmml">âˆ’</mo><mi id="S3.E6.m1.2.2.2.2.1.1.1.3" xref="S3.E6.m1.2.2.2.2.1.1.1.3.cmml">Î±</mi></mrow><mo stretchy="false" id="S3.E6.m1.2.2.2.2.1.1.3" xref="S3.E6.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.3.3.3" xref="S3.E6.m1.3.3.3.3.3.cmml">â€‹</mo><msub id="S3.E6.m1.3.3.3.3.4" xref="S3.E6.m1.3.3.3.3.4.cmml"><mi id="S3.E6.m1.3.3.3.3.4.2" xref="S3.E6.m1.3.3.3.3.4.2.cmml">f</mi><mi id="S3.E6.m1.3.3.3.3.4.3" xref="S3.E6.m1.3.3.3.3.4.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.3.3.3a" xref="S3.E6.m1.3.3.3.3.3.cmml">â€‹</mo><mrow id="S3.E6.m1.3.3.3.3.2.1" xref="S3.E6.m1.3.3.3.3.2.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.3.3.2.1.2" xref="S3.E6.m1.3.3.3.3.2.1.1.cmml">(</mo><msub id="S3.E6.m1.3.3.3.3.2.1.1" xref="S3.E6.m1.3.3.3.3.2.1.1.cmml"><mi id="S3.E6.m1.3.3.3.3.2.1.1.2" xref="S3.E6.m1.3.3.3.3.2.1.1.2.cmml">ğ</mi><mrow id="S3.E6.m1.3.3.3.3.2.1.1.3" xref="S3.E6.m1.3.3.3.3.2.1.1.3.cmml"><mi id="S3.E6.m1.3.3.3.3.2.1.1.3.2" xref="S3.E6.m1.3.3.3.3.2.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.3.3.2.1.1.3.1" xref="S3.E6.m1.3.3.3.3.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.3.3.3.3.2.1.1.3.3" xref="S3.E6.m1.3.3.3.3.2.1.1.3.3.cmml">T</mi></mrow></msub><mo stretchy="false" id="S3.E6.m1.3.3.3.3.2.1.3" xref="S3.E6.m1.3.3.3.3.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.3b"><apply id="S3.E6.m1.3.3.cmml" xref="S3.E6.m1.3.3"><eq id="S3.E6.m1.3.3.4.cmml" xref="S3.E6.m1.3.3.4"></eq><apply id="S3.E6.m1.3.3.5.cmml" xref="S3.E6.m1.3.3.5"><ci id="S3.E6.m1.3.3.5.1.cmml" xref="S3.E6.m1.3.3.5.1">~</ci><ci id="S3.E6.m1.3.3.5.2.cmml" xref="S3.E6.m1.3.3.5.2">ğ</ci></apply><apply id="S3.E6.m1.3.3.3.cmml" xref="S3.E6.m1.3.3.3"><plus id="S3.E6.m1.3.3.3.4.cmml" xref="S3.E6.m1.3.3.3.4"></plus><apply id="S3.E6.m1.3.3.3.5.cmml" xref="S3.E6.m1.3.3.3.5"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.5.1.cmml" xref="S3.E6.m1.3.3.3.5">subscript</csymbol><ci id="S3.E6.m1.3.3.3.5.2.cmml" xref="S3.E6.m1.3.3.3.5.2">ğ</ci><apply id="S3.E6.m1.3.3.3.5.3.cmml" xref="S3.E6.m1.3.3.3.5.3"><times id="S3.E6.m1.3.3.3.5.3.1.cmml" xref="S3.E6.m1.3.3.3.5.3.1"></times><ci id="S3.E6.m1.3.3.3.5.3.2.cmml" xref="S3.E6.m1.3.3.3.5.3.2">ğº</ci><ci id="S3.E6.m1.3.3.3.5.3.3.cmml" xref="S3.E6.m1.3.3.3.5.3.3">ğ‘‡</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1"><times id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"></times><ci id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3">ğ›¼</ci><apply id="S3.E6.m1.1.1.1.1.4.cmml" xref="S3.E6.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.4.1.cmml" xref="S3.E6.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.4.2.cmml" xref="S3.E6.m1.1.1.1.1.4.2">ğ‘“</ci><ci id="S3.E6.m1.1.1.1.1.4.3.cmml" xref="S3.E6.m1.1.1.1.1.4.3">ğ‘</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.2">ğ’</ci><apply id="S3.E6.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.3"><times id="S3.E6.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E6.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.3.2">ğº</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.3.3">ğ‘‡</ci></apply></apply></apply><apply id="S3.E6.m1.3.3.3.3.cmml" xref="S3.E6.m1.3.3.3.3"><times id="S3.E6.m1.3.3.3.3.3.cmml" xref="S3.E6.m1.3.3.3.3.3"></times><apply id="S3.E6.m1.2.2.2.2.1.1.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1"><minus id="S3.E6.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1"></minus><cn type="integer" id="S3.E6.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.2">1</cn><ci id="S3.E6.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.3">ğ›¼</ci></apply><apply id="S3.E6.m1.3.3.3.3.4.cmml" xref="S3.E6.m1.3.3.3.3.4"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.3.4.1.cmml" xref="S3.E6.m1.3.3.3.3.4">subscript</csymbol><ci id="S3.E6.m1.3.3.3.3.4.2.cmml" xref="S3.E6.m1.3.3.3.3.4.2">ğ‘“</ci><ci id="S3.E6.m1.3.3.3.3.4.3.cmml" xref="S3.E6.m1.3.3.3.3.4.3">ğ‘›</ci></apply><apply id="S3.E6.m1.3.3.3.3.2.1.1.cmml" xref="S3.E6.m1.3.3.3.3.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.3.2.1.1.1.cmml" xref="S3.E6.m1.3.3.3.3.2.1">subscript</csymbol><ci id="S3.E6.m1.3.3.3.3.2.1.1.2.cmml" xref="S3.E6.m1.3.3.3.3.2.1.1.2">ğ</ci><apply id="S3.E6.m1.3.3.3.3.2.1.1.3.cmml" xref="S3.E6.m1.3.3.3.3.2.1.1.3"><times id="S3.E6.m1.3.3.3.3.2.1.1.3.1.cmml" xref="S3.E6.m1.3.3.3.3.2.1.1.3.1"></times><ci id="S3.E6.m1.3.3.3.3.2.1.1.3.2.cmml" xref="S3.E6.m1.3.3.3.3.2.1.1.3.2">ğº</ci><ci id="S3.E6.m1.3.3.3.3.2.1.1.3.3.cmml" xref="S3.E6.m1.3.3.3.3.2.1.1.3.3">ğ‘‡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.3c">\mathbf{\tilde{P}}=\mathbf{P}_{GT}+\alpha f_{p}(\mathbf{S}_{GT})+(1-\alpha)f_{n}(\mathbf{P}_{GT})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p2.7" class="ltx_p">where <math id="S3.SS4.p2.1.m1.2" class="ltx_Math" alttext="\alpha\in\{0,1\}" display="inline"><semantics id="S3.SS4.p2.1.m1.2a"><mrow id="S3.SS4.p2.1.m1.2.3" xref="S3.SS4.p2.1.m1.2.3.cmml"><mi id="S3.SS4.p2.1.m1.2.3.2" xref="S3.SS4.p2.1.m1.2.3.2.cmml">Î±</mi><mo id="S3.SS4.p2.1.m1.2.3.1" xref="S3.SS4.p2.1.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS4.p2.1.m1.2.3.3.2" xref="S3.SS4.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p2.1.m1.2.3.3.2.1" xref="S3.SS4.p2.1.m1.2.3.3.1.cmml">{</mo><mn id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">0</mn><mo id="S3.SS4.p2.1.m1.2.3.3.2.2" xref="S3.SS4.p2.1.m1.2.3.3.1.cmml">,</mo><mn id="S3.SS4.p2.1.m1.2.2" xref="S3.SS4.p2.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS4.p2.1.m1.2.3.3.2.3" xref="S3.SS4.p2.1.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.2b"><apply id="S3.SS4.p2.1.m1.2.3.cmml" xref="S3.SS4.p2.1.m1.2.3"><in id="S3.SS4.p2.1.m1.2.3.1.cmml" xref="S3.SS4.p2.1.m1.2.3.1"></in><ci id="S3.SS4.p2.1.m1.2.3.2.cmml" xref="S3.SS4.p2.1.m1.2.3.2">ğ›¼</ci><set id="S3.SS4.p2.1.m1.2.3.3.1.cmml" xref="S3.SS4.p2.1.m1.2.3.3.2"><cn type="integer" id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">0</cn><cn type="integer" id="S3.SS4.p2.1.m1.2.2.cmml" xref="S3.SS4.p2.1.m1.2.2">1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.2c">\alpha\in\{0,1\}</annotation></semantics></math> corresponds to the generation of negative and positive queries, respectively. <math id="S3.SS4.p2.2.m2.2" class="ltx_Math" alttext="\mathbf{P}_{GT},\mathbf{S}_{GT}\in\mathbb{R}^{3}" display="inline"><semantics id="S3.SS4.p2.2.m2.2a"><mrow id="S3.SS4.p2.2.m2.2.2" xref="S3.SS4.p2.2.m2.2.2.cmml"><mrow id="S3.SS4.p2.2.m2.2.2.2.2" xref="S3.SS4.p2.2.m2.2.2.2.3.cmml"><msub id="S3.SS4.p2.2.m2.1.1.1.1.1" xref="S3.SS4.p2.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS4.p2.2.m2.1.1.1.1.1.2" xref="S3.SS4.p2.2.m2.1.1.1.1.1.2.cmml">ğ</mi><mrow id="S3.SS4.p2.2.m2.1.1.1.1.1.3" xref="S3.SS4.p2.2.m2.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p2.2.m2.1.1.1.1.1.3.2" xref="S3.SS4.p2.2.m2.1.1.1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.2.m2.1.1.1.1.1.3.1" xref="S3.SS4.p2.2.m2.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.2.m2.1.1.1.1.1.3.3" xref="S3.SS4.p2.2.m2.1.1.1.1.1.3.3.cmml">T</mi></mrow></msub><mo id="S3.SS4.p2.2.m2.2.2.2.2.3" xref="S3.SS4.p2.2.m2.2.2.2.3.cmml">,</mo><msub id="S3.SS4.p2.2.m2.2.2.2.2.2" xref="S3.SS4.p2.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS4.p2.2.m2.2.2.2.2.2.2" xref="S3.SS4.p2.2.m2.2.2.2.2.2.2.cmml">ğ’</mi><mrow id="S3.SS4.p2.2.m2.2.2.2.2.2.3" xref="S3.SS4.p2.2.m2.2.2.2.2.2.3.cmml"><mi id="S3.SS4.p2.2.m2.2.2.2.2.2.3.2" xref="S3.SS4.p2.2.m2.2.2.2.2.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.2.m2.2.2.2.2.2.3.1" xref="S3.SS4.p2.2.m2.2.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.2.m2.2.2.2.2.2.3.3" xref="S3.SS4.p2.2.m2.2.2.2.2.2.3.3.cmml">T</mi></mrow></msub></mrow><mo id="S3.SS4.p2.2.m2.2.2.3" xref="S3.SS4.p2.2.m2.2.2.3.cmml">âˆˆ</mo><msup id="S3.SS4.p2.2.m2.2.2.4" xref="S3.SS4.p2.2.m2.2.2.4.cmml"><mi id="S3.SS4.p2.2.m2.2.2.4.2" xref="S3.SS4.p2.2.m2.2.2.4.2.cmml">â„</mi><mn id="S3.SS4.p2.2.m2.2.2.4.3" xref="S3.SS4.p2.2.m2.2.2.4.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.2b"><apply id="S3.SS4.p2.2.m2.2.2.cmml" xref="S3.SS4.p2.2.m2.2.2"><in id="S3.SS4.p2.2.m2.2.2.3.cmml" xref="S3.SS4.p2.2.m2.2.2.3"></in><list id="S3.SS4.p2.2.m2.2.2.2.3.cmml" xref="S3.SS4.p2.2.m2.2.2.2.2"><apply id="S3.SS4.p2.2.m2.1.1.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p2.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS4.p2.2.m2.1.1.1.1.1.2">ğ</ci><apply id="S3.SS4.p2.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS4.p2.2.m2.1.1.1.1.1.3"><times id="S3.SS4.p2.2.m2.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p2.2.m2.1.1.1.1.1.3.1"></times><ci id="S3.SS4.p2.2.m2.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p2.2.m2.1.1.1.1.1.3.2">ğº</ci><ci id="S3.SS4.p2.2.m2.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p2.2.m2.1.1.1.1.1.3.3">ğ‘‡</ci></apply></apply><apply id="S3.SS4.p2.2.m2.2.2.2.2.2.cmml" xref="S3.SS4.p2.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS4.p2.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS4.p2.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS4.p2.2.m2.2.2.2.2.2.2">ğ’</ci><apply id="S3.SS4.p2.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS4.p2.2.m2.2.2.2.2.2.3"><times id="S3.SS4.p2.2.m2.2.2.2.2.2.3.1.cmml" xref="S3.SS4.p2.2.m2.2.2.2.2.2.3.1"></times><ci id="S3.SS4.p2.2.m2.2.2.2.2.2.3.2.cmml" xref="S3.SS4.p2.2.m2.2.2.2.2.2.3.2">ğº</ci><ci id="S3.SS4.p2.2.m2.2.2.2.2.2.3.3.cmml" xref="S3.SS4.p2.2.m2.2.2.2.2.2.3.3">ğ‘‡</ci></apply></apply></list><apply id="S3.SS4.p2.2.m2.2.2.4.cmml" xref="S3.SS4.p2.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.2.2.4.1.cmml" xref="S3.SS4.p2.2.m2.2.2.4">superscript</csymbol><ci id="S3.SS4.p2.2.m2.2.2.4.2.cmml" xref="S3.SS4.p2.2.m2.2.2.4.2">â„</ci><cn type="integer" id="S3.SS4.p2.2.m2.2.2.4.3.cmml" xref="S3.SS4.p2.2.m2.2.2.4.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.2c">\mathbf{P}_{GT},\mathbf{S}_{GT}\in\mathbb{R}^{3}</annotation></semantics></math> represents 3D center <math id="S3.SS4.p2.3.m3.3" class="ltx_Math" alttext="(x,y,z)" display="inline"><semantics id="S3.SS4.p2.3.m3.3a"><mrow id="S3.SS4.p2.3.m3.3.4.2" xref="S3.SS4.p2.3.m3.3.4.1.cmml"><mo stretchy="false" id="S3.SS4.p2.3.m3.3.4.2.1" xref="S3.SS4.p2.3.m3.3.4.1.cmml">(</mo><mi id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml">x</mi><mo id="S3.SS4.p2.3.m3.3.4.2.2" xref="S3.SS4.p2.3.m3.3.4.1.cmml">,</mo><mi id="S3.SS4.p2.3.m3.2.2" xref="S3.SS4.p2.3.m3.2.2.cmml">y</mi><mo id="S3.SS4.p2.3.m3.3.4.2.3" xref="S3.SS4.p2.3.m3.3.4.1.cmml">,</mo><mi id="S3.SS4.p2.3.m3.3.3" xref="S3.SS4.p2.3.m3.3.3.cmml">z</mi><mo stretchy="false" id="S3.SS4.p2.3.m3.3.4.2.4" xref="S3.SS4.p2.3.m3.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.3b"><vector id="S3.SS4.p2.3.m3.3.4.1.cmml" xref="S3.SS4.p2.3.m3.3.4.2"><ci id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1">ğ‘¥</ci><ci id="S3.SS4.p2.3.m3.2.2.cmml" xref="S3.SS4.p2.3.m3.2.2">ğ‘¦</ci><ci id="S3.SS4.p2.3.m3.3.3.cmml" xref="S3.SS4.p2.3.m3.3.3">ğ‘§</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.3c">(x,y,z)</annotation></semantics></math> and box scale <math id="S3.SS4.p2.4.m4.3" class="ltx_Math" alttext="(w,l,h)" display="inline"><semantics id="S3.SS4.p2.4.m4.3a"><mrow id="S3.SS4.p2.4.m4.3.4.2" xref="S3.SS4.p2.4.m4.3.4.1.cmml"><mo stretchy="false" id="S3.SS4.p2.4.m4.3.4.2.1" xref="S3.SS4.p2.4.m4.3.4.1.cmml">(</mo><mi id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml">w</mi><mo id="S3.SS4.p2.4.m4.3.4.2.2" xref="S3.SS4.p2.4.m4.3.4.1.cmml">,</mo><mi id="S3.SS4.p2.4.m4.2.2" xref="S3.SS4.p2.4.m4.2.2.cmml">l</mi><mo id="S3.SS4.p2.4.m4.3.4.2.3" xref="S3.SS4.p2.4.m4.3.4.1.cmml">,</mo><mi id="S3.SS4.p2.4.m4.3.3" xref="S3.SS4.p2.4.m4.3.3.cmml">h</mi><mo stretchy="false" id="S3.SS4.p2.4.m4.3.4.2.4" xref="S3.SS4.p2.4.m4.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.3b"><vector id="S3.SS4.p2.4.m4.3.4.1.cmml" xref="S3.SS4.p2.4.m4.3.4.2"><ci id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1">ğ‘¤</ci><ci id="S3.SS4.p2.4.m4.2.2.cmml" xref="S3.SS4.p2.4.m4.2.2">ğ‘™</ci><ci id="S3.SS4.p2.4.m4.3.3.cmml" xref="S3.SS4.p2.4.m4.3.3">â„</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.3c">(w,l,h)</annotation></semantics></math> of GT, and <math id="S3.SS4.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{\tilde{P}}" display="inline"><semantics id="S3.SS4.p2.5.m5.1a"><mover accent="true" id="S3.SS4.p2.5.m5.1.1" xref="S3.SS4.p2.5.m5.1.1.cmml"><mi id="S3.SS4.p2.5.m5.1.1.2" xref="S3.SS4.p2.5.m5.1.1.2.cmml">ğ</mi><mo id="S3.SS4.p2.5.m5.1.1.1" xref="S3.SS4.p2.5.m5.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m5.1b"><apply id="S3.SS4.p2.5.m5.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1"><ci id="S3.SS4.p2.5.m5.1.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1.1">~</ci><ci id="S3.SS4.p2.5.m5.1.1.2.cmml" xref="S3.SS4.p2.5.m5.1.1.2">ğ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.5.m5.1c">\mathbf{\tilde{P}}</annotation></semantics></math> is noisy coordinates. We use functions <math id="S3.SS4.p2.6.m6.1" class="ltx_Math" alttext="f_{p}" display="inline"><semantics id="S3.SS4.p2.6.m6.1a"><msub id="S3.SS4.p2.6.m6.1.1" xref="S3.SS4.p2.6.m6.1.1.cmml"><mi id="S3.SS4.p2.6.m6.1.1.2" xref="S3.SS4.p2.6.m6.1.1.2.cmml">f</mi><mi id="S3.SS4.p2.6.m6.1.1.3" xref="S3.SS4.p2.6.m6.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.6.m6.1b"><apply id="S3.SS4.p2.6.m6.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.6.m6.1.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS4.p2.6.m6.1.1.2.cmml" xref="S3.SS4.p2.6.m6.1.1.2">ğ‘“</ci><ci id="S3.SS4.p2.6.m6.1.1.3.cmml" xref="S3.SS4.p2.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.6.m6.1c">f_{p}</annotation></semantics></math> and <math id="S3.SS4.p2.7.m7.1" class="ltx_Math" alttext="f_{n}" display="inline"><semantics id="S3.SS4.p2.7.m7.1a"><msub id="S3.SS4.p2.7.m7.1.1" xref="S3.SS4.p2.7.m7.1.1.cmml"><mi id="S3.SS4.p2.7.m7.1.1.2" xref="S3.SS4.p2.7.m7.1.1.2.cmml">f</mi><mi id="S3.SS4.p2.7.m7.1.1.3" xref="S3.SS4.p2.7.m7.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.7.m7.1b"><apply id="S3.SS4.p2.7.m7.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.7.m7.1.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS4.p2.7.m7.1.1.2.cmml" xref="S3.SS4.p2.7.m7.1.1.2">ğ‘“</ci><ci id="S3.SS4.p2.7.m7.1.1.3.cmml" xref="S3.SS4.p2.7.m7.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.7.m7.1c">f_{n}</annotation></semantics></math> to encode position-aware noise for positive and negative samples.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.6" class="ltx_p">For positive noisy samples, we set <math id="S3.SS4.p3.1.m1.1" class="ltx_Math" alttext="f_{p}(\mathbf{S}_{GT})" display="inline"><semantics id="S3.SS4.p3.1.m1.1a"><mrow id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml"><msub id="S3.SS4.p3.1.m1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.3.cmml"><mi id="S3.SS4.p3.1.m1.1.1.3.2" xref="S3.SS4.p3.1.m1.1.1.3.2.cmml">f</mi><mi id="S3.SS4.p3.1.m1.1.1.3.3" xref="S3.SS4.p3.1.m1.1.1.3.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS4.p3.1.m1.1.1.1.1" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.p3.1.m1.1.1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS4.p3.1.m1.1.1.1.1.1" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS4.p3.1.m1.1.1.1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.1.1.1.2.cmml">ğ’</mi><mrow id="S3.SS4.p3.1.m1.1.1.1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p3.1.m1.1.1.1.1.1.3.2" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.1.1.1.3.1" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.1.m1.1.1.1.1.1.3.3" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.3.cmml">T</mi></mrow></msub><mo stretchy="false" id="S3.SS4.p3.1.m1.1.1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><apply id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1"><times id="S3.SS4.p3.1.m1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.2"></times><apply id="S3.SS4.p3.1.m1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.1.m1.1.1.3.1.cmml" xref="S3.SS4.p3.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS4.p3.1.m1.1.1.3.2.cmml" xref="S3.SS4.p3.1.m1.1.1.3.2">ğ‘“</ci><ci id="S3.SS4.p3.1.m1.1.1.3.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3.3">ğ‘</ci></apply><apply id="S3.SS4.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.2">ğ’</ci><apply id="S3.SS4.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3"><times id="S3.SS4.p3.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.1"></times><ci id="S3.SS4.p3.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.2">ğº</ci><ci id="S3.SS4.p3.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p3.1.m1.1.1.1.1.1.3.3">ğ‘‡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">f_{p}(\mathbf{S}_{GT})</annotation></semantics></math> as a linear function of 3D box scale with a random variable.
We incorporate the offset constraint within GT boxes to guide the model in accurately reconstructing the GT from positive queries, while ensuring clear distinction from surrounding adjacent boxes.
For negative samples, the offsets are supposed to be relevant to their position range, thus we propose several implementations. For some examples, <math id="S3.SS4.p3.2.m2.1" class="ltx_Math" alttext="f_{n}(\mathbf{P}_{GT})" display="inline"><semantics id="S3.SS4.p3.2.m2.1a"><mrow id="S3.SS4.p3.2.m2.1.1" xref="S3.SS4.p3.2.m2.1.1.cmml"><msub id="S3.SS4.p3.2.m2.1.1.3" xref="S3.SS4.p3.2.m2.1.1.3.cmml"><mi id="S3.SS4.p3.2.m2.1.1.3.2" xref="S3.SS4.p3.2.m2.1.1.3.2.cmml">f</mi><mi id="S3.SS4.p3.2.m2.1.1.3.3" xref="S3.SS4.p3.2.m2.1.1.3.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p3.2.m2.1.1.2" xref="S3.SS4.p3.2.m2.1.1.2.cmml">â€‹</mo><mrow id="S3.SS4.p3.2.m2.1.1.1.1" xref="S3.SS4.p3.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.p3.2.m2.1.1.1.1.2" xref="S3.SS4.p3.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S3.SS4.p3.2.m2.1.1.1.1.1" xref="S3.SS4.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS4.p3.2.m2.1.1.1.1.1.2" xref="S3.SS4.p3.2.m2.1.1.1.1.1.2.cmml">ğ</mi><mrow id="S3.SS4.p3.2.m2.1.1.1.1.1.3" xref="S3.SS4.p3.2.m2.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p3.2.m2.1.1.1.1.1.3.2" xref="S3.SS4.p3.2.m2.1.1.1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.2.m2.1.1.1.1.1.3.1" xref="S3.SS4.p3.2.m2.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.2.m2.1.1.1.1.1.3.3" xref="S3.SS4.p3.2.m2.1.1.1.1.1.3.3.cmml">T</mi></mrow></msub><mo stretchy="false" id="S3.SS4.p3.2.m2.1.1.1.1.3" xref="S3.SS4.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m2.1b"><apply id="S3.SS4.p3.2.m2.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1"><times id="S3.SS4.p3.2.m2.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.2"></times><apply id="S3.SS4.p3.2.m2.1.1.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m2.1.1.3.1.cmml" xref="S3.SS4.p3.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS4.p3.2.m2.1.1.3.2.cmml" xref="S3.SS4.p3.2.m2.1.1.3.2">ğ‘“</ci><ci id="S3.SS4.p3.2.m2.1.1.3.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3.3">ğ‘›</ci></apply><apply id="S3.SS4.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.2">ğ</ci><apply id="S3.SS4.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.3"><times id="S3.SS4.p3.2.m2.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.3.1"></times><ci id="S3.SS4.p3.2.m2.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.3.2">ğº</ci><ci id="S3.SS4.p3.2.m2.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.3.3">ğ‘‡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m2.1c">f_{n}(\mathbf{P}_{GT})</annotation></semantics></math> can be in forms of <math id="S3.SS4.p3.3.m3.1" class="ltx_Math" alttext="log(\mathbf{P}_{GT})" display="inline"><semantics id="S3.SS4.p3.3.m3.1a"><mrow id="S3.SS4.p3.3.m3.1.1" xref="S3.SS4.p3.3.m3.1.1.cmml"><mi id="S3.SS4.p3.3.m3.1.1.3" xref="S3.SS4.p3.3.m3.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.3.m3.1.1.2" xref="S3.SS4.p3.3.m3.1.1.2.cmml">â€‹</mo><mi id="S3.SS4.p3.3.m3.1.1.4" xref="S3.SS4.p3.3.m3.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.3.m3.1.1.2a" xref="S3.SS4.p3.3.m3.1.1.2.cmml">â€‹</mo><mi id="S3.SS4.p3.3.m3.1.1.5" xref="S3.SS4.p3.3.m3.1.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.3.m3.1.1.2b" xref="S3.SS4.p3.3.m3.1.1.2.cmml">â€‹</mo><mrow id="S3.SS4.p3.3.m3.1.1.1.1" xref="S3.SS4.p3.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.p3.3.m3.1.1.1.1.2" xref="S3.SS4.p3.3.m3.1.1.1.1.1.cmml">(</mo><msub id="S3.SS4.p3.3.m3.1.1.1.1.1" xref="S3.SS4.p3.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS4.p3.3.m3.1.1.1.1.1.2" xref="S3.SS4.p3.3.m3.1.1.1.1.1.2.cmml">ğ</mi><mrow id="S3.SS4.p3.3.m3.1.1.1.1.1.3" xref="S3.SS4.p3.3.m3.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p3.3.m3.1.1.1.1.1.3.2" xref="S3.SS4.p3.3.m3.1.1.1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.3.m3.1.1.1.1.1.3.1" xref="S3.SS4.p3.3.m3.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.3.m3.1.1.1.1.1.3.3" xref="S3.SS4.p3.3.m3.1.1.1.1.1.3.3.cmml">T</mi></mrow></msub><mo stretchy="false" id="S3.SS4.p3.3.m3.1.1.1.1.3" xref="S3.SS4.p3.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m3.1b"><apply id="S3.SS4.p3.3.m3.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1"><times id="S3.SS4.p3.3.m3.1.1.2.cmml" xref="S3.SS4.p3.3.m3.1.1.2"></times><ci id="S3.SS4.p3.3.m3.1.1.3.cmml" xref="S3.SS4.p3.3.m3.1.1.3">ğ‘™</ci><ci id="S3.SS4.p3.3.m3.1.1.4.cmml" xref="S3.SS4.p3.3.m3.1.1.4">ğ‘œ</ci><ci id="S3.SS4.p3.3.m3.1.1.5.cmml" xref="S3.SS4.p3.3.m3.1.1.5">ğ‘”</ci><apply id="S3.SS4.p3.3.m3.1.1.1.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p3.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.3.m3.1.1.1.1.1.2">ğ</ci><apply id="S3.SS4.p3.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS4.p3.3.m3.1.1.1.1.1.3"><times id="S3.SS4.p3.3.m3.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p3.3.m3.1.1.1.1.1.3.1"></times><ci id="S3.SS4.p3.3.m3.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p3.3.m3.1.1.1.1.1.3.2">ğº</ci><ci id="S3.SS4.p3.3.m3.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p3.3.m3.1.1.1.1.1.3.3">ğ‘‡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m3.1c">log(\mathbf{P}_{GT})</annotation></semantics></math>, <math id="S3.SS4.p3.4.m4.1" class="ltx_Math" alttext="\lambda_{2}\mathbf{P}_{GT}" display="inline"><semantics id="S3.SS4.p3.4.m4.1a"><mrow id="S3.SS4.p3.4.m4.1.1" xref="S3.SS4.p3.4.m4.1.1.cmml"><msub id="S3.SS4.p3.4.m4.1.1.2" xref="S3.SS4.p3.4.m4.1.1.2.cmml"><mi id="S3.SS4.p3.4.m4.1.1.2.2" xref="S3.SS4.p3.4.m4.1.1.2.2.cmml">Î»</mi><mn id="S3.SS4.p3.4.m4.1.1.2.3" xref="S3.SS4.p3.4.m4.1.1.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p3.4.m4.1.1.1" xref="S3.SS4.p3.4.m4.1.1.1.cmml">â€‹</mo><msub id="S3.SS4.p3.4.m4.1.1.3" xref="S3.SS4.p3.4.m4.1.1.3.cmml"><mi id="S3.SS4.p3.4.m4.1.1.3.2" xref="S3.SS4.p3.4.m4.1.1.3.2.cmml">ğ</mi><mrow id="S3.SS4.p3.4.m4.1.1.3.3" xref="S3.SS4.p3.4.m4.1.1.3.3.cmml"><mi id="S3.SS4.p3.4.m4.1.1.3.3.2" xref="S3.SS4.p3.4.m4.1.1.3.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.4.m4.1.1.3.3.1" xref="S3.SS4.p3.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.4.m4.1.1.3.3.3" xref="S3.SS4.p3.4.m4.1.1.3.3.3.cmml">T</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.4.m4.1b"><apply id="S3.SS4.p3.4.m4.1.1.cmml" xref="S3.SS4.p3.4.m4.1.1"><times id="S3.SS4.p3.4.m4.1.1.1.cmml" xref="S3.SS4.p3.4.m4.1.1.1"></times><apply id="S3.SS4.p3.4.m4.1.1.2.cmml" xref="S3.SS4.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p3.4.m4.1.1.2.1.cmml" xref="S3.SS4.p3.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS4.p3.4.m4.1.1.2.2.cmml" xref="S3.SS4.p3.4.m4.1.1.2.2">ğœ†</ci><cn type="integer" id="S3.SS4.p3.4.m4.1.1.2.3.cmml" xref="S3.SS4.p3.4.m4.1.1.2.3">2</cn></apply><apply id="S3.SS4.p3.4.m4.1.1.3.cmml" xref="S3.SS4.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.4.m4.1.1.3.1.cmml" xref="S3.SS4.p3.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS4.p3.4.m4.1.1.3.2.cmml" xref="S3.SS4.p3.4.m4.1.1.3.2">ğ</ci><apply id="S3.SS4.p3.4.m4.1.1.3.3.cmml" xref="S3.SS4.p3.4.m4.1.1.3.3"><times id="S3.SS4.p3.4.m4.1.1.3.3.1.cmml" xref="S3.SS4.p3.4.m4.1.1.3.3.1"></times><ci id="S3.SS4.p3.4.m4.1.1.3.3.2.cmml" xref="S3.SS4.p3.4.m4.1.1.3.3.2">ğº</ci><ci id="S3.SS4.p3.4.m4.1.1.3.3.3.cmml" xref="S3.SS4.p3.4.m4.1.1.3.3.3">ğ‘‡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.4.m4.1c">\lambda_{2}\mathbf{P}_{GT}</annotation></semantics></math> or <math id="S3.SS4.p3.5.m5.1" class="ltx_Math" alttext="\sqrt{\mathbf{P}_{GT}}" display="inline"><semantics id="S3.SS4.p3.5.m5.1a"><msqrt id="S3.SS4.p3.5.m5.1.1" xref="S3.SS4.p3.5.m5.1.1.cmml"><msub id="S3.SS4.p3.5.m5.1.1.2" xref="S3.SS4.p3.5.m5.1.1.2.cmml"><mi id="S3.SS4.p3.5.m5.1.1.2.2" xref="S3.SS4.p3.5.m5.1.1.2.2.cmml">ğ</mi><mrow id="S3.SS4.p3.5.m5.1.1.2.3" xref="S3.SS4.p3.5.m5.1.1.2.3.cmml"><mi id="S3.SS4.p3.5.m5.1.1.2.3.2" xref="S3.SS4.p3.5.m5.1.1.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.1.1.2.3.1" xref="S3.SS4.p3.5.m5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.1.1.2.3.3" xref="S3.SS4.p3.5.m5.1.1.2.3.3.cmml">T</mi></mrow></msub></msqrt><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.5.m5.1b"><apply id="S3.SS4.p3.5.m5.1.1.cmml" xref="S3.SS4.p3.5.m5.1.1"><root id="S3.SS4.p3.5.m5.1.1a.cmml" xref="S3.SS4.p3.5.m5.1.1"></root><apply id="S3.SS4.p3.5.m5.1.1.2.cmml" xref="S3.SS4.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p3.5.m5.1.1.2.1.cmml" xref="S3.SS4.p3.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS4.p3.5.m5.1.1.2.2.cmml" xref="S3.SS4.p3.5.m5.1.1.2.2">ğ</ci><apply id="S3.SS4.p3.5.m5.1.1.2.3.cmml" xref="S3.SS4.p3.5.m5.1.1.2.3"><times id="S3.SS4.p3.5.m5.1.1.2.3.1.cmml" xref="S3.SS4.p3.5.m5.1.1.2.3.1"></times><ci id="S3.SS4.p3.5.m5.1.1.2.3.2.cmml" xref="S3.SS4.p3.5.m5.1.1.2.3.2">ğº</ci><ci id="S3.SS4.p3.5.m5.1.1.2.3.3.cmml" xref="S3.SS4.p3.5.m5.1.1.2.3.3">ğ‘‡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.5.m5.1c">\sqrt{\mathbf{P}_{GT}}</annotation></semantics></math>. We show these attempts in Sec.Â <a href="#S4.SS4" title="4.4 Ablation Study &amp; Analysis â€£ 4 Experiment â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.
Moreover, multi-group samples are generated for each GT object to enhance query diversity. Each group comprises one positive sample and <math id="S3.SS4.p3.6.m6.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p3.6.m6.1a"><mi id="S3.SS4.p3.6.m6.1.1" xref="S3.SS4.p3.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.6.m6.1b"><ci id="S3.SS4.p3.6.m6.1.1.cmml" xref="S3.SS4.p3.6.m6.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.6.m6.1c">K</annotation></semantics></math> negative samples. This approach serves as an imitation of noisy positive candidates and false positive candidates during training.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2308.09616/assets/x3.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="387" height="105" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>3D Recall and AP of each method with different distance thresholds. Metrics of different ranges show that our approach consistently achieves a better result.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets and Metrics</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We use the large-scale Argoverse 2 datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Wilson etÂ al. <a href="#bib.bib35" title="" class="ltx_ref">2023</a>)</cite> and nuScenes datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Caesar etÂ al. <a href="#bib.bib1" title="" class="ltx_ref">2020</a>)</cite> to explore and evaluate the effectiveness of our approach.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Argoverse 2</span> is a dataset for perception and prediction studies in the autonomous driving domain. It contains 1000 scenes with 15 seconds duration and 10Hz annotation frequency for each scene. And these total scenes are divided into 700 for training, 150 for validation, and 150 for testing. Seven high-resolution ring cameras are provided with a combined 360Â° field of view.
We evaluate it with 26 categories and a 150-meter range, satisfying the need for long-range tasks.
In addition to the mean Average Precision (mAP), we evaluate the methods with the metrics that Argoverse 2 dataset proposed: the Composite Detection Score (CDS), which is the main metric combining all factors in Argoverse 2 dataset, and three true positive metrics, including ATE, ASE, and AOE.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">nuScenes</span> is one of the most trustworthy datasets for multi-camera 3D object detection containing 1000 driving scenes in total. Each scene, approximately 20 seconds long, is annotated in 10 categories with 3D bounding boxes for sampled keyframes. We further conduct experiments on the dataset and compare the results with other methods using the following metrics, including mAP and the nuScenes Detection Score (NDS).</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation of our components on Argoverse 2 <span id="S4.T3.4.1" class="ltx_text ltx_font_typewriter">val</span> set. StreamPETR is employed as the baseline, and we add the adaptive query, perspective-aware aggregation (PA) and range-modulated 3D denoising in order.</figcaption>
<div id="S4.T3.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:242.8pt;height:77.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-20.3pt,6.4pt) scale(0.856859753700852,0.856859753700852) ;">
<table id="S4.T3.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.2.2.2" class="ltx_tr">
<th id="S4.T3.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">#</th>
<th id="S4.T3.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.2.4.1" class="ltx_text ltx_font_bold">Adaptive Query</span></th>
<th id="S4.T3.2.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.2.5.1" class="ltx_text ltx_font_bold">PA</span></th>
<th id="S4.T3.2.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.2.6.1" class="ltx_text ltx_font_bold">3D Denoising</span></th>
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">mAP[%]<math id="S4.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T3.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S4.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.2.2.1" class="ltx_text ltx_font_bold">CDS[%]<math id="S4.T3.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T3.2.2.2.2.1.m1.1.1" xref="S4.T3.2.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.1.m1.1b"><ci id="S4.T3.2.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.2.2.3.1" class="ltx_tr">
<th id="S4.T3.2.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">1</th>
<td id="S4.T3.2.2.3.1.2" class="ltx_td ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="S4.T3.2.2.3.1.3" class="ltx_td ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="S4.T3.2.2.3.1.4" class="ltx_td ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="S4.T3.2.2.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">20.3</td>
<td id="S4.T3.2.2.3.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">14.6</td>
</tr>
<tr id="S4.T3.2.2.4.2" class="ltx_tr">
<th id="S4.T3.2.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">2</th>
<td id="S4.T3.2.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">âœ”</td>
<td id="S4.T3.2.2.4.2.3" class="ltx_td ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="S4.T3.2.2.4.2.4" class="ltx_td ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="S4.T3.2.2.4.2.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">22.4</td>
<td id="S4.T3.2.2.4.2.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">16.1</td>
</tr>
<tr id="S4.T3.2.2.5.3" class="ltx_tr">
<th id="S4.T3.2.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">3</th>
<td id="S4.T3.2.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">âœ”</td>
<td id="S4.T3.2.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">âœ”</td>
<td id="S4.T3.2.2.5.3.4" class="ltx_td ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="S4.T3.2.2.5.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">23.4</td>
<td id="S4.T3.2.2.5.3.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">17.3</td>
</tr>
<tr id="S4.T3.2.2.6.4" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S4.T3.2.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.6.4.1.1" class="ltx_text" style="background-color:#E6E6E6;">4</span></th>
<td id="S4.T3.2.2.6.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.6.4.2.1" class="ltx_text" style="background-color:#E6E6E6;">âœ”</span></td>
<td id="S4.T3.2.2.6.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.6.4.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ”</span></td>
<td id="S4.T3.2.2.6.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.6.4.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ”</span></td>
<td id="S4.T3.2.2.6.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.6.4.5.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">24.4<span id="S4.T3.2.2.6.4.5.1.1" class="ltx_text ltx_font_medium"> (+4.1)</span></span></td>
<td id="S4.T3.2.2.6.4.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.2.2.6.4.6.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">18.1<span id="S4.T3.2.2.6.4.6.1.1" class="ltx_text ltx_font_medium"> (+3.5)</span></span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation Details</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">With StreamPETRÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023a</a>)</cite> as our baseline,
Far3D is composed of a backbone, an FPN neck, a 2D proposal head, and a 3D detection head. We adopt VoVNet-99Â <cite class="ltx_cite ltx_citemacro_citep">(Lee etÂ al. <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> pre-trained with FCOS3DÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib32" title="" class="ltx_ref">2021</a>)</cite> on nuScenes as the backbone to conduct main experiments. ViT-LargeÂ <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy etÂ al. <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> pre-trained by Objects365Â <cite class="ltx_cite ltx_citemacro_citep">(Shao etÂ al. <a href="#bib.bib28" title="" class="ltx_ref">2019</a>)</cite> and COCOÂ <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al. <a href="#bib.bib18" title="" class="ltx_ref">2014</a>)</cite> dataset is used to scale up our model. By default, the FPN gives 4-level feature maps with sizes of 1/8, 1/16, 1/32, and 1/64. The perception range is set as 152.4m <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mo id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><times id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\times</annotation></semantics></math> 152.4m.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">We use AdamWÂ <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov and Hutter <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite> optimizer with a weight decay of 0.01. The total batch size is 8 and the learning rate is set to 2e-4.
The models are totally trained for 6 epochs, following the previous methodÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al. <a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>. Since the resolution of the front-view image is different from other views in Argoverse 2 dataset, we first resize the front image to a consistent resolution, then do the same image data augmentation as other images do. We do not use any BEV data augmentation on Argoverse 2 dataset. On the nuScenes dataset, we set the batch size as 32 and use the ResNet101Â <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al. <a href="#bib.bib7" title="" class="ltx_ref">2016</a>)</cite> backbone to train our method for 60 epochs. Other settings keep in line with StreamPETR.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Main Results</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p"><span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_bold">Argoverse 2 Dataset.</span>
We compare the proposed framework with the existing state-of-the-arts on Argoverse 2 <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">val</span> set. As shown in Tab.Â <a href="#S3.T1" title="Table 1 â€£ 3.3 Perspective-aware Aggregation â€£ 3 Method â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, when adopting VoV-99 backbone and 960<math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mo id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><times id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\times</annotation></semantics></math>640 input size, our method demonstrates a substantial superiority over other methods, achieving an impressive margin of 4.1% mAP and 3.5% CDS.
Besides the listed sparse query-based methods, we also conduct experiments on dense BEV-based methods, BEVStereoÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al. <a href="#bib.bib14" title="" class="ltx_ref">2022b</a>)</cite> and SOLOFusionÂ <cite class="ltx_cite ltx_citemacro_citep">(Park etÂ al. <a href="#bib.bib25" title="" class="ltx_ref">2022</a>)</cite>. The results are barely satisfactory and we suppose that is because of the greater difficulty of depth estimation. We also reproduce MV2DÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib34" title="" class="ltx_ref">2023b</a>)</cite> but it can hardly converge here. The reason is mainly the generated anchors lack accurate depth estimation, leading to large localization deviations over long distances.
To sum up, the convergence problem in long-range detection is severe for the above methods, and we believe that our depth estimation and 3D denoising play key roles to solve it. More explanations are in the supplementary.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ablation study with different score threshold <math id="S4.T4.2.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.T4.2.m1.1b"><mi id="S4.T4.2.m1.1.1" xref="S4.T4.2.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.T4.2.m1.1c"><ci id="S4.T4.2.m1.1.1.cmml" xref="S4.T4.2.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.m1.1d">\tau</annotation></semantics></math> for 2D proposals.</figcaption>
<div id="S4.T4.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:242.8pt;height:105.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.6pt,1.1pt) scale(0.978802249148026,0.978802249148026) ;">
<table id="S4.T4.8.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.8.6.6" class="ltx_tr">
<th id="S4.T4.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S4.T4.3.1.1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.T4.3.1.1.1.m1.1a"><mi id="S4.T4.3.1.1.1.m1.1.1" xref="S4.T4.3.1.1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.T4.3.1.1.1.m1.1b"><ci id="S4.T4.3.1.1.1.m1.1.1.cmml" xref="S4.T4.3.1.1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.1.1.1.m1.1c">\tau</annotation></semantics></math></th>
<th id="S4.T4.4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.4.2.2.2.1" class="ltx_text ltx_font_bold">mAP[%]<math id="S4.T4.4.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.4.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T4.4.2.2.2.1.m1.1.1" xref="S4.T4.4.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.2.2.2.1.m1.1b"><ci id="S4.T4.4.2.2.2.1.m1.1.1.cmml" xref="S4.T4.4.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S4.T4.5.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.5.3.3.3.1" class="ltx_text ltx_font_bold">CDS[%]<math id="S4.T4.5.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.5.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T4.5.3.3.3.1.m1.1.1" xref="S4.T4.5.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T4.5.3.3.3.1.m1.1b"><ci id="S4.T4.5.3.3.3.1.m1.1.1.cmml" xref="S4.T4.5.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S4.T4.6.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.6.4.4.4.1" class="ltx_text ltx_font_bold">mATE<math id="S4.T4.6.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.6.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T4.6.4.4.4.1.m1.1.1" xref="S4.T4.6.4.4.4.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T4.6.4.4.4.1.m1.1b"><ci id="S4.T4.6.4.4.4.1.m1.1.1.cmml" xref="S4.T4.6.4.4.4.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S4.T4.7.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.7.5.5.5.1" class="ltx_text ltx_font_bold">mASE<math id="S4.T4.7.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.7.5.5.5.1.m1.1a"><mo stretchy="false" id="S4.T4.7.5.5.5.1.m1.1.1" xref="S4.T4.7.5.5.5.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T4.7.5.5.5.1.m1.1b"><ci id="S4.T4.7.5.5.5.1.m1.1.1.cmml" xref="S4.T4.7.5.5.5.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S4.T4.8.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.8.6.6.6.1" class="ltx_text ltx_font_bold">mAOE<math id="S4.T4.8.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.8.6.6.6.1.m1.1a"><mo stretchy="false" id="S4.T4.8.6.6.6.1.m1.1.1" xref="S4.T4.8.6.6.6.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T4.8.6.6.6.1.m1.1b"><ci id="S4.T4.8.6.6.6.1.m1.1.1.cmml" xref="S4.T4.8.6.6.6.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.8.6.7.1" class="ltx_tr">
<td id="S4.T4.8.6.7.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">0.01</td>
<td id="S4.T4.8.6.7.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">23.1</td>
<td id="S4.T4.8.6.7.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.2</td>
<td id="S4.T4.8.6.7.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">0.807</td>
<td id="S4.T4.8.6.7.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">0.307</td>
<td id="S4.T4.8.6.7.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">0.531</td>
</tr>
<tr id="S4.T4.8.6.8.2" class="ltx_tr">
<td id="S4.T4.8.6.8.2.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">0.05</td>
<td id="S4.T4.8.6.8.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.4</td>
<td id="S4.T4.8.6.8.2.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">17.3</td>
<td id="S4.T4.8.6.8.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.806</td>
<td id="S4.T4.8.6.8.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.312</td>
<td id="S4.T4.8.6.8.2.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.531</td>
</tr>
<tr id="S4.T4.8.6.9.3" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S4.T4.8.6.9.3.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.8.6.9.3.1.1" class="ltx_text" style="background-color:#E6E6E6;">0.1</span></td>
<td id="S4.T4.8.6.9.3.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.8.6.9.3.2.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">24.4</span></td>
<td id="S4.T4.8.6.9.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.8.6.9.3.3.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">18.1</span></td>
<td id="S4.T4.8.6.9.3.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.8.6.9.3.4.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.796</span></td>
<td id="S4.T4.8.6.9.3.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.8.6.9.3.5.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">0.304</span></td>
<td id="S4.T4.8.6.9.3.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.8.6.9.3.6.1" class="ltx_text" style="background-color:#E6E6E6;">0.538</span></td>
</tr>
<tr id="S4.T4.8.6.10.4" class="ltx_tr">
<td id="S4.T4.8.6.10.4.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">0.2</td>
<td id="S4.T4.8.6.10.4.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.7</td>
<td id="S4.T4.8.6.10.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">17.6</td>
<td id="S4.T4.8.6.10.4.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.802</td>
<td id="S4.T4.8.6.10.4.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.307</td>
<td id="S4.T4.8.6.10.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S4.T4.8.6.10.4.6.1" class="ltx_text ltx_font_bold">0.530</span></td>
</tr>
<tr id="S4.T4.8.6.11.5" class="ltx_tr">
<td id="S4.T4.8.6.11.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">0.3</td>
<td id="S4.T4.8.6.11.5.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">23.5</td>
<td id="S4.T4.8.6.11.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">17.4</td>
<td id="S4.T4.8.6.11.5.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">0.799</td>
<td id="S4.T4.8.6.11.5.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">0.307</td>
<td id="S4.T4.8.6.11.5.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">0.577</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">We further compare it with LiDAR-based SoTAs, CenterPointÂ <cite class="ltx_cite ltx_citemacro_citep">(Yin, Zhou, and Krahenbuhl <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite>, FSDÂ <cite class="ltx_cite ltx_citemacro_citep">(Fan etÂ al. <a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite>, and VoxelNeXtÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al. <a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>. With a ViT-L backbone and 1536<math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mo id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><times id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\times</annotation></semantics></math>1536 resolution, our method outperforms them, showcasing the great potential of surround-view methods. In detail, LiDAR-based methods have a lower localization error (i.e. ATE) due to accurate depth information, while surround-view ones identify orientation properties (i.e. AOE) better.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2308.09616/assets/x4.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="388" height="117" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Visualization results on Argoverse 2 dataset.
We show 3D bounding boxes predicted both in multi-camera images and birdâ€™s eye view.
As illustrated, the view of the front center is distinguished from the other six views. The detection boxes predicted from 3D adaptive queries and 3D global queries are drawn in blue and green respectively. The GTs in orange are presented in BEV only.</figcaption>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">As shown in Fig.Â <a href="#S4.F4" title="Figure 4 â€£ 4 Experiment â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we present the 3D recall and mAP results with different distances of 0-150m and 50-150m. Far3D consistently outperforms other methods. For distant objects, Far3D has a greater improvement when comparing recall and mAP with thresholds of 2m and 4m.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para ltx_noindent">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_bold">nuScenes Dataset.</span>
To evaluate the generalization ability of our approach, we conducted additional comparisons on nuScenes dataset, as shown in Tab.Â <a href="#S3.T2" title="Table 2 â€£ 3.3 Perspective-aware Aggregation â€£ 3 Method â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Notably, our method outperforms previous SoTA methods with impressive results, achieving 51.0% mAP and 59.4% NDS on the <span id="S4.SS3.p4.1.2" class="ltx_text ltx_font_typewriter">val</span> set and 63.5% mAP and 68.7% NDS on the <span id="S4.SS3.p4.1.3" class="ltx_text ltx_font_typewriter">test</span> set. These superior metrics specifically highlight its effectiveness.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Study &amp; Analysis</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In this section, we present a comprehensive analysis of the essential components of our model. As shown in Tab.Â <a href="#S4.T3" title="Table 3 â€£ 4.1 Datasets and Metrics â€£ 4 Experiment â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we start from StreamPETR as the baseline in #1 and add each module to verify its effect.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para ltx_noindent">
<p id="S4.SS4.p2.1" class="ltx_p"><span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_bold">Adaptive Query.</span>
Comparing #1 and #2 in Tab.Â <a href="#S4.T3" title="Table 3 â€£ 4.1 Datasets and Metrics â€£ 4 Experiment â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we can observe that adaptive query brings an improvement of 2.1% mAP and 1.5% CDS. Adaptive queries are insensitive to object range due to the robustness of 2D detectors in images, thus it is more suitable for general detection scenarios.
To choose the optimal score threshold of 2D proposals, we conduct experiments shown in Tab.Â <a href="#S4.T4" title="Table 4 â€£ 4.3 Main Results â€£ 4 Experiment â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Besides, we visualize the detection results in Fig.Â <a href="#S4.F5" title="Figure 5 â€£ 4.3 Main Results â€£ 4 Experiment â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and distinguish the boxes predicted from 3D adaptive queries and 3D global queries. The predictions from 3D adaptive queries cover a larger range, showing their indispensable significance.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para ltx_noindent">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">Perspective-aware Aggregation.</span> Adding the perspective-aware aggregation contributes a gain of 1.0% mAP and 1.2% CDS. Distant objects only occupy a few pixels on the image, therefore employing multi-level scales and views brings rich features according to different object locations.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance Comparison of negative denoising samples with different designs and numbers.</figcaption>
<div id="S4.T5.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:237.8pt;height:138.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-5.0pt,2.9pt) scale(0.959388645535405,0.959388645535405) ;">
<table id="S4.T5.8.8" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.2.2.2" class="ltx_tr">
<th id="S4.T5.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T5.2.2.2.3.1" class="ltx_text ltx_font_bold"># Negative sample</span></th>
<th id="S4.T5.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T5.2.2.2.4.1" class="ltx_text ltx_font_bold">Method</span></th>
<td id="S4.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T5.1.1.1.1.1" class="ltx_text ltx_font_bold">mAP[%]<math id="S4.T5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T5.1.1.1.1.1.m1.1.1" xref="S4.T5.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.1.1.m1.1b"><ci id="S4.T5.1.1.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T5.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T5.2.2.2.2.1" class="ltx_text ltx_font_bold">CDS[%]<math id="S4.T5.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T5.2.2.2.2.1.m1.1.1" xref="S4.T5.2.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.2.1.m1.1b"><ci id="S4.T5.2.2.2.2.1.m1.1.1.cmml" xref="S4.T5.2.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
</tr>
<tr id="S4.T5.8.8.9.1" class="ltx_tr">
<th id="S4.T5.8.8.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">0</th>
<th id="S4.T5.8.8.9.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">â€“</th>
<td id="S4.T5.8.8.9.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">23.4</td>
<td id="S4.T5.8.8.9.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">17.3</td>
</tr>
<tr id="S4.T5.3.3.3" class="ltx_tr">
<th id="S4.T5.3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">1</th>
<th id="S4.T5.3.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S4.T5.3.3.3.1.m1.1" class="ltx_Math" alttext="log(\cdot)" display="inline"><semantics id="S4.T5.3.3.3.1.m1.1a"><mrow id="S4.T5.3.3.3.1.m1.1.2" xref="S4.T5.3.3.3.1.m1.1.2.cmml"><mi id="S4.T5.3.3.3.1.m1.1.2.2" xref="S4.T5.3.3.3.1.m1.1.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.T5.3.3.3.1.m1.1.2.1" xref="S4.T5.3.3.3.1.m1.1.2.1.cmml">â€‹</mo><mi id="S4.T5.3.3.3.1.m1.1.2.3" xref="S4.T5.3.3.3.1.m1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.3.3.3.1.m1.1.2.1a" xref="S4.T5.3.3.3.1.m1.1.2.1.cmml">â€‹</mo><mi id="S4.T5.3.3.3.1.m1.1.2.4" xref="S4.T5.3.3.3.1.m1.1.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.T5.3.3.3.1.m1.1.2.1b" xref="S4.T5.3.3.3.1.m1.1.2.1.cmml">â€‹</mo><mrow id="S4.T5.3.3.3.1.m1.1.2.5.2" xref="S4.T5.3.3.3.1.m1.1.2.cmml"><mo stretchy="false" id="S4.T5.3.3.3.1.m1.1.2.5.2.1" xref="S4.T5.3.3.3.1.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.T5.3.3.3.1.m1.1.1" xref="S4.T5.3.3.3.1.m1.1.1.cmml">â‹…</mo><mo stretchy="false" id="S4.T5.3.3.3.1.m1.1.2.5.2.2" xref="S4.T5.3.3.3.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.1.m1.1b"><apply id="S4.T5.3.3.3.1.m1.1.2.cmml" xref="S4.T5.3.3.3.1.m1.1.2"><times id="S4.T5.3.3.3.1.m1.1.2.1.cmml" xref="S4.T5.3.3.3.1.m1.1.2.1"></times><ci id="S4.T5.3.3.3.1.m1.1.2.2.cmml" xref="S4.T5.3.3.3.1.m1.1.2.2">ğ‘™</ci><ci id="S4.T5.3.3.3.1.m1.1.2.3.cmml" xref="S4.T5.3.3.3.1.m1.1.2.3">ğ‘œ</ci><ci id="S4.T5.3.3.3.1.m1.1.2.4.cmml" xref="S4.T5.3.3.3.1.m1.1.2.4">ğ‘”</ci><ci id="S4.T5.3.3.3.1.m1.1.1.cmml" xref="S4.T5.3.3.3.1.m1.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.1.m1.1c">log(\cdot)</annotation></semantics></math></th>
<td id="S4.T5.3.3.3.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">24.0</td>
<td id="S4.T5.3.3.3.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">17.7</td>
</tr>
<tr id="S4.T5.4.4.4" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S4.T5.4.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T5.4.4.4.2.1" class="ltx_text" style="background-color:#E6E6E6;">2</span></th>
<th id="S4.T5.4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S4.T5.4.4.4.1.m1.1" class="ltx_Math" style="background-color:#E6E6E6;" alttext="log(\cdot)" display="inline"><semantics id="S4.T5.4.4.4.1.m1.1a"><mrow id="S4.T5.4.4.4.1.m1.1.2" xref="S4.T5.4.4.4.1.m1.1.2.cmml"><mi mathbackground="#E6E6E6" id="S4.T5.4.4.4.1.m1.1.2.2" xref="S4.T5.4.4.4.1.m1.1.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.T5.4.4.4.1.m1.1.2.1" xref="S4.T5.4.4.4.1.m1.1.2.1.cmml">â€‹</mo><mi mathbackground="#E6E6E6" id="S4.T5.4.4.4.1.m1.1.2.3" xref="S4.T5.4.4.4.1.m1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.4.4.4.1.m1.1.2.1a" xref="S4.T5.4.4.4.1.m1.1.2.1.cmml">â€‹</mo><mi mathbackground="#E6E6E6" id="S4.T5.4.4.4.1.m1.1.2.4" xref="S4.T5.4.4.4.1.m1.1.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.T5.4.4.4.1.m1.1.2.1b" xref="S4.T5.4.4.4.1.m1.1.2.1.cmml">â€‹</mo><mrow id="S4.T5.4.4.4.1.m1.1.2.5.2" xref="S4.T5.4.4.4.1.m1.1.2.cmml"><mo mathbackground="#E6E6E6" stretchy="false" id="S4.T5.4.4.4.1.m1.1.2.5.2.1" xref="S4.T5.4.4.4.1.m1.1.2.cmml">(</mo><mo lspace="0em" mathbackground="#E6E6E6" rspace="0em" id="S4.T5.4.4.4.1.m1.1.1" xref="S4.T5.4.4.4.1.m1.1.1.cmml">â‹…</mo><mo mathbackground="#E6E6E6" stretchy="false" id="S4.T5.4.4.4.1.m1.1.2.5.2.2" xref="S4.T5.4.4.4.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.4.1.m1.1b"><apply id="S4.T5.4.4.4.1.m1.1.2.cmml" xref="S4.T5.4.4.4.1.m1.1.2"><times id="S4.T5.4.4.4.1.m1.1.2.1.cmml" xref="S4.T5.4.4.4.1.m1.1.2.1"></times><ci id="S4.T5.4.4.4.1.m1.1.2.2.cmml" xref="S4.T5.4.4.4.1.m1.1.2.2">ğ‘™</ci><ci id="S4.T5.4.4.4.1.m1.1.2.3.cmml" xref="S4.T5.4.4.4.1.m1.1.2.3">ğ‘œ</ci><ci id="S4.T5.4.4.4.1.m1.1.2.4.cmml" xref="S4.T5.4.4.4.1.m1.1.2.4">ğ‘”</ci><ci id="S4.T5.4.4.4.1.m1.1.1.cmml" xref="S4.T5.4.4.4.1.m1.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.4.1.m1.1c">log(\cdot)</annotation></semantics></math></th>
<td id="S4.T5.4.4.4.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T5.4.4.4.3.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">24.4</span></td>
<td id="S4.T5.4.4.4.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S4.T5.4.4.4.4.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">18.1</span></td>
</tr>
<tr id="S4.T5.5.5.5" class="ltx_tr">
<th id="S4.T5.5.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">3</th>
<th id="S4.T5.5.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S4.T5.5.5.5.1.m1.1" class="ltx_Math" alttext="log(\cdot)" display="inline"><semantics id="S4.T5.5.5.5.1.m1.1a"><mrow id="S4.T5.5.5.5.1.m1.1.2" xref="S4.T5.5.5.5.1.m1.1.2.cmml"><mi id="S4.T5.5.5.5.1.m1.1.2.2" xref="S4.T5.5.5.5.1.m1.1.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.T5.5.5.5.1.m1.1.2.1" xref="S4.T5.5.5.5.1.m1.1.2.1.cmml">â€‹</mo><mi id="S4.T5.5.5.5.1.m1.1.2.3" xref="S4.T5.5.5.5.1.m1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.5.5.5.1.m1.1.2.1a" xref="S4.T5.5.5.5.1.m1.1.2.1.cmml">â€‹</mo><mi id="S4.T5.5.5.5.1.m1.1.2.4" xref="S4.T5.5.5.5.1.m1.1.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.T5.5.5.5.1.m1.1.2.1b" xref="S4.T5.5.5.5.1.m1.1.2.1.cmml">â€‹</mo><mrow id="S4.T5.5.5.5.1.m1.1.2.5.2" xref="S4.T5.5.5.5.1.m1.1.2.cmml"><mo stretchy="false" id="S4.T5.5.5.5.1.m1.1.2.5.2.1" xref="S4.T5.5.5.5.1.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.T5.5.5.5.1.m1.1.1" xref="S4.T5.5.5.5.1.m1.1.1.cmml">â‹…</mo><mo stretchy="false" id="S4.T5.5.5.5.1.m1.1.2.5.2.2" xref="S4.T5.5.5.5.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.5.5.5.1.m1.1b"><apply id="S4.T5.5.5.5.1.m1.1.2.cmml" xref="S4.T5.5.5.5.1.m1.1.2"><times id="S4.T5.5.5.5.1.m1.1.2.1.cmml" xref="S4.T5.5.5.5.1.m1.1.2.1"></times><ci id="S4.T5.5.5.5.1.m1.1.2.2.cmml" xref="S4.T5.5.5.5.1.m1.1.2.2">ğ‘™</ci><ci id="S4.T5.5.5.5.1.m1.1.2.3.cmml" xref="S4.T5.5.5.5.1.m1.1.2.3">ğ‘œ</ci><ci id="S4.T5.5.5.5.1.m1.1.2.4.cmml" xref="S4.T5.5.5.5.1.m1.1.2.4">ğ‘”</ci><ci id="S4.T5.5.5.5.1.m1.1.1.cmml" xref="S4.T5.5.5.5.1.m1.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.5.5.1.m1.1c">log(\cdot)</annotation></semantics></math></th>
<td id="S4.T5.5.5.5.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">24.3</td>
<td id="S4.T5.5.5.5.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">18.0</td>
</tr>
<tr id="S4.T5.6.6.6" class="ltx_tr">
<th id="S4.T5.6.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">2</th>
<th id="S4.T5.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S4.T5.6.6.6.1.m1.1" class="ltx_Math" alttext="linear" display="inline"><semantics id="S4.T5.6.6.6.1.m1.1a"><mrow id="S4.T5.6.6.6.1.m1.1.1" xref="S4.T5.6.6.6.1.m1.1.1.cmml"><mi id="S4.T5.6.6.6.1.m1.1.1.2" xref="S4.T5.6.6.6.1.m1.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.T5.6.6.6.1.m1.1.1.1" xref="S4.T5.6.6.6.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.6.6.6.1.m1.1.1.3" xref="S4.T5.6.6.6.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.T5.6.6.6.1.m1.1.1.1a" xref="S4.T5.6.6.6.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.6.6.6.1.m1.1.1.4" xref="S4.T5.6.6.6.1.m1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.T5.6.6.6.1.m1.1.1.1b" xref="S4.T5.6.6.6.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.6.6.6.1.m1.1.1.5" xref="S4.T5.6.6.6.1.m1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.T5.6.6.6.1.m1.1.1.1c" xref="S4.T5.6.6.6.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.6.6.6.1.m1.1.1.6" xref="S4.T5.6.6.6.1.m1.1.1.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.T5.6.6.6.1.m1.1.1.1d" xref="S4.T5.6.6.6.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.6.6.6.1.m1.1.1.7" xref="S4.T5.6.6.6.1.m1.1.1.7.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.6.6.6.1.m1.1b"><apply id="S4.T5.6.6.6.1.m1.1.1.cmml" xref="S4.T5.6.6.6.1.m1.1.1"><times id="S4.T5.6.6.6.1.m1.1.1.1.cmml" xref="S4.T5.6.6.6.1.m1.1.1.1"></times><ci id="S4.T5.6.6.6.1.m1.1.1.2.cmml" xref="S4.T5.6.6.6.1.m1.1.1.2">ğ‘™</ci><ci id="S4.T5.6.6.6.1.m1.1.1.3.cmml" xref="S4.T5.6.6.6.1.m1.1.1.3">ğ‘–</ci><ci id="S4.T5.6.6.6.1.m1.1.1.4.cmml" xref="S4.T5.6.6.6.1.m1.1.1.4">ğ‘›</ci><ci id="S4.T5.6.6.6.1.m1.1.1.5.cmml" xref="S4.T5.6.6.6.1.m1.1.1.5">ğ‘’</ci><ci id="S4.T5.6.6.6.1.m1.1.1.6.cmml" xref="S4.T5.6.6.6.1.m1.1.1.6">ğ‘</ci><ci id="S4.T5.6.6.6.1.m1.1.1.7.cmml" xref="S4.T5.6.6.6.1.m1.1.1.7">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.6.6.1.m1.1c">linear</annotation></semantics></math></th>
<td id="S4.T5.6.6.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">24.1</td>
<td id="S4.T5.6.6.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">17.9</td>
</tr>
<tr id="S4.T5.7.7.7" class="ltx_tr">
<th id="S4.T5.7.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">2</th>
<th id="S4.T5.7.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S4.T5.7.7.7.1.m1.1" class="ltx_Math" alttext="sqrt" display="inline"><semantics id="S4.T5.7.7.7.1.m1.1a"><mrow id="S4.T5.7.7.7.1.m1.1.1" xref="S4.T5.7.7.7.1.m1.1.1.cmml"><mi id="S4.T5.7.7.7.1.m1.1.1.2" xref="S4.T5.7.7.7.1.m1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.T5.7.7.7.1.m1.1.1.1" xref="S4.T5.7.7.7.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.7.7.7.1.m1.1.1.3" xref="S4.T5.7.7.7.1.m1.1.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.T5.7.7.7.1.m1.1.1.1a" xref="S4.T5.7.7.7.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.7.7.7.1.m1.1.1.4" xref="S4.T5.7.7.7.1.m1.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.T5.7.7.7.1.m1.1.1.1b" xref="S4.T5.7.7.7.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.7.7.7.1.m1.1.1.5" xref="S4.T5.7.7.7.1.m1.1.1.5.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.7.7.7.1.m1.1b"><apply id="S4.T5.7.7.7.1.m1.1.1.cmml" xref="S4.T5.7.7.7.1.m1.1.1"><times id="S4.T5.7.7.7.1.m1.1.1.1.cmml" xref="S4.T5.7.7.7.1.m1.1.1.1"></times><ci id="S4.T5.7.7.7.1.m1.1.1.2.cmml" xref="S4.T5.7.7.7.1.m1.1.1.2">ğ‘ </ci><ci id="S4.T5.7.7.7.1.m1.1.1.3.cmml" xref="S4.T5.7.7.7.1.m1.1.1.3">ğ‘</ci><ci id="S4.T5.7.7.7.1.m1.1.1.4.cmml" xref="S4.T5.7.7.7.1.m1.1.1.4">ğ‘Ÿ</ci><ci id="S4.T5.7.7.7.1.m1.1.1.5.cmml" xref="S4.T5.7.7.7.1.m1.1.1.5">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.7.7.1.m1.1c">sqrt</annotation></semantics></math></th>
<td id="S4.T5.7.7.7.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">24.0</td>
<td id="S4.T5.7.7.7.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">17.7</td>
</tr>
<tr id="S4.T5.8.8.8" class="ltx_tr">
<th id="S4.T5.8.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">2</th>
<th id="S4.T5.8.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S4.T5.8.8.8.1.m1.1" class="ltx_Math" alttext="fixed" display="inline"><semantics id="S4.T5.8.8.8.1.m1.1a"><mrow id="S4.T5.8.8.8.1.m1.1.1" xref="S4.T5.8.8.8.1.m1.1.1.cmml"><mi id="S4.T5.8.8.8.1.m1.1.1.2" xref="S4.T5.8.8.8.1.m1.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.T5.8.8.8.1.m1.1.1.1" xref="S4.T5.8.8.8.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.8.8.8.1.m1.1.1.3" xref="S4.T5.8.8.8.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.T5.8.8.8.1.m1.1.1.1a" xref="S4.T5.8.8.8.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.8.8.8.1.m1.1.1.4" xref="S4.T5.8.8.8.1.m1.1.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.T5.8.8.8.1.m1.1.1.1b" xref="S4.T5.8.8.8.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.8.8.8.1.m1.1.1.5" xref="S4.T5.8.8.8.1.m1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.T5.8.8.8.1.m1.1.1.1c" xref="S4.T5.8.8.8.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T5.8.8.8.1.m1.1.1.6" xref="S4.T5.8.8.8.1.m1.1.1.6.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.8.8.8.1.m1.1b"><apply id="S4.T5.8.8.8.1.m1.1.1.cmml" xref="S4.T5.8.8.8.1.m1.1.1"><times id="S4.T5.8.8.8.1.m1.1.1.1.cmml" xref="S4.T5.8.8.8.1.m1.1.1.1"></times><ci id="S4.T5.8.8.8.1.m1.1.1.2.cmml" xref="S4.T5.8.8.8.1.m1.1.1.2">ğ‘“</ci><ci id="S4.T5.8.8.8.1.m1.1.1.3.cmml" xref="S4.T5.8.8.8.1.m1.1.1.3">ğ‘–</ci><ci id="S4.T5.8.8.8.1.m1.1.1.4.cmml" xref="S4.T5.8.8.8.1.m1.1.1.4">ğ‘¥</ci><ci id="S4.T5.8.8.8.1.m1.1.1.5.cmml" xref="S4.T5.8.8.8.1.m1.1.1.5">ğ‘’</ci><ci id="S4.T5.8.8.8.1.m1.1.1.6.cmml" xref="S4.T5.8.8.8.1.m1.1.1.6">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.8.8.1.m1.1c">fixed</annotation></semantics></math></th>
<td id="S4.T5.8.8.8.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">23.7</td>
<td id="S4.T5.8.8.8.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">17.6</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS4.p4" class="ltx_para ltx_noindent">
<p id="S4.SS4.p4.1" class="ltx_p"><span id="S4.SS4.p4.1.1" class="ltx_text ltx_font_bold">Range-modulated 3D Denoising.</span> 3D denoising brings an improvement of 1.0% mAP and 0.8% CDS. Penalizing negative samples flexibly alleviates the challenge of false proposals and helps localize 3D objects, by taking the object range into consideration.
We present experiments on different noising designs and numbers of negative samples, shown in Tab.Â <a href="#S4.T5" title="Table 5 â€£ 4.4 Ablation Study &amp; Analysis â€£ 4 Experiment â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The results imply that the logarithm function and two negative samples are optimal settings.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>The impact of global query number. StreamPETR suffers from the convergence problem, where NaN denotes the failed training. In contrast, our framework shows robust performance even with only adaptive queries.</figcaption>
<div id="S4.T6.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:242.8pt;height:74.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(4.1pt,-1.3pt) scale(1.03482506735332,1.03482506735332) ;">
<table id="S4.T6.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.2.2.3.1" class="ltx_tr">
<th id="S4.T6.2.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;" rowspan="2"><span id="S4.T6.2.2.3.1.1.1" class="ltx_text ltx_font_bold"># Global query</span></th>
<th id="S4.T6.2.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;" colspan="3"><span id="S4.T6.2.2.3.1.2.1" class="ltx_text ltx_font_bold">StreamPETR</span></th>
<th id="S4.T6.2.2.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;" colspan="3"><span id="S4.T6.2.2.3.1.3.1" class="ltx_text ltx_font_bold">Far3DÂ (Ours)</span></th>
</tr>
<tr id="S4.T6.2.2.4.2" class="ltx_tr">
<th id="S4.T6.2.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.5pt;padding-right:3.5pt;">100</th>
<th id="S4.T6.2.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.5pt;padding-right:3.5pt;">300</th>
<th id="S4.T6.2.2.4.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">644</th>
<th id="S4.T6.2.2.4.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.5pt;padding-right:3.5pt;">100</th>
<th id="S4.T6.2.2.4.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.5pt;padding-right:3.5pt;">300</th>
<th id="S4.T6.2.2.4.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.5pt;padding-right:3.5pt;">644</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.1.1.1" class="ltx_tr">
<th id="S4.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S4.T6.1.1.1.1.1" class="ltx_text ltx_font_bold">mAP[%]<math id="S4.T6.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T6.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T6.1.1.1.1.1.m1.1.1" xref="S4.T6.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.1.1.m1.1b"><ci id="S4.T6.1.1.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<td id="S4.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">1.5</td>
<td id="S4.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">16.9</td>
<td id="S4.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">20.5</td>
<td id="S4.T6.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">23.5</td>
<td id="S4.T6.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">23.6</td>
<td id="S4.T6.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">24.4</td>
</tr>
<tr id="S4.T6.2.2.2" class="ltx_tr">
<th id="S4.T6.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S4.T6.2.2.2.1.1" class="ltx_text ltx_font_bold">CDS[%]<math id="S4.T6.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T6.2.2.2.1.1.m1.1a"><mo stretchy="false" id="S4.T6.2.2.2.1.1.m1.1.1" xref="S4.T6.2.2.2.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.2.1.1.m1.1b"><ci id="S4.T6.2.2.2.1.1.m1.1.1.cmml" xref="S4.T6.2.2.2.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.2.1.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<td id="S4.T6.2.2.2.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;">0.9</td>
<td id="S4.T6.2.2.2.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;">11.8</td>
<td id="S4.T6.2.2.2.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">14.8</td>
<td id="S4.T6.2.2.2.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;">17.4</td>
<td id="S4.T6.2.2.2.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;">17.5</td>
<td id="S4.T6.2.2.2.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;">18.1</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS4.p5" class="ltx_para ltx_noindent">
<p id="S4.SS4.p5.1" class="ltx_p"><span id="S4.SS4.p5.1.1" class="ltx_text ltx_font_bold">Effect of the Global Query.</span>
We also design the experiment to investigate the effect of global query in Tab.Â <a href="#S4.T6" title="Table 6 â€£ 4.4 Ablation Study &amp; Analysis â€£ 4 Experiment â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. 3D global queries and adaptive queries coexist in our framework and compensate for each other. As a baseline, StreamPETR suffers from the convergence problem when using a small number of global queries (e.g. 100), and only works for a sufficient amount. In contrast, our method showcases distinctive robustness. As the number of global queries decreases, our performance shows a slight decline.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we present a sparse query-based method for 3D long-range detection. Our approach incorporates 3D adaptive queries derived from 2D object priors, yielding high-quality proposals for the decoder.
To improve training efficacy, we introduce a perspective-aware aggregation and range-modulated 3D denoising technique. Experimental results demonstrate the promising performance of our method, indicating its great potential for practical applications.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Limitations and Future Work.</span>
Despite our development for long-range detection, several limitations require future solutions.
On the one hand, existing approaches exhibit poor performance on long-tail classes, ultimately lowering the average precision on Argoverse 2 dataset. On the other hand, evaluating long-range and close-range objects using unified metrics may not be suitable, emphasizing the need for practical and dynamic evaluation criteria that cater to diverse real-world scenarios.

</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caesar etÂ al. (2020)</span>
<span class="ltx_bibblock">
Caesar, H.; Bankiti, V.; Lang, A.Â H.; Vora, S.; Liong, V.Â E.; Xu, Q.; Krishnan,
A.; Pan, Y.; Baldan, G.; and Beijbom, O. 2020.

</span>
<span class="ltx_bibblock">nuscenes: A multimodal dataset for autonomous driving.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, 11621â€“11631.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carion etÂ al. (2020)</span>
<span class="ltx_bibblock">
Carion, N.; Massa, F.; Synnaeve, G.; Usunier, N.; Kirillov, A.; and Zagoruyko,
S. 2020.

</span>
<span class="ltx_bibblock">End-to-end object detection with transformers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">European conference on computer vision</em>, 213â€“229. Springer.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2023)</span>
<span class="ltx_bibblock">
Chen, Y.; Liu, J.; Zhang, X.; Qi, X.; and Jia, J. 2023.

</span>
<span class="ltx_bibblock">Voxelnext: Fully sparse voxelnet for 3d object detection and
tracking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, 21674â€“21683.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy etÂ al. (2020)</span>
<span class="ltx_bibblock">
Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn, D.; Zhai, X.;
Unterthiner, T.; Dehghani, M.; Minderer, M.; Heigold, G.; Gelly, S.; etÂ al.
2020.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at
scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11929</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan etÂ al. (2022)</span>
<span class="ltx_bibblock">
Fan, L.; Wang, F.; Wang, N.; and ZHANG, Z.-X. 2022.

</span>
<span class="ltx_bibblock">Fully sparse 3d object detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:
351â€“363.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ge etÂ al. (2021)</span>
<span class="ltx_bibblock">
Ge, Z.; Liu, S.; Wang, F.; Li, Z.; and Sun, J. 2021.

</span>
<span class="ltx_bibblock">Yolox: Exceeding yolo series in 2021.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.08430</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2016)</span>
<span class="ltx_bibblock">
He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, 770â€“778.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu, Shen, and Sun (2018)</span>
<span class="ltx_bibblock">
Hu, J.; Shen, L.; and Sun, G. 2018.

</span>
<span class="ltx_bibblock">Squeeze-and-excitation networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, 7132â€“7141.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang and Huang (2022)</span>
<span class="ltx_bibblock">
Huang, J.; and Huang, G. 2022.

</span>
<span class="ltx_bibblock">Bevdet4d: Exploit temporal cues in multi-camera 3d object detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.17054</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al. (2021)</span>
<span class="ltx_bibblock">
Huang, J.; Huang, G.; Zhu, Z.; Ye, Y.; and Du, D. 2021.

</span>
<span class="ltx_bibblock">Bevdet: High-performance multi-camera 3d object detection in
bird-eye-view.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.11790</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jiang, Y.; Zhang, L.; Miao, Z.; Zhu, X.; Gao, J.; Hu, W.; and Jiang, Y.-G.
2023.

</span>
<span class="ltx_bibblock">Polarformer: Multi-camera 3d object detection with polar transformer.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volumeÂ 37, 1042â€“1050.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. (2019)</span>
<span class="ltx_bibblock">
Lee, Y.; Hwang, J.-w.; Lee, S.; Bae, Y.; and Park, J. 2019.

</span>
<span class="ltx_bibblock">An energy and GPU-computation efficient backbone network for
real-time object detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition workshops</em>, 0â€“0.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2022a)</span>
<span class="ltx_bibblock">
Li, F.; Zhang, H.; Liu, S.; Guo, J.; Ni, L.Â M.; and Zhang, L.
2022a.

</span>
<span class="ltx_bibblock">Dn-detr: Accelerate detr training by introducing query denoising.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, 13619â€“13627.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2022b)</span>
<span class="ltx_bibblock">
Li, Y.; Bao, H.; Ge, Z.; Yang, J.; Sun, J.; and Li, Z. 2022b.

</span>
<span class="ltx_bibblock">Bevstereo: Enhancing depth estimation in multi-view 3d object
detection with dynamic temporal stereo.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2209.10248</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023)</span>
<span class="ltx_bibblock">
Li, Y.; Ge, Z.; Yu, G.; Yang, J.; Wang, Z.; Shi, Y.; Sun, J.; and Li, Z. 2023.

</span>
<span class="ltx_bibblock">Bevdepth: Acquisition of reliable depth for multi-view 3d object
detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volumeÂ 37, 1477â€“1485.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2022c)</span>
<span class="ltx_bibblock">
Li, Z.; Wang, W.; Li, H.; Xie, E.; Sima, C.; Lu, T.; Qiao, Y.; and Dai, J.
2022c.

</span>
<span class="ltx_bibblock">Bevformer: Learning birdâ€™s-eye-view representation from
multi-camera images via spatiotemporal transformers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">European conference on computer vision</em>, 1â€“18. Springer.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. (2017)</span>
<span class="ltx_bibblock">
Lin, T.-Y.; DollÃ¡r, P.; Girshick, R.; He, K.; Hariharan, B.; and Belongie,
S. 2017.

</span>
<span class="ltx_bibblock">Feature pyramid networks for object detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, 2117â€“2125.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. (2014)</span>
<span class="ltx_bibblock">
Lin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.;
DollÃ¡r, P.; and Zitnick, C.Â L. 2014.

</span>
<span class="ltx_bibblock">Microsoft coco: Common objects in context.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Computer Visionâ€“ECCV 2014: 13th European Conference,
Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13</em>, 740â€“755.
Springer.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. (2022)</span>
<span class="ltx_bibblock">
Lin, X.; Lin, T.; Pei, Z.; Huang, L.; and Su, Z. 2022.

</span>
<span class="ltx_bibblock">Sparse4d: Multi-view 3d object detection with sparse spatial-temporal
fusion.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.10581</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. (2023)</span>
<span class="ltx_bibblock">
Lin, X.; Lin, T.; Pei, Z.; Huang, L.; and Su, Z. 2023.

</span>
<span class="ltx_bibblock">Sparse4D v2: Recurrent Temporal Fusion with Sparse Model.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14018</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Liu, J.; Wang, T.; Liu, B.; Zhang, Q.; Liu, Y.; and Li, H. 2023.

</span>
<span class="ltx_bibblock">Towards Better 3D Knowledge Transfer via Masked Image Modeling for
Multi-view 3D Understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.11325</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2022a)</span>
<span class="ltx_bibblock">
Liu, Y.; Wang, T.; Zhang, X.; and Sun, J. 2022a.

</span>
<span class="ltx_bibblock">Petr: Position embedding transformation for multi-view 3d object
detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>, 531â€“548. Springer.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2022b)</span>
<span class="ltx_bibblock">
Liu, Y.; Yan, J.; Jia, F.; Li, S.; Gao, Q.; Wang, T.; Zhang, X.; and Sun, J.
2022b.

</span>
<span class="ltx_bibblock">Petrv2: A unified framework for 3d perception from multi-camera
images.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.01256</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2017)</span>
<span class="ltx_bibblock">
Loshchilov, I.; and Hutter, F. 2017.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.05101</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park etÂ al. (2022)</span>
<span class="ltx_bibblock">
Park, J.; Xu, C.; Yang, S.; Keutzer, K.; Kitani, K.; Tomizuka, M.; and Zhan, W.
2022.

</span>
<span class="ltx_bibblock">Time will tell: New outlooks and a baseline for temporal multi-view
3d object detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.02443</em>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Philion and Fidler (2020)</span>
<span class="ltx_bibblock">
Philion, J.; and Fidler, S. 2020.

</span>
<span class="ltx_bibblock">Lift, splat, shoot: Encoding images from arbitrary camera rigs by
implicitly unprojecting to 3d.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Computer Visionâ€“ECCV 2020: 16th European Conference,
Glasgow, UK, August 23â€“28, 2020, Proceedings, Part XIV 16</em>, 194â€“210.
Springer.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reading etÂ al. (2021)</span>
<span class="ltx_bibblock">
Reading, C.; Harakeh, A.; Chae, J.; and Waslander, S.Â L. 2021.

</span>
<span class="ltx_bibblock">Categorical depth distribution network for monocular 3d object
detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, 8555â€“8564.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao etÂ al. (2019)</span>
<span class="ltx_bibblock">
Shao, S.; Li, Z.; Zhang, T.; Peng, C.; Yu, G.; Zhang, X.; Li, J.; and Sun, J.
2019.

</span>
<span class="ltx_bibblock">Objects365: A large-scale, high-quality dataset for object detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on
computer vision</em>, 8430â€“8439.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani etÂ al. (2017)</span>
<span class="ltx_bibblock">
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.Â N.;
Kaiser, Å.; and Polosukhin, I. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 30.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang, Jiang, and Li (2022)</span>
<span class="ltx_bibblock">
Wang, S.; Jiang, X.; and Li, Y. 2022.

</span>
<span class="ltx_bibblock">Focal-PETR: Embracing Foreground for Efficient Multi-Camera 3D Object
Detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.05505</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Wang, S.; Liu, Y.; Wang, T.; Li, Y.; and Zhang, X. 2023a.

</span>
<span class="ltx_bibblock">Exploring Object-Centric Temporal Modeling for Efficient Multi-View
3D Object Detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.11926</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2021)</span>
<span class="ltx_bibblock">
Wang, T.; Zhu, X.; Pang, J.; and Lin, D. 2021.

</span>
<span class="ltx_bibblock">Fcos3d: Fully convolutional one-stage monocular 3d object detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em>, 913â€“922.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Wang, Y.; Guizilini, V.Â C.; Zhang, T.; Wang, Y.; Zhao, H.; and Solomon, J.
2022.

</span>
<span class="ltx_bibblock">Detr3d: 3d object detection from multi-view images via 3d-to-2d
queries.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Conference on Robot Learning</em>, 180â€“191. PMLR.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Wang, Z.; Huang, Z.; Fu, J.; Wang, N.; and Liu, S. 2023b.

</span>
<span class="ltx_bibblock">Object as query: Equipping any 2d object detector with 3d detection
ability.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.02364</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilson etÂ al. (2023)</span>
<span class="ltx_bibblock">
Wilson, B.; Qi, W.; Agarwal, T.; Lambert, J.; Singh, J.; Khandelwal, S.; Pan,
B.; Kumar, R.; Hartnett, A.; Pontes, J.Â K.; etÂ al. 2023.

</span>
<span class="ltx_bibblock">Argoverse 2: Next generation datasets for self-driving perception and
forecasting.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.00493</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie etÂ al. (2022)</span>
<span class="ltx_bibblock">
Xie, E.; Yu, Z.; Zhou, D.; Philion, J.; Anandkumar, A.; Fidler, S.; Luo, P.;
and Alvarez, J.Â M. 2022.

</span>
<span class="ltx_bibblock">M2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified
Birds-Eye View Representation.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.05088</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yang, C.; Chen, Y.; Tian, H.; Tao, C.; Zhu, X.; Zhang, Z.; Huang, G.; Li, H.;
Qiao, Y.; Lu, L.; etÂ al. 2023.

</span>
<span class="ltx_bibblock">BEVFormer v2: Adapting Modern Image Backbones to Birdâ€™s-Eye-View
Recognition via Perspective Supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, 17830â€“17839.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin, Zhou, and Krahenbuhl (2021)</span>
<span class="ltx_bibblock">
Yin, T.; Zhou, X.; and Krahenbuhl, P. 2021.

</span>
<span class="ltx_bibblock">Center-based 3d object detection and tracking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, 11784â€“11793.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Zhang, R.; Qiu, H.; Wang, T.; Guo, Z.; Xu, X.; Qiao, Y.; Gao, P.; and Li, H.
2022.

</span>
<span class="ltx_bibblock">MonoDETR: depth-guided transformer for monocular 3D object detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.13310</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Zhang, Y.; Zheng, W.; Zhu, Z.; Huang, G.; Lu, J.; and Zhou, J. 2023.

</span>
<span class="ltx_bibblock">A Simple Baseline for Multi-Camera 3D Object Detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volumeÂ 37, 3507â€“3515.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. (2020)</span>
<span class="ltx_bibblock">
Zhu, X.; Su, W.; Lu, L.; Li, B.; Wang, X.; and Dai, J. 2020.

</span>
<span class="ltx_bibblock">Deformable detr: Deformable transformers for end-to-end object
detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.04159</em>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zong etÂ al. (2023)</span>
<span class="ltx_bibblock">
Zong, Z.; Jiang, D.; Song, G.; Xue, Z.; Su, J.; Li, H.; and Liu, Y. 2023.

</span>
<span class="ltx_bibblock">Temporal Enhanced Training of Multi-view 3D Object Detector via
Historical Object Prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.00967</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Supplementary</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text ltx_font_bold">The background of sparse query-based methods.</span>
To localize 3D objects from surround-view images, DETR3DÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> defines 3D object queries and generates 3D reference points, then samples 2D image features through coordinate projection and cross-attention. Finally, object queries are updated by aggregated features and used to predict the bounding boxes.
PETRÂ <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al. <a href="#bib.bib22" title="" class="ltx_ref">2022a</a>)</cite> generates 3D position-aware features by encoding the 3D coordinate information into position embedding.
PETRv2Â <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al. <a href="#bib.bib23" title="" class="ltx_ref">2022b</a>)</cite> develops multi-frame temporal modeling to boost 3D detection, and StreamPETRÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023a</a>)</cite> takes a step further by proposing an object-centric temporal mechanism, which enables long-sequence query propagation and online prediction.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold">Novelty of the model.</span> Our main contribution is the unified framework for long-range 3D detection, rather than stand-alone components.
To tackle the poor 3D recall, heavy computation cost, and query error propagation existing in long-range detection, we introduce adaptive query, perspective-aware aggregation and 3D denoising strategies.
Combining these strategies in an intuitive manner, we achieve the scalability of perception range.
</p>
</div>
<div id="S6.p3" class="ltx_para ltx_noindent">
<p id="S6.p3.1" class="ltx_p"><span id="S6.p3.1.1" class="ltx_text ltx_font_bold">Benefits in various ranges.</span>
In fact, Far3D brings performance improvements in both close-range and long-range.
Empirically, we observe a common phenomenon of existing methods: the performance of close-range objects will decrease significantly when switching the training range from close range (e.g. 50m) to long range (e.g. 150m).
Far3D mitigates the problem thanks to adaptive query and 3D denoising, thus it not only improves the performance of far objects, but also alleviates the performance degradation of near objects, as shown in TableÂ <a href="#S6.T7" title="Table 7 â€£ 6 Supplementary â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<div id="S6.p4" class="ltx_para ltx_noindent">
<p id="S6.p4.1" class="ltx_p"><span id="S6.p4.1.1" class="ltx_text ltx_font_bold">Temporal modeling.</span> We employ propagated queries (depicted in Figure.Â <a href="#S6.F6" title="Figure 6 â€£ 6 Supplementary â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) from previous frames to incorporate temporal features, following StreamPETR. Propagated queries are selected according to query score and irrelevant to original query type.</p>
</div>
<div id="S6.p5" class="ltx_para ltx_noindent">
<p id="S6.p5.1" class="ltx_p"><span id="S6.p5.1.1" class="ltx_text ltx_font_bold">Difference with recent methods.</span>
We highlight the distinctions between our approach and recent methods such as MV2DÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib34" title="" class="ltx_ref">2023b</a>)</cite> and BEVFormer v2Â <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al. <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite>.
1) Motivations: First and foremost, our motivations differ significantly. Far3D focuses on tackling long-range detection challenges by leveraging 3D adaptive queries capable of adapting to dynamic scenarios and distant objects. In contrast, MV2D primarily aims to elevate 2D detectors to perform 3D detection in conventional detection tasks. BEVFormer v2 explores the synergy between image backbones and BEV detectors by incorporating perspective supervision.
2) Model Designs: Introducing 3D adaptive queries derived from 2D predictions equip the model with flexibility, yet it is not enough to tackle long-range detection. Experimentally, we found that another severe issue is the convergence problem. It is hard to converge for most existing methods, due to the impact of distant objects. Our proposed 3D denoising technique alleviates it significantly, facilitating the model convergence and performance.
3) Performance Superiority: Significantly, our proposed approach achieves exceptional performance compared to previous methods on the Argoverse 2 dataset. Notably, MV2D can hardly converge due to the considerable localization uncertainty associated with distant objects. Similarly, when evaluated on the popular nuScenes dataset, Far3D consistently surpasses MV2D (Far3D 51.0 mAP vs. MV2D 47.1 mAP on <span id="S6.p5.1.2" class="ltx_text ltx_font_typewriter">val</span>) and BEVFormer v2 (Far3D 63.5 mAP vs. BEVFormer v2 55.6 mAP on <span id="S6.p5.1.3" class="ltx_text ltx_font_typewriter">test</span>) by a significant margin.
In conclusion, the distinctiveness of Far3D lies in its <span id="S6.p5.1.4" class="ltx_text ltx_font_bold">motivations</span>, <span id="S6.p5.1.5" class="ltx_text ltx_font_bold">model designs</span>, as well as its <span id="S6.p5.1.6" class="ltx_text ltx_font_bold">superior performance</span>.</p>
</div>
<figure id="S6.F6" class="ltx_figure"><img src="/html/2308.09616/assets/x5.png" id="S6.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="180" height="28" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>There are three types of queries in Far3D: global queries, adaptive queries and propagated queries. For temporal modeling, propagated queries are from previous frames with high-scores, the same as StreamPETR.
</figcaption>
</figure>
<figure id="S6.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Performance comparison in different perception ranges.
We train the StreamPETR and Far3D with 50m and 150m ranges respectively, and present the results of both in 0-50m and 50-150m.
Far3D alleviates the performance degradation in close range while improving the performance by larger scale in long range, compared to StreamPETR.
</figcaption>
<div id="S6.T7.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:242.8pt;height:71.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-62.6pt,18.4pt) scale(0.659699925675991,0.659699925675991) ;">
<table id="S6.T7.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T7.2.2.2" class="ltx_tr">
<th id="S6.T7.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;" rowspan="2"><span id="S6.T7.2.2.2.3.1" class="ltx_text ltx_font_bold"># Perception range</span></th>
<th id="S6.T7.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;" rowspan="2"><span id="S6.T7.2.2.2.4.1" class="ltx_text ltx_font_bold">train range</span></th>
<td id="S6.T7.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;" colspan="2"><span id="S6.T7.1.1.1.1.1" class="ltx_text ltx_font_bold">test mAP[%]<math id="S6.T7.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S6.T7.1.1.1.1.1.m1.1.1" xref="S6.T7.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S6.T7.1.1.1.1.1.m1.1b"><ci id="S6.T7.1.1.1.1.1.m1.1.1.cmml" xref="S6.T7.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S6.T7.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;" colspan="2"><span id="S6.T7.2.2.2.2.1" class="ltx_text ltx_font_bold">test Recall[%]<math id="S6.T7.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T7.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S6.T7.2.2.2.2.1.m1.1.1" xref="S6.T7.2.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S6.T7.2.2.2.2.1.m1.1b"><ci id="S6.T7.2.2.2.2.1.m1.1.1.cmml" xref="S6.T7.2.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
</tr>
<tr id="S6.T7.2.2.3.1" class="ltx_tr">
<td id="S6.T7.2.2.3.1.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0-50m</td>
<td id="S6.T7.2.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">50-150m</td>
<td id="S6.T7.2.2.3.1.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0-50m</td>
<td id="S6.T7.2.2.3.1.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">50-150m</td>
</tr>
<tr id="S6.T7.2.2.4.2" class="ltx_tr">
<th id="S6.T7.2.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S6.T7.2.2.4.2.1.1" class="ltx_text ltx_font_bold">StreamPETR</span></th>
<th id="S6.T7.2.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">50m</th>
<td id="S6.T7.2.2.4.2.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">34.3</td>
<td id="S6.T7.2.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">1.6</td>
<td id="S6.T7.2.2.4.2.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">51.9</td>
<td id="S6.T7.2.2.4.2.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">4.2</td>
</tr>
<tr id="S6.T7.2.2.5.3" class="ltx_tr">
<th id="S6.T7.2.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S6.T7.2.2.5.3.1.1" class="ltx_text ltx_font_bold">StreamPETR</span></th>
<th id="S6.T7.2.2.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">150m</th>
<td id="S6.T7.2.2.5.3.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">31.8(-2.5)</td>
<td id="S6.T7.2.2.5.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">7.4(+5.8)</td>
<td id="S6.T7.2.2.5.3.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">46.9(-5.0)</td>
<td id="S6.T7.2.2.5.3.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">17.2(+13.0)</td>
</tr>
<tr id="S6.T7.2.2.6.4" class="ltx_tr">
<th id="S6.T7.2.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S6.T7.2.2.6.4.1.1" class="ltx_text ltx_font_bold">Ours</span></th>
<th id="S6.T7.2.2.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">50m</th>
<td id="S6.T7.2.2.6.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">38.7</td>
<td id="S6.T7.2.2.6.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">1.9</td>
<td id="S6.T7.2.2.6.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">55.0</td>
<td id="S6.T7.2.2.6.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;">4.6</td>
</tr>
<tr id="S6.T7.2.2.7.5" class="ltx_tr">
<th id="S6.T7.2.2.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S6.T7.2.2.7.5.1.1" class="ltx_text ltx_font_bold">Ours</span></th>
<th id="S6.T7.2.2.7.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">150m</th>
<td id="S6.T7.2.2.7.5.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S6.T7.2.2.7.5.3.1" class="ltx_text ltx_font_bold">37.7</span>(-1.0)</td>
<td id="S6.T7.2.2.7.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S6.T7.2.2.7.5.4.1" class="ltx_text ltx_font_bold">9.9</span>(+8.0)</td>
<td id="S6.T7.2.2.7.5.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S6.T7.2.2.7.5.5.1" class="ltx_text ltx_font_bold">51.9</span>(-3.1)</td>
<td id="S6.T7.2.2.7.5.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S6.T7.2.2.7.5.6.1" class="ltx_text ltx_font_bold">20.5</span>(+15.9)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S6.p6" class="ltx_para">
<p id="S6.p6.1" class="ltx_p">Besides the above analysis, we also present visualization comparisons between Far3D and SOLOFusionÂ <cite class="ltx_cite ltx_citemacro_citep">(Park etÂ al. <a href="#bib.bib25" title="" class="ltx_ref">2022</a>)</cite> in Fig.Â <a href="#S6.F7" title="Figure 7 â€£ 6 Supplementary â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. SOLOFusion is a representative work of BEV-based methods. The visualizations revealed that SOLOFusion, even with NMS, generates numerous duplicate predictions, which led us to speculate that this issue may arise from the limited receptive field of the detection head when dealing with a large perception range.</p>
</div>
<figure id="S6.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.09616/assets/x6.png" id="S6.F7.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="538" height="578" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Far3D</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.09616/assets/x7.png" id="S6.F7.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="538" height="581" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>SOLOFusion</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Visulization results of Far3D and SOLOFusion.</figcaption>
</figure>
<div id="S6.p7" class="ltx_para ltx_noindent">
<p id="S6.p7.1" class="ltx_p"><span id="S6.p7.1.1" class="ltx_text ltx_font_bold">Performance comparisons of all categories.</span>
There are 26 categories in Argoverse 2, far more than other datasets. Fig.Â <a href="#S6.F8" title="Figure 8 â€£ 6 Supplementary â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows the performance comparisons in detail. Furthermore, results of the range 0-50m and 50-100m are presented in Fig.Â <a href="#S6.F9" title="Figure 9 â€£ 6 Supplementary â€£ Far3D: Expanding the Horizon for Surround-view 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. Our method consistently achieves the best results.</p>
</div>
<figure id="S6.F8" class="ltx_figure"><img src="/html/2308.09616/assets/figures/exp_cls.png" id="S6.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="698" height="176" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Performance of all categories on Argoverse 2 <span id="S6.F8.2.1" class="ltx_text ltx_font_typewriter">val</span> set, with adopting VoV-99 backbone. We discard Message Board Trailer due to its near-zero result. </figcaption>
</figure>
<figure id="S6.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.09616/assets/figures/exp_cls_range1.png" id="S6.F9.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="698" height="295" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Range within 50 meters.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.09616/assets/figures/exp_cls_range2.png" id="S6.F9.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="698" height="322" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Range 50-100 meters.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Performance of first eight categories in different ranges.</figcaption>
</figure>
<div id="S6.p8" class="ltx_para ltx_noindent">
<p id="S6.p8.1" class="ltx_p"><span id="S6.p8.1.1" class="ltx_text ltx_font_bold">The statistics of adaptive queries.</span>
For a deeper analysis of the superiority of adaptive queries, we make statistics during training. We observe that the number of adaptive queries of Argoverse 2 dataset is 92 on average for each sample, with a maximum of 236 and a minimum of 11, accounting for only a small proportion of the total. We make an experiment that uses extra 92 queries instead of the adaptive ones, leading to a decrease of 1.5% mAP and 1.3% mCDS. The result validates the distinctive contribution of adaptive queries.</p>
</div>
<div id="S6.p9" class="ltx_para ltx_noindent">
<p id="S6.p9.1" class="ltx_p"><span id="S6.p9.1.1" class="ltx_text ltx_font_bold">More Details of Far3D.</span>
We provide additional details about our proposed Far3D as follows:
1) Our adaptive queries are generated by transforming 2D proposals and corresponding depth estimates into 3D space. To ensure the training efficacy, during the early stages of training, we utilize ground truth (GT) depth to generate 3D adaptive queries. As the network training stabilizes, we introduce predicted depth for the adaptation process.
2) Considering long-range tasks, the image pixel areas occupied by 3D objects at different ranges exhibit significant variation. A single-scale feature representation alone may not address the diverse requirements of different queries in 3D detection. To tackle this, we incorporate multi-scale features (p2-p5) obtained from the FPN. The query undergoes iterative updates using a deformable attention mechanism, reducing computational complexity. Our experiments indicate that the network can adaptively match objects at different distances and leverage multi-scale features effectively. We have compared the approach that manually selects feature layers based on object distance, and the results align closely with that learned by the network.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2308.09615" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2308.09616" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2308.09616">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2308.09616" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2308.09617" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 10:18:23 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
