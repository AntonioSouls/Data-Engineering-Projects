<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2012.05616] Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning</title><meta property="og:description" content="Human pose estimation (HPE) is a central part of understanding the visual narration and body movements of characters depicted in artwork collections, such as Greek vase paintings. Unfortunately, existing HPE methods doâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2012.05616">

<!--Generated on Sat Mar  9 04:41:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">*[enumerate]label=(0)
 








</p>
</div>
<h1 class="ltx_title ltx_title_document">Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Prathmesh Madhu<sup id="id13.2.id1" class="ltx_sup"><span id="id13.2.id1.1" class="ltx_text ltx_font_italic">1â‹†</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Angel Villar-Corrales<sup id="id14.2.id1" class="ltx_sup"><span id="id14.2.id1.1" class="ltx_text ltx_font_italic">1â‹†</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Ronak Kosti<sup id="id15.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Torsten Bendschus<sup id="id16.2.id1" class="ltx_sup">2</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Corinna Reinhardt<sup id="id17.2.id1" class="ltx_sup">2</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break">Peter Bell<sup id="id18.2.id1" class="ltx_sup">3</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Andreas Maier<sup id="id19.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Vincent Christlein<sup id="id20.6.id1" class="ltx_sup">1</sup>
<br class="ltx_break"><sup id="id21.7.id2" class="ltx_sup"><span id="id21.7.id2.1" class="ltx_text" style="font-size:90%;">1</span></sup><span id="id12.5.3" class="ltx_text" style="font-size:90%;">Pattern Recognition Lab, <sup id="id12.5.3.1" class="ltx_sup">2</sup>Institut fÃ¼r Klassische ArchÃ¤ologie, <sup id="id12.5.3.2" class="ltx_sup">3</sup>Institut fÃ¼r Kunstgeschichte
<br class="ltx_break">Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg
<br class="ltx_break"><sup id="id12.5.3.3" class="ltx_sup">â‹†</sup>equal contribution
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id22.id1" class="ltx_p">Human pose estimation (HPE) is a central part of understanding the visual narration and body movements of characters depicted in artwork collections, such as Greek vase paintings. Unfortunately, existing HPE methods do not generalise well across domains resulting in poorly recognized poses.
Therefore, we propose a two step approach: (1) adapting a dataset of natural images of known person and pose annotations to the style of Greek vase paintings by means of image style-transfer.
We introduce a perceptually-grounded style transfer training to enforce perceptual consistency.
Then, we fine-tune the base model with this newly created dataset.
We show that using style-transfer learning significantly improves the SOTA performance on unlabelled data by more than 6â€‰%Â mean average precision (mAP) as well as mean average recall (mAR).
(2) To improve the already strong results further, we created a small dataset (ClassArch) consisting of ancient Greek vase paintings from the 6â€“<span id="id22.id1.1" class="ltx_ERROR undefined">\nth</span>5 century BCE with person and pose annotations. We show that fine-tuning on this data with a style-transferred model improves the performance further.
In a thorough ablation study, we give a targeted analysis of the influence of style intensities, revealing that the model learns generic domain styles. Additionally, we provide a pose-based image retrieval to demonstrate the effectiveness of our method.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Human pose estimation (HPE) is highly challenging as it is difficult to have one method that can generalise across all domains. Estimating human pose involves localising each visible body-keypoint (<a href="#S1.F1.sf3" title="In Fig. 1 â€£ 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1(c)</span></a>), however the state-of-the-art (SOTA) methods underperform when tested on different domains, for example ancient Greek vase paintings (<a href="#S1.F1" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>). HPE is central to understanding the visual narration and body movements of the characters depicted in these paintings and the recent rapid digitisation of art collections has created an opportunity to use HPE as a tool to digitally examine such artworks. These digital copies are usually either photographic reproductionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> or scans of existing archivesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. In addition to the preservation of cultural heritage, these digital collections allow remote access of the invaluable artistic data to the general public. However, due to content complexity and large size, navigating within such collections is often daunting.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To address the challenge of efficiently analysing large digital collections, several computer vision and image analysis techniques have been used for applications, such as artist identificationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, object recognitionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, character recognitionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, artistic image classificationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> and pose-matchingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. However, when these methods are evaluated on a different domain, they show sub-optimal performance, c.f. <a href="#S1.F1" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>. Hence, an important challenge is to learn effective representations using little data. Human pose representation is one such example.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/main/main-fig-orig-4.jpg" id="S1.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="769" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S1.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Original</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/main/main-fig-sota-4.jpg" id="S1.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="768" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S1.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">OpenPose</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S1.F1.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/main/main-fig-stl-4.jpg" id="S1.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="768" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S1.F1.sf3.3.2" class="ltx_text" style="font-size:90%;">Ours</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text" style="font-size:90%;">Attic red-figure, <span id="S1.F1.4.2.1" class="ltx_text ltx_font_italic">Zeus and Ganymede</span>, in ancient Greek vase paintings: <a href="#S1.F1.sf1" title="Fig. 1(a) â€£ Fig. 1 â€£ 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a> original image, <a href="#S1.F1.sf2" title="Fig. 1(b) â€£ Fig. 1 â€£ 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> pose estimation by OpenPoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, <a href="#S1.F1.sf3" title="Fig. 1(c) â€£ Fig. 1 â€£ 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(c)</span></a> our method.</span></figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The understanding of visual narration in Greek vase paintings is one of the main objectives in the field of Classical Archaeology. In order to display the actions and situations of a narrative, as well as to characterise the protagonists, ancient Greek artists made use of a broad variety of often similar image elementsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Some of the key aspects of the narrative are illustrated by meaningful interactions and compositional relationships (<span id="S1.p3.1.1" class="ltx_ERROR undefined">\eg</span>postures or gestures) between the characters displayed in the paintingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. For example, the divine pursuit scene (<a href="#S1.F2" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>,Â <span id="S1.p3.1.2" class="ltx_ERROR undefined">\nth</span>1Â &amp;Â <span id="S1.p3.1.3" class="ltx_ERROR undefined">\nth</span>2 column) is a recurrent narrative in Greek vase paintings, often characterised by a character moving fast from left to right and reaching out with both his arms to catch a woman on her forearm or shoulderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this work, we propose to exploit these recurrent character interactions and postures in order to navigate semantically through collections of Greek vase paintings. We address image retrieval in such databases by measuring the similarity between character postures. Since ancient Greek artists made use of the postures to depict similar narratives, the retrieved images should display the same scene.</p>
</div>
<figure id="S1.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S1.F2.1" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/02_Introduction/pursuit/v0437.jpg" id="S1.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="419" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S1.F2.2" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/02_Introduction/pursuit/v0453.jpg" id="S1.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="419" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S1.F2.3" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/02_Introduction/leading/bf0039.jpg" id="S1.F2.3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="419" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S1.F2.4" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/02_Introduction/leading/bf0040.jpg" id="S1.F2.4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="419" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.7.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.8.2" class="ltx_text" style="font-size:90%;">(<span id="S1.F2.8.2.1" class="ltx_ERROR undefined">\nth</span><span id="S1.F2.8.2.2" class="ltx_text ltx_font_italic">1Â &amp;Â <span id="S1.F2.8.2.2.1" class="ltx_ERROR undefined">\nth</span>2 columns</span>) Divine pursuit scene in ancient Greek vase paintings. The central character, <span id="S1.F2.8.2.3" class="ltx_text ltx_font_italic">a winged persecutor</span>, is depicted with a similar pose, <span id="S1.F2.8.2.4" class="ltx_ERROR undefined">\ie</span>arms extended towards the right (observer viewpoint) and legs with large strides. (<span id="S1.F2.8.2.5" class="ltx_ERROR undefined">\nth</span><span id="S1.F2.8.2.6" class="ltx_text ltx_font_italic">3Â &amp;Â <span id="S1.F2.8.2.6.1" class="ltx_ERROR undefined">\nth</span>4 columns</span>) Leading the bride scene, with the central character <span id="S1.F2.8.2.7" class="ltx_text ltx_font_italic">bride</span> depicted with similar poses with her left hand extended forward (observer viewpoint) held by the groom.</span></figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">For human pose-based image retrieval in Greek vase paintings, we need a reliable human pose estimation algorithm. We propose a two-step approach: (1) First, we apply style-transferÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> to the COCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> dataset to generate a synthetic annotated dataset with the style of Greek vase paintings and fine-tune the baseline person detection and pose estimation models on this dataset (<a href="#S1.F3" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> middle).
(2) Second, we fine-tune these models on a newly generated dataset for Classical Archaeology (<a href="#S1.F3" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> bottom).
We show that both steps improve the person detection and pose estimation tasks and thus the retrieval performance considerably.</p>
</div>
<figure id="S1.F3" class="ltx_figure"><img src="/html/2012.05616/assets/x1.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S1.F3.4.2" class="ltx_text" style="font-size:90%;">(<span id="S1.F3.4.2.1" class="ltx_text ltx_font_italic">first row, Top-down pose estimation</span>) - (<span id="S1.F3.4.2.2" class="ltx_text ltx_font_bold">A*</span>) styled person detector detects all instances, (<span id="S1.F3.4.2.3" class="ltx_text ltx_font_bold">B*</span>) for which the body joint locations are predicted using a person keypoint detector, (<span id="S1.F3.4.2.4" class="ltx_text ltx_font_bold">C*</span>) The pose skeletons are assembled by connecting the detected keypoints for each person. <span id="S1.F3.4.2.5" class="ltx_text ltx_font_bold">2 Step Training Approach:</span> <span id="S1.F3.4.2.6" class="ltx_text ltx_font_bold">Step 1</span>Â (<span id="S1.F3.4.2.7" class="ltx_text ltx_font_italic">second row, Styled Models</span>) Person Detector trained on <span id="S1.F3.4.2.8" class="ltx_text ltx_font_italic">SCP</span> persons data, and HRNet on <span id="S1.F3.4.2.9" class="ltx_text ltx_font_italic">SCP</span> poses data; <span id="S1.F3.4.2.10" class="ltx_text ltx_font_bold">Step 2</span>Â (<span id="S1.F3.4.2.11" class="ltx_text ltx_font_italic">third row, Styled-Tuned Models</span>) Styled Person Detector from <span id="S1.F3.4.2.12" class="ltx_text ltx_font_italic">second row</span> is fine-tuned on <span id="S1.F3.4.2.13" class="ltx_text ltx_font_italic">CA</span> persons data, and Styled HRNet is fine-tuned on <span id="S1.F3.4.2.14" class="ltx_text ltx_font_italic">CA</span> pose data.</span></figcaption>
</figure>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In particular, our main contributions are:

<span id="S1.I1" class="ltx_inline-enumerate">
<span id="S1.I1.i1" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">1.</span> <span id="S1.I1.i1.1" class="ltx_text">We introduce the Styled-COCO-PersonsÂ (<span id="S1.I1.i1.1.1" class="ltx_text ltx_font_bold">SCP</span>) and the ClassArchÂ (<span id="S1.I1.i1.1.2" class="ltx_text ltx_font_bold">CA</span>) datasets. <span id="S1.I1.i1.1.3" class="ltx_text ltx_font_italic">SCP</span> is a synthetic dataset, generated by applying style transfer, with different style-intensities, to the images from COCO (only â€˜personâ€™ class) to mimic the style of the ClassArch-Scenes dataset (Greek vase paintings). The <em id="S1.I1.i1.1.4" class="ltx_emph ltx_font_italic">CA</em> dataset consists of 1783 images (characters) from 1000+ Greek vase paintings along with pose keypoint annotations.
</span></span>
<span id="S1.I1.i2" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">2.</span> <span id="S1.I1.i2.1" class="ltx_text">We show that by just using styles of the ClassArch-Scenes dataset on real images, one can improve the task of human pose estimation in Greek vase paintings without requiring any annotations. We also show that fine-tuning this model with the small <em id="S1.I1.i2.1.1" class="ltx_emph ltx_font_italic">CA</em> dataset modestly enhances the performance compared to direct transfer learning.
</span></span>
<span id="S1.I1.i3" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">3.</span> <span id="S1.I1.i3.1" class="ltx_text">We introduce a perceptual loss for style-transfer and show that this is beneficial for both person detection and pose estimation.
</span></span>
<span id="S1.I1.i4" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">4.</span> <span id="S1.I1.i4.1" class="ltx_text">Our experimental results show how our styled (before fine-tuning on Greek vase paintings) and fine-tuned models outperform, qualitatively and quantitatively, the current state-of-the-art methods on the Styled-COCO and ClassArch-Scenes datasets.
</span></span>
<span id="S1.I1.i5" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">5.</span> <span id="S1.I1.i5.1" class="ltx_text">Additionally,
we show that our styled transfer learning based pipeline is also beneficial for retrieving and discovering similar images based on poses of the character in narratives from ancient Greek vase paintings.
</span></span>
</span></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The task of representing human poses has been studied since the early days of computer visionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. However, its importance is much older. <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">Pathosformeln</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, the iconic study of basic constructs (units) of body language is one of the firsts to view the body gesture (or posture) also as a way of voicing inner emotions. Body movementâ€™s depiction is essential and central to the historianÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, since it gives a way to recognise the inner emotions or expressions of the character. ImpettÂ <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> studies it with a geometrical construct by operationalisation of body movements, which could be considered a way of Pathosformeln. McNivenÂ <span id="S2.p1.1.3" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> also used human poses as the basis to study the interactions between characters in ancient vase paintings.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Since several years, Convolutional Neural Networks (CNNs) have been dominating computer vision tasks, and HPE is not an exception. After <span id="S2.p2.1.1" class="ltx_text ltx_font_italic">DeepPose</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, methods followed that improved HPE by using CNN cascadesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> and graphical modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. Two major types of approaches are popular with HPE: <em id="S2.p2.1.2" class="ltx_emph ltx_font_italic">bottom-up</em> and <em id="S2.p2.1.3" class="ltx_emph ltx_font_italic">top-down</em>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Bottom-up pose estimation approaches</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> directly estimate the location of all keypoints and assemble them into pose skeletons for all people in the image simultaneously. They use CNNs like ResNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and DenseNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> as backbones to predict keypoints and optimisation-based matching techniques like <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">DeepCut</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> and <span id="S2.p3.1.3" class="ltx_text ltx_font_italic">DeeperCut</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> for combining the keypoints into poses. CaoÂ <span id="S2.p3.1.4" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> introduced <span id="S2.p3.1.5" class="ltx_text ltx_font_italic">Part Affinity Fields</span> (PAFs) which is able to estimate poses in real-time by solving a bi-partite graph matching problem, as a way to solve the optimisation problem of aggregating poses. Bottom-up techniquesâ€™ lack of structural information leads to many false positives and often being outperformed by top-down pose estimation approaches.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Top-down pose estimation methods</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> approach HPE in two steps (<a href="#S1.F3" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>,Â <span id="S2.p4.1.2" class="ltx_text ltx_font_italic">first row</span>). The first step addresses the problem of detecting all person instances in the image, whereas the second step aims at predicting the body-keypoints for each of the detected person. For person detection, a specific CNN, <span id="S2.p4.1.3" class="ltx_ERROR undefined">\eg</span>, from the R-CNN family <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> is normally used. The second step involves using a single-person pose estimation model to process each of the person instances independently. TompsonÂ <span id="S2.p4.1.4" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> first proposed the use of a CNN with multi-resolution receptive fields for the task of body joint localisation. More recent methods, however, focus on refinement techniques, such as Iterative Error FeedbackÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, Stacked-hour-glass networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> and PoseFixÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Multi-scale approach by SunÂ <span id="S2.p4.1.5" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> uses a novel architecture to maintain high-resolution representations through the whole estimation process by repeated multi-scale feature fusions. These SOTA methods have improved the performance on their respective benchmark datasets, however, they fail to generalise to domains like Greek vase paintings.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Domain adaptation via Style-transfer</span> based approaches mainly transfer the style of target to the source while training online as a way of domain adaption, using style lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> or even adapting the domain progressivelyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. Some methods also use feature level alignment for aligning the two domainsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, and others enforce it via self-similarity and domain-dissimilarity lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. A work closely related to ours, Jenicek <span id="S2.p5.1.2" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, highlights the importance of using poses for artwork discovery and its subsequent analysis. Their study, however, is based on artworks with case study of images that are relatively simpler for SOTA like OpenPoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> to estimate the poses. However, images from ancient Greek Vase paintings presents a completely different challenge, since OpenPose fails very often (<a href="#S1.F1" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">Our workâ€™s focus, instead, is on using the style transfer to generate a synthetic dataset from already existing labelled dataset like COCO to improve the pose estimation on unlabelled data like ancient Greek vases, by enforcing a pre-computed perceptual consistency loss.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we explain the datasets used for training our models and we also explain in detail our style-based transfer learning approach to enhance pose estimation.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Datasets</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In order to train deep networks in a supervised fashion, it is very important to have a high-quality annotated dataset. Hence we work with 3 main datasets <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">viz</span>.Â <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_bold">COCO-Persons (CP)</span> with images of only the â€˜personâ€™ category, its corresponding styled counterpart called <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_bold">Styled-COCO-Persons (SCP)</span>, and we also introduce our own annotated dataset called <span id="S3.SS1.p1.1.4" class="ltx_text ltx_font_bold">ClassArch (CA)</span>. Each dataset is labelled with person bounding boxes and their corresponding body pose keypoints, details shown inÂ <a href="#S3.T1" title="In 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>. We focus on these datasets for training and evaluation of our models.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.1" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/04_Methods/original_430521.jpg" id="S3.F4.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="479" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.2" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/x2.png" id="S3.F4.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="368" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.3" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/04_Methods/scoco_style_scenes_alpha_05_id_430521.jpg" id="S3.F4.3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="479" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.4" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/04_Methods/scoco_style_scenes_alpha_random_012_id_430521.jpg" id="S3.F4.4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="479" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.5" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/04_Methods/bf0017.jpeg" id="S3.F4.5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="479" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.6" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/x3.png" id="S3.F4.6.g1" class="ltx_graphics ltx_img_landscape" width="461" height="368" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/04_Methods/original_529277.jpg" id="S3.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="479" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><em id="S3.F4.sf1.4.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CP</em><span id="S3.F4.sf1.5.3" class="ltx_text" style="font-size:90%;"> Images</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/x4.png" id="S3.F4.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="369" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><em id="S3.F4.sf2.4.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CP</em><span id="S3.F4.sf2.5.3" class="ltx_text" style="font-size:90%;"> Labels</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/04_Methods/scoco_style_scenes_alpha_05_id_529277.jpg" id="S3.F4.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="479" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf3.5.2.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><em id="S3.F4.sf3.6.3" class="ltx_emph ltx_font_italic" style="font-size:90%;">SCP</em><span id="S3.F4.sf3.2.1" class="ltx_text" style="font-size:90%;">, <math id="S3.F4.sf3.2.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S3.F4.sf3.2.1.m1.1b"><mrow id="S3.F4.sf3.2.1.m1.1.1" xref="S3.F4.sf3.2.1.m1.1.1.cmml"><mi id="S3.F4.sf3.2.1.m1.1.1.2" xref="S3.F4.sf3.2.1.m1.1.1.2.cmml">Î±</mi><mo id="S3.F4.sf3.2.1.m1.1.1.1" xref="S3.F4.sf3.2.1.m1.1.1.1.cmml">=</mo><mn id="S3.F4.sf3.2.1.m1.1.1.3" xref="S3.F4.sf3.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F4.sf3.2.1.m1.1c"><apply id="S3.F4.sf3.2.1.m1.1.1.cmml" xref="S3.F4.sf3.2.1.m1.1.1"><eq id="S3.F4.sf3.2.1.m1.1.1.1.cmml" xref="S3.F4.sf3.2.1.m1.1.1.1"></eq><ci id="S3.F4.sf3.2.1.m1.1.1.2.cmml" xref="S3.F4.sf3.2.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="S3.F4.sf3.2.1.m1.1.1.3.cmml" xref="S3.F4.sf3.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.sf3.2.1.m1.1d">\alpha=0.5</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/04_Methods/scoco_style_scenes_random_alpha_08_id_529277.jpg" id="S3.F4.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="479" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf4.5.2.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><em id="S3.F4.sf4.6.3" class="ltx_emph ltx_font_italic" style="font-size:90%;">SCP</em><span id="S3.F4.sf4.2.1" class="ltx_text" style="font-size:90%;">, <math id="S3.F4.sf4.2.1.m1.1" class="ltx_Math" alttext="\alpha=U" display="inline"><semantics id="S3.F4.sf4.2.1.m1.1b"><mrow id="S3.F4.sf4.2.1.m1.1.1" xref="S3.F4.sf4.2.1.m1.1.1.cmml"><mi id="S3.F4.sf4.2.1.m1.1.1.2" xref="S3.F4.sf4.2.1.m1.1.1.2.cmml">Î±</mi><mo id="S3.F4.sf4.2.1.m1.1.1.1" xref="S3.F4.sf4.2.1.m1.1.1.1.cmml">=</mo><mi id="S3.F4.sf4.2.1.m1.1.1.3" xref="S3.F4.sf4.2.1.m1.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.F4.sf4.2.1.m1.1c"><apply id="S3.F4.sf4.2.1.m1.1.1.cmml" xref="S3.F4.sf4.2.1.m1.1.1"><eq id="S3.F4.sf4.2.1.m1.1.1.1.cmml" xref="S3.F4.sf4.2.1.m1.1.1.1"></eq><ci id="S3.F4.sf4.2.1.m1.1.1.2.cmml" xref="S3.F4.sf4.2.1.m1.1.1.2">ğ›¼</ci><ci id="S3.F4.sf4.2.1.m1.1.1.3.cmml" xref="S3.F4.sf4.2.1.m1.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.sf4.2.1.m1.1d">\alpha=U</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf5" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/04_Methods/bf0029.jpeg" id="S3.F4.sf5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="479" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf5.3.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><em id="S3.F4.sf5.4.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CA</em><span id="S3.F4.sf5.5.3" class="ltx_text" style="font-size:90%;"> Images</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf6" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/x5.png" id="S3.F4.sf6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="462" height="368" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf6.3.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><em id="S3.F4.sf6.4.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CA</em><span id="S3.F4.sf6.5.3" class="ltx_text" style="font-size:90%;"> Labels</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.12.3.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.10.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Dataset Samples<span id="S3.F4.10.2.2" class="ltx_text ltx_font_medium">:<a href="#S3.F4.sf1" title="Fig. 4(a) â€£ Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a> Images &amp; <a href="#S3.F4.sf2" title="Fig. 4(b) â€£ Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a> Labels of <em id="S3.F4.10.2.2.1" class="ltx_emph ltx_font_italic">CP</em> dataset; <a href="#S3.F4.sf3" title="Fig. 4(c) â€£ Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(c)</span></a> &amp; <a href="#S3.F4.sf4" title="Fig. 4(d) â€£ Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(d)</span></a> are samples from the <em id="S3.F4.10.2.2.2" class="ltx_emph ltx_font_italic">SCP</em> dataset with <math id="S3.F4.9.1.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S3.F4.9.1.1.m1.1b"><mrow id="S3.F4.9.1.1.m1.1.1" xref="S3.F4.9.1.1.m1.1.1.cmml"><mi id="S3.F4.9.1.1.m1.1.1.2" xref="S3.F4.9.1.1.m1.1.1.2.cmml">Î±</mi><mo id="S3.F4.9.1.1.m1.1.1.1" xref="S3.F4.9.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.F4.9.1.1.m1.1.1.3" xref="S3.F4.9.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F4.9.1.1.m1.1c"><apply id="S3.F4.9.1.1.m1.1.1.cmml" xref="S3.F4.9.1.1.m1.1.1"><eq id="S3.F4.9.1.1.m1.1.1.1.cmml" xref="S3.F4.9.1.1.m1.1.1.1"></eq><ci id="S3.F4.9.1.1.m1.1.1.2.cmml" xref="S3.F4.9.1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="S3.F4.9.1.1.m1.1.1.3.cmml" xref="S3.F4.9.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.9.1.1.m1.1d">\alpha=0.5</annotation></semantics></math> and <math id="S3.F4.10.2.2.m2.1" class="ltx_Math" alttext="\alpha=U" display="inline"><semantics id="S3.F4.10.2.2.m2.1b"><mrow id="S3.F4.10.2.2.m2.1.1" xref="S3.F4.10.2.2.m2.1.1.cmml"><mi id="S3.F4.10.2.2.m2.1.1.2" xref="S3.F4.10.2.2.m2.1.1.2.cmml">Î±</mi><mo id="S3.F4.10.2.2.m2.1.1.1" xref="S3.F4.10.2.2.m2.1.1.1.cmml">=</mo><mi id="S3.F4.10.2.2.m2.1.1.3" xref="S3.F4.10.2.2.m2.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.F4.10.2.2.m2.1c"><apply id="S3.F4.10.2.2.m2.1.1.cmml" xref="S3.F4.10.2.2.m2.1.1"><eq id="S3.F4.10.2.2.m2.1.1.1.cmml" xref="S3.F4.10.2.2.m2.1.1.1"></eq><ci id="S3.F4.10.2.2.m2.1.1.2.cmml" xref="S3.F4.10.2.2.m2.1.1.2">ğ›¼</ci><ci id="S3.F4.10.2.2.m2.1.1.3.cmml" xref="S3.F4.10.2.2.m2.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.10.2.2.m2.1d">\alpha=U</annotation></semantics></math> respectively; <a href="#S3.F4.sf5" title="Fig. 4(e) â€£ Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(e)</span></a> shows images with <a href="#S3.F4.sf6" title="Fig. 4(f) â€£ Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(f)</span></a> the corresponding labels of our <em id="S3.F4.10.2.2.3" class="ltx_emph ltx_font_italic">CA</em> dataset. Each labelled example shows the corresponding person bounding boxes and their pose keypoints.</span></span></figcaption>
</figure>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.5.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Datasets<span id="S3.T1.6.2.1" class="ltx_text ltx_font_medium"> used in our experiments. For COCO-PersonsÂ (<em id="S3.T1.6.2.1.1" class="ltx_emph ltx_font_italic">CP</em>), we use images from the person category of COCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Styled-COCO-PersonsÂ (<em id="S3.T1.6.2.1.2" class="ltx_emph ltx_font_italic">SCP</em>) is generated by using <em id="S3.T1.6.2.1.3" class="ltx_emph ltx_font_italic">CP</em> images as <span id="S3.T1.6.2.1.4" class="ltx_text ltx_font_italic">content</span> and various splits of ClassArchÂ (<em id="S3.T1.6.2.1.5" class="ltx_emph ltx_font_italic">CA</em>) images as <span id="S3.T1.6.2.1.6" class="ltx_text ltx_font_italic">styles</span> (<span id="S3.T1.6.2.1.7" class="ltx_text ltx_font_italic">Images:</span> images, <span id="S3.T1.6.2.1.8" class="ltx_text ltx_font_italic">Persons:</span> person bounding boxes, <span id="S3.T1.6.2.1.9" class="ltx_text ltx_font_italic">Poses:</span> pose annotations).</span></span></figcaption>
<table id="S3.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S3.T1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Dataset<math id="S3.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.T1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math></span></th>
<th id="S3.T1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S3.T1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">CP &amp; SCP</span></th>
<th id="S3.T1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S3.T1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">CA</span></th>
</tr>
<tr id="S3.T1.2.2" class="ltx_tr">
<th id="S3.T1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.2.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Split<math id="S3.T1.2.2.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.T1.2.2.1.1.m1.1a"><mo stretchy="false" id="S3.T1.2.2.1.1.m1.1.1" xref="S3.T1.2.2.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.1.1.m1.1b"><ci id="S3.T1.2.2.1.1.m1.1.1.cmml" xref="S3.T1.2.2.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.1.1.m1.1c">\rightarrow</annotation></semantics></math></span></th>
<th id="S3.T1.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Train/Val</span></th>
<th id="S3.T1.2.2.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.2.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Total</span></th>
<th id="S3.T1.2.2.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.2.2.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Train/Val</span></th>
<th id="S3.T1.2.2.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.2.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Total</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.2.3.1" class="ltx_tr">
<td id="S3.T1.2.3.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T1.2.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Images</span></td>
<td id="S3.T1.2.3.1.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.2.3.1.2.1" class="ltx_text" style="font-size:90%;">64115/2693</span></td>
<td id="S3.T1.2.3.1.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.2.3.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">66808</span></td>
<td id="S3.T1.2.3.1.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.2.3.1.4.1" class="ltx_text" style="font-size:90%;">1210/303</span></td>
<td id="S3.T1.2.3.1.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T1.2.3.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">1513</span></td>
</tr>
<tr id="S3.T1.2.4.2" class="ltx_tr">
<td id="S3.T1.2.4.2.1" class="ltx_td ltx_align_left"><span id="S3.T1.2.4.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Persons</span></td>
<td id="S3.T1.2.4.2.2" class="ltx_td ltx_align_right"><span id="S3.T1.2.4.2.2.1" class="ltx_text" style="font-size:90%;">257252/10777</span></td>
<td id="S3.T1.2.4.2.3" class="ltx_td ltx_align_right"><span id="S3.T1.2.4.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">268029</span></td>
<td id="S3.T1.2.4.2.4" class="ltx_td ltx_align_right"><span id="S3.T1.2.4.2.4.1" class="ltx_text" style="font-size:90%;">2098/531</span></td>
<td id="S3.T1.2.4.2.5" class="ltx_td ltx_align_left"><span id="S3.T1.2.4.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">2629</span></td>
</tr>
<tr id="S3.T1.2.5.3" class="ltx_tr">
<td id="S3.T1.2.5.3.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T1.2.5.3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Poses</span></td>
<td id="S3.T1.2.5.3.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T1.2.5.3.2.1" class="ltx_text" style="font-size:90%;">149813/6352</span></td>
<td id="S3.T1.2.5.3.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T1.2.5.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">156165</span></td>
<td id="S3.T1.2.5.3.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T1.2.5.3.4.1" class="ltx_text" style="font-size:90%;">1425/303</span></td>
<td id="S3.T1.2.5.3.5" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T1.2.5.3.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">1728</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">COCO-Persons<em id="S3.SS1.p2.1.1.1" class="ltx_emph ltx_font_medium ltx_font_italic">Â (CP)</em></span>
The Common Objects in COntext dataset (COCO)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> was specifically designed for the detection and segmentation of objects in their natural context. COCO has 328K images with over 2.5M labelled instances divided into 91 semantic object categories (<span id="S3.SS1.p2.1.2" class="ltx_ERROR undefined">\eg</span>car, person, dog, banana, <span id="S3.SS1.p2.1.3" class="ltx_ERROR undefined">\etc</span>). We only consider images that include â€œpersonâ€ instances, along with their corresponding bounding boxes and pose-keypoints. We call this split as <span id="S3.SS1.p2.1.4" class="ltx_text ltx_font_bold">COCO-Persons<em id="S3.SS1.p2.1.4.1" class="ltx_emph ltx_font_medium ltx_font_italic">Â (CP)</em></span>. This split is taken across the training and validation sets only since the labels for the test set are not publicly available. Consequently, we use the validation set for testing our models. <a href="#S3.T1" title="In 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> shows the exact splits for the dataset in terms of images, persons and pose-keypoints. <a href="#S3.F4.sf1" title="In Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figs.</span>Â <span class="ltx_text ltx_ref_tag">4(a)</span></a> andÂ <a href="#S3.F4.sf2" title="Fig. 4(b) â€£ Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a> illustrate some samples of <span id="S3.SS1.p2.1.5" class="ltx_text ltx_font_italic">CP</span> dataset.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">ClassArch<em id="S3.SS1.p3.1.1.1" class="ltx_emph ltx_font_medium ltx_font_italic">Â (CA)</em></span>
We introduce a challenging dataset from the domain of Classical Archaeology, called <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_bold">ClassArch<em id="S3.SS1.p3.1.2.1" class="ltx_emph ltx_font_medium ltx_font_italic">Â (CA)</em></span> dataset. We chose five different recurrent narratives, <span id="S3.SS1.p3.1.3" class="ltx_text ltx_font_italic">viz</span>.Â â€˜Pursuitsâ€™, â€˜Leading of the Brideâ€™, â€˜Abductionsâ€™, and â€˜Wrestlingâ€™ in <span id="S3.SS1.p3.1.4" class="ltx_text ltx_font_italic">Agonal</span> and <span id="S3.SS1.p3.1.5" class="ltx_text ltx_font_italic">Mythological</span> contexts, taken from the period between the <span id="S3.SS1.p3.1.6" class="ltx_ERROR undefined">\nth</span>6 and <span id="S3.SS1.p3.1.7" class="ltx_ERROR undefined">\nth</span>5 century BCE. Pose-based analysis of such paintings is of critical importance for Classical Archaeology as discussed inÂ <a href="#S1" title="1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>. Each of the narratives in <span id="S3.SS1.p3.1.8" class="ltx_text ltx_font_italic">CA</span> has its own set of characters, which appear recurrently and are depicted with similar features and in almost identical poses. <a href="#S3.F4.sf5" title="In Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figs.</span>Â <span class="ltx_text ltx_ref_tag">4(e)</span></a> andÂ <a href="#S3.F4.sf6" title="Fig. 4(f) â€£ Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(f)</span></a> illustrate some images and their corresponding person bounding boxes and person keypoints of the <span id="S3.SS1.p3.1.9" class="ltx_text ltx_font_italic">CA</span> dataset. <a href="#S1.F2" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a> displays two examples from the â€˜Pursuitâ€™ (<span id="S3.SS1.p3.1.10" class="ltx_ERROR undefined">\nth</span>1Â &amp;Â <span id="S3.SS1.p3.1.11" class="ltx_ERROR undefined">\nth</span>2 column) and â€˜Leading the brideâ€™ (bottom row) narratives. In both scenes, the main characters (â€˜persecutorâ€™/â€˜fleeingâ€™ &amp; â€˜brideâ€™) are depicted with similar posture in every image. <span id="S3.SS1.p3.1.12" class="ltx_text ltx_font_italic">CA</span> has different sets of labels associated with it. There are 1513 images, with 2629 person annotations and 1728 pose annotations. More detailed splits are shown inÂ <a href="#S3.T1" title="In 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Styled-COCO-Persons (SCP)</span>
The images in <span id="S3.SS1.p4.1.2" class="ltx_text ltx_font_italic">CP</span> significantly differ in semantic content and style from the ancient Greek vase paintings, <span id="S3.SS1.p4.1.3" class="ltx_ERROR undefined">\cf</span><a href="#S3.F4.sf1" title="In Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">4(a)</span></a> vs.Â <a href="#S3.F4.sf5" title="In Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">4(e)</span></a>).
To bridge this domain gap between <span id="S3.SS1.p4.1.4" class="ltx_text ltx_font_italic">CP</span> and <span id="S3.SS1.p4.1.5" class="ltx_text ltx_font_italic">CA</span>, we use style transfer to adapt the style of the CP dataset to vase paintings.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">Style transfer algorithms render a synthetic image that combines the semantic information from one input (denoted as <span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_italic">content image</span>) with the texture from the user-defined <span id="S3.SS1.p5.1.2" class="ltx_text ltx_font_italic">style image</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. We apply an efficient and fast style transfer technique using adaptive instance normalisation (<span id="S3.SS1.p5.1.3" class="ltx_text ltx_font_italic">AdaIN</span>)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> to create <span id="S3.SS1.p5.1.4" class="ltx_text ltx_font_italic">SCP</span>, a synthetic dataset that combines the semantic content of the <span id="S3.SS1.p5.1.5" class="ltx_text ltx_font_italic">CP</span> with the style of <span id="S3.SS1.p5.1.6" class="ltx_text ltx_font_italic">CA</span>. <a href="#S3.F5" title="In 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a> illustrates the style transfer procedure. We can visually observe that images of <a href="#S3.F4.sf3" title="In Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figs.</span>Â <span class="ltx_text ltx_ref_tag">4(c)</span></a> andÂ <a href="#S3.F4.sf4" title="Fig. 4(d) â€£ Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(d)</span></a> are more closer in styles with <a href="#S3.F4.sf5" title="In Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">4(e)</span></a> than <a href="#S3.F4.sf1" title="In Fig. 4 â€£ 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">4(a)</span></a>, <span id="S3.SS1.p5.1.7" class="ltx_ERROR undefined">\ie</span><span id="S3.SS1.p5.1.8" class="ltx_text ltx_font_italic">SCP</span> is closer in style with <span id="S3.SS1.p5.1.9" class="ltx_text ltx_font_italic">CA</span>, than <span id="S3.SS1.p5.1.10" class="ltx_text ltx_font_italic">CP</span> is with <span id="S3.SS1.p5.1.11" class="ltx_text ltx_font_italic">CA</span>.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2012.05616/assets/x6.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="246" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.4.2.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.2.1" class="ltx_text" style="font-size:90%;">Style transfer using <span id="S3.F5.2.1.1" class="ltx_text ltx_font_italic">AdaIN</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> with full style intensity (<math id="S3.F5.2.1.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S3.F5.2.1.m1.1b"><mrow id="S3.F5.2.1.m1.1.1" xref="S3.F5.2.1.m1.1.1.cmml"><mi id="S3.F5.2.1.m1.1.1.2" xref="S3.F5.2.1.m1.1.1.2.cmml">Î±</mi><mo id="S3.F5.2.1.m1.1.1.1" xref="S3.F5.2.1.m1.1.1.1.cmml">=</mo><mn id="S3.F5.2.1.m1.1.1.3" xref="S3.F5.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F5.2.1.m1.1c"><apply id="S3.F5.2.1.m1.1.1.cmml" xref="S3.F5.2.1.m1.1.1"><eq id="S3.F5.2.1.m1.1.1.1.cmml" xref="S3.F5.2.1.m1.1.1.1"></eq><ci id="S3.F5.2.1.m1.1.1.2.cmml" xref="S3.F5.2.1.m1.1.1.2">ğ›¼</ci><cn type="integer" id="S3.F5.2.1.m1.1.1.3.cmml" xref="S3.F5.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.2.1.m1.1d">\alpha=1</annotation></semantics></math>). <span id="S3.F5.2.1.2" class="ltx_text ltx_font_italic">AdaIN</span> adjusts the first and second order moments of the â€˜Content Imageâ€™ to match those of the â€˜Style Imageâ€™. A â€˜Styled Imageâ€™ (style-transferred) is generated with the semantic content of the â€˜content imageâ€™ and style of the â€˜Style Imageâ€™.</span></figcaption>
</figure>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.7" class="ltx_p"><span id="S3.SS1.p6.1.1" class="ltx_text ltx_font_bold">Alpha <math id="S3.SS1.p6.1.1.m1.1" class="ltx_Math" alttext="(\alpha)" display="inline"><semantics id="S3.SS1.p6.1.1.m1.1a"><mrow id="S3.SS1.p6.1.1.m1.1.2.2"><mo stretchy="false" id="S3.SS1.p6.1.1.m1.1.2.2.1">(</mo><mi id="S3.SS1.p6.1.1.m1.1.1" xref="S3.SS1.p6.1.1.m1.1.1.cmml">Î±</mi><mo stretchy="false" id="S3.SS1.p6.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.1.m1.1b"><ci id="S3.SS1.p6.1.1.m1.1.1.cmml" xref="S3.SS1.p6.1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.1.m1.1c">(\alpha)</annotation></semantics></math> and Style-Sets</span>
HuangÂ <span id="S3.SS1.p6.7.2" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> suggest a content-style trade-off technique to control the intensity of style transferred to the content image using <math id="S3.SS1.p6.2.m1.2" class="ltx_Math" alttext="\alpha\in[0,1]" display="inline"><semantics id="S3.SS1.p6.2.m1.2a"><mrow id="S3.SS1.p6.2.m1.2.3" xref="S3.SS1.p6.2.m1.2.3.cmml"><mi id="S3.SS1.p6.2.m1.2.3.2" xref="S3.SS1.p6.2.m1.2.3.2.cmml">Î±</mi><mo id="S3.SS1.p6.2.m1.2.3.1" xref="S3.SS1.p6.2.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.p6.2.m1.2.3.3.2" xref="S3.SS1.p6.2.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p6.2.m1.2.3.3.2.1" xref="S3.SS1.p6.2.m1.2.3.3.1.cmml">[</mo><mn id="S3.SS1.p6.2.m1.1.1" xref="S3.SS1.p6.2.m1.1.1.cmml">0</mn><mo id="S3.SS1.p6.2.m1.2.3.3.2.2" xref="S3.SS1.p6.2.m1.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p6.2.m1.2.2" xref="S3.SS1.p6.2.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.p6.2.m1.2.3.3.2.3" xref="S3.SS1.p6.2.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m1.2b"><apply id="S3.SS1.p6.2.m1.2.3.cmml" xref="S3.SS1.p6.2.m1.2.3"><in id="S3.SS1.p6.2.m1.2.3.1.cmml" xref="S3.SS1.p6.2.m1.2.3.1"></in><ci id="S3.SS1.p6.2.m1.2.3.2.cmml" xref="S3.SS1.p6.2.m1.2.3.2">ğ›¼</ci><interval closure="closed" id="S3.SS1.p6.2.m1.2.3.3.1.cmml" xref="S3.SS1.p6.2.m1.2.3.3.2"><cn type="integer" id="S3.SS1.p6.2.m1.1.1.cmml" xref="S3.SS1.p6.2.m1.1.1">0</cn><cn type="integer" id="S3.SS1.p6.2.m1.2.2.cmml" xref="S3.SS1.p6.2.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.2.m1.2c">\alpha\in[0,1]</annotation></semantics></math>. Based on this, we generate 2 groups of <span id="S3.SS1.p6.7.3" class="ltx_text ltx_font_italic">SCP</span>. First with <math id="S3.SS1.p6.3.m2.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S3.SS1.p6.3.m2.1a"><mrow id="S3.SS1.p6.3.m2.1.1" xref="S3.SS1.p6.3.m2.1.1.cmml"><mi id="S3.SS1.p6.3.m2.1.1.2" xref="S3.SS1.p6.3.m2.1.1.2.cmml">Î±</mi><mo id="S3.SS1.p6.3.m2.1.1.1" xref="S3.SS1.p6.3.m2.1.1.1.cmml">=</mo><mn id="S3.SS1.p6.3.m2.1.1.3" xref="S3.SS1.p6.3.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.3.m2.1b"><apply id="S3.SS1.p6.3.m2.1.1.cmml" xref="S3.SS1.p6.3.m2.1.1"><eq id="S3.SS1.p6.3.m2.1.1.1.cmml" xref="S3.SS1.p6.3.m2.1.1.1"></eq><ci id="S3.SS1.p6.3.m2.1.1.2.cmml" xref="S3.SS1.p6.3.m2.1.1.2">ğ›¼</ci><cn type="float" id="S3.SS1.p6.3.m2.1.1.3.cmml" xref="S3.SS1.p6.3.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.3.m2.1c">\alpha=0.5</annotation></semantics></math>, meaning that we only transfer half of the style intensity to the content images; and a second one in which <math id="S3.SS1.p6.4.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p6.4.m3.1a"><mi id="S3.SS1.p6.4.m3.1.1" xref="S3.SS1.p6.4.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.4.m3.1b"><ci id="S3.SS1.p6.4.m3.1.1.cmml" xref="S3.SS1.p6.4.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.4.m3.1c">\alpha</annotation></semantics></math> is chosen randomly from the uniform distribution <math id="S3.SS1.p6.5.m4.2" class="ltx_Math" alttext="U[0,1]" display="inline"><semantics id="S3.SS1.p6.5.m4.2a"><mrow id="S3.SS1.p6.5.m4.2.3" xref="S3.SS1.p6.5.m4.2.3.cmml"><mi id="S3.SS1.p6.5.m4.2.3.2" xref="S3.SS1.p6.5.m4.2.3.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p6.5.m4.2.3.1" xref="S3.SS1.p6.5.m4.2.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p6.5.m4.2.3.3.2" xref="S3.SS1.p6.5.m4.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p6.5.m4.2.3.3.2.1" xref="S3.SS1.p6.5.m4.2.3.3.1.cmml">[</mo><mn id="S3.SS1.p6.5.m4.1.1" xref="S3.SS1.p6.5.m4.1.1.cmml">0</mn><mo id="S3.SS1.p6.5.m4.2.3.3.2.2" xref="S3.SS1.p6.5.m4.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p6.5.m4.2.2" xref="S3.SS1.p6.5.m4.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.p6.5.m4.2.3.3.2.3" xref="S3.SS1.p6.5.m4.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.5.m4.2b"><apply id="S3.SS1.p6.5.m4.2.3.cmml" xref="S3.SS1.p6.5.m4.2.3"><times id="S3.SS1.p6.5.m4.2.3.1.cmml" xref="S3.SS1.p6.5.m4.2.3.1"></times><ci id="S3.SS1.p6.5.m4.2.3.2.cmml" xref="S3.SS1.p6.5.m4.2.3.2">ğ‘ˆ</ci><interval closure="closed" id="S3.SS1.p6.5.m4.2.3.3.1.cmml" xref="S3.SS1.p6.5.m4.2.3.3.2"><cn type="integer" id="S3.SS1.p6.5.m4.1.1.cmml" xref="S3.SS1.p6.5.m4.1.1">0</cn><cn type="integer" id="S3.SS1.p6.5.m4.2.2.cmml" xref="S3.SS1.p6.5.m4.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.5.m4.2c">U[0,1]</annotation></semantics></math>. The second group contains images across the whole spectrum, from no style (<math id="S3.SS1.p6.6.m5.1" class="ltx_Math" alttext="\alpha=0" display="inline"><semantics id="S3.SS1.p6.6.m5.1a"><mrow id="S3.SS1.p6.6.m5.1.1" xref="S3.SS1.p6.6.m5.1.1.cmml"><mi id="S3.SS1.p6.6.m5.1.1.2" xref="S3.SS1.p6.6.m5.1.1.2.cmml">Î±</mi><mo id="S3.SS1.p6.6.m5.1.1.1" xref="S3.SS1.p6.6.m5.1.1.1.cmml">=</mo><mn id="S3.SS1.p6.6.m5.1.1.3" xref="S3.SS1.p6.6.m5.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.6.m5.1b"><apply id="S3.SS1.p6.6.m5.1.1.cmml" xref="S3.SS1.p6.6.m5.1.1"><eq id="S3.SS1.p6.6.m5.1.1.1.cmml" xref="S3.SS1.p6.6.m5.1.1.1"></eq><ci id="S3.SS1.p6.6.m5.1.1.2.cmml" xref="S3.SS1.p6.6.m5.1.1.2">ğ›¼</ci><cn type="integer" id="S3.SS1.p6.6.m5.1.1.3.cmml" xref="S3.SS1.p6.6.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.6.m5.1c">\alpha=0</annotation></semantics></math>) to full style (<math id="S3.SS1.p6.7.m6.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S3.SS1.p6.7.m6.1a"><mrow id="S3.SS1.p6.7.m6.1.1" xref="S3.SS1.p6.7.m6.1.1.cmml"><mi id="S3.SS1.p6.7.m6.1.1.2" xref="S3.SS1.p6.7.m6.1.1.2.cmml">Î±</mi><mo id="S3.SS1.p6.7.m6.1.1.1" xref="S3.SS1.p6.7.m6.1.1.1.cmml">=</mo><mn id="S3.SS1.p6.7.m6.1.1.3" xref="S3.SS1.p6.7.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.7.m6.1b"><apply id="S3.SS1.p6.7.m6.1.1.cmml" xref="S3.SS1.p6.7.m6.1.1"><eq id="S3.SS1.p6.7.m6.1.1.1.cmml" xref="S3.SS1.p6.7.m6.1.1.1"></eq><ci id="S3.SS1.p6.7.m6.1.1.2.cmml" xref="S3.SS1.p6.7.m6.1.1.2">ğ›¼</ci><cn type="integer" id="S3.SS1.p6.7.m6.1.1.3.cmml" xref="S3.SS1.p6.7.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.7.m6.1c">\alpha=1</annotation></semantics></math>).</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p id="S3.SS1.p7.1" class="ltx_p">Additionally, we generate two more <span id="S3.SS1.p7.1.1" class="ltx_text ltx_font_italic">SCP</span> variations, where we use a different set of style images. We call this set as <span id="S3.SS1.p7.1.2" class="ltx_text ltx_font_bold">Red-Black</span> figures (100 in total) or <span id="S3.SS1.p7.1.3" class="ltx_text ltx_font_italic">just</span> <span id="S3.SS1.p7.1.4" class="ltx_text ltx_font_bold">RB</span>, and they are similar in style to the <span id="S3.SS1.p7.1.5" class="ltx_text ltx_font_italic">CA</span> dataset but do not have any labels. Our hypothesis is that the model should be able to learn the styles and not the content of style images. In the end, we have four groups of <span id="S3.SS1.p7.1.6" class="ltx_text ltx_font_italic">SCP</span> dataset with two different combinations of <math id="S3.SS1.p7.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p7.1.m1.1a"><mi id="S3.SS1.p7.1.m1.1.1" xref="S3.SS1.p7.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.1.m1.1b"><ci id="S3.SS1.p7.1.m1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.1.m1.1c">\alpha</annotation></semantics></math> with the two style-sets <span id="S3.SS1.p7.1.7" class="ltx_text ltx_font_italic">RB</span> and <span id="S3.SS1.p7.1.8" class="ltx_text ltx_font_italic">CA</span>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Pose Estimation Approach</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We take a top-down approach to pose-estimation, which is divided into two stages. <a href="#S1.F3" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> details the two stages of the top-down approach. The first stage (<span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">A/A*</span>) detects all the persons in an image and then estimates the keypoints (<span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">B/B*</span>) for each person instance, then creating the poses for each instance by pose-parsing (<span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_italic">C/C*</span>). We use Faster-RCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> as our person detector that was trained on the COCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> dataset. Top-down pose estimation approaches dominate the COCO keypoint detection challenge in the past few years, and several use the HRNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> as their backbones. Hence, we chose HRNet-W32 (henceforth denoted as <span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_italic">HRNet</span>) as our pose estimation model.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">2-Step Training Approach</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">We adopt a 2 step approach to enhancing pose estimation, as shown inÂ <a href="#S1.F3" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>. In the first stepÂ (<a href="#S1.F3" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>, <span id="S3.SS2.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">second row</span>), we train our models on styled data (different groups of <span id="S3.SS2.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_italic">SCP</span>) to generate <span id="S3.SS2.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_italic">styled</span> models. In this step, the <span id="S3.SS2.SSS0.Px1.p1.1.4" class="ltx_text ltx_font_italic">styled</span> models at the end of their training are expected to learn the styles of the target data, while trying to maintain the performance on the original task.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.1" class="ltx_p">In the second stepÂ (<a href="#S1.F3" title="In 1 Introduction â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>, <span id="S3.SS2.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_italic">third row</span>), we fine-tune these <span id="S3.SS2.SSS0.Px1.p2.1.2" class="ltx_text ltx_font_italic">styled</span> models on our <span id="S3.SS2.SSS0.Px1.p2.1.3" class="ltx_text ltx_font_italic">CA</span> data. During this step, the models that have learned the styles in the first step, now focus on improving their performance for the target dataset of <span id="S3.SS2.SSS0.Px1.p2.1.4" class="ltx_text ltx_font_italic">CA</span>.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p3.1" class="ltx_p">We report all our experiments using four kinds of models for both tasks, person detection and pose estimation.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p4" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p4.1" class="ltx_p"><span id="S3.SS2.SSS0.Px1.p4.1.1" class="ltx_text ltx_font_bold">1.Â Baseline models</span> are SOTA models. In case of the person detector, we drop the heads for all the classes except one, and fine-tune it on the â€˜personâ€™ class, further denoted as our <span id="S3.SS2.SSS0.Px1.p4.1.2" class="ltx_text ltx_font_italic">baseline</span> model.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p5" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p5.1" class="ltx_p"><span id="S3.SS2.SSS0.Px1.p5.1.1" class="ltx_text ltx_font_bold">2.Â Tuned models</span> are SOTA models fine-tuned on the <span id="S3.SS2.SSS0.Px1.p5.1.2" class="ltx_text ltx_font_italic">CA</span> dataset. For the detector, we drop all the heads except one (similar as for baseline model) in Faster-RCNN and fine-tune it on persons data of the <span id="S3.SS2.SSS0.Px1.p5.1.3" class="ltx_text ltx_font_italic">CA</span> dataset. Likewise, for pose estimation, we take the SOTA HRNet and fine-tune it on pose data of <span id="S3.SS2.SSS0.Px1.p5.1.4" class="ltx_text ltx_font_italic">CA</span>.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p6" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p6.1" class="ltx_p"><span id="S3.SS2.SSS0.Px1.p6.1.1" class="ltx_text ltx_font_bold">3.Â Styled models</span> are SOTA models trained on a particular group of the <span id="S3.SS2.SSS0.Px1.p6.1.2" class="ltx_text ltx_font_italic">SCP</span> dataset. As explained inÂ <a href="#S3.SS1" title="3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.1</span></a>, there are 4 different groups of <span id="S3.SS2.SSS0.Px1.p6.1.3" class="ltx_text ltx_font_italic">SCP</span> dataset. Depending on the values of <math id="S3.SS2.SSS0.Px1.p6.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS0.Px1.p6.1.m1.1a"><mi id="S3.SS2.SSS0.Px1.p6.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p6.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p6.1.m1.1b"><ci id="S3.SS2.SSS0.Px1.p6.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p6.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p6.1.m1.1c">\alpha</annotation></semantics></math> and <span id="S3.SS2.SSS0.Px1.p6.1.4" class="ltx_text ltx_font_italic">style-set</span> (RB or CA), the <span id="S3.SS2.SSS0.Px1.p6.1.5" class="ltx_text ltx_font_italic">Styled</span> models are trained on that particular group, for the detector as well as the pose estimator. Accordingly, there are 4 different <span id="S3.SS2.SSS0.Px1.p6.1.6" class="ltx_text ltx_font_italic">Styled</span> models for each of the detector and the pose estimator.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p7" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p7.4" class="ltx_p"><span id="S3.SS2.SSS0.Px1.p7.1.1" class="ltx_text ltx_font_bold">4.Â Styled-Tuned (Sd<math id="S3.SS2.SSS0.Px1.p7.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.SS2.SSS0.Px1.p7.1.1.m1.1a"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p7.1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p7.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p7.1.1.m1.1b"><ci id="S3.SS2.SSS0.Px1.p7.1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p7.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p7.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td) models</span> are <span id="S3.SS2.SSS0.Px1.p7.4.5" class="ltx_text ltx_font_italic">Styled</span> models ((3) above) fine-tuned on <span id="S3.SS2.SSS0.Px1.p7.4.6" class="ltx_text ltx_font_italic">CA</span> dataset. Accordingly, for the detector, <span id="S3.SS2.SSS0.Px1.p7.2.2" class="ltx_text ltx_font_italic">Sd<math id="S3.SS2.SSS0.Px1.p7.2.2.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.SS2.SSS0.Px1.p7.2.2.m1.1a"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p7.2.2.m1.1.1" xref="S3.SS2.SSS0.Px1.p7.2.2.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p7.2.2.m1.1b"><ci id="S3.SS2.SSS0.Px1.p7.2.2.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p7.2.2.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p7.2.2.m1.1c">\rightarrow</annotation></semantics></math>Td</span> model is a <span id="S3.SS2.SSS0.Px1.p7.4.7" class="ltx_text ltx_font_italic">Styled</span> Faster-RCNN model fine-tuned on <span id="S3.SS2.SSS0.Px1.p7.4.8" class="ltx_text ltx_font_italic">CA</span> persons data. Similarly, for the pose estimator, <span id="S3.SS2.SSS0.Px1.p7.3.3" class="ltx_text ltx_font_italic">Sd<math id="S3.SS2.SSS0.Px1.p7.3.3.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.SS2.SSS0.Px1.p7.3.3.m1.1a"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p7.3.3.m1.1.1" xref="S3.SS2.SSS0.Px1.p7.3.3.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p7.3.3.m1.1b"><ci id="S3.SS2.SSS0.Px1.p7.3.3.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p7.3.3.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p7.3.3.m1.1c">\rightarrow</annotation></semantics></math>Td</span> model is a <span id="S3.SS2.SSS0.Px1.p7.4.9" class="ltx_text ltx_font_italic">Styled</span> HRNet model fine-tuned on <span id="S3.SS2.SSS0.Px1.p7.4.10" class="ltx_text ltx_font_italic">CA</span> poses data. Hence, depending on the group of the <span id="S3.SS2.SSS0.Px1.p7.4.11" class="ltx_text ltx_font_italic">Styled</span> model, there is an equivalent <span id="S3.SS2.SSS0.Px1.p7.4.4" class="ltx_text ltx_font_italic">Sd<math id="S3.SS2.SSS0.Px1.p7.4.4.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.SS2.SSS0.Px1.p7.4.4.m1.1a"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p7.4.4.m1.1.1" xref="S3.SS2.SSS0.Px1.p7.4.4.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p7.4.4.m1.1b"><ci id="S3.SS2.SSS0.Px1.p7.4.4.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p7.4.4.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p7.4.4.m1.1c">\rightarrow</annotation></semantics></math>Td</span> model.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Enforcing Perceptual Similarity</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">While training <span id="S3.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">styled</span> models, the network is fed with styled data. The advantage of doing this is to allow the model to expand its capacity to recognise perceptually similar persons/poses with different styles. In order to achieve content consistency in the perceptual space, we enforce a pre-computed perceptual lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> while training, in addition to the regular loss. The model is penalised if it is not able to maintain perceptual consistency.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p2.7" class="ltx_p">We adopt two flavours of the combined loss each for the detector as well as pose. In the first flavourÂ (<math id="S3.SS2.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="L_{comb1}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.1.m1.1a"><msub id="S3.SS2.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.2" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.2.cmml">L</mi><mrow id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.2" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.3" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1a" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.4" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1b" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.5" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1c" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mn id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.6" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.6.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.1.m1.1b"><apply id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.2">ğ¿</ci><apply id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3"><times id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.1"></times><ci id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.4.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.4">ğ‘š</ci><ci id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.5.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.6.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.3.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.1.m1.1c">L_{comb1}</annotation></semantics></math>), we adaptively weigh the perceptual lossÂ (<math id="S3.SS2.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="L_{percept}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.2.m2.1a"><msub id="S3.SS2.SSS0.Px2.p2.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.2" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.2.cmml">L</mi><mrow id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.2" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.3" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1a" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.4" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1b" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.5" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1c" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.6" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1d" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.7" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.7.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1e" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.8" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.8.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.2.m2.1b"><apply id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.2">ğ¿</ci><apply id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3"><times id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.1"></times><ci id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.2">ğ‘</ci><ci id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.3">ğ‘’</ci><ci id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.4.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.4">ğ‘Ÿ</ci><ci id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.5.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.5">ğ‘</ci><ci id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.6.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.6">ğ‘’</ci><ci id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.7.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.7">ğ‘</ci><ci id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.8.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.3.8">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.2.m2.1c">L_{percept}</annotation></semantics></math>) with the corresponding detectorÂ (<math id="S3.SS2.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="L_{T}=L_{det}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.3.m3.1a"><mrow id="S3.SS2.SSS0.Px2.p2.3.m3.1.1" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.cmml"><msub id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.2" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.2.cmml">L</mi><mi id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.3" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.3.cmml">T</mi></msub><mo id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.1" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.1.cmml">=</mo><msub id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.2" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.2.cmml">L</mi><mrow id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.2" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.1" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.3" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.1a" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.4" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.4.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.3.m3.1b"><apply id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1"><eq id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.1"></eq><apply id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.2">ğ¿</ci><ci id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.2.3">ğ‘‡</ci></apply><apply id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.2">ğ¿</ci><apply id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3"><times id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.1"></times><ci id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.3">ğ‘’</ci><ci id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.4.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.4">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.3.m3.1c">L_{T}=L_{det}</annotation></semantics></math>) or the pose lossÂ (<math id="S3.SS2.SSS0.Px2.p2.4.m4.1" class="ltx_Math" alttext="L_{T}=L_{pose}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.4.m4.1a"><mrow id="S3.SS2.SSS0.Px2.p2.4.m4.1.1" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.cmml"><msub id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.2" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.2.cmml">L</mi><mi id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.3" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.3.cmml">T</mi></msub><mo id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.1" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.1.cmml">=</mo><msub id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.2" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.2.cmml">L</mi><mrow id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.2" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.3" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1a" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.4" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1b" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.5" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.5.cmml">e</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.4.m4.1b"><apply id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1"><eq id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.1"></eq><apply id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.2">ğ¿</ci><ci id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.2.3">ğ‘‡</ci></apply><apply id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.2">ğ¿</ci><apply id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3"><times id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1"></times><ci id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.2">ğ‘</ci><ci id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.3">ğ‘œ</ci><ci id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.4.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.4">ğ‘ </ci><ci id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.5.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.5">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.4.m4.1c">L_{T}=L_{pose}</annotation></semantics></math>), as shown inÂ <a href="#S3.E1.1" title="In Eq. 1 â€£ Enforcing Perceptual Similarity â€£ 3.2 Pose Estimation Approach â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">1a</span></a>. While, in the second flavourÂ (<math id="S3.SS2.SSS0.Px2.p2.5.m5.1" class="ltx_Math" alttext="L_{comb2}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.5.m5.1a"><msub id="S3.SS2.SSS0.Px2.p2.5.m5.1.1" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.2" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.2.cmml">L</mi><mrow id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.2" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.3" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1a" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.4" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1b" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.5" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1c" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1.cmml">â€‹</mo><mn id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.6" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.6.cmml">2</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.5.m5.1b"><apply id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.2">ğ¿</ci><apply id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3"><times id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.1"></times><ci id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.2">ğ‘</ci><ci id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.3">ğ‘œ</ci><ci id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.4.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.4">ğ‘š</ci><ci id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.5.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.5">ğ‘</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.6.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.3.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.5.m5.1c">L_{comb2}</annotation></semantics></math>), we weigh each with optimal values of <math id="S3.SS2.SSS0.Px2.p2.6.m6.1" class="ltx_Math" alttext="\lambda_{1}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.6.m6.1a"><msub id="S3.SS2.SSS0.Px2.p2.6.m6.1.1" xref="S3.SS2.SSS0.Px2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p2.6.m6.1.1.2" xref="S3.SS2.SSS0.Px2.p2.6.m6.1.1.2.cmml">Î»</mi><mn id="S3.SS2.SSS0.Px2.p2.6.m6.1.1.3" xref="S3.SS2.SSS0.Px2.p2.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.6.m6.1b"><apply id="S3.SS2.SSS0.Px2.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.6.m6.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.6.m6.1c">\lambda_{1}</annotation></semantics></math> and <math id="S3.SS2.SSS0.Px2.p2.7.m7.1" class="ltx_Math" alttext="\lambda_{2}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.7.m7.1a"><msub id="S3.SS2.SSS0.Px2.p2.7.m7.1.1" xref="S3.SS2.SSS0.Px2.p2.7.m7.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p2.7.m7.1.1.2" xref="S3.SS2.SSS0.Px2.p2.7.m7.1.1.2.cmml">Î»</mi><mn id="S3.SS2.SSS0.Px2.p2.7.m7.1.1.3" xref="S3.SS2.SSS0.Px2.p2.7.m7.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.7.m7.1b"><apply id="S3.SS2.SSS0.Px2.p2.7.m7.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.7.m7.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.7.m7.1c">\lambda_{2}</annotation></semantics></math> chosen using hyperparameter optimisation, as shown inÂ <a href="#S3.E1.2" title="In Eq. 1 â€£ Enforcing Perceptual Similarity â€£ 3.2 Pose Estimation Approach â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">1b</span></a>.</p>
<table id="S3.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S6.EGx1" class="ltx_eqn_row"><td class="ltx_eqn_cell" colspan="5"></td></tr>
<tr id="S3.E1.1" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.1.m1.1" class="ltx_Math" alttext="\displaystyle L_{comb1}" display="inline"><semantics id="S3.E1.1.m1.1a"><msub id="S3.E1.1.m1.1.1" xref="S3.E1.1.m1.1.1.cmml"><mi id="S3.E1.1.m1.1.1.2" xref="S3.E1.1.m1.1.1.2.cmml">L</mi><mrow id="S3.E1.1.m1.1.1.3" xref="S3.E1.1.m1.1.1.3.cmml"><mi id="S3.E1.1.m1.1.1.3.2" xref="S3.E1.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m1.1.1.3.1" xref="S3.E1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E1.1.m1.1.1.3.3" xref="S3.E1.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m1.1.1.3.1a" xref="S3.E1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E1.1.m1.1.1.3.4" xref="S3.E1.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m1.1.1.3.1b" xref="S3.E1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E1.1.m1.1.1.3.5" xref="S3.E1.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m1.1.1.3.1c" xref="S3.E1.1.m1.1.1.3.1.cmml">â€‹</mo><mn id="S3.E1.1.m1.1.1.3.6" xref="S3.E1.1.m1.1.1.3.6.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.E1.1.m1.1b"><apply id="S3.E1.1.m1.1.1.cmml" xref="S3.E1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.E1.1.m1.1.1.1.cmml" xref="S3.E1.1.m1.1.1">subscript</csymbol><ci id="S3.E1.1.m1.1.1.2.cmml" xref="S3.E1.1.m1.1.1.2">ğ¿</ci><apply id="S3.E1.1.m1.1.1.3.cmml" xref="S3.E1.1.m1.1.1.3"><times id="S3.E1.1.m1.1.1.3.1.cmml" xref="S3.E1.1.m1.1.1.3.1"></times><ci id="S3.E1.1.m1.1.1.3.2.cmml" xref="S3.E1.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.E1.1.m1.1.1.3.3.cmml" xref="S3.E1.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S3.E1.1.m1.1.1.3.4.cmml" xref="S3.E1.1.m1.1.1.3.4">ğ‘š</ci><ci id="S3.E1.1.m1.1.1.3.5.cmml" xref="S3.E1.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S3.E1.1.m1.1.1.3.6.cmml" xref="S3.E1.1.m1.1.1.3.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.1.m1.1c">\displaystyle L_{comb1}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1.1.m2.1" class="ltx_Math" alttext="\displaystyle=L_{T}+L_{T}\ast L_{percept}" display="inline"><semantics id="S3.E1.1.m2.1a"><mrow id="S3.E1.1.m2.1.1" xref="S3.E1.1.m2.1.1.cmml"><mi id="S3.E1.1.m2.1.1.2" xref="S3.E1.1.m2.1.1.2.cmml"></mi><mo id="S3.E1.1.m2.1.1.1" xref="S3.E1.1.m2.1.1.1.cmml">=</mo><mrow id="S3.E1.1.m2.1.1.3" xref="S3.E1.1.m2.1.1.3.cmml"><msub id="S3.E1.1.m2.1.1.3.2" xref="S3.E1.1.m2.1.1.3.2.cmml"><mi id="S3.E1.1.m2.1.1.3.2.2" xref="S3.E1.1.m2.1.1.3.2.2.cmml">L</mi><mi id="S3.E1.1.m2.1.1.3.2.3" xref="S3.E1.1.m2.1.1.3.2.3.cmml">T</mi></msub><mo id="S3.E1.1.m2.1.1.3.1" xref="S3.E1.1.m2.1.1.3.1.cmml">+</mo><mrow id="S3.E1.1.m2.1.1.3.3" xref="S3.E1.1.m2.1.1.3.3.cmml"><msub id="S3.E1.1.m2.1.1.3.3.2" xref="S3.E1.1.m2.1.1.3.3.2.cmml"><mi id="S3.E1.1.m2.1.1.3.3.2.2" xref="S3.E1.1.m2.1.1.3.3.2.2.cmml">L</mi><mi id="S3.E1.1.m2.1.1.3.3.2.3" xref="S3.E1.1.m2.1.1.3.3.2.3.cmml">T</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1.1.m2.1.1.3.3.1" xref="S3.E1.1.m2.1.1.3.3.1.cmml">âˆ—</mo><msub id="S3.E1.1.m2.1.1.3.3.3" xref="S3.E1.1.m2.1.1.3.3.3.cmml"><mi id="S3.E1.1.m2.1.1.3.3.3.2" xref="S3.E1.1.m2.1.1.3.3.3.2.cmml">L</mi><mrow id="S3.E1.1.m2.1.1.3.3.3.3" xref="S3.E1.1.m2.1.1.3.3.3.3.cmml"><mi id="S3.E1.1.m2.1.1.3.3.3.3.2" xref="S3.E1.1.m2.1.1.3.3.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m2.1.1.3.3.3.3.1" xref="S3.E1.1.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.1.m2.1.1.3.3.3.3.3" xref="S3.E1.1.m2.1.1.3.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m2.1.1.3.3.3.3.1a" xref="S3.E1.1.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.1.m2.1.1.3.3.3.3.4" xref="S3.E1.1.m2.1.1.3.3.3.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m2.1.1.3.3.3.3.1b" xref="S3.E1.1.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.1.m2.1.1.3.3.3.3.5" xref="S3.E1.1.m2.1.1.3.3.3.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m2.1.1.3.3.3.3.1c" xref="S3.E1.1.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.1.m2.1.1.3.3.3.3.6" xref="S3.E1.1.m2.1.1.3.3.3.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m2.1.1.3.3.3.3.1d" xref="S3.E1.1.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.1.m2.1.1.3.3.3.3.7" xref="S3.E1.1.m2.1.1.3.3.3.3.7.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.1.m2.1.1.3.3.3.3.1e" xref="S3.E1.1.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.1.m2.1.1.3.3.3.3.8" xref="S3.E1.1.m2.1.1.3.3.3.3.8.cmml">t</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.1.m2.1b"><apply id="S3.E1.1.m2.1.1.cmml" xref="S3.E1.1.m2.1.1"><eq id="S3.E1.1.m2.1.1.1.cmml" xref="S3.E1.1.m2.1.1.1"></eq><csymbol cd="latexml" id="S3.E1.1.m2.1.1.2.cmml" xref="S3.E1.1.m2.1.1.2">absent</csymbol><apply id="S3.E1.1.m2.1.1.3.cmml" xref="S3.E1.1.m2.1.1.3"><plus id="S3.E1.1.m2.1.1.3.1.cmml" xref="S3.E1.1.m2.1.1.3.1"></plus><apply id="S3.E1.1.m2.1.1.3.2.cmml" xref="S3.E1.1.m2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.1.m2.1.1.3.2.1.cmml" xref="S3.E1.1.m2.1.1.3.2">subscript</csymbol><ci id="S3.E1.1.m2.1.1.3.2.2.cmml" xref="S3.E1.1.m2.1.1.3.2.2">ğ¿</ci><ci id="S3.E1.1.m2.1.1.3.2.3.cmml" xref="S3.E1.1.m2.1.1.3.2.3">ğ‘‡</ci></apply><apply id="S3.E1.1.m2.1.1.3.3.cmml" xref="S3.E1.1.m2.1.1.3.3"><ci id="S3.E1.1.m2.1.1.3.3.1.cmml" xref="S3.E1.1.m2.1.1.3.3.1">âˆ—</ci><apply id="S3.E1.1.m2.1.1.3.3.2.cmml" xref="S3.E1.1.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E1.1.m2.1.1.3.3.2.1.cmml" xref="S3.E1.1.m2.1.1.3.3.2">subscript</csymbol><ci id="S3.E1.1.m2.1.1.3.3.2.2.cmml" xref="S3.E1.1.m2.1.1.3.3.2.2">ğ¿</ci><ci id="S3.E1.1.m2.1.1.3.3.2.3.cmml" xref="S3.E1.1.m2.1.1.3.3.2.3">ğ‘‡</ci></apply><apply id="S3.E1.1.m2.1.1.3.3.3.cmml" xref="S3.E1.1.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.1.m2.1.1.3.3.3.1.cmml" xref="S3.E1.1.m2.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.1.m2.1.1.3.3.3.2.cmml" xref="S3.E1.1.m2.1.1.3.3.3.2">ğ¿</ci><apply id="S3.E1.1.m2.1.1.3.3.3.3.cmml" xref="S3.E1.1.m2.1.1.3.3.3.3"><times id="S3.E1.1.m2.1.1.3.3.3.3.1.cmml" xref="S3.E1.1.m2.1.1.3.3.3.3.1"></times><ci id="S3.E1.1.m2.1.1.3.3.3.3.2.cmml" xref="S3.E1.1.m2.1.1.3.3.3.3.2">ğ‘</ci><ci id="S3.E1.1.m2.1.1.3.3.3.3.3.cmml" xref="S3.E1.1.m2.1.1.3.3.3.3.3">ğ‘’</ci><ci id="S3.E1.1.m2.1.1.3.3.3.3.4.cmml" xref="S3.E1.1.m2.1.1.3.3.3.3.4">ğ‘Ÿ</ci><ci id="S3.E1.1.m2.1.1.3.3.3.3.5.cmml" xref="S3.E1.1.m2.1.1.3.3.3.3.5">ğ‘</ci><ci id="S3.E1.1.m2.1.1.3.3.3.3.6.cmml" xref="S3.E1.1.m2.1.1.3.3.3.3.6">ğ‘’</ci><ci id="S3.E1.1.m2.1.1.3.3.3.3.7.cmml" xref="S3.E1.1.m2.1.1.3.3.3.3.7">ğ‘</ci><ci id="S3.E1.1.m2.1.1.3.3.3.3.8.cmml" xref="S3.E1.1.m2.1.1.3.3.3.3.8">ğ‘¡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.1.m2.1c">\displaystyle=L_{T}+L_{T}\ast L_{percept}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1a)</span></td>
</tr>
<tr id="S3.E1.2" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.2.m1.1" class="ltx_Math" alttext="\displaystyle L_{comb2}" display="inline"><semantics id="S3.E1.2.m1.1a"><msub id="S3.E1.2.m1.1.1" xref="S3.E1.2.m1.1.1.cmml"><mi id="S3.E1.2.m1.1.1.2" xref="S3.E1.2.m1.1.1.2.cmml">L</mi><mrow id="S3.E1.2.m1.1.1.3" xref="S3.E1.2.m1.1.1.3.cmml"><mi id="S3.E1.2.m1.1.1.3.2" xref="S3.E1.2.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m1.1.1.3.1" xref="S3.E1.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E1.2.m1.1.1.3.3" xref="S3.E1.2.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m1.1.1.3.1a" xref="S3.E1.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E1.2.m1.1.1.3.4" xref="S3.E1.2.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m1.1.1.3.1b" xref="S3.E1.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E1.2.m1.1.1.3.5" xref="S3.E1.2.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m1.1.1.3.1c" xref="S3.E1.2.m1.1.1.3.1.cmml">â€‹</mo><mn id="S3.E1.2.m1.1.1.3.6" xref="S3.E1.2.m1.1.1.3.6.cmml">2</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.E1.2.m1.1b"><apply id="S3.E1.2.m1.1.1.cmml" xref="S3.E1.2.m1.1.1"><csymbol cd="ambiguous" id="S3.E1.2.m1.1.1.1.cmml" xref="S3.E1.2.m1.1.1">subscript</csymbol><ci id="S3.E1.2.m1.1.1.2.cmml" xref="S3.E1.2.m1.1.1.2">ğ¿</ci><apply id="S3.E1.2.m1.1.1.3.cmml" xref="S3.E1.2.m1.1.1.3"><times id="S3.E1.2.m1.1.1.3.1.cmml" xref="S3.E1.2.m1.1.1.3.1"></times><ci id="S3.E1.2.m1.1.1.3.2.cmml" xref="S3.E1.2.m1.1.1.3.2">ğ‘</ci><ci id="S3.E1.2.m1.1.1.3.3.cmml" xref="S3.E1.2.m1.1.1.3.3">ğ‘œ</ci><ci id="S3.E1.2.m1.1.1.3.4.cmml" xref="S3.E1.2.m1.1.1.3.4">ğ‘š</ci><ci id="S3.E1.2.m1.1.1.3.5.cmml" xref="S3.E1.2.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S3.E1.2.m1.1.1.3.6.cmml" xref="S3.E1.2.m1.1.1.3.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.2.m1.1c">\displaystyle L_{comb2}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1.2.m2.1" class="ltx_Math" alttext="\displaystyle=\lambda_{1}\ast L_{T}+\lambda_{2}\ast L_{percept}" display="inline"><semantics id="S3.E1.2.m2.1a"><mrow id="S3.E1.2.m2.1.1" xref="S3.E1.2.m2.1.1.cmml"><mi id="S3.E1.2.m2.1.1.2" xref="S3.E1.2.m2.1.1.2.cmml"></mi><mo id="S3.E1.2.m2.1.1.1" xref="S3.E1.2.m2.1.1.1.cmml">=</mo><mrow id="S3.E1.2.m2.1.1.3" xref="S3.E1.2.m2.1.1.3.cmml"><mrow id="S3.E1.2.m2.1.1.3.2" xref="S3.E1.2.m2.1.1.3.2.cmml"><msub id="S3.E1.2.m2.1.1.3.2.2" xref="S3.E1.2.m2.1.1.3.2.2.cmml"><mi id="S3.E1.2.m2.1.1.3.2.2.2" xref="S3.E1.2.m2.1.1.3.2.2.2.cmml">Î»</mi><mn id="S3.E1.2.m2.1.1.3.2.2.3" xref="S3.E1.2.m2.1.1.3.2.2.3.cmml">1</mn></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1.2.m2.1.1.3.2.1" xref="S3.E1.2.m2.1.1.3.2.1.cmml">âˆ—</mo><msub id="S3.E1.2.m2.1.1.3.2.3" xref="S3.E1.2.m2.1.1.3.2.3.cmml"><mi id="S3.E1.2.m2.1.1.3.2.3.2" xref="S3.E1.2.m2.1.1.3.2.3.2.cmml">L</mi><mi id="S3.E1.2.m2.1.1.3.2.3.3" xref="S3.E1.2.m2.1.1.3.2.3.3.cmml">T</mi></msub></mrow><mo id="S3.E1.2.m2.1.1.3.1" xref="S3.E1.2.m2.1.1.3.1.cmml">+</mo><mrow id="S3.E1.2.m2.1.1.3.3" xref="S3.E1.2.m2.1.1.3.3.cmml"><msub id="S3.E1.2.m2.1.1.3.3.2" xref="S3.E1.2.m2.1.1.3.3.2.cmml"><mi id="S3.E1.2.m2.1.1.3.3.2.2" xref="S3.E1.2.m2.1.1.3.3.2.2.cmml">Î»</mi><mn id="S3.E1.2.m2.1.1.3.3.2.3" xref="S3.E1.2.m2.1.1.3.3.2.3.cmml">2</mn></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1.2.m2.1.1.3.3.1" xref="S3.E1.2.m2.1.1.3.3.1.cmml">âˆ—</mo><msub id="S3.E1.2.m2.1.1.3.3.3" xref="S3.E1.2.m2.1.1.3.3.3.cmml"><mi id="S3.E1.2.m2.1.1.3.3.3.2" xref="S3.E1.2.m2.1.1.3.3.3.2.cmml">L</mi><mrow id="S3.E1.2.m2.1.1.3.3.3.3" xref="S3.E1.2.m2.1.1.3.3.3.3.cmml"><mi id="S3.E1.2.m2.1.1.3.3.3.3.2" xref="S3.E1.2.m2.1.1.3.3.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m2.1.1.3.3.3.3.1" xref="S3.E1.2.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.2.m2.1.1.3.3.3.3.3" xref="S3.E1.2.m2.1.1.3.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m2.1.1.3.3.3.3.1a" xref="S3.E1.2.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.2.m2.1.1.3.3.3.3.4" xref="S3.E1.2.m2.1.1.3.3.3.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m2.1.1.3.3.3.3.1b" xref="S3.E1.2.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.2.m2.1.1.3.3.3.3.5" xref="S3.E1.2.m2.1.1.3.3.3.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m2.1.1.3.3.3.3.1c" xref="S3.E1.2.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.2.m2.1.1.3.3.3.3.6" xref="S3.E1.2.m2.1.1.3.3.3.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m2.1.1.3.3.3.3.1d" xref="S3.E1.2.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.2.m2.1.1.3.3.3.3.7" xref="S3.E1.2.m2.1.1.3.3.3.3.7.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.2.m2.1.1.3.3.3.3.1e" xref="S3.E1.2.m2.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.2.m2.1.1.3.3.3.3.8" xref="S3.E1.2.m2.1.1.3.3.3.3.8.cmml">t</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.2.m2.1b"><apply id="S3.E1.2.m2.1.1.cmml" xref="S3.E1.2.m2.1.1"><eq id="S3.E1.2.m2.1.1.1.cmml" xref="S3.E1.2.m2.1.1.1"></eq><csymbol cd="latexml" id="S3.E1.2.m2.1.1.2.cmml" xref="S3.E1.2.m2.1.1.2">absent</csymbol><apply id="S3.E1.2.m2.1.1.3.cmml" xref="S3.E1.2.m2.1.1.3"><plus id="S3.E1.2.m2.1.1.3.1.cmml" xref="S3.E1.2.m2.1.1.3.1"></plus><apply id="S3.E1.2.m2.1.1.3.2.cmml" xref="S3.E1.2.m2.1.1.3.2"><ci id="S3.E1.2.m2.1.1.3.2.1.cmml" xref="S3.E1.2.m2.1.1.3.2.1">âˆ—</ci><apply id="S3.E1.2.m2.1.1.3.2.2.cmml" xref="S3.E1.2.m2.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.2.m2.1.1.3.2.2.1.cmml" xref="S3.E1.2.m2.1.1.3.2.2">subscript</csymbol><ci id="S3.E1.2.m2.1.1.3.2.2.2.cmml" xref="S3.E1.2.m2.1.1.3.2.2.2">ğœ†</ci><cn type="integer" id="S3.E1.2.m2.1.1.3.2.2.3.cmml" xref="S3.E1.2.m2.1.1.3.2.2.3">1</cn></apply><apply id="S3.E1.2.m2.1.1.3.2.3.cmml" xref="S3.E1.2.m2.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E1.2.m2.1.1.3.2.3.1.cmml" xref="S3.E1.2.m2.1.1.3.2.3">subscript</csymbol><ci id="S3.E1.2.m2.1.1.3.2.3.2.cmml" xref="S3.E1.2.m2.1.1.3.2.3.2">ğ¿</ci><ci id="S3.E1.2.m2.1.1.3.2.3.3.cmml" xref="S3.E1.2.m2.1.1.3.2.3.3">ğ‘‡</ci></apply></apply><apply id="S3.E1.2.m2.1.1.3.3.cmml" xref="S3.E1.2.m2.1.1.3.3"><ci id="S3.E1.2.m2.1.1.3.3.1.cmml" xref="S3.E1.2.m2.1.1.3.3.1">âˆ—</ci><apply id="S3.E1.2.m2.1.1.3.3.2.cmml" xref="S3.E1.2.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E1.2.m2.1.1.3.3.2.1.cmml" xref="S3.E1.2.m2.1.1.3.3.2">subscript</csymbol><ci id="S3.E1.2.m2.1.1.3.3.2.2.cmml" xref="S3.E1.2.m2.1.1.3.3.2.2">ğœ†</ci><cn type="integer" id="S3.E1.2.m2.1.1.3.3.2.3.cmml" xref="S3.E1.2.m2.1.1.3.3.2.3">2</cn></apply><apply id="S3.E1.2.m2.1.1.3.3.3.cmml" xref="S3.E1.2.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.2.m2.1.1.3.3.3.1.cmml" xref="S3.E1.2.m2.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.2.m2.1.1.3.3.3.2.cmml" xref="S3.E1.2.m2.1.1.3.3.3.2">ğ¿</ci><apply id="S3.E1.2.m2.1.1.3.3.3.3.cmml" xref="S3.E1.2.m2.1.1.3.3.3.3"><times id="S3.E1.2.m2.1.1.3.3.3.3.1.cmml" xref="S3.E1.2.m2.1.1.3.3.3.3.1"></times><ci id="S3.E1.2.m2.1.1.3.3.3.3.2.cmml" xref="S3.E1.2.m2.1.1.3.3.3.3.2">ğ‘</ci><ci id="S3.E1.2.m2.1.1.3.3.3.3.3.cmml" xref="S3.E1.2.m2.1.1.3.3.3.3.3">ğ‘’</ci><ci id="S3.E1.2.m2.1.1.3.3.3.3.4.cmml" xref="S3.E1.2.m2.1.1.3.3.3.3.4">ğ‘Ÿ</ci><ci id="S3.E1.2.m2.1.1.3.3.3.3.5.cmml" xref="S3.E1.2.m2.1.1.3.3.3.3.5">ğ‘</ci><ci id="S3.E1.2.m2.1.1.3.3.3.3.6.cmml" xref="S3.E1.2.m2.1.1.3.3.3.3.6">ğ‘’</ci><ci id="S3.E1.2.m2.1.1.3.3.3.3.7.cmml" xref="S3.E1.2.m2.1.1.3.3.3.3.7">ğ‘</ci><ci id="S3.E1.2.m2.1.1.3.3.3.3.8.cmml" xref="S3.E1.2.m2.1.1.3.3.3.3.8">ğ‘¡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.2.m2.1c">\displaystyle=\lambda_{1}\ast L_{T}+\lambda_{2}\ast L_{percept}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1b)</span></td>
</tr>
</tbody>
</table>
<p id="S3.SS2.SSS0.Px2.p2.11" class="ltx_p"><math id="S3.SS2.SSS0.Px2.p2.8.m1.1" class="ltx_Math" alttext="L_{T}=L_{det}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.8.m1.1a"><mrow id="S3.SS2.SSS0.Px2.p2.8.m1.1.1" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.cmml"><msub id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.2" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.2.cmml">L</mi><mi id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.3" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.3.cmml">T</mi></msub><mo id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.1" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.1.cmml">=</mo><msub id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.2" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.2.cmml">L</mi><mrow id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.2" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.1" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.3" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.1a" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.4" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.4.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.8.m1.1b"><apply id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1"><eq id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.1"></eq><apply id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.2">ğ¿</ci><ci id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.2.3">ğ‘‡</ci></apply><apply id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.2">ğ¿</ci><apply id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3"><times id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.1"></times><ci id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.3">ğ‘’</ci><ci id="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.4.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m1.1.1.3.3.4">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.8.m1.1c">L_{T}=L_{det}</annotation></semantics></math> for detector models, and <math id="S3.SS2.SSS0.Px2.p2.9.m2.1" class="ltx_Math" alttext="L_{T}=L_{pose}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.9.m2.1a"><mrow id="S3.SS2.SSS0.Px2.p2.9.m2.1.1" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.cmml"><msub id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.2" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.2.cmml">L</mi><mi id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.3" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.3.cmml">T</mi></msub><mo id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.1" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.1.cmml">=</mo><msub id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.2" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.2.cmml">L</mi><mrow id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.2" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.1" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.3" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.1a" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.4" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.1b" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.5" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.5.cmml">e</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.9.m2.1b"><apply id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1"><eq id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.1"></eq><apply id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.2">ğ¿</ci><ci id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.2.3">ğ‘‡</ci></apply><apply id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.2">ğ¿</ci><apply id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3"><times id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.1"></times><ci id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.2">ğ‘</ci><ci id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.3.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.3">ğ‘œ</ci><ci id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.4.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.4">ğ‘ </ci><ci id="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.5.cmml" xref="S3.SS2.SSS0.Px2.p2.9.m2.1.1.3.3.5">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.9.m2.1c">L_{T}=L_{pose}</annotation></semantics></math> for pose models. Consequently, <math id="S3.SS2.SSS0.Px2.p2.10.m3.1" class="ltx_Math" alttext="\lambda_{1}=1.0" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.10.m3.1a"><mrow id="S3.SS2.SSS0.Px2.p2.10.m3.1.1" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.cmml"><msub id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.2" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.2.cmml">Î»</mi><mn id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.3" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.1" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.3" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.10.m3.1b"><apply id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1"><eq id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.1"></eq><apply id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.2">ğœ†</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.2.3">1</cn></apply><cn type="float" id="S3.SS2.SSS0.Px2.p2.10.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.10.m3.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.10.m3.1c">\lambda_{1}=1.0</annotation></semantics></math> and <math id="S3.SS2.SSS0.Px2.p2.11.m4.1" class="ltx_Math" alttext="\lambda_{2}=L_{(det/pose)}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.11.m4.1a"><mrow id="S3.SS2.SSS0.Px2.p2.11.m4.1.2" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.cmml"><msub id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.cmml"><mi id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.2" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.2.cmml">Î»</mi><mn id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.3" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.1" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.1.cmml">=</mo><msub id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3.2" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3.2.cmml">L</mi><mrow id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.2" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.cmml"><mrow id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.cmml"><mrow id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.cmml"><mi id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.2" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.1" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.3" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.1a" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.4" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.4.cmml">t</mi></mrow><mo id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.1" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.1.cmml">/</mo><mi id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.3" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.3.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.1" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.3" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.1a" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.4" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.1b" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.5" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.5.cmml">e</mi></mrow><mo stretchy="false" id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.3" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.cmml">)</mo></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.11.m4.1b"><apply id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2"><eq id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.1"></eq><apply id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.1.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.2">ğœ†</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.2.3">2</cn></apply><apply id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.2.3.2">ğ¿</ci><apply id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1"><times id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.1"></times><apply id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2"><divide id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.1"></divide><apply id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2"><times id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.1.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.1"></times><ci id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.2">ğ‘‘</ci><ci id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.3">ğ‘’</ci><ci id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.4.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.2.4">ğ‘¡</ci></apply><ci id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.3">ğ‘œ</ci><ci id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.4.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.4">ğ‘ </ci><ci id="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.5.cmml" xref="S3.SS2.SSS0.Px2.p2.11.m4.1.1.1.1.1.5">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.11.m4.1c">\lambda_{2}=L_{(det/pose)}</annotation></semantics></math> forÂ <a href="#S3.E1.1" title="In Eq. 1 â€£ Enforcing Perceptual Similarity â€£ 3.2 Pose Estimation Approach â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">1a</span></a>.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments and Analysis</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The exact number of images, person bounding boxes and pose annotations, along with the corresponding train/val splits used for our experiments are mentioned in <a href="#S3.T1" title="In 3.1 Datasets â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>. In this section, we describe the evaluation protocol to train our detector and pose estimator. We also present the experimental results and discuss our findings.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Training Setup</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.7" class="ltx_p">In general, we use the standard parameters of the SOTA models and make adjustments to suit our experimental needs. For person detection (Faster-RCNN), we use an initial learning rate (<span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">lr<sub id="S4.SS1.p1.1.1.1" class="ltx_sub">init</sub></span>) of 0.0001 with a scheduler <span id="S4.SS1.p1.2.2" class="ltx_text ltx_font_italic">lr<sub id="S4.SS1.p1.2.2.1" class="ltx_sub">scheduler</sub></span> on plateau (3 epochs) which reduces the <span id="S4.SS1.p1.7.6" class="ltx_text ltx_font_italic">lr</span> by a factor of 0.33. We use AdamÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> with its default parameters and a batch-sizeÂ (<span id="S4.SS1.p1.7.7" class="ltx_text ltx_font_italic">bs</span>) of 8. Standard multi-task loss metric, a combination of log loss and regression loss (<math id="S4.SS1.p1.3.m1.1" class="ltx_Math" alttext="L_{det}=L_{CLS}+L_{Reg}" display="inline"><semantics id="S4.SS1.p1.3.m1.1a"><mrow id="S4.SS1.p1.3.m1.1.1" xref="S4.SS1.p1.3.m1.1.1.cmml"><msub id="S4.SS1.p1.3.m1.1.1.2" xref="S4.SS1.p1.3.m1.1.1.2.cmml"><mi id="S4.SS1.p1.3.m1.1.1.2.2" xref="S4.SS1.p1.3.m1.1.1.2.2.cmml">L</mi><mrow id="S4.SS1.p1.3.m1.1.1.2.3" xref="S4.SS1.p1.3.m1.1.1.2.3.cmml"><mi id="S4.SS1.p1.3.m1.1.1.2.3.2" xref="S4.SS1.p1.3.m1.1.1.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.3.m1.1.1.2.3.1" xref="S4.SS1.p1.3.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.3.m1.1.1.2.3.3" xref="S4.SS1.p1.3.m1.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.3.m1.1.1.2.3.1a" xref="S4.SS1.p1.3.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.3.m1.1.1.2.3.4" xref="S4.SS1.p1.3.m1.1.1.2.3.4.cmml">t</mi></mrow></msub><mo id="S4.SS1.p1.3.m1.1.1.1" xref="S4.SS1.p1.3.m1.1.1.1.cmml">=</mo><mrow id="S4.SS1.p1.3.m1.1.1.3" xref="S4.SS1.p1.3.m1.1.1.3.cmml"><msub id="S4.SS1.p1.3.m1.1.1.3.2" xref="S4.SS1.p1.3.m1.1.1.3.2.cmml"><mi id="S4.SS1.p1.3.m1.1.1.3.2.2" xref="S4.SS1.p1.3.m1.1.1.3.2.2.cmml">L</mi><mrow id="S4.SS1.p1.3.m1.1.1.3.2.3" xref="S4.SS1.p1.3.m1.1.1.3.2.3.cmml"><mi id="S4.SS1.p1.3.m1.1.1.3.2.3.2" xref="S4.SS1.p1.3.m1.1.1.3.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.3.m1.1.1.3.2.3.1" xref="S4.SS1.p1.3.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.3.m1.1.1.3.2.3.3" xref="S4.SS1.p1.3.m1.1.1.3.2.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.3.m1.1.1.3.2.3.1a" xref="S4.SS1.p1.3.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.3.m1.1.1.3.2.3.4" xref="S4.SS1.p1.3.m1.1.1.3.2.3.4.cmml">S</mi></mrow></msub><mo id="S4.SS1.p1.3.m1.1.1.3.1" xref="S4.SS1.p1.3.m1.1.1.3.1.cmml">+</mo><msub id="S4.SS1.p1.3.m1.1.1.3.3" xref="S4.SS1.p1.3.m1.1.1.3.3.cmml"><mi id="S4.SS1.p1.3.m1.1.1.3.3.2" xref="S4.SS1.p1.3.m1.1.1.3.3.2.cmml">L</mi><mrow id="S4.SS1.p1.3.m1.1.1.3.3.3" xref="S4.SS1.p1.3.m1.1.1.3.3.3.cmml"><mi id="S4.SS1.p1.3.m1.1.1.3.3.3.2" xref="S4.SS1.p1.3.m1.1.1.3.3.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.3.m1.1.1.3.3.3.1" xref="S4.SS1.p1.3.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.3.m1.1.1.3.3.3.3" xref="S4.SS1.p1.3.m1.1.1.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.3.m1.1.1.3.3.3.1a" xref="S4.SS1.p1.3.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.3.m1.1.1.3.3.3.4" xref="S4.SS1.p1.3.m1.1.1.3.3.3.4.cmml">g</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m1.1b"><apply id="S4.SS1.p1.3.m1.1.1.cmml" xref="S4.SS1.p1.3.m1.1.1"><eq id="S4.SS1.p1.3.m1.1.1.1.cmml" xref="S4.SS1.p1.3.m1.1.1.1"></eq><apply id="S4.SS1.p1.3.m1.1.1.2.cmml" xref="S4.SS1.p1.3.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m1.1.1.2.1.cmml" xref="S4.SS1.p1.3.m1.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.3.m1.1.1.2.2.cmml" xref="S4.SS1.p1.3.m1.1.1.2.2">ğ¿</ci><apply id="S4.SS1.p1.3.m1.1.1.2.3.cmml" xref="S4.SS1.p1.3.m1.1.1.2.3"><times id="S4.SS1.p1.3.m1.1.1.2.3.1.cmml" xref="S4.SS1.p1.3.m1.1.1.2.3.1"></times><ci id="S4.SS1.p1.3.m1.1.1.2.3.2.cmml" xref="S4.SS1.p1.3.m1.1.1.2.3.2">ğ‘‘</ci><ci id="S4.SS1.p1.3.m1.1.1.2.3.3.cmml" xref="S4.SS1.p1.3.m1.1.1.2.3.3">ğ‘’</ci><ci id="S4.SS1.p1.3.m1.1.1.2.3.4.cmml" xref="S4.SS1.p1.3.m1.1.1.2.3.4">ğ‘¡</ci></apply></apply><apply id="S4.SS1.p1.3.m1.1.1.3.cmml" xref="S4.SS1.p1.3.m1.1.1.3"><plus id="S4.SS1.p1.3.m1.1.1.3.1.cmml" xref="S4.SS1.p1.3.m1.1.1.3.1"></plus><apply id="S4.SS1.p1.3.m1.1.1.3.2.cmml" xref="S4.SS1.p1.3.m1.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m1.1.1.3.2.1.cmml" xref="S4.SS1.p1.3.m1.1.1.3.2">subscript</csymbol><ci id="S4.SS1.p1.3.m1.1.1.3.2.2.cmml" xref="S4.SS1.p1.3.m1.1.1.3.2.2">ğ¿</ci><apply id="S4.SS1.p1.3.m1.1.1.3.2.3.cmml" xref="S4.SS1.p1.3.m1.1.1.3.2.3"><times id="S4.SS1.p1.3.m1.1.1.3.2.3.1.cmml" xref="S4.SS1.p1.3.m1.1.1.3.2.3.1"></times><ci id="S4.SS1.p1.3.m1.1.1.3.2.3.2.cmml" xref="S4.SS1.p1.3.m1.1.1.3.2.3.2">ğ¶</ci><ci id="S4.SS1.p1.3.m1.1.1.3.2.3.3.cmml" xref="S4.SS1.p1.3.m1.1.1.3.2.3.3">ğ¿</ci><ci id="S4.SS1.p1.3.m1.1.1.3.2.3.4.cmml" xref="S4.SS1.p1.3.m1.1.1.3.2.3.4">ğ‘†</ci></apply></apply><apply id="S4.SS1.p1.3.m1.1.1.3.3.cmml" xref="S4.SS1.p1.3.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m1.1.1.3.3.1.cmml" xref="S4.SS1.p1.3.m1.1.1.3.3">subscript</csymbol><ci id="S4.SS1.p1.3.m1.1.1.3.3.2.cmml" xref="S4.SS1.p1.3.m1.1.1.3.3.2">ğ¿</ci><apply id="S4.SS1.p1.3.m1.1.1.3.3.3.cmml" xref="S4.SS1.p1.3.m1.1.1.3.3.3"><times id="S4.SS1.p1.3.m1.1.1.3.3.3.1.cmml" xref="S4.SS1.p1.3.m1.1.1.3.3.3.1"></times><ci id="S4.SS1.p1.3.m1.1.1.3.3.3.2.cmml" xref="S4.SS1.p1.3.m1.1.1.3.3.3.2">ğ‘…</ci><ci id="S4.SS1.p1.3.m1.1.1.3.3.3.3.cmml" xref="S4.SS1.p1.3.m1.1.1.3.3.3.3">ğ‘’</ci><ci id="S4.SS1.p1.3.m1.1.1.3.3.3.4.cmml" xref="S4.SS1.p1.3.m1.1.1.3.3.3.4">ğ‘”</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m1.1c">L_{det}=L_{CLS}+L_{Reg}</annotation></semantics></math>), is used in our experiments for the detector. We train for 25 epochs on the <span id="S4.SS1.p1.7.8" class="ltx_text ltx_font_italic">CP</span> dataset and 30 each on the <span id="S4.SS1.p1.7.9" class="ltx_text ltx_font_italic">SCP</span> and <span id="S4.SS1.p1.7.10" class="ltx_text ltx_font_italic">CA</span> datasets. However, we found that our models usually converge between 8â€“12 epochs.
<br class="ltx_break">Similar to the detector, we use Adam with its default values for pose models (HRNet) and <span id="S4.SS1.p1.4.3" class="ltx_text ltx_font_italic">bs<math id="S4.SS1.p1.4.3.m1.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S4.SS1.p1.4.3.m1.1a"><mo id="S4.SS1.p1.4.3.m1.1.1" xref="S4.SS1.p1.4.3.m1.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.3.m1.1b"><eq id="S4.SS1.p1.4.3.m1.1.1.cmml" xref="S4.SS1.p1.4.3.m1.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.3.m1.1c">=</annotation></semantics></math></span>64. With an <span id="S4.SS1.p1.5.4" class="ltx_text ltx_font_italic">lr<sub id="S4.SS1.p1.5.4.1" class="ltx_sub">init</sub></span> of 0.01 and a <span id="S4.SS1.p1.6.5" class="ltx_text ltx_font_italic">lr<sub id="S4.SS1.p1.6.5.1" class="ltx_sub">scheduler</sub></span> on plateau (3 epochs) which reduces the <span id="S4.SS1.p1.7.11" class="ltx_text ltx_font_italic">lr</span> by a factor of 0.1. We train all pose models for 100 epochs. Akin to the original HRNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, we also use the same configs (augmentations, image size) for fair comparison. Like HRNet, Object Keypoint Similarity (OKS) is used as an evaluation metric in our experiments as a simple Euclidean distance (<math id="S4.SS1.p1.7.m2.1" class="ltx_Math" alttext="L_{pose}=L_{MSE}" display="inline"><semantics id="S4.SS1.p1.7.m2.1a"><mrow id="S4.SS1.p1.7.m2.1.1" xref="S4.SS1.p1.7.m2.1.1.cmml"><msub id="S4.SS1.p1.7.m2.1.1.2" xref="S4.SS1.p1.7.m2.1.1.2.cmml"><mi id="S4.SS1.p1.7.m2.1.1.2.2" xref="S4.SS1.p1.7.m2.1.1.2.2.cmml">L</mi><mrow id="S4.SS1.p1.7.m2.1.1.2.3" xref="S4.SS1.p1.7.m2.1.1.2.3.cmml"><mi id="S4.SS1.p1.7.m2.1.1.2.3.2" xref="S4.SS1.p1.7.m2.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.7.m2.1.1.2.3.1" xref="S4.SS1.p1.7.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.7.m2.1.1.2.3.3" xref="S4.SS1.p1.7.m2.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.7.m2.1.1.2.3.1a" xref="S4.SS1.p1.7.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.7.m2.1.1.2.3.4" xref="S4.SS1.p1.7.m2.1.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.7.m2.1.1.2.3.1b" xref="S4.SS1.p1.7.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.7.m2.1.1.2.3.5" xref="S4.SS1.p1.7.m2.1.1.2.3.5.cmml">e</mi></mrow></msub><mo id="S4.SS1.p1.7.m2.1.1.1" xref="S4.SS1.p1.7.m2.1.1.1.cmml">=</mo><msub id="S4.SS1.p1.7.m2.1.1.3" xref="S4.SS1.p1.7.m2.1.1.3.cmml"><mi id="S4.SS1.p1.7.m2.1.1.3.2" xref="S4.SS1.p1.7.m2.1.1.3.2.cmml">L</mi><mrow id="S4.SS1.p1.7.m2.1.1.3.3" xref="S4.SS1.p1.7.m2.1.1.3.3.cmml"><mi id="S4.SS1.p1.7.m2.1.1.3.3.2" xref="S4.SS1.p1.7.m2.1.1.3.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.7.m2.1.1.3.3.1" xref="S4.SS1.p1.7.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.7.m2.1.1.3.3.3" xref="S4.SS1.p1.7.m2.1.1.3.3.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.7.m2.1.1.3.3.1a" xref="S4.SS1.p1.7.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.7.m2.1.1.3.3.4" xref="S4.SS1.p1.7.m2.1.1.3.3.4.cmml">E</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m2.1b"><apply id="S4.SS1.p1.7.m2.1.1.cmml" xref="S4.SS1.p1.7.m2.1.1"><eq id="S4.SS1.p1.7.m2.1.1.1.cmml" xref="S4.SS1.p1.7.m2.1.1.1"></eq><apply id="S4.SS1.p1.7.m2.1.1.2.cmml" xref="S4.SS1.p1.7.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m2.1.1.2.1.cmml" xref="S4.SS1.p1.7.m2.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.7.m2.1.1.2.2.cmml" xref="S4.SS1.p1.7.m2.1.1.2.2">ğ¿</ci><apply id="S4.SS1.p1.7.m2.1.1.2.3.cmml" xref="S4.SS1.p1.7.m2.1.1.2.3"><times id="S4.SS1.p1.7.m2.1.1.2.3.1.cmml" xref="S4.SS1.p1.7.m2.1.1.2.3.1"></times><ci id="S4.SS1.p1.7.m2.1.1.2.3.2.cmml" xref="S4.SS1.p1.7.m2.1.1.2.3.2">ğ‘</ci><ci id="S4.SS1.p1.7.m2.1.1.2.3.3.cmml" xref="S4.SS1.p1.7.m2.1.1.2.3.3">ğ‘œ</ci><ci id="S4.SS1.p1.7.m2.1.1.2.3.4.cmml" xref="S4.SS1.p1.7.m2.1.1.2.3.4">ğ‘ </ci><ci id="S4.SS1.p1.7.m2.1.1.2.3.5.cmml" xref="S4.SS1.p1.7.m2.1.1.2.3.5">ğ‘’</ci></apply></apply><apply id="S4.SS1.p1.7.m2.1.1.3.cmml" xref="S4.SS1.p1.7.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m2.1.1.3.1.cmml" xref="S4.SS1.p1.7.m2.1.1.3">subscript</csymbol><ci id="S4.SS1.p1.7.m2.1.1.3.2.cmml" xref="S4.SS1.p1.7.m2.1.1.3.2">ğ¿</ci><apply id="S4.SS1.p1.7.m2.1.1.3.3.cmml" xref="S4.SS1.p1.7.m2.1.1.3.3"><times id="S4.SS1.p1.7.m2.1.1.3.3.1.cmml" xref="S4.SS1.p1.7.m2.1.1.3.3.1"></times><ci id="S4.SS1.p1.7.m2.1.1.3.3.2.cmml" xref="S4.SS1.p1.7.m2.1.1.3.3.2">ğ‘€</ci><ci id="S4.SS1.p1.7.m2.1.1.3.3.3.cmml" xref="S4.SS1.p1.7.m2.1.1.3.3.3">ğ‘†</ci><ci id="S4.SS1.p1.7.m2.1.1.3.3.4.cmml" xref="S4.SS1.p1.7.m2.1.1.3.3.4">ğ¸</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m2.1c">L_{pose}=L_{MSE}</annotation></semantics></math>) for pose estimation.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">In both cases, person detection and pose estimation, we report the mean Average Precision (<span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_italic">mAP</span>) as well as the corresponding mean Average Recall (<span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_italic">mAR</span>).</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experiments</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We compare different models in separate tables to give a clear understanding of our methods. <a href="#S4.T2" title="In Baseline vs Styled models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>Â (Results A) compares the <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">baseline</span> models with <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">styled</span> models for detector as well as pose. Similarly, <a href="#S4.T3" title="In Tuned vs. Styled-Tuned models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>Â (Results B) compares the <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_italic">tuned</span> with <span id="S4.SS2.p1.1.4" class="ltx_text ltx_font_italic">styled-tuned</span>. <a href="#S4.T4" title="In Tuned vs. Styled-Tuned models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a>Â (Results C) shows the influence of using different data quantities to fine-tune our models, where as <a href="#S4.T5" title="In Perceptual Loss Comparison: â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a> shows the advantage of using perceptual loss.</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Baseline <span id="S4.SS2.SSS0.Px1.1.1" class="ltx_text ltx_font_italic">vs</span>Â Styled models</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">(Results A, <a href="#S4.T2" title="In Baseline vs Styled models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>) It is important to understand the impact of styles on the main task for detection and pose estimation. We study the impact of style-transfer by comparing <span id="S4.SS2.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">baseline</span> and <span id="S4.SS2.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_italic">styled</span> models. As shown in <a href="#S4.T2" title="In Baseline vs Styled models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>Â (<em id="S4.SS2.SSS0.Px1.p1.1.3" class="ltx_emph ltx_font_italic">SCP</em> column), we observe that the styled models perform consistently much better than their baseline counterpart for detection and pose estimation. When tested on the <em id="S4.SS2.SSS0.Px1.p1.1.4" class="ltx_emph ltx_font_italic">CA</em> dataset, these models under perform for detection. Conversely for pose estimation, styled models unambiguously are better for both <em id="S4.SS2.SSS0.Px1.p1.1.5" class="ltx_emph ltx_font_italic">SCP</em> and <em id="S4.SS2.SSS0.Px1.p1.1.6" class="ltx_emph ltx_font_italic">CA</em> datasets. Specifically, styled models, which were not trained on <em id="S4.SS2.SSS0.Px1.p1.1.7" class="ltx_emph ltx_font_italic">CA</em>, give a considerable jump in performance: 7.62 (mAP)Â &amp;Â 8.06 (mAR) when tested on <em id="S4.SS2.SSS0.Px1.p1.1.8" class="ltx_emph ltx_font_italic">CA</em>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.13.4.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.6.3" class="ltx_text ltx_font_bold" style="font-size:90%;">Results A<span id="S4.T2.4.1.1" class="ltx_text ltx_font_medium">: Comparing <span id="S4.T2.4.1.1.1" class="ltx_text ltx_font_italic">baseline</span> model with the <span id="S4.T2.4.1.1.2" class="ltx_text ltx_font_italic">styled</span> model with different combinations of <math id="S4.T2.4.1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T2.4.1.1.m1.1b"><mi id="S4.T2.4.1.1.m1.1.1" xref="S4.T2.4.1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T2.4.1.1.m1.1c"><ci id="S4.T2.4.1.1.m1.1.1.cmml" xref="S4.T2.4.1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.1.1.m1.1d">\alpha</annotation></semantics></math> and <span id="S4.T2.4.1.1.3" class="ltx_text ltx_font_italic">Style-Set</span> (<em id="S4.T2.4.1.1.4" class="ltx_emph ltx_font_italic">SS</em>), for detector (</span>D<span id="S4.T2.6.3.4" class="ltx_text ltx_font_medium">) and pose estimator (</span>P<span id="S4.T2.6.3.3" class="ltx_text ltx_font_medium">). <math id="S4.T2.5.2.2.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.T2.5.2.2.m1.1b"><mrow id="S4.T2.5.2.2.m1.1.1" xref="S4.T2.5.2.2.m1.1.1.cmml"><mi id="S4.T2.5.2.2.m1.1.1.2" xref="S4.T2.5.2.2.m1.1.1.2.cmml">Î±</mi><mo id="S4.T2.5.2.2.m1.1.1.1" xref="S4.T2.5.2.2.m1.1.1.1.cmml">=</mo><mn id="S4.T2.5.2.2.m1.1.1.3" xref="S4.T2.5.2.2.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.2.2.m1.1c"><apply id="S4.T2.5.2.2.m1.1.1.cmml" xref="S4.T2.5.2.2.m1.1.1"><eq id="S4.T2.5.2.2.m1.1.1.1.cmml" xref="S4.T2.5.2.2.m1.1.1.1"></eq><ci id="S4.T2.5.2.2.m1.1.1.2.cmml" xref="S4.T2.5.2.2.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T2.5.2.2.m1.1.1.3.cmml" xref="S4.T2.5.2.2.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.2.2.m1.1d">\alpha=0.5</annotation></semantics></math> or <math id="S4.T2.6.3.3.m2.1" class="ltx_Math" alttext="\alpha=U" display="inline"><semantics id="S4.T2.6.3.3.m2.1b"><mrow id="S4.T2.6.3.3.m2.1.1" xref="S4.T2.6.3.3.m2.1.1.cmml"><mi id="S4.T2.6.3.3.m2.1.1.2" xref="S4.T2.6.3.3.m2.1.1.2.cmml">Î±</mi><mo id="S4.T2.6.3.3.m2.1.1.1" xref="S4.T2.6.3.3.m2.1.1.1.cmml">=</mo><mi id="S4.T2.6.3.3.m2.1.1.3" xref="S4.T2.6.3.3.m2.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.3.3.m2.1c"><apply id="S4.T2.6.3.3.m2.1.1.cmml" xref="S4.T2.6.3.3.m2.1.1"><eq id="S4.T2.6.3.3.m2.1.1.1.cmml" xref="S4.T2.6.3.3.m2.1.1.1"></eq><ci id="S4.T2.6.3.3.m2.1.1.2.cmml" xref="S4.T2.6.3.3.m2.1.1.2">ğ›¼</ci><ci id="S4.T2.6.3.3.m2.1.1.3.cmml" xref="S4.T2.6.3.3.m2.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.3.3.m2.1d">\alpha=U</annotation></semantics></math> (randomly sampled from a uniform distribution). All values in terms of <span id="S4.T2.6.3.3.1" class="ltx_text ltx_font_italic">mAP</span>, except <em id="S4.T2.6.3.3.2" class="ltx_emph ltx_font_italic">CA</em><span id="S4.T2.6.3.3.3" class="ltx_text ltx_font_italic" style="font-size:56%;">mAR</span> (<span id="S4.T2.6.3.3.4" class="ltx_text ltx_font_italic">mAR</span>).</span></span></figcaption>
<table id="S4.T2.11" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.7.1" class="ltx_tr">
<th id="S4.T2.7.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.7.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></th>
<th id="S4.T2.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.7.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CP</span></th>
<th id="S4.T2.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.7.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SCP</span></th>
<th id="S4.T2.7.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.7.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CA</span></th>
<th id="S4.T2.7.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T2.7.1.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CA</span><span id="S4.T2.7.1.6.2" class="ltx_text ltx_font_italic" style="font-size:50%;">mAR</span>
</th>
<th id="S4.T2.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="S4.T2.7.1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T2.7.1.1.m1.1a"><mi mathsize="80%" id="S4.T2.7.1.1.m1.1.1" xref="S4.T2.7.1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T2.7.1.1.m1.1b"><ci id="S4.T2.7.1.1.m1.1.1.cmml" xref="S4.T2.7.1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.1.1.m1.1c">\alpha</annotation></semantics></math></th>
<th id="S4.T2.7.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.7.1.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SS</span></th>
</tr>
<tr id="S4.T2.11.6.1" class="ltx_tr">
<th id="S4.T2.11.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" style="background-color:#CCCCCC;"><span id="S4.T2.11.6.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;background-color:#CCCCCC;">(D)Â Baseline</span></th>
<th id="S4.T2.11.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.6.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">39.4</span></th>
<th id="S4.T2.11.6.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.6.1.3.1" class="ltx_text" style="font-size:80%;">24.2</span></th>
<th id="S4.T2.11.6.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.6.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">10.4</span></th>
<th id="S4.T2.11.6.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.6.1.5.1" class="ltx_text" style="font-size:80%;">9.8</span></th>
<th id="S4.T2.11.6.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.6.1.6.1" class="ltx_text" style="font-size:80%;">0.5</span></th>
<th id="S4.T2.11.6.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.6.1.7.1" class="ltx_text" style="font-size:80%;">RB</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.11.7.1" class="ltx_tr">
<td id="S4.T2.11.7.1.1" class="ltx_td"></td>
<td id="S4.T2.11.7.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.7.1.2.1" class="ltx_text" style="font-size:80%;">37.5</span></td>
<td id="S4.T2.11.7.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.7.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">33.4</span></td>
<td id="S4.T2.11.7.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.7.1.4.1" class="ltx_text" style="font-size:80%;">7.6</span></td>
<td id="S4.T2.11.7.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.7.1.5.1" class="ltx_text" style="font-size:80%;">9.8</span></td>
<td id="S4.T2.11.7.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.7.1.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T2.11.7.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.7.1.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T2.8.2" class="ltx_tr">
<td id="S4.T2.8.2.2" class="ltx_td"></td>
<td id="S4.T2.8.2.3" class="ltx_td ltx_align_center"><span id="S4.T2.8.2.3.1" class="ltx_text" style="font-size:80%;">36.9</span></td>
<td id="S4.T2.8.2.4" class="ltx_td ltx_align_center"><span id="S4.T2.8.2.4.1" class="ltx_text" style="font-size:80%;">32.1</span></td>
<td id="S4.T2.8.2.5" class="ltx_td ltx_align_center"><span id="S4.T2.8.2.5.1" class="ltx_text" style="font-size:80%;">6.5</span></td>
<td id="S4.T2.8.2.6" class="ltx_td ltx_align_center"><span id="S4.T2.8.2.6.1" class="ltx_text" style="font-size:80%;">8.5</span></td>
<td id="S4.T2.8.2.1" class="ltx_td ltx_align_center"><math id="S4.T2.8.2.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T2.8.2.1.m1.1a"><mi mathsize="80%" id="S4.T2.8.2.1.m1.1.1" xref="S4.T2.8.2.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T2.8.2.1.m1.1b"><ci id="S4.T2.8.2.1.m1.1.1.cmml" xref="S4.T2.8.2.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.2.1.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T2.8.2.7" class="ltx_td ltx_align_center"><span id="S4.T2.8.2.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T2.11.8.2" class="ltx_tr">
<td id="S4.T2.11.8.2.1" class="ltx_td"></td>
<td id="S4.T2.11.8.2.2" class="ltx_td ltx_align_center"><span id="S4.T2.11.8.2.2.1" class="ltx_text" style="font-size:80%;">37.7</span></td>
<td id="S4.T2.11.8.2.3" class="ltx_td ltx_align_center"><span id="S4.T2.11.8.2.3.1" class="ltx_text" style="font-size:80%;">33.2</span></td>
<td id="S4.T2.11.8.2.4" class="ltx_td ltx_align_center"><span id="S4.T2.11.8.2.4.1" class="ltx_text" style="font-size:80%;">8.2</span></td>
<td id="S4.T2.11.8.2.5" class="ltx_td ltx_align_center"><span id="S4.T2.11.8.2.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">10.0</span></td>
<td id="S4.T2.11.8.2.6" class="ltx_td ltx_align_center"><span id="S4.T2.11.8.2.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T2.11.8.2.7" class="ltx_td ltx_align_center"><span id="S4.T2.11.8.2.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S4.T2.9.3" class="ltx_tr">
<td id="S4.T2.9.3.2" class="ltx_td ltx_align_left" style="background-color:#CCCCCC;"><span id="S4.T2.9.3.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;background-color:#CCCCCC;">(D)Â Styled</span></td>
<td id="S4.T2.9.3.3" class="ltx_td ltx_align_center"><span id="S4.T2.9.3.3.1" class="ltx_text" style="font-size:80%;">37.0</span></td>
<td id="S4.T2.9.3.4" class="ltx_td ltx_align_center"><span id="S4.T2.9.3.4.1" class="ltx_text" style="font-size:80%;">32.6</span></td>
<td id="S4.T2.9.3.5" class="ltx_td ltx_align_center"><span id="S4.T2.9.3.5.1" class="ltx_text" style="font-size:80%;">6.5</span></td>
<td id="S4.T2.9.3.6" class="ltx_td ltx_align_center"><span id="S4.T2.9.3.6.1" class="ltx_text" style="font-size:80%;">8.6</span></td>
<td id="S4.T2.9.3.1" class="ltx_td ltx_align_center"><math id="S4.T2.9.3.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T2.9.3.1.m1.1a"><mi mathsize="80%" id="S4.T2.9.3.1.m1.1.1" xref="S4.T2.9.3.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T2.9.3.1.m1.1b"><ci id="S4.T2.9.3.1.m1.1.1.cmml" xref="S4.T2.9.3.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.3.1.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T2.9.3.7" class="ltx_td ltx_align_center"><span id="S4.T2.9.3.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S4.T2.11.9.3" class="ltx_tr">
<td id="S4.T2.11.9.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.11.9.3.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(P)Â Baseline</span></td>
<td id="S4.T2.11.9.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.9.3.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">76.5</span></td>
<td id="S4.T2.11.9.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.9.3.3.1" class="ltx_text" style="font-size:80%;">46.2</span></td>
<td id="S4.T2.11.9.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.9.3.4.1" class="ltx_text" style="font-size:80%;">24.7</span></td>
<td id="S4.T2.11.9.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.9.3.5.1" class="ltx_text" style="font-size:80%;">30.9</span></td>
<td id="S4.T2.11.9.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.9.3.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T2.11.9.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.9.3.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T2.11.10.4" class="ltx_tr">
<td id="S4.T2.11.10.4.1" class="ltx_td ltx_align_left ltx_border_bb" rowspan="4"><span id="S4.T2.11.10.4.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(P)Â Styled</span></td>
<td id="S4.T2.11.10.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.10.4.2.1" class="ltx_text" style="font-size:80%;">73.4</span></td>
<td id="S4.T2.11.10.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.10.4.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">54.4</span></td>
<td id="S4.T2.11.10.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.10.4.4.1" class="ltx_text" style="font-size:80%;">29.7</span></td>
<td id="S4.T2.11.10.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.10.4.5.1" class="ltx_text" style="font-size:80%;">36.0</span></td>
<td id="S4.T2.11.10.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.10.4.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T2.11.10.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.11.10.4.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T2.10.4" class="ltx_tr">
<td id="S4.T2.10.4.2" class="ltx_td ltx_align_center"><span id="S4.T2.10.4.2.1" class="ltx_text" style="font-size:80%;">74.0</span></td>
<td id="S4.T2.10.4.3" class="ltx_td ltx_align_center"><span id="S4.T2.10.4.3.1" class="ltx_text" style="font-size:80%;">53.7</span></td>
<td id="S4.T2.10.4.4" class="ltx_td ltx_align_center"><span id="S4.T2.10.4.4.1" class="ltx_text" style="font-size:80%;">30.9</span></td>
<td id="S4.T2.10.4.5" class="ltx_td ltx_align_center"><span id="S4.T2.10.4.5.1" class="ltx_text" style="font-size:80%;">37.7</span></td>
<td id="S4.T2.10.4.1" class="ltx_td ltx_align_center"><math id="S4.T2.10.4.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T2.10.4.1.m1.1a"><mi mathsize="80%" id="S4.T2.10.4.1.m1.1.1" xref="S4.T2.10.4.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T2.10.4.1.m1.1b"><ci id="S4.T2.10.4.1.m1.1.1.cmml" xref="S4.T2.10.4.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.4.1.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T2.10.4.6" class="ltx_td ltx_align_center"><span id="S4.T2.10.4.6.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T2.11.11.5" class="ltx_tr">
<td id="S4.T2.11.11.5.1" class="ltx_td ltx_align_center"><span id="S4.T2.11.11.5.1.1" class="ltx_text" style="font-size:80%;">74.0</span></td>
<td id="S4.T2.11.11.5.2" class="ltx_td ltx_align_center"><span id="S4.T2.11.11.5.2.1" class="ltx_text" style="font-size:80%;">53.8</span></td>
<td id="S4.T2.11.11.5.3" class="ltx_td ltx_align_center"><span id="S4.T2.11.11.5.3.1" class="ltx_text" style="font-size:80%;">30.6</span></td>
<td id="S4.T2.11.11.5.4" class="ltx_td ltx_align_center"><span id="S4.T2.11.11.5.4.1" class="ltx_text" style="font-size:80%;">36.9</span></td>
<td id="S4.T2.11.11.5.5" class="ltx_td ltx_align_center"><span id="S4.T2.11.11.5.5.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T2.11.11.5.6" class="ltx_td ltx_align_center"><span id="S4.T2.11.11.5.6.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S4.T2.11.5" class="ltx_tr">
<td id="S4.T2.11.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.11.5.2.1" class="ltx_text" style="font-size:80%;">74.3</span></td>
<td id="S4.T2.11.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.11.5.3.1" class="ltx_text" style="font-size:80%;">53.5</span></td>
<td id="S4.T2.11.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.11.5.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">32.3</span></td>
<td id="S4.T2.11.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.11.5.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">39.0</span></td>
<td id="S4.T2.11.5.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T2.11.5.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T2.11.5.1.m1.1a"><mi mathsize="80%" id="S4.T2.11.5.1.m1.1.1" xref="S4.T2.11.5.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T2.11.5.1.m1.1b"><ci id="S4.T2.11.5.1.m1.1.1.cmml" xref="S4.T2.11.5.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.5.1.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T2.11.5.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.11.5.6.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Tuned <span id="S4.SS2.SSS0.Px2.1.1" class="ltx_text ltx_font_italic">vs</span>.Â Styled-Tuned models</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.3" class="ltx_p">(Results B, <a href="#S4.T3" title="In Tuned vs. Styled-Tuned models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>) With the goal of enhancing pose estimation on our <em id="S4.SS2.SSS0.Px2.p1.3.3" class="ltx_emph ltx_font_italic">CA</em> dataset, a naive approach is to fine-tune on this data, we call these models as <span id="S4.SS2.SSS0.Px2.p1.3.4" class="ltx_text ltx_font_italic">Tuned models</span>. Then, we take the styled modelsÂ (<a href="#S4.T2" title="In Baseline vs Styled models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>), which have already learned the styles of <em id="S4.SS2.SSS0.Px2.p1.3.5" class="ltx_emph ltx_font_italic">CA</em> data, and fine-tune them on our <em id="S4.SS2.SSS0.Px2.p1.3.6" class="ltx_emph ltx_font_italic">CA</em> data (<span id="S4.SS2.SSS0.Px2.p1.3.7" class="ltx_text ltx_font_italic">Styled-Tuned</span> or <span id="S4.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">Sd<math id="S4.SS2.SSS0.Px2.p1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.1.m1.1a"><mo stretchy="false" id="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.1.m1.1b"><ci id="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span>). As seen in <a href="#S4.T3" title="In Tuned vs. Styled-Tuned models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>, the <span id="S4.SS2.SSS0.Px2.p1.2.2" class="ltx_text ltx_font_italic">Sd<math id="S4.SS2.SSS0.Px2.p1.2.2.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.2.2.m1.1a"><mo stretchy="false" id="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.2.m1.1b"><ci id="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.2.m1.1c">\rightarrow</annotation></semantics></math>Td</span> models give a better performance as compared to their <span id="S4.SS2.SSS0.Px2.p1.3.8" class="ltx_text ltx_font_italic">Tuned</span> counterparts, for pose estimation. Irrespective of the combination of <math id="S4.SS2.SSS0.Px2.p1.3.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.3.m1.1a"><mi id="S4.SS2.SSS0.Px2.p1.3.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.3.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.3.m1.1b"><ci id="S4.SS2.SSS0.Px2.p1.3.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.3.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.3.m1.1c">\alpha</annotation></semantics></math> and <span id="S4.SS2.SSS0.Px2.p1.3.9" class="ltx_text ltx_font_italic">SS</span>, the pose models tend to perform better. We argue that this is partly because the models gradually learn the styles (<span id="S4.SS2.SSS0.Px2.p1.3.10" class="ltx_text ltx_font_italic">SCP</span>), while optimising for the main task. During training, the <span id="S4.SS2.SSS0.Px2.p1.3.11" class="ltx_text ltx_font_italic">Styled</span> modelsÂ (<a href="#S4.T2" title="In Baseline vs Styled models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>) are able to see the different spectrum of style intensities. They adapt the styles while maintaining a consistent performance over the main task.
<br class="ltx_break"></p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.19.6.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.10.5" class="ltx_text ltx_font_bold" style="font-size:90%;">Results B<span id="S4.T3.7.2.2" class="ltx_text ltx_font_medium">: Comparing <span id="S4.T3.7.2.2.2" class="ltx_text ltx_font_italic">tuned</span> model with the <span id="S4.T3.6.1.1.1" class="ltx_text ltx_font_italic">styled-tunedÂ (<em id="S4.T3.6.1.1.1.1" class="ltx_emph ltx_font_upright">Sd</em><math id="S4.T3.6.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T3.6.1.1.1.m1.1b"><mo stretchy="false" id="S4.T3.6.1.1.1.m1.1.1" xref="S4.T3.6.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.1.1.1.m1.1c"><ci id="S4.T3.6.1.1.1.m1.1.1.cmml" xref="S4.T3.6.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.1.1.1.m1.1d">\rightarrow</annotation></semantics></math><em id="S4.T3.6.1.1.1.2" class="ltx_emph ltx_font_upright">Td</em>)</span> model, with different combinations of <math id="S4.T3.7.2.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T3.7.2.2.m1.1b"><mi id="S4.T3.7.2.2.m1.1.1" xref="S4.T3.7.2.2.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T3.7.2.2.m1.1c"><ci id="S4.T3.7.2.2.m1.1.1.cmml" xref="S4.T3.7.2.2.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.2.2.m1.1d">\alpha</annotation></semantics></math> and <span id="S4.T3.7.2.2.3" class="ltx_text ltx_font_italic">Style-Set</span> (<em id="S4.T3.7.2.2.4" class="ltx_emph ltx_font_italic">SS</em>), for detector (</span>D<span id="S4.T3.10.5.6" class="ltx_text ltx_font_medium">) and pose estimator (</span>P<span id="S4.T3.10.5.5" class="ltx_text ltx_font_medium">). <math id="S4.T3.8.3.3.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.T3.8.3.3.m1.1b"><mrow id="S4.T3.8.3.3.m1.1.1" xref="S4.T3.8.3.3.m1.1.1.cmml"><mi id="S4.T3.8.3.3.m1.1.1.2" xref="S4.T3.8.3.3.m1.1.1.2.cmml">Î±</mi><mo id="S4.T3.8.3.3.m1.1.1.1" xref="S4.T3.8.3.3.m1.1.1.1.cmml">=</mo><mn id="S4.T3.8.3.3.m1.1.1.3" xref="S4.T3.8.3.3.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.8.3.3.m1.1c"><apply id="S4.T3.8.3.3.m1.1.1.cmml" xref="S4.T3.8.3.3.m1.1.1"><eq id="S4.T3.8.3.3.m1.1.1.1.cmml" xref="S4.T3.8.3.3.m1.1.1.1"></eq><ci id="S4.T3.8.3.3.m1.1.1.2.cmml" xref="S4.T3.8.3.3.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T3.8.3.3.m1.1.1.3.cmml" xref="S4.T3.8.3.3.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.3.3.m1.1d">\alpha=0.5</annotation></semantics></math> or <math id="S4.T3.9.4.4.m2.1" class="ltx_Math" alttext="\alpha=U" display="inline"><semantics id="S4.T3.9.4.4.m2.1b"><mrow id="S4.T3.9.4.4.m2.1.1" xref="S4.T3.9.4.4.m2.1.1.cmml"><mi id="S4.T3.9.4.4.m2.1.1.2" xref="S4.T3.9.4.4.m2.1.1.2.cmml">Î±</mi><mo id="S4.T3.9.4.4.m2.1.1.1" xref="S4.T3.9.4.4.m2.1.1.1.cmml">=</mo><mi id="S4.T3.9.4.4.m2.1.1.3" xref="S4.T3.9.4.4.m2.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.9.4.4.m2.1c"><apply id="S4.T3.9.4.4.m2.1.1.cmml" xref="S4.T3.9.4.4.m2.1.1"><eq id="S4.T3.9.4.4.m2.1.1.1.cmml" xref="S4.T3.9.4.4.m2.1.1.1"></eq><ci id="S4.T3.9.4.4.m2.1.1.2.cmml" xref="S4.T3.9.4.4.m2.1.1.2">ğ›¼</ci><ci id="S4.T3.9.4.4.m2.1.1.3.cmml" xref="S4.T3.9.4.4.m2.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.4.4.m2.1d">\alpha=U</annotation></semantics></math> (randomly sampled from a uniform distribution: <math id="S4.T3.10.5.5.m3.2" class="ltx_Math" alttext="U=uniform(0,1)" display="inline"><semantics id="S4.T3.10.5.5.m3.2b"><mrow id="S4.T3.10.5.5.m3.2.3" xref="S4.T3.10.5.5.m3.2.3.cmml"><mi id="S4.T3.10.5.5.m3.2.3.2" xref="S4.T3.10.5.5.m3.2.3.2.cmml">U</mi><mo id="S4.T3.10.5.5.m3.2.3.1" xref="S4.T3.10.5.5.m3.2.3.1.cmml">=</mo><mrow id="S4.T3.10.5.5.m3.2.3.3" xref="S4.T3.10.5.5.m3.2.3.3.cmml"><mi id="S4.T3.10.5.5.m3.2.3.3.2" xref="S4.T3.10.5.5.m3.2.3.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.T3.10.5.5.m3.2.3.3.1" xref="S4.T3.10.5.5.m3.2.3.3.1.cmml">â€‹</mo><mi id="S4.T3.10.5.5.m3.2.3.3.3" xref="S4.T3.10.5.5.m3.2.3.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.T3.10.5.5.m3.2.3.3.1b" xref="S4.T3.10.5.5.m3.2.3.3.1.cmml">â€‹</mo><mi id="S4.T3.10.5.5.m3.2.3.3.4" xref="S4.T3.10.5.5.m3.2.3.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.T3.10.5.5.m3.2.3.3.1c" xref="S4.T3.10.5.5.m3.2.3.3.1.cmml">â€‹</mo><mi id="S4.T3.10.5.5.m3.2.3.3.5" xref="S4.T3.10.5.5.m3.2.3.3.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.T3.10.5.5.m3.2.3.3.1d" xref="S4.T3.10.5.5.m3.2.3.3.1.cmml">â€‹</mo><mi id="S4.T3.10.5.5.m3.2.3.3.6" xref="S4.T3.10.5.5.m3.2.3.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T3.10.5.5.m3.2.3.3.1e" xref="S4.T3.10.5.5.m3.2.3.3.1.cmml">â€‹</mo><mi id="S4.T3.10.5.5.m3.2.3.3.7" xref="S4.T3.10.5.5.m3.2.3.3.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.T3.10.5.5.m3.2.3.3.1f" xref="S4.T3.10.5.5.m3.2.3.3.1.cmml">â€‹</mo><mi id="S4.T3.10.5.5.m3.2.3.3.8" xref="S4.T3.10.5.5.m3.2.3.3.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T3.10.5.5.m3.2.3.3.1g" xref="S4.T3.10.5.5.m3.2.3.3.1.cmml">â€‹</mo><mrow id="S4.T3.10.5.5.m3.2.3.3.9.2" xref="S4.T3.10.5.5.m3.2.3.3.9.1.cmml"><mo stretchy="false" id="S4.T3.10.5.5.m3.2.3.3.9.2.1" xref="S4.T3.10.5.5.m3.2.3.3.9.1.cmml">(</mo><mn id="S4.T3.10.5.5.m3.1.1" xref="S4.T3.10.5.5.m3.1.1.cmml">0</mn><mo id="S4.T3.10.5.5.m3.2.3.3.9.2.2" xref="S4.T3.10.5.5.m3.2.3.3.9.1.cmml">,</mo><mn id="S4.T3.10.5.5.m3.2.2" xref="S4.T3.10.5.5.m3.2.2.cmml">1</mn><mo stretchy="false" id="S4.T3.10.5.5.m3.2.3.3.9.2.3" xref="S4.T3.10.5.5.m3.2.3.3.9.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.10.5.5.m3.2c"><apply id="S4.T3.10.5.5.m3.2.3.cmml" xref="S4.T3.10.5.5.m3.2.3"><eq id="S4.T3.10.5.5.m3.2.3.1.cmml" xref="S4.T3.10.5.5.m3.2.3.1"></eq><ci id="S4.T3.10.5.5.m3.2.3.2.cmml" xref="S4.T3.10.5.5.m3.2.3.2">ğ‘ˆ</ci><apply id="S4.T3.10.5.5.m3.2.3.3.cmml" xref="S4.T3.10.5.5.m3.2.3.3"><times id="S4.T3.10.5.5.m3.2.3.3.1.cmml" xref="S4.T3.10.5.5.m3.2.3.3.1"></times><ci id="S4.T3.10.5.5.m3.2.3.3.2.cmml" xref="S4.T3.10.5.5.m3.2.3.3.2">ğ‘¢</ci><ci id="S4.T3.10.5.5.m3.2.3.3.3.cmml" xref="S4.T3.10.5.5.m3.2.3.3.3">ğ‘›</ci><ci id="S4.T3.10.5.5.m3.2.3.3.4.cmml" xref="S4.T3.10.5.5.m3.2.3.3.4">ğ‘–</ci><ci id="S4.T3.10.5.5.m3.2.3.3.5.cmml" xref="S4.T3.10.5.5.m3.2.3.3.5">ğ‘“</ci><ci id="S4.T3.10.5.5.m3.2.3.3.6.cmml" xref="S4.T3.10.5.5.m3.2.3.3.6">ğ‘œ</ci><ci id="S4.T3.10.5.5.m3.2.3.3.7.cmml" xref="S4.T3.10.5.5.m3.2.3.3.7">ğ‘Ÿ</ci><ci id="S4.T3.10.5.5.m3.2.3.3.8.cmml" xref="S4.T3.10.5.5.m3.2.3.3.8">ğ‘š</ci><interval closure="open" id="S4.T3.10.5.5.m3.2.3.3.9.1.cmml" xref="S4.T3.10.5.5.m3.2.3.3.9.2"><cn type="integer" id="S4.T3.10.5.5.m3.1.1.cmml" xref="S4.T3.10.5.5.m3.1.1">0</cn><cn type="integer" id="S4.T3.10.5.5.m3.2.2.cmml" xref="S4.T3.10.5.5.m3.2.2">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.5.5.m3.2d">U=uniform(0,1)</annotation></semantics></math>). All values in <span id="S4.T3.10.5.5.1" class="ltx_text ltx_font_italic">mAP</span>, except <span id="S4.T3.10.5.5.2" class="ltx_text ltx_font_italic">CA<span id="S4.T3.10.5.5.2.1" class="ltx_text" style="font-size:56%;">mAR</span></span> (<span id="S4.T3.10.5.5.3" class="ltx_text ltx_font_italic">mAR</span>).</span></span></figcaption>
<table id="S4.T3.17" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.11.1" class="ltx_tr">
<th id="S4.T3.11.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.11.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></th>
<th id="S4.T3.11.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.11.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CP</span></th>
<th id="S4.T3.11.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.11.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SCP</span></th>
<th id="S4.T3.11.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.11.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CA</span></th>
<th id="S4.T3.11.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T3.11.1.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CA</span><span id="S4.T3.11.1.6.2" class="ltx_text ltx_font_italic" style="font-size:50%;">mAR</span>
</th>
<th id="S4.T3.11.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="S4.T3.11.1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T3.11.1.1.m1.1a"><mi mathsize="80%" id="S4.T3.11.1.1.m1.1.1" xref="S4.T3.11.1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T3.11.1.1.m1.1b"><ci id="S4.T3.11.1.1.m1.1.1.cmml" xref="S4.T3.11.1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.1.1.m1.1c">\alpha</annotation></semantics></math></th>
<th id="S4.T3.11.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.11.1.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SS</span></th>
</tr>
<tr id="S4.T3.17.8.1" class="ltx_tr">
<th id="S4.T3.17.8.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" style="background-color:#CCCCCC;"><span id="S4.T3.17.8.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;background-color:#CCCCCC;">(D)Â Tuned</span></th>
<th id="S4.T3.17.8.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.17.8.1.2.1" class="ltx_text" style="font-size:80%;">-</span></th>
<th id="S4.T3.17.8.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.17.8.1.3.1" class="ltx_text" style="font-size:80%;">-</span></th>
<th id="S4.T3.17.8.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.17.8.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">49.4</span></th>
<th id="S4.T3.17.8.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.17.8.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">37.0</span></th>
<th id="S4.T3.17.8.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.17.8.1.6.1" class="ltx_text" style="font-size:80%;">0.5</span></th>
<th id="S4.T3.17.8.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.17.8.1.7.1" class="ltx_text" style="font-size:80%;">RB</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.17.9.1" class="ltx_tr">
<td id="S4.T3.17.9.1.1" class="ltx_td"></td>
<td id="S4.T3.17.9.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.9.1.2.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.17.9.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.9.1.3.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.17.9.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.9.1.4.1" class="ltx_text" style="font-size:80%;">44.3</span></td>
<td id="S4.T3.17.9.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.9.1.5.1" class="ltx_text" style="font-size:80%;">32.9</span></td>
<td id="S4.T3.17.9.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.9.1.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T3.17.9.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.9.1.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T3.12.2" class="ltx_tr">
<td id="S4.T3.12.2.2" class="ltx_td"></td>
<td id="S4.T3.12.2.3" class="ltx_td ltx_align_center"><span id="S4.T3.12.2.3.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.12.2.4" class="ltx_td ltx_align_center"><span id="S4.T3.12.2.4.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.12.2.5" class="ltx_td ltx_align_center"><span id="S4.T3.12.2.5.1" class="ltx_text" style="font-size:80%;">43.0</span></td>
<td id="S4.T3.12.2.6" class="ltx_td ltx_align_center"><span id="S4.T3.12.2.6.1" class="ltx_text" style="font-size:80%;">32.6</span></td>
<td id="S4.T3.12.2.1" class="ltx_td ltx_align_center"><math id="S4.T3.12.2.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T3.12.2.1.m1.1a"><mi mathsize="80%" id="S4.T3.12.2.1.m1.1.1" xref="S4.T3.12.2.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T3.12.2.1.m1.1b"><ci id="S4.T3.12.2.1.m1.1.1.cmml" xref="S4.T3.12.2.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.2.1.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T3.12.2.7" class="ltx_td ltx_align_center"><span id="S4.T3.12.2.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T3.17.10.2" class="ltx_tr">
<td id="S4.T3.17.10.2.1" class="ltx_td"></td>
<td id="S4.T3.17.10.2.2" class="ltx_td ltx_align_center"><span id="S4.T3.17.10.2.2.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.17.10.2.3" class="ltx_td ltx_align_center"><span id="S4.T3.17.10.2.3.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.17.10.2.4" class="ltx_td ltx_align_center"><span id="S4.T3.17.10.2.4.1" class="ltx_text" style="font-size:80%;">43.7</span></td>
<td id="S4.T3.17.10.2.5" class="ltx_td ltx_align_center"><span id="S4.T3.17.10.2.5.1" class="ltx_text" style="font-size:80%;">33.4</span></td>
<td id="S4.T3.17.10.2.6" class="ltx_td ltx_align_center"><span id="S4.T3.17.10.2.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T3.17.10.2.7" class="ltx_td ltx_align_center"><span id="S4.T3.17.10.2.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S4.T3.14.4" class="ltx_tr">
<td id="S4.T3.13.3.1" class="ltx_td ltx_align_left" style="background-color:#CCCCCC;"><span id="S4.T3.13.3.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;background-color:#CCCCCC;">(D)Â Sd<math id="S4.T3.13.3.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T3.13.3.1.1.1.m1.1a"><mo mathbackground="#CCCCCC" stretchy="false" id="S4.T3.13.3.1.1.1.m1.1.1" xref="S4.T3.13.3.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T3.13.3.1.1.1.m1.1b"><ci id="S4.T3.13.3.1.1.1.m1.1.1.cmml" xref="S4.T3.13.3.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.3.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span></td>
<td id="S4.T3.14.4.3" class="ltx_td ltx_align_center"><span id="S4.T3.14.4.3.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.14.4.4" class="ltx_td ltx_align_center"><span id="S4.T3.14.4.4.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.14.4.5" class="ltx_td ltx_align_center"><span id="S4.T3.14.4.5.1" class="ltx_text" style="font-size:80%;">43.9</span></td>
<td id="S4.T3.14.4.6" class="ltx_td ltx_align_center"><span id="S4.T3.14.4.6.1" class="ltx_text" style="font-size:80%;">32.9</span></td>
<td id="S4.T3.14.4.2" class="ltx_td ltx_align_center"><math id="S4.T3.14.4.2.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T3.14.4.2.m1.1a"><mi mathsize="80%" id="S4.T3.14.4.2.m1.1.1" xref="S4.T3.14.4.2.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T3.14.4.2.m1.1b"><ci id="S4.T3.14.4.2.m1.1.1.cmml" xref="S4.T3.14.4.2.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.4.2.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T3.14.4.7" class="ltx_td ltx_align_center"><span id="S4.T3.14.4.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S4.T3.17.11.3" class="ltx_tr">
<td id="S4.T3.17.11.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.17.11.3.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(P)Â Tuned</span></td>
<td id="S4.T3.17.11.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.11.3.2.1" class="ltx_text" style="font-size:80%;">14.0</span></td>
<td id="S4.T3.17.11.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.11.3.3.1" class="ltx_text" style="font-size:80%;">9.3</span></td>
<td id="S4.T3.17.11.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.11.3.4.1" class="ltx_text" style="font-size:80%;">65.6</span></td>
<td id="S4.T3.17.11.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.11.3.5.1" class="ltx_text" style="font-size:80%;">72.3</span></td>
<td id="S4.T3.17.11.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.11.3.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T3.17.11.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.11.3.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T3.17.12.4" class="ltx_tr">
<td id="S4.T3.17.12.4.1" class="ltx_td"></td>
<td id="S4.T3.17.12.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.12.4.2.1" class="ltx_text" style="font-size:80%;">11.8</span></td>
<td id="S4.T3.17.12.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.12.4.3.1" class="ltx_text" style="font-size:80%;">10.5</span></td>
<td id="S4.T3.17.12.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.12.4.4.1" class="ltx_text" style="font-size:80%;">66.8</span></td>
<td id="S4.T3.17.12.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.12.4.5.1" class="ltx_text" style="font-size:80%;">73.3</span></td>
<td id="S4.T3.17.12.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.12.4.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T3.17.12.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.17.12.4.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T3.15.5" class="ltx_tr">
<td id="S4.T3.15.5.2" class="ltx_td"></td>
<td id="S4.T3.15.5.3" class="ltx_td ltx_align_center"><span id="S4.T3.15.5.3.1" class="ltx_text" style="font-size:80%;">20.3</span></td>
<td id="S4.T3.15.5.4" class="ltx_td ltx_align_center"><span id="S4.T3.15.5.4.1" class="ltx_text" style="font-size:80%;">14.5</span></td>
<td id="S4.T3.15.5.5" class="ltx_td ltx_align_center"><span id="S4.T3.15.5.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">67.2</span></td>
<td id="S4.T3.15.5.6" class="ltx_td ltx_align_center"><span id="S4.T3.15.5.6.1" class="ltx_text" style="font-size:80%;">73.3</span></td>
<td id="S4.T3.15.5.1" class="ltx_td ltx_align_center"><math id="S4.T3.15.5.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T3.15.5.1.m1.1a"><mi mathsize="80%" id="S4.T3.15.5.1.m1.1.1" xref="S4.T3.15.5.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T3.15.5.1.m1.1b"><ci id="S4.T3.15.5.1.m1.1.1.cmml" xref="S4.T3.15.5.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.5.1.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T3.15.5.7" class="ltx_td ltx_align_center"><span id="S4.T3.15.5.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T3.17.13.5" class="ltx_tr">
<td id="S4.T3.17.13.5.1" class="ltx_td"></td>
<td id="S4.T3.17.13.5.2" class="ltx_td ltx_align_center"><span id="S4.T3.17.13.5.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">34.9</span></td>
<td id="S4.T3.17.13.5.3" class="ltx_td ltx_align_center"><span id="S4.T3.17.13.5.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">22.4</span></td>
<td id="S4.T3.17.13.5.4" class="ltx_td ltx_align_center"><span id="S4.T3.17.13.5.4.1" class="ltx_text" style="font-size:80%;">66.6</span></td>
<td id="S4.T3.17.13.5.5" class="ltx_td ltx_align_center"><span id="S4.T3.17.13.5.5.1" class="ltx_text" style="font-size:80%;">73.1</span></td>
<td id="S4.T3.17.13.5.6" class="ltx_td ltx_align_center"><span id="S4.T3.17.13.5.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T3.17.13.5.7" class="ltx_td ltx_align_center"><span id="S4.T3.17.13.5.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S4.T3.17.7" class="ltx_tr">
<td id="S4.T3.16.6.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.16.6.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(P)Â Sd<math id="S4.T3.16.6.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T3.16.6.1.1.1.m1.1a"><mo stretchy="false" id="S4.T3.16.6.1.1.1.m1.1.1" xref="S4.T3.16.6.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T3.16.6.1.1.1.m1.1b"><ci id="S4.T3.16.6.1.1.1.m1.1.1.cmml" xref="S4.T3.16.6.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.6.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span></td>
<td id="S4.T3.17.7.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.17.7.3.1" class="ltx_text" style="font-size:80%;">28.0</span></td>
<td id="S4.T3.17.7.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.17.7.4.1" class="ltx_text" style="font-size:80%;">18.5</span></td>
<td id="S4.T3.17.7.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.17.7.5.1" class="ltx_text" style="font-size:80%;">67.1</span></td>
<td id="S4.T3.17.7.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.17.7.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">73.6</span></td>
<td id="S4.T3.17.7.2" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T3.17.7.2.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T3.17.7.2.m1.1a"><mi mathsize="80%" id="S4.T3.17.7.2.m1.1.1" xref="S4.T3.17.7.2.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T3.17.7.2.m1.1b"><ci id="S4.T3.17.7.2.m1.1.1.cmml" xref="S4.T3.17.7.2.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.7.2.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T3.17.7.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.17.7.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p2.1" class="ltx_p">With <a href="#S4.T2" title="In Baseline vs Styled models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S4.T3" title="In Tuned vs. Styled-Tuned models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>, we were able to enhance the performance of pose models, with <span id="S4.SS2.SSS0.Px2.p2.1.2" class="ltx_text ltx_font_italic">styled</span> as well as <span id="S4.SS2.SSS0.Px2.p2.1.3" class="ltx_text ltx_font_italic">styled-tuned</span> models. <span id="S4.SS2.SSS0.Px2.p2.1.4" class="ltx_text ltx_font_italic">Styled</span> models can help to improve the performance with a 7.7â€‰pp (<span id="S4.SS2.SSS0.Px2.p2.1.5" class="ltx_text ltx_font_italic">mAP</span>) jump in performance, without any labels. While the <span id="S4.SS2.SSS0.Px2.p2.1.6" class="ltx_text ltx_font_italic">styled-tuned</span> models show that fine-tuning with <span id="S4.SS2.SSS0.Px2.p2.1.7" class="ltx_text ltx_font_italic">styled</span> models is generally beneficial for the performance, the <span id="S4.SS2.SSS0.Px2.p2.1.1" class="ltx_text ltx_font_italic">Sd<math id="S4.SS2.SSS0.Px2.p2.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.SSS0.Px2.p2.1.1.m1.1a"><mo stretchy="false" id="S4.SS2.SSS0.Px2.p2.1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p2.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p2.1.1.m1.1b"><ci id="S4.SS2.SSS0.Px2.p2.1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p2.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p2.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span> model for pose gives a significant 1.6â€‰pp (<span id="S4.SS2.SSS0.Px2.p2.1.8" class="ltx_text ltx_font_italic">mAP</span>) performance improvement for <span id="S4.SS2.SSS0.Px2.p2.1.9" class="ltx_text ltx_font_italic">CA</span> dataset over its <span id="S4.SS2.SSS0.Px2.p2.1.10" class="ltx_text ltx_font_italic">Tuned</span> counterpart.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.12.4.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.6.3" class="ltx_text ltx_font_bold" style="font-size:90%;">Results C<span id="S4.T4.6.3.3" class="ltx_text ltx_font_medium">:
Comparing <span id="S4.T4.6.3.3.2" class="ltx_text ltx_font_italic">tuned</span> model with the <span id="S4.T4.4.1.1.1" class="ltx_text ltx_font_italic">styled-tunedÂ (<em id="S4.T4.4.1.1.1.1" class="ltx_emph ltx_font_upright">Sd</em><math id="S4.T4.4.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T4.4.1.1.1.m1.1b"><mo stretchy="false" id="S4.T4.4.1.1.1.m1.1.1" xref="S4.T4.4.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.1.1.1.m1.1c"><ci id="S4.T4.4.1.1.1.m1.1.1.cmml" xref="S4.T4.4.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.1.1.1.m1.1d">\rightarrow</annotation></semantics></math><em id="S4.T4.4.1.1.1.2" class="ltx_emph ltx_font_upright">Td</em>)</span> model, by training on different quantities (25â€‰%, 50â€‰%, 75â€‰%, 100â€‰%) of the <em id="S4.T4.6.3.3.3" class="ltx_emph ltx_font_italic">CA</em> data for pose estimation. It clearly shows that the styled model learns quicker. <math id="S4.T4.5.2.2.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.T4.5.2.2.m1.1b"><mrow id="S4.T4.5.2.2.m1.1.1" xref="S4.T4.5.2.2.m1.1.1.cmml"><mi id="S4.T4.5.2.2.m1.1.1.2" xref="S4.T4.5.2.2.m1.1.1.2.cmml">Î±</mi><mo id="S4.T4.5.2.2.m1.1.1.1" xref="S4.T4.5.2.2.m1.1.1.1.cmml">=</mo><mn id="S4.T4.5.2.2.m1.1.1.3" xref="S4.T4.5.2.2.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.5.2.2.m1.1c"><apply id="S4.T4.5.2.2.m1.1.1.cmml" xref="S4.T4.5.2.2.m1.1.1"><eq id="S4.T4.5.2.2.m1.1.1.1.cmml" xref="S4.T4.5.2.2.m1.1.1.1"></eq><ci id="S4.T4.5.2.2.m1.1.1.2.cmml" xref="S4.T4.5.2.2.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T4.5.2.2.m1.1.1.3.cmml" xref="S4.T4.5.2.2.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.2.2.m1.1d">\alpha=0.5</annotation></semantics></math> or <math id="S4.T4.6.3.3.m2.1" class="ltx_Math" alttext="\alpha=U" display="inline"><semantics id="S4.T4.6.3.3.m2.1b"><mrow id="S4.T4.6.3.3.m2.1.1" xref="S4.T4.6.3.3.m2.1.1.cmml"><mi id="S4.T4.6.3.3.m2.1.1.2" xref="S4.T4.6.3.3.m2.1.1.2.cmml">Î±</mi><mo id="S4.T4.6.3.3.m2.1.1.1" xref="S4.T4.6.3.3.m2.1.1.1.cmml">=</mo><mi id="S4.T4.6.3.3.m2.1.1.3" xref="S4.T4.6.3.3.m2.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.6.3.3.m2.1c"><apply id="S4.T4.6.3.3.m2.1.1.cmml" xref="S4.T4.6.3.3.m2.1.1"><eq id="S4.T4.6.3.3.m2.1.1.1.cmml" xref="S4.T4.6.3.3.m2.1.1.1"></eq><ci id="S4.T4.6.3.3.m2.1.1.2.cmml" xref="S4.T4.6.3.3.m2.1.1.2">ğ›¼</ci><ci id="S4.T4.6.3.3.m2.1.1.3.cmml" xref="S4.T4.6.3.3.m2.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.3.3.m2.1d">\alpha=U</annotation></semantics></math> (randomly sampled from a uniform distribution). All values in <span id="S4.T4.6.3.3.4" class="ltx_text ltx_font_italic">mAP</span>,
<em id="S4.T4.6.3.3.5" class="ltx_emph ltx_font_italic">SS</em>: Style-Set.</span></span></figcaption>
<table id="S4.T4.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.7.1" class="ltx_tr">
<th id="S4.T4.7.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.7.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></th>
<th id="S4.T4.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.7.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">25â€‰%</span></th>
<th id="S4.T4.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.7.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">50â€‰%</span></th>
<th id="S4.T4.7.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.7.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">75â€‰%</span></th>
<th id="S4.T4.7.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.7.1.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">100â€‰%</span></th>
<th id="S4.T4.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="S4.T4.7.1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T4.7.1.1.m1.1a"><mi mathsize="80%" id="S4.T4.7.1.1.m1.1.1" xref="S4.T4.7.1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T4.7.1.1.m1.1b"><ci id="S4.T4.7.1.1.m1.1.1.cmml" xref="S4.T4.7.1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.1.1.m1.1c">\alpha</annotation></semantics></math></th>
<th id="S4.T4.7.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.7.1.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SS</span></th>
</tr>
<tr id="S4.T4.10.5.1" class="ltx_tr">
<th id="S4.T4.10.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.10.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(P)Â Tuned</span></th>
<th id="S4.T4.10.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.10.5.1.2.1" class="ltx_text" style="font-size:80%;">61.3</span></th>
<th id="S4.T4.10.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.10.5.1.3.1" class="ltx_text" style="font-size:80%;">65.0</span></th>
<th id="S4.T4.10.5.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.10.5.1.4.1" class="ltx_text" style="font-size:80%;">65.1</span></th>
<th id="S4.T4.10.5.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.10.5.1.5.1" class="ltx_text" style="font-size:80%;">65.6</span></th>
<th id="S4.T4.10.5.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.10.5.1.6.1" class="ltx_text" style="font-size:80%;">-</span></th>
<th id="S4.T4.10.5.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.10.5.1.7.1" class="ltx_text" style="font-size:80%;">-</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.8.2" class="ltx_tr">
<td id="S4.T4.8.2.1" class="ltx_td ltx_align_left ltx_border_bb" rowspan="4"><span id="S4.T4.8.2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(P)Â Sd<math id="S4.T4.8.2.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T4.8.2.1.1.1.m1.1a"><mo stretchy="false" id="S4.T4.8.2.1.1.1.m1.1.1" xref="S4.T4.8.2.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T4.8.2.1.1.1.m1.1b"><ci id="S4.T4.8.2.1.1.1.m1.1.1.cmml" xref="S4.T4.8.2.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.2.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span></td>
<td id="S4.T4.8.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.8.2.2.1" class="ltx_text" style="font-size:80%;">60.6</span></td>
<td id="S4.T4.8.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.8.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">65.4</span></td>
<td id="S4.T4.8.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.8.2.4.1" class="ltx_text" style="font-size:80%;">65.1</span></td>
<td id="S4.T4.8.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.8.2.5.1" class="ltx_text" style="font-size:80%;">66.8</span></td>
<td id="S4.T4.8.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.8.2.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T4.8.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.8.2.7.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T4.9.3" class="ltx_tr">
<td id="S4.T4.9.3.2" class="ltx_td ltx_align_center"><span id="S4.T4.9.3.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">62.1</span></td>
<td id="S4.T4.9.3.3" class="ltx_td ltx_align_center"><span id="S4.T4.9.3.3.1" class="ltx_text" style="font-size:80%;">64.7</span></td>
<td id="S4.T4.9.3.4" class="ltx_td ltx_align_center"><span id="S4.T4.9.3.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">66.5</span></td>
<td id="S4.T4.9.3.5" class="ltx_td ltx_align_center"><span id="S4.T4.9.3.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">67.2</span></td>
<td id="S4.T4.9.3.1" class="ltx_td ltx_align_center"><math id="S4.T4.9.3.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T4.9.3.1.m1.1a"><mi mathsize="80%" id="S4.T4.9.3.1.m1.1.1" xref="S4.T4.9.3.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T4.9.3.1.m1.1b"><ci id="S4.T4.9.3.1.m1.1.1.cmml" xref="S4.T4.9.3.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.3.1.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T4.9.3.6" class="ltx_td ltx_align_center"><span id="S4.T4.9.3.6.1" class="ltx_text" style="font-size:80%;">RB</span></td>
</tr>
<tr id="S4.T4.10.6.1" class="ltx_tr">
<td id="S4.T4.10.6.1.1" class="ltx_td ltx_align_center"><span id="S4.T4.10.6.1.1.1" class="ltx_text" style="font-size:80%;">60.6</span></td>
<td id="S4.T4.10.6.1.2" class="ltx_td ltx_align_center"><span id="S4.T4.10.6.1.2.1" class="ltx_text" style="font-size:80%;">65.2</span></td>
<td id="S4.T4.10.6.1.3" class="ltx_td ltx_align_center"><span id="S4.T4.10.6.1.3.1" class="ltx_text" style="font-size:80%;">65.4</span></td>
<td id="S4.T4.10.6.1.4" class="ltx_td ltx_align_center"><span id="S4.T4.10.6.1.4.1" class="ltx_text" style="font-size:80%;">66.6</span></td>
<td id="S4.T4.10.6.1.5" class="ltx_td ltx_align_center"><span id="S4.T4.10.6.1.5.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T4.10.6.1.6" class="ltx_td ltx_align_center"><span id="S4.T4.10.6.1.6.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S4.T4.10.4" class="ltx_tr">
<td id="S4.T4.10.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.10.4.2.1" class="ltx_text" style="font-size:80%;">61.4</span></td>
<td id="S4.T4.10.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.10.4.3.1" class="ltx_text" style="font-size:80%;">64.8</span></td>
<td id="S4.T4.10.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.10.4.4.1" class="ltx_text" style="font-size:80%;">65.7</span></td>
<td id="S4.T4.10.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.10.4.5.1" class="ltx_text" style="font-size:80%;">67.1</span></td>
<td id="S4.T4.10.4.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T4.10.4.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S4.T4.10.4.1.m1.1a"><mi mathsize="80%" id="S4.T4.10.4.1.m1.1.1" xref="S4.T4.10.4.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.T4.10.4.1.m1.1b"><ci id="S4.T4.10.4.1.m1.1.1.cmml" xref="S4.T4.10.4.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.4.1.m1.1c">U</annotation></semantics></math></td>
<td id="S4.T4.10.4.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.10.4.6.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Influence of data quantity</h4>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p1.2" class="ltx_p">(Results C, <a href="#S4.T4" title="In Tuned vs. Styled-Tuned models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a>):
<a href="#S4.T4" title="In Tuned vs. Styled-Tuned models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a> shows that <span id="S4.SS2.SSS0.Px3.p1.2.1" class="ltx_text ltx_font_italic">Styled-Tuned</span> models learn faster than their <span id="S4.SS2.SSS0.Px3.p1.2.2" class="ltx_text ltx_font_italic">Tuned</span> counterpart, for each of the corresponding splits of <span id="S4.SS2.SSS0.Px3.p1.2.3" class="ltx_text ltx_font_italic">CA</span> data (model with <math id="S4.SS2.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\alpha=U" display="inline"><semantics id="S4.SS2.SSS0.Px3.p1.1.m1.1a"><mrow id="S4.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml">=</mo><mi id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1"><eq id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1"></eq><ci id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2">ğ›¼</ci><ci id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p1.1.m1.1c">\alpha=U</annotation></semantics></math>, <span id="S4.SS2.SSS0.Px3.p1.2.4" class="ltx_text ltx_font_italic">SS=RB</span> is more consistent). Specifically, the model with <math id="S4.SS2.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.SS2.SSS0.Px3.p1.2.m2.1a"><mrow id="S4.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px3.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS0.Px3.p1.2.m2.1.1.2" xref="S4.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml">Î±</mi><mo id="S4.SS2.SSS0.Px3.p1.2.m2.1.1.1" xref="S4.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS0.Px3.p1.2.m2.1.1.3" xref="S4.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p1.2.m2.1b"><apply id="S4.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.2.m2.1.1"><eq id="S4.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.2.m2.1.1.1"></eq><ci id="S4.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p1.2.m2.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p1.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p1.2.m2.1c">\alpha=0.5</annotation></semantics></math>, <span id="S4.SS2.SSS0.Px3.p1.2.5" class="ltx_text ltx_font_italic">SS=RB</span> and 50% of <span id="S4.SS2.SSS0.Px3.p1.2.6" class="ltx_text ltx_font_italic">CA</span> data gives equivalent performance to the <span id="S4.SS2.SSS0.Px3.p1.2.7" class="ltx_text ltx_font_italic">Tuned</span> model trained with whole <span id="S4.SS2.SSS0.Px3.p1.2.8" class="ltx_text ltx_font_italic">CA</span> data.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Perceptual Loss Comparison:</h4>

<div id="S4.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px4.p1.8" class="ltx_p"><a href="#S4.T5" title="In Perceptual Loss Comparison: â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a> shows the influence of perceptual loss for the model performance. <math id="S4.SS2.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="L_{comb1}" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.1.m1.1a"><msub id="S4.SS2.SSS0.Px4.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.2.cmml">L</mi><mrow id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.cmml"><mi id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.2" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.3" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1a" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.4" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1b" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.5" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1c" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mn id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.6" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.6.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.2">ğ¿</ci><apply id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3"><times id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.1"></times><ci id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.2.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.4.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.4">ğ‘š</ci><ci id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.5.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.6.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.3.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.1.m1.1c">L_{comb1}</annotation></semantics></math> is the experiment with adaptively weighing the detector as well as pose losses (<a href="#S3.E1.1" title="In Eq. 1 â€£ Enforcing Perceptual Similarity â€£ 3.2 Pose Estimation Approach â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">1a</span></a>). For <math id="S4.SS2.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="L_{comb2}" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.2.m2.1a"><msub id="S4.SS2.SSS0.Px4.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.2" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.2.cmml">L</mi><mrow id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.cmml"><mi id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.2" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.3" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1a" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.4" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1b" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.5" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1c" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mn id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.6" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.6.cmml">2</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.2.m2.1b"><apply id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.2">ğ¿</ci><apply id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3"><times id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.1"></times><ci id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.2.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.2">ğ‘</ci><ci id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.3.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.3">ğ‘œ</ci><ci id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.4.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.4">ğ‘š</ci><ci id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.5.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.6.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.3.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.2.m2.1c">L_{comb2}</annotation></semantics></math> (<a href="#S3.E1.2" title="In Eq. 1 â€£ Enforcing Perceptual Similarity â€£ 3.2 Pose Estimation Approach â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">1b</span></a>), we determined the values of <math id="S4.SS2.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.3.m3.1a"><mi id="S4.SS2.SSS0.Px4.p1.3.m3.1.1" xref="S4.SS2.SSS0.Px4.p1.3.m3.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.3.m3.1b"><ci id="S4.SS2.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.3.m3.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.3.m3.1c">\lambda</annotation></semantics></math>s through a parameter searchÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>: <math id="S4.SS2.SSS0.Px4.p1.4.m4.1" class="ltx_Math" alttext="\lambda_{1}=0.43" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.4.m4.1a"><mrow id="S4.SS2.SSS0.Px4.p1.4.m4.1.1" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.cmml"><msub id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.cmml"><mi id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.2" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.2.cmml">Î»</mi><mn id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.3" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.1" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.3" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.3.cmml">0.43</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.4.m4.1b"><apply id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1"><eq id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.1"></eq><apply id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.cmml" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.1.cmml" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.2.cmml" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.2">ğœ†</ci><cn type="integer" id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.3.cmml" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.2.3">1</cn></apply><cn type="float" id="S4.SS2.SSS0.Px4.p1.4.m4.1.1.3.cmml" xref="S4.SS2.SSS0.Px4.p1.4.m4.1.1.3">0.43</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.4.m4.1c">\lambda_{1}=0.43</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px4.p1.5.m5.1" class="ltx_Math" alttext="\lambda_{2}=0.92" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.5.m5.1a"><mrow id="S4.SS2.SSS0.Px4.p1.5.m5.1.1" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.cmml"><msub id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.cmml"><mi id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.2" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.2.cmml">Î»</mi><mn id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.3" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.3.cmml">2</mn></msub><mo id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.1" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.3" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.3.cmml">0.92</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.5.m5.1b"><apply id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1"><eq id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.1"></eq><apply id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.cmml" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.1.cmml" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.2.cmml" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.2">ğœ†</ci><cn type="integer" id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.3.cmml" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.2.3">2</cn></apply><cn type="float" id="S4.SS2.SSS0.Px4.p1.5.m5.1.1.3.cmml" xref="S4.SS2.SSS0.Px4.p1.5.m5.1.1.3">0.92</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.5.m5.1c">\lambda_{2}=0.92</annotation></semantics></math> for person detection and <math id="S4.SS2.SSS0.Px4.p1.6.m6.2" class="ltx_Math" alttext="\lambda_{1}=0.47,\lambda_{2}=0.018" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.6.m6.2a"><mrow id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.3.cmml"><mrow id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.cmml"><msub id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.cmml"><mi id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.2" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.2.cmml">Î»</mi><mn id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.3" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.1" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.3" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.3.cmml">0.47</mn></mrow><mo id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.3" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.3a.cmml">,</mo><mrow id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.cmml"><msub id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.cmml"><mi id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.2" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.2.cmml">Î»</mi><mn id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.3" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.1" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.1.cmml">=</mo><mn id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.3" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.3.cmml">0.018</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.6.m6.2b"><apply id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.3.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.3a.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1"><eq id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.1"></eq><apply id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.1.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2">subscript</csymbol><ci id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.2.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.2">ğœ†</ci><cn type="integer" id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.3.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.2.3">1</cn></apply><cn type="float" id="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.3.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.1.1.1.1.3">0.47</cn></apply><apply id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2"><eq id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.1.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.1"></eq><apply id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.1.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2">subscript</csymbol><ci id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.2.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.2">ğœ†</ci><cn type="integer" id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.3.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.2.3">2</cn></apply><cn type="float" id="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.3.cmml" xref="S4.SS2.SSS0.Px4.p1.6.m6.2.2.2.2.3">0.018</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.6.m6.2c">\lambda_{1}=0.47,\lambda_{2}=0.018</annotation></semantics></math> for pose estimation.
We present results for the combination <span id="S4.SS2.SSS0.Px4.p1.8.1" class="ltx_text ltx_font_italic">SS=CA</span>Â &amp;Â <math id="S4.SS2.SSS0.Px4.p1.7.m7.1" class="ltx_Math" alttext="\alpha=U" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.7.m7.1a"><mrow id="S4.SS2.SSS0.Px4.p1.7.m7.1.1" xref="S4.SS2.SSS0.Px4.p1.7.m7.1.1.cmml"><mi id="S4.SS2.SSS0.Px4.p1.7.m7.1.1.2" xref="S4.SS2.SSS0.Px4.p1.7.m7.1.1.2.cmml">Î±</mi><mo id="S4.SS2.SSS0.Px4.p1.7.m7.1.1.1" xref="S4.SS2.SSS0.Px4.p1.7.m7.1.1.1.cmml">=</mo><mi id="S4.SS2.SSS0.Px4.p1.7.m7.1.1.3" xref="S4.SS2.SSS0.Px4.p1.7.m7.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.7.m7.1b"><apply id="S4.SS2.SSS0.Px4.p1.7.m7.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.7.m7.1.1"><eq id="S4.SS2.SSS0.Px4.p1.7.m7.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.7.m7.1.1.1"></eq><ci id="S4.SS2.SSS0.Px4.p1.7.m7.1.1.2.cmml" xref="S4.SS2.SSS0.Px4.p1.7.m7.1.1.2">ğ›¼</ci><ci id="S4.SS2.SSS0.Px4.p1.7.m7.1.1.3.cmml" xref="S4.SS2.SSS0.Px4.p1.7.m7.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.7.m7.1c">\alpha=U</annotation></semantics></math> for the detector, and we chose <span id="S4.SS2.SSS0.Px4.p1.8.2" class="ltx_text ltx_font_italic">SS=CA</span>Â &amp;Â <math id="S4.SS2.SSS0.Px4.p1.8.m8.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.8.m8.1a"><mrow id="S4.SS2.SSS0.Px4.p1.8.m8.1.1" xref="S4.SS2.SSS0.Px4.p1.8.m8.1.1.cmml"><mi id="S4.SS2.SSS0.Px4.p1.8.m8.1.1.2" xref="S4.SS2.SSS0.Px4.p1.8.m8.1.1.2.cmml">Î±</mi><mo id="S4.SS2.SSS0.Px4.p1.8.m8.1.1.1" xref="S4.SS2.SSS0.Px4.p1.8.m8.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS0.Px4.p1.8.m8.1.1.3" xref="S4.SS2.SSS0.Px4.p1.8.m8.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.8.m8.1b"><apply id="S4.SS2.SSS0.Px4.p1.8.m8.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.8.m8.1.1"><eq id="S4.SS2.SSS0.Px4.p1.8.m8.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.8.m8.1.1.1"></eq><ci id="S4.SS2.SSS0.Px4.p1.8.m8.1.1.2.cmml" xref="S4.SS2.SSS0.Px4.p1.8.m8.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS2.SSS0.Px4.p1.8.m8.1.1.3.cmml" xref="S4.SS2.SSS0.Px4.p1.8.m8.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.8.m8.1c">\alpha=0.5</annotation></semantics></math> for pose estimator.</p>
</div>
<div id="S4.SS2.SSS0.Px4.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px4.p2.3" class="ltx_p"><a href="#S4.T5" title="In Perceptual Loss Comparison: â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a> shows that the perceptual loss (adaptive:<math id="S4.SS2.SSS0.Px4.p2.1.m1.1" class="ltx_Math" alttext="L_{comb1}" display="inline"><semantics id="S4.SS2.SSS0.Px4.p2.1.m1.1a"><msub id="S4.SS2.SSS0.Px4.p2.1.m1.1.1" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.cmml"><mi id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.2" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.2.cmml">L</mi><mrow id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.cmml"><mi id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.2" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.3" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1a" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.4" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1b" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.5" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1c" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mn id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.6" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.6.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p2.1.m1.1b"><apply id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.2">ğ¿</ci><apply id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3"><times id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.1"></times><ci id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.2.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.3.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.4.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.4">ğ‘š</ci><ci id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.5.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.6.cmml" xref="S4.SS2.SSS0.Px4.p2.1.m1.1.1.3.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p2.1.m1.1c">L_{comb1}</annotation></semantics></math> or parameterised one:<math id="S4.SS2.SSS0.Px4.p2.2.m2.1" class="ltx_Math" alttext="L_{comb2}" display="inline"><semantics id="S4.SS2.SSS0.Px4.p2.2.m2.1a"><msub id="S4.SS2.SSS0.Px4.p2.2.m2.1.1" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.cmml"><mi id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.2" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.2.cmml">L</mi><mrow id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.cmml"><mi id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.2" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.3" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1a" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.4" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1b" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.5" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1c" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mn id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.6" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.6.cmml">2</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p2.2.m2.1b"><apply id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.2">ğ¿</ci><apply id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3"><times id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.1"></times><ci id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.2.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.2">ğ‘</ci><ci id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.3.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.3">ğ‘œ</ci><ci id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.4.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.4">ğ‘š</ci><ci id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.5.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.6.cmml" xref="S4.SS2.SSS0.Px4.p2.2.m2.1.1.3.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p2.2.m2.1c">L_{comb2}</annotation></semantics></math>) indeed helps the <span id="S4.SS2.SSS0.Px4.p2.3.2" class="ltx_text ltx_font_italic">styled</span> as well as <span id="S4.SS2.SSS0.Px4.p2.3.1" class="ltx_text ltx_font_italic">Sd<math id="S4.SS2.SSS0.Px4.p2.3.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.SSS0.Px4.p2.3.1.m1.1a"><mo stretchy="false" id="S4.SS2.SSS0.Px4.p2.3.1.m1.1.1" xref="S4.SS2.SSS0.Px4.p2.3.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p2.3.1.m1.1b"><ci id="S4.SS2.SSS0.Px4.p2.3.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p2.3.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p2.3.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span> models to improve their performance, in general. We note that perceptual loss does not hurt the <span id="S4.SS2.SSS0.Px4.p2.3.3" class="ltx_text ltx_font_italic">styled</span> model for poses, however, it does help since the <span id="S4.SS2.SSS0.Px4.p2.3.4" class="ltx_text ltx_font_italic">styled</span> model is fine-tuned on <span id="S4.SS2.SSS0.Px4.p2.3.5" class="ltx_text ltx_font_italic">CA</span>.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.29.7.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.12.6" class="ltx_text ltx_font_bold" style="font-size:90%;">Perceptual Loss Comparison<span id="S4.T5.7.1.1" class="ltx_text ltx_font_medium">: Comparing different loss combinations using the <span id="S4.T5.7.1.1.2" class="ltx_text ltx_font_italic">styled</span> or <span id="S4.T5.7.1.1.1" class="ltx_text ltx_font_italic">styled-tunedÂ (<em id="S4.T5.7.1.1.1.1" class="ltx_emph ltx_font_upright">Sd</em><math id="S4.T5.7.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T5.7.1.1.1.m1.1b"><mo stretchy="false" id="S4.T5.7.1.1.1.m1.1.1" xref="S4.T5.7.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T5.7.1.1.1.m1.1c"><ci id="S4.T5.7.1.1.1.m1.1.1.cmml" xref="S4.T5.7.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.1.1.1.m1.1d">\rightarrow</annotation></semantics></math><em id="S4.T5.7.1.1.1.2" class="ltx_emph ltx_font_upright">Td</em>)</span> model on the <em id="S4.T5.7.1.1.3" class="ltx_emph ltx_font_italic">CA</em> dataset for detection (</span>D<span id="S4.T5.12.6.7" class="ltx_text ltx_font_medium">) and pose estimation (</span>P<span id="S4.T5.10.4.4" class="ltx_text ltx_font_medium">), <span id="S4.T5.10.4.4.1" class="ltx_ERROR undefined">\ie</span>just the detector or pose loss <math id="S4.T5.8.2.2.m1.1" class="ltx_Math" alttext="L_{det}" display="inline"><semantics id="S4.T5.8.2.2.m1.1b"><msub id="S4.T5.8.2.2.m1.1.1" xref="S4.T5.8.2.2.m1.1.1.cmml"><mi id="S4.T5.8.2.2.m1.1.1.2" xref="S4.T5.8.2.2.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.8.2.2.m1.1.1.3" xref="S4.T5.8.2.2.m1.1.1.3.cmml"><mi id="S4.T5.8.2.2.m1.1.1.3.2" xref="S4.T5.8.2.2.m1.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.T5.8.2.2.m1.1.1.3.1" xref="S4.T5.8.2.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T5.8.2.2.m1.1.1.3.3" xref="S4.T5.8.2.2.m1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.T5.8.2.2.m1.1.1.3.1b" xref="S4.T5.8.2.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T5.8.2.2.m1.1.1.3.4" xref="S4.T5.8.2.2.m1.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.8.2.2.m1.1c"><apply id="S4.T5.8.2.2.m1.1.1.cmml" xref="S4.T5.8.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.8.2.2.m1.1.1.1.cmml" xref="S4.T5.8.2.2.m1.1.1">subscript</csymbol><ci id="S4.T5.8.2.2.m1.1.1.2.cmml" xref="S4.T5.8.2.2.m1.1.1.2">ğ¿</ci><apply id="S4.T5.8.2.2.m1.1.1.3.cmml" xref="S4.T5.8.2.2.m1.1.1.3"><times id="S4.T5.8.2.2.m1.1.1.3.1.cmml" xref="S4.T5.8.2.2.m1.1.1.3.1"></times><ci id="S4.T5.8.2.2.m1.1.1.3.2.cmml" xref="S4.T5.8.2.2.m1.1.1.3.2">ğ‘‘</ci><ci id="S4.T5.8.2.2.m1.1.1.3.3.cmml" xref="S4.T5.8.2.2.m1.1.1.3.3">ğ‘’</ci><ci id="S4.T5.8.2.2.m1.1.1.3.4.cmml" xref="S4.T5.8.2.2.m1.1.1.3.4">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.2.2.m1.1d">L_{det}</annotation></semantics></math>/<math id="S4.T5.9.3.3.m2.1" class="ltx_Math" alttext="L_{pose}" display="inline"><semantics id="S4.T5.9.3.3.m2.1b"><msub id="S4.T5.9.3.3.m2.1.1" xref="S4.T5.9.3.3.m2.1.1.cmml"><mi id="S4.T5.9.3.3.m2.1.1.2" xref="S4.T5.9.3.3.m2.1.1.2.cmml">L</mi><mrow id="S4.T5.9.3.3.m2.1.1.3" xref="S4.T5.9.3.3.m2.1.1.3.cmml"><mi id="S4.T5.9.3.3.m2.1.1.3.2" xref="S4.T5.9.3.3.m2.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.T5.9.3.3.m2.1.1.3.1" xref="S4.T5.9.3.3.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.T5.9.3.3.m2.1.1.3.3" xref="S4.T5.9.3.3.m2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.9.3.3.m2.1.1.3.1b" xref="S4.T5.9.3.3.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.T5.9.3.3.m2.1.1.3.4" xref="S4.T5.9.3.3.m2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.T5.9.3.3.m2.1.1.3.1c" xref="S4.T5.9.3.3.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.T5.9.3.3.m2.1.1.3.5" xref="S4.T5.9.3.3.m2.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.9.3.3.m2.1c"><apply id="S4.T5.9.3.3.m2.1.1.cmml" xref="S4.T5.9.3.3.m2.1.1"><csymbol cd="ambiguous" id="S4.T5.9.3.3.m2.1.1.1.cmml" xref="S4.T5.9.3.3.m2.1.1">subscript</csymbol><ci id="S4.T5.9.3.3.m2.1.1.2.cmml" xref="S4.T5.9.3.3.m2.1.1.2">ğ¿</ci><apply id="S4.T5.9.3.3.m2.1.1.3.cmml" xref="S4.T5.9.3.3.m2.1.1.3"><times id="S4.T5.9.3.3.m2.1.1.3.1.cmml" xref="S4.T5.9.3.3.m2.1.1.3.1"></times><ci id="S4.T5.9.3.3.m2.1.1.3.2.cmml" xref="S4.T5.9.3.3.m2.1.1.3.2">ğ‘</ci><ci id="S4.T5.9.3.3.m2.1.1.3.3.cmml" xref="S4.T5.9.3.3.m2.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.9.3.3.m2.1.1.3.4.cmml" xref="S4.T5.9.3.3.m2.1.1.3.4">ğ‘ </ci><ci id="S4.T5.9.3.3.m2.1.1.3.5.cmml" xref="S4.T5.9.3.3.m2.1.1.3.5">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.3.3.m2.1d">L_{pose}</annotation></semantics></math> or in combination with perceptual loss <math id="S4.T5.10.4.4.m3.1" class="ltx_Math" alttext="L_{comb}" display="inline"><semantics id="S4.T5.10.4.4.m3.1b"><msub id="S4.T5.10.4.4.m3.1.1" xref="S4.T5.10.4.4.m3.1.1.cmml"><mi id="S4.T5.10.4.4.m3.1.1.2" xref="S4.T5.10.4.4.m3.1.1.2.cmml">L</mi><mrow id="S4.T5.10.4.4.m3.1.1.3" xref="S4.T5.10.4.4.m3.1.1.3.cmml"><mi id="S4.T5.10.4.4.m3.1.1.3.2" xref="S4.T5.10.4.4.m3.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.10.4.4.m3.1.1.3.1" xref="S4.T5.10.4.4.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.T5.10.4.4.m3.1.1.3.3" xref="S4.T5.10.4.4.m3.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.10.4.4.m3.1.1.3.1b" xref="S4.T5.10.4.4.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.T5.10.4.4.m3.1.1.3.4" xref="S4.T5.10.4.4.m3.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.10.4.4.m3.1.1.3.1c" xref="S4.T5.10.4.4.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.T5.10.4.4.m3.1.1.3.5" xref="S4.T5.10.4.4.m3.1.1.3.5.cmml">b</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.10.4.4.m3.1c"><apply id="S4.T5.10.4.4.m3.1.1.cmml" xref="S4.T5.10.4.4.m3.1.1"><csymbol cd="ambiguous" id="S4.T5.10.4.4.m3.1.1.1.cmml" xref="S4.T5.10.4.4.m3.1.1">subscript</csymbol><ci id="S4.T5.10.4.4.m3.1.1.2.cmml" xref="S4.T5.10.4.4.m3.1.1.2">ğ¿</ci><apply id="S4.T5.10.4.4.m3.1.1.3.cmml" xref="S4.T5.10.4.4.m3.1.1.3"><times id="S4.T5.10.4.4.m3.1.1.3.1.cmml" xref="S4.T5.10.4.4.m3.1.1.3.1"></times><ci id="S4.T5.10.4.4.m3.1.1.3.2.cmml" xref="S4.T5.10.4.4.m3.1.1.3.2">ğ‘</ci><ci id="S4.T5.10.4.4.m3.1.1.3.3.cmml" xref="S4.T5.10.4.4.m3.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.10.4.4.m3.1.1.3.4.cmml" xref="S4.T5.10.4.4.m3.1.1.3.4">ğ‘š</ci><ci id="S4.T5.10.4.4.m3.1.1.3.5.cmml" xref="S4.T5.10.4.4.m3.1.1.3.5">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.10.4.4.m3.1d">L_{comb}</annotation></semantics></math> in two different variantsÂ (<a href="#S3.E1.1" title="In Eq. 1 â€£ Enforcing Perceptual Similarity â€£ 3.2 Pose Estimation Approach â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eqs.</span>Â <span class="ltx_text ltx_ref_tag">1a</span></a> andÂ <a href="#S3.E1.2" title="Eq. 1b â€£ Eq. 1 â€£ Enforcing Perceptual Similarity â€£ 3.2 Pose Estimation Approach â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1b</span></a>. For </span>D<span id="S4.T5.11.5.5" class="ltx_text ltx_font_medium">: <math id="S4.T5.11.5.5.m1.1" class="ltx_Math" alttext="\alpha=U" display="inline"><semantics id="S4.T5.11.5.5.m1.1b"><mrow id="S4.T5.11.5.5.m1.1.1" xref="S4.T5.11.5.5.m1.1.1.cmml"><mi id="S4.T5.11.5.5.m1.1.1.2" xref="S4.T5.11.5.5.m1.1.1.2.cmml">Î±</mi><mo id="S4.T5.11.5.5.m1.1.1.1" xref="S4.T5.11.5.5.m1.1.1.1.cmml">=</mo><mi id="S4.T5.11.5.5.m1.1.1.3" xref="S4.T5.11.5.5.m1.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.11.5.5.m1.1c"><apply id="S4.T5.11.5.5.m1.1.1.cmml" xref="S4.T5.11.5.5.m1.1.1"><eq id="S4.T5.11.5.5.m1.1.1.1.cmml" xref="S4.T5.11.5.5.m1.1.1.1"></eq><ci id="S4.T5.11.5.5.m1.1.1.2.cmml" xref="S4.T5.11.5.5.m1.1.1.2">ğ›¼</ci><ci id="S4.T5.11.5.5.m1.1.1.3.cmml" xref="S4.T5.11.5.5.m1.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.11.5.5.m1.1d">\alpha=U</annotation></semantics></math> and for </span>P<span id="S4.T5.12.6.6" class="ltx_text ltx_font_medium">: <math id="S4.T5.12.6.6.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.T5.12.6.6.m1.1b"><mrow id="S4.T5.12.6.6.m1.1.1" xref="S4.T5.12.6.6.m1.1.1.cmml"><mi id="S4.T5.12.6.6.m1.1.1.2" xref="S4.T5.12.6.6.m1.1.1.2.cmml">Î±</mi><mo id="S4.T5.12.6.6.m1.1.1.1" xref="S4.T5.12.6.6.m1.1.1.1.cmml">=</mo><mn id="S4.T5.12.6.6.m1.1.1.3" xref="S4.T5.12.6.6.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.12.6.6.m1.1c"><apply id="S4.T5.12.6.6.m1.1.1.cmml" xref="S4.T5.12.6.6.m1.1.1"><eq id="S4.T5.12.6.6.m1.1.1.1.cmml" xref="S4.T5.12.6.6.m1.1.1.1"></eq><ci id="S4.T5.12.6.6.m1.1.1.2.cmml" xref="S4.T5.12.6.6.m1.1.1.2">ğ›¼</ci><cn type="float" id="S4.T5.12.6.6.m1.1.1.3.cmml" xref="S4.T5.12.6.6.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.12.6.6.m1.1d">\alpha=0.5</annotation></semantics></math>. <span id="S4.T5.12.6.6.1" class="ltx_text ltx_font_italic">Style-Set</span> (<em id="S4.T5.12.6.6.2" class="ltx_emph ltx_font_italic">SS</em>) is <span id="S4.T5.12.6.6.3" class="ltx_text ltx_font_italic">CA</span> for both.</span></span></figcaption>
<table id="S4.T5.27" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.13.1" class="ltx_tr">
<th id="S4.T5.13.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T5.13.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></th>
<th id="S4.T5.13.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T5.13.1.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">mAP</span></th>
<th id="S4.T5.13.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T5.13.1.4.1" class="ltx_text ltx_font_italic" style="font-size:80%;">mAR</span></th>
<th id="S4.T5.13.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="S4.T5.13.1.1.m1.1" class="ltx_Math" alttext="L_{comb}" display="inline"><semantics id="S4.T5.13.1.1.m1.1a"><msub id="S4.T5.13.1.1.m1.1.1" xref="S4.T5.13.1.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.13.1.1.m1.1.1.2" xref="S4.T5.13.1.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.13.1.1.m1.1.1.3" xref="S4.T5.13.1.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.13.1.1.m1.1.1.3.2" xref="S4.T5.13.1.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.13.1.1.m1.1.1.3.1" xref="S4.T5.13.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.13.1.1.m1.1.1.3.3" xref="S4.T5.13.1.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.13.1.1.m1.1.1.3.1a" xref="S4.T5.13.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.13.1.1.m1.1.1.3.4" xref="S4.T5.13.1.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.13.1.1.m1.1.1.3.1b" xref="S4.T5.13.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.13.1.1.m1.1.1.3.5" xref="S4.T5.13.1.1.m1.1.1.3.5.cmml">b</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.13.1.1.m1.1b"><apply id="S4.T5.13.1.1.m1.1.1.cmml" xref="S4.T5.13.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.13.1.1.m1.1.1.1.cmml" xref="S4.T5.13.1.1.m1.1.1">subscript</csymbol><ci id="S4.T5.13.1.1.m1.1.1.2.cmml" xref="S4.T5.13.1.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.13.1.1.m1.1.1.3.cmml" xref="S4.T5.13.1.1.m1.1.1.3"><times id="S4.T5.13.1.1.m1.1.1.3.1.cmml" xref="S4.T5.13.1.1.m1.1.1.3.1"></times><ci id="S4.T5.13.1.1.m1.1.1.3.2.cmml" xref="S4.T5.13.1.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.13.1.1.m1.1.1.3.3.cmml" xref="S4.T5.13.1.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.13.1.1.m1.1.1.3.4.cmml" xref="S4.T5.13.1.1.m1.1.1.3.4">ğ‘š</ci><ci id="S4.T5.13.1.1.m1.1.1.3.5.cmml" xref="S4.T5.13.1.1.m1.1.1.3.5">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.13.1.1.m1.1c">L_{comb}</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.14.2" class="ltx_tr">
<td id="S4.T5.14.2.2" class="ltx_td ltx_border_t"></td>
<td id="S4.T5.14.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.14.2.3.1" class="ltx_text" style="font-size:80%;">6.5</span></td>
<td id="S4.T5.14.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.14.2.4.1" class="ltx_text" style="font-size:80%;">8.6</span></td>
<td id="S4.T5.14.2.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T5.14.2.1.m1.1" class="ltx_Math" alttext="L_{det}" display="inline"><semantics id="S4.T5.14.2.1.m1.1a"><msub id="S4.T5.14.2.1.m1.1.1" xref="S4.T5.14.2.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.14.2.1.m1.1.1.2" xref="S4.T5.14.2.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.14.2.1.m1.1.1.3" xref="S4.T5.14.2.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.14.2.1.m1.1.1.3.2" xref="S4.T5.14.2.1.m1.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.T5.14.2.1.m1.1.1.3.1" xref="S4.T5.14.2.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.14.2.1.m1.1.1.3.3" xref="S4.T5.14.2.1.m1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.T5.14.2.1.m1.1.1.3.1a" xref="S4.T5.14.2.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.14.2.1.m1.1.1.3.4" xref="S4.T5.14.2.1.m1.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.14.2.1.m1.1b"><apply id="S4.T5.14.2.1.m1.1.1.cmml" xref="S4.T5.14.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.14.2.1.m1.1.1.1.cmml" xref="S4.T5.14.2.1.m1.1.1">subscript</csymbol><ci id="S4.T5.14.2.1.m1.1.1.2.cmml" xref="S4.T5.14.2.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.14.2.1.m1.1.1.3.cmml" xref="S4.T5.14.2.1.m1.1.1.3"><times id="S4.T5.14.2.1.m1.1.1.3.1.cmml" xref="S4.T5.14.2.1.m1.1.1.3.1"></times><ci id="S4.T5.14.2.1.m1.1.1.3.2.cmml" xref="S4.T5.14.2.1.m1.1.1.3.2">ğ‘‘</ci><ci id="S4.T5.14.2.1.m1.1.1.3.3.cmml" xref="S4.T5.14.2.1.m1.1.1.3.3">ğ‘’</ci><ci id="S4.T5.14.2.1.m1.1.1.3.4.cmml" xref="S4.T5.14.2.1.m1.1.1.3.4">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.14.2.1.m1.1c">L_{det}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.15.3" class="ltx_tr">
<td id="S4.T5.15.3.2" class="ltx_td"></td>
<td id="S4.T5.15.3.3" class="ltx_td ltx_align_center"><span id="S4.T5.15.3.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">11.2</span></td>
<td id="S4.T5.15.3.4" class="ltx_td ltx_align_center"><span id="S4.T5.15.3.4.1" class="ltx_text" style="font-size:80%;">11.0</span></td>
<td id="S4.T5.15.3.1" class="ltx_td ltx_align_center"><math id="S4.T5.15.3.1.m1.1" class="ltx_Math" alttext="L_{comb1}" display="inline"><semantics id="S4.T5.15.3.1.m1.1a"><msub id="S4.T5.15.3.1.m1.1.1" xref="S4.T5.15.3.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.15.3.1.m1.1.1.2" xref="S4.T5.15.3.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.15.3.1.m1.1.1.3" xref="S4.T5.15.3.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.15.3.1.m1.1.1.3.2" xref="S4.T5.15.3.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.15.3.1.m1.1.1.3.1" xref="S4.T5.15.3.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.15.3.1.m1.1.1.3.3" xref="S4.T5.15.3.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.15.3.1.m1.1.1.3.1a" xref="S4.T5.15.3.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.15.3.1.m1.1.1.3.4" xref="S4.T5.15.3.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.15.3.1.m1.1.1.3.1b" xref="S4.T5.15.3.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.15.3.1.m1.1.1.3.5" xref="S4.T5.15.3.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.T5.15.3.1.m1.1.1.3.1c" xref="S4.T5.15.3.1.m1.1.1.3.1.cmml">â€‹</mo><mn mathsize="80%" id="S4.T5.15.3.1.m1.1.1.3.6" xref="S4.T5.15.3.1.m1.1.1.3.6.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.15.3.1.m1.1b"><apply id="S4.T5.15.3.1.m1.1.1.cmml" xref="S4.T5.15.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.15.3.1.m1.1.1.1.cmml" xref="S4.T5.15.3.1.m1.1.1">subscript</csymbol><ci id="S4.T5.15.3.1.m1.1.1.2.cmml" xref="S4.T5.15.3.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.15.3.1.m1.1.1.3.cmml" xref="S4.T5.15.3.1.m1.1.1.3"><times id="S4.T5.15.3.1.m1.1.1.3.1.cmml" xref="S4.T5.15.3.1.m1.1.1.3.1"></times><ci id="S4.T5.15.3.1.m1.1.1.3.2.cmml" xref="S4.T5.15.3.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.15.3.1.m1.1.1.3.3.cmml" xref="S4.T5.15.3.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.15.3.1.m1.1.1.3.4.cmml" xref="S4.T5.15.3.1.m1.1.1.3.4">ğ‘š</ci><ci id="S4.T5.15.3.1.m1.1.1.3.5.cmml" xref="S4.T5.15.3.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.T5.15.3.1.m1.1.1.3.6.cmml" xref="S4.T5.15.3.1.m1.1.1.3.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.15.3.1.m1.1c">L_{comb1}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.16.4" class="ltx_tr">
<td id="S4.T5.16.4.2" class="ltx_td ltx_align_left" style="background-color:#CCCCCC;"><span id="S4.T5.16.4.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;background-color:#CCCCCC;">(D)Â Styled</span></td>
<td id="S4.T5.16.4.3" class="ltx_td ltx_align_center"><span id="S4.T5.16.4.3.1" class="ltx_text" style="font-size:80%;">9.8</span></td>
<td id="S4.T5.16.4.4" class="ltx_td ltx_align_center"><span id="S4.T5.16.4.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">11.2</span></td>
<td id="S4.T5.16.4.1" class="ltx_td ltx_align_center"><math id="S4.T5.16.4.1.m1.1" class="ltx_Math" alttext="L_{comb2}" display="inline"><semantics id="S4.T5.16.4.1.m1.1a"><msub id="S4.T5.16.4.1.m1.1.1" xref="S4.T5.16.4.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.16.4.1.m1.1.1.2" xref="S4.T5.16.4.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.16.4.1.m1.1.1.3" xref="S4.T5.16.4.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.16.4.1.m1.1.1.3.2" xref="S4.T5.16.4.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.16.4.1.m1.1.1.3.1" xref="S4.T5.16.4.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.16.4.1.m1.1.1.3.3" xref="S4.T5.16.4.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.16.4.1.m1.1.1.3.1a" xref="S4.T5.16.4.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.16.4.1.m1.1.1.3.4" xref="S4.T5.16.4.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.16.4.1.m1.1.1.3.1b" xref="S4.T5.16.4.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.16.4.1.m1.1.1.3.5" xref="S4.T5.16.4.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.T5.16.4.1.m1.1.1.3.1c" xref="S4.T5.16.4.1.m1.1.1.3.1.cmml">â€‹</mo><mn mathsize="80%" id="S4.T5.16.4.1.m1.1.1.3.6" xref="S4.T5.16.4.1.m1.1.1.3.6.cmml">2</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.16.4.1.m1.1b"><apply id="S4.T5.16.4.1.m1.1.1.cmml" xref="S4.T5.16.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.16.4.1.m1.1.1.1.cmml" xref="S4.T5.16.4.1.m1.1.1">subscript</csymbol><ci id="S4.T5.16.4.1.m1.1.1.2.cmml" xref="S4.T5.16.4.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.16.4.1.m1.1.1.3.cmml" xref="S4.T5.16.4.1.m1.1.1.3"><times id="S4.T5.16.4.1.m1.1.1.3.1.cmml" xref="S4.T5.16.4.1.m1.1.1.3.1"></times><ci id="S4.T5.16.4.1.m1.1.1.3.2.cmml" xref="S4.T5.16.4.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.16.4.1.m1.1.1.3.3.cmml" xref="S4.T5.16.4.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.16.4.1.m1.1.1.3.4.cmml" xref="S4.T5.16.4.1.m1.1.1.3.4">ğ‘š</ci><ci id="S4.T5.16.4.1.m1.1.1.3.5.cmml" xref="S4.T5.16.4.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.T5.16.4.1.m1.1.1.3.6.cmml" xref="S4.T5.16.4.1.m1.1.1.3.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.16.4.1.m1.1c">L_{comb2}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.17.5" class="ltx_tr">
<td id="S4.T5.17.5.2" class="ltx_td"></td>
<td id="S4.T5.17.5.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.17.5.3.1" class="ltx_text" style="font-size:80%;">43.9</span></td>
<td id="S4.T5.17.5.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.17.5.4.1" class="ltx_text" style="font-size:80%;">32.9</span></td>
<td id="S4.T5.17.5.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T5.17.5.1.m1.1" class="ltx_Math" alttext="L_{det}" display="inline"><semantics id="S4.T5.17.5.1.m1.1a"><msub id="S4.T5.17.5.1.m1.1.1" xref="S4.T5.17.5.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.17.5.1.m1.1.1.2" xref="S4.T5.17.5.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.17.5.1.m1.1.1.3" xref="S4.T5.17.5.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.17.5.1.m1.1.1.3.2" xref="S4.T5.17.5.1.m1.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.T5.17.5.1.m1.1.1.3.1" xref="S4.T5.17.5.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.17.5.1.m1.1.1.3.3" xref="S4.T5.17.5.1.m1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.T5.17.5.1.m1.1.1.3.1a" xref="S4.T5.17.5.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.17.5.1.m1.1.1.3.4" xref="S4.T5.17.5.1.m1.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.17.5.1.m1.1b"><apply id="S4.T5.17.5.1.m1.1.1.cmml" xref="S4.T5.17.5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.17.5.1.m1.1.1.1.cmml" xref="S4.T5.17.5.1.m1.1.1">subscript</csymbol><ci id="S4.T5.17.5.1.m1.1.1.2.cmml" xref="S4.T5.17.5.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.17.5.1.m1.1.1.3.cmml" xref="S4.T5.17.5.1.m1.1.1.3"><times id="S4.T5.17.5.1.m1.1.1.3.1.cmml" xref="S4.T5.17.5.1.m1.1.1.3.1"></times><ci id="S4.T5.17.5.1.m1.1.1.3.2.cmml" xref="S4.T5.17.5.1.m1.1.1.3.2">ğ‘‘</ci><ci id="S4.T5.17.5.1.m1.1.1.3.3.cmml" xref="S4.T5.17.5.1.m1.1.1.3.3">ğ‘’</ci><ci id="S4.T5.17.5.1.m1.1.1.3.4.cmml" xref="S4.T5.17.5.1.m1.1.1.3.4">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.17.5.1.m1.1c">L_{det}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.18.6" class="ltx_tr">
<td id="S4.T5.18.6.2" class="ltx_td"></td>
<td id="S4.T5.18.6.3" class="ltx_td ltx_align_center"><span id="S4.T5.18.6.3.1" class="ltx_text" style="font-size:80%;">45.4</span></td>
<td id="S4.T5.18.6.4" class="ltx_td ltx_align_center"><span id="S4.T5.18.6.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">34.7</span></td>
<td id="S4.T5.18.6.1" class="ltx_td ltx_align_center"><math id="S4.T5.18.6.1.m1.1" class="ltx_Math" alttext="L_{comb1}" display="inline"><semantics id="S4.T5.18.6.1.m1.1a"><msub id="S4.T5.18.6.1.m1.1.1" xref="S4.T5.18.6.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.18.6.1.m1.1.1.2" xref="S4.T5.18.6.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.18.6.1.m1.1.1.3" xref="S4.T5.18.6.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.18.6.1.m1.1.1.3.2" xref="S4.T5.18.6.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.18.6.1.m1.1.1.3.1" xref="S4.T5.18.6.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.18.6.1.m1.1.1.3.3" xref="S4.T5.18.6.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.18.6.1.m1.1.1.3.1a" xref="S4.T5.18.6.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.18.6.1.m1.1.1.3.4" xref="S4.T5.18.6.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.18.6.1.m1.1.1.3.1b" xref="S4.T5.18.6.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.18.6.1.m1.1.1.3.5" xref="S4.T5.18.6.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.T5.18.6.1.m1.1.1.3.1c" xref="S4.T5.18.6.1.m1.1.1.3.1.cmml">â€‹</mo><mn mathsize="80%" id="S4.T5.18.6.1.m1.1.1.3.6" xref="S4.T5.18.6.1.m1.1.1.3.6.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.18.6.1.m1.1b"><apply id="S4.T5.18.6.1.m1.1.1.cmml" xref="S4.T5.18.6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.18.6.1.m1.1.1.1.cmml" xref="S4.T5.18.6.1.m1.1.1">subscript</csymbol><ci id="S4.T5.18.6.1.m1.1.1.2.cmml" xref="S4.T5.18.6.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.18.6.1.m1.1.1.3.cmml" xref="S4.T5.18.6.1.m1.1.1.3"><times id="S4.T5.18.6.1.m1.1.1.3.1.cmml" xref="S4.T5.18.6.1.m1.1.1.3.1"></times><ci id="S4.T5.18.6.1.m1.1.1.3.2.cmml" xref="S4.T5.18.6.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.18.6.1.m1.1.1.3.3.cmml" xref="S4.T5.18.6.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.18.6.1.m1.1.1.3.4.cmml" xref="S4.T5.18.6.1.m1.1.1.3.4">ğ‘š</ci><ci id="S4.T5.18.6.1.m1.1.1.3.5.cmml" xref="S4.T5.18.6.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.T5.18.6.1.m1.1.1.3.6.cmml" xref="S4.T5.18.6.1.m1.1.1.3.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.18.6.1.m1.1c">L_{comb1}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.20.8" class="ltx_tr">
<td id="S4.T5.19.7.1" class="ltx_td ltx_align_left" style="background-color:#CCCCCC;"><span id="S4.T5.19.7.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;background-color:#CCCCCC;">(D)Â Sd<math id="S4.T5.19.7.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T5.19.7.1.1.1.m1.1a"><mo mathbackground="#CCCCCC" stretchy="false" id="S4.T5.19.7.1.1.1.m1.1.1" xref="S4.T5.19.7.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T5.19.7.1.1.1.m1.1b"><ci id="S4.T5.19.7.1.1.1.m1.1.1.cmml" xref="S4.T5.19.7.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.19.7.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span></td>
<td id="S4.T5.20.8.3" class="ltx_td ltx_align_center"><span id="S4.T5.20.8.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">45.7</span></td>
<td id="S4.T5.20.8.4" class="ltx_td ltx_align_center"><span id="S4.T5.20.8.4.1" class="ltx_text" style="font-size:80%;">34.0</span></td>
<td id="S4.T5.20.8.2" class="ltx_td ltx_align_center"><math id="S4.T5.20.8.2.m1.1" class="ltx_Math" alttext="L_{comb2}" display="inline"><semantics id="S4.T5.20.8.2.m1.1a"><msub id="S4.T5.20.8.2.m1.1.1" xref="S4.T5.20.8.2.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.20.8.2.m1.1.1.2" xref="S4.T5.20.8.2.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.20.8.2.m1.1.1.3" xref="S4.T5.20.8.2.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.20.8.2.m1.1.1.3.2" xref="S4.T5.20.8.2.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.20.8.2.m1.1.1.3.1" xref="S4.T5.20.8.2.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.20.8.2.m1.1.1.3.3" xref="S4.T5.20.8.2.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.20.8.2.m1.1.1.3.1a" xref="S4.T5.20.8.2.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.20.8.2.m1.1.1.3.4" xref="S4.T5.20.8.2.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.20.8.2.m1.1.1.3.1b" xref="S4.T5.20.8.2.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.20.8.2.m1.1.1.3.5" xref="S4.T5.20.8.2.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.T5.20.8.2.m1.1.1.3.1c" xref="S4.T5.20.8.2.m1.1.1.3.1.cmml">â€‹</mo><mn mathsize="80%" id="S4.T5.20.8.2.m1.1.1.3.6" xref="S4.T5.20.8.2.m1.1.1.3.6.cmml">2</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.20.8.2.m1.1b"><apply id="S4.T5.20.8.2.m1.1.1.cmml" xref="S4.T5.20.8.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.20.8.2.m1.1.1.1.cmml" xref="S4.T5.20.8.2.m1.1.1">subscript</csymbol><ci id="S4.T5.20.8.2.m1.1.1.2.cmml" xref="S4.T5.20.8.2.m1.1.1.2">ğ¿</ci><apply id="S4.T5.20.8.2.m1.1.1.3.cmml" xref="S4.T5.20.8.2.m1.1.1.3"><times id="S4.T5.20.8.2.m1.1.1.3.1.cmml" xref="S4.T5.20.8.2.m1.1.1.3.1"></times><ci id="S4.T5.20.8.2.m1.1.1.3.2.cmml" xref="S4.T5.20.8.2.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.20.8.2.m1.1.1.3.3.cmml" xref="S4.T5.20.8.2.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.20.8.2.m1.1.1.3.4.cmml" xref="S4.T5.20.8.2.m1.1.1.3.4">ğ‘š</ci><ci id="S4.T5.20.8.2.m1.1.1.3.5.cmml" xref="S4.T5.20.8.2.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.T5.20.8.2.m1.1.1.3.6.cmml" xref="S4.T5.20.8.2.m1.1.1.3.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.20.8.2.m1.1c">L_{comb2}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.21.9" class="ltx_tr">
<td id="S4.T5.21.9.2" class="ltx_td ltx_border_t"></td>
<td id="S4.T5.21.9.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.21.9.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">30.6</span></td>
<td id="S4.T5.21.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.21.9.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">36.9</span></td>
<td id="S4.T5.21.9.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T5.21.9.1.m1.1" class="ltx_Math" alttext="L_{pose}" display="inline"><semantics id="S4.T5.21.9.1.m1.1a"><msub id="S4.T5.21.9.1.m1.1.1" xref="S4.T5.21.9.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.21.9.1.m1.1.1.2" xref="S4.T5.21.9.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.21.9.1.m1.1.1.3" xref="S4.T5.21.9.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.21.9.1.m1.1.1.3.2" xref="S4.T5.21.9.1.m1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.T5.21.9.1.m1.1.1.3.1" xref="S4.T5.21.9.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.21.9.1.m1.1.1.3.3" xref="S4.T5.21.9.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.21.9.1.m1.1.1.3.1a" xref="S4.T5.21.9.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.21.9.1.m1.1.1.3.4" xref="S4.T5.21.9.1.m1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.T5.21.9.1.m1.1.1.3.1b" xref="S4.T5.21.9.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.21.9.1.m1.1.1.3.5" xref="S4.T5.21.9.1.m1.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.21.9.1.m1.1b"><apply id="S4.T5.21.9.1.m1.1.1.cmml" xref="S4.T5.21.9.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.21.9.1.m1.1.1.1.cmml" xref="S4.T5.21.9.1.m1.1.1">subscript</csymbol><ci id="S4.T5.21.9.1.m1.1.1.2.cmml" xref="S4.T5.21.9.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.21.9.1.m1.1.1.3.cmml" xref="S4.T5.21.9.1.m1.1.1.3"><times id="S4.T5.21.9.1.m1.1.1.3.1.cmml" xref="S4.T5.21.9.1.m1.1.1.3.1"></times><ci id="S4.T5.21.9.1.m1.1.1.3.2.cmml" xref="S4.T5.21.9.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.21.9.1.m1.1.1.3.3.cmml" xref="S4.T5.21.9.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.21.9.1.m1.1.1.3.4.cmml" xref="S4.T5.21.9.1.m1.1.1.3.4">ğ‘ </ci><ci id="S4.T5.21.9.1.m1.1.1.3.5.cmml" xref="S4.T5.21.9.1.m1.1.1.3.5">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.21.9.1.m1.1c">L_{pose}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.22.10" class="ltx_tr">
<td id="S4.T5.22.10.2" class="ltx_td"></td>
<td id="S4.T5.22.10.3" class="ltx_td ltx_align_center"><span id="S4.T5.22.10.3.1" class="ltx_text" style="font-size:80%;">30.5</span></td>
<td id="S4.T5.22.10.4" class="ltx_td ltx_align_center"><span id="S4.T5.22.10.4.1" class="ltx_text" style="font-size:80%;">36.5</span></td>
<td id="S4.T5.22.10.1" class="ltx_td ltx_align_center"><math id="S4.T5.22.10.1.m1.1" class="ltx_Math" alttext="L_{comb1}" display="inline"><semantics id="S4.T5.22.10.1.m1.1a"><msub id="S4.T5.22.10.1.m1.1.1" xref="S4.T5.22.10.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.22.10.1.m1.1.1.2" xref="S4.T5.22.10.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.22.10.1.m1.1.1.3" xref="S4.T5.22.10.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.22.10.1.m1.1.1.3.2" xref="S4.T5.22.10.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.22.10.1.m1.1.1.3.1" xref="S4.T5.22.10.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.22.10.1.m1.1.1.3.3" xref="S4.T5.22.10.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.22.10.1.m1.1.1.3.1a" xref="S4.T5.22.10.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.22.10.1.m1.1.1.3.4" xref="S4.T5.22.10.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.22.10.1.m1.1.1.3.1b" xref="S4.T5.22.10.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.22.10.1.m1.1.1.3.5" xref="S4.T5.22.10.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.T5.22.10.1.m1.1.1.3.1c" xref="S4.T5.22.10.1.m1.1.1.3.1.cmml">â€‹</mo><mn mathsize="80%" id="S4.T5.22.10.1.m1.1.1.3.6" xref="S4.T5.22.10.1.m1.1.1.3.6.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.22.10.1.m1.1b"><apply id="S4.T5.22.10.1.m1.1.1.cmml" xref="S4.T5.22.10.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.22.10.1.m1.1.1.1.cmml" xref="S4.T5.22.10.1.m1.1.1">subscript</csymbol><ci id="S4.T5.22.10.1.m1.1.1.2.cmml" xref="S4.T5.22.10.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.22.10.1.m1.1.1.3.cmml" xref="S4.T5.22.10.1.m1.1.1.3"><times id="S4.T5.22.10.1.m1.1.1.3.1.cmml" xref="S4.T5.22.10.1.m1.1.1.3.1"></times><ci id="S4.T5.22.10.1.m1.1.1.3.2.cmml" xref="S4.T5.22.10.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.22.10.1.m1.1.1.3.3.cmml" xref="S4.T5.22.10.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.22.10.1.m1.1.1.3.4.cmml" xref="S4.T5.22.10.1.m1.1.1.3.4">ğ‘š</ci><ci id="S4.T5.22.10.1.m1.1.1.3.5.cmml" xref="S4.T5.22.10.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.T5.22.10.1.m1.1.1.3.6.cmml" xref="S4.T5.22.10.1.m1.1.1.3.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.22.10.1.m1.1c">L_{comb1}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.23.11" class="ltx_tr">
<td id="S4.T5.23.11.2" class="ltx_td ltx_align_left"><span id="S4.T5.23.11.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(P)Â Styled</span></td>
<td id="S4.T5.23.11.3" class="ltx_td ltx_align_center"><span id="S4.T5.23.11.3.1" class="ltx_text" style="font-size:80%;">30.5</span></td>
<td id="S4.T5.23.11.4" class="ltx_td ltx_align_center"><span id="S4.T5.23.11.4.1" class="ltx_text" style="font-size:80%;">36.5</span></td>
<td id="S4.T5.23.11.1" class="ltx_td ltx_align_center"><math id="S4.T5.23.11.1.m1.1" class="ltx_Math" alttext="L_{comb2}" display="inline"><semantics id="S4.T5.23.11.1.m1.1a"><msub id="S4.T5.23.11.1.m1.1.1" xref="S4.T5.23.11.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.23.11.1.m1.1.1.2" xref="S4.T5.23.11.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.23.11.1.m1.1.1.3" xref="S4.T5.23.11.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.23.11.1.m1.1.1.3.2" xref="S4.T5.23.11.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.23.11.1.m1.1.1.3.1" xref="S4.T5.23.11.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.23.11.1.m1.1.1.3.3" xref="S4.T5.23.11.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.23.11.1.m1.1.1.3.1a" xref="S4.T5.23.11.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.23.11.1.m1.1.1.3.4" xref="S4.T5.23.11.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.23.11.1.m1.1.1.3.1b" xref="S4.T5.23.11.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.23.11.1.m1.1.1.3.5" xref="S4.T5.23.11.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.T5.23.11.1.m1.1.1.3.1c" xref="S4.T5.23.11.1.m1.1.1.3.1.cmml">â€‹</mo><mn mathsize="80%" id="S4.T5.23.11.1.m1.1.1.3.6" xref="S4.T5.23.11.1.m1.1.1.3.6.cmml">2</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.23.11.1.m1.1b"><apply id="S4.T5.23.11.1.m1.1.1.cmml" xref="S4.T5.23.11.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.23.11.1.m1.1.1.1.cmml" xref="S4.T5.23.11.1.m1.1.1">subscript</csymbol><ci id="S4.T5.23.11.1.m1.1.1.2.cmml" xref="S4.T5.23.11.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.23.11.1.m1.1.1.3.cmml" xref="S4.T5.23.11.1.m1.1.1.3"><times id="S4.T5.23.11.1.m1.1.1.3.1.cmml" xref="S4.T5.23.11.1.m1.1.1.3.1"></times><ci id="S4.T5.23.11.1.m1.1.1.3.2.cmml" xref="S4.T5.23.11.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.23.11.1.m1.1.1.3.3.cmml" xref="S4.T5.23.11.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.23.11.1.m1.1.1.3.4.cmml" xref="S4.T5.23.11.1.m1.1.1.3.4">ğ‘š</ci><ci id="S4.T5.23.11.1.m1.1.1.3.5.cmml" xref="S4.T5.23.11.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.T5.23.11.1.m1.1.1.3.6.cmml" xref="S4.T5.23.11.1.m1.1.1.3.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.23.11.1.m1.1c">L_{comb2}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.24.12" class="ltx_tr">
<td id="S4.T5.24.12.2" class="ltx_td"></td>
<td id="S4.T5.24.12.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.24.12.3.1" class="ltx_text" style="font-size:80%;">66.6</span></td>
<td id="S4.T5.24.12.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.24.12.4.1" class="ltx_text" style="font-size:80%;">73.1</span></td>
<td id="S4.T5.24.12.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T5.24.12.1.m1.1" class="ltx_Math" alttext="L_{pose}" display="inline"><semantics id="S4.T5.24.12.1.m1.1a"><msub id="S4.T5.24.12.1.m1.1.1" xref="S4.T5.24.12.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.24.12.1.m1.1.1.2" xref="S4.T5.24.12.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.24.12.1.m1.1.1.3" xref="S4.T5.24.12.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.24.12.1.m1.1.1.3.2" xref="S4.T5.24.12.1.m1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.T5.24.12.1.m1.1.1.3.1" xref="S4.T5.24.12.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.24.12.1.m1.1.1.3.3" xref="S4.T5.24.12.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.24.12.1.m1.1.1.3.1a" xref="S4.T5.24.12.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.24.12.1.m1.1.1.3.4" xref="S4.T5.24.12.1.m1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.T5.24.12.1.m1.1.1.3.1b" xref="S4.T5.24.12.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.24.12.1.m1.1.1.3.5" xref="S4.T5.24.12.1.m1.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.24.12.1.m1.1b"><apply id="S4.T5.24.12.1.m1.1.1.cmml" xref="S4.T5.24.12.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.24.12.1.m1.1.1.1.cmml" xref="S4.T5.24.12.1.m1.1.1">subscript</csymbol><ci id="S4.T5.24.12.1.m1.1.1.2.cmml" xref="S4.T5.24.12.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.24.12.1.m1.1.1.3.cmml" xref="S4.T5.24.12.1.m1.1.1.3"><times id="S4.T5.24.12.1.m1.1.1.3.1.cmml" xref="S4.T5.24.12.1.m1.1.1.3.1"></times><ci id="S4.T5.24.12.1.m1.1.1.3.2.cmml" xref="S4.T5.24.12.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.24.12.1.m1.1.1.3.3.cmml" xref="S4.T5.24.12.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.24.12.1.m1.1.1.3.4.cmml" xref="S4.T5.24.12.1.m1.1.1.3.4">ğ‘ </ci><ci id="S4.T5.24.12.1.m1.1.1.3.5.cmml" xref="S4.T5.24.12.1.m1.1.1.3.5">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.24.12.1.m1.1c">L_{pose}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.25.13" class="ltx_tr">
<td id="S4.T5.25.13.2" class="ltx_td"></td>
<td id="S4.T5.25.13.3" class="ltx_td ltx_align_center"><span id="S4.T5.25.13.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">67.2</span></td>
<td id="S4.T5.25.13.4" class="ltx_td ltx_align_center"><span id="S4.T5.25.13.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">73.6</span></td>
<td id="S4.T5.25.13.1" class="ltx_td ltx_align_center"><math id="S4.T5.25.13.1.m1.1" class="ltx_Math" alttext="L_{comb1}" display="inline"><semantics id="S4.T5.25.13.1.m1.1a"><msub id="S4.T5.25.13.1.m1.1.1" xref="S4.T5.25.13.1.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.25.13.1.m1.1.1.2" xref="S4.T5.25.13.1.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.25.13.1.m1.1.1.3" xref="S4.T5.25.13.1.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.25.13.1.m1.1.1.3.2" xref="S4.T5.25.13.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.25.13.1.m1.1.1.3.1" xref="S4.T5.25.13.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.25.13.1.m1.1.1.3.3" xref="S4.T5.25.13.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.25.13.1.m1.1.1.3.1a" xref="S4.T5.25.13.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.25.13.1.m1.1.1.3.4" xref="S4.T5.25.13.1.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.25.13.1.m1.1.1.3.1b" xref="S4.T5.25.13.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.25.13.1.m1.1.1.3.5" xref="S4.T5.25.13.1.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.T5.25.13.1.m1.1.1.3.1c" xref="S4.T5.25.13.1.m1.1.1.3.1.cmml">â€‹</mo><mn mathsize="80%" id="S4.T5.25.13.1.m1.1.1.3.6" xref="S4.T5.25.13.1.m1.1.1.3.6.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.25.13.1.m1.1b"><apply id="S4.T5.25.13.1.m1.1.1.cmml" xref="S4.T5.25.13.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.25.13.1.m1.1.1.1.cmml" xref="S4.T5.25.13.1.m1.1.1">subscript</csymbol><ci id="S4.T5.25.13.1.m1.1.1.2.cmml" xref="S4.T5.25.13.1.m1.1.1.2">ğ¿</ci><apply id="S4.T5.25.13.1.m1.1.1.3.cmml" xref="S4.T5.25.13.1.m1.1.1.3"><times id="S4.T5.25.13.1.m1.1.1.3.1.cmml" xref="S4.T5.25.13.1.m1.1.1.3.1"></times><ci id="S4.T5.25.13.1.m1.1.1.3.2.cmml" xref="S4.T5.25.13.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.25.13.1.m1.1.1.3.3.cmml" xref="S4.T5.25.13.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.25.13.1.m1.1.1.3.4.cmml" xref="S4.T5.25.13.1.m1.1.1.3.4">ğ‘š</ci><ci id="S4.T5.25.13.1.m1.1.1.3.5.cmml" xref="S4.T5.25.13.1.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.T5.25.13.1.m1.1.1.3.6.cmml" xref="S4.T5.25.13.1.m1.1.1.3.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.25.13.1.m1.1c">L_{comb1}</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.27.15" class="ltx_tr">
<td id="S4.T5.26.14.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T5.26.14.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(P)Â Sd<math id="S4.T5.26.14.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T5.26.14.1.1.1.m1.1a"><mo stretchy="false" id="S4.T5.26.14.1.1.1.m1.1.1" xref="S4.T5.26.14.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T5.26.14.1.1.1.m1.1b"><ci id="S4.T5.26.14.1.1.1.m1.1.1.cmml" xref="S4.T5.26.14.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.26.14.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span></td>
<td id="S4.T5.27.15.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T5.27.15.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">67.2</span></td>
<td id="S4.T5.27.15.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T5.27.15.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">73.6</span></td>
<td id="S4.T5.27.15.2" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T5.27.15.2.m1.1" class="ltx_Math" alttext="L_{comb2}" display="inline"><semantics id="S4.T5.27.15.2.m1.1a"><msub id="S4.T5.27.15.2.m1.1.1" xref="S4.T5.27.15.2.m1.1.1.cmml"><mi mathsize="80%" id="S4.T5.27.15.2.m1.1.1.2" xref="S4.T5.27.15.2.m1.1.1.2.cmml">L</mi><mrow id="S4.T5.27.15.2.m1.1.1.3" xref="S4.T5.27.15.2.m1.1.1.3.cmml"><mi mathsize="80%" id="S4.T5.27.15.2.m1.1.1.3.2" xref="S4.T5.27.15.2.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T5.27.15.2.m1.1.1.3.1" xref="S4.T5.27.15.2.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.27.15.2.m1.1.1.3.3" xref="S4.T5.27.15.2.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.27.15.2.m1.1.1.3.1a" xref="S4.T5.27.15.2.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.27.15.2.m1.1.1.3.4" xref="S4.T5.27.15.2.m1.1.1.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.27.15.2.m1.1.1.3.1b" xref="S4.T5.27.15.2.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="80%" id="S4.T5.27.15.2.m1.1.1.3.5" xref="S4.T5.27.15.2.m1.1.1.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.T5.27.15.2.m1.1.1.3.1c" xref="S4.T5.27.15.2.m1.1.1.3.1.cmml">â€‹</mo><mn mathsize="80%" id="S4.T5.27.15.2.m1.1.1.3.6" xref="S4.T5.27.15.2.m1.1.1.3.6.cmml">2</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.27.15.2.m1.1b"><apply id="S4.T5.27.15.2.m1.1.1.cmml" xref="S4.T5.27.15.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.27.15.2.m1.1.1.1.cmml" xref="S4.T5.27.15.2.m1.1.1">subscript</csymbol><ci id="S4.T5.27.15.2.m1.1.1.2.cmml" xref="S4.T5.27.15.2.m1.1.1.2">ğ¿</ci><apply id="S4.T5.27.15.2.m1.1.1.3.cmml" xref="S4.T5.27.15.2.m1.1.1.3"><times id="S4.T5.27.15.2.m1.1.1.3.1.cmml" xref="S4.T5.27.15.2.m1.1.1.3.1"></times><ci id="S4.T5.27.15.2.m1.1.1.3.2.cmml" xref="S4.T5.27.15.2.m1.1.1.3.2">ğ‘</ci><ci id="S4.T5.27.15.2.m1.1.1.3.3.cmml" xref="S4.T5.27.15.2.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T5.27.15.2.m1.1.1.3.4.cmml" xref="S4.T5.27.15.2.m1.1.1.3.4">ğ‘š</ci><ci id="S4.T5.27.15.2.m1.1.1.3.5.cmml" xref="S4.T5.27.15.2.m1.1.1.3.5">ğ‘</ci><cn type="integer" id="S4.T5.27.15.2.m1.1.1.3.6.cmml" xref="S4.T5.27.15.2.m1.1.1.3.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.27.15.2.m1.1c">L_{comb2}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Qualitative Pose Estimation Results</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p"><a href="#S4.T3" title="In Tuned vs. Styled-Tuned models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tabs.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> andÂ <a href="#S4.T5" title="Tab. 5 â€£ Perceptual Loss Comparison: â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> show that <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">styled-tuned</span> models are consistently giving a better performance than any other method. We visualise the predictions of these models for comparison of their performances. <a href="#S4.F6" title="In 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">6</span></a> shows four characters (<span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">wrestler</span>, <span id="S4.SS3.p1.1.3" class="ltx_text ltx_font_italic">fleeing</span>, <span id="S4.SS3.p1.1.4" class="ltx_text ltx_font_italic">persecutor</span>, <span id="S4.SS3.p1.1.5" class="ltx_text ltx_font_italic">bride</span>) and their pose predictions from each of our 5 proposed models.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">As shown in <a href="#S4.F6.sf1" title="In Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">6(a)</span></a>, the <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">baseline</span> model is the poorest in pose predictions. It is not able to detect majority of keypoints, confuses between the limbs if multiple characters are present and incorrectly predicts the keypoint locations.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_italic">Styled</span> model is generally much better (<a href="#S4.F6.sf2" title="In Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">6(b)</span></a>) than the baseline model (also <a href="#S4.T2" title="In Baseline vs Styled models â€£ 4.2 Experiments â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>). It is able to predict more keypoints and does not get confused if multiple characters are present. However, it is not able to predict all the visible keypoints and sometimes (<a href="#S4.F6.sf2" title="In Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">6(b)</span></a>, <span id="S4.SS3.p3.1.2" class="ltx_text ltx_font_italic">last row</span>) gives worse performance than even a <span id="S4.SS3.p3.1.3" class="ltx_text ltx_font_italic">baseline</span> model.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.5" class="ltx_p"><span id="S4.SS3.p4.5.6" class="ltx_text ltx_font_italic">Tuned</span>, <span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_italic">styled-tunedÂ (Sd<math id="S4.SS3.p4.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS3.p4.1.1.m1.1a"><mo stretchy="false" id="S4.SS3.p4.1.1.m1.1.1" xref="S4.SS3.p4.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.1.m1.1b"><ci id="S4.SS3.p4.1.1.m1.1.1.cmml" xref="S4.SS3.p4.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td)</span> and <span id="S4.SS3.p4.5.7" class="ltx_text ltx_font_italic">styled-tuned</span> with perceptual loss (<span id="S4.SS3.p4.3.3" class="ltx_text ltx_font_italic">Sd<math id="S4.SS3.p4.2.2.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS3.p4.2.2.m1.1a"><mo stretchy="false" id="S4.SS3.p4.2.2.m1.1.1" xref="S4.SS3.p4.2.2.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.2.m1.1b"><ci id="S4.SS3.p4.2.2.m1.1.1.cmml" xref="S4.SS3.p4.2.2.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.2.m1.1c">\rightarrow</annotation></semantics></math>Td<sub id="S4.SS3.p4.3.3.1" class="ltx_sub">p</sub></span>) models are overall quite superior to <span id="S4.SS3.p4.5.8" class="ltx_text ltx_font_italic">baseline</span> and <span id="S4.SS3.p4.5.9" class="ltx_text ltx_font_italic">styled</span> models. They are able to predict almost all of the visible keypoints, do not confuse between multiple characters and are quite precise with the keypoint locations. However, there are subtle differences that make <span id="S4.SS3.p4.4.4" class="ltx_text ltx_font_italic">Sd<math id="S4.SS3.p4.4.4.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS3.p4.4.4.m1.1a"><mo stretchy="false" id="S4.SS3.p4.4.4.m1.1.1" xref="S4.SS3.p4.4.4.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.4.4.m1.1b"><ci id="S4.SS3.p4.4.4.m1.1.1.cmml" xref="S4.SS3.p4.4.4.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.4.4.m1.1c">\rightarrow</annotation></semantics></math>Td</span> models better. They are able to predict all the visible keypoints as shown in <a href="#S4.F6.sf4" title="In Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">6(d)</span></a> and <a href="#S4.F6.sf5" title="In Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">6(e)</span></a>, whereas tuned models miss some (<span id="S4.SS3.p4.5.10" class="ltx_ERROR undefined">\eg</span><a href="#S4.F6.sf3" title="In Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">6(c)</span></a> where the shoulder joints are missing). The keypoint location precision is also improved using <span id="S4.SS3.p4.5.5" class="ltx_text ltx_font_italic">Sd<math id="S4.SS3.p4.5.5.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS3.p4.5.5.m1.1a"><mo stretchy="false" id="S4.SS3.p4.5.5.m1.1.1" xref="S4.SS3.p4.5.5.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.5.5.m1.1b"><ci id="S4.SS3.p4.5.5.m1.1.1.cmml" xref="S4.SS3.p4.5.5.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.5.5.m1.1c">\rightarrow</annotation></semantics></math>Td</span> models. Visually it is difficult to generalise if models with perceptual loss are better or not, however, they are more precise (<a href="#S4.F6.sf5" title="In Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">6(e)</span></a>, third row ankle is corrected, but a shoulder is missed).</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.1" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/baseline/img_44.jpg" id="S4.F6.1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.2" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/styled/img_44.jpg" id="S4.F6.2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.3" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/tuned/img_44.jpg" id="S4.F6.3.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.4" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/styledtuned/img_44.jpg" id="S4.F6.4.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.5" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/lambdas/img_44.jpg" id="S4.F6.5.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.6" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/baseline/img_48.jpeg" id="S4.F6.6.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.7" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/styled/img_48.jpeg" id="S4.F6.7.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.8" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/tuned/img_48.jpeg" id="S4.F6.8.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.9" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/styledtuned/img_48.jpeg" id="S4.F6.9.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.10" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/lambdas/img_48.jpeg" id="S4.F6.10.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.11" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/baseline/img_10_persecutor_2286_v0212.jpeg" id="S4.F6.11.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.12" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/styled/img_10_persecutor_2286_v0212.jpeg" id="S4.F6.12.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.13" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/tuned/img_10_persecutor_2286_v0212.jpeg" id="S4.F6.13.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.14" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/styledtuned/img_10_persecutor_2286_v0212.jpeg" id="S4.F6.14.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.15" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/lambdas/img_10_persecutor_2286_v0212.jpeg" id="S4.F6.15.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/baseline/img_234.jpg" id="S4.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="586" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><em id="S4.F6.sf1.4.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Baseline</em></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/styled/img_234.jpg" id="S4.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="586" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><em id="S4.F6.sf2.4.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Styled</em></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/tuned/img_234.jpg" id="S4.F6.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="586" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><em id="S4.F6.sf3.4.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Tuned</em></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/styledtuned/img_234.jpg" id="S4.F6.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="586" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf4.4.2.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><em id="S4.F6.sf4.2.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">Sd<math id="S4.F6.sf4.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.F6.sf4.2.1.m1.1b"><mo stretchy="false" id="S4.F6.sf4.2.1.m1.1.1" xref="S4.F6.sf4.2.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.F6.sf4.2.1.m1.1c"><ci id="S4.F6.sf4.2.1.m1.1.1.cmml" xref="S4.F6.sf4.2.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.sf4.2.1.m1.1d">\rightarrow</annotation></semantics></math>Td</em></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F6.sf5" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/lambdas/img_234.jpg" id="S4.F6.sf5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="586" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf5.7.2.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><em id="S4.F6.sf5.3.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">Sd<math id="S4.F6.sf5.3.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.F6.sf5.3.1.m1.1b"><mo stretchy="false" id="S4.F6.sf5.3.1.m1.1.1" xref="S4.F6.sf5.3.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.F6.sf5.3.1.m1.1c"><ci id="S4.F6.sf5.3.1.m1.1.1.cmml" xref="S4.F6.sf5.3.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.sf5.3.1.m1.1d">\rightarrow</annotation></semantics></math>Td</em><sub id="S4.F6.sf5.8.3" class="ltx_sub"><span id="S4.F6.sf5.8.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">p</span></sub></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.29.7.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.27.6" class="ltx_text ltx_font_bold" style="font-size:90%;">Pose models comparison<span id="S4.F6.27.6.6" class="ltx_text ltx_font_medium">: Pose Predictions on 4 examples each from <a href="#S4.F6.sf1" title="Fig. 6(a) â€£ Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a> <span id="S4.F6.27.6.6.5" class="ltx_text ltx_font_italic">baseline</span>, <a href="#S4.F6.sf2" title="Fig. 6(b) â€£ Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a> <span id="S4.F6.27.6.6.6" class="ltx_text ltx_font_italic">styled</span>, <a href="#S4.F6.sf3" title="Fig. 6(c) â€£ Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(c)</span></a> <span id="S4.F6.27.6.6.7" class="ltx_text ltx_font_italic">tuned</span>, <a href="#S4.F6.sf4" title="Fig. 6(d) â€£ Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(d)</span></a> <span id="S4.F6.22.1.1.1" class="ltx_text ltx_font_italic">styled-tunedÂ (St<math id="S4.F6.22.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.F6.22.1.1.1.m1.1b"><mo stretchy="false" id="S4.F6.22.1.1.1.m1.1.1" xref="S4.F6.22.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.F6.22.1.1.1.m1.1c"><ci id="S4.F6.22.1.1.1.m1.1.1.cmml" xref="S4.F6.22.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.22.1.1.1.m1.1d">\rightarrow</annotation></semantics></math>Td)</span> and <a href="#S4.F6.sf5" title="Fig. 6(e) â€£ Fig. 6 â€£ 4.3 Qualitative Pose Estimation Results â€£ 4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(e)</span></a> <span id="S4.F6.27.6.6.8" class="ltx_text ltx_font_italic">styled-tuned</span> with perceptual lossÂ (<em id="S4.F6.23.2.2.2" class="ltx_emph ltx_font_italic">Sd<math id="S4.F6.23.2.2.2.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.F6.23.2.2.2.m1.1b"><mo stretchy="false" id="S4.F6.23.2.2.2.m1.1.1" xref="S4.F6.23.2.2.2.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.F6.23.2.2.2.m1.1c"><ci id="S4.F6.23.2.2.2.m1.1.1.cmml" xref="S4.F6.23.2.2.2.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.23.2.2.2.m1.1d">\rightarrow</annotation></semantics></math>Td</em><sub id="S4.F6.27.6.6.9" class="ltx_sub"><span id="S4.F6.27.6.6.9.1" class="ltx_text ltx_font_italic">p</span></sub>) models. The results clearly show the superiority of predicted poses with the <em id="S4.F6.25.4.4.3" class="ltx_emph ltx_font_italic">St<math id="S4.F6.25.4.4.3.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.F6.25.4.4.3.m1.1b"><mo stretchy="false" id="S4.F6.25.4.4.3.m1.1.1" xref="S4.F6.25.4.4.3.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.F6.25.4.4.3.m1.1c"><ci id="S4.F6.25.4.4.3.m1.1.1.cmml" xref="S4.F6.25.4.4.3.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.25.4.4.3.m1.1d">\rightarrow</annotation></semantics></math>Td</em> and <em id="S4.F6.26.5.5.4" class="ltx_emph ltx_font_italic">Sd<math id="S4.F6.26.5.5.4.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.F6.26.5.5.4.m1.1b"><mo stretchy="false" id="S4.F6.26.5.5.4.m1.1.1" xref="S4.F6.26.5.5.4.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.F6.26.5.5.4.m1.1c"><ci id="S4.F6.26.5.5.4.m1.1.1.cmml" xref="S4.F6.26.5.5.4.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.26.5.5.4.m1.1d">\rightarrow</annotation></semantics></math>Td</em><sub id="S4.F6.27.6.6.10" class="ltx_sub"><span id="S4.F6.27.6.6.10.1" class="ltx_text ltx_font_italic">p</span></sub> models. The characters starting from the top are called <span id="S4.F6.27.6.6.11" class="ltx_text ltx_font_italic">wrestler</span>, <span id="S4.F6.27.6.6.12" class="ltx_text ltx_font_italic">fleeing</span>, <span id="S4.F6.27.6.6.13" class="ltx_text ltx_font_italic">persecutor</span> and <span id="S4.F6.27.6.6.14" class="ltx_text ltx_font_italic">bride</span>.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Pose-Based Retrieval</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our experiments (<a href="#S4" title="4 Experiments and Analysis â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a>) showed that <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">Styled</span> models and <span id="S5.p1.1.2" class="ltx_text ltx_font_italic">Styled-Tuned</span> models achieve better keypoint detection results, quantitatively and qualitatively, than their corresponding counterparts. In this section, we show that our two-step training pipeline is also beneficial for discovering similar images based on character poses. We call the process of retrieving images based on poses as <em id="S5.p1.1.3" class="ltx_emph ltx_font_italic">pose-based retrieval</em>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experimental Setup</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.5" class="ltx_p">The database for image retrieval and discovery is built from the <em id="S5.SS1.p1.5.4" class="ltx_emph ltx_font_italic">CA</em> validation dataset. The database consists of 303 images and their respective detected poses for best of <span id="S5.SS1.p1.5.5" class="ltx_text ltx_font_italic">baseline</span>, <span id="S5.SS1.p1.5.6" class="ltx_text ltx_font_italic">styled</span>, <span id="S5.SS1.p1.5.7" class="ltx_text ltx_font_italic">tuned</span>, <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_italic">Sd<math id="S5.SS1.p1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.SS1.p1.1.1.m1.1a"><mo stretchy="false" id="S5.SS1.p1.1.1.m1.1.1" xref="S5.SS1.p1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.1.m1.1b"><ci id="S5.SS1.p1.1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span> and <span id="S5.SS1.p1.3.3" class="ltx_text ltx_font_italic">Sd<math id="S5.SS1.p1.2.2.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.SS1.p1.2.2.m1.1a"><mo stretchy="false" id="S5.SS1.p1.2.2.m1.1.1" xref="S5.SS1.p1.2.2.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.2.m1.1b"><ci id="S5.SS1.p1.2.2.m1.1.1.cmml" xref="S5.SS1.p1.2.2.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.2.m1.1c">\rightarrow</annotation></semantics></math>Td<sub id="S5.SS1.p1.3.3.1" class="ltx_sub">p</sub>Â (with perceptual loss)</span>.
We perform two retrieval experiments based on the class label for each image, which is either a <span id="S5.SS1.p1.5.8" class="ltx_text ltx_font_italic">character</span> or <span id="S5.SS1.p1.5.9" class="ltx_text ltx_font_italic">scene</span>.
There are 15 unique <em id="S5.SS1.p1.5.10" class="ltx_emph ltx_font_italic">characters</em> (<span id="S5.SS1.p1.5.11" class="ltx_text ltx_font_bold">C</span>) and 5 <em id="S5.SS1.p1.5.12" class="ltx_emph ltx_font_italic">Scenes</em> (<span id="S5.SS1.p1.5.13" class="ltx_text ltx_font_bold">S</span>). Given a query image, we rank the retrieved images based on the OKS metricÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. In order to evaluate the retrieval method, we use the precision as: <math id="S5.SS1.p1.4.m1.1" class="ltx_Math" alttext="P^{*}=\frac{TP^{*}}{TP^{*}+FP^{*}}" display="inline"><semantics id="S5.SS1.p1.4.m1.1a"><mrow id="S5.SS1.p1.4.m1.1.1" xref="S5.SS1.p1.4.m1.1.1.cmml"><msup id="S5.SS1.p1.4.m1.1.1.2" xref="S5.SS1.p1.4.m1.1.1.2.cmml"><mi id="S5.SS1.p1.4.m1.1.1.2.2" xref="S5.SS1.p1.4.m1.1.1.2.2.cmml">P</mi><mo id="S5.SS1.p1.4.m1.1.1.2.3" xref="S5.SS1.p1.4.m1.1.1.2.3.cmml">âˆ—</mo></msup><mo id="S5.SS1.p1.4.m1.1.1.1" xref="S5.SS1.p1.4.m1.1.1.1.cmml">=</mo><mfrac id="S5.SS1.p1.4.m1.1.1.3" xref="S5.SS1.p1.4.m1.1.1.3.cmml"><mrow id="S5.SS1.p1.4.m1.1.1.3.2" xref="S5.SS1.p1.4.m1.1.1.3.2.cmml"><mi id="S5.SS1.p1.4.m1.1.1.3.2.2" xref="S5.SS1.p1.4.m1.1.1.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p1.4.m1.1.1.3.2.1" xref="S5.SS1.p1.4.m1.1.1.3.2.1.cmml">â€‹</mo><msup id="S5.SS1.p1.4.m1.1.1.3.2.3" xref="S5.SS1.p1.4.m1.1.1.3.2.3.cmml"><mi id="S5.SS1.p1.4.m1.1.1.3.2.3.2" xref="S5.SS1.p1.4.m1.1.1.3.2.3.2.cmml">P</mi><mo id="S5.SS1.p1.4.m1.1.1.3.2.3.3" xref="S5.SS1.p1.4.m1.1.1.3.2.3.3.cmml">âˆ—</mo></msup></mrow><mrow id="S5.SS1.p1.4.m1.1.1.3.3" xref="S5.SS1.p1.4.m1.1.1.3.3.cmml"><mrow id="S5.SS1.p1.4.m1.1.1.3.3.2" xref="S5.SS1.p1.4.m1.1.1.3.3.2.cmml"><mi id="S5.SS1.p1.4.m1.1.1.3.3.2.2" xref="S5.SS1.p1.4.m1.1.1.3.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p1.4.m1.1.1.3.3.2.1" xref="S5.SS1.p1.4.m1.1.1.3.3.2.1.cmml">â€‹</mo><msup id="S5.SS1.p1.4.m1.1.1.3.3.2.3" xref="S5.SS1.p1.4.m1.1.1.3.3.2.3.cmml"><mi id="S5.SS1.p1.4.m1.1.1.3.3.2.3.2" xref="S5.SS1.p1.4.m1.1.1.3.3.2.3.2.cmml">P</mi><mo id="S5.SS1.p1.4.m1.1.1.3.3.2.3.3" xref="S5.SS1.p1.4.m1.1.1.3.3.2.3.3.cmml">âˆ—</mo></msup></mrow><mo id="S5.SS1.p1.4.m1.1.1.3.3.1" xref="S5.SS1.p1.4.m1.1.1.3.3.1.cmml">+</mo><mrow id="S5.SS1.p1.4.m1.1.1.3.3.3" xref="S5.SS1.p1.4.m1.1.1.3.3.3.cmml"><mi id="S5.SS1.p1.4.m1.1.1.3.3.3.2" xref="S5.SS1.p1.4.m1.1.1.3.3.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p1.4.m1.1.1.3.3.3.1" xref="S5.SS1.p1.4.m1.1.1.3.3.3.1.cmml">â€‹</mo><msup id="S5.SS1.p1.4.m1.1.1.3.3.3.3" xref="S5.SS1.p1.4.m1.1.1.3.3.3.3.cmml"><mi id="S5.SS1.p1.4.m1.1.1.3.3.3.3.2" xref="S5.SS1.p1.4.m1.1.1.3.3.3.3.2.cmml">P</mi><mo id="S5.SS1.p1.4.m1.1.1.3.3.3.3.3" xref="S5.SS1.p1.4.m1.1.1.3.3.3.3.3.cmml">âˆ—</mo></msup></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m1.1b"><apply id="S5.SS1.p1.4.m1.1.1.cmml" xref="S5.SS1.p1.4.m1.1.1"><eq id="S5.SS1.p1.4.m1.1.1.1.cmml" xref="S5.SS1.p1.4.m1.1.1.1"></eq><apply id="S5.SS1.p1.4.m1.1.1.2.cmml" xref="S5.SS1.p1.4.m1.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.p1.4.m1.1.1.2.1.cmml" xref="S5.SS1.p1.4.m1.1.1.2">superscript</csymbol><ci id="S5.SS1.p1.4.m1.1.1.2.2.cmml" xref="S5.SS1.p1.4.m1.1.1.2.2">ğ‘ƒ</ci><times id="S5.SS1.p1.4.m1.1.1.2.3.cmml" xref="S5.SS1.p1.4.m1.1.1.2.3"></times></apply><apply id="S5.SS1.p1.4.m1.1.1.3.cmml" xref="S5.SS1.p1.4.m1.1.1.3"><divide id="S5.SS1.p1.4.m1.1.1.3.1.cmml" xref="S5.SS1.p1.4.m1.1.1.3"></divide><apply id="S5.SS1.p1.4.m1.1.1.3.2.cmml" xref="S5.SS1.p1.4.m1.1.1.3.2"><times id="S5.SS1.p1.4.m1.1.1.3.2.1.cmml" xref="S5.SS1.p1.4.m1.1.1.3.2.1"></times><ci id="S5.SS1.p1.4.m1.1.1.3.2.2.cmml" xref="S5.SS1.p1.4.m1.1.1.3.2.2">ğ‘‡</ci><apply id="S5.SS1.p1.4.m1.1.1.3.2.3.cmml" xref="S5.SS1.p1.4.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S5.SS1.p1.4.m1.1.1.3.2.3.1.cmml" xref="S5.SS1.p1.4.m1.1.1.3.2.3">superscript</csymbol><ci id="S5.SS1.p1.4.m1.1.1.3.2.3.2.cmml" xref="S5.SS1.p1.4.m1.1.1.3.2.3.2">ğ‘ƒ</ci><times id="S5.SS1.p1.4.m1.1.1.3.2.3.3.cmml" xref="S5.SS1.p1.4.m1.1.1.3.2.3.3"></times></apply></apply><apply id="S5.SS1.p1.4.m1.1.1.3.3.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3"><plus id="S5.SS1.p1.4.m1.1.1.3.3.1.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.1"></plus><apply id="S5.SS1.p1.4.m1.1.1.3.3.2.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.2"><times id="S5.SS1.p1.4.m1.1.1.3.3.2.1.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.2.1"></times><ci id="S5.SS1.p1.4.m1.1.1.3.3.2.2.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.2.2">ğ‘‡</ci><apply id="S5.SS1.p1.4.m1.1.1.3.3.2.3.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S5.SS1.p1.4.m1.1.1.3.3.2.3.1.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.2.3">superscript</csymbol><ci id="S5.SS1.p1.4.m1.1.1.3.3.2.3.2.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.2.3.2">ğ‘ƒ</ci><times id="S5.SS1.p1.4.m1.1.1.3.3.2.3.3.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.2.3.3"></times></apply></apply><apply id="S5.SS1.p1.4.m1.1.1.3.3.3.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.3"><times id="S5.SS1.p1.4.m1.1.1.3.3.3.1.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.3.1"></times><ci id="S5.SS1.p1.4.m1.1.1.3.3.3.2.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.3.2">ğ¹</ci><apply id="S5.SS1.p1.4.m1.1.1.3.3.3.3.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S5.SS1.p1.4.m1.1.1.3.3.3.3.1.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.3.3">superscript</csymbol><ci id="S5.SS1.p1.4.m1.1.1.3.3.3.3.2.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.3.3.2">ğ‘ƒ</ci><times id="S5.SS1.p1.4.m1.1.1.3.3.3.3.3.cmml" xref="S5.SS1.p1.4.m1.1.1.3.3.3.3.3"></times></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m1.1c">P^{*}=\frac{TP^{*}}{TP^{*}+FP^{*}}</annotation></semantics></math>, where <math id="S5.SS1.p1.5.m2.1" class="ltx_math_unparsed" alttext="{}^{*}=@k" display="inline"><semantics id="S5.SS1.p1.5.m2.1a"><mrow id="S5.SS1.p1.5.m2.1b"><mmultiscripts id="S5.SS1.p1.5.m2.1.1"><mo id="S5.SS1.p1.5.m2.1.1.2">=</mo><mprescripts id="S5.SS1.p1.5.m2.1.1a"></mprescripts><mrow id="S5.SS1.p1.5.m2.1.1b"></mrow><mo id="S5.SS1.p1.5.m2.1.1.3">âˆ—</mo></mmultiscripts><mi mathvariant="normal" id="S5.SS1.p1.5.m2.1.2">@</mi><mi id="S5.SS1.p1.5.m2.1.3">k</mi></mrow><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m2.1c">{}^{*}=@k</annotation></semantics></math>, consequently P@k := Precision at k; TP := true positives, FP := false positives and FN := false negatives.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">We report P@k and mAP, for k=1 and k=5. In all our experiments, we exclude the self-retrieval (query itself) from the evaluation.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T6.25.5.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S5.T6.8.4" class="ltx_text ltx_font_bold" style="font-size:90%;">Retrieval Results<span id="S5.T6.8.4.5" class="ltx_text ltx_font_medium">: The </span>(C)*<span id="S5.T6.8.4.6" class="ltx_text ltx_font_medium"> models show the retrieval values based on <span id="S5.T6.8.4.6.1" class="ltx_text ltx_font_italic">characters</span>, where as the </span>(S)*<span id="S5.T6.8.4.7" class="ltx_text ltx_font_medium"> models show for the <span id="S5.T6.8.4.7.1" class="ltx_text ltx_font_italic">scenes</span>. </span>P<span id="S5.T6.8.4.8" class="ltx_text ltx_font_medium"> is <span id="S5.T6.8.4.8.1" class="ltx_text ltx_font_italic">Precision</span>, and </span>mAP<span id="S5.T6.8.4.4" class="ltx_text ltx_font_medium"> is <span id="S5.T6.8.4.4.2" class="ltx_text ltx_font_italic">mean-Average Precision</span>. <math id="S5.T6.5.1.1.m1.1" class="ltx_Math" alttext="\alpha=U" display="inline"><semantics id="S5.T6.5.1.1.m1.1b"><mrow id="S5.T6.5.1.1.m1.1.1" xref="S5.T6.5.1.1.m1.1.1.cmml"><mi id="S5.T6.5.1.1.m1.1.1.2" xref="S5.T6.5.1.1.m1.1.1.2.cmml">Î±</mi><mo id="S5.T6.5.1.1.m1.1.1.1" xref="S5.T6.5.1.1.m1.1.1.1.cmml">=</mo><mi id="S5.T6.5.1.1.m1.1.1.3" xref="S5.T6.5.1.1.m1.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.5.1.1.m1.1c"><apply id="S5.T6.5.1.1.m1.1.1.cmml" xref="S5.T6.5.1.1.m1.1.1"><eq id="S5.T6.5.1.1.m1.1.1.1.cmml" xref="S5.T6.5.1.1.m1.1.1.1"></eq><ci id="S5.T6.5.1.1.m1.1.1.2.cmml" xref="S5.T6.5.1.1.m1.1.1.2">ğ›¼</ci><ci id="S5.T6.5.1.1.m1.1.1.3.cmml" xref="S5.T6.5.1.1.m1.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.5.1.1.m1.1d">\alpha=U</annotation></semantics></math>; <span id="S5.T6.8.4.4.3" class="ltx_text ltx_font_italic">SS: Style-Set</span>. <span id="S5.T6.6.2.2.1" class="ltx_text ltx_font_italic">Sd<math id="S5.T6.6.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T6.6.2.2.1.m1.1b"><mo stretchy="false" id="S5.T6.6.2.2.1.m1.1.1" xref="S5.T6.6.2.2.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.T6.6.2.2.1.m1.1c"><ci id="S5.T6.6.2.2.1.m1.1.1.cmml" xref="S5.T6.6.2.2.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.6.2.2.1.m1.1d">\rightarrow</annotation></semantics></math>Td*</span> are <span id="S5.T6.8.4.4.4" class="ltx_text ltx_font_italic">style-tuned</span> models, where <math id="S5.T6.7.3.3.m2.1" class="ltx_Math" alttext="p1=L_{comb1}" display="inline"><semantics id="S5.T6.7.3.3.m2.1b"><mrow id="S5.T6.7.3.3.m2.1.1" xref="S5.T6.7.3.3.m2.1.1.cmml"><mrow id="S5.T6.7.3.3.m2.1.1.2" xref="S5.T6.7.3.3.m2.1.1.2.cmml"><mi id="S5.T6.7.3.3.m2.1.1.2.2" xref="S5.T6.7.3.3.m2.1.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.T6.7.3.3.m2.1.1.2.1" xref="S5.T6.7.3.3.m2.1.1.2.1.cmml">â€‹</mo><mn id="S5.T6.7.3.3.m2.1.1.2.3" xref="S5.T6.7.3.3.m2.1.1.2.3.cmml">1</mn></mrow><mo id="S5.T6.7.3.3.m2.1.1.1" xref="S5.T6.7.3.3.m2.1.1.1.cmml">=</mo><msub id="S5.T6.7.3.3.m2.1.1.3" xref="S5.T6.7.3.3.m2.1.1.3.cmml"><mi id="S5.T6.7.3.3.m2.1.1.3.2" xref="S5.T6.7.3.3.m2.1.1.3.2.cmml">L</mi><mrow id="S5.T6.7.3.3.m2.1.1.3.3" xref="S5.T6.7.3.3.m2.1.1.3.3.cmml"><mi id="S5.T6.7.3.3.m2.1.1.3.3.2" xref="S5.T6.7.3.3.m2.1.1.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T6.7.3.3.m2.1.1.3.3.1" xref="S5.T6.7.3.3.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.T6.7.3.3.m2.1.1.3.3.3" xref="S5.T6.7.3.3.m2.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.T6.7.3.3.m2.1.1.3.3.1b" xref="S5.T6.7.3.3.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.T6.7.3.3.m2.1.1.3.3.4" xref="S5.T6.7.3.3.m2.1.1.3.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.T6.7.3.3.m2.1.1.3.3.1c" xref="S5.T6.7.3.3.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.T6.7.3.3.m2.1.1.3.3.5" xref="S5.T6.7.3.3.m2.1.1.3.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S5.T6.7.3.3.m2.1.1.3.3.1d" xref="S5.T6.7.3.3.m2.1.1.3.3.1.cmml">â€‹</mo><mn id="S5.T6.7.3.3.m2.1.1.3.3.6" xref="S5.T6.7.3.3.m2.1.1.3.3.6.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.7.3.3.m2.1c"><apply id="S5.T6.7.3.3.m2.1.1.cmml" xref="S5.T6.7.3.3.m2.1.1"><eq id="S5.T6.7.3.3.m2.1.1.1.cmml" xref="S5.T6.7.3.3.m2.1.1.1"></eq><apply id="S5.T6.7.3.3.m2.1.1.2.cmml" xref="S5.T6.7.3.3.m2.1.1.2"><times id="S5.T6.7.3.3.m2.1.1.2.1.cmml" xref="S5.T6.7.3.3.m2.1.1.2.1"></times><ci id="S5.T6.7.3.3.m2.1.1.2.2.cmml" xref="S5.T6.7.3.3.m2.1.1.2.2">ğ‘</ci><cn type="integer" id="S5.T6.7.3.3.m2.1.1.2.3.cmml" xref="S5.T6.7.3.3.m2.1.1.2.3">1</cn></apply><apply id="S5.T6.7.3.3.m2.1.1.3.cmml" xref="S5.T6.7.3.3.m2.1.1.3"><csymbol cd="ambiguous" id="S5.T6.7.3.3.m2.1.1.3.1.cmml" xref="S5.T6.7.3.3.m2.1.1.3">subscript</csymbol><ci id="S5.T6.7.3.3.m2.1.1.3.2.cmml" xref="S5.T6.7.3.3.m2.1.1.3.2">ğ¿</ci><apply id="S5.T6.7.3.3.m2.1.1.3.3.cmml" xref="S5.T6.7.3.3.m2.1.1.3.3"><times id="S5.T6.7.3.3.m2.1.1.3.3.1.cmml" xref="S5.T6.7.3.3.m2.1.1.3.3.1"></times><ci id="S5.T6.7.3.3.m2.1.1.3.3.2.cmml" xref="S5.T6.7.3.3.m2.1.1.3.3.2">ğ‘</ci><ci id="S5.T6.7.3.3.m2.1.1.3.3.3.cmml" xref="S5.T6.7.3.3.m2.1.1.3.3.3">ğ‘œ</ci><ci id="S5.T6.7.3.3.m2.1.1.3.3.4.cmml" xref="S5.T6.7.3.3.m2.1.1.3.3.4">ğ‘š</ci><ci id="S5.T6.7.3.3.m2.1.1.3.3.5.cmml" xref="S5.T6.7.3.3.m2.1.1.3.3.5">ğ‘</ci><cn type="integer" id="S5.T6.7.3.3.m2.1.1.3.3.6.cmml" xref="S5.T6.7.3.3.m2.1.1.3.3.6">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.7.3.3.m2.1d">p1=L_{comb1}</annotation></semantics></math>Â (<a href="#S3.E1.1" title="In Eq. 1 â€£ Enforcing Perceptual Similarity â€£ 3.2 Pose Estimation Approach â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">1a</span></a>) and <math id="S5.T6.8.4.4.m3.1" class="ltx_Math" alttext="p2=L_{comb2}" display="inline"><semantics id="S5.T6.8.4.4.m3.1b"><mrow id="S5.T6.8.4.4.m3.1.1" xref="S5.T6.8.4.4.m3.1.1.cmml"><mrow id="S5.T6.8.4.4.m3.1.1.2" xref="S5.T6.8.4.4.m3.1.1.2.cmml"><mi id="S5.T6.8.4.4.m3.1.1.2.2" xref="S5.T6.8.4.4.m3.1.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.T6.8.4.4.m3.1.1.2.1" xref="S5.T6.8.4.4.m3.1.1.2.1.cmml">â€‹</mo><mn id="S5.T6.8.4.4.m3.1.1.2.3" xref="S5.T6.8.4.4.m3.1.1.2.3.cmml">2</mn></mrow><mo id="S5.T6.8.4.4.m3.1.1.1" xref="S5.T6.8.4.4.m3.1.1.1.cmml">=</mo><msub id="S5.T6.8.4.4.m3.1.1.3" xref="S5.T6.8.4.4.m3.1.1.3.cmml"><mi id="S5.T6.8.4.4.m3.1.1.3.2" xref="S5.T6.8.4.4.m3.1.1.3.2.cmml">L</mi><mrow id="S5.T6.8.4.4.m3.1.1.3.3" xref="S5.T6.8.4.4.m3.1.1.3.3.cmml"><mi id="S5.T6.8.4.4.m3.1.1.3.3.2" xref="S5.T6.8.4.4.m3.1.1.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T6.8.4.4.m3.1.1.3.3.1" xref="S5.T6.8.4.4.m3.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.T6.8.4.4.m3.1.1.3.3.3" xref="S5.T6.8.4.4.m3.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.T6.8.4.4.m3.1.1.3.3.1b" xref="S5.T6.8.4.4.m3.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.T6.8.4.4.m3.1.1.3.3.4" xref="S5.T6.8.4.4.m3.1.1.3.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.T6.8.4.4.m3.1.1.3.3.1c" xref="S5.T6.8.4.4.m3.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.T6.8.4.4.m3.1.1.3.3.5" xref="S5.T6.8.4.4.m3.1.1.3.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S5.T6.8.4.4.m3.1.1.3.3.1d" xref="S5.T6.8.4.4.m3.1.1.3.3.1.cmml">â€‹</mo><mn id="S5.T6.8.4.4.m3.1.1.3.3.6" xref="S5.T6.8.4.4.m3.1.1.3.3.6.cmml">2</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.8.4.4.m3.1c"><apply id="S5.T6.8.4.4.m3.1.1.cmml" xref="S5.T6.8.4.4.m3.1.1"><eq id="S5.T6.8.4.4.m3.1.1.1.cmml" xref="S5.T6.8.4.4.m3.1.1.1"></eq><apply id="S5.T6.8.4.4.m3.1.1.2.cmml" xref="S5.T6.8.4.4.m3.1.1.2"><times id="S5.T6.8.4.4.m3.1.1.2.1.cmml" xref="S5.T6.8.4.4.m3.1.1.2.1"></times><ci id="S5.T6.8.4.4.m3.1.1.2.2.cmml" xref="S5.T6.8.4.4.m3.1.1.2.2">ğ‘</ci><cn type="integer" id="S5.T6.8.4.4.m3.1.1.2.3.cmml" xref="S5.T6.8.4.4.m3.1.1.2.3">2</cn></apply><apply id="S5.T6.8.4.4.m3.1.1.3.cmml" xref="S5.T6.8.4.4.m3.1.1.3"><csymbol cd="ambiguous" id="S5.T6.8.4.4.m3.1.1.3.1.cmml" xref="S5.T6.8.4.4.m3.1.1.3">subscript</csymbol><ci id="S5.T6.8.4.4.m3.1.1.3.2.cmml" xref="S5.T6.8.4.4.m3.1.1.3.2">ğ¿</ci><apply id="S5.T6.8.4.4.m3.1.1.3.3.cmml" xref="S5.T6.8.4.4.m3.1.1.3.3"><times id="S5.T6.8.4.4.m3.1.1.3.3.1.cmml" xref="S5.T6.8.4.4.m3.1.1.3.3.1"></times><ci id="S5.T6.8.4.4.m3.1.1.3.3.2.cmml" xref="S5.T6.8.4.4.m3.1.1.3.3.2">ğ‘</ci><ci id="S5.T6.8.4.4.m3.1.1.3.3.3.cmml" xref="S5.T6.8.4.4.m3.1.1.3.3.3">ğ‘œ</ci><ci id="S5.T6.8.4.4.m3.1.1.3.3.4.cmml" xref="S5.T6.8.4.4.m3.1.1.3.3.4">ğ‘š</ci><ci id="S5.T6.8.4.4.m3.1.1.3.3.5.cmml" xref="S5.T6.8.4.4.m3.1.1.3.3.5">ğ‘</ci><cn type="integer" id="S5.T6.8.4.4.m3.1.1.3.3.6.cmml" xref="S5.T6.8.4.4.m3.1.1.3.3.6">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.8.4.4.m3.1d">p2=L_{comb2}</annotation></semantics></math>Â <a href="#S3.E1.2" title="In Eq. 1 â€£ Enforcing Perceptual Similarity â€£ 3.2 Pose Estimation Approach â€£ 3 Proposed Method â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">1b</span></a></span></span></figcaption>
<table id="S5.T6.23" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T6.9.1" class="ltx_tr">
<th id="S5.T6.9.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.9.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></th>
<th id="S5.T6.9.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.9.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">P@1</span></th>
<th id="S5.T6.9.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.9.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">P@5</span></th>
<th id="S5.T6.9.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.9.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">mAP</span></th>
<th id="S5.T6.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="S5.T6.9.1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.T6.9.1.1.m1.1a"><mi mathsize="80%" id="S5.T6.9.1.1.m1.1.1" xref="S5.T6.9.1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S5.T6.9.1.1.m1.1b"><ci id="S5.T6.9.1.1.m1.1.1.cmml" xref="S5.T6.9.1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.9.1.1.m1.1c">\alpha</annotation></semantics></math></th>
<th id="S5.T6.9.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.9.1.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SS</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T6.23.16.1" class="ltx_tr">
<td id="S5.T6.23.16.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.23.16.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(C)Â Baseline</span></td>
<td id="S5.T6.23.16.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.16.1.2.1" class="ltx_text" style="font-size:80%;">31.7</span></td>
<td id="S5.T6.23.16.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.16.1.3.1" class="ltx_text" style="font-size:80%;">25.5</span></td>
<td id="S5.T6.23.16.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.16.1.4.1" class="ltx_text" style="font-size:80%;">21.5</span></td>
<td id="S5.T6.23.16.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.16.1.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T6.23.16.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.16.1.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T6.10.2" class="ltx_tr">
<td id="S5.T6.10.2.2" class="ltx_td ltx_align_left"><span id="S5.T6.10.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(C)Â Styled</span></td>
<td id="S5.T6.10.2.3" class="ltx_td ltx_align_center"><span id="S5.T6.10.2.3.1" class="ltx_text" style="font-size:80%;">37.3</span></td>
<td id="S5.T6.10.2.4" class="ltx_td ltx_align_center"><span id="S5.T6.10.2.4.1" class="ltx_text" style="font-size:80%;">30.2</span></td>
<td id="S5.T6.10.2.5" class="ltx_td ltx_align_center"><span id="S5.T6.10.2.5.1" class="ltx_text" style="font-size:80%;">23.1</span></td>
<td id="S5.T6.10.2.1" class="ltx_td ltx_align_center"><math id="S5.T6.10.2.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S5.T6.10.2.1.m1.1a"><mi mathsize="80%" id="S5.T6.10.2.1.m1.1.1" xref="S5.T6.10.2.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S5.T6.10.2.1.m1.1b"><ci id="S5.T6.10.2.1.m1.1.1.cmml" xref="S5.T6.10.2.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.10.2.1.m1.1c">U</annotation></semantics></math></td>
<td id="S5.T6.10.2.6" class="ltx_td ltx_align_center"><span id="S5.T6.10.2.6.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S5.T6.23.17.2" class="ltx_tr">
<td id="S5.T6.23.17.2.1" class="ltx_td ltx_align_left"><span id="S5.T6.23.17.2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(C)Â Tuned</span></td>
<td id="S5.T6.23.17.2.2" class="ltx_td ltx_align_center"><span id="S5.T6.23.17.2.2.1" class="ltx_text" style="font-size:80%;">43.0</span></td>
<td id="S5.T6.23.17.2.3" class="ltx_td ltx_align_center"><span id="S5.T6.23.17.2.3.1" class="ltx_text" style="font-size:80%;">39.8</span></td>
<td id="S5.T6.23.17.2.4" class="ltx_td ltx_align_center"><span id="S5.T6.23.17.2.4.1" class="ltx_text" style="font-size:80%;">27.5</span></td>
<td id="S5.T6.23.17.2.5" class="ltx_td ltx_align_center"><span id="S5.T6.23.17.2.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T6.23.17.2.6" class="ltx_td ltx_align_center"><span id="S5.T6.23.17.2.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T6.12.4" class="ltx_tr">
<td id="S5.T6.11.3.1" class="ltx_td ltx_align_left"><span id="S5.T6.11.3.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(C)Â Sd<math id="S5.T6.11.3.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T6.11.3.1.1.m1.1a"><mo stretchy="false" id="S5.T6.11.3.1.1.m1.1.1" xref="S5.T6.11.3.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.T6.11.3.1.1.m1.1b"><ci id="S5.T6.11.3.1.1.m1.1.1.cmml" xref="S5.T6.11.3.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.11.3.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span></td>
<td id="S5.T6.12.4.3" class="ltx_td ltx_align_center"><span id="S5.T6.12.4.3.1" class="ltx_text" style="font-size:80%;">47.7</span></td>
<td id="S5.T6.12.4.4" class="ltx_td ltx_align_center"><span id="S5.T6.12.4.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">42.2</span></td>
<td id="S5.T6.12.4.5" class="ltx_td ltx_align_center"><span id="S5.T6.12.4.5.1" class="ltx_text" style="font-size:80%;">28.3</span></td>
<td id="S5.T6.12.4.2" class="ltx_td ltx_align_center"><math id="S5.T6.12.4.2.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S5.T6.12.4.2.m1.1a"><mi mathsize="80%" id="S5.T6.12.4.2.m1.1.1" xref="S5.T6.12.4.2.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S5.T6.12.4.2.m1.1b"><ci id="S5.T6.12.4.2.m1.1.1.cmml" xref="S5.T6.12.4.2.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.12.4.2.m1.1c">U</annotation></semantics></math></td>
<td id="S5.T6.12.4.6" class="ltx_td ltx_align_center"><span id="S5.T6.12.4.6.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S5.T6.14.6" class="ltx_tr">
<td id="S5.T6.14.6.2" class="ltx_td ltx_align_left"><span id="S5.T6.14.6.2.2" class="ltx_text ltx_font_bold" style="font-size:80%;">(C)Â Sd<math id="S5.T6.13.5.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T6.13.5.1.1.m1.1a"><mo stretchy="false" id="S5.T6.13.5.1.1.m1.1.1" xref="S5.T6.13.5.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.T6.13.5.1.1.m1.1b"><ci id="S5.T6.13.5.1.1.m1.1.1.cmml" xref="S5.T6.13.5.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.13.5.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td<sub id="S5.T6.14.6.2.2.1" class="ltx_sub"><span id="S5.T6.14.6.2.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">p1</span></sub></span></td>
<td id="S5.T6.14.6.3" class="ltx_td ltx_align_center"><span id="S5.T6.14.6.3.1" class="ltx_text" style="font-size:80%;">45.7</span></td>
<td id="S5.T6.14.6.4" class="ltx_td ltx_align_center"><span id="S5.T6.14.6.4.1" class="ltx_text" style="font-size:80%;">41.4</span></td>
<td id="S5.T6.14.6.5" class="ltx_td ltx_align_center"><span id="S5.T6.14.6.5.1" class="ltx_text" style="font-size:80%;">28.0</span></td>
<td id="S5.T6.14.6.6" class="ltx_td ltx_align_center"><span id="S5.T6.14.6.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S5.T6.14.6.7" class="ltx_td ltx_align_center"><span id="S5.T6.14.6.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S5.T6.16.8" class="ltx_tr">
<td id="S5.T6.16.8.2" class="ltx_td ltx_align_left"><span id="S5.T6.16.8.2.2" class="ltx_text ltx_font_bold" style="font-size:80%;">(C)Â Sd<math id="S5.T6.15.7.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T6.15.7.1.1.m1.1a"><mo stretchy="false" id="S5.T6.15.7.1.1.m1.1.1" xref="S5.T6.15.7.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.T6.15.7.1.1.m1.1b"><ci id="S5.T6.15.7.1.1.m1.1.1.cmml" xref="S5.T6.15.7.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.15.7.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td<sub id="S5.T6.16.8.2.2.1" class="ltx_sub"><span id="S5.T6.16.8.2.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">p2</span></sub></span></td>
<td id="S5.T6.16.8.3" class="ltx_td ltx_align_center"><span id="S5.T6.16.8.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">48.3</span></td>
<td id="S5.T6.16.8.4" class="ltx_td ltx_align_center"><span id="S5.T6.16.8.4.1" class="ltx_text" style="font-size:80%;">41.1</span></td>
<td id="S5.T6.16.8.5" class="ltx_td ltx_align_center"><span id="S5.T6.16.8.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">28.4</span></td>
<td id="S5.T6.16.8.6" class="ltx_td ltx_align_center"><span id="S5.T6.16.8.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S5.T6.16.8.7" class="ltx_td ltx_align_center"><span id="S5.T6.16.8.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S5.T6.23.18.3" class="ltx_tr">
<td id="S5.T6.23.18.3.1" class="ltx_td ltx_align_left"><span id="S5.T6.23.18.3.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(S)Â Baseline</span></td>
<td id="S5.T6.23.18.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.18.3.2.1" class="ltx_text" style="font-size:80%;">43.6</span></td>
<td id="S5.T6.23.18.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.18.3.3.1" class="ltx_text" style="font-size:80%;">43.2</span></td>
<td id="S5.T6.23.18.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.18.3.4.1" class="ltx_text" style="font-size:80%;">35.9</span></td>
<td id="S5.T6.23.18.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.18.3.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T6.23.18.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.23.18.3.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T6.17.9" class="ltx_tr">
<td id="S5.T6.17.9.2" class="ltx_td ltx_align_left"><span id="S5.T6.17.9.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(S)Â Styled</span></td>
<td id="S5.T6.17.9.3" class="ltx_td ltx_align_center"><span id="S5.T6.17.9.3.1" class="ltx_text" style="font-size:80%;">46.9</span></td>
<td id="S5.T6.17.9.4" class="ltx_td ltx_align_center"><span id="S5.T6.17.9.4.1" class="ltx_text" style="font-size:80%;">43.6</span></td>
<td id="S5.T6.17.9.5" class="ltx_td ltx_align_center"><span id="S5.T6.17.9.5.1" class="ltx_text" style="font-size:80%;">37.3</span></td>
<td id="S5.T6.17.9.1" class="ltx_td ltx_align_center"><math id="S5.T6.17.9.1.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S5.T6.17.9.1.m1.1a"><mi mathsize="80%" id="S5.T6.17.9.1.m1.1.1" xref="S5.T6.17.9.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S5.T6.17.9.1.m1.1b"><ci id="S5.T6.17.9.1.m1.1.1.cmml" xref="S5.T6.17.9.1.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.17.9.1.m1.1c">U</annotation></semantics></math></td>
<td id="S5.T6.17.9.6" class="ltx_td ltx_align_center"><span id="S5.T6.17.9.6.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S5.T6.23.19.4" class="ltx_tr">
<td id="S5.T6.23.19.4.1" class="ltx_td ltx_align_left"><span id="S5.T6.23.19.4.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(S)Â Tuned</span></td>
<td id="S5.T6.23.19.4.2" class="ltx_td ltx_align_center"><span id="S5.T6.23.19.4.2.1" class="ltx_text" style="font-size:80%;">56.4</span></td>
<td id="S5.T6.23.19.4.3" class="ltx_td ltx_align_center"><span id="S5.T6.23.19.4.3.1" class="ltx_text" style="font-size:80%;">52.7</span></td>
<td id="S5.T6.23.19.4.4" class="ltx_td ltx_align_center"><span id="S5.T6.23.19.4.4.1" class="ltx_text" style="font-size:80%;">41.5</span></td>
<td id="S5.T6.23.19.4.5" class="ltx_td ltx_align_center"><span id="S5.T6.23.19.4.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T6.23.19.4.6" class="ltx_td ltx_align_center"><span id="S5.T6.23.19.4.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T6.19.11" class="ltx_tr">
<td id="S5.T6.18.10.1" class="ltx_td ltx_align_left"><span id="S5.T6.18.10.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">(S)Â Sd<math id="S5.T6.18.10.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T6.18.10.1.1.m1.1a"><mo stretchy="false" id="S5.T6.18.10.1.1.m1.1.1" xref="S5.T6.18.10.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.T6.18.10.1.1.m1.1b"><ci id="S5.T6.18.10.1.1.m1.1.1.cmml" xref="S5.T6.18.10.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.18.10.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td</span></td>
<td id="S5.T6.19.11.3" class="ltx_td ltx_align_center"><span id="S5.T6.19.11.3.1" class="ltx_text" style="font-size:80%;">58.8</span></td>
<td id="S5.T6.19.11.4" class="ltx_td ltx_align_center"><span id="S5.T6.19.11.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">55.2</span></td>
<td id="S5.T6.19.11.5" class="ltx_td ltx_align_center"><span id="S5.T6.19.11.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">42.1</span></td>
<td id="S5.T6.19.11.2" class="ltx_td ltx_align_center"><math id="S5.T6.19.11.2.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S5.T6.19.11.2.m1.1a"><mi mathsize="80%" id="S5.T6.19.11.2.m1.1.1" xref="S5.T6.19.11.2.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S5.T6.19.11.2.m1.1b"><ci id="S5.T6.19.11.2.m1.1.1.cmml" xref="S5.T6.19.11.2.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.19.11.2.m1.1c">U</annotation></semantics></math></td>
<td id="S5.T6.19.11.6" class="ltx_td ltx_align_center"><span id="S5.T6.19.11.6.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S5.T6.21.13" class="ltx_tr">
<td id="S5.T6.21.13.2" class="ltx_td ltx_align_left"><span id="S5.T6.21.13.2.2" class="ltx_text ltx_font_bold" style="font-size:80%;">(S)Â Sd<math id="S5.T6.20.12.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T6.20.12.1.1.m1.1a"><mo stretchy="false" id="S5.T6.20.12.1.1.m1.1.1" xref="S5.T6.20.12.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.T6.20.12.1.1.m1.1b"><ci id="S5.T6.20.12.1.1.m1.1.1.cmml" xref="S5.T6.20.12.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.20.12.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td<sub id="S5.T6.21.13.2.2.1" class="ltx_sub"><span id="S5.T6.21.13.2.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">p1</span></sub></span></td>
<td id="S5.T6.21.13.3" class="ltx_td ltx_align_center"><span id="S5.T6.21.13.3.1" class="ltx_text" style="font-size:80%;">57.8</span></td>
<td id="S5.T6.21.13.4" class="ltx_td ltx_align_center"><span id="S5.T6.21.13.4.1" class="ltx_text" style="font-size:80%;">53.5</span></td>
<td id="S5.T6.21.13.5" class="ltx_td ltx_align_center"><span id="S5.T6.21.13.5.1" class="ltx_text" style="font-size:80%;">41.5</span></td>
<td id="S5.T6.21.13.6" class="ltx_td ltx_align_center"><span id="S5.T6.21.13.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S5.T6.21.13.7" class="ltx_td ltx_align_center"><span id="S5.T6.21.13.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
<tr id="S5.T6.23.15" class="ltx_tr">
<td id="S5.T6.23.15.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T6.23.15.2.2" class="ltx_text ltx_font_bold" style="font-size:80%;">(S)Â Sd<math id="S5.T6.22.14.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T6.22.14.1.1.m1.1a"><mo stretchy="false" id="S5.T6.22.14.1.1.m1.1.1" xref="S5.T6.22.14.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.T6.22.14.1.1.m1.1b"><ci id="S5.T6.22.14.1.1.m1.1.1.cmml" xref="S5.T6.22.14.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.22.14.1.1.m1.1c">\rightarrow</annotation></semantics></math>Td<sub id="S5.T6.23.15.2.2.1" class="ltx_sub"><span id="S5.T6.23.15.2.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">p2</span></sub></span></td>
<td id="S5.T6.23.15.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.23.15.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">58.8</span></td>
<td id="S5.T6.23.15.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.23.15.4.1" class="ltx_text" style="font-size:80%;">53.4</span></td>
<td id="S5.T6.23.15.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.23.15.5.1" class="ltx_text" style="font-size:80%;">41.8</span></td>
<td id="S5.T6.23.15.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.23.15.6.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S5.T6.23.15.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.23.15.7.1" class="ltx_text" style="font-size:80%;">CA</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.1" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/baseline/exp_4_query_fleeing_Pursuit.png" id="S5.F7.1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.2" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/baseline/exp_4_retrieval_2_wrestler_Wrestling_Agonal.png" id="S5.F7.2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.3" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/baseline/exp_4_retrieval_3_Triton_Wrestling_Mythological.png" id="S5.F7.3.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.4" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/baseline/exp_4_retrieval_4_fleeing_Pursuit.png" id="S5.F7.4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.5" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/baseline/exp_4_retrieval_5_groom_Leading.png" id="S5.F7.5.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.6" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/baseline/exp_4_retrieval_6_groom_Leading.png" id="S5.F7.6.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.7" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled/exp_4_query_fleeing_Pursuit.png" id="S5.F7.7.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.8" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled/exp_4_retrieval_2_fleeing_Pursuit.png" id="S5.F7.8.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.9" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled/exp_4_retrieval_3_fleeing_Pursuit.png" id="S5.F7.9.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.10" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled/exp_4_retrieval_4_fleeing_Pursuit.png" id="S5.F7.10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.11" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled/exp_4_retrieval_5_fleeing_Pursuit.png" id="S5.F7.11.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.12" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled/exp_4_retrieval_6_persecutor_Pursuit.png" id="S5.F7.12.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.13" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/tuned/exp_4_query_fleeing_Pursuit.png" id="S5.F7.13.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.14" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/tuned/exp_4_retrieval_2_fleeing_Pursuit.png" id="S5.F7.14.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.15" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/tuned/exp_4_retrieval_3_fleeing_Pursuit.png" id="S5.F7.15.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.16" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/tuned/exp_4_retrieval_4_fleeing_Pursuit.png" id="S5.F7.16.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.17" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/tuned/exp_4_retrieval_5_fleeing_Pursuit.png" id="S5.F7.17.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.18" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/tuned/exp_4_retrieval_6_fleeing_Pursuit.png" id="S5.F7.18.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.19" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled-tuned/exp_4_query_fleeing_Pursuit.png" id="S5.F7.19.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.20" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled-tuned/exp_4_retrieval_2_fleeing_Pursuit.png" id="S5.F7.20.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.21" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled-tuned/exp_4_retrieval_3_fleeing_Pursuit.png" id="S5.F7.21.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.22" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled-tuned/exp_4_retrieval_4_fleeing_Pursuit.png" id="S5.F7.22.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.23" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled-tuned/exp_4_retrieval_5_fleeing_Pursuit.png" id="S5.F7.23.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.24" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/styled-tuned/exp_4_retrieval_6_fleeing_Pursuit.png" id="S5.F7.24.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.25" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_mult/exp_4_query_fleeing_Pursuit.png" id="S5.F7.25.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.26" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_mult/exp_4_retrieval_2_fleeing_Pursuit.png" id="S5.F7.26.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.27" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_mult/exp_4_retrieval_3_fleeing_Pursuit.png" id="S5.F7.27.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.28" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_mult/exp_4_retrieval_4_fleeing_Pursuit.png" id="S5.F7.28.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.29" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_mult/exp_4_retrieval_5_fleeing_Pursuit.png" id="S5.F7.29.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.30" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_mult/exp_4_retrieval_6_fleeing_Pursuit.png" id="S5.F7.30.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_lambda/exp_4_query_fleeing_Pursuit.png" id="S5.F7.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_lambda/exp_4_retrieval_2_fleeing_Pursuit.png" id="S5.F7.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_lambda/exp_4_retrieval_3_fleeing_Pursuit.png" id="S5.F7.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_lambda/exp_4_retrieval_4_fleeing_Pursuit.png" id="S5.F7.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.sf5" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_lambda/exp_4_retrieval_5_fleeing_Pursuit.png" id="S5.F7.sf5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F7.sf6" class="ltx_figure ltx_figure_panel"><img src="/html/2012.05616/assets/figures/results/retrieval/perceptual_lambda/exp_4_retrieval_6_fleeing_Pursuit.png" id="S5.F7.sf6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.sf6.2.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.42.6.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S5.F7.40.5" class="ltx_text ltx_font_bold" style="font-size:90%;">Discovery and Retrieval comparison<span id="S5.F7.40.5.5" class="ltx_text ltx_font_medium">: <a href="#S5.F7.sf1" title="Fig. 7(a) â€£ Fig. 7 â€£ 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a> are query images (<em id="S5.F7.40.5.5.6" class="ltx_emph ltx_font_italic">fleeing</em> character, <em id="S5.F7.40.5.5.7" class="ltx_emph ltx_font_italic">pursuit</em> scene), and the remaining 5 columns, <a href="#S5.F7.sf2" title="Fig. 7(b) â€£ Fig. 7 â€£ 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(b)</span></a>,<a href="#S5.F7.sf3" title="Fig. 7(c) â€£ Fig. 7 â€£ 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(c)</span></a>,<a href="#S5.F7.sf4" title="Fig. 7(d) â€£ Fig. 7 â€£ 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(d)</span></a>,<a href="#S5.F7.sf5" title="Fig. 7(e) â€£ Fig. 7 â€£ 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(e)</span></a>,<a href="#S5.F7.sf6" title="Fig. 7(f) â€£ Fig. 7 â€£ 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(f)</span></a>, show the top 5 retrieval results across four models; <span id="S5.F7.40.5.5.8" class="ltx_ERROR undefined">\nth</span>1 row â€“ <span id="S5.F7.40.5.5.9" class="ltx_text ltx_font_italic">baseline</span>, <span id="S5.F7.40.5.5.10" class="ltx_ERROR undefined">\nth</span>2 row â€“ <span id="S5.F7.40.5.5.11" class="ltx_text ltx_font_italic">styled</span>, <span id="S5.F7.40.5.5.12" class="ltx_ERROR undefined">\nth</span>3 row â€“ <span id="S5.F7.40.5.5.13" class="ltx_text ltx_font_italic">Tuned</span>, <span id="S5.F7.40.5.5.14" class="ltx_ERROR undefined">\nth</span>4 row â€“ <span id="S5.F7.36.1.1.1" class="ltx_text ltx_font_italic">Sd<math id="S5.F7.36.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.F7.36.1.1.1.m1.1b"><mo stretchy="false" id="S5.F7.36.1.1.1.m1.1.1" xref="S5.F7.36.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.F7.36.1.1.1.m1.1c"><ci id="S5.F7.36.1.1.1.m1.1.1.cmml" xref="S5.F7.36.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.36.1.1.1.m1.1d">\rightarrow</annotation></semantics></math>Td</span>, <span id="S5.F7.40.5.5.15" class="ltx_ERROR undefined">\nth</span>5 and <span id="S5.F7.40.5.5.16" class="ltx_ERROR undefined">\nth</span>6 row â€“ <span id="S5.F7.38.3.3.3" class="ltx_text ltx_font_italic">Sd<math id="S5.F7.37.2.2.2.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.F7.37.2.2.2.m1.1b"><mo stretchy="false" id="S5.F7.37.2.2.2.m1.1.1" xref="S5.F7.37.2.2.2.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.F7.37.2.2.2.m1.1c"><ci id="S5.F7.37.2.2.2.m1.1.1.cmml" xref="S5.F7.37.2.2.2.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.37.2.2.2.m1.1d">\rightarrow</annotation></semantics></math>Td<sub id="S5.F7.38.3.3.3.1" class="ltx_sub">p1</sub></span> and <span id="S5.F7.40.5.5.5" class="ltx_text ltx_font_italic">Sd<math id="S5.F7.39.4.4.4.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.F7.39.4.4.4.m1.1b"><mo stretchy="false" id="S5.F7.39.4.4.4.m1.1.1" xref="S5.F7.39.4.4.4.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.F7.39.4.4.4.m1.1c"><ci id="S5.F7.39.4.4.4.m1.1.1.cmml" xref="S5.F7.39.4.4.4.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.39.4.4.4.m1.1d">\rightarrow</annotation></semantics></math>Td<sub id="S5.F7.40.5.5.5.1" class="ltx_sub">p2</sub></span> respectively. The results clearly show that the styled-tuned models retrieve the most precise results based on poses.</span></span></figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Retrieval Results and Discovery</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p"><a href="#S5.T6" title="In 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">6</span></a> presents our pose-based retrieval results. We observe that <em id="S5.SS2.p1.1.1" class="ltx_emph ltx_font_italic">styled-tuned</em> models are consistently better for <span id="S5.SS2.p1.1.2" class="ltx_text ltx_font_bold">C</span> and <span id="S5.SS2.p1.1.3" class="ltx_text ltx_font_bold">S</span>, and the <span id="S5.SS2.p1.1.4" class="ltx_text ltx_font_italic">styled</span> are better than <span id="S5.SS2.p1.1.5" class="ltx_text ltx_font_italic">baselines</span> counterparts.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p"><a href="#S5.F7" title="In 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">7</span></a> displays a query image <a href="#S5.F7.sf1" title="Fig. 7(a) â€£ Fig. 7 â€£ 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a> along with the top-5 ranked retrievals for the six different evaluated models. It can be observed that the tuned and the styled-tuned models outperform the baseline and the styled models.
<a href="#S5.F7" title="In 5.1 Experimental Setup â€£ 5 Pose-Based Retrieval â€£ Enhancing Human Pose Estimation in Ancient Vase Paintings via Perceptually-grounded Style Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">7</span></a> row 1 shows poor retrieval results for the baseline model. For a pursuit scene, the first two retrieved samples belong to a wrestling scene while the last 2 belong to leading of the bride scene.
The styled model (row 2) is already better wherein all the five retrievals belong to the pursuit scene, however at a character level, it retrieves a persecutor at the <span id="S5.SS2.p2.1.1" class="ltx_ERROR undefined">\nth</span>5 retrieval.
Tuned (row 3) and <em id="S5.SS2.p2.1.2" class="ltx_emph ltx_font_italic">styled-tuned</em> (row 4-6) models perform similarly well. On a close look, we see that the <span id="S5.SS2.p2.1.3" class="ltx_ERROR undefined">\nth</span>2 and <span id="S5.SS2.p2.1.4" class="ltx_ERROR undefined">\nth</span>4 retrieved samples of the <em id="S5.SS2.p2.1.5" class="ltx_emph ltx_font_italic">styled-tuned</em> model are closer to the query sample compared to the tuned model.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We presented a 2-step training approach to using style transfer and transfer learning in combination with perceptual consistency for enhancing pose estimation in ancient Greek vase paintings. We show that using styled transfer learning as a domain adaptation technique for such data significantly improves the performance of state-of-the-art pose estimation models on unlabelled data byÂ 6% mean average precision (mAP) as well as mean average recall (mAR). We also analysed the impact of styles as progressive learning in a comprehensive manner showing that models do learn generic domain styles. We showed experimentally that our proposed method outperforms their counterparts for human pose estimation. Finally, we also show that our method can be used for pose-based image retrieval and discovery of similar, relevant poses and corresponding scenes in collections such as ancient Greek vase paintings. In general, our method shows potential and can be applied to diverse unlabelled datasets without explicit supervised learning. Additionally, with a modest number of annotations and enforcing perceptual consistency, our method can achieve performance improvement. Subsequently, our method provides a way for exploring diverse cross domain datasets with low or no labels using human poses as a tool.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Optuna: A next-generation hyperparameter optimization framework.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery &amp; Data Mining</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, pages 2623â€“2631, 2019.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
ColleenÂ M. Becker.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Aby warburgâ€™s pathosformel as methodological paradigm.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The Journal of Art Historiography</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, 9, 2013.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Peter Bell and Leonardo Impett.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Ikonographie und interaktion. computergestÃ¼tzte analyse von posen
in bildern der heilsgeschichte.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Das Mittelalter</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 24(1):31â€“53, 2019.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Realtime multi-person 2d pose estimation using part affinity fields.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 7291â€“7299, 2017.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Gustavo Carneiro, NunoÂ Pinho DaÂ Silva, Alessio DelÂ Bue, and JoÃ£oÂ Paulo
Costeira.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Artistic image classification: An analysis on the printart database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European conference on computer vision</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, pages 143â€“157.
Springer, 2012.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Joao Carreira, Pulkit Agrawal, Katerina Fragkiadaki, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Human pose estimation with iterative error feedback.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 4733â€“4742, 2016.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Yilun Chen, Zhicheng Wang, Yuxiang Peng, Zhiqiang Zhang, Gang Yu, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Cascaded pyramid network for multi-person pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 7103â€“7112, 2018.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Elliot Crowley and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">The state of the art: Object retrieval in paintings using
discriminative regions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">British Machine Vision Conference, BMVC 2014, Nottingham,
UK, September 1-5, 2014</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">. BMVA Press, 2014.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Weijian Deng, Liang Zheng, Qixiang Ye, Guoliang Kang, Yi Yang, and Jianbin
Jiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Image-image domain adaptation with preserved self-similarity and
domain-dissimilarity for person re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, pages 994â€“1003, 2018.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Hao-Shu Fang, Shuqin Xie, Yu-Wing Tai, and Cewu Lu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Rmpe: Regional multi-person pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, pages 2334â€“2343, 2017.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
LeonÂ A Gatys, AlexanderÂ S Ecker, and Matthias Bethge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Image style transfer using convolutional neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 2414â€“2423, 2016.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Fast r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages 1440â€“1448, 2015.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Rich feature hierarchies for accurate object detection and semantic
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 580â€“587, 2014.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Luca Giuliani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Bild und Mythos: Geschichte der BilderzÃ¤hlung in der
griechischen Kunst</span><span id="bib.bib14.3.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.4.1" class="ltx_text" style="font-size:90%;">CH Beck, 2003.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Peter Hall, Hongping Cai, Qi Wu, and Tadeo Corradi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Cross-depiction problem: Recognition and synthesis of photographs and
artwork.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computational Visual Media</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, 1(2):91â€“103, Jun 2015.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 770â€“778, 2016.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Gao Huang, Zhuang Liu, Laurens Van DerÂ Maaten, and KilianÂ Q Weinberger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Densely connected convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 4700â€“4708, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Xun Huang and Serge Belongie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Arbitrary style transfer in real-time with adaptive instance
normalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 1501â€“1510, 2017.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Leonardo Impett and Franco Moretti.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Totentanz. operationalizing aby warburgâ€™s pathosformeln.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">Technical report, Stanford Literary Lab, 2017.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Naoto Inoue, Ryosuke Furuta, Toshihiko Yamasaki, and Kiyoharu Aizawa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Cross-domain weakly-supervised object detection through progressive
domain adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 5001â€“5009, 2018.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Eldar Insafutdinov, Leonid Pishchulin, Bjoern Andres, Mykhaylo Andriluka, and
Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Deepercut: A deeper, stronger, and faster multi-person pose
estimation model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 34â€“50.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Tomas Jenicek and OndÅ™ej Chum.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Linking art through human poses.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 International Conference on Document Analysis and
Recognition (ICDAR)</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, pages 1338â€“1345. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
CÂ Richard Johnson, Ella Hendriks, IgorÂ J Berezhnoy, Eugene Brevdo, ShannonÂ M
Hughes, Ingrid Daubechies, Jia Li, Eric Postma, and JamesÂ Z Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Image processing for artist identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Signal Processing Magazine</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 25(4):37â€“48, 2008.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Justin Johnson, Alexandre Alahi, and Li Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Perceptual Losses for Real-Time Style Transfer and
Super-Resolution.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling, editors,
</span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision â€“ ECCV 2016</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, volume 9906, pages
694â€“711. Springer International Publishing, Cham, 2016.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
DiederikÂ P Kingma and JimmyÂ Lei Ba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Adam: A method for stochastic gradient descent.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR: International Conference on Learning Representations</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">,
2015.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Yijun Li, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, and Ming-Hsuan Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Universal style transfer via feature transforms.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages
386â€“396, 2017.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr DollÃ¡r, and CÂ Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European conference on computer vision</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, pages 740â€“755.
Springer, 2014.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Prathmesh Madhu, Ronak Kosti, Lara MÃ¼hrenberg, Peter Bell, Andreas Maier,
and Vincent Christlein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Recognizing characters in art history using deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 1st Workshop on Structuring and
Understanding of Multimedia heritAge Contents</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, pages 15â€“22, 2019.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
TimothyÂ John McNiven.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Gestures in attic vase painting: use and meaning, 550-450 bc.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">1983.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Thomas Mensink and Jan VanÂ Gemert.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">The rijksmuseum challenge: Museum-centered visual recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of International Conference on Multimedia
Retrieval</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages 451â€“454, 2014.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Gyeongsik Moon, JuÂ Yong Chang, and KyoungÂ Mu Lee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Posefix: Model-agnostic general human pose refinement network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Ramakant Nevatia and ThomasÂ O Binford.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Description and recognition of curved objects.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Artificial intelligence</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:90%;">, 8(1):77â€“98, 1977.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Alejandro Newell, Kaiyu Yang, and Jia Deng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Stacked hourglass networks for human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European conference on computer vision</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, pages 483â€“499.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
George Papandreou, Tyler Zhu, Nori Kanazawa, Alexander Toshev, Jonathan
Tompson, Chris Bregler, and Kevin Murphy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Towards accurate multi-person pose estimation in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 4903â€“4911, 2017.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo
Andriluka, PeterÂ V Gehler, and Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Deepcut: Joint subset partition and labeling for multi person pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 4929â€“4937, 2016.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Faster r-cnn: Towards real-time object detection with region proposal
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, pages
91â€“99, 2015.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
AL Rodriguez and K Mikolajczyk.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Domain adaptation for object detection via style consistency.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">BMVC</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Babak Saleh and Ahmed Elgammal.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Large-scale classification of fine-art paintings: Learning the right
metric on the right feature.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International Journal for Digital Art History</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, (2), 2015.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Benoit Seguin, Lisandra Costiner, Isabella di Lenardo, and FrÃ©dÃ©ric
Kaplan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">New techniques for the digitization of art historical photographic
archives-the case of the cini foundation in venice.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Archiving Conference</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, numberÂ 1 in 2018, pages 1â€“5. Society
for Imaging Science and Technology, 2018.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">
Mark Stansbury-Oâ€™Donnell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.4.1" class="ltx_text" style="font-size:90%;">Structural differentiation of pursuit scenes.
</span>
</span>
<span class="ltx_bibblock"><math id="bib.bib40.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="bib.bib40.1.m1.1a"><mi mathsize="90%" id="bib.bib40.1.m1.1.1" xref="bib.bib40.1.m1.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="bib.bib40.1.m1.1b"><ci id="bib.bib40.1.m1.1.1.cmml" xref="bib.bib40.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib40.1.m1.1c">\sigma</annotation></semantics></math><math id="bib.bib40.2.m2.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="bib.bib40.2.m2.1a"><mi mathsize="90%" id="bib.bib40.2.m2.1.1" xref="bib.bib40.2.m2.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="bib.bib40.2.m2.1b"><ci id="bib.bib40.2.m2.1.1.cmml" xref="bib.bib40.2.m2.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib40.2.m2.1c">\tau</annotation></semantics></math><span id="bib.bib40.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">o: Yatromanolakis</span><span id="bib.bib40.6.2" class="ltx_text" style="font-size:90%;">, pages 341â€“372, 2009.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Deep high-resolution representation learning for human pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, pages 5693â€“5703, 2019.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
JonathanÂ J Tompson, Arjun Jain, Yann LeCun, and Christoph Bregler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Joint training of a convolutional network and a graphical model for
human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:90%;">, pages
1799â€“1807, 2014.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Alexander Toshev and Christian Szegedy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Deeppose: Human pose estimation via deep neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">, pages 1653â€“1660, 2014.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Shih-En Wei, Varun Ramakrishna, Takeo Kanade, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Convolutional pose machines.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:90%;">, pages 4724â€“4732, 2016.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Bin Xiao, Haiping Wu, and Yichen Wei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Simple baselines for human pose estimation and tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European conference on computer vision
(ECCV)</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">, pages 466â€“481, 2018.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2012.05615" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2012.05616" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2012.05616">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2012.05616" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2012.05617" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  9 04:41:26 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
