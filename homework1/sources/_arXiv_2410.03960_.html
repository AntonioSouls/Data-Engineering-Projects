<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation</title>
<!--Generated on Fri Oct  4 22:46:28 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.03960v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S1" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S2" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>SwiftKV: Design and Implementation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.SS1" title="In 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Preliminaries</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.SS2" title="In 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>SingleInputKV: Project KV cache from a single layer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.SS3" title="In 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>AcrossKV: Sharing KV cache for consecutive layers</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.SS4" title="In 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Knowledge Recovery</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.SS5" title="In 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Optimized Implementation for Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Main Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.SS1" title="In 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.SS2" title="In 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Model Quality with Compression</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.SS3" title="In 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Inference Performance</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Ablation and Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.SS1" title="In 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>The impact of distillation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.SS2" title="In 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Full model training vs. partial model training.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.SS3" title="In 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>The impact of fine-tuning datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.SS4" title="In 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Combining with other KV cache compression methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.SS5" title="In 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Simple Early Exit for Decoding Tokens</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S6" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A1" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Additional Motivation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A2" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Calculating Computation Reduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Experimental Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3.SS1" title="In Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Training and evaluation details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3.SS2" title="In Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Inference Speedup Evaluation Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3.SS2.SSS0.Px1" title="In C.2 Inference Speedup Evaluation Details ‣ Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title">Hardware Details.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3.SS2.SSS0.Px2" title="In C.2 Inference Speedup Evaluation Details ‣ Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title">vLLM Configuration.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3.SS2.SSS0.Px3" title="In C.2 Inference Speedup Evaluation Details ‣ Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title">Llama-3.1-8B Latency Evaluation.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A4" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Inter-layer AcrossKV vs Intra-Layer KV cache Reduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A5" title="In SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Early Exit Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A5.SS1" title="In Appendix E Early Exit Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Early Exit Examples</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\useunder</span>
<p class="ltx_p" id="p1.2"><span class="ltx_text ltx_ulem_uline" id="p1.2.1"></span><span class="ltx_text ltx_framed ltx_framed_underline" id="p1.2.2"></span>
</p>
</div>
<h1 class="ltx_title ltx_title_document">SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Aurick Qiao &amp;Zhewei Yao &amp;Samyam Rajbhandari &amp;Yuxiong He
</span><span class="ltx_author_notes">Aurick – model design &amp; implementation, inference optimization, main results. Zhewei – model design, main results &amp; ablations. Samyam – core idea &amp; direction, project leadership. Yuxiong – project leadership.</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.1.id1">{aurick.qiao,zhewei.yao,samyam.rajbhandari,yuxiong.he}@snowflake.com</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break"/>Snowflake AI Research
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.2">LLM inference for popular enterprise use cases, such as summarization, RAG, and code-generation, typically observes orders of magnitude longer prompt lengths than generation lengths.
This characteristic leads to high cost of prefill and increased response latency.
In this paper, we present SwiftKV, a novel model transformation and distillation procedure specifically designed to reduce the time and cost of processing prompt tokens while preserving high quality of generated tokens.
SwiftKV combines three key mechanisms: i) SingleInputKV, which prefills later layers’ KV cache using a much earlier layer’s output, allowing prompt tokens to skip much of the model computation,
ii) AcrossKV, which merges the KV caches of neighboring layers to reduce the memory footprint and support larger batch size for higher throughput,
and iii) a knowledge-preserving distillation procedure that can adapt existing LLMs for SwiftKV with minimal accuracy impact and low compute and data requirement.
For Llama-3.1-8B and 70B, SwiftKV reduces the compute requirement of prefill by 50% and the memory requirement of the KV cache by 62.5% while incurring minimum quality degradation across a wide range of tasks.
In the end-to-end inference serving using an optimized vLLM implementation, SwiftKV realizes up to <math alttext="2\times" class="ltx_math_unparsed" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1b"><mn id="id1.1.m1.1.1">2</mn><mo id="id1.1.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="id1.1.m1.1c">2\times</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">2 ×</annotation></semantics></math> higher aggregate throughput and 60% lower time per output token.
It can achieve a staggering 560 TFlops/GPU of normalized inference throughput, which translates to 16K tokens/s for Llama-3.1-70B in 16-bit precision on 4<math alttext="\times" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><mo id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><times id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">×</annotation></semantics></math> H100 GPUs.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large Language Models (LLMs) are quickly becoming an integral enabler of enterprise applications and offerings, including code and data co-pilots <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib8" title="">2021</a>; Pourreza &amp; Rafiei, <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib38" title="">2024</a>)</cite>, retrieval augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib26" title="">2020</a>; Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib28" title="">2024</a>)</cite>, summarization <cite class="ltx_cite ltx_citemacro_citep">(Pu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib39" title="">2023</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib56" title="">2024</a>)</cite>, and agentic workflows <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib50" title="">2024</a>; Schick et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib41" title="">2023</a>)</cite>. While it is clear that LLMs can add value to these applications, the cost and speed of inference determine their practicality. Therefore, improving the aggregate throughput and reducing latency of LLM inference has become an increasingly important topic of interest, with various efforts (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S2" title="2 Related Work ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">2</span></a>) tackling the problem from multiple angles.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In this paper, we take a unique approach to improving LLM inference for enterprise applications based on the key observation that typical enterprise workloads process many more input tokens than output tokens. For example, tasks like code completion, text-to-SQL, summarization and RAG each submit long prompts but produce a small number of generated tokens, and a majority of enterprise LLM use cases in Snowflake incur a 10:1 ratio between prompt and generated tokens.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Based on this observation, we designed <em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">SwiftKV</em>, which improves throughput and latency by: i) reducing the computation required to pre-fill the KV cache for input tokens, and ii) enabling memory savings to support larger batch sizes needed to serve LLMs more cost effectively <cite class="ltx_cite ltx_citemacro_citep">(Sheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib43" title="">2023</a>; Pope et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib37" title="">2022</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib54" title="">2022</a>)</cite>. SwiftKV (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">1</span></a>) consists of four key components:</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="207" id="S1.F1.g1" src="x1.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
Illustration of SwiftKV with 50% SingleInputKV and 2-way AcrossKV. After distillation, the KV cache of layers 5–8 can all be populated using the hidden state outputs of layer 4. For prefill tokens, layers 5–8 may be skipped altogether, while decode tokens complete all layers. Existing models may be efficiently adapted for SwiftKV by distilling from the original unmodified model using a small dataset. Model knowledge is preserved by keeping the trainable parameters limited to the Q, K, and V projections of the layers affected by SingleInputKV.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text ltx_font_bold" id="S1.p4.1.1">SingleInputKV.</span> SingleInputKV rewires an existing model so that the pre-fill stage during inference can skip a number of later layers in the network, and their KV cache are computed by a single earlier layer. SingleInputKV is motivated by the observation that the output hidden states of the later transformer layers do not change significantly (see Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.SS2" title="3.2 SingleInputKV: Project KV cache from a single layer ‣ 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">3.2</span></a>, also independently discovered by <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib31" title="">2024c</a>)</cite>). With SingleInputKV, the computation required for pre-fill is reduced by approximately the number of layers skipped. We found that it is possible to skip at least 50% of the layers without significantly impacting the model quality (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.SS2" title="4.2 Model Quality with Compression ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4.2</span></a>), which translates to a 50% reduction of the pre-fill computation in inference.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_bold" id="S1.p5.1.1">AcrossKV.</span> While SingleInputKV reduces the pre-fill computation, it does not reduce the KV cache memory requirement. AcrossKV combines the KV projections from multiple adjacent layers into a single one, and share the KV cache across these layers to reduce its size in memory. AcrossKV allows significant memory savings, which unlocks higher throughput by enabling larger batches during inference. In Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3" title="3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">3</span></a>, we show that AcrossKV can reduce the KV cache size by 25% with less than a 1% quality gap. We also show in ablation studies (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5" title="5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5</span></a>) that AcrossKV is compatible with existing KV cache quantization methods, which combine to unlock 62.5% reduction in KV cache size.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text ltx_font_bold" id="S1.p6.1.1">Knowledge Recovery.</span> Although SingleInputKV and AcrossKV can be applied to existing LLMs with minimal changes to their architectures, we found that the resulting model parameters should still be adapted to the new architecture to recover their original prediction quality. This can be done via distillation from the original model. With SwiftKV, we found that a lightweight distillation is sufficient, with only a fraction of the model (Q, K, and V projections of the affected layers) trained on 680M tokens, which takes less than 3 hours on a single <math alttext="8\times" class="ltx_math_unparsed" display="inline" id="S1.p6.1.m1.1"><semantics id="S1.p6.1.m1.1a"><mrow id="S1.p6.1.m1.1b"><mn id="S1.p6.1.m1.1.1">8</mn><mo id="S1.p6.1.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">8\times</annotation><annotation encoding="application/x-llamapun" id="S1.p6.1.m1.1d">8 ×</annotation></semantics></math> H100 node for Llama-3.1-8B.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><span class="ltx_text ltx_font_bold" id="S1.p7.1.1">SwiftKV Optimized Inference.</span> To realize the computation and memory reductions of SingleInputKV and AcrossKV into end-to-end throughput and latency improvements, we implemented SwiftKV in vLLM <cite class="ltx_cite ltx_citemacro_citep">(Kwon et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib24" title="">2023</a>)</cite>. Our implementation includes several additional optimizations, including fusing all KV-projections beyond layer <math alttext="l" class="ltx_Math" display="inline" id="S1.p7.1.m1.1"><semantics id="S1.p7.1.m1.1a"><mi id="S1.p7.1.m1.1.1" xref="S1.p7.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S1.p7.1.m1.1b"><ci id="S1.p7.1.m1.1.1.cmml" xref="S1.p7.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S1.p7.1.m1.1d">italic_l</annotation></semantics></math> into a single GEMM operation, and integrated memory management needed to lower the KV cache memory footprint achievable via AcrossKV.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">SwiftKV increases the aggregate throughput of enterprise workloads by up to <math alttext="2\times" class="ltx_math_unparsed" display="inline" id="S1.p8.1.m1.1"><semantics id="S1.p8.1.m1.1a"><mrow id="S1.p8.1.m1.1b"><mn id="S1.p8.1.m1.1.1">2</mn><mo id="S1.p8.1.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S1.p8.1.m1.1c">2\times</annotation><annotation encoding="application/x-llamapun" id="S1.p8.1.m1.1d">2 ×</annotation></semantics></math>, while reducing time-to-first-token (TTFT) and time-per-output-token (TPOT) by up to 50% and 60%, respectively. In fact, for Llama-3.1-70B, SwiftKV can achieve a normalized throughput of 560 TFLops/GPU<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Normalized throughput and MFU is based on number of floating point operations in the baseline model.</span></span></span>. This is an unprecedented 56.6% MFU utilization for inference (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.SS3" title="4.3 Inference Performance ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4.3</span></a>). We show that SwiftKV incurs minimal quality degradation averaged across a wide range of tasks (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.SS2" title="4.2 Model Quality with Compression ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4.2</span></a>), including ARC-Challenge <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib9" title="">2018</a>)</cite>, Winogrande <cite class="ltx_cite ltx_citemacro_citep">(Sakaguchi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib40" title="">2019</a>)</cite>, HellaSwag <cite class="ltx_cite ltx_citemacro_citep">(Zellers et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib55" title="">2019</a>)</cite>, TruthfulQA <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib27" title="">2022</a>)</cite>, MMLU <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib18" title="">2021</a>)</cite>, and GSM8K <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib10" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">In addition to these main results, in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5" title="5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5</span></a> we discuss the impact of distillation, datasets, choice of trainable parameters for training SwiftKV. We also present our analysis of the hidden state similarities, and how AcrossKV can be extended and combined with other KV cache compression works. Additionally, we also discuss how SingleInputKV can enable compute savings not just during pre-fill but also during decoding phase.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Hardware and System Optimizations.</span> Lower-precision quantization techniques like FP8 <cite class="ltx_cite ltx_citemacro_citep">(Kuzmin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib23" title="">2024</a>)</cite> can enable the use of tensor-cores to accelerate inference <cite class="ltx_cite ltx_citemacro_citep">(Luo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib33" title="">2024</a>)</cite>. System approaches like PagedAttention <cite class="ltx_cite ltx_citemacro_citep">(Kwon et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib24" title="">2023</a>)</cite>, Tensor-Parallelism<cite class="ltx_cite ltx_citemacro_citep">(Shoeybi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib44" title="">2020</a>)</cite>, Split-Fuse <cite class="ltx_cite ltx_citemacro_citep">(Holmes et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib20" title="">2024</a>; Agrawal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib1" title="">2024</a>)</cite>, Flash Attention <cite class="ltx_cite ltx_citemacro_citep">(Dao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib11" title="">2024</a>)</cite>, and their optimized implementations in TensorRT <cite class="ltx_cite ltx_citemacro_citep">(NVIDIA, <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib35" title="">2019</a>)</cite>, FasterTransformer <cite class="ltx_cite ltx_citemacro_citep">(NVIDIA, <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib36" title="">2021</a>)</cite>, vLLM <cite class="ltx_cite ltx_citemacro_citep">(Kwon et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib24" title="">2023</a>)</cite>, and DeepSpeed-Inference <cite class="ltx_cite ltx_citemacro_citep">(Aminabadi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib4" title="">2022</a>)</cite> enable better parallelization, batching, and scheduling to eliminate performance overheads and achieve better hardware peak utilization without impacting model quality.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Memory Compression.</span> A wide range of techniques have been developed to reduce the memory footprint for inference. Lower-precision quantization techniques like FP8/FP4 can reduce the memory footprint for both KV cache and parameters <cite class="ltx_cite ltx_citemacro_citep">(Hooper et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib21" title="">2024</a>)</cite>. Attention optimization techniques like MQA <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib42" title="">2019</a>)</cite>, GQA <cite class="ltx_cite ltx_citemacro_citep">(Ainslie et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib3" title="">2023b</a>)</cite>, low-rank attention <cite class="ltx_cite ltx_citemacro_citep">(Chang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib7" title="">2024</a>)</cite> also reduce the KV Cache. All of these approaches are complementary to SwiftKV.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Similar to our work AcrossKV, MiniCache (<cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib30" title="">2024b</a>)</cite>) reduces KV Cache by consolidating adjacent layers of KV cache. While both consolidate KV cache across adjacent layers, AcrossKV enables consolidating more than just two layers, allowing for higher level of compression. Furthermore, due to the distillation based fine-tuning, AcrossKV does not require any token retention strategy where distinct KV caches are stored for special tokens even for consolidated layers. The simplicity of AcrossKV makes it easier to translate the KV cache savings into real world performance improvements.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p4">
<p class="ltx_p" id="S2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.p4.1.1">Other Inference Optimizations.</span>
Speculative Decoding based approaches (<cite class="ltx_cite ltx_citemacro_cite">Cai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib6" title="">2024</a>); Xia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib52" title="">2024</a>)</cite>) reduce the number of decoding steps to speed up the generation phase of inference, but it does not reduce prefill computation. Model distillation techniques (e.g., <cite class="ltx_cite ltx_citemacro_cite">Sreenivas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib45" title="">2024</a>)</cite>) transfer the knowledge of a large teacher model into a smaller student model, reducing inference computation by decreasing the number of parameters. However, these methods require significant retraining over long token horizons, and typically incur a significant quality degradation from the teacher to the student model.
In contrast, SwiftKV reduces the computation of the model, not its number of parameters, by approximating the KV cache of later layers, and aims to fully recover the model performance using distillation. Moreover, it requires minimal training resources including compute and data.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>SwiftKV: Design and Implementation</h2>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="317" id="S3.F2.g1" src="x2.png" width="423"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="220" id="S3.F2.g2" src="x3.png" width="233"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
LEFT: the input similarity of several smaller scale models (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A1.F1" title="Figure A.1 ‣ Appendix A Additional Motivation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">A.1</span></a> in the Appendix shows a similar observation for larger models). RIGHT: The time per forward pass of Llama-3.1-8B. SingleInputKV effectively reduces the forward pass processing time across a range of batch sizes.
</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Preliminaries</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.12">In transformer models <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib49" title="">2017</a>)</cite>, attention enables each token to focus on other tokens by comparing <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.12.1">queries</em> (<math alttext="Q" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_Q</annotation></semantics></math>) with <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.12.2">keys</em> (<math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_K</annotation></semantics></math>) and using <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.12.3">values</em> (<math alttext="V" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_V</annotation></semantics></math>) to compute the final representation. For a sequence of input tokens <math alttext="x^{(1)},\dots,x^{(n)}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.5"><semantics id="S3.SS1.p1.4.m4.5a"><mrow id="S3.SS1.p1.4.m4.5.5.2" xref="S3.SS1.p1.4.m4.5.5.3.cmml"><msup id="S3.SS1.p1.4.m4.4.4.1.1" xref="S3.SS1.p1.4.m4.4.4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.4.4.1.1.2" xref="S3.SS1.p1.4.m4.4.4.1.1.2.cmml">x</mi><mrow id="S3.SS1.p1.4.m4.1.1.1.3" xref="S3.SS1.p1.4.m4.4.4.1.1.cmml"><mo id="S3.SS1.p1.4.m4.1.1.1.3.1" stretchy="false" xref="S3.SS1.p1.4.m4.4.4.1.1.cmml">(</mo><mn id="S3.SS1.p1.4.m4.1.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.1.cmml">1</mn><mo id="S3.SS1.p1.4.m4.1.1.1.3.2" stretchy="false" xref="S3.SS1.p1.4.m4.4.4.1.1.cmml">)</mo></mrow></msup><mo id="S3.SS1.p1.4.m4.5.5.2.3" xref="S3.SS1.p1.4.m4.5.5.3.cmml">,</mo><mi id="S3.SS1.p1.4.m4.3.3" mathvariant="normal" xref="S3.SS1.p1.4.m4.3.3.cmml">…</mi><mo id="S3.SS1.p1.4.m4.5.5.2.4" xref="S3.SS1.p1.4.m4.5.5.3.cmml">,</mo><msup id="S3.SS1.p1.4.m4.5.5.2.2" xref="S3.SS1.p1.4.m4.5.5.2.2.cmml"><mi id="S3.SS1.p1.4.m4.5.5.2.2.2" xref="S3.SS1.p1.4.m4.5.5.2.2.2.cmml">x</mi><mrow id="S3.SS1.p1.4.m4.2.2.1.3" xref="S3.SS1.p1.4.m4.5.5.2.2.cmml"><mo id="S3.SS1.p1.4.m4.2.2.1.3.1" stretchy="false" xref="S3.SS1.p1.4.m4.5.5.2.2.cmml">(</mo><mi id="S3.SS1.p1.4.m4.2.2.1.1" xref="S3.SS1.p1.4.m4.2.2.1.1.cmml">n</mi><mo id="S3.SS1.p1.4.m4.2.2.1.3.2" stretchy="false" xref="S3.SS1.p1.4.m4.5.5.2.2.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.5b"><list id="S3.SS1.p1.4.m4.5.5.3.cmml" xref="S3.SS1.p1.4.m4.5.5.2"><apply id="S3.SS1.p1.4.m4.4.4.1.1.cmml" xref="S3.SS1.p1.4.m4.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.4.4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.4.4.1.1">superscript</csymbol><ci id="S3.SS1.p1.4.m4.4.4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.4.4.1.1.2">𝑥</ci><cn id="S3.SS1.p1.4.m4.1.1.1.1.cmml" type="integer" xref="S3.SS1.p1.4.m4.1.1.1.1">1</cn></apply><ci id="S3.SS1.p1.4.m4.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3">…</ci><apply id="S3.SS1.p1.4.m4.5.5.2.2.cmml" xref="S3.SS1.p1.4.m4.5.5.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.5.5.2.2.1.cmml" xref="S3.SS1.p1.4.m4.5.5.2.2">superscript</csymbol><ci id="S3.SS1.p1.4.m4.5.5.2.2.2.cmml" xref="S3.SS1.p1.4.m4.5.5.2.2.2">𝑥</ci><ci id="S3.SS1.p1.4.m4.2.2.1.1.cmml" xref="S3.SS1.p1.4.m4.2.2.1.1">𝑛</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.5c">x^{(1)},\dots,x^{(n)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.5d">italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , italic_x start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT</annotation></semantics></math>, the projections are defined as follows: <math alttext="Q=XW_{Q},\quad K=XW_{K},\quad V=XW_{V}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.2"><semantics id="S3.SS1.p1.5.m5.2a"><mrow id="S3.SS1.p1.5.m5.2.2.2" xref="S3.SS1.p1.5.m5.2.2.3.cmml"><mrow id="S3.SS1.p1.5.m5.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.1.1.2" xref="S3.SS1.p1.5.m5.1.1.1.1.2.cmml">Q</mi><mo id="S3.SS1.p1.5.m5.1.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.1.cmml">=</mo><mrow id="S3.SS1.p1.5.m5.1.1.1.1.3" xref="S3.SS1.p1.5.m5.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.1.1.3.2" xref="S3.SS1.p1.5.m5.1.1.1.1.3.2.cmml">X</mi><mo id="S3.SS1.p1.5.m5.1.1.1.1.3.1" xref="S3.SS1.p1.5.m5.1.1.1.1.3.1.cmml">⁢</mo><msub id="S3.SS1.p1.5.m5.1.1.1.1.3.3" xref="S3.SS1.p1.5.m5.1.1.1.1.3.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.1.1.3.3.2" xref="S3.SS1.p1.5.m5.1.1.1.1.3.3.2.cmml">W</mi><mi id="S3.SS1.p1.5.m5.1.1.1.1.3.3.3" xref="S3.SS1.p1.5.m5.1.1.1.1.3.3.3.cmml">Q</mi></msub></mrow></mrow><mo id="S3.SS1.p1.5.m5.2.2.2.3" rspace="1.167em" xref="S3.SS1.p1.5.m5.2.2.3a.cmml">,</mo><mrow id="S3.SS1.p1.5.m5.2.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.3.cmml"><mrow id="S3.SS1.p1.5.m5.2.2.2.2.1.1" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.2.1.1.2" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.2.cmml">K</mi><mo id="S3.SS1.p1.5.m5.2.2.2.2.1.1.1" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.1.cmml">=</mo><mrow id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.2" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.2.cmml">X</mi><mo id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.1" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.1.cmml">⁢</mo><msub id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.2" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.2.cmml">W</mi><mi id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.3" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.3.cmml">K</mi></msub></mrow></mrow><mo id="S3.SS1.p1.5.m5.2.2.2.2.2.3" rspace="1.167em" xref="S3.SS1.p1.5.m5.2.2.2.2.3a.cmml">,</mo><mrow id="S3.SS1.p1.5.m5.2.2.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.2.cmml">V</mi><mo id="S3.SS1.p1.5.m5.2.2.2.2.2.2.1" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.1.cmml">=</mo><mrow id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.2" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.2.cmml">X</mi><mo id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.1" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.1.cmml">⁢</mo><msub id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.2" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.2.cmml">W</mi><mi id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.3" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.3.cmml">V</mi></msub></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.2b"><apply id="S3.SS1.p1.5.m5.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.3a.cmml" xref="S3.SS1.p1.5.m5.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS1.p1.5.m5.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1"><eq id="S3.SS1.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1"></eq><ci id="S3.SS1.p1.5.m5.1.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.2">𝑄</ci><apply id="S3.SS1.p1.5.m5.1.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3"><times id="S3.SS1.p1.5.m5.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3.1"></times><ci id="S3.SS1.p1.5.m5.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3.2">𝑋</ci><apply id="S3.SS1.p1.5.m5.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.1.3.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.1.1.3.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3.3.2">𝑊</ci><ci id="S3.SS1.p1.5.m5.1.1.1.1.3.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3.3.3">𝑄</ci></apply></apply></apply><apply id="S3.SS1.p1.5.m5.2.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.2.2.3a.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS1.p1.5.m5.2.2.2.2.1.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1"><eq id="S3.SS1.p1.5.m5.2.2.2.2.1.1.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.1"></eq><ci id="S3.SS1.p1.5.m5.2.2.2.2.1.1.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.2">𝐾</ci><apply id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3"><times id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.1"></times><ci id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.2">𝑋</ci><apply id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.2">𝑊</ci><ci id="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.1.1.3.3.3">𝐾</ci></apply></apply></apply><apply id="S3.SS1.p1.5.m5.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2"><eq id="S3.SS1.p1.5.m5.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.1"></eq><ci id="S3.SS1.p1.5.m5.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.2">𝑉</ci><apply id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3"><times id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.1"></times><ci id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.2">𝑋</ci><apply id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.2">𝑊</ci><ci id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.3.3">𝑉</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.2c">Q=XW_{Q},\quad K=XW_{K},\quad V=XW_{V}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.2d">italic_Q = italic_X italic_W start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT , italic_K = italic_X italic_W start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT , italic_V = italic_X italic_W start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="X\in\mathbb{R}^{n\times d}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><mrow id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">X</mi><mo id="S3.SS1.p1.6.m6.1.1.1" xref="S3.SS1.p1.6.m6.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml"><mi id="S3.SS1.p1.6.m6.1.1.3.2" xref="S3.SS1.p1.6.m6.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.6.m6.1.1.3.3" xref="S3.SS1.p1.6.m6.1.1.3.3.cmml"><mi id="S3.SS1.p1.6.m6.1.1.3.3.2" xref="S3.SS1.p1.6.m6.1.1.3.3.2.cmml">n</mi><mo id="S3.SS1.p1.6.m6.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.6.m6.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.6.m6.1.1.3.3.3" xref="S3.SS1.p1.6.m6.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><in id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1"></in><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">𝑋</ci><apply id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.6.m6.1.1.3.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3"><times id="S3.SS1.p1.6.m6.1.1.3.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3.1"></times><ci id="S3.SS1.p1.6.m6.1.1.3.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3.2">𝑛</ci><ci id="S3.SS1.p1.6.m6.1.1.3.3.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">X\in\mathbb{R}^{n\times d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">italic_X ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> are the input embeddings, and <math alttext="W_{Q}\in\mathbb{R}^{d\times d_{k}}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><msub id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2.2" xref="S3.SS1.p1.7.m7.1.1.2.2.cmml">W</mi><mi id="S3.SS1.p1.7.m7.1.1.2.3" xref="S3.SS1.p1.7.m7.1.1.2.3.cmml">Q</mi></msub><mo id="S3.SS1.p1.7.m7.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml"><mi id="S3.SS1.p1.7.m7.1.1.3.2" xref="S3.SS1.p1.7.m7.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.7.m7.1.1.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.cmml"><mi id="S3.SS1.p1.7.m7.1.1.3.3.2" xref="S3.SS1.p1.7.m7.1.1.3.3.2.cmml">d</mi><mo id="S3.SS1.p1.7.m7.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.7.m7.1.1.3.3.1.cmml">×</mo><msub id="S3.SS1.p1.7.m7.1.1.3.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.3.cmml"><mi id="S3.SS1.p1.7.m7.1.1.3.3.3.2" xref="S3.SS1.p1.7.m7.1.1.3.3.3.2.cmml">d</mi><mi id="S3.SS1.p1.7.m7.1.1.3.3.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.3.3.cmml">k</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><in id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1"></in><apply id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.2.1.cmml" xref="S3.SS1.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2.2">𝑊</ci><ci id="S3.SS1.p1.7.m7.1.1.2.3.cmml" xref="S3.SS1.p1.7.m7.1.1.2.3">𝑄</ci></apply><apply id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.7.m7.1.1.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3"><times id="S3.SS1.p1.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.1"></times><ci id="S3.SS1.p1.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.2">𝑑</ci><apply id="S3.SS1.p1.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.3.3.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.3.3.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.3.2">𝑑</ci><ci id="S3.SS1.p1.7.m7.1.1.3.3.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">W_{Q}\in\mathbb{R}^{d\times d_{k}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">italic_W start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="W_{K},W_{V}\in\mathbb{R}^{d\times d_{g}}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.2"><semantics id="S3.SS1.p1.8.m8.2a"><mrow id="S3.SS1.p1.8.m8.2.2" xref="S3.SS1.p1.8.m8.2.2.cmml"><mrow id="S3.SS1.p1.8.m8.2.2.2.2" xref="S3.SS1.p1.8.m8.2.2.2.3.cmml"><msub id="S3.SS1.p1.8.m8.1.1.1.1.1" xref="S3.SS1.p1.8.m8.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.8.m8.1.1.1.1.1.2" xref="S3.SS1.p1.8.m8.1.1.1.1.1.2.cmml">W</mi><mi id="S3.SS1.p1.8.m8.1.1.1.1.1.3" xref="S3.SS1.p1.8.m8.1.1.1.1.1.3.cmml">K</mi></msub><mo id="S3.SS1.p1.8.m8.2.2.2.2.3" xref="S3.SS1.p1.8.m8.2.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.8.m8.2.2.2.2.2" xref="S3.SS1.p1.8.m8.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.8.m8.2.2.2.2.2.2" xref="S3.SS1.p1.8.m8.2.2.2.2.2.2.cmml">W</mi><mi id="S3.SS1.p1.8.m8.2.2.2.2.2.3" xref="S3.SS1.p1.8.m8.2.2.2.2.2.3.cmml">V</mi></msub></mrow><mo id="S3.SS1.p1.8.m8.2.2.3" xref="S3.SS1.p1.8.m8.2.2.3.cmml">∈</mo><msup id="S3.SS1.p1.8.m8.2.2.4" xref="S3.SS1.p1.8.m8.2.2.4.cmml"><mi id="S3.SS1.p1.8.m8.2.2.4.2" xref="S3.SS1.p1.8.m8.2.2.4.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.8.m8.2.2.4.3" xref="S3.SS1.p1.8.m8.2.2.4.3.cmml"><mi id="S3.SS1.p1.8.m8.2.2.4.3.2" xref="S3.SS1.p1.8.m8.2.2.4.3.2.cmml">d</mi><mo id="S3.SS1.p1.8.m8.2.2.4.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.8.m8.2.2.4.3.1.cmml">×</mo><msub id="S3.SS1.p1.8.m8.2.2.4.3.3" xref="S3.SS1.p1.8.m8.2.2.4.3.3.cmml"><mi id="S3.SS1.p1.8.m8.2.2.4.3.3.2" xref="S3.SS1.p1.8.m8.2.2.4.3.3.2.cmml">d</mi><mi id="S3.SS1.p1.8.m8.2.2.4.3.3.3" xref="S3.SS1.p1.8.m8.2.2.4.3.3.3.cmml">g</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.2b"><apply id="S3.SS1.p1.8.m8.2.2.cmml" xref="S3.SS1.p1.8.m8.2.2"><in id="S3.SS1.p1.8.m8.2.2.3.cmml" xref="S3.SS1.p1.8.m8.2.2.3"></in><list id="S3.SS1.p1.8.m8.2.2.2.3.cmml" xref="S3.SS1.p1.8.m8.2.2.2.2"><apply id="S3.SS1.p1.8.m8.1.1.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.1.1.1.2">𝑊</ci><ci id="S3.SS1.p1.8.m8.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.1.1.1.3">𝐾</ci></apply><apply id="S3.SS1.p1.8.m8.2.2.2.2.2.cmml" xref="S3.SS1.p1.8.m8.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.8.m8.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.8.m8.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.8.m8.2.2.2.2.2.2">𝑊</ci><ci id="S3.SS1.p1.8.m8.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.8.m8.2.2.2.2.2.3">𝑉</ci></apply></list><apply id="S3.SS1.p1.8.m8.2.2.4.cmml" xref="S3.SS1.p1.8.m8.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.2.2.4.1.cmml" xref="S3.SS1.p1.8.m8.2.2.4">superscript</csymbol><ci id="S3.SS1.p1.8.m8.2.2.4.2.cmml" xref="S3.SS1.p1.8.m8.2.2.4.2">ℝ</ci><apply id="S3.SS1.p1.8.m8.2.2.4.3.cmml" xref="S3.SS1.p1.8.m8.2.2.4.3"><times id="S3.SS1.p1.8.m8.2.2.4.3.1.cmml" xref="S3.SS1.p1.8.m8.2.2.4.3.1"></times><ci id="S3.SS1.p1.8.m8.2.2.4.3.2.cmml" xref="S3.SS1.p1.8.m8.2.2.4.3.2">𝑑</ci><apply id="S3.SS1.p1.8.m8.2.2.4.3.3.cmml" xref="S3.SS1.p1.8.m8.2.2.4.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.2.2.4.3.3.1.cmml" xref="S3.SS1.p1.8.m8.2.2.4.3.3">subscript</csymbol><ci id="S3.SS1.p1.8.m8.2.2.4.3.3.2.cmml" xref="S3.SS1.p1.8.m8.2.2.4.3.3.2">𝑑</ci><ci id="S3.SS1.p1.8.m8.2.2.4.3.3.3.cmml" xref="S3.SS1.p1.8.m8.2.2.4.3.3.3">𝑔</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.2c">W_{K},W_{V}\in\mathbb{R}^{d\times d_{g}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m8.2d">italic_W start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT , italic_W start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_d start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math> are trained model parameters with <math alttext="d_{g}|d_{k}" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m9.1"><semantics id="S3.SS1.p1.9.m9.1a"><mrow id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><msub id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2.2" xref="S3.SS1.p1.9.m9.1.1.2.2.cmml">d</mi><mi id="S3.SS1.p1.9.m9.1.1.2.3" xref="S3.SS1.p1.9.m9.1.1.2.3.cmml">g</mi></msub><mo fence="false" id="S3.SS1.p1.9.m9.1.1.1" xref="S3.SS1.p1.9.m9.1.1.1.cmml">|</mo><msub id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.3.2" xref="S3.SS1.p1.9.m9.1.1.3.2.cmml">d</mi><mi id="S3.SS1.p1.9.m9.1.1.3.3" xref="S3.SS1.p1.9.m9.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><csymbol cd="latexml" id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1">conditional</csymbol><apply id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.2.1.cmml" xref="S3.SS1.p1.9.m9.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.2.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2.2">𝑑</ci><ci id="S3.SS1.p1.9.m9.1.1.2.3.cmml" xref="S3.SS1.p1.9.m9.1.1.2.3">𝑔</ci></apply><apply id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.3.2">𝑑</ci><ci id="S3.SS1.p1.9.m9.1.1.3.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">d_{g}|d_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m9.1d">italic_d start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT | italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>. Hereafter, we may also refer to <math alttext="W_{K}" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m10.1"><semantics id="S3.SS1.p1.10.m10.1a"><msub id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml"><mi id="S3.SS1.p1.10.m10.1.1.2" xref="S3.SS1.p1.10.m10.1.1.2.cmml">W</mi><mi id="S3.SS1.p1.10.m10.1.1.3" xref="S3.SS1.p1.10.m10.1.1.3.cmml">K</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2">𝑊</ci><ci id="S3.SS1.p1.10.m10.1.1.3.cmml" xref="S3.SS1.p1.10.m10.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">W_{K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.10.m10.1d">italic_W start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="W_{V}" class="ltx_Math" display="inline" id="S3.SS1.p1.11.m11.1"><semantics id="S3.SS1.p1.11.m11.1a"><msub id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml"><mi id="S3.SS1.p1.11.m11.1.1.2" xref="S3.SS1.p1.11.m11.1.1.2.cmml">W</mi><mi id="S3.SS1.p1.11.m11.1.1.3" xref="S3.SS1.p1.11.m11.1.1.3.cmml">V</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b"><apply id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m11.1.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m11.1.1.2.cmml" xref="S3.SS1.p1.11.m11.1.1.2">𝑊</ci><ci id="S3.SS1.p1.11.m11.1.1.3.cmml" xref="S3.SS1.p1.11.m11.1.1.3">𝑉</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">W_{V}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.11.m11.1d">italic_W start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT</annotation></semantics></math> as a single matrix <math alttext="W_{KV}\in\mathbb{R}^{d\times 2d_{k}}" class="ltx_Math" display="inline" id="S3.SS1.p1.12.m12.1"><semantics id="S3.SS1.p1.12.m12.1a"><mrow id="S3.SS1.p1.12.m12.1.1" xref="S3.SS1.p1.12.m12.1.1.cmml"><msub id="S3.SS1.p1.12.m12.1.1.2" xref="S3.SS1.p1.12.m12.1.1.2.cmml"><mi id="S3.SS1.p1.12.m12.1.1.2.2" xref="S3.SS1.p1.12.m12.1.1.2.2.cmml">W</mi><mrow id="S3.SS1.p1.12.m12.1.1.2.3" xref="S3.SS1.p1.12.m12.1.1.2.3.cmml"><mi id="S3.SS1.p1.12.m12.1.1.2.3.2" xref="S3.SS1.p1.12.m12.1.1.2.3.2.cmml">K</mi><mo id="S3.SS1.p1.12.m12.1.1.2.3.1" xref="S3.SS1.p1.12.m12.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.12.m12.1.1.2.3.3" xref="S3.SS1.p1.12.m12.1.1.2.3.3.cmml">V</mi></mrow></msub><mo id="S3.SS1.p1.12.m12.1.1.1" xref="S3.SS1.p1.12.m12.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.12.m12.1.1.3" xref="S3.SS1.p1.12.m12.1.1.3.cmml"><mi id="S3.SS1.p1.12.m12.1.1.3.2" xref="S3.SS1.p1.12.m12.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.12.m12.1.1.3.3" xref="S3.SS1.p1.12.m12.1.1.3.3.cmml"><mrow id="S3.SS1.p1.12.m12.1.1.3.3.2" xref="S3.SS1.p1.12.m12.1.1.3.3.2.cmml"><mi id="S3.SS1.p1.12.m12.1.1.3.3.2.2" xref="S3.SS1.p1.12.m12.1.1.3.3.2.2.cmml">d</mi><mo id="S3.SS1.p1.12.m12.1.1.3.3.2.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.12.m12.1.1.3.3.2.1.cmml">×</mo><mn id="S3.SS1.p1.12.m12.1.1.3.3.2.3" xref="S3.SS1.p1.12.m12.1.1.3.3.2.3.cmml">2</mn></mrow><mo id="S3.SS1.p1.12.m12.1.1.3.3.1" xref="S3.SS1.p1.12.m12.1.1.3.3.1.cmml">⁢</mo><msub id="S3.SS1.p1.12.m12.1.1.3.3.3" xref="S3.SS1.p1.12.m12.1.1.3.3.3.cmml"><mi id="S3.SS1.p1.12.m12.1.1.3.3.3.2" xref="S3.SS1.p1.12.m12.1.1.3.3.3.2.cmml">d</mi><mi id="S3.SS1.p1.12.m12.1.1.3.3.3.3" xref="S3.SS1.p1.12.m12.1.1.3.3.3.3.cmml">k</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m12.1b"><apply id="S3.SS1.p1.12.m12.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1"><in id="S3.SS1.p1.12.m12.1.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1.1"></in><apply id="S3.SS1.p1.12.m12.1.1.2.cmml" xref="S3.SS1.p1.12.m12.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m12.1.1.2.1.cmml" xref="S3.SS1.p1.12.m12.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.12.m12.1.1.2.2.cmml" xref="S3.SS1.p1.12.m12.1.1.2.2">𝑊</ci><apply id="S3.SS1.p1.12.m12.1.1.2.3.cmml" xref="S3.SS1.p1.12.m12.1.1.2.3"><times id="S3.SS1.p1.12.m12.1.1.2.3.1.cmml" xref="S3.SS1.p1.12.m12.1.1.2.3.1"></times><ci id="S3.SS1.p1.12.m12.1.1.2.3.2.cmml" xref="S3.SS1.p1.12.m12.1.1.2.3.2">𝐾</ci><ci id="S3.SS1.p1.12.m12.1.1.2.3.3.cmml" xref="S3.SS1.p1.12.m12.1.1.2.3.3">𝑉</ci></apply></apply><apply id="S3.SS1.p1.12.m12.1.1.3.cmml" xref="S3.SS1.p1.12.m12.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m12.1.1.3.1.cmml" xref="S3.SS1.p1.12.m12.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.12.m12.1.1.3.2.cmml" xref="S3.SS1.p1.12.m12.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.12.m12.1.1.3.3.cmml" xref="S3.SS1.p1.12.m12.1.1.3.3"><times id="S3.SS1.p1.12.m12.1.1.3.3.1.cmml" xref="S3.SS1.p1.12.m12.1.1.3.3.1"></times><apply id="S3.SS1.p1.12.m12.1.1.3.3.2.cmml" xref="S3.SS1.p1.12.m12.1.1.3.3.2"><times id="S3.SS1.p1.12.m12.1.1.3.3.2.1.cmml" xref="S3.SS1.p1.12.m12.1.1.3.3.2.1"></times><ci id="S3.SS1.p1.12.m12.1.1.3.3.2.2.cmml" xref="S3.SS1.p1.12.m12.1.1.3.3.2.2">𝑑</ci><cn id="S3.SS1.p1.12.m12.1.1.3.3.2.3.cmml" type="integer" xref="S3.SS1.p1.12.m12.1.1.3.3.2.3">2</cn></apply><apply id="S3.SS1.p1.12.m12.1.1.3.3.3.cmml" xref="S3.SS1.p1.12.m12.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m12.1.1.3.3.3.1.cmml" xref="S3.SS1.p1.12.m12.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.12.m12.1.1.3.3.3.2.cmml" xref="S3.SS1.p1.12.m12.1.1.3.3.3.2">𝑑</ci><ci id="S3.SS1.p1.12.m12.1.1.3.3.3.3.cmml" xref="S3.SS1.p1.12.m12.1.1.3.3.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m12.1c">W_{KV}\in\mathbb{R}^{d\times 2d_{k}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.12.m12.1d">italic_W start_POSTSUBSCRIPT italic_K italic_V end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × 2 italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.2">During the <em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.2.1">prefill phase</em> of inference, the model processes the entire input sequence at once, computing <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_K</annotation></semantics></math> and <math alttext="V" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_V</annotation></semantics></math> for all tokens in parallel (or in chunks in the case of Split-Fuse <cite class="ltx_cite ltx_citemacro_citep">(Holmes et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib20" title="">2024</a>; Agrawal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib1" title="">2024</a>)</cite>). This typically occurs when the model handles an initial prompt or context.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.3">During the <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.3.1">decoding phase</em> of inference, new tokens are generated one at a time. When predicting the next token, only the query (<math alttext="Q^{(t+1)}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><msup id="S3.SS1.p3.1.m1.1.2" xref="S3.SS1.p3.1.m1.1.2.cmml"><mi id="S3.SS1.p3.1.m1.1.2.2" xref="S3.SS1.p3.1.m1.1.2.2.cmml">Q</mi><mrow id="S3.SS1.p3.1.m1.1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS1.p3.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p3.1.m1.1.1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.1.1.1.2.cmml">t</mi><mo id="S3.SS1.p3.1.m1.1.1.1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.p3.1.m1.1.1.1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS1.p3.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.2.1.cmml" xref="S3.SS1.p3.1.m1.1.2">superscript</csymbol><ci id="S3.SS1.p3.1.m1.1.2.2.cmml" xref="S3.SS1.p3.1.m1.1.2.2">𝑄</ci><apply id="S3.SS1.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1.1"><plus id="S3.SS1.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1.1.1.1"></plus><ci id="S3.SS1.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.1.1.1.2">𝑡</ci><cn id="S3.SS1.p3.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS1.p3.1.m1.1.1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">Q^{(t+1)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_Q start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT</annotation></semantics></math>) for the new token needs to be computed, while the model must attend to the keys and values (<math alttext="K^{(1)},\dots,K^{(t)}" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.5"><semantics id="S3.SS1.p3.2.m2.5a"><mrow id="S3.SS1.p3.2.m2.5.5.2" xref="S3.SS1.p3.2.m2.5.5.3.cmml"><msup id="S3.SS1.p3.2.m2.4.4.1.1" xref="S3.SS1.p3.2.m2.4.4.1.1.cmml"><mi id="S3.SS1.p3.2.m2.4.4.1.1.2" xref="S3.SS1.p3.2.m2.4.4.1.1.2.cmml">K</mi><mrow id="S3.SS1.p3.2.m2.1.1.1.3" xref="S3.SS1.p3.2.m2.4.4.1.1.cmml"><mo id="S3.SS1.p3.2.m2.1.1.1.3.1" stretchy="false" xref="S3.SS1.p3.2.m2.4.4.1.1.cmml">(</mo><mn id="S3.SS1.p3.2.m2.1.1.1.1" xref="S3.SS1.p3.2.m2.1.1.1.1.cmml">1</mn><mo id="S3.SS1.p3.2.m2.1.1.1.3.2" stretchy="false" xref="S3.SS1.p3.2.m2.4.4.1.1.cmml">)</mo></mrow></msup><mo id="S3.SS1.p3.2.m2.5.5.2.3" xref="S3.SS1.p3.2.m2.5.5.3.cmml">,</mo><mi id="S3.SS1.p3.2.m2.3.3" mathvariant="normal" xref="S3.SS1.p3.2.m2.3.3.cmml">…</mi><mo id="S3.SS1.p3.2.m2.5.5.2.4" xref="S3.SS1.p3.2.m2.5.5.3.cmml">,</mo><msup id="S3.SS1.p3.2.m2.5.5.2.2" xref="S3.SS1.p3.2.m2.5.5.2.2.cmml"><mi id="S3.SS1.p3.2.m2.5.5.2.2.2" xref="S3.SS1.p3.2.m2.5.5.2.2.2.cmml">K</mi><mrow id="S3.SS1.p3.2.m2.2.2.1.3" xref="S3.SS1.p3.2.m2.5.5.2.2.cmml"><mo id="S3.SS1.p3.2.m2.2.2.1.3.1" stretchy="false" xref="S3.SS1.p3.2.m2.5.5.2.2.cmml">(</mo><mi id="S3.SS1.p3.2.m2.2.2.1.1" xref="S3.SS1.p3.2.m2.2.2.1.1.cmml">t</mi><mo id="S3.SS1.p3.2.m2.2.2.1.3.2" stretchy="false" xref="S3.SS1.p3.2.m2.5.5.2.2.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.5b"><list id="S3.SS1.p3.2.m2.5.5.3.cmml" xref="S3.SS1.p3.2.m2.5.5.2"><apply id="S3.SS1.p3.2.m2.4.4.1.1.cmml" xref="S3.SS1.p3.2.m2.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.4.4.1.1.1.cmml" xref="S3.SS1.p3.2.m2.4.4.1.1">superscript</csymbol><ci id="S3.SS1.p3.2.m2.4.4.1.1.2.cmml" xref="S3.SS1.p3.2.m2.4.4.1.1.2">𝐾</ci><cn id="S3.SS1.p3.2.m2.1.1.1.1.cmml" type="integer" xref="S3.SS1.p3.2.m2.1.1.1.1">1</cn></apply><ci id="S3.SS1.p3.2.m2.3.3.cmml" xref="S3.SS1.p3.2.m2.3.3">…</ci><apply id="S3.SS1.p3.2.m2.5.5.2.2.cmml" xref="S3.SS1.p3.2.m2.5.5.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.5.5.2.2.1.cmml" xref="S3.SS1.p3.2.m2.5.5.2.2">superscript</csymbol><ci id="S3.SS1.p3.2.m2.5.5.2.2.2.cmml" xref="S3.SS1.p3.2.m2.5.5.2.2.2">𝐾</ci><ci id="S3.SS1.p3.2.m2.2.2.1.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1">𝑡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.5c">K^{(1)},\dots,K^{(t)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.5d">italic_K start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , italic_K start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="V^{(1)},\dots,V^{(t)}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.5"><semantics id="S3.SS1.p3.3.m3.5a"><mrow id="S3.SS1.p3.3.m3.5.5.2" xref="S3.SS1.p3.3.m3.5.5.3.cmml"><msup id="S3.SS1.p3.3.m3.4.4.1.1" xref="S3.SS1.p3.3.m3.4.4.1.1.cmml"><mi id="S3.SS1.p3.3.m3.4.4.1.1.2" xref="S3.SS1.p3.3.m3.4.4.1.1.2.cmml">V</mi><mrow id="S3.SS1.p3.3.m3.1.1.1.3" xref="S3.SS1.p3.3.m3.4.4.1.1.cmml"><mo id="S3.SS1.p3.3.m3.1.1.1.3.1" stretchy="false" xref="S3.SS1.p3.3.m3.4.4.1.1.cmml">(</mo><mn id="S3.SS1.p3.3.m3.1.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.1.cmml">1</mn><mo id="S3.SS1.p3.3.m3.1.1.1.3.2" stretchy="false" xref="S3.SS1.p3.3.m3.4.4.1.1.cmml">)</mo></mrow></msup><mo id="S3.SS1.p3.3.m3.5.5.2.3" xref="S3.SS1.p3.3.m3.5.5.3.cmml">,</mo><mi id="S3.SS1.p3.3.m3.3.3" mathvariant="normal" xref="S3.SS1.p3.3.m3.3.3.cmml">…</mi><mo id="S3.SS1.p3.3.m3.5.5.2.4" xref="S3.SS1.p3.3.m3.5.5.3.cmml">,</mo><msup id="S3.SS1.p3.3.m3.5.5.2.2" xref="S3.SS1.p3.3.m3.5.5.2.2.cmml"><mi id="S3.SS1.p3.3.m3.5.5.2.2.2" xref="S3.SS1.p3.3.m3.5.5.2.2.2.cmml">V</mi><mrow id="S3.SS1.p3.3.m3.2.2.1.3" xref="S3.SS1.p3.3.m3.5.5.2.2.cmml"><mo id="S3.SS1.p3.3.m3.2.2.1.3.1" stretchy="false" xref="S3.SS1.p3.3.m3.5.5.2.2.cmml">(</mo><mi id="S3.SS1.p3.3.m3.2.2.1.1" xref="S3.SS1.p3.3.m3.2.2.1.1.cmml">t</mi><mo id="S3.SS1.p3.3.m3.2.2.1.3.2" stretchy="false" xref="S3.SS1.p3.3.m3.5.5.2.2.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.5b"><list id="S3.SS1.p3.3.m3.5.5.3.cmml" xref="S3.SS1.p3.3.m3.5.5.2"><apply id="S3.SS1.p3.3.m3.4.4.1.1.cmml" xref="S3.SS1.p3.3.m3.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.4.4.1.1.1.cmml" xref="S3.SS1.p3.3.m3.4.4.1.1">superscript</csymbol><ci id="S3.SS1.p3.3.m3.4.4.1.1.2.cmml" xref="S3.SS1.p3.3.m3.4.4.1.1.2">𝑉</ci><cn id="S3.SS1.p3.3.m3.1.1.1.1.cmml" type="integer" xref="S3.SS1.p3.3.m3.1.1.1.1">1</cn></apply><ci id="S3.SS1.p3.3.m3.3.3.cmml" xref="S3.SS1.p3.3.m3.3.3">…</ci><apply id="S3.SS1.p3.3.m3.5.5.2.2.cmml" xref="S3.SS1.p3.3.m3.5.5.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.5.5.2.2.1.cmml" xref="S3.SS1.p3.3.m3.5.5.2.2">superscript</csymbol><ci id="S3.SS1.p3.3.m3.5.5.2.2.2.cmml" xref="S3.SS1.p3.3.m3.5.5.2.2.2">𝑉</ci><ci id="S3.SS1.p3.3.m3.2.2.1.1.cmml" xref="S3.SS1.p3.3.m3.2.2.1.1">𝑡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.5c">V^{(1)},\dots,V^{(t)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.5d">italic_V start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , italic_V start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT</annotation></semantics></math>) of all previously processed tokens.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.9">To optimize efficiency in the decoding phase, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p4.9.1">KV caching</em> is employed. After processing each token <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">italic_t</annotation></semantics></math>, the newly computed <math alttext="K^{(t)}" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><msup id="S3.SS1.p4.2.m2.1.2" xref="S3.SS1.p4.2.m2.1.2.cmml"><mi id="S3.SS1.p4.2.m2.1.2.2" xref="S3.SS1.p4.2.m2.1.2.2.cmml">K</mi><mrow id="S3.SS1.p4.2.m2.1.1.1.3" xref="S3.SS1.p4.2.m2.1.2.cmml"><mo id="S3.SS1.p4.2.m2.1.1.1.3.1" stretchy="false" xref="S3.SS1.p4.2.m2.1.2.cmml">(</mo><mi id="S3.SS1.p4.2.m2.1.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.1.cmml">t</mi><mo id="S3.SS1.p4.2.m2.1.1.1.3.2" stretchy="false" xref="S3.SS1.p4.2.m2.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.2.cmml" xref="S3.SS1.p4.2.m2.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.2.1.cmml" xref="S3.SS1.p4.2.m2.1.2">superscript</csymbol><ci id="S3.SS1.p4.2.m2.1.2.2.cmml" xref="S3.SS1.p4.2.m2.1.2.2">𝐾</ci><ci id="S3.SS1.p4.2.m2.1.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">K^{(t)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">italic_K start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="V^{(t)}" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.1"><semantics id="S3.SS1.p4.3.m3.1a"><msup id="S3.SS1.p4.3.m3.1.2" xref="S3.SS1.p4.3.m3.1.2.cmml"><mi id="S3.SS1.p4.3.m3.1.2.2" xref="S3.SS1.p4.3.m3.1.2.2.cmml">V</mi><mrow id="S3.SS1.p4.3.m3.1.1.1.3" xref="S3.SS1.p4.3.m3.1.2.cmml"><mo id="S3.SS1.p4.3.m3.1.1.1.3.1" stretchy="false" xref="S3.SS1.p4.3.m3.1.2.cmml">(</mo><mi id="S3.SS1.p4.3.m3.1.1.1.1" xref="S3.SS1.p4.3.m3.1.1.1.1.cmml">t</mi><mo id="S3.SS1.p4.3.m3.1.1.1.3.2" stretchy="false" xref="S3.SS1.p4.3.m3.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.2.cmml" xref="S3.SS1.p4.3.m3.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.2.1.cmml" xref="S3.SS1.p4.3.m3.1.2">superscript</csymbol><ci id="S3.SS1.p4.3.m3.1.2.2.cmml" xref="S3.SS1.p4.3.m3.1.2.2">𝑉</ci><ci id="S3.SS1.p4.3.m3.1.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">V^{(t)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.1d">italic_V start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT</annotation></semantics></math> are stored in a cache. For the next token <math alttext="t+1" class="ltx_Math" display="inline" id="S3.SS1.p4.4.m4.1"><semantics id="S3.SS1.p4.4.m4.1a"><mrow id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml"><mi id="S3.SS1.p4.4.m4.1.1.2" xref="S3.SS1.p4.4.m4.1.1.2.cmml">t</mi><mo id="S3.SS1.p4.4.m4.1.1.1" xref="S3.SS1.p4.4.m4.1.1.1.cmml">+</mo><mn id="S3.SS1.p4.4.m4.1.1.3" xref="S3.SS1.p4.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><apply id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1"><plus id="S3.SS1.p4.4.m4.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1.1"></plus><ci id="S3.SS1.p4.4.m4.1.1.2.cmml" xref="S3.SS1.p4.4.m4.1.1.2">𝑡</ci><cn id="S3.SS1.p4.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.p4.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">t+1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.4.m4.1d">italic_t + 1</annotation></semantics></math>, only the new query <math alttext="Q^{(t+1)}" class="ltx_Math" display="inline" id="S3.SS1.p4.5.m5.1"><semantics id="S3.SS1.p4.5.m5.1a"><msup id="S3.SS1.p4.5.m5.1.2" xref="S3.SS1.p4.5.m5.1.2.cmml"><mi id="S3.SS1.p4.5.m5.1.2.2" xref="S3.SS1.p4.5.m5.1.2.2.cmml">Q</mi><mrow id="S3.SS1.p4.5.m5.1.1.1.1" xref="S3.SS1.p4.5.m5.1.1.1.1.1.cmml"><mo id="S3.SS1.p4.5.m5.1.1.1.1.2" stretchy="false" xref="S3.SS1.p4.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p4.5.m5.1.1.1.1.1" xref="S3.SS1.p4.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS1.p4.5.m5.1.1.1.1.1.2" xref="S3.SS1.p4.5.m5.1.1.1.1.1.2.cmml">t</mi><mo id="S3.SS1.p4.5.m5.1.1.1.1.1.1" xref="S3.SS1.p4.5.m5.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.p4.5.m5.1.1.1.1.1.3" xref="S3.SS1.p4.5.m5.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS1.p4.5.m5.1.1.1.1.3" stretchy="false" xref="S3.SS1.p4.5.m5.1.1.1.1.1.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.2.cmml" xref="S3.SS1.p4.5.m5.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.2.1.cmml" xref="S3.SS1.p4.5.m5.1.2">superscript</csymbol><ci id="S3.SS1.p4.5.m5.1.2.2.cmml" xref="S3.SS1.p4.5.m5.1.2.2">𝑄</ci><apply id="S3.SS1.p4.5.m5.1.1.1.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1.1.1"><plus id="S3.SS1.p4.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1.1.1.1.1"></plus><ci id="S3.SS1.p4.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS1.p4.5.m5.1.1.1.1.1.2">𝑡</ci><cn id="S3.SS1.p4.5.m5.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS1.p4.5.m5.1.1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">Q^{(t+1)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.5.m5.1d">italic_Q start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT</annotation></semantics></math>, key <math alttext="K^{(t+1)}" class="ltx_Math" display="inline" id="S3.SS1.p4.6.m6.1"><semantics id="S3.SS1.p4.6.m6.1a"><msup id="S3.SS1.p4.6.m6.1.2" xref="S3.SS1.p4.6.m6.1.2.cmml"><mi id="S3.SS1.p4.6.m6.1.2.2" xref="S3.SS1.p4.6.m6.1.2.2.cmml">K</mi><mrow id="S3.SS1.p4.6.m6.1.1.1.1" xref="S3.SS1.p4.6.m6.1.1.1.1.1.cmml"><mo id="S3.SS1.p4.6.m6.1.1.1.1.2" stretchy="false" xref="S3.SS1.p4.6.m6.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p4.6.m6.1.1.1.1.1" xref="S3.SS1.p4.6.m6.1.1.1.1.1.cmml"><mi id="S3.SS1.p4.6.m6.1.1.1.1.1.2" xref="S3.SS1.p4.6.m6.1.1.1.1.1.2.cmml">t</mi><mo id="S3.SS1.p4.6.m6.1.1.1.1.1.1" xref="S3.SS1.p4.6.m6.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.p4.6.m6.1.1.1.1.1.3" xref="S3.SS1.p4.6.m6.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS1.p4.6.m6.1.1.1.1.3" stretchy="false" xref="S3.SS1.p4.6.m6.1.1.1.1.1.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m6.1b"><apply id="S3.SS1.p4.6.m6.1.2.cmml" xref="S3.SS1.p4.6.m6.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.6.m6.1.2.1.cmml" xref="S3.SS1.p4.6.m6.1.2">superscript</csymbol><ci id="S3.SS1.p4.6.m6.1.2.2.cmml" xref="S3.SS1.p4.6.m6.1.2.2">𝐾</ci><apply id="S3.SS1.p4.6.m6.1.1.1.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1.1.1"><plus id="S3.SS1.p4.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1.1.1.1.1"></plus><ci id="S3.SS1.p4.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS1.p4.6.m6.1.1.1.1.1.2">𝑡</ci><cn id="S3.SS1.p4.6.m6.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS1.p4.6.m6.1.1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m6.1c">K^{(t+1)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.6.m6.1d">italic_K start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT</annotation></semantics></math>, and value <math alttext="V^{(t+1)}" class="ltx_Math" display="inline" id="S3.SS1.p4.7.m7.1"><semantics id="S3.SS1.p4.7.m7.1a"><msup id="S3.SS1.p4.7.m7.1.2" xref="S3.SS1.p4.7.m7.1.2.cmml"><mi id="S3.SS1.p4.7.m7.1.2.2" xref="S3.SS1.p4.7.m7.1.2.2.cmml">V</mi><mrow id="S3.SS1.p4.7.m7.1.1.1.1" xref="S3.SS1.p4.7.m7.1.1.1.1.1.cmml"><mo id="S3.SS1.p4.7.m7.1.1.1.1.2" stretchy="false" xref="S3.SS1.p4.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p4.7.m7.1.1.1.1.1" xref="S3.SS1.p4.7.m7.1.1.1.1.1.cmml"><mi id="S3.SS1.p4.7.m7.1.1.1.1.1.2" xref="S3.SS1.p4.7.m7.1.1.1.1.1.2.cmml">t</mi><mo id="S3.SS1.p4.7.m7.1.1.1.1.1.1" xref="S3.SS1.p4.7.m7.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.p4.7.m7.1.1.1.1.1.3" xref="S3.SS1.p4.7.m7.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS1.p4.7.m7.1.1.1.1.3" stretchy="false" xref="S3.SS1.p4.7.m7.1.1.1.1.1.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m7.1b"><apply id="S3.SS1.p4.7.m7.1.2.cmml" xref="S3.SS1.p4.7.m7.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.7.m7.1.2.1.cmml" xref="S3.SS1.p4.7.m7.1.2">superscript</csymbol><ci id="S3.SS1.p4.7.m7.1.2.2.cmml" xref="S3.SS1.p4.7.m7.1.2.2">𝑉</ci><apply id="S3.SS1.p4.7.m7.1.1.1.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1.1.1"><plus id="S3.SS1.p4.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1.1.1.1.1"></plus><ci id="S3.SS1.p4.7.m7.1.1.1.1.1.2.cmml" xref="S3.SS1.p4.7.m7.1.1.1.1.1.2">𝑡</ci><cn id="S3.SS1.p4.7.m7.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS1.p4.7.m7.1.1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m7.1c">V^{(t+1)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.7.m7.1d">italic_V start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT</annotation></semantics></math> are computed. The attention computation will then utilize the cached <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p4.8.m8.1"><semantics id="S3.SS1.p4.8.m8.1a"><mi id="S3.SS1.p4.8.m8.1.1" xref="S3.SS1.p4.8.m8.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.8.m8.1b"><ci id="S3.SS1.p4.8.m8.1.1.cmml" xref="S3.SS1.p4.8.m8.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.8.m8.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.8.m8.1d">italic_K</annotation></semantics></math> and <math alttext="V" class="ltx_Math" display="inline" id="S3.SS1.p4.9.m9.1"><semantics id="S3.SS1.p4.9.m9.1a"><mi id="S3.SS1.p4.9.m9.1.1" xref="S3.SS1.p4.9.m9.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.9.m9.1b"><ci id="S3.SS1.p4.9.m9.1.1.cmml" xref="S3.SS1.p4.9.m9.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.9.m9.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.9.m9.1d">italic_V</annotation></semantics></math> from all prior tokens, allowing for reduced computational overhead during inference.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>SingleInputKV: Project KV cache from a single layer</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.5">Assume the input of <math alttext="l" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_l</annotation></semantics></math>-th layer is <math alttext="{\bf x}_{l}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">𝐱</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">𝐱</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">{\bf x}_{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math>, and its <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_i</annotation></semantics></math>-th token is <math alttext="{\bf x}_{l}^{(i)}" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><msubsup id="S3.SS2.p1.4.m4.1.2" xref="S3.SS2.p1.4.m4.1.2.cmml"><mi id="S3.SS2.p1.4.m4.1.2.2.2" xref="S3.SS2.p1.4.m4.1.2.2.2.cmml">𝐱</mi><mi id="S3.SS2.p1.4.m4.1.2.2.3" xref="S3.SS2.p1.4.m4.1.2.2.3.cmml">l</mi><mrow id="S3.SS2.p1.4.m4.1.1.1.3" xref="S3.SS2.p1.4.m4.1.2.cmml"><mo id="S3.SS2.p1.4.m4.1.1.1.3.1" stretchy="false" xref="S3.SS2.p1.4.m4.1.2.cmml">(</mo><mi id="S3.SS2.p1.4.m4.1.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p1.4.m4.1.1.1.3.2" stretchy="false" xref="S3.SS2.p1.4.m4.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.2.cmml" xref="S3.SS2.p1.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.2.1.cmml" xref="S3.SS2.p1.4.m4.1.2">superscript</csymbol><apply id="S3.SS2.p1.4.m4.1.2.2.cmml" xref="S3.SS2.p1.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.2.2.1.cmml" xref="S3.SS2.p1.4.m4.1.2">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.2.2.2.cmml" xref="S3.SS2.p1.4.m4.1.2.2.2">𝐱</ci><ci id="S3.SS2.p1.4.m4.1.2.2.3.cmml" xref="S3.SS2.p1.4.m4.1.2.2.3">𝑙</ci></apply><ci id="S3.SS2.p1.4.m4.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">{\bf x}_{l}^{(i)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math>.
Prior studies <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib31" title="">2024c</a>; Gromov et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib17" title="">2024</a>)</cite> showed that <math alttext="{\bf x}_{l}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.1"><semantics id="S3.SS2.p1.5.m5.1a"><msub id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">𝐱</mi><mi id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">𝐱</ci><ci id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">{\bf x}_{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.1d">bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> becomes more similar as the depth grows.
Here, we conduct a similar study.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">We compute the average input similarity between <math alttext="l" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_l</annotation></semantics></math>-th layer’s input and all remaining layers’ input, i.e.,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathrm{SimScore}({\bf x}_{l})=\frac{\sum_{j=l+1}^{L}\mathrm{Similarity}({\bf x%
}_{l},{\bf x}_{j})}{L-l}," class="ltx_Math" display="block" id="S3.E1.m1.3"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.3.cmml">SimScore</mi><mo id="S3.E1.m1.3.3.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.3.3.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.3.3.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S3.E1.m1.3.3.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml">=</mo><mfrac id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml"><msubsup id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.2.3.cmml"><mo id="S3.E1.m1.2.2.2.3.2.2" xref="S3.E1.m1.2.2.2.3.2.2.cmml">∑</mo><mrow id="S3.E1.m1.2.2.2.3.2.3" xref="S3.E1.m1.2.2.2.3.2.3.cmml"><mi id="S3.E1.m1.2.2.2.3.2.3.2" xref="S3.E1.m1.2.2.2.3.2.3.2.cmml">j</mi><mo id="S3.E1.m1.2.2.2.3.2.3.1" xref="S3.E1.m1.2.2.2.3.2.3.1.cmml">=</mo><mrow id="S3.E1.m1.2.2.2.3.2.3.3" xref="S3.E1.m1.2.2.2.3.2.3.3.cmml"><mi id="S3.E1.m1.2.2.2.3.2.3.3.2" xref="S3.E1.m1.2.2.2.3.2.3.3.2.cmml">l</mi><mo id="S3.E1.m1.2.2.2.3.2.3.3.1" xref="S3.E1.m1.2.2.2.3.2.3.3.1.cmml">+</mo><mn id="S3.E1.m1.2.2.2.3.2.3.3.3" xref="S3.E1.m1.2.2.2.3.2.3.3.3.cmml">1</mn></mrow></mrow><mi id="S3.E1.m1.2.2.2.3.3" xref="S3.E1.m1.2.2.2.3.3.cmml">L</mi></msubsup><mrow id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.4.cmml">Similarity</mi><mo id="S3.E1.m1.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.3.cmml"><mo id="S3.E1.m1.2.2.2.2.2.2.3" stretchy="false" xref="S3.E1.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S3.E1.m1.2.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E1.m1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.cmml">𝐱</mi><mi id="S3.E1.m1.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.E1.m1.2.2.2.2.2.2.5" stretchy="false" xref="S3.E1.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mrow id="S3.E1.m1.2.2.4" xref="S3.E1.m1.2.2.4.cmml"><mi id="S3.E1.m1.2.2.4.2" xref="S3.E1.m1.2.2.4.2.cmml">L</mi><mo id="S3.E1.m1.2.2.4.1" xref="S3.E1.m1.2.2.4.1.cmml">−</mo><mi id="S3.E1.m1.2.2.4.3" xref="S3.E1.m1.2.2.4.3.cmml">l</mi></mrow></mfrac></mrow><mo id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><eq id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2"></eq><apply id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.2"></times><ci id="S3.E1.m1.3.3.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.3">SimScore</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2">𝐱</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3">𝑙</ci></apply></apply><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><divide id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2"></divide><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"><apply id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.3">superscript</csymbol><apply id="S3.E1.m1.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.3.2.1.cmml" xref="S3.E1.m1.2.2.2.3">subscript</csymbol><sum id="S3.E1.m1.2.2.2.3.2.2.cmml" xref="S3.E1.m1.2.2.2.3.2.2"></sum><apply id="S3.E1.m1.2.2.2.3.2.3.cmml" xref="S3.E1.m1.2.2.2.3.2.3"><eq id="S3.E1.m1.2.2.2.3.2.3.1.cmml" xref="S3.E1.m1.2.2.2.3.2.3.1"></eq><ci id="S3.E1.m1.2.2.2.3.2.3.2.cmml" xref="S3.E1.m1.2.2.2.3.2.3.2">𝑗</ci><apply id="S3.E1.m1.2.2.2.3.2.3.3.cmml" xref="S3.E1.m1.2.2.2.3.2.3.3"><plus id="S3.E1.m1.2.2.2.3.2.3.3.1.cmml" xref="S3.E1.m1.2.2.2.3.2.3.3.1"></plus><ci id="S3.E1.m1.2.2.2.3.2.3.3.2.cmml" xref="S3.E1.m1.2.2.2.3.2.3.3.2">𝑙</ci><cn id="S3.E1.m1.2.2.2.3.2.3.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.2.3.2.3.3.3">1</cn></apply></apply></apply><ci id="S3.E1.m1.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.2.3.3">𝐿</ci></apply><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"><times id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.3"></times><ci id="S3.E1.m1.2.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.2.4">Similarity</ci><interval closure="open" id="S3.E1.m1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3">𝑙</ci></apply><apply id="S3.E1.m1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2">𝐱</ci><ci id="S3.E1.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3">𝑗</ci></apply></interval></apply></apply><apply id="S3.E1.m1.2.2.4.cmml" xref="S3.E1.m1.2.2.4"><minus id="S3.E1.m1.2.2.4.1.cmml" xref="S3.E1.m1.2.2.4.1"></minus><ci id="S3.E1.m1.2.2.4.2.cmml" xref="S3.E1.m1.2.2.4.2">𝐿</ci><ci id="S3.E1.m1.2.2.4.3.cmml" xref="S3.E1.m1.2.2.4.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\mathrm{SimScore}({\bf x}_{l})=\frac{\sum_{j=l+1}^{L}\mathrm{Similarity}({\bf x%
}_{l},{\bf x}_{j})}{L-l},</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.3d">roman_SimScore ( bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) = divide start_ARG ∑ start_POSTSUBSCRIPT italic_j = italic_l + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT roman_Similarity ( bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) end_ARG start_ARG italic_L - italic_l end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p2.5">where <math alttext="L" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m1.1"><semantics id="S3.SS2.p2.2.m1.1a"><mi id="S3.SS2.p2.2.m1.1.1" xref="S3.SS2.p2.2.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m1.1b"><ci id="S3.SS2.p2.2.m1.1.1.cmml" xref="S3.SS2.p2.2.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m1.1d">italic_L</annotation></semantics></math> is the number of layers in the model and <math alttext="\mathrm{Similarity({\bf x}_{l},{\bf x}_{j})}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m2.2"><semantics id="S3.SS2.p2.3.m2.2a"><mrow id="S3.SS2.p2.3.m2.2.2" xref="S3.SS2.p2.3.m2.2.2.cmml"><mi id="S3.SS2.p2.3.m2.2.2.4" xref="S3.SS2.p2.3.m2.2.2.4.cmml">Similarity</mi><mo id="S3.SS2.p2.3.m2.2.2.3" xref="S3.SS2.p2.3.m2.2.2.3.cmml">⁢</mo><mrow id="S3.SS2.p2.3.m2.2.2.2.2" xref="S3.SS2.p2.3.m2.2.2.2.3.cmml"><mo id="S3.SS2.p2.3.m2.2.2.2.2.3" stretchy="false" xref="S3.SS2.p2.3.m2.2.2.2.3.cmml">(</mo><msub id="S3.SS2.p2.3.m2.1.1.1.1.1" xref="S3.SS2.p2.3.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.3.m2.1.1.1.1.1.2" xref="S3.SS2.p2.3.m2.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S3.SS2.p2.3.m2.1.1.1.1.1.3" mathvariant="normal" xref="S3.SS2.p2.3.m2.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S3.SS2.p2.3.m2.2.2.2.2.4" xref="S3.SS2.p2.3.m2.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p2.3.m2.2.2.2.2.2" xref="S3.SS2.p2.3.m2.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.3.m2.2.2.2.2.2.2" xref="S3.SS2.p2.3.m2.2.2.2.2.2.2.cmml">𝐱</mi><mi id="S3.SS2.p2.3.m2.2.2.2.2.2.3" mathvariant="normal" xref="S3.SS2.p2.3.m2.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.SS2.p2.3.m2.2.2.2.2.5" stretchy="false" xref="S3.SS2.p2.3.m2.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m2.2b"><apply id="S3.SS2.p2.3.m2.2.2.cmml" xref="S3.SS2.p2.3.m2.2.2"><times id="S3.SS2.p2.3.m2.2.2.3.cmml" xref="S3.SS2.p2.3.m2.2.2.3"></times><ci id="S3.SS2.p2.3.m2.2.2.4.cmml" xref="S3.SS2.p2.3.m2.2.2.4">Similarity</ci><interval closure="open" id="S3.SS2.p2.3.m2.2.2.2.3.cmml" xref="S3.SS2.p2.3.m2.2.2.2.2"><apply id="S3.SS2.p2.3.m2.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.3.m2.1.1.1.1.1.2">𝐱</ci><ci id="S3.SS2.p2.3.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.3.m2.1.1.1.1.1.3">l</ci></apply><apply id="S3.SS2.p2.3.m2.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m2.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.3.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.3.m2.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m2.2.2.2.2.2.2">𝐱</ci><ci id="S3.SS2.p2.3.m2.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.3.m2.2.2.2.2.2.3">j</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m2.2c">\mathrm{Similarity({\bf x}_{l},{\bf x}_{j})}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m2.2d">roman_Similarity ( bold_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT roman_j end_POSTSUBSCRIPT )</annotation></semantics></math> is the average cosine similarity between all <math alttext="{\bf x}_{l}^{(i)}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m3.1"><semantics id="S3.SS2.p2.4.m3.1a"><msubsup id="S3.SS2.p2.4.m3.1.2" xref="S3.SS2.p2.4.m3.1.2.cmml"><mi id="S3.SS2.p2.4.m3.1.2.2.2" xref="S3.SS2.p2.4.m3.1.2.2.2.cmml">𝐱</mi><mi id="S3.SS2.p2.4.m3.1.2.2.3" xref="S3.SS2.p2.4.m3.1.2.2.3.cmml">l</mi><mrow id="S3.SS2.p2.4.m3.1.1.1.3" xref="S3.SS2.p2.4.m3.1.2.cmml"><mo id="S3.SS2.p2.4.m3.1.1.1.3.1" stretchy="false" xref="S3.SS2.p2.4.m3.1.2.cmml">(</mo><mi id="S3.SS2.p2.4.m3.1.1.1.1" xref="S3.SS2.p2.4.m3.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p2.4.m3.1.1.1.3.2" stretchy="false" xref="S3.SS2.p2.4.m3.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m3.1b"><apply id="S3.SS2.p2.4.m3.1.2.cmml" xref="S3.SS2.p2.4.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m3.1.2.1.cmml" xref="S3.SS2.p2.4.m3.1.2">superscript</csymbol><apply id="S3.SS2.p2.4.m3.1.2.2.cmml" xref="S3.SS2.p2.4.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m3.1.2.2.1.cmml" xref="S3.SS2.p2.4.m3.1.2">subscript</csymbol><ci id="S3.SS2.p2.4.m3.1.2.2.2.cmml" xref="S3.SS2.p2.4.m3.1.2.2.2">𝐱</ci><ci id="S3.SS2.p2.4.m3.1.2.2.3.cmml" xref="S3.SS2.p2.4.m3.1.2.2.3">𝑙</ci></apply><ci id="S3.SS2.p2.4.m3.1.1.1.1.cmml" xref="S3.SS2.p2.4.m3.1.1.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m3.1c">{\bf x}_{l}^{(i)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m3.1d">bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="{\bf x}_{j}^{(i)}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m4.1"><semantics id="S3.SS2.p2.5.m4.1a"><msubsup id="S3.SS2.p2.5.m4.1.2" xref="S3.SS2.p2.5.m4.1.2.cmml"><mi id="S3.SS2.p2.5.m4.1.2.2.2" xref="S3.SS2.p2.5.m4.1.2.2.2.cmml">𝐱</mi><mi id="S3.SS2.p2.5.m4.1.2.2.3" xref="S3.SS2.p2.5.m4.1.2.2.3.cmml">j</mi><mrow id="S3.SS2.p2.5.m4.1.1.1.3" xref="S3.SS2.p2.5.m4.1.2.cmml"><mo id="S3.SS2.p2.5.m4.1.1.1.3.1" stretchy="false" xref="S3.SS2.p2.5.m4.1.2.cmml">(</mo><mi id="S3.SS2.p2.5.m4.1.1.1.1" xref="S3.SS2.p2.5.m4.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p2.5.m4.1.1.1.3.2" stretchy="false" xref="S3.SS2.p2.5.m4.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m4.1b"><apply id="S3.SS2.p2.5.m4.1.2.cmml" xref="S3.SS2.p2.5.m4.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m4.1.2.1.cmml" xref="S3.SS2.p2.5.m4.1.2">superscript</csymbol><apply id="S3.SS2.p2.5.m4.1.2.2.cmml" xref="S3.SS2.p2.5.m4.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m4.1.2.2.1.cmml" xref="S3.SS2.p2.5.m4.1.2">subscript</csymbol><ci id="S3.SS2.p2.5.m4.1.2.2.2.cmml" xref="S3.SS2.p2.5.m4.1.2.2.2">𝐱</ci><ci id="S3.SS2.p2.5.m4.1.2.2.3.cmml" xref="S3.SS2.p2.5.m4.1.2.2.3">𝑗</ci></apply><ci id="S3.SS2.p2.5.m4.1.1.1.1.cmml" xref="S3.SS2.p2.5.m4.1.1.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m4.1c">{\bf x}_{j}^{(i)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m4.1d">bold_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math> tokens.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.5">We use 50 random training examples from <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.5.1">HuggingFaceH4/ultrachat_200k</span> to estimate <math alttext="\mathrm{SimScore}({\bf x}_{l})" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">SimScore</mi><mo id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p3.1.m1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S3.SS2.p3.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><times id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2"></times><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">SimScore</ci><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2">𝐱</ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathrm{SimScore}({\bf x}_{l})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">roman_SimScore ( bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT )</annotation></semantics></math>, and
the results of Llama-3.1-8B-Instruct, Mistral-7B-Instruct-v0.1, and Qwen2.5-7B-Instruct are shown in the left of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.F2" title="Figure 2 ‣ 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">2</span></a>.
As the layers get deeper, <math alttext="\mathrm{SimScore}({\bf x}_{l})" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mrow id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">SimScore</mi><mo id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.2.m2.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p3.2.m2.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S3.SS2.p3.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><times id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2"></times><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">SimScore</ci><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2">𝐱</ci><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\mathrm{SimScore}({\bf x}_{l})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">roman_SimScore ( bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT )</annotation></semantics></math> gets higher.
Particularly, around half of the depth, the average similarity of <math alttext="{\bf x}_{l}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">𝐱</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">𝐱</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">{\bf x}_{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> with <math alttext="{\bf x}_{&gt;l}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">𝐱</mi><mrow id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml"><mi id="S3.SS2.p3.4.m4.1.1.3.2" xref="S3.SS2.p3.4.m4.1.1.3.2.cmml"></mi><mo id="S3.SS2.p3.4.m4.1.1.3.1" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">&gt;</mo><mi id="S3.SS2.p3.4.m4.1.1.3.3" xref="S3.SS2.p3.4.m4.1.1.3.3.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">𝐱</ci><apply id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3"><gt id="S3.SS2.p3.4.m4.1.1.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.3.1"></gt><csymbol cd="latexml" id="S3.SS2.p3.4.m4.1.1.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.3.2">absent</csymbol><ci id="S3.SS2.p3.4.m4.1.1.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">{\bf x}_{&gt;l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">bold_x start_POSTSUBSCRIPT &gt; italic_l end_POSTSUBSCRIPT</annotation></semantics></math> is above <math alttext="0.5" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mn id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><cn id="S3.SS2.p3.5.m5.1.1.cmml" type="float" xref="S3.SS2.p3.5.m5.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">0.5</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">0.5</annotation></semantics></math> for all models, which shows that the difference of input hidden states are small in deeper layers.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.4">Based on this observation, the first key component of SwiftKV is to use <math alttext="l" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">italic_l</annotation></semantics></math>-th layer’s output <math alttext="{\bf x}_{l+1}" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><msub id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">𝐱</mi><mrow id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml"><mi id="S3.SS2.p4.2.m2.1.1.3.2" xref="S3.SS2.p4.2.m2.1.1.3.2.cmml">l</mi><mo id="S3.SS2.p4.2.m2.1.1.3.1" xref="S3.SS2.p4.2.m2.1.1.3.1.cmml">+</mo><mn id="S3.SS2.p4.2.m2.1.1.3.3" xref="S3.SS2.p4.2.m2.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">𝐱</ci><apply id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3"><plus id="S3.SS2.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.p4.2.m2.1.1.3.1"></plus><ci id="S3.SS2.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2">𝑙</ci><cn id="S3.SS2.p4.2.m2.1.1.3.3.cmml" type="integer" xref="S3.SS2.p4.2.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">{\bf x}_{l+1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">bold_x start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT</annotation></semantics></math> to compute the KV cache for all remaining layers. More specifically, SwiftKV retains the standard transformer architecture up to and including the <math alttext="l" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.1"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">l</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.1d">italic_l</annotation></semantics></math>-th layer, but the KV cache for all remaining layers are computed immediately using <math alttext="{\bf x}_{l+1}" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m4.1"><semantics id="S3.SS2.p4.4.m4.1a"><msub id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><mi id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml">𝐱</mi><mrow id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml"><mi id="S3.SS2.p4.4.m4.1.1.3.2" xref="S3.SS2.p4.4.m4.1.1.3.2.cmml">l</mi><mo id="S3.SS2.p4.4.m4.1.1.3.1" xref="S3.SS2.p4.4.m4.1.1.3.1.cmml">+</mo><mn id="S3.SS2.p4.4.m4.1.1.3.3" xref="S3.SS2.p4.4.m4.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2">𝐱</ci><apply id="S3.SS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3"><plus id="S3.SS2.p4.4.m4.1.1.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.1"></plus><ci id="S3.SS2.p4.4.m4.1.1.3.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2">𝑙</ci><cn id="S3.SS2.p4.4.m4.1.1.3.3.cmml" type="integer" xref="S3.SS2.p4.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">{\bf x}_{l+1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.1d">bold_x start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT</annotation></semantics></math>, i.e.</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{\mathbf{KV}}_{j}={\mathbf{W}}_{KV}^{j}{\bf x}_{l+1},~{}~{}~{}~{}\text{for all%
 $j&gt;l$,}" class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><msub id="S3.E2.m1.2.2.3" xref="S3.E2.m1.2.2.3.cmml"><mi id="S3.E2.m1.2.2.3.2" xref="S3.E2.m1.2.2.3.2.cmml">𝐊𝐕</mi><mi id="S3.E2.m1.2.2.3.3" xref="S3.E2.m1.2.2.3.3.cmml">j</mi></msub><mo id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.2.cmml"><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><msubsup id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.2.2.2" xref="S3.E2.m1.2.2.1.1.1.2.2.2.cmml">𝐖</mi><mrow id="S3.E2.m1.2.2.1.1.1.2.2.3" xref="S3.E2.m1.2.2.1.1.1.2.2.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.2.2.3.2" xref="S3.E2.m1.2.2.1.1.1.2.2.3.2.cmml">K</mi><mo id="S3.E2.m1.2.2.1.1.1.2.2.3.1" xref="S3.E2.m1.2.2.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.E2.m1.2.2.1.1.1.2.2.3.3" xref="S3.E2.m1.2.2.1.1.1.2.2.3.3.cmml">V</mi></mrow><mi id="S3.E2.m1.2.2.1.1.1.2.3" xref="S3.E2.m1.2.2.1.1.1.2.3.cmml">j</mi></msubsup><mo id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml">⁢</mo><msub id="S3.E2.m1.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.3.2.cmml">𝐱</mi><mrow id="S3.E2.m1.2.2.1.1.1.3.3" xref="S3.E2.m1.2.2.1.1.1.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3.3.2" xref="S3.E2.m1.2.2.1.1.1.3.3.2.cmml">l</mi><mo id="S3.E2.m1.2.2.1.1.1.3.3.1" xref="S3.E2.m1.2.2.1.1.1.3.3.1.cmml">+</mo><mn id="S3.E2.m1.2.2.1.1.1.3.3.3" xref="S3.E2.m1.2.2.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S3.E2.m1.2.2.1.1.2" rspace="1.487em" xref="S3.E2.m1.2.2.1.2.cmml">,</mo><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1c.cmml"><mtext id="S3.E2.m1.1.1.1a" xref="S3.E2.m1.1.1.1c.cmml">for all </mtext><mrow id="S3.E2.m1.1.1.1.m1.1.1" xref="S3.E2.m1.1.1.1.m1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.m1.1.1.2" xref="S3.E2.m1.1.1.1.m1.1.1.2.cmml">j</mi><mo id="S3.E2.m1.1.1.1.m1.1.1.1" xref="S3.E2.m1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mi id="S3.E2.m1.1.1.1.m1.1.1.3" xref="S3.E2.m1.1.1.1.m1.1.1.3.cmml">l</mi></mrow><mtext id="S3.E2.m1.1.1.1b" xref="S3.E2.m1.1.1.1c.cmml">,</mtext></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><eq id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"></eq><apply id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.3.1.cmml" xref="S3.E2.m1.2.2.3">subscript</csymbol><ci id="S3.E2.m1.2.2.3.2.cmml" xref="S3.E2.m1.2.2.3.2">𝐊𝐕</ci><ci id="S3.E2.m1.2.2.3.3.cmml" xref="S3.E2.m1.2.2.3.3">𝑗</ci></apply><list id="S3.E2.m1.2.2.1.2.cmml" xref="S3.E2.m1.2.2.1.1"><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1"></times><apply id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.2">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2.2.2">𝐖</ci><apply id="S3.E2.m1.2.2.1.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.2.2.3"><times id="S3.E2.m1.2.2.1.1.1.2.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.2.2.3.1"></times><ci id="S3.E2.m1.2.2.1.1.1.2.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2.2.3.2">𝐾</ci><ci id="S3.E2.m1.2.2.1.1.1.2.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.2.2.3.3">𝑉</ci></apply></apply><ci id="S3.E2.m1.2.2.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.2.3">𝑗</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.2">𝐱</ci><apply id="S3.E2.m1.2.2.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3"><plus id="S3.E2.m1.2.2.1.1.1.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.1"></plus><ci id="S3.E2.m1.2.2.1.1.1.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.3.3.2">𝑙</ci><cn id="S3.E2.m1.2.2.1.1.1.3.3.3.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.1.3.3.3">1</cn></apply></apply></apply><ci id="S3.E2.m1.1.1.1c.cmml" xref="S3.E2.m1.1.1.1"><mrow id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><mtext id="S3.E2.m1.1.1.1a.cmml" xref="S3.E2.m1.1.1.1">for all </mtext><mrow id="S3.E2.m1.1.1.1.m1.1.1.cmml" xref="S3.E2.m1.1.1.1.m1.1.1"><mi id="S3.E2.m1.1.1.1.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.m1.1.1.2">j</mi><mo id="S3.E2.m1.1.1.1.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.m1.1.1.1">&gt;</mo><mi id="S3.E2.m1.1.1.1.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.m1.1.1.3">l</mi></mrow><mtext id="S3.E2.m1.1.1.1b.cmml" xref="S3.E2.m1.1.1.1">,</mtext></mrow></ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">{\mathbf{KV}}_{j}={\mathbf{W}}_{KV}^{j}{\bf x}_{l+1},~{}~{}~{}~{}\text{for all%
 $j&gt;l$,}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">bold_KV start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = bold_W start_POSTSUBSCRIPT italic_K italic_V end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT bold_x start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT , for all italic_j &gt; italic_l ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p4.7">where <math alttext="{\mathbf{KV}}_{j}" class="ltx_Math" display="inline" id="S3.SS2.p4.5.m1.1"><semantics id="S3.SS2.p4.5.m1.1a"><msub id="S3.SS2.p4.5.m1.1.1" xref="S3.SS2.p4.5.m1.1.1.cmml"><mi id="S3.SS2.p4.5.m1.1.1.2" xref="S3.SS2.p4.5.m1.1.1.2.cmml">𝐊𝐕</mi><mi id="S3.SS2.p4.5.m1.1.1.3" xref="S3.SS2.p4.5.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m1.1b"><apply id="S3.SS2.p4.5.m1.1.1.cmml" xref="S3.SS2.p4.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m1.1.1.1.cmml" xref="S3.SS2.p4.5.m1.1.1">subscript</csymbol><ci id="S3.SS2.p4.5.m1.1.1.2.cmml" xref="S3.SS2.p4.5.m1.1.1.2">𝐊𝐕</ci><ci id="S3.SS2.p4.5.m1.1.1.3.cmml" xref="S3.SS2.p4.5.m1.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m1.1c">{\mathbf{KV}}_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.5.m1.1d">bold_KV start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is the KV cache for <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.p4.6.m2.1"><semantics id="S3.SS2.p4.6.m2.1a"><mi id="S3.SS2.p4.6.m2.1.1" xref="S3.SS2.p4.6.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m2.1b"><ci id="S3.SS2.p4.6.m2.1.1.cmml" xref="S3.SS2.p4.6.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m2.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.6.m2.1d">italic_j</annotation></semantics></math>-th layer and <math alttext="{\mathbf{W}}_{KV}^{j}" class="ltx_Math" display="inline" id="S3.SS2.p4.7.m3.1"><semantics id="S3.SS2.p4.7.m3.1a"><msubsup id="S3.SS2.p4.7.m3.1.1" xref="S3.SS2.p4.7.m3.1.1.cmml"><mi id="S3.SS2.p4.7.m3.1.1.2.2" xref="S3.SS2.p4.7.m3.1.1.2.2.cmml">𝐖</mi><mrow id="S3.SS2.p4.7.m3.1.1.2.3" xref="S3.SS2.p4.7.m3.1.1.2.3.cmml"><mi id="S3.SS2.p4.7.m3.1.1.2.3.2" xref="S3.SS2.p4.7.m3.1.1.2.3.2.cmml">K</mi><mo id="S3.SS2.p4.7.m3.1.1.2.3.1" xref="S3.SS2.p4.7.m3.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.7.m3.1.1.2.3.3" xref="S3.SS2.p4.7.m3.1.1.2.3.3.cmml">V</mi></mrow><mi id="S3.SS2.p4.7.m3.1.1.3" xref="S3.SS2.p4.7.m3.1.1.3.cmml">j</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m3.1b"><apply id="S3.SS2.p4.7.m3.1.1.cmml" xref="S3.SS2.p4.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m3.1.1.1.cmml" xref="S3.SS2.p4.7.m3.1.1">superscript</csymbol><apply id="S3.SS2.p4.7.m3.1.1.2.cmml" xref="S3.SS2.p4.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m3.1.1.2.1.cmml" xref="S3.SS2.p4.7.m3.1.1">subscript</csymbol><ci id="S3.SS2.p4.7.m3.1.1.2.2.cmml" xref="S3.SS2.p4.7.m3.1.1.2.2">𝐖</ci><apply id="S3.SS2.p4.7.m3.1.1.2.3.cmml" xref="S3.SS2.p4.7.m3.1.1.2.3"><times id="S3.SS2.p4.7.m3.1.1.2.3.1.cmml" xref="S3.SS2.p4.7.m3.1.1.2.3.1"></times><ci id="S3.SS2.p4.7.m3.1.1.2.3.2.cmml" xref="S3.SS2.p4.7.m3.1.1.2.3.2">𝐾</ci><ci id="S3.SS2.p4.7.m3.1.1.2.3.3.cmml" xref="S3.SS2.p4.7.m3.1.1.2.3.3">𝑉</ci></apply></apply><ci id="S3.SS2.p4.7.m3.1.1.3.cmml" xref="S3.SS2.p4.7.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m3.1c">{\mathbf{W}}_{KV}^{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.7.m3.1d">bold_W start_POSTSUBSCRIPT italic_K italic_V end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT</annotation></semantics></math> is its KV projection weight matrix.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.3"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.3.1">Prefill Compute Reduction.</span> SingleInputKV can enable significant reduction in prefill computation during LLM inference. Originally, all input tokens need to be processed by all transformer layers in order to generate the first new token.
Using SingleInputKV, after layer <math alttext="l" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">italic_l</annotation></semantics></math>, since all the required KV cache are computed, for all remaining layers (<math alttext="&gt;l" class="ltx_Math" display="inline" id="S3.SS2.p5.2.m2.1"><semantics id="S3.SS2.p5.2.m2.1a"><mrow id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml"><mi id="S3.SS2.p5.2.m2.1.1.2" xref="S3.SS2.p5.2.m2.1.1.2.cmml"></mi><mo id="S3.SS2.p5.2.m2.1.1.1" xref="S3.SS2.p5.2.m2.1.1.1.cmml">&gt;</mo><mi id="S3.SS2.p5.2.m2.1.1.3" xref="S3.SS2.p5.2.m2.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><apply id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1"><gt id="S3.SS2.p5.2.m2.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1"></gt><csymbol cd="latexml" id="S3.SS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.2">absent</csymbol><ci id="S3.SS2.p5.2.m2.1.1.3.cmml" xref="S3.SS2.p5.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">&gt;l</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.2.m2.1d">&gt; italic_l</annotation></semantics></math>), we only need to process the last token in the input. When prefill computation dominates generated token computation, this reduces the total inference computation to approximately <math alttext="l/L" class="ltx_Math" display="inline" id="S3.SS2.p5.3.m3.1"><semantics id="S3.SS2.p5.3.m3.1a"><mrow id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml"><mi id="S3.SS2.p5.3.m3.1.1.2" xref="S3.SS2.p5.3.m3.1.1.2.cmml">l</mi><mo id="S3.SS2.p5.3.m3.1.1.1" xref="S3.SS2.p5.3.m3.1.1.1.cmml">/</mo><mi id="S3.SS2.p5.3.m3.1.1.3" xref="S3.SS2.p5.3.m3.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><apply id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1"><divide id="S3.SS2.p5.3.m3.1.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1.1"></divide><ci id="S3.SS2.p5.3.m3.1.1.2.cmml" xref="S3.SS2.p5.3.m3.1.1.2">𝑙</ci><ci id="S3.SS2.p5.3.m3.1.1.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">l/L</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.3.m3.1d">italic_l / italic_L</annotation></semantics></math>. See Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A2" title="Appendix B Calculating Computation Reduction ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">B</span></a> for more details.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>AcrossKV: Sharing KV cache for consecutive layers</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">GQA <cite class="ltx_cite ltx_citemacro_citep">(Ainslie et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib2" title="">2023a</a>)</cite>, one of the most widely adopted KV cache compression methods, showed that the KV cache can be easily shared within a transformer layer. Later, <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib29" title="">2024a</a>)</cite> showed that the KV cache can be merged for certain pairs of adjacent layers.
AcrossKV extends the ideas to cross-layer KV cache sharing.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Particularly, instead of computing KV cache for all of the remaining layers as shown in equation <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.E2" title="In 3.2 SingleInputKV: Project KV cache from a single layer ‣ 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">2</span></a>, AcrossKV selectively chooses one layer to compute the KV cache for several consecutive layers and share it within the small group. The key idea is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">1</span></a>. As AcrossKV can combine multiple layers’ KV caches into a single one rather than just two adjacent layers, it offers higher potential reduction ratio compared to <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib29" title="">2024a</a>)</cite> while simplifying the implementation to realize the benefits of the KV cache reduction. (See Sec.  <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S2" title="2 Related Work ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">2</span></a> for more detailed comparison with <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib29" title="">2024a</a>)</cite>).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Knowledge Recovery</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.3">While SingleInputKV preserves all the original parameters, it re-wires the architecture so that the KV cache projections may receive different inputs. We found that this re-wiring (and AcrossKV) requires fine-tuning to recover the original capabilities from the modified model. As we only change the computation of the attention part for layer <math alttext="&gt;l" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1"><semantics id="S3.SS4.p1.1.m1.1a"><mrow id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml"></mi><mo id="S3.SS4.p1.1.m1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.cmml">&gt;</mo><mi id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><gt id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">absent</csymbol><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">&gt;l</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.1d">&gt; italic_l</annotation></semantics></math>, this can be achieved by fine-tune just the <math alttext="{\mathbf{W}}_{QKV}" class="ltx_Math" display="inline" id="S3.SS4.p1.2.m2.1"><semantics id="S3.SS4.p1.2.m2.1a"><msub id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">𝐖</mi><mrow id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml"><mi id="S3.SS4.p1.2.m2.1.1.3.2" xref="S3.SS4.p1.2.m2.1.1.3.2.cmml">Q</mi><mo id="S3.SS4.p1.2.m2.1.1.3.1" xref="S3.SS4.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.2.m2.1.1.3.3" xref="S3.SS4.p1.2.m2.1.1.3.3.cmml">K</mi><mo id="S3.SS4.p1.2.m2.1.1.3.1a" xref="S3.SS4.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.2.m2.1.1.3.4" xref="S3.SS4.p1.2.m2.1.1.3.4.cmml">V</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">𝐖</ci><apply id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3"><times id="S3.SS4.p1.2.m2.1.1.3.1.cmml" xref="S3.SS4.p1.2.m2.1.1.3.1"></times><ci id="S3.SS4.p1.2.m2.1.1.3.2.cmml" xref="S3.SS4.p1.2.m2.1.1.3.2">𝑄</ci><ci id="S3.SS4.p1.2.m2.1.1.3.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3.3">𝐾</ci><ci id="S3.SS4.p1.2.m2.1.1.3.4.cmml" xref="S3.SS4.p1.2.m2.1.1.3.4">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">{\mathbf{W}}_{QKV}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.2.m2.1d">bold_W start_POSTSUBSCRIPT italic_Q italic_K italic_V end_POSTSUBSCRIPT</annotation></semantics></math> weight matrices from the <math alttext="(l+1)" class="ltx_Math" display="inline" id="S3.SS4.p1.3.m3.1"><semantics id="S3.SS4.p1.3.m3.1a"><mrow id="S3.SS4.p1.3.m3.1.1.1" xref="S3.SS4.p1.3.m3.1.1.1.1.cmml"><mo id="S3.SS4.p1.3.m3.1.1.1.2" stretchy="false" xref="S3.SS4.p1.3.m3.1.1.1.1.cmml">(</mo><mrow id="S3.SS4.p1.3.m3.1.1.1.1" xref="S3.SS4.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS4.p1.3.m3.1.1.1.1.2" xref="S3.SS4.p1.3.m3.1.1.1.1.2.cmml">l</mi><mo id="S3.SS4.p1.3.m3.1.1.1.1.1" xref="S3.SS4.p1.3.m3.1.1.1.1.1.cmml">+</mo><mn id="S3.SS4.p1.3.m3.1.1.1.1.3" xref="S3.SS4.p1.3.m3.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS4.p1.3.m3.1.1.1.3" stretchy="false" xref="S3.SS4.p1.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><apply id="S3.SS4.p1.3.m3.1.1.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1.1"><plus id="S3.SS4.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1.1.1.1"></plus><ci id="S3.SS4.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS4.p1.3.m3.1.1.1.1.2">𝑙</ci><cn id="S3.SS4.p1.3.m3.1.1.1.1.3.cmml" type="integer" xref="S3.SS4.p1.3.m3.1.1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">(l+1)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.3.m3.1d">( italic_l + 1 )</annotation></semantics></math>-th layer onwards. However, instead of directly fine-tuning these parameters using standard LM loss, we find that distilling using the output logits of the original model allows for better knowledge recovery (see Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5" title="5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5</span></a> for more details).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.3"><span class="ltx_text ltx_font_bold" id="S3.SS4.p2.3.1">Implementing the Distillation.</span> Since only a few <math alttext="{\mathbf{W}}_{QKV}" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><msub id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">𝐖</mi><mrow id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml"><mi id="S3.SS4.p2.1.m1.1.1.3.2" xref="S3.SS4.p2.1.m1.1.1.3.2.cmml">Q</mi><mo id="S3.SS4.p2.1.m1.1.1.3.1" xref="S3.SS4.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.1.m1.1.1.3.3" xref="S3.SS4.p2.1.m1.1.1.3.3.cmml">K</mi><mo id="S3.SS4.p2.1.m1.1.1.3.1a" xref="S3.SS4.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.1.m1.1.1.3.4" xref="S3.SS4.p2.1.m1.1.1.3.4.cmml">V</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">𝐖</ci><apply id="S3.SS4.p2.1.m1.1.1.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3"><times id="S3.SS4.p2.1.m1.1.1.3.1.cmml" xref="S3.SS4.p2.1.m1.1.1.3.1"></times><ci id="S3.SS4.p2.1.m1.1.1.3.2.cmml" xref="S3.SS4.p2.1.m1.1.1.3.2">𝑄</ci><ci id="S3.SS4.p2.1.m1.1.1.3.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3.3">𝐾</ci><ci id="S3.SS4.p2.1.m1.1.1.3.4.cmml" xref="S3.SS4.p2.1.m1.1.1.3.4">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">{\mathbf{W}}_{QKV}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">bold_W start_POSTSUBSCRIPT italic_Q italic_K italic_V end_POSTSUBSCRIPT</annotation></semantics></math> parameters need fine-tuning, we are able to do a memory efficient parameter-sharing based distillation. More specifically, we keep a single copy of the original model weights in memory that are frozen during training, and add an extra trainable copy of the <math alttext="{\mathbf{W}}_{QKV}" class="ltx_Math" display="inline" id="S3.SS4.p2.2.m2.1"><semantics id="S3.SS4.p2.2.m2.1a"><msub id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml"><mi id="S3.SS4.p2.2.m2.1.1.2" xref="S3.SS4.p2.2.m2.1.1.2.cmml">𝐖</mi><mrow id="S3.SS4.p2.2.m2.1.1.3" xref="S3.SS4.p2.2.m2.1.1.3.cmml"><mi id="S3.SS4.p2.2.m2.1.1.3.2" xref="S3.SS4.p2.2.m2.1.1.3.2.cmml">Q</mi><mo id="S3.SS4.p2.2.m2.1.1.3.1" xref="S3.SS4.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.2.m2.1.1.3.3" xref="S3.SS4.p2.2.m2.1.1.3.3.cmml">K</mi><mo id="S3.SS4.p2.2.m2.1.1.3.1a" xref="S3.SS4.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.2.m2.1.1.3.4" xref="S3.SS4.p2.2.m2.1.1.3.4.cmml">V</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><apply id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p2.2.m2.1.1.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2">𝐖</ci><apply id="S3.SS4.p2.2.m2.1.1.3.cmml" xref="S3.SS4.p2.2.m2.1.1.3"><times id="S3.SS4.p2.2.m2.1.1.3.1.cmml" xref="S3.SS4.p2.2.m2.1.1.3.1"></times><ci id="S3.SS4.p2.2.m2.1.1.3.2.cmml" xref="S3.SS4.p2.2.m2.1.1.3.2">𝑄</ci><ci id="S3.SS4.p2.2.m2.1.1.3.3.cmml" xref="S3.SS4.p2.2.m2.1.1.3.3">𝐾</ci><ci id="S3.SS4.p2.2.m2.1.1.3.4.cmml" xref="S3.SS4.p2.2.m2.1.1.3.4">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">{\mathbf{W}}_{QKV}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.2.m2.1d">bold_W start_POSTSUBSCRIPT italic_Q italic_K italic_V end_POSTSUBSCRIPT</annotation></semantics></math> parameters for layers <math alttext="&gt;l" class="ltx_Math" display="inline" id="S3.SS4.p2.3.m3.1"><semantics id="S3.SS4.p2.3.m3.1a"><mrow id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml"><mi id="S3.SS4.p2.3.m3.1.1.2" xref="S3.SS4.p2.3.m3.1.1.2.cmml"></mi><mo id="S3.SS4.p2.3.m3.1.1.1" xref="S3.SS4.p2.3.m3.1.1.1.cmml">&gt;</mo><mi id="S3.SS4.p2.3.m3.1.1.3" xref="S3.SS4.p2.3.m3.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><apply id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1"><gt id="S3.SS4.p2.3.m3.1.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1.1"></gt><csymbol cd="latexml" id="S3.SS4.p2.3.m3.1.1.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2">absent</csymbol><ci id="S3.SS4.p2.3.m3.1.1.3.cmml" xref="S3.SS4.p2.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">&gt;l</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.3.m3.1d">&gt; italic_l</annotation></semantics></math> initialized using the original model (See Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">During the training, we create two forward modes for the later layers <math alttext="&gt;l" class="ltx_Math" display="inline" id="S3.SS4.p3.1.m1.1"><semantics id="S3.SS4.p3.1.m1.1a"><mrow id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml"><mi id="S3.SS4.p3.1.m1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.2.cmml"></mi><mo id="S3.SS4.p3.1.m1.1.1.1" xref="S3.SS4.p3.1.m1.1.1.1.cmml">&gt;</mo><mi id="S3.SS4.p3.1.m1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><apply id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1"><gt id="S3.SS4.p3.1.m1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S3.SS4.p3.1.m1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.2">absent</csymbol><ci id="S3.SS4.p3.1.m1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">&gt;l</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.1.m1.1d">&gt; italic_l</annotation></semantics></math>, one with original frozen parameters using original architecture, and another with the SwiftKV re-wiring using new QKV projections i.e.,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{\bf y}_{teacher}={\mathbf{M}}({\bf x},SwiftKV=False),~{}~{}\text{and}~{}~{}~{%
}{\bf y}_{student}={\mathbf{M}}({\bf x},SwiftKV=True)," class="ltx_Math" display="block" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3.1"><mrow id="S3.E3.m1.3.3.1.1.2" xref="S3.E3.m1.3.3.1.1.3.cmml"><mrow id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.2.cmml">𝐲</mi><mrow id="S3.E3.m1.3.3.1.1.1.1.3.3" xref="S3.E3.m1.3.3.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.3.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.1" xref="S3.E3.m1.3.3.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.3.3.3" xref="S3.E3.m1.3.3.1.1.1.1.3.3.3.cmml">e</mi><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.1a" xref="S3.E3.m1.3.3.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.3.3.4" xref="S3.E3.m1.3.3.1.1.1.1.3.3.4.cmml">a</mi><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.1b" xref="S3.E3.m1.3.3.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.3.3.5" xref="S3.E3.m1.3.3.1.1.1.1.3.3.5.cmml">c</mi><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.1c" xref="S3.E3.m1.3.3.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.3.3.6" xref="S3.E3.m1.3.3.1.1.1.1.3.3.6.cmml">h</mi><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.1d" xref="S3.E3.m1.3.3.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.3.3.7" xref="S3.E3.m1.3.3.1.1.1.1.3.3.7.cmml">e</mi><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.1e" xref="S3.E3.m1.3.3.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.3.3.8" xref="S3.E3.m1.3.3.1.1.1.1.3.3.8.cmml">r</mi></mrow></msub><mo id="S3.E3.m1.3.3.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.3.cmml">𝐌</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">𝐱</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml">S</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml">w</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1a" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.4.cmml">i</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1b" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.5" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.5.cmml">f</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1c" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.6" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.6.cmml">t</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1d" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.7" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.7.cmml">K</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1e" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.8" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.8.cmml">V</mi></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml">F</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml">a</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1a" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.4" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.4.cmml">l</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1b" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.5" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.5.cmml">s</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1c" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.6" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.6.cmml">e</mi></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.2.3" rspace="0.827em" xref="S3.E3.m1.3.3.1.1.3a.cmml">,</mo><mrow id="S3.E3.m1.3.3.1.1.2.2" xref="S3.E3.m1.3.3.1.1.2.2.cmml"><mrow id="S3.E3.m1.3.3.1.1.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.3.cmml"><mtext id="S3.E3.m1.3.3.1.1.2.2.3.2" xref="S3.E3.m1.3.3.1.1.2.2.3.2a.cmml">and</mtext><mo id="S3.E3.m1.3.3.1.1.2.2.3.1" lspace="0.990em" xref="S3.E3.m1.3.3.1.1.2.2.3.1.cmml">⁢</mo><msub id="S3.E3.m1.3.3.1.1.2.2.3.3" xref="S3.E3.m1.3.3.1.1.2.2.3.3.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.3.3.2" xref="S3.E3.m1.3.3.1.1.2.2.3.3.2.cmml">𝐲</mi><mrow id="S3.E3.m1.3.3.1.1.2.2.3.3.3" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.3.3.3.2" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.2.cmml">s</mi><mo id="S3.E3.m1.3.3.1.1.2.2.3.3.3.1" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.3.3.3.3" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.3.cmml">t</mi><mo id="S3.E3.m1.3.3.1.1.2.2.3.3.3.1a" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.3.3.3.4" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.4.cmml">u</mi><mo id="S3.E3.m1.3.3.1.1.2.2.3.3.3.1b" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.3.3.3.5" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.5.cmml">d</mi><mo id="S3.E3.m1.3.3.1.1.2.2.3.3.3.1c" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.3.3.3.6" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.6.cmml">e</mi><mo id="S3.E3.m1.3.3.1.1.2.2.3.3.3.1d" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.3.3.3.7" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.7.cmml">n</mi><mo id="S3.E3.m1.3.3.1.1.2.2.3.3.3.1e" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.3.3.3.8" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.8.cmml">t</mi></mrow></msub></mrow><mo id="S3.E3.m1.3.3.1.1.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.1" xref="S3.E3.m1.3.3.1.1.2.2.1.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.1.3" xref="S3.E3.m1.3.3.1.1.2.2.1.3.cmml">𝐌</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.2" xref="S3.E3.m1.3.3.1.1.2.2.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.1.1.1" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">𝐱</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.2.cmml">,</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.2.cmml">S</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.3.cmml">w</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1a" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.4" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.4.cmml">i</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1b" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.5" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.5.cmml">f</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1c" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.6" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.6.cmml">t</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1d" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.7" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.7.cmml">K</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1e" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.8" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.8.cmml">V</mi></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.2.cmml">T</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.1" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.3" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.3.cmml">r</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.1a" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.4" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.4.cmml">u</mi><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.1b" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.5" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.5.cmml">e</mi></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.2.2.1.1.1.3" stretchy="false" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.3.3.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.3a.cmml" xref="S3.E3.m1.3.3.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1"><eq id="S3.E3.m1.3.3.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2"></eq><apply id="S3.E3.m1.3.3.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2">𝐲</ci><apply id="S3.E3.m1.3.3.1.1.1.1.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3"><times id="S3.E3.m1.3.3.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3.1"></times><ci id="S3.E3.m1.3.3.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3.2">𝑡</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3.3">𝑒</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.3.4.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3.4">𝑎</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.3.5.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3.5">𝑐</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.3.6.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3.6">ℎ</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.3.7.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3.7">𝑒</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.3.8.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.3.8">𝑟</ci></apply></apply><apply id="S3.E3.m1.3.3.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.2"></times><ci id="S3.E3.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.3">𝐌</ci><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1"><eq id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2"></eq><list id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝐱</ci><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2">𝑆</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3">𝑤</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.4">𝑖</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.5">𝑓</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.6">𝑡</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.7.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.7">𝐾</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.8.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.8">𝑉</ci></apply></list><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3"><times id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2">𝐹</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3">𝑎</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.4">𝑙</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.5.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.5">𝑠</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.6.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.6">𝑒</ci></apply></apply></apply></apply><apply id="S3.E3.m1.3.3.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2"><eq id="S3.E3.m1.3.3.1.1.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2"></eq><apply id="S3.E3.m1.3.3.1.1.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3"><times id="S3.E3.m1.3.3.1.1.2.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.1"></times><ci id="S3.E3.m1.3.3.1.1.2.2.3.2a.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.2"><mtext id="S3.E3.m1.3.3.1.1.2.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.2">and</mtext></ci><apply id="S3.E3.m1.3.3.1.1.2.2.3.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.3.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.3.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.2">𝐲</ci><apply id="S3.E3.m1.3.3.1.1.2.2.3.3.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3"><times id="S3.E3.m1.3.3.1.1.2.2.3.3.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.1"></times><ci id="S3.E3.m1.3.3.1.1.2.2.3.3.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.2">𝑠</ci><ci id="S3.E3.m1.3.3.1.1.2.2.3.3.3.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.3">𝑡</ci><ci id="S3.E3.m1.3.3.1.1.2.2.3.3.3.4.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.4">𝑢</ci><ci id="S3.E3.m1.3.3.1.1.2.2.3.3.3.5.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.5">𝑑</ci><ci id="S3.E3.m1.3.3.1.1.2.2.3.3.3.6.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.6">𝑒</ci><ci id="S3.E3.m1.3.3.1.1.2.2.3.3.3.7.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.7">𝑛</ci><ci id="S3.E3.m1.3.3.1.1.2.2.3.3.3.8.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3.3.8">𝑡</ci></apply></apply></apply><apply id="S3.E3.m1.3.3.1.1.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1"><times id="S3.E3.m1.3.3.1.1.2.2.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.2"></times><ci id="S3.E3.m1.3.3.1.1.2.2.1.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.3">𝐌</ci><apply id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1"><eq id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.2"></eq><list id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1"><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝐱</ci><apply id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.2">𝑆</ci><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.3">𝑤</ci><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.4.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.4">𝑖</ci><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.5.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.5">𝑓</ci><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.6.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.6">𝑡</ci><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.7.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.7">𝐾</ci><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.8.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.1.1.1.8">𝑉</ci></apply></list><apply id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3"><times id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.1"></times><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.2">𝑇</ci><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.3">𝑟</ci><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.4.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.4">𝑢</ci><ci id="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.5.cmml" xref="S3.E3.m1.3.3.1.1.2.2.1.1.1.1.3.5">𝑒</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">{\bf y}_{teacher}={\mathbf{M}}({\bf x},SwiftKV=False),~{}~{}\text{and}~{}~{}~{%
}{\bf y}_{student}={\mathbf{M}}({\bf x},SwiftKV=True),</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">bold_y start_POSTSUBSCRIPT italic_t italic_e italic_a italic_c italic_h italic_e italic_r end_POSTSUBSCRIPT = bold_M ( bold_x , italic_S italic_w italic_i italic_f italic_t italic_K italic_V = italic_F italic_a italic_l italic_s italic_e ) , and bold_y start_POSTSUBSCRIPT italic_s italic_t italic_u italic_d italic_e italic_n italic_t end_POSTSUBSCRIPT = bold_M ( bold_x , italic_S italic_w italic_i italic_f italic_t italic_K italic_V = italic_T italic_r italic_u italic_e ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p3.7">where <math alttext="{\bf y}_{\cdot}" class="ltx_Math" display="inline" id="S3.SS4.p3.2.m1.1"><semantics id="S3.SS4.p3.2.m1.1a"><msub id="S3.SS4.p3.2.m1.1.1" xref="S3.SS4.p3.2.m1.1.1.cmml"><mi id="S3.SS4.p3.2.m1.1.1.2" xref="S3.SS4.p3.2.m1.1.1.2.cmml">𝐲</mi><mo id="S3.SS4.p3.2.m1.1.1.3" xref="S3.SS4.p3.2.m1.1.1.3.cmml">⋅</mo></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m1.1b"><apply id="S3.SS4.p3.2.m1.1.1.cmml" xref="S3.SS4.p3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m1.1.1.1.cmml" xref="S3.SS4.p3.2.m1.1.1">subscript</csymbol><ci id="S3.SS4.p3.2.m1.1.1.2.cmml" xref="S3.SS4.p3.2.m1.1.1.2">𝐲</ci><ci id="S3.SS4.p3.2.m1.1.1.3.cmml" xref="S3.SS4.p3.2.m1.1.1.3">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m1.1c">{\bf y}_{\cdot}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.2.m1.1d">bold_y start_POSTSUBSCRIPT ⋅ end_POSTSUBSCRIPT</annotation></semantics></math> is the final logits, <math alttext="{\mathbf{M}}" class="ltx_Math" display="inline" id="S3.SS4.p3.3.m2.1"><semantics id="S3.SS4.p3.3.m2.1a"><mi id="S3.SS4.p3.3.m2.1.1" xref="S3.SS4.p3.3.m2.1.1.cmml">𝐌</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m2.1b"><ci id="S3.SS4.p3.3.m2.1.1.cmml" xref="S3.SS4.p3.3.m2.1.1">𝐌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m2.1c">{\mathbf{M}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.3.m2.1d">bold_M</annotation></semantics></math> is the model, and <math alttext="{\bf x}" class="ltx_Math" display="inline" id="S3.SS4.p3.4.m3.1"><semantics id="S3.SS4.p3.4.m3.1a"><mi id="S3.SS4.p3.4.m3.1.1" xref="S3.SS4.p3.4.m3.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.4.m3.1b"><ci id="S3.SS4.p3.4.m3.1.1.cmml" xref="S3.SS4.p3.4.m3.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.4.m3.1c">{\bf x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.4.m3.1d">bold_x</annotation></semantics></math> is the input. Afterwards, we apply the standard distillation loss (<math alttext="L" class="ltx_Math" display="inline" id="S3.SS4.p3.5.m4.1"><semantics id="S3.SS4.p3.5.m4.1a"><mi id="S3.SS4.p3.5.m4.1.1" xref="S3.SS4.p3.5.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.5.m4.1b"><ci id="S3.SS4.p3.5.m4.1.1.cmml" xref="S3.SS4.p3.5.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.5.m4.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.5.m4.1d">italic_L</annotation></semantics></math>) upon the outputs with temperature (<math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS4.p3.6.m5.1"><semantics id="S3.SS4.p3.6.m5.1a"><mi id="S3.SS4.p3.6.m5.1.1" xref="S3.SS4.p3.6.m5.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.6.m5.1b"><ci id="S3.SS4.p3.6.m5.1.1.cmml" xref="S3.SS4.p3.6.m5.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.6.m5.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.6.m5.1d">italic_τ</annotation></semantics></math>) using <cite class="ltx_cite ltx_citemacro_citep">(Hinton et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib19" title="">2015</a>)</cite>.
After the distillation, the original KV projection layers <math alttext="&gt;l" class="ltx_Math" display="inline" id="S3.SS4.p3.7.m6.1"><semantics id="S3.SS4.p3.7.m6.1a"><mrow id="S3.SS4.p3.7.m6.1.1" xref="S3.SS4.p3.7.m6.1.1.cmml"><mi id="S3.SS4.p3.7.m6.1.1.2" xref="S3.SS4.p3.7.m6.1.1.2.cmml"></mi><mo id="S3.SS4.p3.7.m6.1.1.1" xref="S3.SS4.p3.7.m6.1.1.1.cmml">&gt;</mo><mi id="S3.SS4.p3.7.m6.1.1.3" xref="S3.SS4.p3.7.m6.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.7.m6.1b"><apply id="S3.SS4.p3.7.m6.1.1.cmml" xref="S3.SS4.p3.7.m6.1.1"><gt id="S3.SS4.p3.7.m6.1.1.1.cmml" xref="S3.SS4.p3.7.m6.1.1.1"></gt><csymbol cd="latexml" id="S3.SS4.p3.7.m6.1.1.2.cmml" xref="S3.SS4.p3.7.m6.1.1.2">absent</csymbol><ci id="S3.SS4.p3.7.m6.1.1.3.cmml" xref="S3.SS4.p3.7.m6.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.7.m6.1c">&gt;l</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.7.m6.1d">&gt; italic_l</annotation></semantics></math> are discarded during inference.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">This method allows us to perform the distillation for Llama-3.1-8B-Instruct on 680M tokens of data in 3 hours using 8 H100 GPUs, and Llama-3.1-70B-Instruct in 5 hours using 32 H100 GPUs across 4 nodes.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Optimized Implementation for Inference</h3>
<div class="ltx_para ltx_noindent" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">LLM serving systems can be complex and incorporate many simultaneous optimizations at multiple layers of the stack, such as PagedAttention <cite class="ltx_cite ltx_citemacro_citep">(Kwon et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib24" title="">2023</a>)</cite>, Speculative Decoding <cite class="ltx_cite ltx_citemacro_citep">(Leviathan et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib25" title="">2023</a>)</cite>, SplitFuse <cite class="ltx_cite ltx_citemacro_citep">(Holmes et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib20" title="">2024</a>; Agrawal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib1" title="">2024</a>)</cite>, and more. One benefit of SwiftKV is that it makes minimal changes to the model architecture, limited to only a few linear projection layers. This means that SwiftKV can easily be integrated into existing serving systems without implementing new kernels (e.g. for custom attention operations or sparse computation) or novel inference procedures.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.2"><span class="ltx_text ltx_font_bold" id="S3.SS5.p2.2.1">Implementation in vLLM.</span> To realize the performance benefits of SwiftKV, we integrated it with vLLM . Our implementation is compatible with vLLM’s chunked prefill, which processes prefill tokens in chunks and may mix prefills and decodes in each minibatch. During each forward pass, after completing layer <math alttext="l" class="ltx_Math" display="inline" id="S3.SS5.p2.1.m1.1"><semantics id="S3.SS5.p2.1.m1.1a"><mi id="S3.SS5.p2.1.m1.1.1" xref="S3.SS5.p2.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.1.m1.1b"><ci id="S3.SS5.p2.1.m1.1.1.cmml" xref="S3.SS5.p2.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.1.m1.1d">italic_l</annotation></semantics></math>, the KV-cache for the remaining layers (<math alttext="&gt;l" class="ltx_Math" display="inline" id="S3.SS5.p2.2.m2.1"><semantics id="S3.SS5.p2.2.m2.1a"><mrow id="S3.SS5.p2.2.m2.1.1" xref="S3.SS5.p2.2.m2.1.1.cmml"><mi id="S3.SS5.p2.2.m2.1.1.2" xref="S3.SS5.p2.2.m2.1.1.2.cmml"></mi><mo id="S3.SS5.p2.2.m2.1.1.1" xref="S3.SS5.p2.2.m2.1.1.1.cmml">&gt;</mo><mi id="S3.SS5.p2.2.m2.1.1.3" xref="S3.SS5.p2.2.m2.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.2.m2.1b"><apply id="S3.SS5.p2.2.m2.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1"><gt id="S3.SS5.p2.2.m2.1.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1.1"></gt><csymbol cd="latexml" id="S3.SS5.p2.2.m2.1.1.2.cmml" xref="S3.SS5.p2.2.m2.1.1.2">absent</csymbol><ci id="S3.SS5.p2.2.m2.1.1.3.cmml" xref="S3.SS5.p2.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.2.m2.1c">&gt;l</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.2.m2.1d">&gt; italic_l</annotation></semantics></math>) are immediately computed, and only the decode tokens are propagated through the rest of the model layers.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS5.p3">
<p class="ltx_p" id="S3.SS5.p3.4"><span class="ltx_text ltx_font_bold" id="S3.SS5.p3.4.1">GEMM and Memory Optimizations.</span> Upon this basic implementation, we implemented two additional optimizations. First, <em class="ltx_emph ltx_font_italic" id="S3.SS5.p3.4.2">SingleInputKV fusion</em>: instead of computing the KV cache <math alttext="{\mathbf{KV}}_{j}" class="ltx_Math" display="inline" id="S3.SS5.p3.1.m1.1"><semantics id="S3.SS5.p3.1.m1.1a"><msub id="S3.SS5.p3.1.m1.1.1" xref="S3.SS5.p3.1.m1.1.1.cmml"><mi id="S3.SS5.p3.1.m1.1.1.2" xref="S3.SS5.p3.1.m1.1.1.2.cmml">𝐊𝐕</mi><mi id="S3.SS5.p3.1.m1.1.1.3" xref="S3.SS5.p3.1.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.1.m1.1b"><apply id="S3.SS5.p3.1.m1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.1.m1.1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.p3.1.m1.1.1.2.cmml" xref="S3.SS5.p3.1.m1.1.1.2">𝐊𝐕</ci><ci id="S3.SS5.p3.1.m1.1.1.3.cmml" xref="S3.SS5.p3.1.m1.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.1.m1.1c">{\mathbf{KV}}_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p3.1.m1.1d">bold_KV start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> for each layer <math alttext="j&gt;l" class="ltx_Math" display="inline" id="S3.SS5.p3.2.m2.1"><semantics id="S3.SS5.p3.2.m2.1a"><mrow id="S3.SS5.p3.2.m2.1.1" xref="S3.SS5.p3.2.m2.1.1.cmml"><mi id="S3.SS5.p3.2.m2.1.1.2" xref="S3.SS5.p3.2.m2.1.1.2.cmml">j</mi><mo id="S3.SS5.p3.2.m2.1.1.1" xref="S3.SS5.p3.2.m2.1.1.1.cmml">&gt;</mo><mi id="S3.SS5.p3.2.m2.1.1.3" xref="S3.SS5.p3.2.m2.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.2.m2.1b"><apply id="S3.SS5.p3.2.m2.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1"><gt id="S3.SS5.p3.2.m2.1.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1.1"></gt><ci id="S3.SS5.p3.2.m2.1.1.2.cmml" xref="S3.SS5.p3.2.m2.1.1.2">𝑗</ci><ci id="S3.SS5.p3.2.m2.1.1.3.cmml" xref="S3.SS5.p3.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.2.m2.1c">j&gt;l</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p3.2.m2.1d">italic_j &gt; italic_l</annotation></semantics></math> one at a time, we fused all <math alttext="{\mathbf{W}}_{KV}^{j}" class="ltx_Math" display="inline" id="S3.SS5.p3.3.m3.1"><semantics id="S3.SS5.p3.3.m3.1a"><msubsup id="S3.SS5.p3.3.m3.1.1" xref="S3.SS5.p3.3.m3.1.1.cmml"><mi id="S3.SS5.p3.3.m3.1.1.2.2" xref="S3.SS5.p3.3.m3.1.1.2.2.cmml">𝐖</mi><mrow id="S3.SS5.p3.3.m3.1.1.2.3" xref="S3.SS5.p3.3.m3.1.1.2.3.cmml"><mi id="S3.SS5.p3.3.m3.1.1.2.3.2" xref="S3.SS5.p3.3.m3.1.1.2.3.2.cmml">K</mi><mo id="S3.SS5.p3.3.m3.1.1.2.3.1" xref="S3.SS5.p3.3.m3.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS5.p3.3.m3.1.1.2.3.3" xref="S3.SS5.p3.3.m3.1.1.2.3.3.cmml">V</mi></mrow><mi id="S3.SS5.p3.3.m3.1.1.3" xref="S3.SS5.p3.3.m3.1.1.3.cmml">j</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.3.m3.1b"><apply id="S3.SS5.p3.3.m3.1.1.cmml" xref="S3.SS5.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.3.m3.1.1.1.cmml" xref="S3.SS5.p3.3.m3.1.1">superscript</csymbol><apply id="S3.SS5.p3.3.m3.1.1.2.cmml" xref="S3.SS5.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.3.m3.1.1.2.1.cmml" xref="S3.SS5.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS5.p3.3.m3.1.1.2.2.cmml" xref="S3.SS5.p3.3.m3.1.1.2.2">𝐖</ci><apply id="S3.SS5.p3.3.m3.1.1.2.3.cmml" xref="S3.SS5.p3.3.m3.1.1.2.3"><times id="S3.SS5.p3.3.m3.1.1.2.3.1.cmml" xref="S3.SS5.p3.3.m3.1.1.2.3.1"></times><ci id="S3.SS5.p3.3.m3.1.1.2.3.2.cmml" xref="S3.SS5.p3.3.m3.1.1.2.3.2">𝐾</ci><ci id="S3.SS5.p3.3.m3.1.1.2.3.3.cmml" xref="S3.SS5.p3.3.m3.1.1.2.3.3">𝑉</ci></apply></apply><ci id="S3.SS5.p3.3.m3.1.1.3.cmml" xref="S3.SS5.p3.3.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.3.m3.1c">{\mathbf{W}}_{KV}^{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p3.3.m3.1d">bold_W start_POSTSUBSCRIPT italic_K italic_V end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT</annotation></semantics></math> into one large weight matrix <math alttext="{\mathbf{W}}_{KV}^{j&gt;l}" class="ltx_Math" display="inline" id="S3.SS5.p3.4.m4.1"><semantics id="S3.SS5.p3.4.m4.1a"><msubsup id="S3.SS5.p3.4.m4.1.1" xref="S3.SS5.p3.4.m4.1.1.cmml"><mi id="S3.SS5.p3.4.m4.1.1.2.2" xref="S3.SS5.p3.4.m4.1.1.2.2.cmml">𝐖</mi><mrow id="S3.SS5.p3.4.m4.1.1.2.3" xref="S3.SS5.p3.4.m4.1.1.2.3.cmml"><mi id="S3.SS5.p3.4.m4.1.1.2.3.2" xref="S3.SS5.p3.4.m4.1.1.2.3.2.cmml">K</mi><mo id="S3.SS5.p3.4.m4.1.1.2.3.1" xref="S3.SS5.p3.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS5.p3.4.m4.1.1.2.3.3" xref="S3.SS5.p3.4.m4.1.1.2.3.3.cmml">V</mi></mrow><mrow id="S3.SS5.p3.4.m4.1.1.3" xref="S3.SS5.p3.4.m4.1.1.3.cmml"><mi id="S3.SS5.p3.4.m4.1.1.3.2" xref="S3.SS5.p3.4.m4.1.1.3.2.cmml">j</mi><mo id="S3.SS5.p3.4.m4.1.1.3.1" xref="S3.SS5.p3.4.m4.1.1.3.1.cmml">&gt;</mo><mi id="S3.SS5.p3.4.m4.1.1.3.3" xref="S3.SS5.p3.4.m4.1.1.3.3.cmml">l</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.4.m4.1b"><apply id="S3.SS5.p3.4.m4.1.1.cmml" xref="S3.SS5.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.4.m4.1.1.1.cmml" xref="S3.SS5.p3.4.m4.1.1">superscript</csymbol><apply id="S3.SS5.p3.4.m4.1.1.2.cmml" xref="S3.SS5.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.4.m4.1.1.2.1.cmml" xref="S3.SS5.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS5.p3.4.m4.1.1.2.2.cmml" xref="S3.SS5.p3.4.m4.1.1.2.2">𝐖</ci><apply id="S3.SS5.p3.4.m4.1.1.2.3.cmml" xref="S3.SS5.p3.4.m4.1.1.2.3"><times id="S3.SS5.p3.4.m4.1.1.2.3.1.cmml" xref="S3.SS5.p3.4.m4.1.1.2.3.1"></times><ci id="S3.SS5.p3.4.m4.1.1.2.3.2.cmml" xref="S3.SS5.p3.4.m4.1.1.2.3.2">𝐾</ci><ci id="S3.SS5.p3.4.m4.1.1.2.3.3.cmml" xref="S3.SS5.p3.4.m4.1.1.2.3.3">𝑉</ci></apply></apply><apply id="S3.SS5.p3.4.m4.1.1.3.cmml" xref="S3.SS5.p3.4.m4.1.1.3"><gt id="S3.SS5.p3.4.m4.1.1.3.1.cmml" xref="S3.SS5.p3.4.m4.1.1.3.1"></gt><ci id="S3.SS5.p3.4.m4.1.1.3.2.cmml" xref="S3.SS5.p3.4.m4.1.1.3.2">𝑗</ci><ci id="S3.SS5.p3.4.m4.1.1.3.3.cmml" xref="S3.SS5.p3.4.m4.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.4.m4.1c">{\mathbf{W}}_{KV}^{j&gt;l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p3.4.m4.1d">bold_W start_POSTSUBSCRIPT italic_K italic_V end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j &gt; italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> so that their KV cache can be computed with a single efficient GEMM operation. Second, <em class="ltx_emph ltx_font_italic" id="S3.SS5.p3.4.3">AcrossKV reduction</em>: we modified vLLM to only allocate one layer’s KV-cache for each group of merged layers, which realizes the memory gains of AcrossKV.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Main Results</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Setup</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">Training and Evaluation.</span> We use Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as our base models for SwiftKV.
Our training datasets include a mixture of the full supervised training data from <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.2">HuggingFaceH4/ultrachat_200k</span> <cite class="ltx_cite ltx_citemacro_citep">(Ding et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib12" title="">2023</a>)</cite> and <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.3">teknium/OpenHermes-2.5</span> <cite class="ltx_cite ltx_citemacro_citep">(Teknium, <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib47" title="">2023</a>)</cite>. We evaluated model quality using a modified LM-Eval-Harness <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib14" title="">2024</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/neuralmagic/lm-evaluation-harness/tree/llama_3.1_instruct" title="">https://github.com/neuralmagic/lm-evaluation-harness/tree/llama_3.1_instruct</a></span></span></span> due to its support for the custom prompt format of Llama-3.1, particularly for MMLU and MMLU-CoT <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib18" title="">2021</a>)</cite>, GSM8K <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib10" title="">2021</a>)</cite>, and Arc-Challenge <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib9" title="">2018</a>)</cite>. For more details, please see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3" title="Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.2.1">Compression Metrics.</span> For prefill computation, we report the approximate reduction as <math alttext="(L-l)/L" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mrow id="S4.SS1.p2.1.m1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.cmml"><mo id="S4.SS1.p2.1.m1.1.1.1.1.2" stretchy="false" xref="S4.SS1.p2.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS1.p2.1.m1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml">L</mi><mo id="S4.SS1.p2.1.m1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.cmml">−</mo><mi id="S4.SS1.p2.1.m1.1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.1.3.cmml">l</mi></mrow><mo id="S4.SS1.p2.1.m1.1.1.1.1.3" stretchy="false" xref="S4.SS1.p2.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">/</mo><mi id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><divide id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2"></divide><apply id="S4.SS1.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1"><minus id="S4.SS1.p2.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1"></minus><ci id="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2">𝐿</ci><ci id="S4.SS1.p2.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.3">𝑙</ci></apply><ci id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">(L-l)/L</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">( italic_L - italic_l ) / italic_L</annotation></semantics></math> due to SingleInputKV, and for KV cache, we report the exact memory reduction due to AcrossKV. For example, SwiftKV with SingleInputKV (<math alttext="l=L/2" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">l</mi><mo id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml"><mi id="S4.SS1.p2.2.m2.1.1.3.2" xref="S4.SS1.p2.2.m2.1.1.3.2.cmml">L</mi><mo id="S4.SS1.p2.2.m2.1.1.3.1" xref="S4.SS1.p2.2.m2.1.1.3.1.cmml">/</mo><mn id="S4.SS1.p2.2.m2.1.1.3.3" xref="S4.SS1.p2.2.m2.1.1.3.3.cmml">2</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><eq id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1"></eq><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">𝑙</ci><apply id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3"><divide id="S4.SS1.p2.2.m2.1.1.3.1.cmml" xref="S4.SS1.p2.2.m2.1.1.3.1"></divide><ci id="S4.SS1.p2.2.m2.1.1.3.2.cmml" xref="S4.SS1.p2.2.m2.1.1.3.2">𝐿</ci><cn id="S4.SS1.p2.2.m2.1.1.3.3.cmml" type="integer" xref="S4.SS1.p2.2.m2.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">l=L/2</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">italic_l = italic_L / 2</annotation></semantics></math>) and 4-way AcrossKV is reported as 50% prefill compute reduction and 37.5% KV cache memory reduction. We further study how these theoretical compute and memory reductions translate into end-to-end inference improvements in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.SS3" title="4.3 Inference Performance ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Inference Performance.</span> In our inference evaluation, we focus on two common scenarios: <em class="ltx_emph ltx_font_italic" id="S4.SS1.p3.1.2">batch-inference</em> for cost sensitive scenarios and <em class="ltx_emph ltx_font_italic" id="S4.SS1.p3.1.3">interactive-inference</em> for latency sensitive scenario.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><em class="ltx_emph ltx_font_italic" id="S4.SS1.p4.1.1">Batch-Inference</em> When processing text in bulk or when serving a model under high usage demand, it is important to achieve high <em class="ltx_emph ltx_font_italic" id="S4.SS1.p4.1.2">combined throughput</em> in terms of input + output tokens processed per second. For bulk processing, the combined throughput determines the time it takes to finish the job. For interactive use, it determines the volume of concurrent users and requests that can be supported per unit of hardware. In both scenarios, the combined throughput is a key determinant of the cost of serving the model.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1"><em class="ltx_emph ltx_font_italic" id="S4.SS1.p5.1.1">Interactive-Inference</em> In interactive scenarios (e.g., chatbots, copilots), not only the combined throughput is important, but also metrics that define the end-user experience. Chief upon them are the time-to-first-token (TTFT) and time-per-output-token (TPOT). TTFT is the time between the user sending a message and receiving the first token in the response. TPOT is the time between each output token after the first token has been received. Low TTFT and TPOT are desirable by interactive applications to deliver smooth usage experiences.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1">For all experiments on Llama-3.1-8B-Instruct, we use 1 NVIDIA H100 GPU with 80GB of memory, and for all experiments on Llama-3.1-70B-Instruct, we use 4 NVIDIA H100 GPUs running the model with 4-way tensor parallelism. We provide the full hardware and vLLM configurations in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3.SS2" title="C.2 Inference Speedup Evaluation Details ‣ Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">C.2</span></a></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model Quality with Compression</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2"><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.2.1">Llama-3.1-8B-Instruct.</span>
The top rows of  Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.T1" title="Table 1 ‣ 4.2 Model Quality with Compression ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">1</span></a> show that SwiftKV can preserve model quality well until 50% prefill reduction using SingleInputKV. For 25% prefill reduction, the accuracy degradation is only about 0.12 points and for 50% reduction, the gap is about 1 point <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Note that we did not try to find the best training recipe, regarding to either training data (e.g., we did not include any math or coding datasets) or training pipeline (e.g., we did not include reinforce-learning rated steps, like DPO/RLHF). Yet, the quality of SwiftKV is close to the original base Llama-3.1-8/70B-Instruct models. In Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.SS3" title="5.3 The impact of fine-tuning datasets ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5.3</span></a>, we show that better data recipe could boost the model performance and close the quality gap further.</span></span></span>. When we push to 62.5% reduction (i.e. SingleInputKV with <math alttext="l=12" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">l</mi><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><eq id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></eq><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">𝑙</ci><cn id="S4.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">l=12</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_l = 12</annotation></semantics></math> and <math alttext="L=32" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">L</mi><mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><eq id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></eq><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">𝐿</ci><cn id="S4.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">L=32</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_L = 32</annotation></semantics></math>), the accuracy drops to 66.09 points, which is significantly lower than the baseline. This can be explained by the drop in activation similarity from 0.61 to 0.51 between layer 16 to layer 12 (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.F2" title="Figure 2 ‣ 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">The bottom rows of Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.T1" title="Table 1 ‣ 4.2 Model Quality with Compression ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">1</span></a> show the model quality when adding AcrossKV to 50% SingleInputKV. From pure SingleInputKV to 2-way AcrossKV, the accuracy drops about 0.9 points with 25% KV cache reduction.
The accuracy drops by another 0.32, going from 2-way to 8-way sharing, and 0.62 when going all the way to 16-way sharing.
Particularly, for the extreme case, i.e., using a single KV cache for all remaining layers, the accuracy is only about 2.5 points lower than pure SingleInputKV, and could be useful for more memory constrained cases, e.g., embedding and/or mobile devices.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Furthermore, the design of AcrossKV is complementary to many existing KV cache compression methods. In Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.SS4" title="5.4 Combining with other KV cache compression methods ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5.4</span></a>, we show that AcrossKV can be combined with quantization to achieve 62.5% reduction in KV cache memory with only a 1-point accuracy gap compared to SingleInputKV only.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>
Llama-3.1-8B-Instruct</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T1.1" style="width:687.0pt;height:181pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S4.T1.1.1"><span class="ltx_text" id="S4.T1.1.1.1">
<span class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1.1.1.1">
<span class="ltx_tr" id="S4.T1.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S4.T1.1.1.1.1.1.1"><span class="ltx_text" id="S4.T1.1.1.1.1.1.1.1">Model</span></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.1.1.2">SingleInputKV</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.1.1.3">AcrossKV</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.1.1.4">Arc-Challenge</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.1.1.5">Winogrande</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.1.1.6">HelloSwag</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.1.1.7">truthfulqa</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.1.1.8">MMLU</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.1.1.9">MMLU-CoT</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.1.1.10">GSM-8K</span>
<span class="ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S4.T1.1.1.1.1.1.11"><span class="ltx_text" id="S4.T1.1.1.1.1.1.11.1">Avg.</span></span></span>
<span class="ltx_tr" id="S4.T1.1.1.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.2.1">(Prefill Reduction)</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.2.2">(Cache Reduction)</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.2.3">0-shot</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.2.4">5-shots</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.2.5">10-shots</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.2.6">0-shot</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.2.7">5-shots</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.2.8">0-shot</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.2.9">8-shots</span></span>
<span class="ltx_tr" id="S4.T1.1.1.1.1.3">
<span class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.1.1.3.1">Baseline</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.2">N/A</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.3">N/A</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.4">82.00</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.5">77.90</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.6">80.40</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.7">54.56</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.8">67.90</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.9">70.63</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.10">82.56</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.3.11">73.71</span></span>
<span class="ltx_tr" id="S4.T1.1.1.1.1.4">
<span class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.1.1.4.1">SwiftKV</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.2">✓(25%)</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.3">✗</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.4">82.08</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.5">77.98</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.6">80.63</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.7">54.59</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.8">67.95</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.9">70.45</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.10">81.43</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.4.11">73.59</span></span>
<span class="ltx_tr" id="S4.T1.1.1.1.1.5">
<span class="ltx_td ltx_align_left" id="S4.T1.1.1.1.1.5.1">SwiftKV</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.2">✓(50%)</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.3">✗</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.4">80.38</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.5">78.22</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.6">79.30</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.7">54.54</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.8">67.30</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.9">69.73</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.10">79.45</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.5.11">72.70</span></span>
<span class="ltx_tr" id="S4.T1.1.1.1.1.6">
<span class="ltx_td ltx_align_left" id="S4.T1.1.1.1.1.6.1">SwiftKV</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.2">✓(62.5%)</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.3">✗</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.4">71.76</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.5">75.77</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.6">78.21</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.7">52.73</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.8">61.55</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.9">53.68</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.10">68.92</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.6.11">66.09</span></span>
<span class="ltx_tr" id="S4.T1.1.1.1.1.7">
<span class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.1.1.7.1">SwiftKV</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.2">✓(50%)</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.3">2-way (25%)</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.4">80.29</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.5">77.82</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.6">79.03</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.7">54.66</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.8">66.96</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.9">68.39</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.10">75.59</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.1.7.11">71.82</span></span>
<span class="ltx_tr" id="S4.T1.1.1.1.1.8">
<span class="ltx_td ltx_align_left" id="S4.T1.1.1.1.1.8.1">SwiftKV</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.2">✓(50%)</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.3">4-way (37.5%)</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.4">79.35</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.5">77.51</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.6">78.44</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.7">54.96</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.8">65.71</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.9">67.75</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.10">76.72</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.8.11">71.49</span></span>
<span class="ltx_tr" id="S4.T1.1.1.1.1.9">
<span class="ltx_td ltx_align_left" id="S4.T1.1.1.1.1.9.1">SwiftKV</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.2">✓(50%)</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.3">8-way (43.75%)</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.4">79.18</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.5">77.19</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.6">77.38</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.7">54.79</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.8">65.73</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.9">66.88</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.10">72.33</span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.9.11">70.50</span></span>
<span class="ltx_tr" id="S4.T1.1.1.1.1.10">
<span class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.1.1.1.10.1">SwiftKV</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.2">✓(50%)</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.3">16-way (46.875%)</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.4">78.24</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.5">76.80</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.6">76.87</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.7">56.86</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.8">64.65</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.9">65.86</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.10">72.25</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.1.1.10.11">70.22</span></span>
</span></span></p>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>
Llama-3.1-70B-Instruct</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T2.1" style="width:671.5pt;height:127pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S4.T2.1.1"><span class="ltx_text" id="S4.T2.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.1.1.1">
<span class="ltx_tr" id="S4.T2.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S4.T2.1.1.1.1.1.1"><span class="ltx_text" id="S4.T2.1.1.1.1.1.1.1">Model</span></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.1.1.2">SingleInputKV</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.1.1.3">AcrossKV</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.1.1.4">Arc-Challenge</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.1.1.5">Winogrande</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.1.1.6">HelloSwag</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.1.1.7">truthfulqa</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.1.1.8">MMLU</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.1.1.9">MMLU-CoT</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.1.1.10">GSM-8K</span>
<span class="ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S4.T2.1.1.1.1.1.11"><span class="ltx_text" id="S4.T2.1.1.1.1.1.11.1">Avg.</span></span></span>
<span class="ltx_tr" id="S4.T2.1.1.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.2.1">Prefill Reduction</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.2.2">Cache Reduction</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.2.3">0-shot</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.2.4">5-shots</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.2.5">10-shots</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.2.6">0-shot</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.2.7">5-shots</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.2.8">0-shot</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.2.9">8-shots</span></span>
<span class="ltx_tr" id="S4.T2.1.1.1.1.3">
<span class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.1.1.3.1">Baseline</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.2">N/A</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.3">N/A</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.4">93.34</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.5">85.16</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.6">86.42</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.7">59.95</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.8">83.97</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.9">86.21</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.10">95.15</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.3.11">84.31</span></span>
<span class="ltx_tr" id="S4.T2.1.1.1.1.4">
<span class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.1.1.4.1">SwiftKV</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.2">✓(25%)</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.3">✗</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.4">93.00</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.5">84.69</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.6">85.98</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.7">59.43</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.8">82.82</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.9">85.81</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.10">95.07</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.4.11">83.83</span></span>
<span class="ltx_tr" id="S4.T2.1.1.1.1.5">
<span class="ltx_td ltx_align_left" id="S4.T2.1.1.1.1.5.1">SwiftKV</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.2">✓(50%)</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.3">✗</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.4">93.09</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.5">83.82</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.6">84.45</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.7">58.40</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.8">82.51</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.9">85.00</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.10">93.56</span>
<span class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.5.11">82.98</span></span>
<span class="ltx_tr" id="S4.T2.1.1.1.1.6">
<span class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.1.1.6.1">SwiftKV</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.2">✓(50%)</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.3">2-way (25%)</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.4">92.92</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.5">82.95</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.6">84.10</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.7">57.79</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.8">82.66</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.9">84.55</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.10">93.48</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1.6.11">82.63</span></span>
<span class="ltx_tr" id="S4.T2.1.1.1.1.7">
<span class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.1.1.1.7.1">SwiftKV</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.2">✓(50%)</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.3">4-way (37.5%)</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.4">92.92</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.5">83.74</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.6">84.72</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.7">58.28</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.8">82.60</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.9">84.79</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.10">93.71</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.1.7.11">82.96</span></span>
</span></span></p>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">Llama-3.1-70B-Instruct.</span>
 Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.T2" title="Table 2 ‣ 4.2 Model Quality with Compression ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">2</span></a> shows that with 50% prefill reduction using SingleInputKV, Llama-3.1-70B-Instruct incurs a 1.3 point drop in accuracy which is slightly higher than the results of Llama-3.1-8B-Instruct. However, Llama-3.1-70B-Instruct is more resilient to AcrossKV, incurring less than a 0.35 point drop in accuracy even for 4-way sharing across layers.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Inference Performance </h3>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.1">Batch Inference Performance.</span>
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.F3" title="Figure 3 ‣ 4.3 Inference Performance ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">3</span></a> shows the results of Llama-3.1-8B and Llama-3.1-70B across several workloads with a range of input lengths. SwiftKV achieves higher combined throughput than the baseline model across all the workloads we evaluated.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.4">For Llama-3.1-8B-Instruct, with 2K input tokens per prompt, SwiftKV achieves <math alttext="1.2-1.3\times" class="ltx_math_unparsed" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1b"><mn id="S4.SS3.p2.1.m1.1.1">1.2</mn><mo id="S4.SS3.p2.1.m1.1.2">−</mo><mn id="S4.SS3.p2.1.m1.1.3">1.3</mn><mo id="S4.SS3.p2.1.m1.1.4" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">1.2-1.3\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">1.2 - 1.3 ×</annotation></semantics></math> higher combined throughput than the baseline model, and our benefits increase further to <math alttext="1.8-1.9\times" class="ltx_math_unparsed" display="inline" id="S4.SS3.p2.2.m2.1"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1b"><mn id="S4.SS3.p2.2.m2.1.1">1.8</mn><mo id="S4.SS3.p2.2.m2.1.2">−</mo><mn id="S4.SS3.p2.2.m2.1.3">1.9</mn><mo id="S4.SS3.p2.2.m2.1.4" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">1.8-1.9\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.2.m2.1d">1.8 - 1.9 ×</annotation></semantics></math> higher combined throughput with 128K inputs. Note that for an input length of 8K tokens, SwiftKV achieves a staggering 30K tokens/sec/GPU (480 TFLOPS/GPU). For Llama-3.1-70B with 2K input tokens per prompt, SwiftKV achieves <math alttext="1.4-1.5\times" class="ltx_math_unparsed" display="inline" id="S4.SS3.p2.3.m3.1"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1b"><mn id="S4.SS3.p2.3.m3.1.1">1.4</mn><mo id="S4.SS3.p2.3.m3.1.2">−</mo><mn id="S4.SS3.p2.3.m3.1.3">1.5</mn><mo id="S4.SS3.p2.3.m3.1.4" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">1.4-1.5\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.3.m3.1d">1.4 - 1.5 ×</annotation></semantics></math> higher combined throughput than the baseline model, which improves to <math alttext="1.8-2.0\times" class="ltx_math_unparsed" display="inline" id="S4.SS3.p2.4.m4.1"><semantics id="S4.SS3.p2.4.m4.1a"><mrow id="S4.SS3.p2.4.m4.1b"><mn id="S4.SS3.p2.4.m4.1.1">1.8</mn><mo id="S4.SS3.p2.4.m4.1.2">−</mo><mn id="S4.SS3.p2.4.m4.1.3">2.0</mn><mo id="S4.SS3.p2.4.m4.1.4" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">1.8-2.0\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.4.m4.1d">1.8 - 2.0 ×</annotation></semantics></math> better combined throughput for 128K inputs.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>While the total compute savings is roughly <math alttext="2\times" class="ltx_math_unparsed" display="inline" id="footnote4.m1.1"><semantics id="footnote4.m1.1b"><mrow id="footnote4.m1.1c"><mn id="footnote4.m1.1.1">2</mn><mo id="footnote4.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="footnote4.m1.1d">2\times</annotation><annotation encoding="application/x-llamapun" id="footnote4.m1.1e">2 ×</annotation></semantics></math>, the end-to-end speedup is lower due to two main reasons: i) the performance improvement is limited to the decoding computation which needs the output activation of all the layers. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.F2" title="Figure 2 ‣ 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">2</span></a> (right) shows the max possible speedup for Llama-3.1-8B-Instruct during model forward pass despite the decoding overhead, and ii) due to additional vLLM overheads outside of the model forward pass, such as sampling, optimizing which is beyond the scope of the paper.</span></span></span> As expected, SwiftKV provides greater improvements when the inputs are long.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">We also observe AcrossKV can further improve the combined throughput due to its ability to reduce the memory usage for the KV-cache and supporting larger batch sizes. For sequence length of 8K, Llama-3.1-70B-Instruct with SwiftKV achieves a combined throughput of over 16K toks/sec over 4xH100 GPUs which corresponds to 560 TFLOPS/GPU of bf16 performance when normalized to baseline. This is an unprecedented throughput for BF16 inference workloads.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="167" id="S4.F3.g1" src="x4.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>
Combined input and output throughput for Llama-3.1-8B (left) and Llama-3.1-70B (right) across a range of input lengths (bottom). For each experiment, a number of requests are sent to vLLM at once such that the total number of tokens is roughly 15M. Each request generates 256 output tokens.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.1">Interactive-Inference Performance.</span>
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.F4" title="Figure 4 ‣ 4.3 Inference Performance ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4</span></a> shows the TTFT and TPOT of Llama-3.1-70B-Instruct across a range of request arrival rates and input lengths. When the arrival rate is too high, the TTFT explodes due to the request queue accumulating faster than they can be processed by the system. However, SwiftKV can sustain <math alttext="1.5-2.0\times" class="ltx_math_unparsed" display="inline" id="S4.SS3.p4.1.m1.1"><semantics id="S4.SS3.p4.1.m1.1a"><mrow id="S4.SS3.p4.1.m1.1b"><mn id="S4.SS3.p4.1.m1.1.1">1.5</mn><mo id="S4.SS3.p4.1.m1.1.2">−</mo><mn id="S4.SS3.p4.1.m1.1.3">2.0</mn><mo id="S4.SS3.p4.1.m1.1.4" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">1.5-2.0\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.1.m1.1d">1.5 - 2.0 ×</annotation></semantics></math> higher arrival rates before experiencing such TTFT explosion. When the arrival rate is low, SwiftKV can reduce the TTFT by up to 50% for workloads with longer input lengths. In terms of TPOT, SwiftKV achieves significant reductions for all but the lowest arrival rates, up to 60% for certain settings. A similar story unfolds for Llama-3.1-8B, which can be found in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3.F1" title="Figure C.1 ‣ C.2 Inference Speedup Evaluation Details ‣ Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">C.1</span></a> in the Appendix.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="262" id="S4.F4.g1" src="x5.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>
Time to first token (TTFT, top) and time per output token (TPOT, bottom) for input lengths 2000 (left), 8000 (middle), and 32000 (right) for Llama-3.1-70B. For each experiment, a range of different request arrival rates is simulated. Each request generates 256 output tokens.
</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Ablation and Discussion</h2>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>
Impact of Distillation and Full/Partial Model Finetuning on Llama-3.1-8B-Instruct</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T3.1" style="width:539.2pt;height:145pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S5.T3.1.1"><span class="ltx_text" id="S5.T3.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="S5.T3.1.1.1.1">
<span class="ltx_tr" id="S5.T3.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S5.T3.1.1.1.1.1.1"><span class="ltx_text" id="S5.T3.1.1.1.1.1.1.1">Setting</span></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.1.2">Arc-Challenge</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.1.3">Winogrande</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.1.4">Hellaswag</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.1.5">TruthfulQA</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.1.6">MMLU</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.1.7">MMLU-CoT</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.1.8">GSM-8K</span>
<span class="ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S5.T3.1.1.1.1.1.9"><span class="ltx_text" id="S5.T3.1.1.1.1.1.9.1">Avg.</span></span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.1.2">
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.2.1">0-shot</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.2.2">5-shots</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.2.3">10-shots</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.2.4">0-shot</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.2.5">5-shots</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.2.6">0-shot</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.2.7">8-shots</span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.1.3">
<span class="ltx_td ltx_align_center ltx_border_t ltx_colspan ltx_colspan_9" id="S5.T3.1.1.1.1.3.1">(a) The effect of distillation</span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.1.4">
<span class="ltx_td ltx_align_left" id="S5.T3.1.1.1.1.4.1">W/o Distillation</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.4.2">79.44</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.4.3">77.27</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.4.4">78.71</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.4.5">51.14</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.4.6">65.55</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.4.7">65.60</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.4.8">72.71</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.4.9">70.06</span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.1.5">
<span class="ltx_td ltx_align_left" id="S5.T3.1.1.1.1.5.1">W Distillation</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.5.2">80.38</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.5.3">78.22</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.5.4">79.30</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.5.5">54.54</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.5.6">67.30</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.5.7">69.73</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.5.8">79.45</span>
<span class="ltx_td ltx_align_center" id="S5.T3.1.1.1.1.5.9">72.70</span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.1.6">
<span class="ltx_td ltx_align_center ltx_border_t ltx_colspan ltx_colspan_9" id="S5.T3.1.1.1.1.6.1">(b) Full model finetuning vs. part model finetuning</span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.1.7">
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.1.1.1.7.1">Full Model</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.7.2">76.79</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.7.3">74.82</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.7.4">76.42</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.7.5">53.08</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.7.6">62.94</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.7.7">64.20</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.7.8">69.37</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.7.9">68.23</span></span>
<span class="ltx_tr" id="S5.T3.1.1.1.1.8">
<span class="ltx_td ltx_align_left ltx_border_bb" id="S5.T3.1.1.1.1.8.1">Part Model</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.1.1.8.2">80.38</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.1.1.8.3">78.22</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.1.1.8.4">79.30</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.1.1.8.5">54.54</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.1.1.8.6">67.30</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.1.1.8.7">69.73</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.1.1.8.8">79.45</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.1.1.8.9">72.70</span></span>
</span></span></p>
</span></div>
</figure>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>The impact of distillation</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">To demonstrate the effectiveness of our distillation, we train Llama-3.1-8B-Instruct with 50% SingleInputKV and no AcrossKV using the standard language model loss, and compare it with our distillation based approach discussed in  Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.SS4" title="3.4 Knowledge Recovery ‣ 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">3.4</span></a>.
The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.T3" title="Table 3 ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">3</span></a> (a).
As we can see, the model trained with distillation has a 2.64 point higher average.
Particularly, for generative tasks, i.e., MMLU-Cot and GSM-8K, the performance improvement is 4.13 and 6.74, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Full model training vs. partial model training.</h3>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Our distillation method only fine-tuned the <math alttext="{\mathbf{W}}_{QKV}" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><msub id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">𝐖</mi><mrow id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml"><mi id="S5.SS2.p1.1.m1.1.1.3.2" xref="S5.SS2.p1.1.m1.1.1.3.2.cmml">Q</mi><mo id="S5.SS2.p1.1.m1.1.1.3.1" xref="S5.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS2.p1.1.m1.1.1.3.3" xref="S5.SS2.p1.1.m1.1.1.3.3.cmml">K</mi><mo id="S5.SS2.p1.1.m1.1.1.3.1a" xref="S5.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS2.p1.1.m1.1.1.3.4" xref="S5.SS2.p1.1.m1.1.1.3.4.cmml">V</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">𝐖</ci><apply id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3"><times id="S5.SS2.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.p1.1.m1.1.1.3.1"></times><ci id="S5.SS2.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.p1.1.m1.1.1.3.2">𝑄</ci><ci id="S5.SS2.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3.3">𝐾</ci><ci id="S5.SS2.p1.1.m1.1.1.3.4.cmml" xref="S5.SS2.p1.1.m1.1.1.3.4">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">{\mathbf{W}}_{QKV}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">bold_W start_POSTSUBSCRIPT italic_Q italic_K italic_V end_POSTSUBSCRIPT</annotation></semantics></math> parameters, as discussed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.SS4" title="3.4 Knowledge Recovery ‣ 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">3.4</span></a>, with the hypothesis that it preserves the knowledge from the original models compared to fine-tuning the entire model. This hypothesis aligns with <cite class="ltx_cite ltx_citemacro_cite">Meng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib34" title="">2024</a>)</cite>, <cite class="ltx_cite ltx_citemacro_cite">Geva et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib15" title="">2021</a>)</cite>, and <cite class="ltx_cite ltx_citemacro_cite">Elhage et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib13" title="">2021</a>)</cite>, which suggest that MLP layers player a more prominent role in storing knowledge.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">To validate this, we fine-tuned a model with 50% SingleInputKV on Llama-3.1-8B-Instruct where all parameters in the latter 50% of layers are trained.
The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.T3" title="Table 3 ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">3</span></a> (b).
Note that the model quality of full model distillation is about 4.5 points lower than our proposed partial model distillation.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>The impact of fine-tuning datasets</h3>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Note that in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4" title="4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4</span></a>, we did not try to maximize the performance of SwiftKV from the data recipe perspective since the search space is very large and outside the scope of our paper. However, we want to share some initial findings about the dataset recipe.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p2.1.1">How good is the data used to train SwiftKV?</span>
We chose the datasets to train SwiftKV due to their popular adoption and broad domain and task coverage.
However, as compared to other high-quality domain specific fine-tuning datasets, they may have weaknesses.
To measure the quality of these two datasets, we directly fine-tuned a model using the Llama-3.1-8B base model, and compared this trained model with the Llama-3.1-8B-Instruct model released by Meta.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.T4" title="Table 4 ‣ 5.3 The impact of fine-tuning datasets ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4</span></a> (a).
The original Llama-3.1-8B-Instruct has a average score of 73.71 but the model trained using our two datasets only achieved 65.77.
This indicates the training data used for SwiftKV is not optimal and there may be opportunities to further improve the results we reported in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4" title="4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4</span></a> as discussed next.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p4.1.1">Does more math/coding data help GSM-8K?</span>
From Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.T1" title="Table 1 ‣ 4.2 Model Quality with Compression ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">1</span></a>, the main degradation among 7 tasks for 50% SingleInputKV is GSM-8K.
This may be due to the lack of math and coding examples in the two datasets we picked to train the model.
To verify this, we distilled SwiftKV using one extra math-related dataset, <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p4.1.2">gretelai/synthetic-gsm8k-reflection-405b</span> <cite class="ltx_cite ltx_citemacro_citep">(GretelAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib16" title="">2024</a>)</cite>, and one extra coding dataset, <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p4.1.3">ise-uiuc/Magicoder-OSS-Instruct-75K</span> <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib51" title="">2023</a>)</cite>, in total about <math alttext="8\text{K}+75\text{K}=83\text{K}" class="ltx_Math" display="inline" id="S5.SS3.p4.1.m1.1"><semantics id="S5.SS3.p4.1.m1.1a"><mrow id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml"><mrow id="S5.SS3.p4.1.m1.1.1.2" xref="S5.SS3.p4.1.m1.1.1.2.cmml"><mrow id="S5.SS3.p4.1.m1.1.1.2.2" xref="S5.SS3.p4.1.m1.1.1.2.2.cmml"><mn id="S5.SS3.p4.1.m1.1.1.2.2.2" xref="S5.SS3.p4.1.m1.1.1.2.2.2.cmml">8</mn><mo id="S5.SS3.p4.1.m1.1.1.2.2.1" xref="S5.SS3.p4.1.m1.1.1.2.2.1.cmml">⁢</mo><mtext id="S5.SS3.p4.1.m1.1.1.2.2.3" xref="S5.SS3.p4.1.m1.1.1.2.2.3a.cmml">K</mtext></mrow><mo id="S5.SS3.p4.1.m1.1.1.2.1" xref="S5.SS3.p4.1.m1.1.1.2.1.cmml">+</mo><mrow id="S5.SS3.p4.1.m1.1.1.2.3" xref="S5.SS3.p4.1.m1.1.1.2.3.cmml"><mn id="S5.SS3.p4.1.m1.1.1.2.3.2" xref="S5.SS3.p4.1.m1.1.1.2.3.2.cmml">75</mn><mo id="S5.SS3.p4.1.m1.1.1.2.3.1" xref="S5.SS3.p4.1.m1.1.1.2.3.1.cmml">⁢</mo><mtext id="S5.SS3.p4.1.m1.1.1.2.3.3" xref="S5.SS3.p4.1.m1.1.1.2.3.3a.cmml">K</mtext></mrow></mrow><mo id="S5.SS3.p4.1.m1.1.1.1" xref="S5.SS3.p4.1.m1.1.1.1.cmml">=</mo><mrow id="S5.SS3.p4.1.m1.1.1.3" xref="S5.SS3.p4.1.m1.1.1.3.cmml"><mn id="S5.SS3.p4.1.m1.1.1.3.2" xref="S5.SS3.p4.1.m1.1.1.3.2.cmml">83</mn><mo id="S5.SS3.p4.1.m1.1.1.3.1" xref="S5.SS3.p4.1.m1.1.1.3.1.cmml">⁢</mo><mtext id="S5.SS3.p4.1.m1.1.1.3.3" xref="S5.SS3.p4.1.m1.1.1.3.3a.cmml">K</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><apply id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1"><eq id="S5.SS3.p4.1.m1.1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1.1"></eq><apply id="S5.SS3.p4.1.m1.1.1.2.cmml" xref="S5.SS3.p4.1.m1.1.1.2"><plus id="S5.SS3.p4.1.m1.1.1.2.1.cmml" xref="S5.SS3.p4.1.m1.1.1.2.1"></plus><apply id="S5.SS3.p4.1.m1.1.1.2.2.cmml" xref="S5.SS3.p4.1.m1.1.1.2.2"><times id="S5.SS3.p4.1.m1.1.1.2.2.1.cmml" xref="S5.SS3.p4.1.m1.1.1.2.2.1"></times><cn id="S5.SS3.p4.1.m1.1.1.2.2.2.cmml" type="integer" xref="S5.SS3.p4.1.m1.1.1.2.2.2">8</cn><ci id="S5.SS3.p4.1.m1.1.1.2.2.3a.cmml" xref="S5.SS3.p4.1.m1.1.1.2.2.3"><mtext id="S5.SS3.p4.1.m1.1.1.2.2.3.cmml" xref="S5.SS3.p4.1.m1.1.1.2.2.3">K</mtext></ci></apply><apply id="S5.SS3.p4.1.m1.1.1.2.3.cmml" xref="S5.SS3.p4.1.m1.1.1.2.3"><times id="S5.SS3.p4.1.m1.1.1.2.3.1.cmml" xref="S5.SS3.p4.1.m1.1.1.2.3.1"></times><cn id="S5.SS3.p4.1.m1.1.1.2.3.2.cmml" type="integer" xref="S5.SS3.p4.1.m1.1.1.2.3.2">75</cn><ci id="S5.SS3.p4.1.m1.1.1.2.3.3a.cmml" xref="S5.SS3.p4.1.m1.1.1.2.3.3"><mtext id="S5.SS3.p4.1.m1.1.1.2.3.3.cmml" xref="S5.SS3.p4.1.m1.1.1.2.3.3">K</mtext></ci></apply></apply><apply id="S5.SS3.p4.1.m1.1.1.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3"><times id="S5.SS3.p4.1.m1.1.1.3.1.cmml" xref="S5.SS3.p4.1.m1.1.1.3.1"></times><cn id="S5.SS3.p4.1.m1.1.1.3.2.cmml" type="integer" xref="S5.SS3.p4.1.m1.1.1.3.2">83</cn><ci id="S5.SS3.p4.1.m1.1.1.3.3a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.3"><mtext id="S5.SS3.p4.1.m1.1.1.3.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3.3">K</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">8\text{K}+75\text{K}=83\text{K}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.1.m1.1d">8 K + 75 K = 83 K</annotation></semantics></math> samples, and about 16M tokens.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p5">
<p class="ltx_p" id="S5.SS3.p5.1">The results are reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.T4" title="Table 4 ‣ 5.3 The impact of fine-tuning datasets ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4</span></a> (b).
The performance of all tasks except Winogrande are slightly improved, with the average score being 0.23 higher.
Particularly, GSM-8K improves the most, with a 0.53% improvement. This is expected since we added extra math and coding datasets.
Considering the small amount of new data (83k vs. 1.2M), the improvement is remarkable.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p6">
<p class="ltx_p" id="S5.SS3.p6.1">This study indicates that improvements in distillation data is potentially an important direction for future work, particularly domain-specific datasets to reduce the quality gap compared to the original model when using SwiftKV.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>
The impact of datasets on Llama-3.1-8B-Instruct.
</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T4.1" style="width:569.0pt;height:151pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S5.T4.1.1"><span class="ltx_text" id="S5.T4.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.1.1.1.1">
<span class="ltx_tr" id="S5.T4.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S5.T4.1.1.1.1.1.1"><span class="ltx_text" id="S5.T4.1.1.1.1.1.1.1">Setting</span></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.1.1.2">Arc-Challenge</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.1.1.3">Winogrande</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.1.1.4">Hellaswag</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.1.1.5">TruthfulQA</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.1.1.6">MMLU</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.1.1.7">MMLU-CoT</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.1.1.8">GSM-8K</span>
<span class="ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S5.T4.1.1.1.1.1.9"><span class="ltx_text" id="S5.T4.1.1.1.1.1.9.1">Avg.</span></span></span>
<span class="ltx_tr" id="S5.T4.1.1.1.1.2">
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.2.1">0-shot</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.2.2">5-shots</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.2.3">10-shots</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.2.4">0-shot</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.2.5">5-shots</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.2.6">0-shot</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.2.7">8-shots</span></span>
<span class="ltx_tr" id="S5.T4.1.1.1.1.3">
<span class="ltx_td ltx_align_center ltx_border_t ltx_colspan ltx_colspan_9" id="S5.T4.1.1.1.1.3.1">(a) Quality of Llama-3.1-8B-Instruct vs model fine-tuned using “ultrachat_200k” and “OpenHermes-2.5”.</span></span>
<span class="ltx_tr" id="S5.T4.1.1.1.1.4">
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.1.1.1.4.1">Llama-3.1-8B-Instruct</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.4.2">82.00</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.4.3">77.90</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.4.4">80.40</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.4.5">54.56</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.4.6">67.90</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.4.7">70.63</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.4.8">82.56</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.4.9">73.71</span></span>
<span class="ltx_tr" id="S5.T4.1.1.1.1.5">
<span class="ltx_td ltx_align_left" id="S5.T4.1.1.1.1.5.1">Our fine-tuned model</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.5.2">71.42</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.5.3">76.56</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.5.4">80.29</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.5.5">55.37</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.5.6">59.14</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.5.7">54.03</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.5.8">63.61</span>
<span class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1.5.9">65.77</span></span>
<span class="ltx_tr" id="S5.T4.1.1.1.1.6">
<span class="ltx_td ltx_align_center ltx_border_t ltx_colspan ltx_colspan_9" id="S5.T4.1.1.1.1.6.1">(b) Adding more data improves model quality.</span></span>
<span class="ltx_tr" id="S5.T4.1.1.1.1.7">
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.1.1.1.7.1">Original SwiftKV data</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.7.2">80.38</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.7.3">78.22</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.7.4">79.30</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.7.5">54.54</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.7.6">67.30</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.7.7">69.73</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.7.8">79.45</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1.7.9">72.70</span></span>
<span class="ltx_tr" id="S5.T4.1.1.1.1.8">
<span class="ltx_td ltx_align_left ltx_border_bb" id="S5.T4.1.1.1.1.8.1">Plus math &amp; code data</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.1.1.8.2">80.89</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.1.1.8.3">77.98</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.1.1.8.4">79.54</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.1.1.8.5">54.70</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.1.1.8.6">67.41</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.1.1.8.7">70.00</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.1.1.8.8">79.98</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.1.1.8.9">72.93</span></span>
</span></span></p>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Combining with other KV cache compression methods</h3>
<div class="ltx_para ltx_noindent" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">SwiftKV explores an orthogonal design space from many existing KV cache compression methods, which means that it can be easily combined with them, e.g., sliding window <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib22" title="">2023</a>)</cite>, token-level pruning <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib32" title="">2024d</a>)</cite>, quantization <cite class="ltx_cite ltx_citemacro_citep">(Hooper et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib21" title="">2024</a>)</cite> etc.
In this section, we show the combined effect of SwiftKV with per-token KV cache FP8 quantization  <cite class="ltx_cite ltx_citemacro_citep">(Yao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib53" title="">2022</a>)</cite> using PyTorch’s natively supported <span class="ltx_text ltx_font_typewriter" id="S5.SS4.p1.1.1">float8_e4m3fn</span>.  Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.T5" title="Table 5 ‣ 5.4 Combining with other KV cache compression methods ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5</span></a> shows the accuracy degradation is within 0.4 points for all cases, even though we applied post-training quantization with no quantization-aware finetuning.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A4" title="Appendix D Inter-layer AcrossKV vs Intra-Layer KV cache Reduction ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">D</span></a> explores a second, potentially interesting, trade-off between AcrossKV (inter-layer) vs GQA (intra-layer) KV cache sharing.</p>
</div>
<figure class="ltx_table" id="S5.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>
Llama-3.1-8B-Instruct KV cache quantization results.
</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T5.1" style="width:686.2pt;height:145pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S5.T5.1.1"><span class="ltx_text" id="S5.T5.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="S5.T5.1.1.1.1">
<span class="ltx_tr" id="S5.T5.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S5.T5.1.1.1.1.1.1"><span class="ltx_text" id="S5.T5.1.1.1.1.1.1.1">Model</span></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.1.1.1.2">AcrossKV</span>
<span class="ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S5.T5.1.1.1.1.1.3"><span class="ltx_text" id="S5.T5.1.1.1.1.1.3.1">KV Quantization</span></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.1.1.1.4">Arc-Challenge</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.1.1.1.5">Winogrande</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.1.1.1.6">Hellaswag</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.1.1.1.7">TruthfulQA</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.1.1.1.8">MMLU</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.1.1.1.9">MMLU-CoT</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.1.1.1.1.1.10">GSM-8K</span>
<span class="ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S5.T5.1.1.1.1.1.11"><span class="ltx_text" id="S5.T5.1.1.1.1.1.11.1">Avg.</span></span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.1.2">
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.2.1">(Cache Reduction)</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.2.2">0-shot</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.2.3">5-shots</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.2.4">10-shots</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.2.5">0-shot</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.2.6">5-shots</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.2.7">0-shot</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.2.8">8-shots</span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.1.3">
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.1.1.1.1.3.1">SwiftKV</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.2">✗</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.3">✗</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.4">80.38</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.5">78.22</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.6">79.30</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.7">54.54</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.8">67.30</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.9">69.73</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.10">79.45</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.1.1.3.11">72.70</span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.1.4">
<span class="ltx_td ltx_align_left" id="S5.T5.1.1.1.1.4.1">SwiftKV</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.2">✗</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.3">✓</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.4">80.29</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.5">77.66</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.6">79.23</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.7">54.40</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.8">67.10</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.9">69.51</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.10">77.94</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.4.11">72.30</span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.1.5">
<span class="ltx_td ltx_align_left" id="S5.T5.1.1.1.1.5.1">SwiftKV</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.2">2-way (25%)</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.3">✗</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.4">80.29</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.5">77.82</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.6">79.03</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.7">54.66</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.8">66.96</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.9">68.39</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.10">75.59</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.5.11">71.82</span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.1.6">
<span class="ltx_td ltx_align_left" id="S5.T5.1.1.1.1.6.1">SwiftKV</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.2">2-way (62.5%)</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.3">✓</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.4">80.03</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.5">77.35</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.6">78.86</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.7">54.44</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.8">66.89</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.9">68.27</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.10">75.97</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.6.11">71.69</span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.1.7">
<span class="ltx_td ltx_align_left" id="S5.T5.1.1.1.1.7.1">SwiftKV</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.2">4-way (37.5%)</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.3">✗</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.4">79.35</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.5">77.51</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.6">78.44</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.7">54.96</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.8">65.71</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.9">67.75</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.10">76.72</span>
<span class="ltx_td ltx_align_center" id="S5.T5.1.1.1.1.7.11">71.49</span></span>
<span class="ltx_tr" id="S5.T5.1.1.1.1.8">
<span class="ltx_td ltx_align_left ltx_border_bb" id="S5.T5.1.1.1.1.8.1">SwiftKV</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.2">4-way (68.75%)</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.3">✓</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.4">79.27</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.5">77.43</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.6">78.38</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.7">54.76</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.8">65.62</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.9">68.00</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.10">75.97</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.1.1.8.11">71.35</span></span>
</span></span></p>
</span></div>
</figure>
<figure class="ltx_table" id="S5.T6">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_middle" id="S5.F5" style="width:159.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="251" id="S5.T6.1.g1" src="x6.png" width="753"/>
<br class="ltx_break ltx_break"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span> Density of early exit probabilities and alignment of early exit vs final logits.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S5.T6.fig1" style="width:238.5pt;">
<div class="ltx_listing ltx_lstlisting ltx_listing" id="S5.T6.fig1.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,UXVlc3Rpb246IFdoYXQgYXJlIHRoZSB0aHJlZSBwcmltYXJ5IGNvbG9ycz8KQW5zd2VyOiBUaGUgdGhyZWUgcHJpbWFyeSBjb2xvcnMgYXJlOgoxLiBSZWQKMi4gQmx1ZQozLiBZZWxsb3cKVGhlc2UgY29sb3JzIGFyZSBjYWxsZWQgcHJpbWFyeSBiZWNhdXNlIHRoZXkgYXJlIHRoZQpiYXNpYyBidWlsZGluZyBibG9ja3Mgb2YgYWxsIG90aGVyIGNvbG9ycy4gVGhleSBjYW5ub3QgYmUKY3JlYXRlZCBieSBtaXhpbmcgb3RoZXIgY29sb3JzIHRvZ2V0aGVyLCBhbmQgdGhleSBhcmUgdGhlCm9ubHkgY29sb3JzIHRoYXQgY2FuIGJlIHVzZWQgdG8gY3JlYXRlIGFsbCBvdGhlciBjb2xvcnMKdGhyb3VnaCBtaXhpbmcu">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx1.1">Question</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx1.2"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx1.3">What</span><span class="ltx_text ltx_lst_space" id="lstnumberx1.4"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx1.5">are</span><span class="ltx_text ltx_lst_space" id="lstnumberx1.6"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx1.7">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx1.8"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx1.9">three</span><span class="ltx_text ltx_lst_space" id="lstnumberx1.10"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx1.11">primary</span><span class="ltx_text ltx_lst_space" id="lstnumberx1.12"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx1.13">colors</span>?
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx2.1">Answer</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx2.2"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.3">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.4"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.5">three</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.6"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.7">primary</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.8"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.9">colors</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.10"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.11">are</span>:
</div>
<div class="ltx_listingline" id="lstnumberx3">1.<span class="ltx_text ltx_lst_space" id="lstnumberx3.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.2">Red</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">2.<span class="ltx_text ltx_lst_space" id="lstnumberx4.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.2">Blue</span>
</div>
<div class="ltx_listingline" id="lstnumberx5">3.<span class="ltx_text ltx_lst_space" id="lstnumberx5.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.2">Yellow</span>
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx6.1">These</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.2"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.3">colors</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.4"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.5">are</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.6"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.7">called</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.8"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.9">primary</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.10"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.11">because</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.12"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.13">they</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.14"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.15">are</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.16"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.17">the</span>
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx7.1">basic</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.2"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.3">building</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.4"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.5">blocks</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.6"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.7">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.8"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.9">all</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.10"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.11">other</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.12"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.13">colors</span>.<span class="ltx_text ltx_lst_space" id="lstnumberx7.14"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.15">They</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.16"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.17">cannot</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.18"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.19">be</span>
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx8.1">created</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.2"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.3">by</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.4"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.5">mixing</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.6"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.7">other</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.8"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.9">colors</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.10"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.11">together</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx8.12"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.13">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.14"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.15">they</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.16"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.17">are</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.18"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.19">the</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx9.1">only</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.2"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.3">colors</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.4"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.5">that</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.6"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.7">can</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.8"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.9">be</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.10"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.11">used</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.12"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.13">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.14"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.15">create</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.16"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.17">all</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.18"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.19">other</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.20"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.21">colors</span>
</div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx10.1">through</span><span class="ltx_text ltx_lst_space" id="lstnumberx10.2"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx10.3">mixing</span>.
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 6: </span>A Q&amp;A example of early exit.</figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Simple Early Exit for Decoding Tokens</h3>
<div class="ltx_para ltx_noindent" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">SingleInputKV allows all the KV cache needed for generating future tokens to be computed without having to forward-pass though the entire LLM. This means that even the decoding phase could exit earlier without worrying about missing KV cache for subsequent tokens.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p2">
<p class="ltx_p" id="S5.SS5.p2.1">To test the feasibility, we added an early exit language modeling head. We then used the input to SingleInputKV layer to calculate output logits, and incorporated them as part of the distillation training. Our results are preliminary and requires further evaluation, but we found that the alignment between early exit logits and the final output logits to be over 66% when the largest probability from the early exit logits is over 95% (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.F5" title="Figure 5 ‣ Table 6 ‣ 5.4 Combining with other KV cache compression methods ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5</span></a>). We used this as our early exit criteria (i.e., decoding tokens exit early if it predicts an output token with 95%+ probability), and  Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.T6" title="Table 6 ‣ 5.4 Combining with other KV cache compression methods ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">6</span></a> shows a sample result. See Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A5" title="Appendix E Early Exit Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">E</span></a> for more details.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we presented SwiftKV, a novel model transformation for reducing inference cost for prompt-dominant workloads, combined with a KV cache reduction strategy to reduce memory footprint, and a light-weight distillation procedure to preserve model accuracy. While we presented strong results on the effectiveness of SwiftKV, exploration of parameter-preserving model transformations for inference optimization is still in its early stages. We have identified both limitations as well as areas of improvement. Given the simplicity and effectiveness of SwiftKV, we hope that this will spark further exploration from the AI community which we hope will continue lower the latency and cost of inference.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations and Future Work</h2>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">It is important for every work to acknowledge its limitations and suggest future directions, particularly for LLM-related works.
In our work, we did not aim to optimize the training data selection though we provide potential ways in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.SS3" title="5.3 The impact of fine-tuning datasets ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5.3</span></a>.
Additionally, we did not include a detailed benchmark analysis for our method.
However, as shown in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.SS3" title="5.3 The impact of fine-tuning datasets ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5.3</span></a>, we ensured that our datasets were not cherry-picked to overfit the reported tasks.
Furthermore, we did not finetune our model with advanced post-training approaches, like DPO and RLHF, which we leave for future work.
Finally, we hypothesize that our method can work even better when combined with pretraining or continued-pretraining,
but due to resources constraints, we did not explore this direction.
We hope to revisit these ideas in the future.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal et al. (2024)</span>
<span class="ltx_bibblock">
Amey Agrawal, Nitin Kedia, Ashish Panwar, Jayashree Mohan, Nipun Kwatra, Bhargav Gulavani, Alexey Tumanov, and Ramachandran Ramjee.

</span>
<span class="ltx_bibblock">Taming Throughput-Latency tradeoff in LLM inference with Sarathi-Serve.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">18th USENIX Symposium on Operating Systems Design and Implementation (OSDI 24)</em>, pp.  117–134, Santa Clara, CA, July 2024. USENIX Association.

</span>
<span class="ltx_bibblock">ISBN 978-1-939133-40-3.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.usenix.org/conference/osdi24/presentation/agrawal" title="">https://www.usenix.org/conference/osdi24/presentation/agrawal</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ainslie et al. (2023a)</span>
<span class="ltx_bibblock">
Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebron, and Sumit Sanghai.

</span>
<span class="ltx_bibblock">GQA: Training generalized multi-query transformer models from multi-head checkpoints.

</span>
<span class="ltx_bibblock">In Houda Bouamor, Juan Pino, and Kalika Bali (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pp.  4895–4901, Singapore, December 2023a. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.emnlp-main.298</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.emnlp-main.298" title="">https://aclanthology.org/2023.emnlp-main.298</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ainslie et al. (2023b)</span>
<span class="ltx_bibblock">
Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai.

</span>
<span class="ltx_bibblock">Gqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2305.13245" title="">https://arxiv.org/abs/2305.13245</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aminabadi et al. (2022)</span>
<span class="ltx_bibblock">
Reza Yazdani Aminabadi, Samyam Rajbhandari, Minjia Zhang, Ammar Ahmad Awan, Cheng Li, Du Li, Elton Zheng, Jeff Rasley, Shaden Smith, Olatunji Ruwase, and Yuxiong He.

</span>
<span class="ltx_bibblock">Deepspeed inference: Enabling efficient inference of transformer models at unprecedented scale, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2207.00032" title="">https://arxiv.org/abs/2207.00032</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu.

</span>
<span class="ltx_bibblock">Qwen technical report, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2309.16609" title="">https://arxiv.org/abs/2309.16609</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al. (2024)</span>
<span class="ltx_bibblock">
Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng, Jason D. Lee, Deming Chen, and Tri Dao.

</span>
<span class="ltx_bibblock">Medusa: Simple llm inference acceleration framework with multiple decoding heads, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2401.10774" title="">https://arxiv.org/abs/2401.10774</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al. (2024)</span>
<span class="ltx_bibblock">
Chi-Chih Chang, Wei-Cheng Lin, Chien-Yu Lin, Chong-Yan Chen, Yu-Fang Hu, Pei-Shuo Wang, Ning-Chi Huang, Luis Ceze, and Kai-Chiang Wu.

</span>
<span class="ltx_bibblock">Palu: Compressing kv-cache with low-rank projection, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2407.21118" title="">https://arxiv.org/abs/2407.21118</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2107.03374" title="">https://arxiv.org/abs/2107.03374</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et al. (2018)</span>
<span class="ltx_bibblock">
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the ai2 reasoning challenge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">ArXiv</em>, abs/1803.05457, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et al. (2021)</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao et al. (2024)</span>
<span class="ltx_bibblock">
Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, and Christopher Ré.

</span>
<span class="ltx_bibblock">Flashattention: fast and memory-efficient exact attention with io-awareness.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 36th International Conference on Neural Information Processing Systems</em>, NIPS ’22, Red Hook, NY, USA, 2024. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781713871088.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al. (2023)</span>
<span class="ltx_bibblock">
Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou.

</span>
<span class="ltx_bibblock">Enhancing chat language models by scaling high-quality instructional conversations, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elhage et al. (2021)</span>
<span class="ltx_bibblock">
Nelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova DasSarma, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah.

</span>
<span class="ltx_bibblock">A mathematical framework for transformer circuits.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Transformer Circuits Thread</em>, 2021.

</span>
<span class="ltx_bibblock">https://transformer-circuits.pub/2021/framework/index.html.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2024)</span>
<span class="ltx_bibblock">
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le Noac’h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou.

</span>
<span class="ltx_bibblock">A framework for few-shot language model evaluation, 07 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://zenodo.org/records/12608602" title="">https://zenodo.org/records/12608602</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et al. (2021)</span>
<span class="ltx_bibblock">
Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy.

</span>
<span class="ltx_bibblock">Transformer feed-forward layers are key-value memories.

</span>
<span class="ltx_bibblock">In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pp.  5484–5495, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2021.emnlp-main.446</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.emnlp-main.446" title="">https://aclanthology.org/2021.emnlp-main.446</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GretelAI (2024)</span>
<span class="ltx_bibblock">
GretelAI.

</span>
<span class="ltx_bibblock">Synthetically generated reasoning dataset (gsm8k-inspired) with enhanced diversity using gretel navigator and meta-llama/meta-llama-3.1-405b.

</span>
<span class="ltx_bibblock">https://huggingface.co/gretelai/synthetic-gsm8k-reflection-405b, 9 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gromov et al. (2024)</span>
<span class="ltx_bibblock">
Andrey Gromov, Kushal Tirumala, Hassan Shapourian, Paolo Glorioso, and Daniel A. Roberts.

</span>
<span class="ltx_bibblock">The unreasonable ineffectiveness of the deeper layers, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2403.17887" title="">https://arxiv.org/abs/2403.17887</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et al. (2015)</span>
<span class="ltx_bibblock">
Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">CoRR</em>, abs/1503.02531, 2015.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://dblp.uni-trier.de/db/journals/corr/corr1503.html#HintonVD15" title="">http://dblp.uni-trier.de/db/journals/corr/corr1503.html#HintonVD15</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holmes et al. (2024)</span>
<span class="ltx_bibblock">
Connor Holmes, Masahiro Tanaka, Michael Wyatt, Ammar Ahmad Awan, Jeff Rasley, Samyam Rajbhandari, Reza Yazdani Aminabadi, Heyang Qin, Arash Bakhtiari, Lev Kurilenko, and Yuxiong He.

</span>
<span class="ltx_bibblock">Deepspeed-fastgen: High-throughput text generation for llms via mii and deepspeed-inference, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2401.08671" title="">https://arxiv.org/abs/2401.08671</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hooper et al. (2024)</span>
<span class="ltx_bibblock">
Coleman Hooper, Sehoon Kim, Hiva Mohammadzadeh, Michael W. Mahoney, Yakun Sophia Shao, Kurt Keutzer, and Amir Gholami.

</span>
<span class="ltx_bibblock">Kvquant: Towards 10 million context length llm inference with kv cache quantization, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2401.18079" title="">https://arxiv.org/abs/2401.18079</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed.

</span>
<span class="ltx_bibblock">Mistral 7b, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2310.06825" title="">https://arxiv.org/abs/2310.06825</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuzmin et al. (2024)</span>
<span class="ltx_bibblock">
Andrey Kuzmin, Mart Van Baalen, Yuwei Ren, Markus Nagel, Jorn Peters, and Tijmen Blankevoort.

</span>
<span class="ltx_bibblock">Fp8 quantization: the power of the exponent.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 36th International Conference on Neural Information Processing Systems</em>, NIPS ’22, Red Hook, NY, USA, 2024. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781713871088.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwon et al. (2023)</span>
<span class="ltx_bibblock">
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica.

</span>
<span class="ltx_bibblock">Efficient memory management for large language model serving with pagedattention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 29th Symposium on Operating Systems Principles</em>, SOSP ’23, pp.  611–626, New York, NY, USA, 2023. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9798400702297.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3600006.3613165</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3600006.3613165" title="">https://doi.org/10.1145/3600006.3613165</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leviathan et al. (2023)</span>
<span class="ltx_bibblock">
Yaniv Leviathan, Matan Kalman, and Yossi Matias.

</span>
<span class="ltx_bibblock">Fast inference from transformers via speculative decoding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 40th International Conference on Machine Learning</em>, ICML’23. JMLR.org, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</em>, NIPS ’20, Red Hook, NY, USA, 2020. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781713829546.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2022)</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">TruthfulQA: Measuring how models mimic human falsehoods.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp.  3214–3252, Dublin, Ireland, May 2022. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2022.acl-long.229</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.acl-long.229" title="">https://aclanthology.org/2022.acl-long.229</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2024)</span>
<span class="ltx_bibblock">
Xi Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi, Maria Lomeli, Richard James, Pedro Rodriguez, Jacob Kahn, Gergely Szilvasy, Mike Lewis, Luke Zettlemoyer, and Wen tau Yih.

</span>
<span class="ltx_bibblock">RA-DIT: Retrieval-augmented dual instruction tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">The Twelfth International Conference on Learning Representations</em>, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=22OTbutug9" title="">https://openreview.net/forum?id=22OTbutug9</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024a)</span>
<span class="ltx_bibblock">
Akide Liu, Jing Liu, Zizheng Pan, Yefei He, Gholamreza Haffari, and Bohan Zhuang.

</span>
<span class="ltx_bibblock">Minicache: Kv cache compression in depth dimension for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2405.14366</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024b)</span>
<span class="ltx_bibblock">
Akide Liu, Jing Liu, Zizheng Pan, Yefei He, Gholamreza Haffari, and Bohan Zhuang.

</span>
<span class="ltx_bibblock">Minicache: Kv cache compression in depth dimension for large language models, 2024b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2405.14366" title="">https://arxiv.org/abs/2405.14366</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024c)</span>
<span class="ltx_bibblock">
Songwei Liu, Chao Zeng, Lianqiang Li, Chenqian Yan, Lean Fu, Xing Mei, and Fangmin Chen.

</span>
<span class="ltx_bibblock">Foldgpt: Simple and effective large language model compression scheme, 2024c.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2407.00928" title="">https://arxiv.org/abs/2407.00928</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024d)</span>
<span class="ltx_bibblock">
Zichang Liu, Aditya Desai, Fangshuo Liao, Weitao Wang, Victor Xie, Zhaozhuo Xu, Anastasios Kyrillidis, and Anshumali Shrivastava.

</span>
<span class="ltx_bibblock">Scissorhands: exploiting the persistence of importance hypothesis for llm kv cache compression at test time.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 37th International Conference on Neural Information Processing Systems</em>, NIPS ’23, Red Hook, NY, USA, 2024d. Curran Associates Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al. (2024)</span>
<span class="ltx_bibblock">
Weile Luo, Ruibo Fan, Zeyu Li, Dayou Du, Qiang Wang, and Xiaowen Chu.

</span>
<span class="ltx_bibblock">Benchmarking and dissecting the nvidia hopper gpu architecture, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2402.13499" title="">https://arxiv.org/abs/2402.13499</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et al. (2024)</span>
<span class="ltx_bibblock">
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.

</span>
<span class="ltx_bibblock">Locating and editing factual associations in gpt.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the 36th International Conference on Neural Information Processing Systems</em>, NIPS ’22, Red Hook, NY, USA, 2024. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781713871088.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NVIDIA (2019)</span>
<span class="ltx_bibblock">
NVIDIA.

</span>
<span class="ltx_bibblock">Tensorrt.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/NVIDIA/TensorRT" title="">https://github.com/NVIDIA/TensorRT</a>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NVIDIA (2021)</span>
<span class="ltx_bibblock">
NVIDIA.

</span>
<span class="ltx_bibblock">Fastertransformer.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/NVIDIA/FasterTransformer" title="">https://github.com/NVIDIA/FasterTransformer</a>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pope et al. (2022)</span>
<span class="ltx_bibblock">
Reiner Pope, Sholto Douglas, Aakanksha Chowdhery, Jacob Devlin, James Bradbury, Anselm Levskaya, Jonathan Heek, Kefan Xiao, Shivani Agrawal, and Jeff Dean.

</span>
<span class="ltx_bibblock">Efficiently scaling transformer inference, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2211.05102" title="">https://arxiv.org/abs/2211.05102</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pourreza &amp; Rafiei (2024)</span>
<span class="ltx_bibblock">
Mohammadreza Pourreza and Davood Rafiei.

</span>
<span class="ltx_bibblock">Din-sql: decomposed in-context learning of text-to-sql with self-correction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 37th International Conference on Neural Information Processing Systems</em>, NIPS ’23, Red Hook, NY, USA, 2024. Curran Associates Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pu et al. (2023)</span>
<span class="ltx_bibblock">
Xiao Pu, Mingqi Gao, and Xiaojun Wan.

</span>
<span class="ltx_bibblock">Summarization is (almost) dead, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2309.09558" title="">https://arxiv.org/abs/2309.09558</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sakaguchi et al. (2019)</span>
<span class="ltx_bibblock">
Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi.

</span>
<span class="ltx_bibblock">Winogrande: An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:1907.10641</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick et al. (2023)</span>
<span class="ltx_bibblock">
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.

</span>
<span class="ltx_bibblock">Toolformer: Language models can teach themselves to use tools, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2302.04761" title="">https://arxiv.org/abs/2302.04761</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2019)</span>
<span class="ltx_bibblock">
Noam Shazeer.

</span>
<span class="ltx_bibblock">Fast transformer decoding: One write-head is all you need, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1911.02150" title="">https://arxiv.org/abs/1911.02150</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheng et al. (2023)</span>
<span class="ltx_bibblock">
Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Beidi Chen, Percy Liang, Christopher Ré, Ion Stoica, and Ce Zhang.

</span>
<span class="ltx_bibblock">Flexgen: high-throughput generative inference of large language models with a single gpu.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the 40th International Conference on Machine Learning</em>, ICML’23. JMLR.org, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shoeybi et al. (2020)</span>
<span class="ltx_bibblock">
Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro.

</span>
<span class="ltx_bibblock">Megatron-lm: Training multi-billion parameter language models using model parallelism, 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1909.08053" title="">https://arxiv.org/abs/1909.08053</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sreenivas et al. (2024)</span>
<span class="ltx_bibblock">
Sharath Turuvekere Sreenivas, Saurav Muralidharan, Raviraj Joshi, Marcin Chochowski, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, and Pavlo Molchanov.

</span>
<span class="ltx_bibblock">Llm pruning and distillation in practice: The minitron approach, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2408.11796" title="">https://arxiv.org/abs/2408.11796</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" title="">https://github.com/tatsu-lab/stanford_alpaca</a>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Teknium (2023)</span>
<span class="ltx_bibblock">
Teknium.

</span>
<span class="ltx_bibblock">Openhermes 2.5: An open dataset of synthetic data for generalist llm assistants, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/teknium/OpenHermes-2.5" title="">https://huggingface.co/datasets/teknium/OpenHermes-2.5</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2302.13971" title="">https://arxiv.org/abs/2302.13971</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the 31st International Conference on Neural Information Processing Systems</em>, NIPS’17, pp.  6000–6010, Red Hook, NY, USA, 2017. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781510860964.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024)</span>
<span class="ltx_bibblock">
Junlin Wang, Jue Wang, Ben Athiwaratkun, Ce Zhang, and James Zou.

</span>
<span class="ltx_bibblock">Mixture-of-agents enhances large language model capabilities, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2406.04692" title="">https://arxiv.org/abs/2406.04692</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2023)</span>
<span class="ltx_bibblock">
Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang.

</span>
<span class="ltx_bibblock">Magicoder: Source code is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2312.02120</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et al. (2024)</span>
<span class="ltx_bibblock">
Heming Xia, Zhe Yang, Qingxiu Dong, Peiyi Wang, Yongqi Li, Tao Ge, Tianyu Liu, Wenjie Li, and Zhifang Sui.

</span>
<span class="ltx_bibblock">Unlocking efficiency in large language model inference: A comprehensive survey of speculative decoding, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2401.07851" title="">https://arxiv.org/abs/2401.07851</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2022)</span>
<span class="ltx_bibblock">
Zhewei Yao, Reza Yazdani Aminabadi, Minjia Zhang, Xiaoxia Wu, Conglong Li, and Yuxiong He.

</span>
<span class="ltx_bibblock">Zeroquant: Efficient and affordable post-training quantization for large-scale transformers, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2206.01861" title="">https://arxiv.org/abs/2206.01861</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
Gyeong-In Yu, Joo Seong Jeong, Geon-Woo Kim, Soojeong Kim, and Byung-Gon Chun.

</span>
<span class="ltx_bibblock">Orca: A distributed serving system for Transformer-Based generative models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)</em>, pp.  521–538, Carlsbad, CA, July 2022. USENIX Association.

</span>
<span class="ltx_bibblock">ISBN 978-1-939133-28-1.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.usenix.org/conference/osdi22/presentation/yu" title="">https://www.usenix.org/conference/osdi22/presentation/yu</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et al. (2019)</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.

</span>
<span class="ltx_bibblock">Hellaswag: Can a machine really finish your sentence?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang, Kathleen McKeown, and Tatsunori B. Hashimoto.

</span>
<span class="ltx_bibblock">Benchmarking large language models for news summarization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Transactions of the Association for Computational Linguistics</em>, 12:39–57, 2024.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00632</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2024.tacl-1.3" title="">https://aclanthology.org/2024.tacl-1.3</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Additional Motivation</h2>
<figure class="ltx_figure" id="A1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="280" id="A1.F1.g1" src="x7.png" width="373"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="280" id="A1.F1.g2" src="x8.png" width="373"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A.1: </span>
The input similarity of small scale models (left) and large scale models (right).
</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Calculating Computation Reduction</h2>
<div class="ltx_para ltx_noindent" id="A2.p1">
<p class="ltx_p" id="A2.p1.10">For a vanilla transformer model <cite class="ltx_cite ltx_citemacro_cite">Vaswani et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib49" title="">2017</a>)</cite> with a hidden dimension size <math alttext="d" class="ltx_Math" display="inline" id="A2.p1.1.m1.1"><semantics id="A2.p1.1.m1.1a"><mi id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><ci id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="A2.p1.1.m1.1d">italic_d</annotation></semantics></math>, the total amount of computation per token per layer is roughly given by <math alttext="24d^{2}" class="ltx_Math" display="inline" id="A2.p1.2.m2.1"><semantics id="A2.p1.2.m2.1a"><mrow id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml"><mn id="A2.p1.2.m2.1.1.2" xref="A2.p1.2.m2.1.1.2.cmml">24</mn><mo id="A2.p1.2.m2.1.1.1" xref="A2.p1.2.m2.1.1.1.cmml">⁢</mo><msup id="A2.p1.2.m2.1.1.3" xref="A2.p1.2.m2.1.1.3.cmml"><mi id="A2.p1.2.m2.1.1.3.2" xref="A2.p1.2.m2.1.1.3.2.cmml">d</mi><mn id="A2.p1.2.m2.1.1.3.3" xref="A2.p1.2.m2.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><apply id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1"><times id="A2.p1.2.m2.1.1.1.cmml" xref="A2.p1.2.m2.1.1.1"></times><cn id="A2.p1.2.m2.1.1.2.cmml" type="integer" xref="A2.p1.2.m2.1.1.2">24</cn><apply id="A2.p1.2.m2.1.1.3.cmml" xref="A2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="A2.p1.2.m2.1.1.3.1.cmml" xref="A2.p1.2.m2.1.1.3">superscript</csymbol><ci id="A2.p1.2.m2.1.1.3.2.cmml" xref="A2.p1.2.m2.1.1.3.2">𝑑</ci><cn id="A2.p1.2.m2.1.1.3.3.cmml" type="integer" xref="A2.p1.2.m2.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">24d^{2}</annotation><annotation encoding="application/x-llamapun" id="A2.p1.2.m2.1d">24 italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="4d^{2}" class="ltx_Math" display="inline" id="A2.p1.3.m3.1"><semantics id="A2.p1.3.m3.1a"><mrow id="A2.p1.3.m3.1.1" xref="A2.p1.3.m3.1.1.cmml"><mn id="A2.p1.3.m3.1.1.2" xref="A2.p1.3.m3.1.1.2.cmml">4</mn><mo id="A2.p1.3.m3.1.1.1" xref="A2.p1.3.m3.1.1.1.cmml">⁢</mo><msup id="A2.p1.3.m3.1.1.3" xref="A2.p1.3.m3.1.1.3.cmml"><mi id="A2.p1.3.m3.1.1.3.2" xref="A2.p1.3.m3.1.1.3.2.cmml">d</mi><mn id="A2.p1.3.m3.1.1.3.3" xref="A2.p1.3.m3.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.3.m3.1b"><apply id="A2.p1.3.m3.1.1.cmml" xref="A2.p1.3.m3.1.1"><times id="A2.p1.3.m3.1.1.1.cmml" xref="A2.p1.3.m3.1.1.1"></times><cn id="A2.p1.3.m3.1.1.2.cmml" type="integer" xref="A2.p1.3.m3.1.1.2">4</cn><apply id="A2.p1.3.m3.1.1.3.cmml" xref="A2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A2.p1.3.m3.1.1.3.1.cmml" xref="A2.p1.3.m3.1.1.3">superscript</csymbol><ci id="A2.p1.3.m3.1.1.3.2.cmml" xref="A2.p1.3.m3.1.1.3.2">𝑑</ci><cn id="A2.p1.3.m3.1.1.3.3.cmml" type="integer" xref="A2.p1.3.m3.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.3.m3.1c">4d^{2}</annotation><annotation encoding="application/x-llamapun" id="A2.p1.3.m3.1d">4 italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> goes to KV projections, another <math alttext="4d^{2}" class="ltx_Math" display="inline" id="A2.p1.4.m4.1"><semantics id="A2.p1.4.m4.1a"><mrow id="A2.p1.4.m4.1.1" xref="A2.p1.4.m4.1.1.cmml"><mn id="A2.p1.4.m4.1.1.2" xref="A2.p1.4.m4.1.1.2.cmml">4</mn><mo id="A2.p1.4.m4.1.1.1" xref="A2.p1.4.m4.1.1.1.cmml">⁢</mo><msup id="A2.p1.4.m4.1.1.3" xref="A2.p1.4.m4.1.1.3.cmml"><mi id="A2.p1.4.m4.1.1.3.2" xref="A2.p1.4.m4.1.1.3.2.cmml">d</mi><mn id="A2.p1.4.m4.1.1.3.3" xref="A2.p1.4.m4.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.4.m4.1b"><apply id="A2.p1.4.m4.1.1.cmml" xref="A2.p1.4.m4.1.1"><times id="A2.p1.4.m4.1.1.1.cmml" xref="A2.p1.4.m4.1.1.1"></times><cn id="A2.p1.4.m4.1.1.2.cmml" type="integer" xref="A2.p1.4.m4.1.1.2">4</cn><apply id="A2.p1.4.m4.1.1.3.cmml" xref="A2.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="A2.p1.4.m4.1.1.3.1.cmml" xref="A2.p1.4.m4.1.1.3">superscript</csymbol><ci id="A2.p1.4.m4.1.1.3.2.cmml" xref="A2.p1.4.m4.1.1.3.2">𝑑</ci><cn id="A2.p1.4.m4.1.1.3.3.cmml" type="integer" xref="A2.p1.4.m4.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.4.m4.1c">4d^{2}</annotation><annotation encoding="application/x-llamapun" id="A2.p1.4.m4.1d">4 italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> goes to Q projection and context GEMM, and the remaining <math alttext="16d^{2}" class="ltx_Math" display="inline" id="A2.p1.5.m5.1"><semantics id="A2.p1.5.m5.1a"><mrow id="A2.p1.5.m5.1.1" xref="A2.p1.5.m5.1.1.cmml"><mn id="A2.p1.5.m5.1.1.2" xref="A2.p1.5.m5.1.1.2.cmml">16</mn><mo id="A2.p1.5.m5.1.1.1" xref="A2.p1.5.m5.1.1.1.cmml">⁢</mo><msup id="A2.p1.5.m5.1.1.3" xref="A2.p1.5.m5.1.1.3.cmml"><mi id="A2.p1.5.m5.1.1.3.2" xref="A2.p1.5.m5.1.1.3.2.cmml">d</mi><mn id="A2.p1.5.m5.1.1.3.3" xref="A2.p1.5.m5.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.5.m5.1b"><apply id="A2.p1.5.m5.1.1.cmml" xref="A2.p1.5.m5.1.1"><times id="A2.p1.5.m5.1.1.1.cmml" xref="A2.p1.5.m5.1.1.1"></times><cn id="A2.p1.5.m5.1.1.2.cmml" type="integer" xref="A2.p1.5.m5.1.1.2">16</cn><apply id="A2.p1.5.m5.1.1.3.cmml" xref="A2.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="A2.p1.5.m5.1.1.3.1.cmml" xref="A2.p1.5.m5.1.1.3">superscript</csymbol><ci id="A2.p1.5.m5.1.1.3.2.cmml" xref="A2.p1.5.m5.1.1.3.2">𝑑</ci><cn id="A2.p1.5.m5.1.1.3.3.cmml" type="integer" xref="A2.p1.5.m5.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.5.m5.1c">16d^{2}</annotation><annotation encoding="application/x-llamapun" id="A2.p1.5.m5.1d">16 italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> goes to MLP computation. For popular GQA <cite class="ltx_cite ltx_citemacro_citep">(Ainslie et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib3" title="">2023b</a>)</cite> based architectures like Llama <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib48" title="">2023</a>)</cite>, Mistral <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib22" title="">2023</a>)</cite>, Qwen <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib5" title="">2023</a>)</cite>, and many others, the KV projection is reduced to <math alttext="4d^{2}/G" class="ltx_Math" display="inline" id="A2.p1.6.m6.1"><semantics id="A2.p1.6.m6.1a"><mrow id="A2.p1.6.m6.1.1" xref="A2.p1.6.m6.1.1.cmml"><mrow id="A2.p1.6.m6.1.1.2" xref="A2.p1.6.m6.1.1.2.cmml"><mn id="A2.p1.6.m6.1.1.2.2" xref="A2.p1.6.m6.1.1.2.2.cmml">4</mn><mo id="A2.p1.6.m6.1.1.2.1" xref="A2.p1.6.m6.1.1.2.1.cmml">⁢</mo><msup id="A2.p1.6.m6.1.1.2.3" xref="A2.p1.6.m6.1.1.2.3.cmml"><mi id="A2.p1.6.m6.1.1.2.3.2" xref="A2.p1.6.m6.1.1.2.3.2.cmml">d</mi><mn id="A2.p1.6.m6.1.1.2.3.3" xref="A2.p1.6.m6.1.1.2.3.3.cmml">2</mn></msup></mrow><mo id="A2.p1.6.m6.1.1.1" xref="A2.p1.6.m6.1.1.1.cmml">/</mo><mi id="A2.p1.6.m6.1.1.3" xref="A2.p1.6.m6.1.1.3.cmml">G</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.6.m6.1b"><apply id="A2.p1.6.m6.1.1.cmml" xref="A2.p1.6.m6.1.1"><divide id="A2.p1.6.m6.1.1.1.cmml" xref="A2.p1.6.m6.1.1.1"></divide><apply id="A2.p1.6.m6.1.1.2.cmml" xref="A2.p1.6.m6.1.1.2"><times id="A2.p1.6.m6.1.1.2.1.cmml" xref="A2.p1.6.m6.1.1.2.1"></times><cn id="A2.p1.6.m6.1.1.2.2.cmml" type="integer" xref="A2.p1.6.m6.1.1.2.2">4</cn><apply id="A2.p1.6.m6.1.1.2.3.cmml" xref="A2.p1.6.m6.1.1.2.3"><csymbol cd="ambiguous" id="A2.p1.6.m6.1.1.2.3.1.cmml" xref="A2.p1.6.m6.1.1.2.3">superscript</csymbol><ci id="A2.p1.6.m6.1.1.2.3.2.cmml" xref="A2.p1.6.m6.1.1.2.3.2">𝑑</ci><cn id="A2.p1.6.m6.1.1.2.3.3.cmml" type="integer" xref="A2.p1.6.m6.1.1.2.3.3">2</cn></apply></apply><ci id="A2.p1.6.m6.1.1.3.cmml" xref="A2.p1.6.m6.1.1.3">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.6.m6.1c">4d^{2}/G</annotation><annotation encoding="application/x-llamapun" id="A2.p1.6.m6.1d">4 italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_G</annotation></semantics></math>, where <math alttext="G" class="ltx_Math" display="inline" id="A2.p1.7.m7.1"><semantics id="A2.p1.7.m7.1a"><mi id="A2.p1.7.m7.1.1" xref="A2.p1.7.m7.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="A2.p1.7.m7.1b"><ci id="A2.p1.7.m7.1.1.cmml" xref="A2.p1.7.m7.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.7.m7.1c">G</annotation><annotation encoding="application/x-llamapun" id="A2.p1.7.m7.1d">italic_G</annotation></semantics></math> is the group size and is <math alttext="\geq 4" class="ltx_Math" display="inline" id="A2.p1.8.m8.1"><semantics id="A2.p1.8.m8.1a"><mrow id="A2.p1.8.m8.1.1" xref="A2.p1.8.m8.1.1.cmml"><mi id="A2.p1.8.m8.1.1.2" xref="A2.p1.8.m8.1.1.2.cmml"></mi><mo id="A2.p1.8.m8.1.1.1" xref="A2.p1.8.m8.1.1.1.cmml">≥</mo><mn id="A2.p1.8.m8.1.1.3" xref="A2.p1.8.m8.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.8.m8.1b"><apply id="A2.p1.8.m8.1.1.cmml" xref="A2.p1.8.m8.1.1"><geq id="A2.p1.8.m8.1.1.1.cmml" xref="A2.p1.8.m8.1.1.1"></geq><csymbol cd="latexml" id="A2.p1.8.m8.1.1.2.cmml" xref="A2.p1.8.m8.1.1.2">absent</csymbol><cn id="A2.p1.8.m8.1.1.3.cmml" type="integer" xref="A2.p1.8.m8.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.8.m8.1c">\geq 4</annotation><annotation encoding="application/x-llamapun" id="A2.p1.8.m8.1d">≥ 4</annotation></semantics></math>. As such, the compute cost of the KV projection is negligible (<math alttext="\frac{4d^{2}/G}{20d^{2}+4d^{2}/G}" class="ltx_Math" display="inline" id="A2.p1.9.m9.1"><semantics id="A2.p1.9.m9.1a"><mfrac id="A2.p1.9.m9.1.1" xref="A2.p1.9.m9.1.1.cmml"><mrow id="A2.p1.9.m9.1.1.2" xref="A2.p1.9.m9.1.1.2.cmml"><mrow id="A2.p1.9.m9.1.1.2.2" xref="A2.p1.9.m9.1.1.2.2.cmml"><mn id="A2.p1.9.m9.1.1.2.2.2" xref="A2.p1.9.m9.1.1.2.2.2.cmml">4</mn><mo id="A2.p1.9.m9.1.1.2.2.1" xref="A2.p1.9.m9.1.1.2.2.1.cmml">⁢</mo><msup id="A2.p1.9.m9.1.1.2.2.3" xref="A2.p1.9.m9.1.1.2.2.3.cmml"><mi id="A2.p1.9.m9.1.1.2.2.3.2" xref="A2.p1.9.m9.1.1.2.2.3.2.cmml">d</mi><mn id="A2.p1.9.m9.1.1.2.2.3.3" xref="A2.p1.9.m9.1.1.2.2.3.3.cmml">2</mn></msup></mrow><mo id="A2.p1.9.m9.1.1.2.1" xref="A2.p1.9.m9.1.1.2.1.cmml">/</mo><mi id="A2.p1.9.m9.1.1.2.3" xref="A2.p1.9.m9.1.1.2.3.cmml">G</mi></mrow><mrow id="A2.p1.9.m9.1.1.3" xref="A2.p1.9.m9.1.1.3.cmml"><mrow id="A2.p1.9.m9.1.1.3.2" xref="A2.p1.9.m9.1.1.3.2.cmml"><mn id="A2.p1.9.m9.1.1.3.2.2" xref="A2.p1.9.m9.1.1.3.2.2.cmml">20</mn><mo id="A2.p1.9.m9.1.1.3.2.1" xref="A2.p1.9.m9.1.1.3.2.1.cmml">⁢</mo><msup id="A2.p1.9.m9.1.1.3.2.3" xref="A2.p1.9.m9.1.1.3.2.3.cmml"><mi id="A2.p1.9.m9.1.1.3.2.3.2" xref="A2.p1.9.m9.1.1.3.2.3.2.cmml">d</mi><mn id="A2.p1.9.m9.1.1.3.2.3.3" xref="A2.p1.9.m9.1.1.3.2.3.3.cmml">2</mn></msup></mrow><mo id="A2.p1.9.m9.1.1.3.1" xref="A2.p1.9.m9.1.1.3.1.cmml">+</mo><mrow id="A2.p1.9.m9.1.1.3.3" xref="A2.p1.9.m9.1.1.3.3.cmml"><mrow id="A2.p1.9.m9.1.1.3.3.2" xref="A2.p1.9.m9.1.1.3.3.2.cmml"><mn id="A2.p1.9.m9.1.1.3.3.2.2" xref="A2.p1.9.m9.1.1.3.3.2.2.cmml">4</mn><mo id="A2.p1.9.m9.1.1.3.3.2.1" xref="A2.p1.9.m9.1.1.3.3.2.1.cmml">⁢</mo><msup id="A2.p1.9.m9.1.1.3.3.2.3" xref="A2.p1.9.m9.1.1.3.3.2.3.cmml"><mi id="A2.p1.9.m9.1.1.3.3.2.3.2" xref="A2.p1.9.m9.1.1.3.3.2.3.2.cmml">d</mi><mn id="A2.p1.9.m9.1.1.3.3.2.3.3" xref="A2.p1.9.m9.1.1.3.3.2.3.3.cmml">2</mn></msup></mrow><mo id="A2.p1.9.m9.1.1.3.3.1" xref="A2.p1.9.m9.1.1.3.3.1.cmml">/</mo><mi id="A2.p1.9.m9.1.1.3.3.3" xref="A2.p1.9.m9.1.1.3.3.3.cmml">G</mi></mrow></mrow></mfrac><annotation-xml encoding="MathML-Content" id="A2.p1.9.m9.1b"><apply id="A2.p1.9.m9.1.1.cmml" xref="A2.p1.9.m9.1.1"><divide id="A2.p1.9.m9.1.1.1.cmml" xref="A2.p1.9.m9.1.1"></divide><apply id="A2.p1.9.m9.1.1.2.cmml" xref="A2.p1.9.m9.1.1.2"><divide id="A2.p1.9.m9.1.1.2.1.cmml" xref="A2.p1.9.m9.1.1.2.1"></divide><apply id="A2.p1.9.m9.1.1.2.2.cmml" xref="A2.p1.9.m9.1.1.2.2"><times id="A2.p1.9.m9.1.1.2.2.1.cmml" xref="A2.p1.9.m9.1.1.2.2.1"></times><cn id="A2.p1.9.m9.1.1.2.2.2.cmml" type="integer" xref="A2.p1.9.m9.1.1.2.2.2">4</cn><apply id="A2.p1.9.m9.1.1.2.2.3.cmml" xref="A2.p1.9.m9.1.1.2.2.3"><csymbol cd="ambiguous" id="A2.p1.9.m9.1.1.2.2.3.1.cmml" xref="A2.p1.9.m9.1.1.2.2.3">superscript</csymbol><ci id="A2.p1.9.m9.1.1.2.2.3.2.cmml" xref="A2.p1.9.m9.1.1.2.2.3.2">𝑑</ci><cn id="A2.p1.9.m9.1.1.2.2.3.3.cmml" type="integer" xref="A2.p1.9.m9.1.1.2.2.3.3">2</cn></apply></apply><ci id="A2.p1.9.m9.1.1.2.3.cmml" xref="A2.p1.9.m9.1.1.2.3">𝐺</ci></apply><apply id="A2.p1.9.m9.1.1.3.cmml" xref="A2.p1.9.m9.1.1.3"><plus id="A2.p1.9.m9.1.1.3.1.cmml" xref="A2.p1.9.m9.1.1.3.1"></plus><apply id="A2.p1.9.m9.1.1.3.2.cmml" xref="A2.p1.9.m9.1.1.3.2"><times id="A2.p1.9.m9.1.1.3.2.1.cmml" xref="A2.p1.9.m9.1.1.3.2.1"></times><cn id="A2.p1.9.m9.1.1.3.2.2.cmml" type="integer" xref="A2.p1.9.m9.1.1.3.2.2">20</cn><apply id="A2.p1.9.m9.1.1.3.2.3.cmml" xref="A2.p1.9.m9.1.1.3.2.3"><csymbol cd="ambiguous" id="A2.p1.9.m9.1.1.3.2.3.1.cmml" xref="A2.p1.9.m9.1.1.3.2.3">superscript</csymbol><ci id="A2.p1.9.m9.1.1.3.2.3.2.cmml" xref="A2.p1.9.m9.1.1.3.2.3.2">𝑑</ci><cn id="A2.p1.9.m9.1.1.3.2.3.3.cmml" type="integer" xref="A2.p1.9.m9.1.1.3.2.3.3">2</cn></apply></apply><apply id="A2.p1.9.m9.1.1.3.3.cmml" xref="A2.p1.9.m9.1.1.3.3"><divide id="A2.p1.9.m9.1.1.3.3.1.cmml" xref="A2.p1.9.m9.1.1.3.3.1"></divide><apply id="A2.p1.9.m9.1.1.3.3.2.cmml" xref="A2.p1.9.m9.1.1.3.3.2"><times id="A2.p1.9.m9.1.1.3.3.2.1.cmml" xref="A2.p1.9.m9.1.1.3.3.2.1"></times><cn id="A2.p1.9.m9.1.1.3.3.2.2.cmml" type="integer" xref="A2.p1.9.m9.1.1.3.3.2.2">4</cn><apply id="A2.p1.9.m9.1.1.3.3.2.3.cmml" xref="A2.p1.9.m9.1.1.3.3.2.3"><csymbol cd="ambiguous" id="A2.p1.9.m9.1.1.3.3.2.3.1.cmml" xref="A2.p1.9.m9.1.1.3.3.2.3">superscript</csymbol><ci id="A2.p1.9.m9.1.1.3.3.2.3.2.cmml" xref="A2.p1.9.m9.1.1.3.3.2.3.2">𝑑</ci><cn id="A2.p1.9.m9.1.1.3.3.2.3.3.cmml" type="integer" xref="A2.p1.9.m9.1.1.3.3.2.3.3">2</cn></apply></apply><ci id="A2.p1.9.m9.1.1.3.3.3.cmml" xref="A2.p1.9.m9.1.1.3.3.3">𝐺</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.9.m9.1c">\frac{4d^{2}/G}{20d^{2}+4d^{2}/G}</annotation><annotation encoding="application/x-llamapun" id="A2.p1.9.m9.1d">divide start_ARG 4 italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_G end_ARG start_ARG 20 italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 4 italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_G end_ARG</annotation></semantics></math> which is less than 5% when <math alttext="G\geq 4" class="ltx_Math" display="inline" id="A2.p1.10.m10.1"><semantics id="A2.p1.10.m10.1a"><mrow id="A2.p1.10.m10.1.1" xref="A2.p1.10.m10.1.1.cmml"><mi id="A2.p1.10.m10.1.1.2" xref="A2.p1.10.m10.1.1.2.cmml">G</mi><mo id="A2.p1.10.m10.1.1.1" xref="A2.p1.10.m10.1.1.1.cmml">≥</mo><mn id="A2.p1.10.m10.1.1.3" xref="A2.p1.10.m10.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.10.m10.1b"><apply id="A2.p1.10.m10.1.1.cmml" xref="A2.p1.10.m10.1.1"><geq id="A2.p1.10.m10.1.1.1.cmml" xref="A2.p1.10.m10.1.1.1"></geq><ci id="A2.p1.10.m10.1.1.2.cmml" xref="A2.p1.10.m10.1.1.2">𝐺</ci><cn id="A2.p1.10.m10.1.1.3.cmml" type="integer" xref="A2.p1.10.m10.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.10.m10.1c">G\geq 4</annotation><annotation encoding="application/x-llamapun" id="A2.p1.10.m10.1d">italic_G ≥ 4</annotation></semantics></math>), compared to the rest of the computation.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.p2">
<p class="ltx_p" id="A2.p2.4">With SingleInputKV, pre-fill tokens only require computing this negligible KV projection for layers <math alttext="&gt;l" class="ltx_Math" display="inline" id="A2.p2.1.m1.1"><semantics id="A2.p2.1.m1.1a"><mrow id="A2.p2.1.m1.1.1" xref="A2.p2.1.m1.1.1.cmml"><mi id="A2.p2.1.m1.1.1.2" xref="A2.p2.1.m1.1.1.2.cmml"></mi><mo id="A2.p2.1.m1.1.1.1" xref="A2.p2.1.m1.1.1.1.cmml">&gt;</mo><mi id="A2.p2.1.m1.1.1.3" xref="A2.p2.1.m1.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.p2.1.m1.1b"><apply id="A2.p2.1.m1.1.1.cmml" xref="A2.p2.1.m1.1.1"><gt id="A2.p2.1.m1.1.1.1.cmml" xref="A2.p2.1.m1.1.1.1"></gt><csymbol cd="latexml" id="A2.p2.1.m1.1.1.2.cmml" xref="A2.p2.1.m1.1.1.2">absent</csymbol><ci id="A2.p2.1.m1.1.1.3.cmml" xref="A2.p2.1.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.1.m1.1c">&gt;l</annotation><annotation encoding="application/x-llamapun" id="A2.p2.1.m1.1d">&gt; italic_l</annotation></semantics></math>. Therefore, it reduces the total pre-fill computation to approximately <math alttext="l/L" class="ltx_Math" display="inline" id="A2.p2.2.m2.1"><semantics id="A2.p2.2.m2.1a"><mrow id="A2.p2.2.m2.1.1" xref="A2.p2.2.m2.1.1.cmml"><mi id="A2.p2.2.m2.1.1.2" xref="A2.p2.2.m2.1.1.2.cmml">l</mi><mo id="A2.p2.2.m2.1.1.1" xref="A2.p2.2.m2.1.1.1.cmml">/</mo><mi id="A2.p2.2.m2.1.1.3" xref="A2.p2.2.m2.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.p2.2.m2.1b"><apply id="A2.p2.2.m2.1.1.cmml" xref="A2.p2.2.m2.1.1"><divide id="A2.p2.2.m2.1.1.1.cmml" xref="A2.p2.2.m2.1.1.1"></divide><ci id="A2.p2.2.m2.1.1.2.cmml" xref="A2.p2.2.m2.1.1.2">𝑙</ci><ci id="A2.p2.2.m2.1.1.3.cmml" xref="A2.p2.2.m2.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.2.m2.1c">l/L</annotation><annotation encoding="application/x-llamapun" id="A2.p2.2.m2.1d">italic_l / italic_L</annotation></semantics></math>.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S3.F2" title="Figure 2 ‣ 3 SwiftKV: Design and Implementation ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">2</span></a> shows significant end-to-end reduction in model forward time for different value of <math alttext="l" class="ltx_Math" display="inline" id="A2.p2.3.m3.1"><semantics id="A2.p2.3.m3.1a"><mi id="A2.p2.3.m3.1.1" xref="A2.p2.3.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="A2.p2.3.m3.1b"><ci id="A2.p2.3.m3.1.1.cmml" xref="A2.p2.3.m3.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.3.m3.1c">l</annotation><annotation encoding="application/x-llamapun" id="A2.p2.3.m3.1d">italic_l</annotation></semantics></math> compared to <math alttext="L" class="ltx_Math" display="inline" id="A2.p2.4.m4.1"><semantics id="A2.p2.4.m4.1a"><mi id="A2.p2.4.m4.1.1" xref="A2.p2.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A2.p2.4.m4.1b"><ci id="A2.p2.4.m4.1.1.cmml" xref="A2.p2.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.4.m4.1c">L</annotation><annotation encoding="application/x-llamapun" id="A2.p2.4.m4.1d">italic_L</annotation></semantics></math>. In Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.SS3" title="4.3 Inference Performance ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">4.3</span></a>, we show that such compute reduction translates to considerably higher aggregate serving throughput and lower latency, reducing both serving cost, and improving end-user experience.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Experimental Details</h2>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Training and evaluation details</h3>
<div class="ltx_para ltx_noindent" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.1">We directly use the Huggingface LLama-3.1 checkpoints, particularly, “meta-llama/Meta-Llama-3.1-8B-Instruct” and “meta-llama/Meta-Llama-3.1-70B-Instruct”.
For datasets, we use the supervised finetuning datasets from “HuggingFaceH4/ultrachat_200k” and “teknium/OpenHermes-2.5”, which in total is about 1.2M samples, and about 160M tokens.
We set training epochs to be 2, learning rate to be 3e-4, weight decay to be 0.05, warm up ratio to be 5%, maximum sequence length to be 8192 with attention separated sequence packing, the distillation temperature to be 2.0, and the training batch size to be 32 for both Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS1.p2">
<p class="ltx_p" id="A3.SS1.p2.1">Our evaluation follows <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8" title="">https://huggingface.co/neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8</a> using the github repository <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/neuralmagic/lm-evaluation-harness/tree/llama_3.1_instruct" title="">https://github.com/neuralmagic/lm-evaluation-harness/tree/llama_3.1_instruct</a>.
The main reason behind this is that the implemention from the repository aligns with original Llama-3.1 evaluation, which has superme scores over the original Lm-eval-harness repository.
One issue we found in the provided commands is the one used to run MMLU-5-shots.
Directly using the command does not give us desired accuracy.
Therefore, we added both <span class="ltx_text ltx_font_typewriter" id="A3.SS1.p2.1.1">--apply_chat_template</span> and <span class="ltx_text ltx_font_typewriter" id="A3.SS1.p2.1.2">--fewshot_as_multiturn</span>, and the accuracy is even slightly higher than what they reported.</p>
</div>
<div class="ltx_para" id="A3.SS1.p3">
<p class="ltx_p" id="A3.SS1.p3.1">For all tasks, we follow the same number of few shots and/or chain of thoughts as the provided commands.
We present the number of shots and metrics used in the paper in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3.T1" title="Table C.1 ‣ C.1 Training and evaluation details ‣ Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">C.1</span></a>.</p>
</div>
<figure class="ltx_table" id="A3.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table C.1: </span>
The setting for different tasks
</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="A3.T1.1" style="width:738.1pt;height:55pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="A3.T1.1.1"><span class="ltx_text" id="A3.T1.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="A3.T1.1.1.1.1">
<span class="ltx_tr" id="A3.T1.1.1.1.1.1">
<span class="ltx_td ltx_align_center ltx_border_tt" id="A3.T1.1.1.1.1.1.1">Arc-Challenge</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A3.T1.1.1.1.1.1.2">Winogrande</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A3.T1.1.1.1.1.1.3">HelloSwag</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A3.T1.1.1.1.1.1.4">truthfulqa</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A3.T1.1.1.1.1.1.5">MMLU</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A3.T1.1.1.1.1.1.6">MMLU-CoT</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A3.T1.1.1.1.1.1.7">GSM-8K</span></span>
<span class="ltx_tr" id="A3.T1.1.1.1.1.2">
<span class="ltx_td ltx_align_center ltx_border_t" id="A3.T1.1.1.1.1.2.1">0-shot</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A3.T1.1.1.1.1.2.2">5-shots</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A3.T1.1.1.1.1.2.3">10-shots</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A3.T1.1.1.1.1.2.4">0-shot</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A3.T1.1.1.1.1.2.5">5-shots</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A3.T1.1.1.1.1.2.6">0-shot</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A3.T1.1.1.1.1.2.7">8-shots</span></span>
<span class="ltx_tr" id="A3.T1.1.1.1.1.3">
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T1.1.1.1.1.3.1">exact_match,multi_choice</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T1.1.1.1.1.3.2">acc</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T1.1.1.1.1.3.3">acc_norm</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T1.1.1.1.1.3.4">truthfulqa_mc2 (acc)</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T1.1.1.1.1.3.5">exact_match,multi_choice</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T1.1.1.1.1.3.6">exact_match,strict-match</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T1.1.1.1.1.3.7">exact_match,strict-match</span></span>
</span></span></p>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Inference Speedup Evaluation Details</h3>
<figure class="ltx_figure" id="A3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="262" id="A3.F1.g1" src="x9.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure C.1: </span>
Time to first token (TTFT, top) and time per output token (TPOT, bottom) for input lengths 2000 (left), 8000 (middle), and 32000 (right) for Llama-3.1-8B. For each experiment, a range of different request arrival rates is simulated. Each request generates 256 output tokens.
</figcaption>
</figure>
<section class="ltx_paragraph" id="A3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Hardware Details.</h4>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A3.SS2.SSS0.Px1.p1.1">We ran all inference speedup experiments on a AWS p5.48xlarge instance, with 8 NVIDIA H100 GPUs, 192 vCPUs, and 2TB memory. Llama-3.1-8B-Instruct experiments are run using 1 of the 8 GPUs, and Llama-3.1-70B-Instruct experiments are run using 4 of the 8 GPUs.</p>
</div>
</section>
<section class="ltx_paragraph" id="A3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">vLLM Configuration.</h4>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="A3.SS2.SSS0.Px2.p1.1">We ran all experiments with <span class="ltx_text ltx_font_typewriter" id="A3.SS2.SSS0.Px2.p1.1.1">enforce_eager</span> and chunked prefill enabled with <span class="ltx_text ltx_font_typewriter" id="A3.SS2.SSS0.Px2.p1.1.2">max_num_batched_tokens</span> set to 2048. To run each benchmark, we instantiated vLLM’s <span class="ltx_text ltx_font_typewriter" id="A3.SS2.SSS0.Px2.p1.1.3">AsyncLLMEngine</span> and submitted requests using its <span class="ltx_text ltx_font_typewriter" id="A3.SS2.SSS0.Px2.p1.1.4">generate</span> method according to each benchmark setting. For each request, the inputs are tokenized before being submitted, and the outputs are forced to a fixed length of 256.</p>
</div>
</section>
<section class="ltx_paragraph" id="A3.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Llama-3.1-8B Latency Evaluation.</h4>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="A3.SS2.SSS0.Px3.p1.1">See Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A3.F1" title="Figure C.1 ‣ C.2 Inference Speedup Evaluation Details ‣ Appendix C Experimental Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">C.1</span></a>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Inter-layer AcrossKV vs Intra-Layer KV cache Reduction</h2>
<div class="ltx_para ltx_noindent" id="A4.p1">
<p class="ltx_p" id="A4.p1.2">In this section, we share different design choices of AcrossKV, which considers the tradeoff between GQA <cite class="ltx_cite ltx_citemacro_citep">(Ainslie et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib2" title="">2023a</a>)</cite> and the acorss layer sharing into the design.
Particularly, when <math alttext="\text{AcrossKV}\geq 2" class="ltx_Math" display="inline" id="A4.p1.1.m1.1"><semantics id="A4.p1.1.m1.1a"><mrow id="A4.p1.1.m1.1.1" xref="A4.p1.1.m1.1.1.cmml"><mtext id="A4.p1.1.m1.1.1.2" xref="A4.p1.1.m1.1.1.2a.cmml">AcrossKV</mtext><mo id="A4.p1.1.m1.1.1.1" xref="A4.p1.1.m1.1.1.1.cmml">≥</mo><mn id="A4.p1.1.m1.1.1.3" xref="A4.p1.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.1.m1.1b"><apply id="A4.p1.1.m1.1.1.cmml" xref="A4.p1.1.m1.1.1"><geq id="A4.p1.1.m1.1.1.1.cmml" xref="A4.p1.1.m1.1.1.1"></geq><ci id="A4.p1.1.m1.1.1.2a.cmml" xref="A4.p1.1.m1.1.1.2"><mtext id="A4.p1.1.m1.1.1.2.cmml" xref="A4.p1.1.m1.1.1.2">AcrossKV</mtext></ci><cn id="A4.p1.1.m1.1.1.3.cmml" type="integer" xref="A4.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.1.m1.1c">\text{AcrossKV}\geq 2</annotation><annotation encoding="application/x-llamapun" id="A4.p1.1.m1.1d">AcrossKV ≥ 2</annotation></semantics></math>, we can either use GQA and AcrossKV together or we can simply use AcrossKV to get all savings.
For instance, when <math alttext="\text{AcrossKV}=4" class="ltx_Math" display="inline" id="A4.p1.2.m2.1"><semantics id="A4.p1.2.m2.1a"><mrow id="A4.p1.2.m2.1.1" xref="A4.p1.2.m2.1.1.cmml"><mtext id="A4.p1.2.m2.1.1.2" xref="A4.p1.2.m2.1.1.2a.cmml">AcrossKV</mtext><mo id="A4.p1.2.m2.1.1.1" xref="A4.p1.2.m2.1.1.1.cmml">=</mo><mn id="A4.p1.2.m2.1.1.3" xref="A4.p1.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.2.m2.1b"><apply id="A4.p1.2.m2.1.1.cmml" xref="A4.p1.2.m2.1.1"><eq id="A4.p1.2.m2.1.1.1.cmml" xref="A4.p1.2.m2.1.1.1"></eq><ci id="A4.p1.2.m2.1.1.2a.cmml" xref="A4.p1.2.m2.1.1.2"><mtext id="A4.p1.2.m2.1.1.2.cmml" xref="A4.p1.2.m2.1.1.2">AcrossKV</mtext></ci><cn id="A4.p1.2.m2.1.1.3.cmml" type="integer" xref="A4.p1.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.2.m2.1c">\text{AcrossKV}=4</annotation><annotation encoding="application/x-llamapun" id="A4.p1.2.m2.1d">AcrossKV = 4</annotation></semantics></math> (a.k.a., the second row of the final session in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.T1" title="Table 1 ‣ 4.2 Model Quality with Compression ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">1</span></a>), we have KV cache reduction from both GQA and AcrossKV.
However, we can either do multi-query attention (MQA) for all 16 layers or do multi-head attention (MHA) but share the KV cache for all 16 layers.</p>
</div>
<figure class="ltx_table" id="A4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table D.1: </span>
Llama-3.1-8B-Instruct AcrossKV design
</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="A4.T1.1" style="width:538.3pt;height:91pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="A4.T1.1.1"><span class="ltx_text" id="A4.T1.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="A4.T1.1.1.1.1">
<span class="ltx_tr" id="A4.T1.1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_border_tt ltx_rowspan ltx_rowspan_2" id="A4.T1.1.1.1.1.1.1"><span class="ltx_text" id="A4.T1.1.1.1.1.1.1.1">Method</span></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A4.T1.1.1.1.1.1.2">Arc-Challenge</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A4.T1.1.1.1.1.1.3">Winogrande</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A4.T1.1.1.1.1.1.4">Hellaswag</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A4.T1.1.1.1.1.1.5">TruthfulQA</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A4.T1.1.1.1.1.1.6">MMLU</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A4.T1.1.1.1.1.1.7">MMLU-CoT</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="A4.T1.1.1.1.1.1.8">GSM-8K</span>
<span class="ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_2" id="A4.T1.1.1.1.1.1.9"><span class="ltx_text" id="A4.T1.1.1.1.1.1.9.1">Avg.</span></span></span>
<span class="ltx_tr" id="A4.T1.1.1.1.1.2">
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.2.1">0-shot</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.2.2">5-shots</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.2.3">10-shots</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.2.4">0-shot</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.2.5">5-shots</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.2.6">0-shot</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.2.7">8-shots</span></span>
<span class="ltx_tr" id="A4.T1.1.1.1.1.3">
<span class="ltx_td ltx_align_left ltx_border_t" id="A4.T1.1.1.1.1.3.1">MQA</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A4.T1.1.1.1.1.3.2">66.89</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A4.T1.1.1.1.1.3.3">72.22</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A4.T1.1.1.1.1.3.4">67.33</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A4.T1.1.1.1.1.3.5">55.00</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A4.T1.1.1.1.1.3.6">55.96</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A4.T1.1.1.1.1.3.7">39.12</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A4.T1.1.1.1.1.3.8">22.37</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A4.T1.1.1.1.1.3.9">54.13</span></span>
<span class="ltx_tr" id="A4.T1.1.1.1.1.4">
<span class="ltx_td ltx_align_left" id="A4.T1.1.1.1.1.4.1">AcrossKV-MHA</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.4.2">77.99</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.4.3">75.85</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.4.4">77.37</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.4.5">55.50</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.4.6">63.55</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.4.7">65.48</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.4.8">72.63</span>
<span class="ltx_td ltx_align_center" id="A4.T1.1.1.1.1.4.9">69.76</span></span>
<span class="ltx_tr" id="A4.T1.1.1.1.1.5">
<span class="ltx_td ltx_align_left ltx_border_bb" id="A4.T1.1.1.1.1.5.1">AcrossKV-GQA</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="A4.T1.1.1.1.1.5.2">79.35</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="A4.T1.1.1.1.1.5.3">77.51</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="A4.T1.1.1.1.1.5.4">78.44</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="A4.T1.1.1.1.1.5.5">54.96</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="A4.T1.1.1.1.1.5.6">65.71</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="A4.T1.1.1.1.1.5.7">67.75</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="A4.T1.1.1.1.1.5.8">76.72</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="A4.T1.1.1.1.1.5.9">71.49</span></span>
</span></span></p>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="A4.p2">
<p class="ltx_p" id="A4.p2.1">We present the <math alttext="50\%" class="ltx_Math" display="inline" id="A4.p2.1.m1.1"><semantics id="A4.p2.1.m1.1a"><mrow id="A4.p2.1.m1.1.1" xref="A4.p2.1.m1.1.1.cmml"><mn id="A4.p2.1.m1.1.1.2" xref="A4.p2.1.m1.1.1.2.cmml">50</mn><mo id="A4.p2.1.m1.1.1.1" xref="A4.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.p2.1.m1.1b"><apply id="A4.p2.1.m1.1.1.cmml" xref="A4.p2.1.m1.1.1"><csymbol cd="latexml" id="A4.p2.1.m1.1.1.1.cmml" xref="A4.p2.1.m1.1.1.1">percent</csymbol><cn id="A4.p2.1.m1.1.1.2.cmml" type="integer" xref="A4.p2.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p2.1.m1.1c">50\%</annotation><annotation encoding="application/x-llamapun" id="A4.p2.1.m1.1d">50 %</annotation></semantics></math> SingleInputKV reduction with MQA, GQA plus AcrossKV, and GQA plus MHA in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A4.T1" title="Table D.1 ‣ Appendix D Inter-layer AcrossKV vs Intra-Layer KV cache Reduction ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">D.1</span></a>, that all have the same KV cache reduction, 37.5%.
AcrossKV-GQA actually provides the best performance.
One thing to notice is that the AcrossKV-MHA is actually worse than the result of AcrossKV-16x from from Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S4.T1" title="Table 1 ‣ 4.2 Model Quality with Compression ‣ 4 Main Results ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">1</span></a> even though AcrossKV-MHA has larger KV cache than AcrossKV-16x.
We hypothesis that this might be related to hyper-paramter tuning but did not invest deeper.
Also, note that pure MQA leads to worst performance, which is about 17 points lower than AcrossKV-GQA</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p3">
<p class="ltx_p" id="A4.p3.1">How to effectively balance inter/intra-layer KV cache sharing is an interesting direction to explore.
We hope that our initial experiments here shed some light for future research.</p>
</div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Early Exit Details</h2>
<div class="ltx_para ltx_noindent" id="A5.p1">
<p class="ltx_p" id="A5.p1.1">Thanks to SingleInputKV, there is no need to go through the entire network to compute all KV cache for later tokens generation.
This also brings another unique opportunity as compared to standard transformer architecture design: it allows the model to perform early exit to speedup both the prefill and generation phases without worrying about missing KV cache.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.p2">
<p class="ltx_p" id="A5.p2.1">To add early exit upon SwiftKV, we add an extra language modeling head and use the input to calculate SingleInputKV to directly compute the output logits.
We apply the same distillation loss of this early exit logits with the original teacher’s logits and directly sum the two distillation losses together as our final optimizing loss.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.p3">
<p class="ltx_p" id="A5.p3.1">After training, we first look the alignment between the early exit logits and the final logits.
The figure is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.F5" title="Figure 5 ‣ Table 6 ‣ 5.4 Combining with other KV cache compression methods ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">5</span></a>.
The left axis plot the density of early exit largest probabilities.
And the right axis shows the probabilities when the maximum of early exit logits aligns with the final logits for each bin.
As can be seen, when the maximum logits is larger than <math alttext="0.95" class="ltx_Math" display="inline" id="A5.p3.1.m1.1"><semantics id="A5.p3.1.m1.1a"><mn id="A5.p3.1.m1.1.1" xref="A5.p3.1.m1.1.1.cmml">0.95</mn><annotation-xml encoding="MathML-Content" id="A5.p3.1.m1.1b"><cn id="A5.p3.1.m1.1.1.cmml" type="float" xref="A5.p3.1.m1.1.1">0.95</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.p3.1.m1.1c">0.95</annotation><annotation encoding="application/x-llamapun" id="A5.p3.1.m1.1d">0.95</annotation></semantics></math>, the alignment likelihood is larger than 66%.
Note that this is achieved within 160M token training and longer training should help the alignment.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.p4">
<p class="ltx_p" id="A5.p4.1">How to use early exit is always an interesting directly and research topic.
Fully exploring this is out of the scope of this paper.
Here we adopt a simple heuristic approach.
When the largest probability is larger than 0.95, we directly use the early exit prediction.
Otherwise, we still process the remaining layers to get the final prediction.
We apply this logic to some questions we selected from Alpaca <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#bib.bib46" title="">2023</a>)</cite> and the results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#S5.T6" title="Table 6 ‣ 5.4 Combining with other KV cache compression methods ‣ 5 Ablation and Discussion ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">6</span></a> and Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03960v1#A5.SS1" title="E.1 Early Exit Examples ‣ Appendix E Early Exit Details ‣ SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation"><span class="ltx_text ltx_ref_tag">E.1</span></a>.</p>
</div>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Early Exit Examples</h3>
<div class="ltx_para ltx_noindent" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.1">Here we provide more examples of early exit from Alpaca dataset.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p2">
<div class="ltx_listing ltx_lstlisting ltx_listing" id="A5.SS1.p2.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,Question:

Describe a time when you had to make a difficult decision.

Answer:

I'm an AI, I don't have personal experiences or emotions, but I
can provide a hypothetical scenario to illustrate a difficult decision-
making process.

Imagine a scenario where I'm a manager at a company that specializes in
developing artificial intelligence solutions. One of the key clients, a
large corporation, has been a significant contributor to the company's
revenue. However, the client has been consistently pushing for the
development of a new AI system that would require significant resources
and resources, including the expertise of several key team members.

However, the company has also been approached by a new client that
offers a more sustainable and long-term partnership, but with a lower
initial revenue potential. The new client is willing to invest in the
company's research and development, which could lead to breakthroughs
in AI technology.

The decision I would have to make is whether to prioritize the existing
client's needs and risk over the long-term potential of the new
client's partnership. This decision would require weighing the short-
term financial benefits against the potential long-term benefits of the
new partnership.

To make this decision, I would consider the following factors:

1. **Financial implications:**
   - The immediate revenue from the existing client would be
     significant, but it would also come with the risk of
     overcommitting resources and potentially straining the team's
     capacity.
   - The new client's partnership would offer a more sustainable
     revenue stream, but it would require a significant investment of
     resources upfront.

2. **Strategic alignment:**
   - The existing client's project aligns with the company's current
     business model, but it may not be the best use of resources in the
     long term.
   - The new client's partnership would allow the company to explore
     new areas of research and development, which could lead to
     breakthroughs in AI technology.

3. **Team dynamics:**
   - The existing client's project would require the involvement of
     several key team members, which could lead to burnout and
     decreased morale.
   - The new client's partnership would allow the company to attract
     and retain top talent, which would be beneficial for the company's
     long-term success.
...
======================================================================
Question:

What is the capital of France?

Answer:

The capital of France is Paris.
======================================================================
Question:

Explain the use of word embeddings in Natural Language Processing

Answer:

**Word Embeddings in Natural Language Processing**

Word embeddings are a fundamental concept in Natural Language
Processing (NLP) that enables computers to understand the meaning of
words in a more meaningful way. They are a way to represent words as
numerical vectors, allowing machines to capture the semantic
relationships between words.

**What are Word embeddings?**

Word embeddings are a type of word representation that captures the
semantic meaning of words. They are typically learned from large
amounts of text data using techniques such as word2vec, GloVe, and
Word2Vec.

**How do Word embeddings work?**

Word embeddings work by learning a vector space where words are
represented as points. Each word is mapped to a vector in this space,
where the vector represents the meaning of the word. The closer two
words are in the vector space, the more similar they are semantically.

**Types of Word embeddings**

There are several types of word embeddings, including:

1. **Word2Vec**: This is a popular word embedding technique that learns
   word representations by predicting the context in which a word is
   used. Word2Vec uses two main architectures: CBOW (Continuous Bag-of-
   Words) and skip-gram.
2. **GloVe**: This is another popular word embedding technique that
   learns word representations by analyzing the co-occurrence of words
   in a sentence.
3. **Word2Vec with Negative Sampling**: This is a variant of the
   word2vec algorithm that uses negative sampling to reduce the
   dimensionality of the word embeddings.

**How are Word embeddings used in NLP tasks?**

Word embeddings are used in a variety of NLP tasks, including:

1. **Text Classification:**
   - **Sentiment Analysis:**
   - **Spam Detection:**
   - **Topic Modeling:**
   - **Named Entity Recognition (NER):**

2. **Text Generation:**
   - **Text Summarization:**
   - **Text Generation:**

3. **Information Retrieval:**
   - **Information Retrieval:**

4. **Machine Translation:**

5. **Question Answering:**
...
======================================================================
Question:

What is the product of 6 and 2?

Answer:

The product of 6 and 2 is 12.
======================================================================
Question:

Give three tips for staying healthy.

Answer:

Here are three tips for staying healthy:

1. **Maintain a Balanced Diet:**

Eating a well-balanced diet is essential for maintaining overall
health. This includes consuming a variety of fruits, vegetables, whole
grains, lean proteins, and healthy fats. Aim to include a rainbow of
colors on your plate to ensure you're getting a range of essential
vitamins and minerals. Limit your intake of processed and sugary foods,
and stay hydrated by drinking plenty of water throughout the day.

2. **Stay Physically Active:**

Regular physical activity is crucial for maintaining physical and
mental health. Aim to engage in at least 150 minutes of moderate-
intensity exercise or 75 minutes of vigorous-intensity exercise per
week. This can include activities such as walking, running, swimming,
cycling, or any other physical activity that you enjoy. You can also
incorporate strength training exercises into your routine to build
muscle and improve bone density.

3. **Get Enough Sleep and Manage Stress:**

Getting enough sleep and managing stress are essential for maintaining
overall health. Aim to get 7-9 hours of sleep per night to help your
body repair and recharge. Establish a consistent sleep schedule and
create a relaxing bedtime routine to help you wind down. Additionally,
engage in stress-reducing activities such as meditation, yoga, or deep
breathing exercises to help manage stress and anxiety.

Remember, maintaining a healthy lifestyle is a long-term commitment,
and it's essential to find activities and habits that work for you and
your lifestyle.">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.1">Question</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx12">
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.1">Describe</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.3">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.5">time</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.7">when</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.9">you</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.11">had</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.13">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.15">make</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.17">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.19">difficult</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.21">decision</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.22">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx14">
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.1">Answer</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx16">
</div>
<div class="ltx_listingline" id="lstnumberx17">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.1">I</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.2">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.3">m</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.5">an</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.7">AI</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.8">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.10">I</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.12">don</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.13">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.14">t</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.16">have</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.18">personal</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.20">experiences</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.22">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.24">emotions</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.25">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.27">but</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.28"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.29">I</span>
</div>
<div class="ltx_listingline" id="lstnumberx18">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.1">can</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.3">provide</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.5">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.7">hypothetical</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.9">scenario</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.11">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.13">illustrate</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.15">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.17">difficult</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.19">decision</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.20">-</span>
</div>
<div class="ltx_listingline" id="lstnumberx19">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.1">making</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.3">process</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.4">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx20">
</div>
<div class="ltx_listingline" id="lstnumberx21">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.1">Imagine</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.3">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.5">scenario</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.7">where</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.9">I</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.10">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.11">m</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.13">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.15">manager</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.17">at</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.19">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.21">company</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.23">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.25">specializes</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.27">in</span>
</div>
<div class="ltx_listingline" id="lstnumberx22">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.1">developing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.3">artificial</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.5">intelligence</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.7">solutions</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.8">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.10">One</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.12">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.14">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.16">key</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.18">clients</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.19">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.21">a</span>
</div>
<div class="ltx_listingline" id="lstnumberx23">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.1">large</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.3">corporation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.4">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.6">has</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.8">been</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.10">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.12">significant</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.14">contributor</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.16">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.18">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.20">company</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.21">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.22">s</span>
</div>
<div class="ltx_listingline" id="lstnumberx24">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.1">revenue</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.2">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.4">However</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.5">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.7">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.9">client</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.11">has</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.13">been</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.15">consistently</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.17">pushing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.19">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.21">the</span>
</div>
<div class="ltx_listingline" id="lstnumberx25">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.1">development</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.3">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.5">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.7">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.9">AI</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.11">system</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.13">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.15">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.17">require</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.19">significant</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.21">resources</span>
</div>
<div class="ltx_listingline" id="lstnumberx26">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.1">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.3">resources</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.4">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.6">including</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.8">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.10">expertise</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.12">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.14">several</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.16">key</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.18">team</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.20">members</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.21">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx27">
</div>
<div class="ltx_listingline" id="lstnumberx28">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.1">However</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.2">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.4">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.6">company</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.8">has</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.10">also</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.12">been</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.14">approached</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.16">by</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.18">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.20">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.22">client</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.24">that</span>
</div>
<div class="ltx_listingline" id="lstnumberx29">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.1">offers</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.3">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.5">more</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.7">sustainable</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.9">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.11">long</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.12">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.13">term</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.15">partnership</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.16">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.18">but</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.20">with</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.22">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.24">lower</span>
</div>
<div class="ltx_listingline" id="lstnumberx30">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.1">initial</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.3">revenue</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.5">potential</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.6">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.8">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.10">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.12">client</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.14">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.16">willing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.18">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.20">invest</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.22">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.24">the</span>
</div>
<div class="ltx_listingline" id="lstnumberx31">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.1">company</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx31.2">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.3">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.5">research</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.7">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.9">development</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx31.10">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.12">which</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.14">could</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.16">lead</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.18">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.20">breakthroughs</span>
</div>
<div class="ltx_listingline" id="lstnumberx32">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx32.1">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx32.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx32.3">AI</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx32.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx32.5">technology</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx32.6">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx33">
</div>
<div class="ltx_listingline" id="lstnumberx34">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.1">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.3">decision</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.5">I</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.7">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.9">have</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.11">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.13">make</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.15">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.17">whether</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.19">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.21">prioritize</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.23">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.25">existing</span>
</div>
<div class="ltx_listingline" id="lstnumberx35">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.1">client</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx35.2">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.3">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.5">needs</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.7">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.9">risk</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.11">over</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.13">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.15">long</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx35.16">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.17">term</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.19">potential</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.21">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.23">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.25">new</span>
</div>
<div class="ltx_listingline" id="lstnumberx36">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.1">client</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx36.2">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.3">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.5">partnership</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx36.6">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.8">This</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.10">decision</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.12">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.14">require</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.16">weighing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.18">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.20">short</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx36.21">-</span>
</div>
<div class="ltx_listingline" id="lstnumberx37">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.1">term</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.3">financial</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.5">benefits</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.7">against</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.9">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.11">potential</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.13">long</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx37.14">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.15">term</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.17">benefits</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.19">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.21">the</span>
</div>
<div class="ltx_listingline" id="lstnumberx38">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.1">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx38.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.3">partnership</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx38.4">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx39">
</div>
<div class="ltx_listingline" id="lstnumberx40">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.1">To</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.3">make</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.5">this</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.7">decision</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx40.8">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.10">I</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.12">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.14">consider</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.16">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.18">following</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.20">factors</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx40.21">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx41">
</div>
<div class="ltx_listingline" id="lstnumberx42">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx42.1">1.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx42.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx42.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx42.4">Financial</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx42.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx42.6">implications</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx42.7">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx43">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx43.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.4">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.6">immediate</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.8">revenue</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.10">from</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.12">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.14">existing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.16">client</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.18">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.20">be</span>
</div>
<div class="ltx_listingline" id="lstnumberx44">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.2">significant</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.3">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.5">but</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.7">it</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.9">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.11">also</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.13">come</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.15">with</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.17">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.19">risk</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.21">of</span>
</div>
<div class="ltx_listingline" id="lstnumberx45">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.2">overcommitting</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.4">resources</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.6">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.8">potentially</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.10">straining</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.12">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.14">team</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.15">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.16">s</span>
</div>
<div class="ltx_listingline" id="lstnumberx46">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx46.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx46.2">capacity</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx46.3">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx47">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx47.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.4">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.6">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.8">client</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx47.9">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.10">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.12">partnership</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.14">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.16">offer</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.18">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.20">more</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.22">sustainable</span>
</div>
<div class="ltx_listingline" id="lstnumberx48">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.2">revenue</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.4">stream</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx48.5">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.7">but</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.9">it</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.11">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.13">require</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.15">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.17">significant</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.19">investment</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx48.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.21">of</span>
</div>
<div class="ltx_listingline" id="lstnumberx49">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx49.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx49.2">resources</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx49.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx49.4">upfront</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx49.5">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx50">
</div>
<div class="ltx_listingline" id="lstnumberx51">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx51.1">2.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx51.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx51.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx51.4">Strategic</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx51.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx51.6">alignment</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx51.7">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx52">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx52.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.4">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.6">existing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.8">client</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx52.9">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.10">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.12">project</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.14">aligns</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.16">with</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.18">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.20">company</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx52.21">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.22">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.24">current</span>
</div>
<div class="ltx_listingline" id="lstnumberx53">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.2">business</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.4">model</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx53.5">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.7">but</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.9">it</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.11">may</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.13">not</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.15">be</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.17">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.19">best</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.21">use</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.23">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.25">resources</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.27">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx53.28"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.29">the</span>
</div>
<div class="ltx_listingline" id="lstnumberx54">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx54.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx54.2">long</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx54.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx54.4">term</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx54.5">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx55">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx55.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.4">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.6">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.8">client</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx55.9">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.10">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.12">partnership</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.14">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.16">allow</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.18">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.20">company</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.22">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx55.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx55.24">explore</span>
</div>
<div class="ltx_listingline" id="lstnumberx56">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.2">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.4">areas</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.6">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.8">research</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.10">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.12">development</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx56.13">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.15">which</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.17">could</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.19">lead</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.21">to</span>
</div>
<div class="ltx_listingline" id="lstnumberx57">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx57.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx57.2">breakthroughs</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx57.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx57.4">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx57.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx57.6">AI</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx57.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx57.8">technology</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx57.9">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx58">
</div>
<div class="ltx_listingline" id="lstnumberx59">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx59.1">3.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx59.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx59.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx59.4">Team</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx59.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx59.6">dynamics</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx59.7">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx60">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx60.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.4">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.6">existing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.8">client</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx60.9">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.10">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.12">project</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.14">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.16">require</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.18">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.20">involvement</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx60.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx60.22">of</span>
</div>
<div class="ltx_listingline" id="lstnumberx61">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.2">several</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.4">key</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.6">team</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.8">members</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx61.9">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.11">which</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.13">could</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.15">lead</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.17">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.19">burnout</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx61.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx61.21">and</span>
</div>
<div class="ltx_listingline" id="lstnumberx62">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx62.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx62.2">decreased</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx62.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx62.4">morale</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx62.5">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx63">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx63.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.4">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.6">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.8">client</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx63.9">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.10">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.12">partnership</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.14">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.16">allow</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.18">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.20">company</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.22">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx63.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx63.24">attract</span>
</div>
<div class="ltx_listingline" id="lstnumberx64">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.2">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.4">retain</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.6">top</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.8">talent</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx64.9">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.11">which</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.13">would</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.15">be</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.17">beneficial</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.19">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.21">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx64.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.23">company</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx64.24">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx64.25">s</span>
</div>
<div class="ltx_listingline" id="lstnumberx65">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx65.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx65.2">long</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx65.3">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx65.4">term</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx65.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx65.6">success</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx65.7">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx66">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx66.1">...</span>
</div>
<div class="ltx_listingline" id="lstnumberx67">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx67.1">======================================================================</span>
</div>
<div class="ltx_listingline" id="lstnumberx68">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx68.1">Question</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx68.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx69">
</div>
<div class="ltx_listingline" id="lstnumberx70">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx70.1">What</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx70.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx70.3">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx70.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx70.5">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx70.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx70.7">capital</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx70.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx70.9">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx70.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx70.11">France</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx70.12">?</span>
</div>
<div class="ltx_listingline" id="lstnumberx71">
</div>
<div class="ltx_listingline" id="lstnumberx72">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx72.1">Answer</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx72.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx73">
</div>
<div class="ltx_listingline" id="lstnumberx74">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx74.1">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx74.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx74.3">capital</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx74.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx74.5">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx74.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx74.7">France</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx74.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx74.9">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx74.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx74.11">Paris</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx74.12">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx75">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx75.1">======================================================================</span>
</div>
<div class="ltx_listingline" id="lstnumberx76">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx76.1">Question</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx76.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx77">
</div>
<div class="ltx_listingline" id="lstnumberx78">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.1">Explain</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx78.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.3">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx78.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.5">use</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx78.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.7">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx78.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.9">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx78.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.11">embeddings</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx78.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.13">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx78.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.15">Natural</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx78.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.17">Language</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx78.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx78.19">Processing</span>
</div>
<div class="ltx_listingline" id="lstnumberx79">
</div>
<div class="ltx_listingline" id="lstnumberx80">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx80.1">Answer</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx80.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx81">
</div>
<div class="ltx_listingline" id="lstnumberx82">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx82.1">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx82.2">Word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx82.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx82.4">Embeddings</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx82.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx82.6">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx82.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx82.8">Natural</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx82.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx82.10">Language</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx82.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx82.12">Processing</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx82.13">**</span>
</div>
<div class="ltx_listingline" id="lstnumberx83">
</div>
<div class="ltx_listingline" id="lstnumberx84">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx84.1">Word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx84.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx84.3">embeddings</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx84.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx84.5">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx84.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx84.7">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx84.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx84.9">fundamental</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx84.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx84.11">concept</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx84.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx84.13">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx84.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx84.15">Natural</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx84.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx84.17">Language</span>
</div>
<div class="ltx_listingline" id="lstnumberx85">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.1">Processing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx85.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx85.3">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.4">NLP</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx85.5">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx85.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.7">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx85.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.9">enables</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx85.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.11">computers</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx85.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.13">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx85.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.15">understand</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx85.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.17">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx85.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.19">meaning</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx85.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx85.21">of</span>
</div>
<div class="ltx_listingline" id="lstnumberx86">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.1">words</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.3">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.5">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.7">more</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.9">meaningful</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.11">way</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx86.12">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.14">They</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.16">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.18">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.20">way</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.22">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.24">represent</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.26">words</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx86.27"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx86.28">as</span>
</div>
<div class="ltx_listingline" id="lstnumberx87">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx87.1">numerical</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx87.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx87.3">vectors</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx87.4">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx87.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx87.6">allowing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx87.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx87.8">machines</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx87.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx87.10">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx87.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx87.12">capture</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx87.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx87.14">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx87.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx87.16">semantic</span>
</div>
<div class="ltx_listingline" id="lstnumberx88">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx88.1">relationships</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx88.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx88.3">between</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx88.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx88.5">words</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx88.6">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx89">
</div>
<div class="ltx_listingline" id="lstnumberx90">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx90.1">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx90.2">What</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx90.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx90.4">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx90.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx90.6">Word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx90.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx90.8">embeddings</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx90.9">?**</span>
</div>
<div class="ltx_listingline" id="lstnumberx91">
</div>
<div class="ltx_listingline" id="lstnumberx92">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.1">Word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.3">embeddings</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.5">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.7">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.9">type</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.11">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.13">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.15">representation</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.17">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.19">captures</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx92.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx92.21">the</span>
</div>
<div class="ltx_listingline" id="lstnumberx93">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.1">semantic</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx93.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.3">meaning</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx93.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.5">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx93.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.7">words</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx93.8">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx93.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.10">They</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx93.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.12">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx93.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.14">typically</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx93.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.16">learned</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx93.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.18">from</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx93.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx93.20">large</span>
</div>
<div class="ltx_listingline" id="lstnumberx94">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.1">amounts</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.3">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.5">text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.7">data</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.9">using</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.11">techniques</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.13">such</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.15">as</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.17">word2vec</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx94.18">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.20">GloVe</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx94.21">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx94.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx94.23">and</span>
</div>
<div class="ltx_listingline" id="lstnumberx95">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx95.1">Word2Vec</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx95.2">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx96">
</div>
<div class="ltx_listingline" id="lstnumberx97">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx97.1">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx97.2">How</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx97.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx97.4">do</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx97.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx97.6">Word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx97.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx97.8">embeddings</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx97.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx97.10">work</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx97.11">?**</span>
</div>
<div class="ltx_listingline" id="lstnumberx98">
</div>
<div class="ltx_listingline" id="lstnumberx99">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.1">Word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.3">embeddings</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.5">work</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.7">by</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.9">learning</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.11">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.13">vector</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.15">space</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.17">where</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.19">words</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx99.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx99.21">are</span>
</div>
<div class="ltx_listingline" id="lstnumberx100">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.1">represented</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.3">as</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.5">points</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx100.6">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.8">Each</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.10">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.12">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.14">mapped</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.16">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.18">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.20">vector</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.22">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.24">this</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx100.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx100.26">space</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx100.27">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx101">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.1">where</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.3">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.5">vector</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.7">represents</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.9">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.11">meaning</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.13">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.15">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.17">word</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx101.18">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.20">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.22">closer</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx101.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx101.24">two</span>
</div>
<div class="ltx_listingline" id="lstnumberx102">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.1">words</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.3">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.5">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.7">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.9">vector</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.11">space</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx102.12">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.14">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.16">more</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.18">similar</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.20">they</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.22">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx102.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx102.24">semantically</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx102.25">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx103">
</div>
<div class="ltx_listingline" id="lstnumberx104">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx104.1">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx104.2">Types</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx104.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx104.4">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx104.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx104.6">Word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx104.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx104.8">embeddings</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx104.9">**</span>
</div>
<div class="ltx_listingline" id="lstnumberx105">
</div>
<div class="ltx_listingline" id="lstnumberx106">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx106.1">There</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx106.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx106.3">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx106.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx106.5">several</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx106.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx106.7">types</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx106.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx106.9">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx106.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx106.11">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx106.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx106.13">embeddings</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx106.14">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx106.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx106.16">including</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx106.17">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx107">
</div>
<div class="ltx_listingline" id="lstnumberx108">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx108.1">1.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx108.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.4">Word2Vec</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx108.5">**:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.7">This</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.9">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.11">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.13">popular</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.15">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.17">embedding</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.19">technique</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.21">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx108.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx108.23">learns</span>
</div>
<div class="ltx_listingline" id="lstnumberx109">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.2">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.4">representations</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.6">by</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.8">predicting</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.10">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.12">context</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.14">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.16">which</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.18">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.20">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx109.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx109.22">is</span>
</div>
<div class="ltx_listingline" id="lstnumberx110">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx110.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.2">used</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx110.3">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx110.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.5">Word2Vec</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx110.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.7">uses</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx110.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.9">two</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx110.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.11">main</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx110.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.13">architectures</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx110.14">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx110.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.16">CBOW</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx110.17"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx110.18">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.19">Continuous</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx110.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.21">Bag</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx110.22">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx110.23">of</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx110.24">-</span>
</div>
<div class="ltx_listingline" id="lstnumberx111">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx111.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx111.2">Words</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx111.3">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx111.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx111.5">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx111.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx111.7">skip</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx111.8">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx111.9">gram</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx111.10">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx112">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx112.1">2.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx112.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx112.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx112.4">GloVe</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx112.5">**:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx112.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx112.7">This</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx112.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx112.9">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx112.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx112.11">another</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx112.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx112.13">popular</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx112.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx112.15">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx112.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx112.17">embedding</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx112.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx112.19">technique</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx112.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx112.21">that</span>
</div>
<div class="ltx_listingline" id="lstnumberx113">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx113.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.2">learns</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx113.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.4">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx113.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.6">representations</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx113.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.8">by</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx113.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.10">analyzing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx113.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.12">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx113.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.14">co</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx113.15">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.16">occurrence</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx113.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.18">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx113.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx113.20">words</span>
</div>
<div class="ltx_listingline" id="lstnumberx114">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx114.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx114.2">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx114.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx114.4">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx114.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx114.6">sentence</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx114.7">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx115">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx115.1">3.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx115.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.4">Word2Vec</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.6">with</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.8">Negative</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.10">Sampling</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx115.11">**:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.13">This</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.15">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.17">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.19">variant</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.21">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx115.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx115.23">the</span>
</div>
<div class="ltx_listingline" id="lstnumberx116">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx116.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx116.2">word2vec</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx116.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx116.4">algorithm</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx116.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx116.6">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx116.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx116.8">uses</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx116.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx116.10">negative</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx116.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx116.12">sampling</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx116.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx116.14">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx116.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx116.16">reduce</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx116.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx116.18">the</span>
</div>
<div class="ltx_listingline" id="lstnumberx117">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx117.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx117.2">dimensionality</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx117.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx117.4">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx117.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx117.6">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx117.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx117.8">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx117.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx117.10">embeddings</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx117.11">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx118">
</div>
<div class="ltx_listingline" id="lstnumberx119">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx119.1">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx119.2">How</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx119.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx119.4">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx119.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx119.6">Word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx119.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx119.8">embeddings</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx119.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx119.10">used</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx119.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx119.12">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx119.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx119.14">NLP</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx119.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx119.16">tasks</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx119.17">?**</span>
</div>
<div class="ltx_listingline" id="lstnumberx120">
</div>
<div class="ltx_listingline" id="lstnumberx121">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.1">Word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.3">embeddings</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.5">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.7">used</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.9">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.11">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.13">variety</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.15">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.17">NLP</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.19">tasks</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx121.20">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx121.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx121.22">including</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx121.23">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx122">
</div>
<div class="ltx_listingline" id="lstnumberx123">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx123.1">1.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx123.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx123.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx123.4">Text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx123.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx123.6">Classification</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx123.7">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx124">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx124.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx124.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx124.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx124.4">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx124.5">Sentiment</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx124.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx124.7">Analysis</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx124.8">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx125">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx125.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx125.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx125.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx125.4">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx125.5">Spam</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx125.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx125.7">Detection</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx125.8">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx126">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx126.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx126.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx126.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx126.4">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx126.5">Topic</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx126.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx126.7">Modeling</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx126.8">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx127">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx127.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx127.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx127.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx127.4">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx127.5">Named</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx127.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx127.7">Entity</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx127.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx127.9">Recognition</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx127.10"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx127.11">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx127.12">NER</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx127.13">):**</span>
</div>
<div class="ltx_listingline" id="lstnumberx128">
</div>
<div class="ltx_listingline" id="lstnumberx129">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx129.1">2.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx129.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx129.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx129.4">Text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx129.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx129.6">Generation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx129.7">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx130">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx130.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx130.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx130.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx130.4">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx130.5">Text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx130.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx130.7">Summarization</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx130.8">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx131">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx131.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx131.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx131.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx131.4">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx131.5">Text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx131.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx131.7">Generation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx131.8">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx132">
</div>
<div class="ltx_listingline" id="lstnumberx133">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx133.1">3.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx133.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx133.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx133.4">Information</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx133.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx133.6">Retrieval</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx133.7">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx134">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx134.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx134.2">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx134.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx134.4">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx134.5">Information</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx134.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx134.7">Retrieval</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx134.8">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx135">
</div>
<div class="ltx_listingline" id="lstnumberx136">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx136.1">4.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx136.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx136.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx136.4">Machine</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx136.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx136.6">Translation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx136.7">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx137">
</div>
<div class="ltx_listingline" id="lstnumberx138">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx138.1">5.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx138.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx138.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx138.4">Question</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx138.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx138.6">Answering</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx138.7">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx139">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx139.1">...</span>
</div>
<div class="ltx_listingline" id="lstnumberx140">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx140.1">======================================================================</span>
</div>
<div class="ltx_listingline" id="lstnumberx141">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx141.1">Question</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx141.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx142">
</div>
<div class="ltx_listingline" id="lstnumberx143">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx143.1">What</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx143.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx143.3">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx143.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx143.5">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx143.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx143.7">product</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx143.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx143.9">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx143.10"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx143.11">6</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx143.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx143.13">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx143.14"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx143.15">2?</span>
</div>
<div class="ltx_listingline" id="lstnumberx144">
</div>
<div class="ltx_listingline" id="lstnumberx145">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx145.1">Answer</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx145.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx146">
</div>
<div class="ltx_listingline" id="lstnumberx147">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx147.1">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx147.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx147.3">product</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx147.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx147.5">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx147.6"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx147.7">6</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx147.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx147.9">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx147.10"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx147.11">2</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx147.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx147.13">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx147.14"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx147.15">12.</span>
</div>
<div class="ltx_listingline" id="lstnumberx148">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx148.1">======================================================================</span>
</div>
<div class="ltx_listingline" id="lstnumberx149">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx149.1">Question</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx149.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx150">
</div>
<div class="ltx_listingline" id="lstnumberx151">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx151.1">Give</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx151.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx151.3">three</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx151.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx151.5">tips</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx151.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx151.7">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx151.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx151.9">staying</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx151.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx151.11">healthy</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx151.12">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx152">
</div>
<div class="ltx_listingline" id="lstnumberx153">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx153.1">Answer</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx153.2">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx154">
</div>
<div class="ltx_listingline" id="lstnumberx155">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx155.1">Here</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx155.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx155.3">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx155.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx155.5">three</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx155.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx155.7">tips</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx155.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx155.9">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx155.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx155.11">staying</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx155.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx155.13">healthy</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx155.14">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx156">
</div>
<div class="ltx_listingline" id="lstnumberx157">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx157.1">1.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx157.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx157.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx157.4">Maintain</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx157.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx157.6">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx157.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx157.8">Balanced</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx157.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx157.10">Diet</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx157.11">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx158">
</div>
<div class="ltx_listingline" id="lstnumberx159">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.1">Eating</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx159.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.3">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx159.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.5">well</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx159.6">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.7">balanced</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx159.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.9">diet</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx159.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.11">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx159.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.13">essential</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx159.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.15">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx159.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.17">maintaining</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx159.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx159.19">overall</span>
</div>
<div class="ltx_listingline" id="lstnumberx160">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.1">health</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx160.2">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx160.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.4">This</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx160.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.6">includes</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx160.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.8">consuming</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx160.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.10">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx160.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.12">variety</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx160.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.14">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx160.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.16">fruits</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx160.17">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx160.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.19">vegetables</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx160.20">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx160.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx160.22">whole</span>
</div>
<div class="ltx_listingline" id="lstnumberx161">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.1">grains</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx161.2">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.4">lean</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.6">proteins</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx161.7">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.9">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.11">healthy</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.13">fats</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx161.14">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.16">Aim</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.18">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.20">include</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.22">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.24">rainbow</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx161.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx161.26">of</span>
</div>
<div class="ltx_listingline" id="lstnumberx162">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.1">colors</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.3">on</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.5">your</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.7">plate</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.9">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.11">ensure</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.13">you</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx162.14">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.15">re</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.17">getting</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.19">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.21">range</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.23">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx162.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx162.25">essential</span>
</div>
<div class="ltx_listingline" id="lstnumberx163">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.1">vitamins</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.3">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.5">minerals</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx163.6">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.8">Limit</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.10">your</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.12">intake</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.14">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.16">processed</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.18">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.20">sugary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx163.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx163.22">foods</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx163.23">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx164">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.1">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.3">stay</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.5">hydrated</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.7">by</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.9">drinking</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.11">plenty</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.13">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.15">water</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.17">throughout</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.19">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx164.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx164.21">day</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx164.22">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx165">
</div>
<div class="ltx_listingline" id="lstnumberx166">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx166.1">2.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx166.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx166.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx166.4">Stay</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx166.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx166.6">Physically</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx166.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx166.8">Active</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx166.9">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx167">
</div>
<div class="ltx_listingline" id="lstnumberx168">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx168.1">Regular</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx168.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx168.3">physical</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx168.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx168.5">activity</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx168.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx168.7">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx168.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx168.9">crucial</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx168.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx168.11">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx168.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx168.13">maintaining</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx168.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx168.15">physical</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx168.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx168.17">and</span>
</div>
<div class="ltx_listingline" id="lstnumberx169">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.1">mental</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.3">health</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx169.4">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.6">Aim</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.8">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.10">engage</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.12">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.14">at</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.16">least</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.17"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx169.18">150</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.20">minutes</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.22">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx169.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx169.24">moderate</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx169.25">-</span>
</div>
<div class="ltx_listingline" id="lstnumberx170">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx170.1">intensity</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx170.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx170.3">exercise</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx170.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx170.5">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx170.6"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx170.7">75</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx170.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx170.9">minutes</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx170.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx170.11">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx170.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx170.13">vigorous</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx170.14">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx170.15">intensity</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx170.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx170.17">exercise</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx170.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx170.19">per</span>
</div>
<div class="ltx_listingline" id="lstnumberx171">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.1">week</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx171.2">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx171.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.4">This</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx171.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.6">can</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx171.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.8">include</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx171.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.10">activities</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx171.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.12">such</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx171.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.14">as</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx171.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.16">walking</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx171.17">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx171.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.19">running</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx171.20">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx171.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx171.22">swimming</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx171.23">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx172">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.1">cycling</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx172.2">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.4">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.6">any</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.8">other</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.10">physical</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.12">activity</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.14">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.16">you</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.18">enjoy</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx172.19">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.21">You</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.23">can</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx172.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx172.25">also</span>
</div>
<div class="ltx_listingline" id="lstnumberx173">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx173.1">incorporate</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx173.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx173.3">strength</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx173.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx173.5">training</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx173.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx173.7">exercises</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx173.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx173.9">into</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx173.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx173.11">your</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx173.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx173.13">routine</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx173.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx173.15">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx173.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx173.17">build</span>
</div>
<div class="ltx_listingline" id="lstnumberx174">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx174.1">muscle</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx174.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx174.3">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx174.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx174.5">improve</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx174.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx174.7">bone</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx174.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx174.9">density</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx174.10">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx175">
</div>
<div class="ltx_listingline" id="lstnumberx176">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx176.1">3.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx176.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx176.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx176.4">Get</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx176.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx176.6">Enough</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx176.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx176.8">Sleep</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx176.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx176.10">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx176.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx176.12">Manage</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx176.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx176.14">Stress</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx176.15">:**</span>
</div>
<div class="ltx_listingline" id="lstnumberx177">
</div>
<div class="ltx_listingline" id="lstnumberx178">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.1">Getting</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx178.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.3">enough</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx178.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.5">sleep</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx178.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.7">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx178.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.9">managing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx178.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.11">stress</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx178.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.13">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx178.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.15">essential</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx178.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.17">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx178.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx178.19">maintaining</span>
</div>
<div class="ltx_listingline" id="lstnumberx179">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.1">overall</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.3">health</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx179.4">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.6">Aim</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.8">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.10">get</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.11"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx179.12">7-9</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.14">hours</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.16">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.18">sleep</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.20">per</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.22">night</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.24">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.26">help</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx179.27"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx179.28">your</span>
</div>
<div class="ltx_listingline" id="lstnumberx180">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.1">body</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx180.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.3">repair</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx180.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.5">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx180.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.7">recharge</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx180.8">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx180.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.10">Establish</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx180.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.12">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx180.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.14">consistent</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx180.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.16">sleep</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx180.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.18">schedule</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx180.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx180.20">and</span>
</div>
<div class="ltx_listingline" id="lstnumberx181">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.1">create</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.3">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.5">relaxing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.7">bedtime</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.9">routine</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.11">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.13">help</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.15">you</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.17">wind</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.19">down</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx181.20">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx181.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx181.22">Additionally</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx181.23">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx182">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.1">engage</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx182.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.3">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx182.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.5">stress</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx182.6">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.7">reducing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx182.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.9">activities</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx182.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.11">such</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx182.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.13">as</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx182.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.15">meditation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx182.16">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx182.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.18">yoga</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx182.19">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx182.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.21">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx182.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx182.23">deep</span>
</div>
<div class="ltx_listingline" id="lstnumberx183">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx183.1">breathing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx183.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx183.3">exercises</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx183.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx183.5">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx183.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx183.7">help</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx183.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx183.9">manage</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx183.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx183.11">stress</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx183.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx183.13">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx183.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx183.15">anxiety</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx183.16">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx184">
</div>
<div class="ltx_listingline" id="lstnumberx185">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.1">Remember</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx185.2">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx185.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.4">maintaining</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx185.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.6">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx185.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.8">healthy</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx185.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.10">lifestyle</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx185.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.12">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx185.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.14">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx185.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.16">long</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx185.17">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.18">term</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx185.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx185.20">commitment</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx185.21">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx186">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.1">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.3">it</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx186.4">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.5">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.7">essential</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.9">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.11">find</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.13">activities</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.15">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.17">habits</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.19">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.21">work</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.23">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.25">you</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx186.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx186.27">and</span>
</div>
<div class="ltx_listingline" id="lstnumberx187">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx187.1">your</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx187.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx187.3">lifestyle</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx187.4">.</span>
</div>
</div>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Oct  4 22:46:28 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
