<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.05717] STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines</title><meta property="og:description" content="In this work, we present STOPNet, a framework for 6-DoF object suction detection on production lines, with a focus on but not limited to transparent objects, which is an important and challenging problem in robotic sysâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.05717">

<!--Generated on Wed Feb 28 01:21:32 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">
<span id="id13.id1" class="ltx_text" style="color:#00FFFF;">STOP</span>Net: Multiview-based 6-DoF <span id="id14.id2" class="ltx_text" style="color:#00FFFF;">S</span>uction Detection for
<br class="ltx_break"><span id="id15.id3" class="ltx_text" style="color:#00FFFF;">T</span>ransparent <span id="id16.id4" class="ltx_text" style="color:#00FFFF;">O</span>bjects on <span id="id17.id5" class="ltx_text" style="color:#00FFFF;">P</span>roduction Lines
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuxuan Kuang<sup id="id18.13.id1" class="ltx_sup"><span id="id18.13.id1.1" class="ltx_text ltx_font_italic">1,2âˆ—</span></sup>, Qin Han<sup id="id19.14.id2" class="ltx_sup"><span id="id19.14.id2.1" class="ltx_text ltx_font_italic">1âˆ—</span></sup>, Danshi Li<sup id="id20.15.id3" class="ltx_sup"><span id="id20.15.id3.1" class="ltx_text ltx_font_italic">2,3</span></sup>, Qiyu Dai<sup id="id21.16.id4" class="ltx_sup"><span id="id21.16.id4.1" class="ltx_text ltx_font_italic">1</span></sup>, Lian Ding<sup id="id22.17.id5" class="ltx_sup"><span id="id22.17.id5.1" class="ltx_text ltx_font_italic">4</span></sup>, Dong Sun<sup id="id23.18.id6" class="ltx_sup"><span id="id23.18.id6.1" class="ltx_text ltx_font_italic">4</span></sup>, Hanlin Zhao<sup id="id24.19.id7" class="ltx_sup"><span id="id24.19.id7.1" class="ltx_text ltx_font_italic">4</span></sup>, He Wang<sup id="id25.20.id8" class="ltx_sup"><span id="id25.20.id8.1" class="ltx_text ltx_font_italic">1â€ </span></sup>
</span><span class="ltx_author_notes"><sup id="id26.21.id1" class="ltx_sup"><span id="id26.21.id1.1" class="ltx_text ltx_font_italic">1</span></sup>Center on Frontiers of Computing Studies, School of Computer Science, Peking University.<sup id="id27.22.id1" class="ltx_sup"><span id="id27.22.id1.1" class="ltx_text ltx_font_italic">2</span></sup>Galbot.<sup id="id28.23.id1" class="ltx_sup"><span id="id28.23.id1.1" class="ltx_text ltx_font_italic">3</span></sup>New York University.<sup id="id29.24.id1" class="ltx_sup"><span id="id29.24.id1.1" class="ltx_text ltx_font_italic">4</span></sup>Huawei Cloud Computing Technologies Co., Ltd.*The first two authors contributed equally.â€ Corresponding to hewang@pku.edu.cn.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id30.id1" class="ltx_p">In this work, we present STOPNet, a framework for 6-DoF object suction detection on production lines, with a focus on but not limited to transparent objects, which is an important and challenging problem in robotic systems and modern industry. Current methods requiring depth input fail on transparent objects due to depth camerasâ€™ deficiency in sensing their geometry, while we proposed a novel framework to reconstruct the scene on the production line depending only on RGB input, based on multiview stereo. Compared to existing works, our method not only reconstructs the whole 3D scene in order to obtain high-quality 6-DoF suction poses in real time but also generalizes to novel environments, novel arrangements and novel objects, including challenging transparent objects, both in simulation and the real world. Extensive experiments in simulation and the real world show that our method significantly surpasses the baselines and has better generalizability, which caters to practical industrial needs.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">INTRODUCTION</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Object picking on production lines is an essential task for robotic systems and is widely used in modern industrial applications, such as logistics sorting and bin picking, <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">etc.</span> Building such an autonomous robotic system to pick and place objects on a moving production line can greatly save time, reduce human labor and increase productivity. In addition, as a major end-effector in picking objects, the suction cup has gained much popularity due to its simplicity, efficiency and robustness. Therefore reliable suction detection is also worth studying to solve this task.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Due to the importance of this task, recent years have witnessed great progress in developing such systems to automatically conduct production line pick and placeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. These methods rely on low-level image features or 3D CAD models to detect suction poses, which only work on regular or seen objects. There are also learning-based methods on static object suctionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> that leverage accurate surface information from RGBD/depth input and can generalize to novel diffuse objects.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, transparent object suction still remains a challenging case for such a system. Depth sensors can hardly sense transparent objects and often generate wrong, missing and fuzzy depth on these objects, which causes the failure of these learning-based methods on transparent objects.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2310.05717/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="360" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of our production line real robot setup and our proposed STOPNet. Taking multi-timestep RGB input from two cameras, our framework conducts 3D scene reconstruction and suction detection in real time. Our model is trained on a large-scale synthetic dataset but it can also generalize to real-world objects and environments effectively.
</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">For grasping transparent objects, recent studies have focused on depth restorationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, leveraging imperfect depthÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> and RGB-based graspingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. However, recent works for suction detectionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> require accurate depth input, since suction relies more on local surface geometry than 6-DoF grasping. Therefore these methods struggle to detect suction on transparent objects without reliable depth input. In that sense, the issue of suction detection for transparent objects is worthy of study.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">As to production line pick and place system design, recent works mainly focus on suction detection from a single viewÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. These methods usually suffer from performance degradation in cluttered scenes due to their limited observations. Instead, our method utilizes multi-timestep multiview images to reconstruct the whole scene using volumetric truncated signed distance function (TSDF) representation, making it easier to handle cluttered scenes, which are common in real-world applications.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Our method, STOPNet, addresses the problems mentioned above by â€œstoppingâ€ the production line. Specifically, assuming that the production line is moving at a constant speed, we can transform our multi-timestep multiview RGB observations to static multiview observations, which enable 3D reconstruction. After that, we tackle this problem by combining 2D and 3D, where in 3D space, we conduct scene reconstruction and wrench-collision prediction only given multiview RGB images, and in 2D space, we predict pixel-level seal and normal on original RGB input since these two attributes rely more on local object surface smoothness than global scene geometry. By conducting the 2D-3D fusion, we can obtain reliable Top-<span id="S1.p6.1.1" class="ltx_text ltx_font_italic">k</span> suction poses, which will be further executed by robot suction cups.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">To achieve generalizability and reduce the sim2real gap while saving training costs, we utilize a domain randomization-based synthetic data generation pipeline to generate a large-scale and diverse synthetic dataset containing over 300K images and 40M suction poses for our training. Combining this with other designs, such as discarding redundant textures and illuminations, extensive experiments demonstrate our methodâ€™s generalizability both in simulation and the real world.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">To summarize, our framework has many advantages over current methods on production line object suction: it is generalizable to diverse objects in the real world, achieving success rates up to 90.38% in the real world; it performs well on transparent objects without depth input, which is a challenging case in practice; it utilizes multi-timestep multiview input to conduct 3D reconstruction, thus is able to handle cluttered scenes; it is in real time and can be adapted to practical industrial production; it has a low cost of only 2 RGB cameras; and it can perform 6-DoF suction detection.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">RELATED WORK</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Transparent Object Grasping</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Grasping transparent objects is a challenging task for robotic manipulation since stereo cameras can hardly capture good-quality depth images of transparent objects. Thus recent studies on object suctionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> based on RGBD or depth images will inevitably fail on transparent objects due to their imperfect depth.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Recent years have witnessed multiple solutions to this issue. One direct way is to restore depths in advance, such as inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Some studies focus on using single-view fuzzy RGBD images to learn a grasping policyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, which cannot handle cluttered scenes due to their single-view input. There are also works focusing on taking multiview RGB as input. For example, GlassLocÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> constructs a Depth Likelihood Volume (DLV) descriptor from multiview light field observations to represent transparent object clutter scenes. GhostPoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> conducts transparent object grasping by a model-free pose estimation method based on multiview geometry. And GraspNeRFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> represents the scene geometry as the generalizable NeRF and jointly trains the NeRF and grasping detection. Similar toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, our method predicts TSDF and detects suction poses directly from multiview RGB images, thus being able to handle transparent objects.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Suction Analytic Models and Suction Detection</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Different from grasping by parallel grippers, suction cups have the advantage of high efficiency, flexibility and simplicity, thus are widely used in industrial production lines. Many studiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> have proposed suction analytic models and their evaluation. As elaborated inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, a suction pose is defined as a 3D suction point and a direction vector starting from the suction point and pointing outside of the object surface. And a suction pose can be evaluated in dimensions of seal, wrench and collision. We follow their suction analytic model in our setting.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">As to suction detection, database-based or CAD model-based suction detectionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> is one of the most commonly used methods in the industry since itâ€™s simple and efficient. However, it is not generalizable and thus cannot handle a wide variety of objects. Current learning-based methods, such asÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> are generalizable but only cater to single view static suction and need depth input, which will fail on transparent objects. Our method, instead, not only utilizes multi-timestep multiview RGB images to handle dynamic and cluttered scenes but is also generalizable to a wide variety of objects, including challenging transparent objects.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Object Picking on Production Lines</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In line with the principles of Industry 4.0Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> which aims to push for flexibility on target changes and autonomy, object picking on production lines has wide applications in autonomous industrial scenarios, thus was heavily studied in the previous decadesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Recent studies implement object recognition and suction detection mainly by CAD model database matchingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, HOG/SVMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> or morphological operatorsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, which are either non-generalizable or ineffective. By contrast, our method can both generalize to novel objects and achieve high performance, with a low cost of 2 RGB cameras.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">METHOD</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Problem Statement and Method Overview</span>
</h3>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2310.05717/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="370" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The framework of our proposed STOPNet:
(a) <span id="S3.F2.11.1" class="ltx_text ltx_font_bold">Inference Pipeline</span>: multi-timestep multiview RGB images are captured by two cameras as the input to our framework. Volumetric TSDF, wrench and collision volumes are predicted from our <span id="S3.F2.12.2" class="ltx_text ltx_font_italic">Volumetric WrcColNet</span>, while seal and normal maps are predicted from our <span id="S3.F2.13.3" class="ltx_text ltx_font_italic">2D SealNormNet</span>. We then use the grid sampling method to sample proposal suctions from predicted 2D seal maps and conduct 2D-3D fusion to obtain Top-<span id="S3.F2.14.4" class="ltx_text ltx_font_italic">k</span> suction poses for robot execution.
(b) <span id="S3.F2.15.5" class="ltx_text ltx_font_bold">Volumetric WrcColNet</span>: from RGB input we predict depth maps, from which we extract and aggregate features to construct the aggregated feature volume <math id="S3.F2.3.m1.1" class="ltx_Math" alttext="V_{a}" display="inline"><semantics id="S3.F2.3.m1.1b"><msub id="S3.F2.3.m1.1.1" xref="S3.F2.3.m1.1.1.cmml"><mi id="S3.F2.3.m1.1.1.2" xref="S3.F2.3.m1.1.1.2.cmml">V</mi><mi id="S3.F2.3.m1.1.1.3" xref="S3.F2.3.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.3.m1.1c"><apply id="S3.F2.3.m1.1.1.cmml" xref="S3.F2.3.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.3.m1.1.1.1.cmml" xref="S3.F2.3.m1.1.1">subscript</csymbol><ci id="S3.F2.3.m1.1.1.2.cmml" xref="S3.F2.3.m1.1.1.2">ğ‘‰</ci><ci id="S3.F2.3.m1.1.1.3.cmml" xref="S3.F2.3.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.3.m1.1d">V_{a}</annotation></semantics></math>. Then we predict the TSDF volume <math id="S3.F2.4.m2.1" class="ltx_Math" alttext="V_{TSDF}" display="inline"><semantics id="S3.F2.4.m2.1b"><msub id="S3.F2.4.m2.1.1" xref="S3.F2.4.m2.1.1.cmml"><mi id="S3.F2.4.m2.1.1.2" xref="S3.F2.4.m2.1.1.2.cmml">V</mi><mrow id="S3.F2.4.m2.1.1.3" xref="S3.F2.4.m2.1.1.3.cmml"><mi id="S3.F2.4.m2.1.1.3.2" xref="S3.F2.4.m2.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.F2.4.m2.1.1.3.1" xref="S3.F2.4.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.4.m2.1.1.3.3" xref="S3.F2.4.m2.1.1.3.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.F2.4.m2.1.1.3.1b" xref="S3.F2.4.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.4.m2.1.1.3.4" xref="S3.F2.4.m2.1.1.3.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.F2.4.m2.1.1.3.1c" xref="S3.F2.4.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.4.m2.1.1.3.5" xref="S3.F2.4.m2.1.1.3.5.cmml">F</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.F2.4.m2.1c"><apply id="S3.F2.4.m2.1.1.cmml" xref="S3.F2.4.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.4.m2.1.1.1.cmml" xref="S3.F2.4.m2.1.1">subscript</csymbol><ci id="S3.F2.4.m2.1.1.2.cmml" xref="S3.F2.4.m2.1.1.2">ğ‘‰</ci><apply id="S3.F2.4.m2.1.1.3.cmml" xref="S3.F2.4.m2.1.1.3"><times id="S3.F2.4.m2.1.1.3.1.cmml" xref="S3.F2.4.m2.1.1.3.1"></times><ci id="S3.F2.4.m2.1.1.3.2.cmml" xref="S3.F2.4.m2.1.1.3.2">ğ‘‡</ci><ci id="S3.F2.4.m2.1.1.3.3.cmml" xref="S3.F2.4.m2.1.1.3.3">ğ‘†</ci><ci id="S3.F2.4.m2.1.1.3.4.cmml" xref="S3.F2.4.m2.1.1.3.4">ğ·</ci><ci id="S3.F2.4.m2.1.1.3.5.cmml" xref="S3.F2.4.m2.1.1.3.5">ğ¹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.4.m2.1d">V_{TSDF}</annotation></semantics></math> and conduct volumetric wrench-collision predictions;
(c) <span id="S3.F2.16.6" class="ltx_text ltx_font_bold">2D SealNormNet</span>: from monocular RGB images, we jointly predict seal and normal maps.
</figcaption>
</figure>
<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Given a sequence of RGB images of objects on a production line, the goal of the proposed robotic system is to detect the 6-DoF suction poses and then execute the suction to remove objects on the line, as shown in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I INTRODUCTION â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The production line moves at a known fixed speed from left to right. On the left side is the reconstruction zone, where RGB images are captured by two cameras at regular timesteps. Then 3D reconstruction and suction pose detection are conducted in real time and the final suction pose at this timestep will be sent to the robot arm. When objects move into the robotâ€™s workspace on the right side, <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, the suction zone, the robot arm will execute the suction based on a position shift. The process is pipelined and repeated until there is no detected valid suction pose.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.13" class="ltx_p">After the production line is stable, for each timestep, we get the paired images of this timestep, and retrieve paired images of previous <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="N-1" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">N</mi><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">âˆ’</mo><mn id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><minus id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></minus><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ğ‘</ci><cn type="integer" id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">N-1</annotation></semantics></math> timesteps, obtaining <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">N</annotation></semantics></math> pairs of multi-timestep images in total. In this way, we formulate the 6-DoF suction detection as a learning problem that maps a set of paired RGB images from <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">N</annotation></semantics></math> timesteps, <span id="S3.SS1.p2.13.1" class="ltx_text ltx_font_italic">i.e.</span>Â <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="2N" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mn id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><times id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1"></times><cn type="integer" id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">2</cn><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">2N</annotation></semantics></math> images, <math id="S3.SS1.p2.5.m5.4" class="ltx_Math" alttext="{\{I_{i}\}}_{i=1,\dots,2N}" display="inline"><semantics id="S3.SS1.p2.5.m5.4a"><msub id="S3.SS1.p2.5.m5.4.4" xref="S3.SS1.p2.5.m5.4.4.cmml"><mrow id="S3.SS1.p2.5.m5.4.4.1.1" xref="S3.SS1.p2.5.m5.4.4.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.5.m5.4.4.1.1.2" xref="S3.SS1.p2.5.m5.4.4.1.2.cmml">{</mo><msub id="S3.SS1.p2.5.m5.4.4.1.1.1" xref="S3.SS1.p2.5.m5.4.4.1.1.1.cmml"><mi id="S3.SS1.p2.5.m5.4.4.1.1.1.2" xref="S3.SS1.p2.5.m5.4.4.1.1.1.2.cmml">I</mi><mi id="S3.SS1.p2.5.m5.4.4.1.1.1.3" xref="S3.SS1.p2.5.m5.4.4.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.p2.5.m5.4.4.1.1.3" xref="S3.SS1.p2.5.m5.4.4.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.p2.5.m5.3.3.3" xref="S3.SS1.p2.5.m5.3.3.3.cmml"><mi id="S3.SS1.p2.5.m5.3.3.3.5" xref="S3.SS1.p2.5.m5.3.3.3.5.cmml">i</mi><mo id="S3.SS1.p2.5.m5.3.3.3.4" xref="S3.SS1.p2.5.m5.3.3.3.4.cmml">=</mo><mrow id="S3.SS1.p2.5.m5.3.3.3.3.1" xref="S3.SS1.p2.5.m5.3.3.3.3.2.cmml"><mn id="S3.SS1.p2.5.m5.1.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.1.cmml">1</mn><mo id="S3.SS1.p2.5.m5.3.3.3.3.1.2" xref="S3.SS1.p2.5.m5.3.3.3.3.2.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.5.m5.2.2.2.2" xref="S3.SS1.p2.5.m5.2.2.2.2.cmml">â€¦</mi><mo id="S3.SS1.p2.5.m5.3.3.3.3.1.3" xref="S3.SS1.p2.5.m5.3.3.3.3.2.cmml">,</mo><mrow id="S3.SS1.p2.5.m5.3.3.3.3.1.1" xref="S3.SS1.p2.5.m5.3.3.3.3.1.1.cmml"><mn id="S3.SS1.p2.5.m5.3.3.3.3.1.1.2" xref="S3.SS1.p2.5.m5.3.3.3.3.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.3.3.3.3.1.1.1" xref="S3.SS1.p2.5.m5.3.3.3.3.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p2.5.m5.3.3.3.3.1.1.3" xref="S3.SS1.p2.5.m5.3.3.3.3.1.1.3.cmml">N</mi></mrow></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.4b"><apply id="S3.SS1.p2.5.m5.4.4.cmml" xref="S3.SS1.p2.5.m5.4.4"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.4.4.2.cmml" xref="S3.SS1.p2.5.m5.4.4">subscript</csymbol><set id="S3.SS1.p2.5.m5.4.4.1.2.cmml" xref="S3.SS1.p2.5.m5.4.4.1.1"><apply id="S3.SS1.p2.5.m5.4.4.1.1.1.cmml" xref="S3.SS1.p2.5.m5.4.4.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.4.4.1.1.1.1.cmml" xref="S3.SS1.p2.5.m5.4.4.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.4.4.1.1.1.2.cmml" xref="S3.SS1.p2.5.m5.4.4.1.1.1.2">ğ¼</ci><ci id="S3.SS1.p2.5.m5.4.4.1.1.1.3.cmml" xref="S3.SS1.p2.5.m5.4.4.1.1.1.3">ğ‘–</ci></apply></set><apply id="S3.SS1.p2.5.m5.3.3.3.cmml" xref="S3.SS1.p2.5.m5.3.3.3"><eq id="S3.SS1.p2.5.m5.3.3.3.4.cmml" xref="S3.SS1.p2.5.m5.3.3.3.4"></eq><ci id="S3.SS1.p2.5.m5.3.3.3.5.cmml" xref="S3.SS1.p2.5.m5.3.3.3.5">ğ‘–</ci><list id="S3.SS1.p2.5.m5.3.3.3.3.2.cmml" xref="S3.SS1.p2.5.m5.3.3.3.3.1"><cn type="integer" id="S3.SS1.p2.5.m5.1.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1.1">1</cn><ci id="S3.SS1.p2.5.m5.2.2.2.2.cmml" xref="S3.SS1.p2.5.m5.2.2.2.2">â€¦</ci><apply id="S3.SS1.p2.5.m5.3.3.3.3.1.1.cmml" xref="S3.SS1.p2.5.m5.3.3.3.3.1.1"><times id="S3.SS1.p2.5.m5.3.3.3.3.1.1.1.cmml" xref="S3.SS1.p2.5.m5.3.3.3.3.1.1.1"></times><cn type="integer" id="S3.SS1.p2.5.m5.3.3.3.3.1.1.2.cmml" xref="S3.SS1.p2.5.m5.3.3.3.3.1.1.2">2</cn><ci id="S3.SS1.p2.5.m5.3.3.3.3.1.1.3.cmml" xref="S3.SS1.p2.5.m5.3.3.3.3.1.1.3">ğ‘</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.4c">{\{I_{i}\}}_{i=1,\dots,2N}</annotation></semantics></math>, to a set of 6-DoF suction poses <math id="S3.SS1.p2.6.m6.2" class="ltx_Math" alttext="{\{S_{j}|S_{j}=(p_{j},d_{j},s_{j})\}}" display="inline"><semantics id="S3.SS1.p2.6.m6.2a"><mrow id="S3.SS1.p2.6.m6.2.2.2" xref="S3.SS1.p2.6.m6.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p2.6.m6.2.2.2.3" xref="S3.SS1.p2.6.m6.2.2.3.1.cmml">{</mo><msub id="S3.SS1.p2.6.m6.1.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.1.1.2" xref="S3.SS1.p2.6.m6.1.1.1.1.2.cmml">S</mi><mi id="S3.SS1.p2.6.m6.1.1.1.1.3" xref="S3.SS1.p2.6.m6.1.1.1.1.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p2.6.m6.2.2.2.4" xref="S3.SS1.p2.6.m6.2.2.3.1.cmml">|</mo><mrow id="S3.SS1.p2.6.m6.2.2.2.2" xref="S3.SS1.p2.6.m6.2.2.2.2.cmml"><msub id="S3.SS1.p2.6.m6.2.2.2.2.5" xref="S3.SS1.p2.6.m6.2.2.2.2.5.cmml"><mi id="S3.SS1.p2.6.m6.2.2.2.2.5.2" xref="S3.SS1.p2.6.m6.2.2.2.2.5.2.cmml">S</mi><mi id="S3.SS1.p2.6.m6.2.2.2.2.5.3" xref="S3.SS1.p2.6.m6.2.2.2.2.5.3.cmml">j</mi></msub><mo id="S3.SS1.p2.6.m6.2.2.2.2.4" xref="S3.SS1.p2.6.m6.2.2.2.2.4.cmml">=</mo><mrow id="S3.SS1.p2.6.m6.2.2.2.2.3.3" xref="S3.SS1.p2.6.m6.2.2.2.2.3.4.cmml"><mo stretchy="false" id="S3.SS1.p2.6.m6.2.2.2.2.3.3.4" xref="S3.SS1.p2.6.m6.2.2.2.2.3.4.cmml">(</mo><msub id="S3.SS1.p2.6.m6.2.2.2.2.1.1.1" xref="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.cmml"><mi id="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.2" xref="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.2.cmml">p</mi><mi id="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.3" xref="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS1.p2.6.m6.2.2.2.2.3.3.5" xref="S3.SS1.p2.6.m6.2.2.2.2.3.4.cmml">,</mo><msub id="S3.SS1.p2.6.m6.2.2.2.2.2.2.2" xref="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.cmml"><mi id="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.2" xref="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.2.cmml">d</mi><mi id="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.3" xref="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.SS1.p2.6.m6.2.2.2.2.3.3.6" xref="S3.SS1.p2.6.m6.2.2.2.2.3.4.cmml">,</mo><msub id="S3.SS1.p2.6.m6.2.2.2.2.3.3.3" xref="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.cmml"><mi id="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.2" xref="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.2.cmml">s</mi><mi id="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.3" xref="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS1.p2.6.m6.2.2.2.2.3.3.7" xref="S3.SS1.p2.6.m6.2.2.2.2.3.4.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p2.6.m6.2.2.2.5" xref="S3.SS1.p2.6.m6.2.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.2b"><apply id="S3.SS1.p2.6.m6.2.2.3.cmml" xref="S3.SS1.p2.6.m6.2.2.2"><csymbol cd="latexml" id="S3.SS1.p2.6.m6.2.2.3.1.cmml" xref="S3.SS1.p2.6.m6.2.2.2.3">conditional-set</csymbol><apply id="S3.SS1.p2.6.m6.1.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.2">ğ‘†</ci><ci id="S3.SS1.p2.6.m6.1.1.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.SS1.p2.6.m6.2.2.2.2.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2"><eq id="S3.SS1.p2.6.m6.2.2.2.2.4.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.4"></eq><apply id="S3.SS1.p2.6.m6.2.2.2.2.5.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.5"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.2.2.2.2.5.1.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.5">subscript</csymbol><ci id="S3.SS1.p2.6.m6.2.2.2.2.5.2.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.5.2">ğ‘†</ci><ci id="S3.SS1.p2.6.m6.2.2.2.2.5.3.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.5.3">ğ‘—</ci></apply><vector id="S3.SS1.p2.6.m6.2.2.2.2.3.4.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.3.3"><apply id="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.1.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.2.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.2">ğ‘</ci><ci id="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.3.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.1.1.1.3">ğ‘—</ci></apply><apply id="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.2">ğ‘‘</ci><ci id="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.2.2.2.3">ğ‘—</ci></apply><apply id="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.1.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.2.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.2">ğ‘ </ci><ci id="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.3.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.3.3.3.3">ğ‘—</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.2c">{\{S_{j}|S_{j}=(p_{j},d_{j},s_{j})\}}</annotation></semantics></math>, where, for each detected suction <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="S_{j}" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><msub id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml">S</mi><mi id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2">ğ‘†</ci><ci id="S3.SS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">S_{j}</annotation></semantics></math>, <math id="S3.SS1.p2.8.m8.1" class="ltx_Math" alttext="p_{j}\in\mathbb{R}^{3}" display="inline"><semantics id="S3.SS1.p2.8.m8.1a"><mrow id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml"><msub id="S3.SS1.p2.8.m8.1.1.2" xref="S3.SS1.p2.8.m8.1.1.2.cmml"><mi id="S3.SS1.p2.8.m8.1.1.2.2" xref="S3.SS1.p2.8.m8.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p2.8.m8.1.1.2.3" xref="S3.SS1.p2.8.m8.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS1.p2.8.m8.1.1.1" xref="S3.SS1.p2.8.m8.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.8.m8.1.1.3" xref="S3.SS1.p2.8.m8.1.1.3.cmml"><mi id="S3.SS1.p2.8.m8.1.1.3.2" xref="S3.SS1.p2.8.m8.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.8.m8.1.1.3.3" xref="S3.SS1.p2.8.m8.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><apply id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1"><in id="S3.SS1.p2.8.m8.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1.1"></in><apply id="S3.SS1.p2.8.m8.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.2.1.cmml" xref="S3.SS1.p2.8.m8.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.8.m8.1.1.2.2.cmml" xref="S3.SS1.p2.8.m8.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p2.8.m8.1.1.2.3.cmml" xref="S3.SS1.p2.8.m8.1.1.2.3">ğ‘—</ci></apply><apply id="S3.SS1.p2.8.m8.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.3.1.cmml" xref="S3.SS1.p2.8.m8.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.8.m8.1.1.3.2.cmml" xref="S3.SS1.p2.8.m8.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.8.m8.1.1.3.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">p_{j}\in\mathbb{R}^{3}</annotation></semantics></math> is the suction position, <math id="S3.SS1.p2.9.m9.1" class="ltx_Math" alttext="d_{j}\in\mathbb{R}^{3}" display="inline"><semantics id="S3.SS1.p2.9.m9.1a"><mrow id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml"><msub id="S3.SS1.p2.9.m9.1.1.2" xref="S3.SS1.p2.9.m9.1.1.2.cmml"><mi id="S3.SS1.p2.9.m9.1.1.2.2" xref="S3.SS1.p2.9.m9.1.1.2.2.cmml">d</mi><mi id="S3.SS1.p2.9.m9.1.1.2.3" xref="S3.SS1.p2.9.m9.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS1.p2.9.m9.1.1.1" xref="S3.SS1.p2.9.m9.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.9.m9.1.1.3" xref="S3.SS1.p2.9.m9.1.1.3.cmml"><mi id="S3.SS1.p2.9.m9.1.1.3.2" xref="S3.SS1.p2.9.m9.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.9.m9.1.1.3.3" xref="S3.SS1.p2.9.m9.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><apply id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1"><in id="S3.SS1.p2.9.m9.1.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1.1"></in><apply id="S3.SS1.p2.9.m9.1.1.2.cmml" xref="S3.SS1.p2.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.9.m9.1.1.2.1.cmml" xref="S3.SS1.p2.9.m9.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.9.m9.1.1.2.2.cmml" xref="S3.SS1.p2.9.m9.1.1.2.2">ğ‘‘</ci><ci id="S3.SS1.p2.9.m9.1.1.2.3.cmml" xref="S3.SS1.p2.9.m9.1.1.2.3">ğ‘—</ci></apply><apply id="S3.SS1.p2.9.m9.1.1.3.cmml" xref="S3.SS1.p2.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.9.m9.1.1.3.1.cmml" xref="S3.SS1.p2.9.m9.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.9.m9.1.1.3.2.cmml" xref="S3.SS1.p2.9.m9.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.9.m9.1.1.3.3.cmml" xref="S3.SS1.p2.9.m9.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">d_{j}\in\mathbb{R}^{3}</annotation></semantics></math> is the suction direction, and <math id="S3.SS1.p2.10.m10.2" class="ltx_Math" alttext="s_{j}\in[0,1]" display="inline"><semantics id="S3.SS1.p2.10.m10.2a"><mrow id="S3.SS1.p2.10.m10.2.3" xref="S3.SS1.p2.10.m10.2.3.cmml"><msub id="S3.SS1.p2.10.m10.2.3.2" xref="S3.SS1.p2.10.m10.2.3.2.cmml"><mi id="S3.SS1.p2.10.m10.2.3.2.2" xref="S3.SS1.p2.10.m10.2.3.2.2.cmml">s</mi><mi id="S3.SS1.p2.10.m10.2.3.2.3" xref="S3.SS1.p2.10.m10.2.3.2.3.cmml">j</mi></msub><mo id="S3.SS1.p2.10.m10.2.3.1" xref="S3.SS1.p2.10.m10.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.p2.10.m10.2.3.3.2" xref="S3.SS1.p2.10.m10.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.10.m10.2.3.3.2.1" xref="S3.SS1.p2.10.m10.2.3.3.1.cmml">[</mo><mn id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml">0</mn><mo id="S3.SS1.p2.10.m10.2.3.3.2.2" xref="S3.SS1.p2.10.m10.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p2.10.m10.2.2" xref="S3.SS1.p2.10.m10.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.p2.10.m10.2.3.3.2.3" xref="S3.SS1.p2.10.m10.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.2b"><apply id="S3.SS1.p2.10.m10.2.3.cmml" xref="S3.SS1.p2.10.m10.2.3"><in id="S3.SS1.p2.10.m10.2.3.1.cmml" xref="S3.SS1.p2.10.m10.2.3.1"></in><apply id="S3.SS1.p2.10.m10.2.3.2.cmml" xref="S3.SS1.p2.10.m10.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.10.m10.2.3.2.1.cmml" xref="S3.SS1.p2.10.m10.2.3.2">subscript</csymbol><ci id="S3.SS1.p2.10.m10.2.3.2.2.cmml" xref="S3.SS1.p2.10.m10.2.3.2.2">ğ‘ </ci><ci id="S3.SS1.p2.10.m10.2.3.2.3.cmml" xref="S3.SS1.p2.10.m10.2.3.2.3">ğ‘—</ci></apply><interval closure="closed" id="S3.SS1.p2.10.m10.2.3.3.1.cmml" xref="S3.SS1.p2.10.m10.2.3.3.2"><cn type="integer" id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1">0</cn><cn type="integer" id="S3.SS1.p2.10.m10.2.2.cmml" xref="S3.SS1.p2.10.m10.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.2c">s_{j}\in[0,1]</annotation></semantics></math> is the overall suction score, which is composed of 3 parts: seal score, wrench score and collision score, where seal score <math id="S3.SS1.p2.11.m11.2" class="ltx_Math" alttext="s_{seal}\in[0,1]" display="inline"><semantics id="S3.SS1.p2.11.m11.2a"><mrow id="S3.SS1.p2.11.m11.2.3" xref="S3.SS1.p2.11.m11.2.3.cmml"><msub id="S3.SS1.p2.11.m11.2.3.2" xref="S3.SS1.p2.11.m11.2.3.2.cmml"><mi id="S3.SS1.p2.11.m11.2.3.2.2" xref="S3.SS1.p2.11.m11.2.3.2.2.cmml">s</mi><mrow id="S3.SS1.p2.11.m11.2.3.2.3" xref="S3.SS1.p2.11.m11.2.3.2.3.cmml"><mi id="S3.SS1.p2.11.m11.2.3.2.3.2" xref="S3.SS1.p2.11.m11.2.3.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m11.2.3.2.3.1" xref="S3.SS1.p2.11.m11.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.11.m11.2.3.2.3.3" xref="S3.SS1.p2.11.m11.2.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m11.2.3.2.3.1a" xref="S3.SS1.p2.11.m11.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.11.m11.2.3.2.3.4" xref="S3.SS1.p2.11.m11.2.3.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m11.2.3.2.3.1b" xref="S3.SS1.p2.11.m11.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.11.m11.2.3.2.3.5" xref="S3.SS1.p2.11.m11.2.3.2.3.5.cmml">l</mi></mrow></msub><mo id="S3.SS1.p2.11.m11.2.3.1" xref="S3.SS1.p2.11.m11.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.p2.11.m11.2.3.3.2" xref="S3.SS1.p2.11.m11.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.11.m11.2.3.3.2.1" xref="S3.SS1.p2.11.m11.2.3.3.1.cmml">[</mo><mn id="S3.SS1.p2.11.m11.1.1" xref="S3.SS1.p2.11.m11.1.1.cmml">0</mn><mo id="S3.SS1.p2.11.m11.2.3.3.2.2" xref="S3.SS1.p2.11.m11.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p2.11.m11.2.2" xref="S3.SS1.p2.11.m11.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.p2.11.m11.2.3.3.2.3" xref="S3.SS1.p2.11.m11.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m11.2b"><apply id="S3.SS1.p2.11.m11.2.3.cmml" xref="S3.SS1.p2.11.m11.2.3"><in id="S3.SS1.p2.11.m11.2.3.1.cmml" xref="S3.SS1.p2.11.m11.2.3.1"></in><apply id="S3.SS1.p2.11.m11.2.3.2.cmml" xref="S3.SS1.p2.11.m11.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.11.m11.2.3.2.1.cmml" xref="S3.SS1.p2.11.m11.2.3.2">subscript</csymbol><ci id="S3.SS1.p2.11.m11.2.3.2.2.cmml" xref="S3.SS1.p2.11.m11.2.3.2.2">ğ‘ </ci><apply id="S3.SS1.p2.11.m11.2.3.2.3.cmml" xref="S3.SS1.p2.11.m11.2.3.2.3"><times id="S3.SS1.p2.11.m11.2.3.2.3.1.cmml" xref="S3.SS1.p2.11.m11.2.3.2.3.1"></times><ci id="S3.SS1.p2.11.m11.2.3.2.3.2.cmml" xref="S3.SS1.p2.11.m11.2.3.2.3.2">ğ‘ </ci><ci id="S3.SS1.p2.11.m11.2.3.2.3.3.cmml" xref="S3.SS1.p2.11.m11.2.3.2.3.3">ğ‘’</ci><ci id="S3.SS1.p2.11.m11.2.3.2.3.4.cmml" xref="S3.SS1.p2.11.m11.2.3.2.3.4">ğ‘</ci><ci id="S3.SS1.p2.11.m11.2.3.2.3.5.cmml" xref="S3.SS1.p2.11.m11.2.3.2.3.5">ğ‘™</ci></apply></apply><interval closure="closed" id="S3.SS1.p2.11.m11.2.3.3.1.cmml" xref="S3.SS1.p2.11.m11.2.3.3.2"><cn type="integer" id="S3.SS1.p2.11.m11.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1">0</cn><cn type="integer" id="S3.SS1.p2.11.m11.2.2.cmml" xref="S3.SS1.p2.11.m11.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m11.2c">s_{seal}\in[0,1]</annotation></semantics></math> models the seal formation of the suction cup, wrench score <math id="S3.SS1.p2.12.m12.2" class="ltx_Math" alttext="s_{wrench}\in[0,1]" display="inline"><semantics id="S3.SS1.p2.12.m12.2a"><mrow id="S3.SS1.p2.12.m12.2.3" xref="S3.SS1.p2.12.m12.2.3.cmml"><msub id="S3.SS1.p2.12.m12.2.3.2" xref="S3.SS1.p2.12.m12.2.3.2.cmml"><mi id="S3.SS1.p2.12.m12.2.3.2.2" xref="S3.SS1.p2.12.m12.2.3.2.2.cmml">s</mi><mrow id="S3.SS1.p2.12.m12.2.3.2.3" xref="S3.SS1.p2.12.m12.2.3.2.3.cmml"><mi id="S3.SS1.p2.12.m12.2.3.2.3.2" xref="S3.SS1.p2.12.m12.2.3.2.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.12.m12.2.3.2.3.1" xref="S3.SS1.p2.12.m12.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.12.m12.2.3.2.3.3" xref="S3.SS1.p2.12.m12.2.3.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.12.m12.2.3.2.3.1a" xref="S3.SS1.p2.12.m12.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.12.m12.2.3.2.3.4" xref="S3.SS1.p2.12.m12.2.3.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.12.m12.2.3.2.3.1b" xref="S3.SS1.p2.12.m12.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.12.m12.2.3.2.3.5" xref="S3.SS1.p2.12.m12.2.3.2.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.12.m12.2.3.2.3.1c" xref="S3.SS1.p2.12.m12.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.12.m12.2.3.2.3.6" xref="S3.SS1.p2.12.m12.2.3.2.3.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.12.m12.2.3.2.3.1d" xref="S3.SS1.p2.12.m12.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.12.m12.2.3.2.3.7" xref="S3.SS1.p2.12.m12.2.3.2.3.7.cmml">h</mi></mrow></msub><mo id="S3.SS1.p2.12.m12.2.3.1" xref="S3.SS1.p2.12.m12.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.p2.12.m12.2.3.3.2" xref="S3.SS1.p2.12.m12.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.12.m12.2.3.3.2.1" xref="S3.SS1.p2.12.m12.2.3.3.1.cmml">[</mo><mn id="S3.SS1.p2.12.m12.1.1" xref="S3.SS1.p2.12.m12.1.1.cmml">0</mn><mo id="S3.SS1.p2.12.m12.2.3.3.2.2" xref="S3.SS1.p2.12.m12.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p2.12.m12.2.2" xref="S3.SS1.p2.12.m12.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.p2.12.m12.2.3.3.2.3" xref="S3.SS1.p2.12.m12.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m12.2b"><apply id="S3.SS1.p2.12.m12.2.3.cmml" xref="S3.SS1.p2.12.m12.2.3"><in id="S3.SS1.p2.12.m12.2.3.1.cmml" xref="S3.SS1.p2.12.m12.2.3.1"></in><apply id="S3.SS1.p2.12.m12.2.3.2.cmml" xref="S3.SS1.p2.12.m12.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.12.m12.2.3.2.1.cmml" xref="S3.SS1.p2.12.m12.2.3.2">subscript</csymbol><ci id="S3.SS1.p2.12.m12.2.3.2.2.cmml" xref="S3.SS1.p2.12.m12.2.3.2.2">ğ‘ </ci><apply id="S3.SS1.p2.12.m12.2.3.2.3.cmml" xref="S3.SS1.p2.12.m12.2.3.2.3"><times id="S3.SS1.p2.12.m12.2.3.2.3.1.cmml" xref="S3.SS1.p2.12.m12.2.3.2.3.1"></times><ci id="S3.SS1.p2.12.m12.2.3.2.3.2.cmml" xref="S3.SS1.p2.12.m12.2.3.2.3.2">ğ‘¤</ci><ci id="S3.SS1.p2.12.m12.2.3.2.3.3.cmml" xref="S3.SS1.p2.12.m12.2.3.2.3.3">ğ‘Ÿ</ci><ci id="S3.SS1.p2.12.m12.2.3.2.3.4.cmml" xref="S3.SS1.p2.12.m12.2.3.2.3.4">ğ‘’</ci><ci id="S3.SS1.p2.12.m12.2.3.2.3.5.cmml" xref="S3.SS1.p2.12.m12.2.3.2.3.5">ğ‘›</ci><ci id="S3.SS1.p2.12.m12.2.3.2.3.6.cmml" xref="S3.SS1.p2.12.m12.2.3.2.3.6">ğ‘</ci><ci id="S3.SS1.p2.12.m12.2.3.2.3.7.cmml" xref="S3.SS1.p2.12.m12.2.3.2.3.7">â„</ci></apply></apply><interval closure="closed" id="S3.SS1.p2.12.m12.2.3.3.1.cmml" xref="S3.SS1.p2.12.m12.2.3.3.2"><cn type="integer" id="S3.SS1.p2.12.m12.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1">0</cn><cn type="integer" id="S3.SS1.p2.12.m12.2.2.cmml" xref="S3.SS1.p2.12.m12.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m12.2c">s_{wrench}\in[0,1]</annotation></semantics></math> models the resistency to the wrench caused by gravity, and the binary collision score <math id="S3.SS1.p2.13.m13.2" class="ltx_Math" alttext="s_{collision}\in\{0,1\}" display="inline"><semantics id="S3.SS1.p2.13.m13.2a"><mrow id="S3.SS1.p2.13.m13.2.3" xref="S3.SS1.p2.13.m13.2.3.cmml"><msub id="S3.SS1.p2.13.m13.2.3.2" xref="S3.SS1.p2.13.m13.2.3.2.cmml"><mi id="S3.SS1.p2.13.m13.2.3.2.2" xref="S3.SS1.p2.13.m13.2.3.2.2.cmml">s</mi><mrow id="S3.SS1.p2.13.m13.2.3.2.3" xref="S3.SS1.p2.13.m13.2.3.2.3.cmml"><mi id="S3.SS1.p2.13.m13.2.3.2.3.2" xref="S3.SS1.p2.13.m13.2.3.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.13.m13.2.3.2.3.1" xref="S3.SS1.p2.13.m13.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.13.m13.2.3.2.3.3" xref="S3.SS1.p2.13.m13.2.3.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.13.m13.2.3.2.3.1a" xref="S3.SS1.p2.13.m13.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.13.m13.2.3.2.3.4" xref="S3.SS1.p2.13.m13.2.3.2.3.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.13.m13.2.3.2.3.1b" xref="S3.SS1.p2.13.m13.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.13.m13.2.3.2.3.5" xref="S3.SS1.p2.13.m13.2.3.2.3.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.13.m13.2.3.2.3.1c" xref="S3.SS1.p2.13.m13.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.13.m13.2.3.2.3.6" xref="S3.SS1.p2.13.m13.2.3.2.3.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.13.m13.2.3.2.3.1d" xref="S3.SS1.p2.13.m13.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.13.m13.2.3.2.3.7" xref="S3.SS1.p2.13.m13.2.3.2.3.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.13.m13.2.3.2.3.1e" xref="S3.SS1.p2.13.m13.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.13.m13.2.3.2.3.8" xref="S3.SS1.p2.13.m13.2.3.2.3.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.13.m13.2.3.2.3.1f" xref="S3.SS1.p2.13.m13.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.13.m13.2.3.2.3.9" xref="S3.SS1.p2.13.m13.2.3.2.3.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.13.m13.2.3.2.3.1g" xref="S3.SS1.p2.13.m13.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.13.m13.2.3.2.3.10" xref="S3.SS1.p2.13.m13.2.3.2.3.10.cmml">n</mi></mrow></msub><mo id="S3.SS1.p2.13.m13.2.3.1" xref="S3.SS1.p2.13.m13.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.p2.13.m13.2.3.3.2" xref="S3.SS1.p2.13.m13.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.13.m13.2.3.3.2.1" xref="S3.SS1.p2.13.m13.2.3.3.1.cmml">{</mo><mn id="S3.SS1.p2.13.m13.1.1" xref="S3.SS1.p2.13.m13.1.1.cmml">0</mn><mo id="S3.SS1.p2.13.m13.2.3.3.2.2" xref="S3.SS1.p2.13.m13.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p2.13.m13.2.2" xref="S3.SS1.p2.13.m13.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.p2.13.m13.2.3.3.2.3" xref="S3.SS1.p2.13.m13.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m13.2b"><apply id="S3.SS1.p2.13.m13.2.3.cmml" xref="S3.SS1.p2.13.m13.2.3"><in id="S3.SS1.p2.13.m13.2.3.1.cmml" xref="S3.SS1.p2.13.m13.2.3.1"></in><apply id="S3.SS1.p2.13.m13.2.3.2.cmml" xref="S3.SS1.p2.13.m13.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.2.3.2.1.cmml" xref="S3.SS1.p2.13.m13.2.3.2">subscript</csymbol><ci id="S3.SS1.p2.13.m13.2.3.2.2.cmml" xref="S3.SS1.p2.13.m13.2.3.2.2">ğ‘ </ci><apply id="S3.SS1.p2.13.m13.2.3.2.3.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3"><times id="S3.SS1.p2.13.m13.2.3.2.3.1.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.1"></times><ci id="S3.SS1.p2.13.m13.2.3.2.3.2.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.2">ğ‘</ci><ci id="S3.SS1.p2.13.m13.2.3.2.3.3.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.3">ğ‘œ</ci><ci id="S3.SS1.p2.13.m13.2.3.2.3.4.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.4">ğ‘™</ci><ci id="S3.SS1.p2.13.m13.2.3.2.3.5.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.5">ğ‘™</ci><ci id="S3.SS1.p2.13.m13.2.3.2.3.6.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.6">ğ‘–</ci><ci id="S3.SS1.p2.13.m13.2.3.2.3.7.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.7">ğ‘ </ci><ci id="S3.SS1.p2.13.m13.2.3.2.3.8.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.8">ğ‘–</ci><ci id="S3.SS1.p2.13.m13.2.3.2.3.9.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.9">ğ‘œ</ci><ci id="S3.SS1.p2.13.m13.2.3.2.3.10.cmml" xref="S3.SS1.p2.13.m13.2.3.2.3.10">ğ‘›</ci></apply></apply><set id="S3.SS1.p2.13.m13.2.3.3.1.cmml" xref="S3.SS1.p2.13.m13.2.3.3.2"><cn type="integer" id="S3.SS1.p2.13.m13.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1">0</cn><cn type="integer" id="S3.SS1.p2.13.m13.2.2.cmml" xref="S3.SS1.p2.13.m13.2.2">1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.13.m13.2c">s_{collision}\in\{0,1\}</annotation></semantics></math> denotes whether a suction pose is in collision with other objects in the scene. The overall score for a suction pose is then computed by:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="s_{j}=s_{seal}\times s_{wrench}\times s_{collision}" display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><msub id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.2.2" xref="S3.E1.m1.1.1.2.2.cmml">s</mi><mi id="S3.E1.m1.1.1.2.3" xref="S3.E1.m1.1.1.2.3.cmml">j</mi></msub><mo id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><msub id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.3.2.2" xref="S3.E1.m1.1.1.3.2.2.cmml">s</mi><mrow id="S3.E1.m1.1.1.3.2.3" xref="S3.E1.m1.1.1.3.2.3.cmml"><mi id="S3.E1.m1.1.1.3.2.3.2" xref="S3.E1.m1.1.1.3.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.2.3.1" xref="S3.E1.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.2.3.3" xref="S3.E1.m1.1.1.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.2.3.1a" xref="S3.E1.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.2.3.4" xref="S3.E1.m1.1.1.3.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.2.3.1b" xref="S3.E1.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.2.3.5" xref="S3.E1.m1.1.1.3.2.3.5.cmml">l</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.3.1" xref="S3.E1.m1.1.1.3.1.cmml">Ã—</mo><msub id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.3.3.2" xref="S3.E1.m1.1.1.3.3.2.cmml">s</mi><mrow id="S3.E1.m1.1.1.3.3.3" xref="S3.E1.m1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.1.1.3.3.3.2" xref="S3.E1.m1.1.1.3.3.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.3.3.1" xref="S3.E1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.3.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.3.3.1a" xref="S3.E1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.3.3.4" xref="S3.E1.m1.1.1.3.3.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.3.3.1b" xref="S3.E1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.3.3.5" xref="S3.E1.m1.1.1.3.3.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.3.3.1c" xref="S3.E1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.3.3.6" xref="S3.E1.m1.1.1.3.3.3.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.3.3.1d" xref="S3.E1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.3.3.7" xref="S3.E1.m1.1.1.3.3.3.7.cmml">h</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.3.1a" xref="S3.E1.m1.1.1.3.1.cmml">Ã—</mo><msub id="S3.E1.m1.1.1.3.4" xref="S3.E1.m1.1.1.3.4.cmml"><mi id="S3.E1.m1.1.1.3.4.2" xref="S3.E1.m1.1.1.3.4.2.cmml">s</mi><mrow id="S3.E1.m1.1.1.3.4.3" xref="S3.E1.m1.1.1.3.4.3.cmml"><mi id="S3.E1.m1.1.1.3.4.3.2" xref="S3.E1.m1.1.1.3.4.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.4.3.1" xref="S3.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.4.3.3" xref="S3.E1.m1.1.1.3.4.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.4.3.1a" xref="S3.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.4.3.4" xref="S3.E1.m1.1.1.3.4.3.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.4.3.1b" xref="S3.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.4.3.5" xref="S3.E1.m1.1.1.3.4.3.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.4.3.1c" xref="S3.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.4.3.6" xref="S3.E1.m1.1.1.3.4.3.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.4.3.1d" xref="S3.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.4.3.7" xref="S3.E1.m1.1.1.3.4.3.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.4.3.1e" xref="S3.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.4.3.8" xref="S3.E1.m1.1.1.3.4.3.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.4.3.1f" xref="S3.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.4.3.9" xref="S3.E1.m1.1.1.3.4.3.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.4.3.1g" xref="S3.E1.m1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.4.3.10" xref="S3.E1.m1.1.1.3.4.3.10.cmml">n</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"></eq><apply id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.2.2">ğ‘ </ci><ci id="S3.E1.m1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.2.3">ğ‘—</ci></apply><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><times id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3.1"></times><apply id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2">ğ‘ </ci><apply id="S3.E1.m1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.3.2.3"><times id="S3.E1.m1.1.1.3.2.3.1.cmml" xref="S3.E1.m1.1.1.3.2.3.1"></times><ci id="S3.E1.m1.1.1.3.2.3.2.cmml" xref="S3.E1.m1.1.1.3.2.3.2">ğ‘ </ci><ci id="S3.E1.m1.1.1.3.2.3.3.cmml" xref="S3.E1.m1.1.1.3.2.3.3">ğ‘’</ci><ci id="S3.E1.m1.1.1.3.2.3.4.cmml" xref="S3.E1.m1.1.1.3.2.3.4">ğ‘</ci><ci id="S3.E1.m1.1.1.3.2.3.5.cmml" xref="S3.E1.m1.1.1.3.2.3.5">ğ‘™</ci></apply></apply><apply id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.2">ğ‘ </ci><apply id="S3.E1.m1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3"><times id="S3.E1.m1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3.3.1"></times><ci id="S3.E1.m1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.3.2">ğ‘¤</ci><ci id="S3.E1.m1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3.3">ğ‘Ÿ</ci><ci id="S3.E1.m1.1.1.3.3.3.4.cmml" xref="S3.E1.m1.1.1.3.3.3.4">ğ‘’</ci><ci id="S3.E1.m1.1.1.3.3.3.5.cmml" xref="S3.E1.m1.1.1.3.3.3.5">ğ‘›</ci><ci id="S3.E1.m1.1.1.3.3.3.6.cmml" xref="S3.E1.m1.1.1.3.3.3.6">ğ‘</ci><ci id="S3.E1.m1.1.1.3.3.3.7.cmml" xref="S3.E1.m1.1.1.3.3.3.7">â„</ci></apply></apply><apply id="S3.E1.m1.1.1.3.4.cmml" xref="S3.E1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.4.1.cmml" xref="S3.E1.m1.1.1.3.4">subscript</csymbol><ci id="S3.E1.m1.1.1.3.4.2.cmml" xref="S3.E1.m1.1.1.3.4.2">ğ‘ </ci><apply id="S3.E1.m1.1.1.3.4.3.cmml" xref="S3.E1.m1.1.1.3.4.3"><times id="S3.E1.m1.1.1.3.4.3.1.cmml" xref="S3.E1.m1.1.1.3.4.3.1"></times><ci id="S3.E1.m1.1.1.3.4.3.2.cmml" xref="S3.E1.m1.1.1.3.4.3.2">ğ‘</ci><ci id="S3.E1.m1.1.1.3.4.3.3.cmml" xref="S3.E1.m1.1.1.3.4.3.3">ğ‘œ</ci><ci id="S3.E1.m1.1.1.3.4.3.4.cmml" xref="S3.E1.m1.1.1.3.4.3.4">ğ‘™</ci><ci id="S3.E1.m1.1.1.3.4.3.5.cmml" xref="S3.E1.m1.1.1.3.4.3.5">ğ‘™</ci><ci id="S3.E1.m1.1.1.3.4.3.6.cmml" xref="S3.E1.m1.1.1.3.4.3.6">ğ‘–</ci><ci id="S3.E1.m1.1.1.3.4.3.7.cmml" xref="S3.E1.m1.1.1.3.4.3.7">ğ‘ </ci><ci id="S3.E1.m1.1.1.3.4.3.8.cmml" xref="S3.E1.m1.1.1.3.4.3.8">ğ‘–</ci><ci id="S3.E1.m1.1.1.3.4.3.9.cmml" xref="S3.E1.m1.1.1.3.4.3.9">ğ‘œ</ci><ci id="S3.E1.m1.1.1.3.4.3.10.cmml" xref="S3.E1.m1.1.1.3.4.3.10">ğ‘›</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">s_{j}=s_{seal}\times s_{wrench}\times s_{collision}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Given that the production line is moving at a fixed and known speed, we can transform the observed multi-timestep multiview images into static multiview images. This is because we can consider the objects to be stationary and the cameras to be moving, as illustrated in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I INTRODUCTION â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. It allows us to calculate the transformed camera extrinsics of each timestep based on the production lineâ€™s speed and original camera calibration. We can then use these images, along with the transformed camera extrinsics, to perform 3D reconstruction and suction pose detection.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">Our proposed framework is composed of two branches, <span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_italic">Volumetric WrcColNet</span> and <span id="S3.SS1.p4.1.2" class="ltx_text ltx_font_italic">2D SealNormNet</span>, as illustrated in Fig.Â <a href="#S3.F2" title="Figure 2 â€£ III-A Problem Statement and Method Overview â€£ III METHOD â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. For each timestep, in <span id="S3.SS1.p4.1.3" class="ltx_text ltx_font_italic">Volumetric WrcColNet</span>, we leverage our <span id="S3.SS1.p4.1.4" class="ltx_text ltx_font_italic">DPT-Depth Module</span> to conduct monocular depth estimation on separate RGB inputs and feed depth predictions into a multiview <span id="S3.SS1.p4.1.5" class="ltx_text ltx_font_italic">Scene Geometry Reconstruction Module</span> to output volumetric TSDF of the reconstruction zone. Taking TSDF as input, the following <span id="S3.SS1.p4.1.6" class="ltx_text ltx_font_italic">Volumetric Suction Module</span> learns to predict grid-level wrench scores and collision scores of the whole scene. In <span id="S3.SS1.p4.1.7" class="ltx_text ltx_font_italic">2D SealNormNet</span>, we take RGB images as input to jointly predict pixel-level seal scores and surface normals. The two branches are separately trained and fused together at inference time to output the Top-<span id="S3.SS1.p4.1.8" class="ltx_text ltx_font_italic">k</span> suction poses for each timestep.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Volumetric WrcColNet: Scene Reconstruction and Wrench-Collision Prediction</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To better detect suction poses on a moving production line, it is crucial to wholly and accurately reconstruct the scene geometry in a generalizable way. Therefore our proposed <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">Volumetric WrcColNet</span>, which is composed of <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">DPT-Depth Module</span>, <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_italic">Scene Geometry Reconstruction Module</span> and <span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_italic">Volumetric Suction Module</span>, utilizes multi-timestep multiview images to reconstruct the whole 3D scene to learn better suction detection. All the modules above are jointly trained in a fully end-to-end manner.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.5.1.1" class="ltx_text">III-B</span>1 </span>DPT-Depth Module</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Since real-world data are expensive and labor intensive, it is more common to get training data from simulation environments, thus the sim2real gap is an inevitable issue to tackle. Under these circumstances, we propose to first learn a module to unify synthetic data and real data into the depth domain.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p">Dense Prediction Transformers, <span id="S3.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_italic">i.e.</span>Â DPTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> is a large-scale vision transformer that can be applied to many dense image-to-image prediction tasks, such as semantic segmentation, monocular depth estimation, <span id="S3.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_italic">etc</span>. DPTâ€™s network architecture contains an encoder that is composed of a series of embedding layers, transformer blocks, reassemble layers and fusion layers to encode the RGB input into dense image feature maps, and a convolutional decoder network to output dense prediction results of the same resolution as input.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.3" class="ltx_p">Specifically, we leverage a DPT model pretrained on <span id="S3.SS2.SSS1.p3.3.2" class="ltx_text ltx_font_italic">MIX 6</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, a large-scale real-world monocular depth estimation dataset containing about 1.4 million images, and finetune it in our setting. Therefore the network inherits the abundant real-world knowledge in advance and thus better generalizes to the real world. Taking multi-timestep RGB observations <math id="S3.SS2.SSS1.p3.1.m1.1" class="ltx_Math" alttext="\{I_{i}\}" display="inline"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><mrow id="S3.SS2.SSS1.p3.1.m1.1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p3.1.m1.1.1.1.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml">{</mo><msub id="S3.SS2.SSS1.p3.1.m1.1.1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.2.cmml">I</mi><mi id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.SSS1.p3.1.m1.1.1.1.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><set id="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1"><apply id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.2">ğ¼</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.3">ğ‘–</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">\{I_{i}\}</annotation></semantics></math> as input, the module outputs depth map predictions <math id="S3.SS2.SSS1.p3.2.m2.1" class="ltx_Math" alttext="\{D_{i}\}" display="inline"><semantics id="S3.SS2.SSS1.p3.2.m2.1a"><mrow id="S3.SS2.SSS1.p3.2.m2.1.1.1" xref="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p3.2.m2.1.1.1.2" xref="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml">{</mo><msub id="S3.SS2.SSS1.p3.2.m2.1.1.1.1" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.2.m2.1.1.1.1.2" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.1.2.cmml">D</mi><mi id="S3.SS2.SSS1.p3.2.m2.1.1.1.1.3" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.SSS1.p3.2.m2.1.1.1.3" xref="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.2.m2.1b"><set id="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.1"><apply id="S3.SS2.SSS1.p3.2.m2.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p3.2.m2.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.1.2">ğ·</ci><ci id="S3.SS2.SSS1.p3.2.m2.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.1.3">ğ‘–</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.2.m2.1c">\{D_{i}\}</annotation></semantics></math> for 3D reconstruction. In this way we discard redundant textures and illuminations from input and unify input domains into the depth domain, which helps to bridge the sim2real gap. To supervise the <span id="S3.SS2.SSS1.p3.3.3" class="ltx_text ltx_font_italic">DPT-Depth Module</span>, an L1 pixel-level <span id="S3.SS2.SSS1.p3.3.1" class="ltx_text ltx_font_bold">Depth Loss <math id="S3.SS2.SSS1.p3.3.1.m1.1" class="ltx_Math" alttext="L_{d}" display="inline"><semantics id="S3.SS2.SSS1.p3.3.1.m1.1a"><msub id="S3.SS2.SSS1.p3.3.1.m1.1.1" xref="S3.SS2.SSS1.p3.3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.3.1.m1.1.1.2" xref="S3.SS2.SSS1.p3.3.1.m1.1.1.2.cmml">L</mi><mi id="S3.SS2.SSS1.p3.3.1.m1.1.1.3" xref="S3.SS2.SSS1.p3.3.1.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.3.1.m1.1b"><apply id="S3.SS2.SSS1.p3.3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p3.3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.3.1.m1.1.1.2">ğ¿</ci><ci id="S3.SS2.SSS1.p3.3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.3.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.3.1.m1.1c">L_{d}</annotation></semantics></math></span> is utilized to directly supervise depth estimations.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.5.1.1" class="ltx_text">III-B</span>2 </span>Scene Geometry Reconstruction Module</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.6" class="ltx_p">Inspired byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, first we propose a <span id="S3.SS2.SSS2.p1.6.1" class="ltx_text ltx_font_italic">Multiview Feature Extraction and Aggregation Network</span> to encode the depth predictions into a volumetric representation. To be specific, we divide our 3D reconstruction zone into grids of size <math id="S3.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mi id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><ci id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">ğ‘‹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">X</annotation></semantics></math>, <math id="S3.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><mi id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><ci id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">Y</annotation></semantics></math> and <math id="S3.SS2.SSS2.p1.3.m3.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S3.SS2.SSS2.p1.3.m3.1a"><mi id="S3.SS2.SSS2.p1.3.m3.1.1" xref="S3.SS2.SSS2.p1.3.m3.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.3.m3.1b"><ci id="S3.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.3.m3.1c">Z</annotation></semantics></math> and utilize a CNN encoder to extract input depth prediction feature maps. Each grid point <math id="S3.SS2.SSS2.p1.4.m4.1" class="ltx_Math" alttext="x\in\mathbb{R}^{XYZ}" display="inline"><semantics id="S3.SS2.SSS2.p1.4.m4.1a"><mrow id="S3.SS2.SSS2.p1.4.m4.1.1" xref="S3.SS2.SSS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS2.p1.4.m4.1.1.2" xref="S3.SS2.SSS2.p1.4.m4.1.1.2.cmml">x</mi><mo id="S3.SS2.SSS2.p1.4.m4.1.1.1" xref="S3.SS2.SSS2.p1.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.SSS2.p1.4.m4.1.1.3" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.cmml"><mi id="S3.SS2.SSS2.p1.4.m4.1.1.3.2" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.SSS2.p1.4.m4.1.1.3.3" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.cmml"><mi id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.2" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.1" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.3" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.3.cmml">Y</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.1a" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.4" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.4.cmml">Z</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.4.m4.1b"><apply id="S3.SS2.SSS2.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1"><in id="S3.SS2.SSS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.1"></in><ci id="S3.SS2.SSS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.2">ğ‘¥</ci><apply id="S3.SS2.SSS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.4.m4.1.1.3.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS2.p1.4.m4.1.1.3.2.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.2">â„</ci><apply id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3"><times id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.1"></times><ci id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.2">ğ‘‹</ci><ci id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.3">ğ‘Œ</ci><ci id="S3.SS2.SSS2.p1.4.m4.1.1.3.3.4.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.3.4">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.4.m4.1c">x\in\mathbb{R}^{XYZ}</annotation></semantics></math> is then projected to the <math id="S3.SS2.SSS2.p1.5.m5.1" class="ltx_Math" alttext="2N" display="inline"><semantics id="S3.SS2.SSS2.p1.5.m5.1a"><mrow id="S3.SS2.SSS2.p1.5.m5.1.1" xref="S3.SS2.SSS2.p1.5.m5.1.1.cmml"><mn id="S3.SS2.SSS2.p1.5.m5.1.1.2" xref="S3.SS2.SSS2.p1.5.m5.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p1.5.m5.1.1.1" xref="S3.SS2.SSS2.p1.5.m5.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p1.5.m5.1.1.3" xref="S3.SS2.SSS2.p1.5.m5.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.5.m5.1b"><apply id="S3.SS2.SSS2.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1"><times id="S3.SS2.SSS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.1"></times><cn type="integer" id="S3.SS2.SSS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.2">2</cn><ci id="S3.SS2.SSS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.5.m5.1c">2N</annotation></semantics></math> depth feature maps and queries the corresponding features, which are then aggregated among views using MLPs to form an aggregated feature volume <math id="S3.SS2.SSS2.p1.6.m6.1" class="ltx_Math" alttext="V_{a}\in\mathbb{R}^{XYZ\times C}" display="inline"><semantics id="S3.SS2.SSS2.p1.6.m6.1a"><mrow id="S3.SS2.SSS2.p1.6.m6.1.1" xref="S3.SS2.SSS2.p1.6.m6.1.1.cmml"><msub id="S3.SS2.SSS2.p1.6.m6.1.1.2" xref="S3.SS2.SSS2.p1.6.m6.1.1.2.cmml"><mi id="S3.SS2.SSS2.p1.6.m6.1.1.2.2" xref="S3.SS2.SSS2.p1.6.m6.1.1.2.2.cmml">V</mi><mi id="S3.SS2.SSS2.p1.6.m6.1.1.2.3" xref="S3.SS2.SSS2.p1.6.m6.1.1.2.3.cmml">a</mi></msub><mo id="S3.SS2.SSS2.p1.6.m6.1.1.1" xref="S3.SS2.SSS2.p1.6.m6.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.SSS2.p1.6.m6.1.1.3" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.cmml"><mi id="S3.SS2.SSS2.p1.6.m6.1.1.3.2" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.SSS2.p1.6.m6.1.1.3.3" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.cmml"><mrow id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.cmml"><mi id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.2" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.1" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.3" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.3.cmml">Y</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.1a" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.4" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.4.cmml">Z</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.1" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.3" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.6.m6.1b"><apply id="S3.SS2.SSS2.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1"><in id="S3.SS2.SSS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.1"></in><apply id="S3.SS2.SSS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.6.m6.1.1.2.1.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS2.p1.6.m6.1.1.2.2.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.2.2">ğ‘‰</ci><ci id="S3.SS2.SSS2.p1.6.m6.1.1.2.3.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.SSS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.6.m6.1.1.3.1.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS2.p1.6.m6.1.1.3.2.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.2">â„</ci><apply id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3"><times id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.1.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.1"></times><apply id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2"><times id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.1.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.1"></times><ci id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.2.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.2">ğ‘‹</ci><ci id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.3.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.3">ğ‘Œ</ci><ci id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.4.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.2.4">ğ‘</ci></apply><ci id="S3.SS2.SSS2.p1.6.m6.1.1.3.3.3.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.3.3">ğ¶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.6.m6.1c">V_{a}\in\mathbb{R}^{XYZ\times C}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.4" class="ltx_p">After obtaining aggregated feature volume <math id="S3.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="V_{a}" display="inline"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><msub id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p2.1.m1.1.1.2" xref="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml">V</mi><mi id="S3.SS2.SSS2.p2.1.m1.1.1.3" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><apply id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.2">ğ‘‰</ci><ci id="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">V_{a}</annotation></semantics></math>, similar toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> andÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, we propose a <span id="S3.SS2.SSS2.p2.4.2" class="ltx_text ltx_font_italic">TSDF Prediction Network</span> to predict volumetric TSDF <math id="S3.SS2.SSS2.p2.2.m2.2" class="ltx_Math" alttext="V_{TSDF}\in[-1,1]^{XYZ}" display="inline"><semantics id="S3.SS2.SSS2.p2.2.m2.2a"><mrow id="S3.SS2.SSS2.p2.2.m2.2.2" xref="S3.SS2.SSS2.p2.2.m2.2.2.cmml"><msub id="S3.SS2.SSS2.p2.2.m2.2.2.3" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.cmml"><mi id="S3.SS2.SSS2.p2.2.m2.2.2.3.2" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.2.cmml">V</mi><mrow id="S3.SS2.SSS2.p2.2.m2.2.2.3.3" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.cmml"><mi id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.2" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.1" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.3" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.1a" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.4" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.1b" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.5" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.5.cmml">F</mi></mrow></msub><mo id="S3.SS2.SSS2.p2.2.m2.2.2.2" xref="S3.SS2.SSS2.p2.2.m2.2.2.2.cmml">âˆˆ</mo><msup id="S3.SS2.SSS2.p2.2.m2.2.2.1" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.cmml"><mrow id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.2" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.2.cmml">[</mo><mrow id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1.cmml"><mo id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1a" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1.cmml">âˆ’</mo><mn id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1.2" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1.2.cmml">1</mn></mrow><mo id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.3" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.2.cmml">,</mo><mn id="S3.SS2.SSS2.p2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml">1</mn><mo stretchy="false" id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.4" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.2.cmml">]</mo></mrow><mrow id="S3.SS2.SSS2.p2.2.m2.2.2.1.3" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.cmml"><mi id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.2" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.1" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.3" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.3.cmml">Y</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.1a" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.4" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.4.cmml">Z</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.2b"><apply id="S3.SS2.SSS2.p2.2.m2.2.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2"><in id="S3.SS2.SSS2.p2.2.m2.2.2.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.2"></in><apply id="S3.SS2.SSS2.p2.2.m2.2.2.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.2.m2.2.2.3.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.3">subscript</csymbol><ci id="S3.SS2.SSS2.p2.2.m2.2.2.3.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.2">ğ‘‰</ci><apply id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3"><times id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.1"></times><ci id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.2">ğ‘‡</ci><ci id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.3">ğ‘†</ci><ci id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.4.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.4">ğ·</ci><ci id="S3.SS2.SSS2.p2.2.m2.2.2.3.3.5.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.3.3.5">ğ¹</ci></apply></apply><apply id="S3.SS2.SSS2.p2.2.m2.2.2.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.2.m2.2.2.1.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1">superscript</csymbol><interval closure="closed" id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1"><apply id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1"><minus id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1"></minus><cn type="integer" id="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.1.1.1.2">1</cn></apply><cn type="integer" id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1">1</cn></interval><apply id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3"><times id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.1"></times><ci id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.2">ğ‘‹</ci><ci id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.3">ğ‘Œ</ci><ci id="S3.SS2.SSS2.p2.2.m2.2.2.1.3.4.cmml" xref="S3.SS2.SSS2.p2.2.m2.2.2.1.3.4">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.2c">V_{TSDF}\in[-1,1]^{XYZ}</annotation></semantics></math> from <math id="S3.SS2.SSS2.p2.3.m3.1" class="ltx_Math" alttext="V_{a}" display="inline"><semantics id="S3.SS2.SSS2.p2.3.m3.1a"><msub id="S3.SS2.SSS2.p2.3.m3.1.1" xref="S3.SS2.SSS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p2.3.m3.1.1.2" xref="S3.SS2.SSS2.p2.3.m3.1.1.2.cmml">V</mi><mi id="S3.SS2.SSS2.p2.3.m3.1.1.3" xref="S3.SS2.SSS2.p2.3.m3.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.3.m3.1b"><apply id="S3.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1.2">ğ‘‰</ci><ci id="S3.SS2.SSS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.3.m3.1c">V_{a}</annotation></semantics></math>, supervised by a L1 <span id="S3.SS2.SSS2.p2.4.1" class="ltx_text ltx_font_bold">TSDF Geometry Loss <math id="S3.SS2.SSS2.p2.4.1.m1.1" class="ltx_Math" alttext="L_{g}" display="inline"><semantics id="S3.SS2.SSS2.p2.4.1.m1.1a"><msub id="S3.SS2.SSS2.p2.4.1.m1.1.1" xref="S3.SS2.SSS2.p2.4.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p2.4.1.m1.1.1.2" xref="S3.SS2.SSS2.p2.4.1.m1.1.1.2.cmml">L</mi><mi id="S3.SS2.SSS2.p2.4.1.m1.1.1.3" xref="S3.SS2.SSS2.p2.4.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.4.1.m1.1b"><apply id="S3.SS2.SSS2.p2.4.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p2.4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.4.1.m1.1.1.2">ğ¿</ci><ci id="S3.SS2.SSS2.p2.4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p2.4.1.m1.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.4.1.m1.1c">L_{g}</annotation></semantics></math></span>.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS3.5.1.1" class="ltx_text">III-B</span>3 </span>Volumetric Suction Module</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.4" class="ltx_p">Motivated byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, taking predicted TSDF as input, we propose a 3D CNN encoder-decoder <span id="S3.SS2.SSS3.p1.4.1" class="ltx_text ltx_font_italic">Wrench and Collision Prediction Network</span> to predict volumetric wrench scores <math id="S3.SS2.SSS3.p1.1.m1.2" class="ltx_Math" alttext="W\in[0,1]^{XYZ}" display="inline"><semantics id="S3.SS2.SSS3.p1.1.m1.2a"><mrow id="S3.SS2.SSS3.p1.1.m1.2.3" xref="S3.SS2.SSS3.p1.1.m1.2.3.cmml"><mi id="S3.SS2.SSS3.p1.1.m1.2.3.2" xref="S3.SS2.SSS3.p1.1.m1.2.3.2.cmml">W</mi><mo id="S3.SS2.SSS3.p1.1.m1.2.3.1" xref="S3.SS2.SSS3.p1.1.m1.2.3.1.cmml">âˆˆ</mo><msup id="S3.SS2.SSS3.p1.1.m1.2.3.3" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.cmml"><mrow id="S3.SS2.SSS3.p1.1.m1.2.3.3.2.2" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS3.p1.1.m1.2.3.3.2.2.1" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.2.1.cmml">[</mo><mn id="S3.SS2.SSS3.p1.1.m1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.cmml">0</mn><mo id="S3.SS2.SSS3.p1.1.m1.2.3.3.2.2.2" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.2.1.cmml">,</mo><mn id="S3.SS2.SSS3.p1.1.m1.2.2" xref="S3.SS2.SSS3.p1.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS2.SSS3.p1.1.m1.2.3.3.2.2.3" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.2.1.cmml">]</mo></mrow><mrow id="S3.SS2.SSS3.p1.1.m1.2.3.3.3" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.cmml"><mi id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.2" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.1" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.3" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.3.cmml">Y</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.1a" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.4" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.4.cmml">Z</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.1.m1.2b"><apply id="S3.SS2.SSS3.p1.1.m1.2.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3"><in id="S3.SS2.SSS3.p1.1.m1.2.3.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.1"></in><ci id="S3.SS2.SSS3.p1.1.m1.2.3.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.2">ğ‘Š</ci><apply id="S3.SS2.SSS3.p1.1.m1.2.3.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.1.m1.2.3.3.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.3">superscript</csymbol><interval closure="closed" id="S3.SS2.SSS3.p1.1.m1.2.3.3.2.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.2.2"><cn type="integer" id="S3.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1">0</cn><cn type="integer" id="S3.SS2.SSS3.p1.1.m1.2.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.2">1</cn></interval><apply id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3"><times id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.1"></times><ci id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.2">ğ‘‹</ci><ci id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.3">ğ‘Œ</ci><ci id="S3.SS2.SSS3.p1.1.m1.2.3.3.3.4.cmml" xref="S3.SS2.SSS3.p1.1.m1.2.3.3.3.4">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.1.m1.2c">W\in[0,1]^{XYZ}</annotation></semantics></math> and collision scores <math id="S3.SS2.SSS3.p1.2.m2.2" class="ltx_Math" alttext="C\in\{0,1\}^{XYZ}" display="inline"><semantics id="S3.SS2.SSS3.p1.2.m2.2a"><mrow id="S3.SS2.SSS3.p1.2.m2.2.3" xref="S3.SS2.SSS3.p1.2.m2.2.3.cmml"><mi id="S3.SS2.SSS3.p1.2.m2.2.3.2" xref="S3.SS2.SSS3.p1.2.m2.2.3.2.cmml">C</mi><mo id="S3.SS2.SSS3.p1.2.m2.2.3.1" xref="S3.SS2.SSS3.p1.2.m2.2.3.1.cmml">âˆˆ</mo><msup id="S3.SS2.SSS3.p1.2.m2.2.3.3" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.cmml"><mrow id="S3.SS2.SSS3.p1.2.m2.2.3.3.2.2" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS3.p1.2.m2.2.3.3.2.2.1" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.2.1.cmml">{</mo><mn id="S3.SS2.SSS3.p1.2.m2.1.1" xref="S3.SS2.SSS3.p1.2.m2.1.1.cmml">0</mn><mo id="S3.SS2.SSS3.p1.2.m2.2.3.3.2.2.2" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.2.1.cmml">,</mo><mn id="S3.SS2.SSS3.p1.2.m2.2.2" xref="S3.SS2.SSS3.p1.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS2.SSS3.p1.2.m2.2.3.3.2.2.3" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.2.1.cmml">}</mo></mrow><mrow id="S3.SS2.SSS3.p1.2.m2.2.3.3.3" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.cmml"><mi id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.2" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.1" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.3" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.3.cmml">Y</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.1a" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.4" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.4.cmml">Z</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.2.m2.2b"><apply id="S3.SS2.SSS3.p1.2.m2.2.3.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3"><in id="S3.SS2.SSS3.p1.2.m2.2.3.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.1"></in><ci id="S3.SS2.SSS3.p1.2.m2.2.3.2.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.2">ğ¶</ci><apply id="S3.SS2.SSS3.p1.2.m2.2.3.3.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.2.m2.2.3.3.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.3">superscript</csymbol><set id="S3.SS2.SSS3.p1.2.m2.2.3.3.2.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.2.2"><cn type="integer" id="S3.SS2.SSS3.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1">0</cn><cn type="integer" id="S3.SS2.SSS3.p1.2.m2.2.2.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.2">1</cn></set><apply id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3"><times id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.1"></times><ci id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.2.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.2">ğ‘‹</ci><ci id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.3.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.3">ğ‘Œ</ci><ci id="S3.SS2.SSS3.p1.2.m2.2.3.3.3.4.cmml" xref="S3.SS2.SSS3.p1.2.m2.2.3.3.3.4">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.2.m2.2c">C\in\{0,1\}^{XYZ}</annotation></semantics></math>. We explicitly supervise the
L2 <span id="S3.SS2.SSS3.p1.4.2" class="ltx_text ltx_font_bold">Wrench Loss</span> <math id="S3.SS2.SSS3.p1.3.m3.1" class="ltx_Math" alttext="L_{w}" display="inline"><semantics id="S3.SS2.SSS3.p1.3.m3.1a"><msub id="S3.SS2.SSS3.p1.3.m3.1.1" xref="S3.SS2.SSS3.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS3.p1.3.m3.1.1.2" xref="S3.SS2.SSS3.p1.3.m3.1.1.2.cmml">L</mi><mi id="S3.SS2.SSS3.p1.3.m3.1.1.3" xref="S3.SS2.SSS3.p1.3.m3.1.1.3.cmml">w</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.3.m3.1b"><apply id="S3.SS2.SSS3.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1.2">ğ¿</ci><ci id="S3.SS2.SSS3.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1.3">ğ‘¤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.3.m3.1c">L_{w}</annotation></semantics></math> and binary cross entropy <span id="S3.SS2.SSS3.p1.4.3" class="ltx_text ltx_font_bold">Collision Loss</span> <math id="S3.SS2.SSS3.p1.4.m4.1" class="ltx_Math" alttext="L_{c}" display="inline"><semantics id="S3.SS2.SSS3.p1.4.m4.1a"><msub id="S3.SS2.SSS3.p1.4.m4.1.1" xref="S3.SS2.SSS3.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS3.p1.4.m4.1.1.2" xref="S3.SS2.SSS3.p1.4.m4.1.1.2.cmml">L</mi><mi id="S3.SS2.SSS3.p1.4.m4.1.1.3" xref="S3.SS2.SSS3.p1.4.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.4.m4.1b"><apply id="S3.SS2.SSS3.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1.2">ğ¿</ci><ci id="S3.SS2.SSS3.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.4.m4.1c">L_{c}</annotation></semantics></math> on grids.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p id="S3.SS2.SSS3.p2.1" class="ltx_p">Therefore the whole <span id="S3.SS2.SSS3.p2.1.1" class="ltx_text ltx_font_italic">Volumetric WrcColNet</span>â€™s objective <math id="S3.SS2.SSS3.p2.1.m1.1" class="ltx_Math" alttext="L_{3D}" display="inline"><semantics id="S3.SS2.SSS3.p2.1.m1.1a"><msub id="S3.SS2.SSS3.p2.1.m1.1.1" xref="S3.SS2.SSS3.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p2.1.m1.1.1.2" xref="S3.SS2.SSS3.p2.1.m1.1.1.2.cmml">L</mi><mrow id="S3.SS2.SSS3.p2.1.m1.1.1.3" xref="S3.SS2.SSS3.p2.1.m1.1.1.3.cmml"><mn id="S3.SS2.SSS3.p2.1.m1.1.1.3.2" xref="S3.SS2.SSS3.p2.1.m1.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.1.m1.1.1.3.1" xref="S3.SS2.SSS3.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p2.1.m1.1.1.3.3" xref="S3.SS2.SSS3.p2.1.m1.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.1.m1.1b"><apply id="S3.SS2.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1.2">ğ¿</ci><apply id="S3.SS2.SSS3.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1.3"><times id="S3.SS2.SSS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1.3.1"></times><cn type="integer" id="S3.SS2.SSS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1.3.2">3</cn><ci id="S3.SS2.SSS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.1.m1.1c">L_{3D}</annotation></semantics></math> can be formulated as:</p>
</div>
<div id="S3.SS2.SSS3.p3" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="L_{3D}=\alpha_{1}L_{d}+\alpha_{2}L_{g}+\alpha_{3}L_{w}+\alpha_{4}L_{c}" display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><msub id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.2.2" xref="S3.E2.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E2.m1.1.1.2.3" xref="S3.E2.m1.1.1.2.3.cmml"><mn id="S3.E2.m1.1.1.2.3.2" xref="S3.E2.m1.1.1.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.2.3.1" xref="S3.E2.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.1.1.2.3.3" xref="S3.E2.m1.1.1.2.3.3.cmml">D</mi></mrow></msub><mo id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml"><msub id="S3.E2.m1.1.1.3.2.2" xref="S3.E2.m1.1.1.3.2.2.cmml"><mi id="S3.E2.m1.1.1.3.2.2.2" xref="S3.E2.m1.1.1.3.2.2.2.cmml">Î±</mi><mn id="S3.E2.m1.1.1.3.2.2.3" xref="S3.E2.m1.1.1.3.2.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.2.1" xref="S3.E2.m1.1.1.3.2.1.cmml">â€‹</mo><msub id="S3.E2.m1.1.1.3.2.3" xref="S3.E2.m1.1.1.3.2.3.cmml"><mi id="S3.E2.m1.1.1.3.2.3.2" xref="S3.E2.m1.1.1.3.2.3.2.cmml">L</mi><mi id="S3.E2.m1.1.1.3.2.3.3" xref="S3.E2.m1.1.1.3.2.3.3.cmml">d</mi></msub></mrow><mo id="S3.E2.m1.1.1.3.1" xref="S3.E2.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E2.m1.1.1.3.3" xref="S3.E2.m1.1.1.3.3.cmml"><msub id="S3.E2.m1.1.1.3.3.2" xref="S3.E2.m1.1.1.3.3.2.cmml"><mi id="S3.E2.m1.1.1.3.3.2.2" xref="S3.E2.m1.1.1.3.3.2.2.cmml">Î±</mi><mn id="S3.E2.m1.1.1.3.3.2.3" xref="S3.E2.m1.1.1.3.3.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.3.1" xref="S3.E2.m1.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.E2.m1.1.1.3.3.3" xref="S3.E2.m1.1.1.3.3.3.cmml"><mi id="S3.E2.m1.1.1.3.3.3.2" xref="S3.E2.m1.1.1.3.3.3.2.cmml">L</mi><mi id="S3.E2.m1.1.1.3.3.3.3" xref="S3.E2.m1.1.1.3.3.3.3.cmml">g</mi></msub></mrow><mo id="S3.E2.m1.1.1.3.1a" xref="S3.E2.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E2.m1.1.1.3.4" xref="S3.E2.m1.1.1.3.4.cmml"><msub id="S3.E2.m1.1.1.3.4.2" xref="S3.E2.m1.1.1.3.4.2.cmml"><mi id="S3.E2.m1.1.1.3.4.2.2" xref="S3.E2.m1.1.1.3.4.2.2.cmml">Î±</mi><mn id="S3.E2.m1.1.1.3.4.2.3" xref="S3.E2.m1.1.1.3.4.2.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.4.1" xref="S3.E2.m1.1.1.3.4.1.cmml">â€‹</mo><msub id="S3.E2.m1.1.1.3.4.3" xref="S3.E2.m1.1.1.3.4.3.cmml"><mi id="S3.E2.m1.1.1.3.4.3.2" xref="S3.E2.m1.1.1.3.4.3.2.cmml">L</mi><mi id="S3.E2.m1.1.1.3.4.3.3" xref="S3.E2.m1.1.1.3.4.3.3.cmml">w</mi></msub></mrow><mo id="S3.E2.m1.1.1.3.1b" xref="S3.E2.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E2.m1.1.1.3.5" xref="S3.E2.m1.1.1.3.5.cmml"><msub id="S3.E2.m1.1.1.3.5.2" xref="S3.E2.m1.1.1.3.5.2.cmml"><mi id="S3.E2.m1.1.1.3.5.2.2" xref="S3.E2.m1.1.1.3.5.2.2.cmml">Î±</mi><mn id="S3.E2.m1.1.1.3.5.2.3" xref="S3.E2.m1.1.1.3.5.2.3.cmml">4</mn></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.5.1" xref="S3.E2.m1.1.1.3.5.1.cmml">â€‹</mo><msub id="S3.E2.m1.1.1.3.5.3" xref="S3.E2.m1.1.1.3.5.3.cmml"><mi id="S3.E2.m1.1.1.3.5.3.2" xref="S3.E2.m1.1.1.3.5.3.2.cmml">L</mi><mi id="S3.E2.m1.1.1.3.5.3.3" xref="S3.E2.m1.1.1.3.5.3.3.cmml">c</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"></eq><apply id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.2.2">ğ¿</ci><apply id="S3.E2.m1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.2.3"><times id="S3.E2.m1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.2.3.1"></times><cn type="integer" id="S3.E2.m1.1.1.2.3.2.cmml" xref="S3.E2.m1.1.1.2.3.2">3</cn><ci id="S3.E2.m1.1.1.2.3.3.cmml" xref="S3.E2.m1.1.1.2.3.3">ğ·</ci></apply></apply><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><plus id="S3.E2.m1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.3.1"></plus><apply id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2"><times id="S3.E2.m1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.3.2.1"></times><apply id="S3.E2.m1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.2.2.1.cmml" xref="S3.E2.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.2.2.2.cmml" xref="S3.E2.m1.1.1.3.2.2.2">ğ›¼</ci><cn type="integer" id="S3.E2.m1.1.1.3.2.2.3.cmml" xref="S3.E2.m1.1.1.3.2.2.3">1</cn></apply><apply id="S3.E2.m1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.2.3.1.cmml" xref="S3.E2.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.3.2.3.2.cmml" xref="S3.E2.m1.1.1.3.2.3.2">ğ¿</ci><ci id="S3.E2.m1.1.1.3.2.3.3.cmml" xref="S3.E2.m1.1.1.3.2.3.3">ğ‘‘</ci></apply></apply><apply id="S3.E2.m1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.3.3"><times id="S3.E2.m1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.3.3.1"></times><apply id="S3.E2.m1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.3.2.1.cmml" xref="S3.E2.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.3.2.2.cmml" xref="S3.E2.m1.1.1.3.3.2.2">ğ›¼</ci><cn type="integer" id="S3.E2.m1.1.1.3.3.2.3.cmml" xref="S3.E2.m1.1.1.3.3.2.3">2</cn></apply><apply id="S3.E2.m1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.3.3.1.cmml" xref="S3.E2.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E2.m1.1.1.3.3.3.2.cmml" xref="S3.E2.m1.1.1.3.3.3.2">ğ¿</ci><ci id="S3.E2.m1.1.1.3.3.3.3.cmml" xref="S3.E2.m1.1.1.3.3.3.3">ğ‘”</ci></apply></apply><apply id="S3.E2.m1.1.1.3.4.cmml" xref="S3.E2.m1.1.1.3.4"><times id="S3.E2.m1.1.1.3.4.1.cmml" xref="S3.E2.m1.1.1.3.4.1"></times><apply id="S3.E2.m1.1.1.3.4.2.cmml" xref="S3.E2.m1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.4.2.1.cmml" xref="S3.E2.m1.1.1.3.4.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.4.2.2.cmml" xref="S3.E2.m1.1.1.3.4.2.2">ğ›¼</ci><cn type="integer" id="S3.E2.m1.1.1.3.4.2.3.cmml" xref="S3.E2.m1.1.1.3.4.2.3">3</cn></apply><apply id="S3.E2.m1.1.1.3.4.3.cmml" xref="S3.E2.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.4.3.1.cmml" xref="S3.E2.m1.1.1.3.4.3">subscript</csymbol><ci id="S3.E2.m1.1.1.3.4.3.2.cmml" xref="S3.E2.m1.1.1.3.4.3.2">ğ¿</ci><ci id="S3.E2.m1.1.1.3.4.3.3.cmml" xref="S3.E2.m1.1.1.3.4.3.3">ğ‘¤</ci></apply></apply><apply id="S3.E2.m1.1.1.3.5.cmml" xref="S3.E2.m1.1.1.3.5"><times id="S3.E2.m1.1.1.3.5.1.cmml" xref="S3.E2.m1.1.1.3.5.1"></times><apply id="S3.E2.m1.1.1.3.5.2.cmml" xref="S3.E2.m1.1.1.3.5.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.5.2.1.cmml" xref="S3.E2.m1.1.1.3.5.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.5.2.2.cmml" xref="S3.E2.m1.1.1.3.5.2.2">ğ›¼</ci><cn type="integer" id="S3.E2.m1.1.1.3.5.2.3.cmml" xref="S3.E2.m1.1.1.3.5.2.3">4</cn></apply><apply id="S3.E2.m1.1.1.3.5.3.cmml" xref="S3.E2.m1.1.1.3.5.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.5.3.1.cmml" xref="S3.E2.m1.1.1.3.5.3">subscript</csymbol><ci id="S3.E2.m1.1.1.3.5.3.2.cmml" xref="S3.E2.m1.1.1.3.5.3.2">ğ¿</ci><ci id="S3.E2.m1.1.1.3.5.3.3.cmml" xref="S3.E2.m1.1.1.3.5.3.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">L_{3D}=\alpha_{1}L_{d}+\alpha_{2}L_{g}+\alpha_{3}L_{w}+\alpha_{4}L_{c}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">2D SealNormNet: Suction Pose Detection</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">As SuctionNet-1BillionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> indicates, each suction pose contains 6 degrees of freedom and can be evaluated through three dimensions: seal, wrench and collision. Wrench and collision mainly focus on the global characteristics of objects and scenes, while seal heavily relies on the local characteristics of object surfaces. Therefore a prediction of seal scores from unreliable 3D representations can do great harm to the performance, and so do surface normals, which are the default choices of suction directions. To this end, we propose to predict seal scores and surface normal in a 2D manner.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.2" class="ltx_p">Specifically, taking RGB as input, we utilize a DPT model that shares the transformer encoder layers to extract image features and leverage different convolutional decoder layers to jointly predict the seal map <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="M_{s}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">M</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">ğ‘€</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">M_{s}</annotation></semantics></math> and the normal map <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="M_{n}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">M</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">ğ‘€</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">M_{n}</annotation></semantics></math>. And we directly supervise the dense pixel loss, which is:</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="L_{2D}=\beta_{1}\|M_{s}-M^{*}_{s}\|_{2}+\beta_{2}\|M_{n}-M^{*}_{n}\|_{1}" display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><msub id="S3.E3.m1.2.2.4" xref="S3.E3.m1.2.2.4.cmml"><mi id="S3.E3.m1.2.2.4.2" xref="S3.E3.m1.2.2.4.2.cmml">L</mi><mrow id="S3.E3.m1.2.2.4.3" xref="S3.E3.m1.2.2.4.3.cmml"><mn id="S3.E3.m1.2.2.4.3.2" xref="S3.E3.m1.2.2.4.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.4.3.1" xref="S3.E3.m1.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.4.3.3" xref="S3.E3.m1.2.2.4.3.3.cmml">D</mi></mrow></msub><mo id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">=</mo><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml">Î²</mi><mn id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml">â€‹</mo><msub id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml">M</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml">s</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.E3.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">M</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.3.cmml">s</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.3.cmml">âˆ—</mo></msubsup></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml">2</mn></msub></mrow><mo id="S3.E3.m1.2.2.2.3" xref="S3.E3.m1.2.2.2.3.cmml">+</mo><mrow id="S3.E3.m1.2.2.2.2" xref="S3.E3.m1.2.2.2.2.cmml"><msub id="S3.E3.m1.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.3.cmml"><mi id="S3.E3.m1.2.2.2.2.3.2" xref="S3.E3.m1.2.2.2.2.3.2.cmml">Î²</mi><mn id="S3.E3.m1.2.2.2.2.3.3" xref="S3.E3.m1.2.2.2.2.3.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.cmml">â€‹</mo><msub id="S3.E3.m1.2.2.2.2.1" xref="S3.E3.m1.2.2.2.2.1.cmml"><mrow id="S3.E3.m1.2.2.2.2.1.1.1" xref="S3.E3.m1.2.2.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.2.2.1.1.1.2" xref="S3.E3.m1.2.2.2.2.1.1.2.1.cmml">â€–</mo><mrow id="S3.E3.m1.2.2.2.2.1.1.1.1" xref="S3.E3.m1.2.2.2.2.1.1.1.1.cmml"><msub id="S3.E3.m1.2.2.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.2.2.1.1.1.1.2.cmml"><mi id="S3.E3.m1.2.2.2.2.1.1.1.1.2.2" xref="S3.E3.m1.2.2.2.2.1.1.1.1.2.2.cmml">M</mi><mi id="S3.E3.m1.2.2.2.2.1.1.1.1.2.3" xref="S3.E3.m1.2.2.2.2.1.1.1.1.2.3.cmml">n</mi></msub><mo id="S3.E3.m1.2.2.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.2.2.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.E3.m1.2.2.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.2" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.2.cmml">M</mi><mi id="S3.E3.m1.2.2.2.2.1.1.1.1.3.3" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3.3.cmml">n</mi><mo id="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.3" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.3.cmml">âˆ—</mo></msubsup></mrow><mo stretchy="false" id="S3.E3.m1.2.2.2.2.1.1.1.3" xref="S3.E3.m1.2.2.2.2.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E3.m1.2.2.2.2.1.3" xref="S3.E3.m1.2.2.2.2.1.3.cmml">1</mn></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3"></eq><apply id="S3.E3.m1.2.2.4.cmml" xref="S3.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.4.2">ğ¿</ci><apply id="S3.E3.m1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.4.3"><times id="S3.E3.m1.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.4.3.1"></times><cn type="integer" id="S3.E3.m1.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.4.3.2">2</cn><ci id="S3.E3.m1.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.4.3.3">ğ·</ci></apply></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><plus id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"></plus><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2">ğ›½</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3">1</cn></apply><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2">ğ‘€</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3">ğ‘ </ci></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.2">ğ‘€</ci><times id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.3"></times></apply><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.3">ğ‘ </ci></apply></apply></apply><cn type="integer" id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3">2</cn></apply></apply><apply id="S3.E3.m1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2"><times id="S3.E3.m1.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2"></times><apply id="S3.E3.m1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.3.2">ğ›½</ci><cn type="integer" id="S3.E3.m1.2.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.2.2.3.3">2</cn></apply><apply id="S3.E3.m1.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.1.2.cmml" xref="S3.E3.m1.2.2.2.2.1">subscript</csymbol><apply id="S3.E3.m1.2.2.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.2.2.2.2.1.1.2.1.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.2">norm</csymbol><apply id="S3.E3.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1"><minus id="S3.E3.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.1"></minus><apply id="S3.E3.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.1.1.1.1.2.2.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.2.2">ğ‘€</ci><ci id="S3.E3.m1.2.2.2.2.1.1.1.1.2.3.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.2.3">ğ‘›</ci></apply><apply id="S3.E3.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3">subscript</csymbol><apply id="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.2">ğ‘€</ci><times id="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3.2.3"></times></apply><ci id="S3.E3.m1.2.2.2.2.1.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.2.2.1.1.1.1.3.3">ğ‘›</ci></apply></apply></apply><cn type="integer" id="S3.E3.m1.2.2.2.2.1.3.cmml" xref="S3.E3.m1.2.2.2.2.1.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">L_{2D}=\beta_{1}\|M_{s}-M^{*}_{s}\|_{2}+\beta_{2}\|M_{n}-M^{*}_{n}\|_{1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.2" class="ltx_p">where <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="M^{*}_{s}" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><msubsup id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2.2" xref="S3.SS3.p4.1.m1.1.1.2.2.cmml">M</mi><mi id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">s</mi><mo id="S3.SS3.p4.1.m1.1.1.2.3" xref="S3.SS3.p4.1.m1.1.1.2.3.cmml">âˆ—</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><apply id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.2.1.cmml" xref="S3.SS3.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2.2">ğ‘€</ci><times id="S3.SS3.p4.1.m1.1.1.2.3.cmml" xref="S3.SS3.p4.1.m1.1.1.2.3"></times></apply><ci id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">M^{*}_{s}</annotation></semantics></math> and <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="M^{*}_{n}" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><msubsup id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi id="S3.SS3.p4.2.m2.1.1.2.2" xref="S3.SS3.p4.2.m2.1.1.2.2.cmml">M</mi><mi id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml">n</mi><mo id="S3.SS3.p4.2.m2.1.1.2.3" xref="S3.SS3.p4.2.m2.1.1.2.3.cmml">âˆ—</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">subscript</csymbol><apply id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.2.1.cmml" xref="S3.SS3.p4.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.2.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2.2">ğ‘€</ci><times id="S3.SS3.p4.2.m2.1.1.2.3.cmml" xref="S3.SS3.p4.2.m2.1.1.2.3"></times></apply><ci id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">M^{*}_{n}</annotation></semantics></math> are the GT seal and normal map.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Inference Pipeline</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.8" class="ltx_p">At inference time, we need to conduct 2D-3D fusion to acquire Top-<span id="S3.SS4.p1.8.1" class="ltx_text ltx_font_italic">k</span> suction poses to execute. First we do grid sampling on 2D seal maps to get pixel positions of high seal scores and query corresponding normals on predicted normal maps to obtain our 2D suction proposals. Based on the predicted TSDF volume <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="V_{TSDF}" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><msub id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">V</mi><mrow id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml"><mi id="S3.SS4.p1.1.m1.1.1.3.2" xref="S3.SS4.p1.1.m1.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.1.m1.1.1.3.1" xref="S3.SS4.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.1.m1.1.1.3.3" xref="S3.SS4.p1.1.m1.1.1.3.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.1.m1.1.1.3.1a" xref="S3.SS4.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.1.m1.1.1.3.4" xref="S3.SS4.p1.1.m1.1.1.3.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.1.m1.1.1.3.1b" xref="S3.SS4.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.1.m1.1.1.3.5" xref="S3.SS4.p1.1.m1.1.1.3.5.cmml">F</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">ğ‘‰</ci><apply id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3"><times id="S3.SS4.p1.1.m1.1.1.3.1.cmml" xref="S3.SS4.p1.1.m1.1.1.3.1"></times><ci id="S3.SS4.p1.1.m1.1.1.3.2.cmml" xref="S3.SS4.p1.1.m1.1.1.3.2">ğ‘‡</ci><ci id="S3.SS4.p1.1.m1.1.1.3.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3.3">ğ‘†</ci><ci id="S3.SS4.p1.1.m1.1.1.3.4.cmml" xref="S3.SS4.p1.1.m1.1.1.3.4">ğ·</ci><ci id="S3.SS4.p1.1.m1.1.1.3.5.cmml" xref="S3.SS4.p1.1.m1.1.1.3.5">ğ¹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">V_{TSDF}</annotation></semantics></math>, we can render the corresponding de-noised depth maps using the Marching Cube AlgorithmÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. This allows us to obtain 3D positions <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="\{p_{j}\}" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mrow id="S3.SS4.p1.2.m2.1.1.1" xref="S3.SS4.p1.2.m2.1.1.2.cmml"><mo stretchy="false" id="S3.SS4.p1.2.m2.1.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">{</mo><msub id="S3.SS4.p1.2.m2.1.1.1.1" xref="S3.SS4.p1.2.m2.1.1.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.1.1.2" xref="S3.SS4.p1.2.m2.1.1.1.1.2.cmml">p</mi><mi id="S3.SS4.p1.2.m2.1.1.1.1.3" xref="S3.SS4.p1.2.m2.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS4.p1.2.m2.1.1.1.3" xref="S3.SS4.p1.2.m2.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><set id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.1"><apply id="S3.SS4.p1.2.m2.1.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1.2">ğ‘</ci><ci id="S3.SS4.p1.2.m2.1.1.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1.3">ğ‘—</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">\{p_{j}\}</annotation></semantics></math> and normals <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="\{d_{j}\}" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mrow id="S3.SS4.p1.3.m3.1.1.1" xref="S3.SS4.p1.3.m3.1.1.2.cmml"><mo stretchy="false" id="S3.SS4.p1.3.m3.1.1.1.2" xref="S3.SS4.p1.3.m3.1.1.2.cmml">{</mo><msub id="S3.SS4.p1.3.m3.1.1.1.1" xref="S3.SS4.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS4.p1.3.m3.1.1.1.1.2" xref="S3.SS4.p1.3.m3.1.1.1.1.2.cmml">d</mi><mi id="S3.SS4.p1.3.m3.1.1.1.1.3" xref="S3.SS4.p1.3.m3.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS4.p1.3.m3.1.1.1.3" xref="S3.SS4.p1.3.m3.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><set id="S3.SS4.p1.3.m3.1.1.2.cmml" xref="S3.SS4.p1.3.m3.1.1.1"><apply id="S3.SS4.p1.3.m3.1.1.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS4.p1.3.m3.1.1.1.1.2">ğ‘‘</ci><ci id="S3.SS4.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS4.p1.3.m3.1.1.1.1.3">ğ‘—</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">\{d_{j}\}</annotation></semantics></math> from 2D pixels. Given 3D points of seal scores <math id="S3.SS4.p1.4.m4.2" class="ltx_Math" alttext="s_{seal}\in[0,1]" display="inline"><semantics id="S3.SS4.p1.4.m4.2a"><mrow id="S3.SS4.p1.4.m4.2.3" xref="S3.SS4.p1.4.m4.2.3.cmml"><msub id="S3.SS4.p1.4.m4.2.3.2" xref="S3.SS4.p1.4.m4.2.3.2.cmml"><mi id="S3.SS4.p1.4.m4.2.3.2.2" xref="S3.SS4.p1.4.m4.2.3.2.2.cmml">s</mi><mrow id="S3.SS4.p1.4.m4.2.3.2.3" xref="S3.SS4.p1.4.m4.2.3.2.3.cmml"><mi id="S3.SS4.p1.4.m4.2.3.2.3.2" xref="S3.SS4.p1.4.m4.2.3.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.4.m4.2.3.2.3.1" xref="S3.SS4.p1.4.m4.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.4.m4.2.3.2.3.3" xref="S3.SS4.p1.4.m4.2.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.4.m4.2.3.2.3.1a" xref="S3.SS4.p1.4.m4.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.4.m4.2.3.2.3.4" xref="S3.SS4.p1.4.m4.2.3.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.4.m4.2.3.2.3.1b" xref="S3.SS4.p1.4.m4.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.4.m4.2.3.2.3.5" xref="S3.SS4.p1.4.m4.2.3.2.3.5.cmml">l</mi></mrow></msub><mo id="S3.SS4.p1.4.m4.2.3.1" xref="S3.SS4.p1.4.m4.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS4.p1.4.m4.2.3.3.2" xref="S3.SS4.p1.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p1.4.m4.2.3.3.2.1" xref="S3.SS4.p1.4.m4.2.3.3.1.cmml">[</mo><mn id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">0</mn><mo id="S3.SS4.p1.4.m4.2.3.3.2.2" xref="S3.SS4.p1.4.m4.2.3.3.1.cmml">,</mo><mn id="S3.SS4.p1.4.m4.2.2" xref="S3.SS4.p1.4.m4.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS4.p1.4.m4.2.3.3.2.3" xref="S3.SS4.p1.4.m4.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.2b"><apply id="S3.SS4.p1.4.m4.2.3.cmml" xref="S3.SS4.p1.4.m4.2.3"><in id="S3.SS4.p1.4.m4.2.3.1.cmml" xref="S3.SS4.p1.4.m4.2.3.1"></in><apply id="S3.SS4.p1.4.m4.2.3.2.cmml" xref="S3.SS4.p1.4.m4.2.3.2"><csymbol cd="ambiguous" id="S3.SS4.p1.4.m4.2.3.2.1.cmml" xref="S3.SS4.p1.4.m4.2.3.2">subscript</csymbol><ci id="S3.SS4.p1.4.m4.2.3.2.2.cmml" xref="S3.SS4.p1.4.m4.2.3.2.2">ğ‘ </ci><apply id="S3.SS4.p1.4.m4.2.3.2.3.cmml" xref="S3.SS4.p1.4.m4.2.3.2.3"><times id="S3.SS4.p1.4.m4.2.3.2.3.1.cmml" xref="S3.SS4.p1.4.m4.2.3.2.3.1"></times><ci id="S3.SS4.p1.4.m4.2.3.2.3.2.cmml" xref="S3.SS4.p1.4.m4.2.3.2.3.2">ğ‘ </ci><ci id="S3.SS4.p1.4.m4.2.3.2.3.3.cmml" xref="S3.SS4.p1.4.m4.2.3.2.3.3">ğ‘’</ci><ci id="S3.SS4.p1.4.m4.2.3.2.3.4.cmml" xref="S3.SS4.p1.4.m4.2.3.2.3.4">ğ‘</ci><ci id="S3.SS4.p1.4.m4.2.3.2.3.5.cmml" xref="S3.SS4.p1.4.m4.2.3.2.3.5">ğ‘™</ci></apply></apply><interval closure="closed" id="S3.SS4.p1.4.m4.2.3.3.1.cmml" xref="S3.SS4.p1.4.m4.2.3.3.2"><cn type="integer" id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">0</cn><cn type="integer" id="S3.SS4.p1.4.m4.2.2.cmml" xref="S3.SS4.p1.4.m4.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.2c">s_{seal}\in[0,1]</annotation></semantics></math>, both wrench scores <math id="S3.SS4.p1.5.m5.2" class="ltx_Math" alttext="s_{wrench}\in[0,1]" display="inline"><semantics id="S3.SS4.p1.5.m5.2a"><mrow id="S3.SS4.p1.5.m5.2.3" xref="S3.SS4.p1.5.m5.2.3.cmml"><msub id="S3.SS4.p1.5.m5.2.3.2" xref="S3.SS4.p1.5.m5.2.3.2.cmml"><mi id="S3.SS4.p1.5.m5.2.3.2.2" xref="S3.SS4.p1.5.m5.2.3.2.2.cmml">s</mi><mrow id="S3.SS4.p1.5.m5.2.3.2.3" xref="S3.SS4.p1.5.m5.2.3.2.3.cmml"><mi id="S3.SS4.p1.5.m5.2.3.2.3.2" xref="S3.SS4.p1.5.m5.2.3.2.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.5.m5.2.3.2.3.1" xref="S3.SS4.p1.5.m5.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.5.m5.2.3.2.3.3" xref="S3.SS4.p1.5.m5.2.3.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.5.m5.2.3.2.3.1a" xref="S3.SS4.p1.5.m5.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.5.m5.2.3.2.3.4" xref="S3.SS4.p1.5.m5.2.3.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.5.m5.2.3.2.3.1b" xref="S3.SS4.p1.5.m5.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.5.m5.2.3.2.3.5" xref="S3.SS4.p1.5.m5.2.3.2.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.5.m5.2.3.2.3.1c" xref="S3.SS4.p1.5.m5.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.5.m5.2.3.2.3.6" xref="S3.SS4.p1.5.m5.2.3.2.3.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.5.m5.2.3.2.3.1d" xref="S3.SS4.p1.5.m5.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.5.m5.2.3.2.3.7" xref="S3.SS4.p1.5.m5.2.3.2.3.7.cmml">h</mi></mrow></msub><mo id="S3.SS4.p1.5.m5.2.3.1" xref="S3.SS4.p1.5.m5.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS4.p1.5.m5.2.3.3.2" xref="S3.SS4.p1.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p1.5.m5.2.3.3.2.1" xref="S3.SS4.p1.5.m5.2.3.3.1.cmml">[</mo><mn id="S3.SS4.p1.5.m5.1.1" xref="S3.SS4.p1.5.m5.1.1.cmml">0</mn><mo id="S3.SS4.p1.5.m5.2.3.3.2.2" xref="S3.SS4.p1.5.m5.2.3.3.1.cmml">,</mo><mn id="S3.SS4.p1.5.m5.2.2" xref="S3.SS4.p1.5.m5.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS4.p1.5.m5.2.3.3.2.3" xref="S3.SS4.p1.5.m5.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m5.2b"><apply id="S3.SS4.p1.5.m5.2.3.cmml" xref="S3.SS4.p1.5.m5.2.3"><in id="S3.SS4.p1.5.m5.2.3.1.cmml" xref="S3.SS4.p1.5.m5.2.3.1"></in><apply id="S3.SS4.p1.5.m5.2.3.2.cmml" xref="S3.SS4.p1.5.m5.2.3.2"><csymbol cd="ambiguous" id="S3.SS4.p1.5.m5.2.3.2.1.cmml" xref="S3.SS4.p1.5.m5.2.3.2">subscript</csymbol><ci id="S3.SS4.p1.5.m5.2.3.2.2.cmml" xref="S3.SS4.p1.5.m5.2.3.2.2">ğ‘ </ci><apply id="S3.SS4.p1.5.m5.2.3.2.3.cmml" xref="S3.SS4.p1.5.m5.2.3.2.3"><times id="S3.SS4.p1.5.m5.2.3.2.3.1.cmml" xref="S3.SS4.p1.5.m5.2.3.2.3.1"></times><ci id="S3.SS4.p1.5.m5.2.3.2.3.2.cmml" xref="S3.SS4.p1.5.m5.2.3.2.3.2">ğ‘¤</ci><ci id="S3.SS4.p1.5.m5.2.3.2.3.3.cmml" xref="S3.SS4.p1.5.m5.2.3.2.3.3">ğ‘Ÿ</ci><ci id="S3.SS4.p1.5.m5.2.3.2.3.4.cmml" xref="S3.SS4.p1.5.m5.2.3.2.3.4">ğ‘’</ci><ci id="S3.SS4.p1.5.m5.2.3.2.3.5.cmml" xref="S3.SS4.p1.5.m5.2.3.2.3.5">ğ‘›</ci><ci id="S3.SS4.p1.5.m5.2.3.2.3.6.cmml" xref="S3.SS4.p1.5.m5.2.3.2.3.6">ğ‘</ci><ci id="S3.SS4.p1.5.m5.2.3.2.3.7.cmml" xref="S3.SS4.p1.5.m5.2.3.2.3.7">â„</ci></apply></apply><interval closure="closed" id="S3.SS4.p1.5.m5.2.3.3.1.cmml" xref="S3.SS4.p1.5.m5.2.3.3.2"><cn type="integer" id="S3.SS4.p1.5.m5.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1">0</cn><cn type="integer" id="S3.SS4.p1.5.m5.2.2.cmml" xref="S3.SS4.p1.5.m5.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m5.2c">s_{wrench}\in[0,1]</annotation></semantics></math> and collision scores <math id="S3.SS4.p1.6.m6.2" class="ltx_Math" alttext="s_{collision}\in\{0,1\}" display="inline"><semantics id="S3.SS4.p1.6.m6.2a"><mrow id="S3.SS4.p1.6.m6.2.3" xref="S3.SS4.p1.6.m6.2.3.cmml"><msub id="S3.SS4.p1.6.m6.2.3.2" xref="S3.SS4.p1.6.m6.2.3.2.cmml"><mi id="S3.SS4.p1.6.m6.2.3.2.2" xref="S3.SS4.p1.6.m6.2.3.2.2.cmml">s</mi><mrow id="S3.SS4.p1.6.m6.2.3.2.3" xref="S3.SS4.p1.6.m6.2.3.2.3.cmml"><mi id="S3.SS4.p1.6.m6.2.3.2.3.2" xref="S3.SS4.p1.6.m6.2.3.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.2.3.2.3.1" xref="S3.SS4.p1.6.m6.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.2.3.2.3.3" xref="S3.SS4.p1.6.m6.2.3.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.2.3.2.3.1a" xref="S3.SS4.p1.6.m6.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.2.3.2.3.4" xref="S3.SS4.p1.6.m6.2.3.2.3.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.2.3.2.3.1b" xref="S3.SS4.p1.6.m6.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.2.3.2.3.5" xref="S3.SS4.p1.6.m6.2.3.2.3.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.2.3.2.3.1c" xref="S3.SS4.p1.6.m6.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.2.3.2.3.6" xref="S3.SS4.p1.6.m6.2.3.2.3.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.2.3.2.3.1d" xref="S3.SS4.p1.6.m6.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.2.3.2.3.7" xref="S3.SS4.p1.6.m6.2.3.2.3.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.2.3.2.3.1e" xref="S3.SS4.p1.6.m6.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.2.3.2.3.8" xref="S3.SS4.p1.6.m6.2.3.2.3.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.2.3.2.3.1f" xref="S3.SS4.p1.6.m6.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.2.3.2.3.9" xref="S3.SS4.p1.6.m6.2.3.2.3.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.6.m6.2.3.2.3.1g" xref="S3.SS4.p1.6.m6.2.3.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p1.6.m6.2.3.2.3.10" xref="S3.SS4.p1.6.m6.2.3.2.3.10.cmml">n</mi></mrow></msub><mo id="S3.SS4.p1.6.m6.2.3.1" xref="S3.SS4.p1.6.m6.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS4.p1.6.m6.2.3.3.2" xref="S3.SS4.p1.6.m6.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p1.6.m6.2.3.3.2.1" xref="S3.SS4.p1.6.m6.2.3.3.1.cmml">{</mo><mn id="S3.SS4.p1.6.m6.1.1" xref="S3.SS4.p1.6.m6.1.1.cmml">0</mn><mo id="S3.SS4.p1.6.m6.2.3.3.2.2" xref="S3.SS4.p1.6.m6.2.3.3.1.cmml">,</mo><mn id="S3.SS4.p1.6.m6.2.2" xref="S3.SS4.p1.6.m6.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS4.p1.6.m6.2.3.3.2.3" xref="S3.SS4.p1.6.m6.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.6.m6.2b"><apply id="S3.SS4.p1.6.m6.2.3.cmml" xref="S3.SS4.p1.6.m6.2.3"><in id="S3.SS4.p1.6.m6.2.3.1.cmml" xref="S3.SS4.p1.6.m6.2.3.1"></in><apply id="S3.SS4.p1.6.m6.2.3.2.cmml" xref="S3.SS4.p1.6.m6.2.3.2"><csymbol cd="ambiguous" id="S3.SS4.p1.6.m6.2.3.2.1.cmml" xref="S3.SS4.p1.6.m6.2.3.2">subscript</csymbol><ci id="S3.SS4.p1.6.m6.2.3.2.2.cmml" xref="S3.SS4.p1.6.m6.2.3.2.2">ğ‘ </ci><apply id="S3.SS4.p1.6.m6.2.3.2.3.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3"><times id="S3.SS4.p1.6.m6.2.3.2.3.1.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.1"></times><ci id="S3.SS4.p1.6.m6.2.3.2.3.2.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.2">ğ‘</ci><ci id="S3.SS4.p1.6.m6.2.3.2.3.3.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.3">ğ‘œ</ci><ci id="S3.SS4.p1.6.m6.2.3.2.3.4.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.4">ğ‘™</ci><ci id="S3.SS4.p1.6.m6.2.3.2.3.5.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.5">ğ‘™</ci><ci id="S3.SS4.p1.6.m6.2.3.2.3.6.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.6">ğ‘–</ci><ci id="S3.SS4.p1.6.m6.2.3.2.3.7.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.7">ğ‘ </ci><ci id="S3.SS4.p1.6.m6.2.3.2.3.8.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.8">ğ‘–</ci><ci id="S3.SS4.p1.6.m6.2.3.2.3.9.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.9">ğ‘œ</ci><ci id="S3.SS4.p1.6.m6.2.3.2.3.10.cmml" xref="S3.SS4.p1.6.m6.2.3.2.3.10">ğ‘›</ci></apply></apply><set id="S3.SS4.p1.6.m6.2.3.3.1.cmml" xref="S3.SS4.p1.6.m6.2.3.3.2"><cn type="integer" id="S3.SS4.p1.6.m6.1.1.cmml" xref="S3.SS4.p1.6.m6.1.1">0</cn><cn type="integer" id="S3.SS4.p1.6.m6.2.2.cmml" xref="S3.SS4.p1.6.m6.2.2">1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.6.m6.2c">s_{collision}\in\{0,1\}</annotation></semantics></math> of the nearest grids from the predicted wrench and collision volumes will be assigned to these points. Finally, we calculate the overall scores by Eq.Â <a href="#S3.E1" title="In III-A Problem Statement and Method Overview â€£ III METHOD â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and rank them to get <math id="S3.SS4.p1.7.m7.1" class="ltx_Math" alttext="\{s_{j}\}" display="inline"><semantics id="S3.SS4.p1.7.m7.1a"><mrow id="S3.SS4.p1.7.m7.1.1.1" xref="S3.SS4.p1.7.m7.1.1.2.cmml"><mo stretchy="false" id="S3.SS4.p1.7.m7.1.1.1.2" xref="S3.SS4.p1.7.m7.1.1.2.cmml">{</mo><msub id="S3.SS4.p1.7.m7.1.1.1.1" xref="S3.SS4.p1.7.m7.1.1.1.1.cmml"><mi id="S3.SS4.p1.7.m7.1.1.1.1.2" xref="S3.SS4.p1.7.m7.1.1.1.1.2.cmml">s</mi><mi id="S3.SS4.p1.7.m7.1.1.1.1.3" xref="S3.SS4.p1.7.m7.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS4.p1.7.m7.1.1.1.3" xref="S3.SS4.p1.7.m7.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.7.m7.1b"><set id="S3.SS4.p1.7.m7.1.1.2.cmml" xref="S3.SS4.p1.7.m7.1.1.1"><apply id="S3.SS4.p1.7.m7.1.1.1.1.cmml" xref="S3.SS4.p1.7.m7.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.7.m7.1.1.1.1.1.cmml" xref="S3.SS4.p1.7.m7.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.7.m7.1.1.1.1.2.cmml" xref="S3.SS4.p1.7.m7.1.1.1.1.2">ğ‘ </ci><ci id="S3.SS4.p1.7.m7.1.1.1.1.3.cmml" xref="S3.SS4.p1.7.m7.1.1.1.1.3">ğ‘—</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.7.m7.1c">\{s_{j}\}</annotation></semantics></math>. In this way we obtain the 3D Top-<span id="S3.SS4.p1.8.2" class="ltx_text ltx_font_italic">k</span> suction poses <math id="S3.SS4.p1.8.m8.2" class="ltx_Math" alttext="{\{S_{j}|S_{j}=(p_{j},d_{j},s_{j})\}}" display="inline"><semantics id="S3.SS4.p1.8.m8.2a"><mrow id="S3.SS4.p1.8.m8.2.2.2" xref="S3.SS4.p1.8.m8.2.2.3.cmml"><mo stretchy="false" id="S3.SS4.p1.8.m8.2.2.2.3" xref="S3.SS4.p1.8.m8.2.2.3.1.cmml">{</mo><msub id="S3.SS4.p1.8.m8.1.1.1.1" xref="S3.SS4.p1.8.m8.1.1.1.1.cmml"><mi id="S3.SS4.p1.8.m8.1.1.1.1.2" xref="S3.SS4.p1.8.m8.1.1.1.1.2.cmml">S</mi><mi id="S3.SS4.p1.8.m8.1.1.1.1.3" xref="S3.SS4.p1.8.m8.1.1.1.1.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p1.8.m8.2.2.2.4" xref="S3.SS4.p1.8.m8.2.2.3.1.cmml">|</mo><mrow id="S3.SS4.p1.8.m8.2.2.2.2" xref="S3.SS4.p1.8.m8.2.2.2.2.cmml"><msub id="S3.SS4.p1.8.m8.2.2.2.2.5" xref="S3.SS4.p1.8.m8.2.2.2.2.5.cmml"><mi id="S3.SS4.p1.8.m8.2.2.2.2.5.2" xref="S3.SS4.p1.8.m8.2.2.2.2.5.2.cmml">S</mi><mi id="S3.SS4.p1.8.m8.2.2.2.2.5.3" xref="S3.SS4.p1.8.m8.2.2.2.2.5.3.cmml">j</mi></msub><mo id="S3.SS4.p1.8.m8.2.2.2.2.4" xref="S3.SS4.p1.8.m8.2.2.2.2.4.cmml">=</mo><mrow id="S3.SS4.p1.8.m8.2.2.2.2.3.3" xref="S3.SS4.p1.8.m8.2.2.2.2.3.4.cmml"><mo stretchy="false" id="S3.SS4.p1.8.m8.2.2.2.2.3.3.4" xref="S3.SS4.p1.8.m8.2.2.2.2.3.4.cmml">(</mo><msub id="S3.SS4.p1.8.m8.2.2.2.2.1.1.1" xref="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.cmml"><mi id="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.2" xref="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.2.cmml">p</mi><mi id="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.3" xref="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS4.p1.8.m8.2.2.2.2.3.3.5" xref="S3.SS4.p1.8.m8.2.2.2.2.3.4.cmml">,</mo><msub id="S3.SS4.p1.8.m8.2.2.2.2.2.2.2" xref="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.cmml"><mi id="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.2" xref="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.2.cmml">d</mi><mi id="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.3" xref="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.SS4.p1.8.m8.2.2.2.2.3.3.6" xref="S3.SS4.p1.8.m8.2.2.2.2.3.4.cmml">,</mo><msub id="S3.SS4.p1.8.m8.2.2.2.2.3.3.3" xref="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.cmml"><mi id="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.2" xref="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.2.cmml">s</mi><mi id="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.3" xref="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS4.p1.8.m8.2.2.2.2.3.3.7" xref="S3.SS4.p1.8.m8.2.2.2.2.3.4.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS4.p1.8.m8.2.2.2.5" xref="S3.SS4.p1.8.m8.2.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.8.m8.2b"><apply id="S3.SS4.p1.8.m8.2.2.3.cmml" xref="S3.SS4.p1.8.m8.2.2.2"><csymbol cd="latexml" id="S3.SS4.p1.8.m8.2.2.3.1.cmml" xref="S3.SS4.p1.8.m8.2.2.2.3">conditional-set</csymbol><apply id="S3.SS4.p1.8.m8.1.1.1.1.cmml" xref="S3.SS4.p1.8.m8.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.8.m8.1.1.1.1.1.cmml" xref="S3.SS4.p1.8.m8.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.8.m8.1.1.1.1.2.cmml" xref="S3.SS4.p1.8.m8.1.1.1.1.2">ğ‘†</ci><ci id="S3.SS4.p1.8.m8.1.1.1.1.3.cmml" xref="S3.SS4.p1.8.m8.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.SS4.p1.8.m8.2.2.2.2.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2"><eq id="S3.SS4.p1.8.m8.2.2.2.2.4.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.4"></eq><apply id="S3.SS4.p1.8.m8.2.2.2.2.5.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.5"><csymbol cd="ambiguous" id="S3.SS4.p1.8.m8.2.2.2.2.5.1.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.5">subscript</csymbol><ci id="S3.SS4.p1.8.m8.2.2.2.2.5.2.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.5.2">ğ‘†</ci><ci id="S3.SS4.p1.8.m8.2.2.2.2.5.3.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.5.3">ğ‘—</ci></apply><vector id="S3.SS4.p1.8.m8.2.2.2.2.3.4.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.3.3"><apply id="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.1.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.2.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.2">ğ‘</ci><ci id="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.3.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.1.1.1.3">ğ‘—</ci></apply><apply id="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.1.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.2.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.2">ğ‘‘</ci><ci id="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.3.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.2.2.2.3">ğ‘—</ci></apply><apply id="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.1.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.3.3.3">subscript</csymbol><ci id="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.2.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.2">ğ‘ </ci><ci id="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.3.cmml" xref="S3.SS4.p1.8.m8.2.2.2.2.3.3.3.3">ğ‘—</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.8.m8.2c">{\{S_{j}|S_{j}=(p_{j},d_{j},s_{j})\}}</annotation></semantics></math>, which can be further executed by robot suction cups.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">As Top-<span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_italic">k</span> suction poses are unaware of object identities, multiple suctions can be predicted on the same object. To avoid this, we propose <span id="S3.SS4.p2.1.2" class="ltx_text ltx_font_italic">Repetitive Suction Avoidance</span>, where we predict instance masks with MobileSAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and apply heuristic filters to ensure each object is only sucked once. At each timestep, if there exist valid and non-repetitive suction poses, one final suction pose will be selected and sent to the robot arm. It will be executed once the object appears in the end-effectorâ€™s workspace.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS5.5.1.1" class="ltx_text">III-E</span> </span><span id="S3.SS5.6.2" class="ltx_text ltx_font_italic">Synthetic Data Generation and Sim2real Gap Reduction</span>
</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Since our case is specific, no existing dataset can satisfy our needs. And as real-world data with annotations can be expensive and labor intensive, training on synthetic datasets is more costless and scalable. Hence, motivated byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, we propose an automatic data generation pipeline and a large-scale production line suction dataset, containing over 1000 production line layouts, 10000 multiview scenes, 300K images and 40M suction poses of diverse objects.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p">To generate the data, we first collect a wide range of CAD models and textures. Then we randomly place these objects on a moving production line in PyBullet simulatorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Based on simulation output, we render photo-realistic multiview RGB images, depth and normal maps in BlenderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. For suction annotation, we use APIs provided byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> to generate GT seal, wrench and collision scores. We then render the corresponding 2D seal maps using PyTorch3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Example data can be found in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I INTRODUCTION â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> upper right.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p id="S3.SS5.p3.1" class="ltx_p">To better bridge the sim2real gap, we leverage domain randomization to randomize object arrangements, illuminations, camera poses and backgrounds. Combining this with our finetuned <span id="S3.SS5.p3.1.1" class="ltx_text ltx_font_italic">DPT-Depth Module</span>, we largely reduce sim2real gaps, as models trained on our synthetic dataset can easily generalize to the real world and achieve higher performance than other methods, which will be covered in Section <a href="#S4" title="IV EXPERIMENTS â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">EXPERIMENTS</span>
</h2>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Evaluation for different methods in the simulation environment 
<br class="ltx_break">Each cell: transparent / mixed </figcaption>
<table id="S4.T1.6.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T1.6.6.6" class="ltx_tr">
<td id="S4.T1.6.6.6.7" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2">Metrics</td>
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">TSDF MAE <math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Surf. TSDF MAE <math id="S4.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T1.2.2.2.2.m1.1.1" xref="S4.T1.2.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Seal MAE <math id="S4.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.3.3.3.3.m1.1a"><mo stretchy="false" id="S4.T1.3.3.3.3.m1.1.1" xref="S4.T1.3.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.m1.1b"><ci id="S4.T1.3.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Collision Acc. (%) <math id="S4.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.4.4.4.4.m1.1a"><mo stretchy="false" id="S4.T1.4.4.4.4.m1.1.1" xref="S4.T1.4.4.4.4.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.m1.1b"><ci id="S4.T1.4.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">AP@Top-1 <math id="S4.T1.5.5.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.5.5.5.5.m1.1a"><mo stretchy="false" id="S4.T1.5.5.5.5.m1.1.1" xref="S4.T1.5.5.5.5.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.5.m1.1b"><ci id="S4.T1.5.5.5.5.m1.1.1.cmml" xref="S4.T1.5.5.5.5.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">AP@Top-5 <math id="S4.T1.6.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.6.6.6.6.m1.1a"><mo stretchy="false" id="S4.T1.6.6.6.6.m1.1.1" xref="S4.T1.6.6.6.6.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.6.m1.1b"><ci id="S4.T1.6.6.6.6.m1.1.1.cmml" xref="S4.T1.6.6.6.6.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T1.6.6.7" class="ltx_tr">
<td id="S4.T1.6.6.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T1.6.6.7.1.1" class="ltx_text">Seen</span></td>
<td id="S4.T1.6.6.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DPT-FusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S4.T1.6.6.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.73 / 2.88</td>
<td id="S4.T1.6.6.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.03 / 12.25</td>
<td id="S4.T1.6.6.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.7.5.1" class="ltx_text ltx_font_bold">0.018</span> / <span id="S4.T1.6.6.7.5.2" class="ltx_text ltx_font_bold">0.020</span>
</td>
<td id="S4.T1.6.6.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.93 / 94.44</td>
<td id="S4.T1.6.6.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.55 / 0.44</td>
<td id="S4.T1.6.6.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.55 / 0.42</td>
</tr>
<tr id="S4.T1.6.6.8" class="ltx_tr">
<td id="S4.T1.6.6.8.1" class="ltx_td ltx_align_center ltx_border_r">SuctionNeRFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T1.6.6.8.2" class="ltx_td ltx_align_center ltx_border_r">0.88 / 0.71</td>
<td id="S4.T1.6.6.8.3" class="ltx_td ltx_align_center ltx_border_r">3.09 / 2.03</td>
<td id="S4.T1.6.6.8.4" class="ltx_td ltx_align_center ltx_border_r">0.280 / 0.269</td>
<td id="S4.T1.6.6.8.5" class="ltx_td ltx_align_center ltx_border_r">95.89 / 95.25</td>
<td id="S4.T1.6.6.8.6" class="ltx_td ltx_align_center ltx_border_r">0.05 / 0.04</td>
<td id="S4.T1.6.6.8.7" class="ltx_td ltx_align_center ltx_border_r">0.05 / 0.04</td>
</tr>
<tr id="S4.T1.6.6.9" class="ltx_tr">
<td id="S4.T1.6.6.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Ours</td>
<td id="S4.T1.6.6.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.9.2.1" class="ltx_text ltx_font_bold">0.55</span> / <span id="S4.T1.6.6.9.2.2" class="ltx_text ltx_font_bold">0.47</span>
</td>
<td id="S4.T1.6.6.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.9.3.1" class="ltx_text ltx_font_bold">2.08</span> / <span id="S4.T1.6.6.9.3.2" class="ltx_text ltx_font_bold">1.43</span>
</td>
<td id="S4.T1.6.6.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.9.4.1" class="ltx_text ltx_font_bold">0.018</span> / <span id="S4.T1.6.6.9.4.2" class="ltx_text ltx_font_bold">0.020</span>
</td>
<td id="S4.T1.6.6.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.9.5.1" class="ltx_text ltx_font_bold">96.32</span> / <span id="S4.T1.6.6.9.5.2" class="ltx_text ltx_font_bold">95.68</span>
</td>
<td id="S4.T1.6.6.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.9.6.1" class="ltx_text ltx_font_bold">0.65</span> / <span id="S4.T1.6.6.9.6.2" class="ltx_text ltx_font_bold">0.80</span>
</td>
<td id="S4.T1.6.6.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.9.7.1" class="ltx_text ltx_font_bold">0.58</span> / <span id="S4.T1.6.6.9.7.2" class="ltx_text ltx_font_bold">0.71</span>
</td>
</tr>
<tr id="S4.T1.6.6.10" class="ltx_tr">
<td id="S4.T1.6.6.10.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T1.6.6.10.1.1" class="ltx_text">Similar</span></td>
<td id="S4.T1.6.6.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DPT-FusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S4.T1.6.6.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.12 / 3.78</td>
<td id="S4.T1.6.6.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">23.32 / 12.43</td>
<td id="S4.T1.6.6.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.10.5.1" class="ltx_text ltx_font_bold">0.025</span> / <span id="S4.T1.6.6.10.5.2" class="ltx_text ltx_font_bold">0.024</span>
</td>
<td id="S4.T1.6.6.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.36 / 94.60</td>
<td id="S4.T1.6.6.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.45 / 0.55</td>
<td id="S4.T1.6.6.10.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.30 / 0.56</td>
</tr>
<tr id="S4.T1.6.6.11" class="ltx_tr">
<td id="S4.T1.6.6.11.1" class="ltx_td ltx_align_center ltx_border_r">SuctionNeRFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T1.6.6.11.2" class="ltx_td ltx_align_center ltx_border_r">1.41 / 1.01</td>
<td id="S4.T1.6.6.11.3" class="ltx_td ltx_align_center ltx_border_r">4.02 / 2.52</td>
<td id="S4.T1.6.6.11.4" class="ltx_td ltx_align_center ltx_border_r">0.237 / 0.222</td>
<td id="S4.T1.6.6.11.5" class="ltx_td ltx_align_center ltx_border_r">95.29 / 95.69</td>
<td id="S4.T1.6.6.11.6" class="ltx_td ltx_align_center ltx_border_r">0.00 / 0.10</td>
<td id="S4.T1.6.6.11.7" class="ltx_td ltx_align_center ltx_border_r">0.10 / 0.07</td>
</tr>
<tr id="S4.T1.6.6.12" class="ltx_tr">
<td id="S4.T1.6.6.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Ours</td>
<td id="S4.T1.6.6.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.12.2.1" class="ltx_text ltx_font_bold">0.97</span> / <span id="S4.T1.6.6.12.2.2" class="ltx_text ltx_font_bold">0.65</span>
</td>
<td id="S4.T1.6.6.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.12.3.1" class="ltx_text ltx_font_bold">2.82</span> / <span id="S4.T1.6.6.12.3.2" class="ltx_text ltx_font_bold">1.59</span>
</td>
<td id="S4.T1.6.6.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.12.4.1" class="ltx_text ltx_font_bold">0.025</span> / <span id="S4.T1.6.6.12.4.2" class="ltx_text ltx_font_bold">0.024</span>
</td>
<td id="S4.T1.6.6.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.12.5.1" class="ltx_text ltx_font_bold">95.57</span> / <span id="S4.T1.6.6.12.5.2" class="ltx_text ltx_font_bold">96.51</span>
</td>
<td id="S4.T1.6.6.12.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.12.6.1" class="ltx_text ltx_font_bold">0.55</span> / <span id="S4.T1.6.6.12.6.2" class="ltx_text ltx_font_bold">0.85</span>
</td>
<td id="S4.T1.6.6.12.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.12.7.1" class="ltx_text ltx_font_bold">0.59</span> / <span id="S4.T1.6.6.12.7.2" class="ltx_text ltx_font_bold">0.81</span>
</td>
</tr>
<tr id="S4.T1.6.6.13" class="ltx_tr">
<td id="S4.T1.6.6.13.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T1.6.6.13.1.1" class="ltx_text">Novel</span></td>
<td id="S4.T1.6.6.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DPT-FusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S4.T1.6.6.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.30 / 3.23</td>
<td id="S4.T1.6.6.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">18.77 / 16.62</td>
<td id="S4.T1.6.6.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.13.5.1" class="ltx_text ltx_font_bold">0.032</span> / <span id="S4.T1.6.6.13.5.2" class="ltx_text ltx_font_bold">0.034</span>
</td>
<td id="S4.T1.6.6.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.08 / 93.06</td>
<td id="S4.T1.6.6.13.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.42 / 0.51</td>
<td id="S4.T1.6.6.13.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.22 / 0.43</td>
</tr>
<tr id="S4.T1.6.6.14" class="ltx_tr">
<td id="S4.T1.6.6.14.1" class="ltx_td ltx_align_center ltx_border_r">SuctionNeRFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T1.6.6.14.2" class="ltx_td ltx_align_center ltx_border_r">0.67 / 0.85</td>
<td id="S4.T1.6.6.14.3" class="ltx_td ltx_align_center ltx_border_r">2.43 / 3.14</td>
<td id="S4.T1.6.6.14.4" class="ltx_td ltx_align_center ltx_border_r">0.394 / 0.371</td>
<td id="S4.T1.6.6.14.5" class="ltx_td ltx_align_center ltx_border_r">95.56 / 93.20</td>
<td id="S4.T1.6.6.14.6" class="ltx_td ltx_align_center ltx_border_r">0.00 / 0.10</td>
<td id="S4.T1.6.6.14.7" class="ltx_td ltx_align_center ltx_border_r">0.06 / 0.07</td>
</tr>
<tr id="S4.T1.6.6.15" class="ltx_tr">
<td id="S4.T1.6.6.15.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Ours</td>
<td id="S4.T1.6.6.15.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.15.2.1" class="ltx_text ltx_font_bold">0.47</span> / <span id="S4.T1.6.6.15.2.2" class="ltx_text ltx_font_bold">0.59</span>
</td>
<td id="S4.T1.6.6.15.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.15.3.1" class="ltx_text ltx_font_bold">1.84</span> / <span id="S4.T1.6.6.15.3.2" class="ltx_text ltx_font_bold">2.19</span>
</td>
<td id="S4.T1.6.6.15.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.15.4.1" class="ltx_text ltx_font_bold">0.032</span> / <span id="S4.T1.6.6.15.4.2" class="ltx_text ltx_font_bold">0.034</span>
</td>
<td id="S4.T1.6.6.15.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.15.5.1" class="ltx_text ltx_font_bold">95.87</span> / <span id="S4.T1.6.6.15.5.2" class="ltx_text ltx_font_bold">93.34</span>
</td>
<td id="S4.T1.6.6.15.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.15.6.1" class="ltx_text ltx_font_bold">0.55</span> / <span id="S4.T1.6.6.15.6.2" class="ltx_text ltx_font_bold">0.80</span>
</td>
<td id="S4.T1.6.6.15.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.6.6.15.7.1" class="ltx_text ltx_font_bold">0.44</span> / <span id="S4.T1.6.6.15.7.2" class="ltx_text ltx_font_bold">0.65</span>
</td>
</tr>
</table>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we evaluate the performance of our proposed method for production line suction tasks in both simulation and real-world environments. We also perform ablation studies in the real world to analyze the effectiveness of different modules of our framework.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Implementation Details</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.4" class="ltx_p">As indicated in Section <a href="#S3" title="III METHOD â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, we set the size of the reconstruction zone grid as <math id="S4.SS1.p1.1.m1.2" class="ltx_Math" alttext="X=50,Y=40,Z=30" display="inline"><semantics id="S4.SS1.p1.1.m1.2a"><mrow id="S4.SS1.p1.1.m1.2.2.2" xref="S4.SS1.p1.1.m1.2.2.3.cmml"><mrow id="S4.SS1.p1.1.m1.1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.1.1.2.cmml">X</mi><mo id="S4.SS1.p1.1.m1.1.1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.1.m1.1.1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.1.1.3.cmml">50</mn></mrow><mo id="S4.SS1.p1.1.m1.2.2.2.3" xref="S4.SS1.p1.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.SS1.p1.1.m1.2.2.2.2.2" xref="S4.SS1.p1.1.m1.2.2.2.2.3.cmml"><mrow id="S4.SS1.p1.1.m1.2.2.2.2.1.1" xref="S4.SS1.p1.1.m1.2.2.2.2.1.1.cmml"><mi id="S4.SS1.p1.1.m1.2.2.2.2.1.1.2" xref="S4.SS1.p1.1.m1.2.2.2.2.1.1.2.cmml">Y</mi><mo id="S4.SS1.p1.1.m1.2.2.2.2.1.1.1" xref="S4.SS1.p1.1.m1.2.2.2.2.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.1.m1.2.2.2.2.1.1.3" xref="S4.SS1.p1.1.m1.2.2.2.2.1.1.3.cmml">40</mn></mrow><mo id="S4.SS1.p1.1.m1.2.2.2.2.2.3" xref="S4.SS1.p1.1.m1.2.2.2.2.3a.cmml">,</mo><mrow id="S4.SS1.p1.1.m1.2.2.2.2.2.2" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2.cmml"><mi id="S4.SS1.p1.1.m1.2.2.2.2.2.2.2" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2.2.cmml">Z</mi><mo id="S4.SS1.p1.1.m1.2.2.2.2.2.2.1" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2.1.cmml">=</mo><mn id="S4.SS1.p1.1.m1.2.2.2.2.2.2.3" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2.3.cmml">30</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.2b"><apply id="S4.SS1.p1.1.m1.2.2.3.cmml" xref="S4.SS1.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.2.2.3a.cmml" xref="S4.SS1.p1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS1.p1.1.m1.1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1"><eq id="S4.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.1"></eq><ci id="S4.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.2">ğ‘‹</ci><cn type="integer" id="S4.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.3">50</cn></apply><apply id="S4.SS1.p1.1.m1.2.2.2.2.3.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.2.2.2.2.3a.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS1.p1.1.m1.2.2.2.2.1.1.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.1.1"><eq id="S4.SS1.p1.1.m1.2.2.2.2.1.1.1.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.1.1.1"></eq><ci id="S4.SS1.p1.1.m1.2.2.2.2.1.1.2.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.1.1.2">ğ‘Œ</ci><cn type="integer" id="S4.SS1.p1.1.m1.2.2.2.2.1.1.3.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.1.1.3">40</cn></apply><apply id="S4.SS1.p1.1.m1.2.2.2.2.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2"><eq id="S4.SS1.p1.1.m1.2.2.2.2.2.2.1.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2.1"></eq><ci id="S4.SS1.p1.1.m1.2.2.2.2.2.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2.2">ğ‘</ci><cn type="integer" id="S4.SS1.p1.1.m1.2.2.2.2.2.2.3.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2.3">30</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.2c">X=50,Y=40,Z=30</annotation></semantics></math> in <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="cm" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><times id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></times><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">ğ‘</ci><ci id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">cm</annotation></semantics></math>, and the number of timesteps used in one reconstruction is <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="N=5" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">N</mi><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><eq id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></eq><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">ğ‘</ci><cn type="integer" id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">N=5</annotation></semantics></math>. We train our model for a maximum number of 300K iterations utilizing the Adam optimizerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> with a learning rate of <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mrow id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mn id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.4.m4.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.cmml">Ã—</mo><msup id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml"><mn id="S4.SS1.p1.4.m4.1.1.3.2" xref="S4.SS1.p1.4.m4.1.1.3.2.cmml">10</mn><mrow id="S4.SS1.p1.4.m4.1.1.3.3" xref="S4.SS1.p1.4.m4.1.1.3.3.cmml"><mo id="S4.SS1.p1.4.m4.1.1.3.3a" xref="S4.SS1.p1.4.m4.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS1.p1.4.m4.1.1.3.3.2" xref="S4.SS1.p1.4.m4.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><times id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1"></times><cn type="integer" id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">1</cn><apply id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.3.1.cmml" xref="S4.SS1.p1.4.m4.1.1.3">superscript</csymbol><cn type="integer" id="S4.SS1.p1.4.m4.1.1.3.2.cmml" xref="S4.SS1.p1.4.m4.1.1.3.2">10</cn><apply id="S4.SS1.p1.4.m4.1.1.3.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3.3"><minus id="S4.SS1.p1.4.m4.1.1.3.3.1.cmml" xref="S4.SS1.p1.4.m4.1.1.3.3"></minus><cn type="integer" id="S4.SS1.p1.4.m4.1.1.3.3.2.cmml" xref="S4.SS1.p1.4.m4.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">1\times 10^{-4}</annotation></semantics></math> and a learning rate decay of 0.5 per 100K iterations.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Experiment Setup</span>
</h3>

<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS1.5.1.1" class="ltx_text">IV-B</span>1 </span>Object Sets</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">In simulation, we utilize 160 hand-scale objects fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> and assign them with transparent textures. We then replenish the object set with 80 package objects of similar scales and assign them with diverse real-world textures in order to learn suction detection for practical industrial usage. FollowingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> andÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, objects are split into seen, similar, and novel sets. We train our model only on the seen set and test them on all three sets in novel arrangements to check the generalizability of our framework.</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p">In the real world, we gather around 30 different types of diverse objects, including transparent ones and other common items, to put on the production line. All the objects are unseen to our model so we split them into similar and novel sets based on their geometry, as shown in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I INTRODUCTION â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS2.5.1.1" class="ltx_text">IV-B</span>2 </span>Real Robot Setup</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">As in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I INTRODUCTION â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we set two RealSense D415 cameras diagonally to capture RGB images (depth is not used in our method) and set the speed of the production line to 100mm/s. For motion planning, since the objects are moving at a fixed speed, we utilize a heuristic algorithm that moves the robot arm above to track the suction position in the workspace. When the two trajectories coincide, the suction cup will push down to execute the suction.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">For the final suction pose selection from Top-<span id="S4.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_italic">k</span> proposals at each timestep, we take heights and directions of suction poses into account to adapt 6-DoF suction poses to our 4-DoF AtomRobot D3P-1100-P3 parallel robot arm. We set the timestep length to 1s, and the inference time of our whole pipeline is around 0.5s using a single GPU, leading to continuous and pipelined suctions on the production line in 1Hz, which is compatible with our robot armâ€™s cycle time.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Baseline Methods</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We compare our method with the following baselines in simulation or real-world environments.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">DPT-Fusion</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. As multiview depths can be directly used to fuse a TSDF in a non-learning way, we utilize the toolbox provided byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> to fuse a TSDF volume from predicted depths by finetuned DPTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> in place of our <span id="S4.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">Scene Geometry Reconstruction Module</span>. We utilize our <span id="S4.I1.i1.p1.1.3" class="ltx_text ltx_font_italic">2D SealNormNet</span> for seal and normal prediction.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">SuctionNeRF</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. Based on GraspNeRFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, a multiview 3D reconstruction and grasp detection framework using generalizable NeRF, we modify its VGNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> grasping detection head layer to predict seal, wrench and collision scores to adapt to our setting.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">SuctionNet</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. An object suction detection framework that takes RGBD images as input. It gets a partial point cloud from depth input and a 2D heatmap from RGBD input, and then executes suction by the heatmap scores and projected point coordinates.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">2D Object Detector</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. In industry, a common practice is to use a 2D object detector to detect objectsâ€™ centroids. To ensure generalizability, we utilize YOLOv8Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> for object detection and finetuned DPTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> for depth estimation.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_italic">Simulation Experiments</span>
</h3>

<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS1.5.1.1" class="ltx_text">IV-D</span>1 </span>Metrics</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.3" class="ltx_p">In simulation environments, we mainly focus on different methodsâ€™ performance on 3D object reconstruction and 6-DoF suction prediction precision, so we compare our method with DPT-FusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and SuctionNeRFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> using multiple metrics, including the <span id="S4.SS4.SSS1.p1.3.1" class="ltx_text ltx_font_bold">TSDF MAE</span> and <span id="S4.SS4.SSS1.p1.3.2" class="ltx_text ltx_font_bold">Surface TSDF MAE</span> (converted to millimeters) to evaluate reconstruction quality of the whole scene and object surfaces, <span id="S4.SS4.SSS1.p1.3.3" class="ltx_text ltx_font_bold">Seal MAE</span> to evaluate seal score prediction and <span id="S4.SS4.SSS1.p1.3.4" class="ltx_text ltx_font_bold">Collision Accuracy</span> to evaluate collision score prediction. FollowingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, we also evaluate the overall suction score prediction using <span id="S4.SS4.SSS1.p1.3.5" class="ltx_text ltx_font_bold">AP@Top-<span id="S4.SS4.SSS1.p1.3.5.1" class="ltx_text ltx_font_italic">k</span></span>, the average of <math id="S4.SS4.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\rm{AP}_{s}" display="inline"><semantics id="S4.SS4.SSS1.p1.1.m1.1a"><msub id="S4.SS4.SSS1.p1.1.m1.1.1" xref="S4.SS4.SSS1.p1.1.m1.1.1.cmml"><mi id="S4.SS4.SSS1.p1.1.m1.1.1.2" xref="S4.SS4.SSS1.p1.1.m1.1.1.2.cmml">AP</mi><mi mathvariant="normal" id="S4.SS4.SSS1.p1.1.m1.1.1.3" xref="S4.SS4.SSS1.p1.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p1.1.m1.1b"><apply id="S4.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p1.1.m1.1.1.1.cmml" xref="S4.SS4.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.SSS1.p1.1.m1.1.1.2.cmml" xref="S4.SS4.SSS1.p1.1.m1.1.1.2">AP</ci><ci id="S4.SS4.SSS1.p1.1.m1.1.1.3.cmml" xref="S4.SS4.SSS1.p1.1.m1.1.1.3">s</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p1.1.m1.1c">\rm{AP}_{s}</annotation></semantics></math> with threshold <math id="S4.SS4.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\rm{s}" display="inline"><semantics id="S4.SS4.SSS1.p1.2.m2.1a"><mi mathvariant="normal" id="S4.SS4.SSS1.p1.2.m2.1.1" xref="S4.SS4.SSS1.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p1.2.m2.1b"><ci id="S4.SS4.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS4.SSS1.p1.2.m2.1.1">s</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p1.2.m2.1c">\rm{s}</annotation></semantics></math> ranging from 0.2 to 0.8, with an interval of <math id="S4.SS4.SSS1.p1.3.m3.1" class="ltx_Math" alttext="\delta_{\rm{s}}=0.2" display="inline"><semantics id="S4.SS4.SSS1.p1.3.m3.1a"><mrow id="S4.SS4.SSS1.p1.3.m3.1.1" xref="S4.SS4.SSS1.p1.3.m3.1.1.cmml"><msub id="S4.SS4.SSS1.p1.3.m3.1.1.2" xref="S4.SS4.SSS1.p1.3.m3.1.1.2.cmml"><mi id="S4.SS4.SSS1.p1.3.m3.1.1.2.2" xref="S4.SS4.SSS1.p1.3.m3.1.1.2.2.cmml">Î´</mi><mi mathvariant="normal" id="S4.SS4.SSS1.p1.3.m3.1.1.2.3" xref="S4.SS4.SSS1.p1.3.m3.1.1.2.3.cmml">s</mi></msub><mo id="S4.SS4.SSS1.p1.3.m3.1.1.1" xref="S4.SS4.SSS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS4.SSS1.p1.3.m3.1.1.3" xref="S4.SS4.SSS1.p1.3.m3.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p1.3.m3.1b"><apply id="S4.SS4.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS4.SSS1.p1.3.m3.1.1"><eq id="S4.SS4.SSS1.p1.3.m3.1.1.1.cmml" xref="S4.SS4.SSS1.p1.3.m3.1.1.1"></eq><apply id="S4.SS4.SSS1.p1.3.m3.1.1.2.cmml" xref="S4.SS4.SSS1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p1.3.m3.1.1.2.1.cmml" xref="S4.SS4.SSS1.p1.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS4.SSS1.p1.3.m3.1.1.2.2.cmml" xref="S4.SS4.SSS1.p1.3.m3.1.1.2.2">ğ›¿</ci><ci id="S4.SS4.SSS1.p1.3.m3.1.1.2.3.cmml" xref="S4.SS4.SSS1.p1.3.m3.1.1.2.3">s</ci></apply><cn type="float" id="S4.SS4.SSS1.p1.3.m3.1.1.3.cmml" xref="S4.SS4.SSS1.p1.3.m3.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p1.3.m3.1c">\delta_{\rm{s}}=0.2</annotation></semantics></math>. We report the AP value under Top-1 and Top-5.</p>
</div>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS2.5.1.1" class="ltx_text">IV-D</span>2 </span>Results and Analysis</h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.1" class="ltx_p">As presented in Table <a href="#S4.T1" title="TABLE I â€£ IV EXPERIMENTS â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, in the simulation environment, our method outperforms all the baselines for all combinations of object sets (seen/similar/novel) and object types (transparent/mixed), demonstrating the superiority of our method.</p>
</div>
<div id="S4.SS4.SSS2.p2" class="ltx_para">
<p id="S4.SS4.SSS2.p2.1" class="ltx_p">Compared to non-learning DPT-Fusion, we perform significantly better due to our methodâ€™s great improvement in reconstruction quality, which verifies that our <span id="S4.SS4.SSS2.p2.1.1" class="ltx_text ltx_font_italic">Scene Geometry Reconstruction Module</span> can significantly reduce the inconsistency of multiple monocular depth estimations.</p>
</div>
<div id="S4.SS4.SSS2.p3" class="ltx_para">
<p id="S4.SS4.SSS2.p3.1" class="ltx_p">Also, compared to SuctionNeRF, our method improves reconstruction quality because of the prior knowledge on depth estimation embodied in the pretrained <span id="S4.SS4.SSS2.p3.1.1" class="ltx_text ltx_font_italic">DPT-Depth Module</span>. Moreover, better reconstruction quality benefits suction collision detection, as our method has better performance on collision accuracy.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Evaluation for different methods in the real world 
<br class="ltx_break">Each cell: transparent / mixed </figcaption>
<div id="S4.T2.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:182.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-19.5pt,8.2pt) scale(0.917503460689394,0.917503460689394) ;">
<table id="S4.T2.2.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.2.2.2.2" class="ltx_tr">
<td id="S4.T2.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2">Metrics</td>
<td id="S4.T2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SR (%) <math id="S4.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T2.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DR (%) <math id="S4.T2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.2.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T2.2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T2.2.2.2.3" class="ltx_tr">
<td id="S4.T2.2.2.2.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="5"><span id="S4.T2.2.2.2.3.1.1" class="ltx_text">Similar</span></td>
<td id="S4.T2.2.2.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DPT-FusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S4.T2.2.2.2.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13.76 / 27.64</td>
<td id="S4.T2.2.2.2.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">12.50 / 26.25</td>
</tr>
<tr id="S4.T2.2.2.2.4" class="ltx_tr">
<td id="S4.T2.2.2.2.4.1" class="ltx_td ltx_align_center ltx_border_r">SuctionNeRFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T2.2.2.2.4.2" class="ltx_td ltx_align_center ltx_border_r">48.78 / 42.56</td>
<td id="S4.T2.2.2.2.4.3" class="ltx_td ltx_align_center ltx_border_r">46.87 / 39.33</td>
</tr>
<tr id="S4.T2.2.2.2.5" class="ltx_tr">
<td id="S4.T2.2.2.2.5.1" class="ltx_td ltx_align_center ltx_border_r">SuctionNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S4.T2.2.2.2.5.2" class="ltx_td ltx_align_center ltx_border_r">27.27 / 40.00</td>
<td id="S4.T2.2.2.2.5.3" class="ltx_td ltx_align_center ltx_border_r">22.72 / 33.33</td>
</tr>
<tr id="S4.T2.2.2.2.6" class="ltx_tr">
<td id="S4.T2.2.2.2.6.1" class="ltx_td ltx_align_center ltx_border_r">2D Object DetectorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="S4.T2.2.2.2.6.2" class="ltx_td ltx_align_center ltx_border_r">27.77 / 28.57</td>
<td id="S4.T2.2.2.2.6.3" class="ltx_td ltx_align_center ltx_border_r">14.28 / 15.38</td>
</tr>
<tr id="S4.T2.2.2.2.7" class="ltx_tr">
<td id="S4.T2.2.2.2.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Ours</td>
<td id="S4.T2.2.2.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T2.2.2.2.7.2.1" class="ltx_text ltx_font_bold">87.64</span> / <span id="S4.T2.2.2.2.7.2.2" class="ltx_text ltx_font_bold">90.38</span>
</td>
<td id="S4.T2.2.2.2.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T2.2.2.2.7.3.1" class="ltx_text ltx_font_bold">70.90</span> / <span id="S4.T2.2.2.2.7.3.2" class="ltx_text ltx_font_bold">78.77</span>
</td>
</tr>
<tr id="S4.T2.2.2.2.8" class="ltx_tr">
<td id="S4.T2.2.2.2.8.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="5"><span id="S4.T2.2.2.2.8.1.1" class="ltx_text">Novel</span></td>
<td id="S4.T2.2.2.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DPT-FusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S4.T2.2.2.2.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.81 / 14.01</td>
<td id="S4.T2.2.2.2.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.38 / 12.71</td>
</tr>
<tr id="S4.T2.2.2.2.9" class="ltx_tr">
<td id="S4.T2.2.2.2.9.1" class="ltx_td ltx_align_center ltx_border_r">SuctionNeRFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T2.2.2.2.9.2" class="ltx_td ltx_align_center ltx_border_r">19.56 / 13.15</td>
<td id="S4.T2.2.2.2.9.3" class="ltx_td ltx_align_center ltx_border_r">19.14 / 11.36</td>
</tr>
<tr id="S4.T2.2.2.2.10" class="ltx_tr">
<td id="S4.T2.2.2.2.10.1" class="ltx_td ltx_align_center ltx_border_r">SuctionNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S4.T2.2.2.2.10.2" class="ltx_td ltx_align_center ltx_border_r">9.66 / 15.38</td>
<td id="S4.T2.2.2.2.10.3" class="ltx_td ltx_align_center ltx_border_r">8.10 / 12.50</td>
</tr>
<tr id="S4.T2.2.2.2.11" class="ltx_tr">
<td id="S4.T2.2.2.2.11.1" class="ltx_td ltx_align_center ltx_border_r">2D Object DetectorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="S4.T2.2.2.2.11.2" class="ltx_td ltx_align_center ltx_border_r">10.00 / 11.76</td>
<td id="S4.T2.2.2.2.11.3" class="ltx_td ltx_align_center ltx_border_r">10.00 / 9.75</td>
</tr>
<tr id="S4.T2.2.2.2.12" class="ltx_tr">
<td id="S4.T2.2.2.2.12.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Ours</td>
<td id="S4.T2.2.2.2.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T2.2.2.2.12.2.1" class="ltx_text ltx_font_bold">69.23</span> / <span id="S4.T2.2.2.2.12.2.2" class="ltx_text ltx_font_bold">85.52</span>
</td>
<td id="S4.T2.2.2.2.12.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T2.2.2.2.12.3.1" class="ltx_text ltx_font_bold">61.36</span> / <span id="S4.T2.2.2.2.12.3.2" class="ltx_text ltx_font_bold">73.86</span>
</td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS4.SSS2.p4" class="ltx_para">
<p id="S4.SS4.SSS2.p4.1" class="ltx_p">For seal prediction and AP@Top-<span id="S4.SS4.SSS2.p4.1.1" class="ltx_text ltx_font_italic">k</span>, our method greatly surpasses SuctionNeRF because instead of taking flawed TSDF as input, we predict seal scores in a 2D manner, which takes RGB as input so that the model can better learn local characteristics of object surfaces, which is crucial for seal scores. Our method also beats DPT-Fusion since our reconstruction quality is better.</p>
</div>
<div id="S4.SS4.SSS2.p5" class="ltx_para">
<p id="S4.SS4.SSS2.p5.1" class="ltx_p">In addition, our methodâ€™s improvement on similar and novel object sets demonstrates that our method has better generalizability due to our pretrained <span id="S4.SS4.SSS2.p5.1.1" class="ltx_text ltx_font_italic">DPT-Depth Module</span> and using predicted depth as input of 3D reconstruction.</p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.5.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.6.2" class="ltx_text ltx_font_italic">Real Robot Experiments</span>
</h3>

<figure id="S4.F3" class="ltx_figure"><img src="/html/2310.05717/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="118" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Visualization of TSDF reconstructed by different methods. The geometry from DPT-Fusion, which is directly fused from depth estimations has severe flaws, indicating that our method can greatly reduce the inconsistency of multiple monocular depth estimations. In comparison to SuctionNeRF, which uses direct RGB input and produces floaters in 3D reconstruction, our method results in more accurate reconstruction and better suction detection.
</figcaption>
</figure>
<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">We evaluate our method and all baselines in the real world with a production line and objects configured as in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I INTRODUCTION â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Each experiment consists of 3 rounds with each round featuring 120 objects which are sequentially placed in the same arrangement. A suction is considered successful if it removes the object from the production line.</p>
</div>
<section id="S4.SS5.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS5.SSS1.5.1.1" class="ltx_text">IV-E</span>1 </span>Metrics</h4>

<div id="S4.SS5.SSS1.p1" class="ltx_para">
<p id="S4.SS5.SSS1.p1.1" class="ltx_p">As the GT labels are not available in the real world, following<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, we measure the performance by <span id="S4.SS5.SSS1.p1.1.1" class="ltx_text ltx_font_bold">Success Rate (SR)</span>: the ratio of the successful suction number to the attempt number; and <span id="S4.SS5.SSS1.p1.1.2" class="ltx_text ltx_font_bold">Declutter Rate (DR)</span>: the average percentage of removed objects to all objects.</p>
</div>
</section>
<section id="S4.SS5.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS5.SSS2.5.1.1" class="ltx_text">IV-E</span>2 </span>Results and Analysis</h4>

<div id="S4.SS5.SSS2.p1" class="ltx_para">
<p id="S4.SS5.SSS2.p1.1" class="ltx_p">Table <a href="#S4.T2" title="TABLE II â€£ IV-D2 Results and Analysis â€£ IV-D Simulation Experiments â€£ IV EXPERIMENTS â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> presents SR &amp; DR of real-world object suction on the production line with the same objects and arrangements. Results show that our method beats all the baselines for all combinations of object sets (similar/novel) and object types (transparent/mixed). The great improvement in the novel object set also indicates our methodâ€™s generalizability. In addition, in Fig.Â <a href="#S4.F3" title="Figure 3 â€£ IV-E Real Robot Experiments â€£ IV EXPERIMENTS â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> we provide real-world reconstruction results using different methods.</p>
</div>
<div id="S4.SS5.SSS2.p2" class="ltx_para">
<p id="S4.SS5.SSS2.p2.1" class="ltx_p">Based on the results, it is clear that our approach performs much better than DPT-Fusion and SuctionNeRF, as explained in SectionÂ <a href="#S4.SS4.SSS2" title="IV-D2 Results and Analysis â€£ IV-D Simulation Experiments â€£ IV EXPERIMENTS â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-D</span>2</span></a>. Additionally, the visualization in Fig.Â <a href="#S4.F3" title="Figure 3 â€£ IV-E Real Robot Experiments â€£ IV EXPERIMENTS â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrates that our method can create more precise and superior 3D scenes in real-world settings. This is in contrast to other methods that generate artifacts or floaters that hinder wrench prediction and collision detection.</p>
</div>
<div id="S4.SS5.SSS2.p3" class="ltx_para">
<p id="S4.SS5.SSS2.p3.1" class="ltx_p">Compared to SuctionNet, which needs depth for input, our method performs significantly better in SR and DR, especially in transparent objects, indicating that errors in transparent object depths greatly harm the performance of RGBD-based methods.</p>
</div>
<div id="S4.SS5.SSS2.p4" class="ltx_para">
<p id="S4.SS5.SSS2.p4.1" class="ltx_p">Finally, our method outperforms the basic 2D object detector method because we leverage multi-timestep images to wholly reconstruct the scene, making it more capable of handling cluttered scenes. Also, rather than just selecting the centroids of objects, our method can better predict seal scores on objects, contributing to better performance.</p>
</div>
<div id="S4.SS5.SSS2.p5" class="ltx_para">
<p id="S4.SS5.SSS2.p5.1" class="ltx_p">However, we also notice some failure cases. For example, occasionally there will be a small offset in reconstruction and suction detection because of the unstable condition of production lines.</p>
</div>
</section>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS6.5.1.1" class="ltx_text">IV-F</span> </span><span id="S4.SS6.6.2" class="ltx_text ltx_font_italic">Ablation Studies</span>
</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">To analyze our method design, we conduct ablation studies on different configurations in the real world. As the effectiveness of our <span id="S4.SS6.p1.1.1" class="ltx_text ltx_font_italic">2D SealNormNet</span> has been analyzed at SectionÂ <a href="#S4.SS4.SSS2" title="IV-D2 Results and Analysis â€£ IV-D Simulation Experiments â€£ IV EXPERIMENTS â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-D</span>2</span></a>, this section focuses mainly on our <span id="S4.SS6.p1.1.2" class="ltx_text ltx_font_italic">Volumetric WrcColNet</span>. Results can be found in TableÂ <a href="#S4.T3" title="TABLE III â€£ IV-F Ablation Studies â€£ IV EXPERIMENTS â€£ STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects on Production Lines" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Ablation studies in the real world 
<br class="ltx_break">Each cell: transparent / mixed </figcaption>
<div id="S4.T3.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:261pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(82.2pt,-49.5pt) scale(1.6108027900073,1.6108027900073) ;">
<table id="S4.T3.2.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.2.2.2.2" class="ltx_tr">
<td id="S4.T3.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2">Metrics</td>
<td id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SR (%) <math id="S4.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T3.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T3.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DR (%) <math id="S4.T3.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.2.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T3.2.2.2.2.2.m1.1.1" xref="S4.T3.2.2.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.2.m1.1b"><ci id="S4.T3.2.2.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T3.2.2.2.3" class="ltx_tr">
<td id="S4.T3.2.2.2.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T3.2.2.2.3.1.1" class="ltx_text">Similar</span></td>
<td id="S4.T3.2.2.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">RGB</td>
<td id="S4.T3.2.2.2.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.37 / 74.71</td>
<td id="S4.T3.2.2.2.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.64 / 65.19</td>
</tr>
<tr id="S4.T3.2.2.2.4" class="ltx_tr">
<td id="S4.T3.2.2.2.4.1" class="ltx_td ltx_align_center ltx_border_r">w/o pretraining</td>
<td id="S4.T3.2.2.2.4.2" class="ltx_td ltx_align_center ltx_border_r">68.33 / 79.60</td>
<td id="S4.T3.2.2.2.4.3" class="ltx_td ltx_align_center ltx_border_r">58.15 / 72.62</td>
</tr>
<tr id="S4.T3.2.2.2.5" class="ltx_tr">
<td id="S4.T3.2.2.2.5.1" class="ltx_td ltx_align_center ltx_border_r">1/5 Data</td>
<td id="S4.T3.2.2.2.5.2" class="ltx_td ltx_align_center ltx_border_r">70.12 / 76.43</td>
<td id="S4.T3.2.2.2.5.3" class="ltx_td ltx_align_center ltx_border_r">49.09 / 62.82</td>
</tr>
<tr id="S4.T3.2.2.2.6" class="ltx_tr">
<td id="S4.T3.2.2.2.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Ours</td>
<td id="S4.T3.2.2.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T3.2.2.2.6.2.1" class="ltx_text ltx_font_bold">87.64</span> / <span id="S4.T3.2.2.2.6.2.2" class="ltx_text ltx_font_bold">90.38</span>
</td>
<td id="S4.T3.2.2.2.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T3.2.2.2.6.3.1" class="ltx_text ltx_font_bold">70.90</span> / <span id="S4.T3.2.2.2.6.3.2" class="ltx_text ltx_font_bold">78.77</span>
</td>
</tr>
<tr id="S4.T3.2.2.2.7" class="ltx_tr">
<td id="S4.T3.2.2.2.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T3.2.2.2.7.1.1" class="ltx_text">Novel</span></td>
<td id="S4.T3.2.2.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">RGB</td>
<td id="S4.T3.2.2.2.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50.94 / 52.08</td>
<td id="S4.T3.2.2.2.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48.21 / 42.01</td>
</tr>
<tr id="S4.T3.2.2.2.8" class="ltx_tr">
<td id="S4.T3.2.2.2.8.1" class="ltx_td ltx_align_center ltx_border_r">w/o pretraining</td>
<td id="S4.T3.2.2.2.8.2" class="ltx_td ltx_align_center ltx_border_r">50.00 / 51.85</td>
<td id="S4.T3.2.2.2.8.3" class="ltx_td ltx_align_center ltx_border_r">43.63 / 41.17</td>
</tr>
<tr id="S4.T3.2.2.2.9" class="ltx_tr">
<td id="S4.T3.2.2.2.9.1" class="ltx_td ltx_align_center ltx_border_r">1/5 Data</td>
<td id="S4.T3.2.2.2.9.2" class="ltx_td ltx_align_center ltx_border_r">60.00 / 70.00</td>
<td id="S4.T3.2.2.2.9.3" class="ltx_td ltx_align_center ltx_border_r">50.00 / 57.14</td>
</tr>
<tr id="S4.T3.2.2.2.10" class="ltx_tr">
<td id="S4.T3.2.2.2.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Ours</td>
<td id="S4.T3.2.2.2.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T3.2.2.2.10.2.1" class="ltx_text ltx_font_bold">69.23</span> / <span id="S4.T3.2.2.2.10.2.2" class="ltx_text ltx_font_bold">85.52</span>
</td>
<td id="S4.T3.2.2.2.10.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T3.2.2.2.10.3.1" class="ltx_text ltx_font_bold">61.36</span> / <span id="S4.T3.2.2.2.10.3.2" class="ltx_text ltx_font_bold">73.86</span>
</td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p">First, we examine the effect of taking depth maps as input to our <span id="S4.SS6.p2.1.1" class="ltx_text ltx_font_italic">Scene Geometry Reconstruction Module</span>. We change the moduleâ€™s input from predicted depth maps to raw RGB images, and the performance degradation indicates that removing redundant elements, such as textures and illuminations from input helps to bridge the sim2real gap.</p>
</div>
<div id="S4.SS6.p3" class="ltx_para">
<p id="S4.SS6.p3.1" class="ltx_p">Then we analyze the effect of the pretrained <span id="S4.SS6.p3.1.1" class="ltx_text ltx_font_italic">DPT-Depth Module</span> on <span id="S4.SS6.p3.1.2" class="ltx_text ltx_font_italic">MIX 6</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> dataset. Results show that compared with training <span id="S4.SS6.p3.1.3" class="ltx_text ltx_font_italic">DPT-Depth Module</span> from scratch, our method can better generalize to the real world due to the prior knowledge from pretraining.</p>
</div>
<div id="S4.SS6.p4" class="ltx_para">
<p id="S4.SS6.p4.1" class="ltx_p">To show the necessity of the large scale of our synthetic dataset, we cut down training data to 1/5 of the original data. The resulting decrease in performance highlights the significance of a large training data scale for model performance.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">CONCLUSIONS</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we propose STOPNet, a multiview RGB-based 3D reconstruction and 6-DoF suction detection framework for transparent objects on production lines. We also present a large-scale synthetic dataset and corresponding data generation pipeline for object suction on production lines. We also leverage multiple practices to reduce the sim2real gap. Experiments in simulation and the real world demonstrate our methodâ€™s superiority over current methods and great generalizability to the real world. We hope our work can benefit related research and industrial practices.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
L.Â DucÂ Hanh, N.Â Luat, and L.Â Bich, â€œCombining 3d matching and image moment based visual servoing for bin picking application,â€ <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">International Journal on Interactive Design and Manufacturing (IJIDeM)</em>, vol.Â 16, 03 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
S.Â Dâ€™Avella, C.Â A. Avizzano, and P.Â Tripicchio, â€œRos-industrial based robotic cell for industry 4.0: Eye-in-hand stereo camera and visual servoing for flexible, fast, and accurate picking and hooking in the production line,â€ <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Robotics and Computer-Integrated Manufacturing</em>, vol.Â 80, p. 102453, 2023. [Online]. Available: <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0736584522001351" title="" class="ltx_ref ltx_url">https://www.sciencedirect.com/science/article/pii/S0736584522001351</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M.Â Pfeffer, C.Â Goth, D.Â Craiovan, and J.Â Franke, â€œ3d-assembly of molded interconnect devices with standard smd pick &amp; place machines using an active multi axis workpiece carrier,â€ in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">2011 IEEE International Symposium on Assembly and Manufacturing (ISAM)</em>, 2011, pp. 1â€“6.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
R.Â Reif and W.Â A. GÃ¼nthner, â€œPick-by-vision: augmented reality supported order picking,â€ <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Vis. Comput.</em>, vol.Â 25, no. 5-7, pp. 461â€“467, 2009. [Online]. Available: <a target="_blank" href="https://doi.org/10.1007/s00371-009-0348-y" title="" class="ltx_ref ltx_url">https://doi.org/10.1007/s00371-009-0348-y</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
M.Â Naeem, S.Â Aslam, M.Â Suhaib, S.Â Gul, Z.Â Murtaza, and M.Â J. Khan, â€œDesign and implementation of pick and place manipulation system for industrial automation,â€ in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS)</em>, 2021, pp. 1â€“6.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
K.Â Castelli, A.Â M.Â A. Zaki, and H.Â Giberti, â€œDevelopment of a practical tool for designing multi-robot systems in pick-and-place applications,â€ <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Robotics</em>, vol.Â 8, no.Â 3, 2019. [Online]. Available: <a target="_blank" href="https://www.mdpi.com/2218-6581/8/3/71" title="" class="ltx_ref ltx_url">https://www.mdpi.com/2218-6581/8/3/71</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
I.Â Akinola, J.Â Xu, S.Â Song, and P.Â K. Allen, â€œDynamic grasping with reachability and motion awareness,â€ in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2021, pp. 9422â€“9429.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
A.Â Zeng, S.Â Song, K.-T. Yu, E.Â Donlon, F.Â R. Hogan, M.Â Bauza, D.Â Ma, O.Â Taylor, M.Â Liu, E.Â Romo, N.Â Fazeli, F.Â Alet, N.Â C. Dafle, R.Â Holladay, I.Â Morona, P.Â Q. Nair, D.Â Green, I.Â Taylor, W.Â Liu, T.Â Funkhouser, and A.Â Rodriguez, â€œRobotic pick-and-place of novel objects in clutter with multi-affordance grasping and cross-domain image matching,â€ <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">The International Journal of Robotics Research</em>, vol.Â 41, no.Â 7, pp. 690â€“705, 2022. [Online]. Available: <a target="_blank" href="https://doi.org/10.1177/0278364919868017" title="" class="ltx_ref ltx_url">https://doi.org/10.1177/0278364919868017</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J.Â Mahler, M.Â Matl, X.Â Liu, A.Â Li, D.Â Gealy, and K.Â Goldberg, â€œDex-net 3.0: Computing robust vacuum suction grasp targets in point clouds using a new analytic model and deep learning,â€ in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2018, pp. 5620â€“5627.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J.Â Mahler, M.Â Matl, V.Â Satish, M.Â Danielczuk, B.Â DeRose, S.Â McKinley, and K.Â Goldberg, â€œLearning ambidextrous robot grasping policies,â€ <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Science Robotics</em>, vol.Â 4, no.Â 26, p. eaau4984, 2019. [Online]. Available: <a target="_blank" href="https://www.science.org/doi/abs/10.1126/scirobotics.aau4984" title="" class="ltx_ref ltx_url">https://www.science.org/doi/abs/10.1126/scirobotics.aau4984</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H.Â Cao, H.-S. Fang, W.Â Liu, and C.Â Lu, â€œSuctionnet-1billion: A large-scale benchmark for suction grasping,â€ <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Robotics and Automation Letters</em>, vol.Â 6, no.Â 4, pp. 8718â€“8725, 2021.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Y.Â Fu, T.Â Sun, L.Â Wang, S.Â Yu, L.Â Deng, B.Â Chen, L.Â Li, Y.Â Xie, S.Â Deng, and H.Â Yin, â€œRgb-d instance segmentation-based suction point detection for grasping,â€ in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">2022 IEEE International Conference on Robotics and Biomimetics (ROBIO)</em>, 2022, pp. 1643â€“1650.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
S.Â Sajjan, M.Â Moore, M.Â Pan, G.Â Nagaraja, J.Â Lee, A.Â Zeng, and S.Â Song, â€œClear grasp: 3d shape estimation of transparent objects for manipulation,â€ in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2020, pp. 3634â€“3642.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
H.Â Fang, H.-S. Fang, S.Â Xu, and C.Â Lu, â€œTranscg: A large-scale real-world dataset for transparent object depth completion and a grasping baseline,â€ <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Robotics and Automation Letters</em>, vol.Â 7, no.Â 3, pp. 7383â€“7390, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Q.Â Dai, J.Â Zhang, Q.Â Li, T.Â Wu, H.Â Dong, Z.Â Liu, P.Â Tan, and H.Â Wang, â€œDomain randomization-enhanced depth simulation andÂ restoration forÂ perceiving andÂ grasping specular andÂ transparent objects,â€ in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Computer Vision â€“ ECCV 2022</em>, S.Â Avidan, G.Â Brostow, M.Â CissÃ©, G.Â M. Farinella, and T.Â Hassner, Eds.Â Â Â Cham: Springer Nature Switzerland, 2022, pp. 374â€“391.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
T.Â Weng, A.Â Pallankize, Y.Â Tang, O.Â Kroemer, and D.Â Held, â€œMulti-modal transfer learning for grasping transparent and specular objects,â€ <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Robotics and Automation Letters</em>, vol.Â 5, no.Â 3, pp. 3791â€“3798, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
H.Â Cao, J.Â Huang, Y.Â Li, J.Â Zhou, and Y.Â Liu, â€œFuzzy-depth objects grasping based on fsg algorithm and a soft robotic hand,â€ in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2021, pp. 3948â€“3954.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Z.Â Zhou, T.Â Pan, S.Â Wu, H.Â Chang, and O.Â C. Jenkins, â€œGlassloc: Plenoptic grasp pose detection in transparent clutter,â€ in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2019, pp. 4776â€“4783.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
J.Â Chang, M.Â Kim, S.Â Kang, H.Â Han, S.Â Hong, K.Â Jang, and S.Â Kang, â€œGhostpose: Multi-view pose estimation of transparent objects for robot hand grasping,â€ in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2021, pp. 5749â€“5755.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Q.Â Dai, Y.Â Zhu, Y.Â Geng, C.Â Ruan, J.Â Zhang, and H.Â Wang, â€œGraspnerf: Multiview-based 6-dof grasp detection for transparent and specular objects using generalizable nerf,â€ in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">2023 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023, pp. 1757â€“1763.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J.Â Hudoklin, S.Â Seo, M.Â Kang, H.Â Seong, A.Â T. Luong, and H.Â Moon, â€œVacuum suction cup modeling for evaluation of sealing and real-time simulation,â€ <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Robotics and Automation Letters</em>, vol.Â 7, no.Â 2, pp. 3616â€“3623, 2022.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
H.Â Lasi, P.Â Fettke, H.-G. Kemper, T.Â Feld, and M.Â Hoffmann, â€œIndustry 4.0,â€ <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Business &amp; Information Systems Engineering</em>, vol.Â 6, no.Â 4, pp. 239â€“242, Aug 2014. [Online]. Available: <a target="_blank" href="https://doi.org/10.1007/s12599-014-0334-4" title="" class="ltx_ref ltx_url">https://doi.org/10.1007/s12599-014-0334-4</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
R.Â Ranftl, A.Â Bochkovskiy, and V.Â Koltun, â€œVision transformers for dense prediction,â€ in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>, October 2021, pp. 12â€‰179â€“12â€‰188.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
P.Â Wang, L.Â Liu, Y.Â Liu, C.Â Theobalt, T.Â Komura, and W.Â Wang, â€œNeus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction,â€ in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, M.Â Ranzato, A.Â Beygelzimer, Y.Â Dauphin, P.Â Liang, and J.Â W. Vaughan, Eds., vol.Â 34.Â Â Â Curran Associates, Inc., 2021, pp. 27â€‰171â€“27â€‰183. [Online]. Available: <a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2021/file/e41e164f7485ec4a28741a2d0ea41c74-Paper.pdf" title="" class="ltx_ref ltx_url">https://proceedings.neurips.cc/paperË™files/paper/2021/file/e41e164f7485ec4a28741a2d0ea41c74-Paper.pdf</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
M.Â Breyer, J.Â J. Chung, L.Â Ott, R.Â Siegwart, and J.Â Nieto, â€œVolumetric grasping network: Real-time 6 dof grasp detection in clutter,â€ in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Robot Learning</em>, ser. Proceedings of Machine Learning Research, J.Â Kober, F.Â Ramos, and C.Â Tomlin, Eds., vol. 155.Â Â Â PMLR, 16â€“18 Nov 2021, pp. 1602â€“1611. [Online]. Available: <a target="_blank" href="https://proceedings.mlr.press/v155/breyer21a.html" title="" class="ltx_ref ltx_url">https://proceedings.mlr.press/v155/breyer21a.html</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
W.Â E. Lorensen and H.Â E. Cline, â€œMarching cubes: A high resolution 3d surface construction algorithm.â€ in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">SIGGRAPH</em>, M.Â C. Stone, Ed.Â Â Â ACM, 1987, pp. 163â€“169. [Online]. Available: <a target="_blank" href="http://dblp.uni-trier.de/db/conf/siggraph/siggraph1987.html#LorensenC87" title="" class="ltx_ref ltx_url">http://dblp.uni-trier.de/db/conf/siggraph/siggraph1987.html#LorensenC87</a>

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
C.Â Zhang, D.Â Han, Y.Â Qiao, J.Â U. Kim, S.-H. Bae, S.Â Lee, and C.Â S. Hong, â€œFaster segment anything: Towards lightweight sam for mobile applications,â€ <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.14289</em>, 2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
E.Â Coumans and Y.Â Bai, â€œPybullet, a python module for physics simulation for games, robotics and machine learning,â€ <a target="_blank" href="http://pybullet.org" title="" class="ltx_ref ltx_url">http://pybullet.org</a>, 2016â€“2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
B.Â O. Community, <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Blender - a 3D modelling and rendering package</em>, Blender Foundation, Stichting Blender Foundation, Amsterdam, 2018. [Online]. Available: <a target="_blank" href="http://www.blender.org" title="" class="ltx_ref ltx_url">http://www.blender.org</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
N.Â Ravi, J.Â Reizenstein, D.Â Novotny, T.Â Gordon, W.-Y. Lo, J.Â Johnson, and G.Â Gkioxari, â€œAccelerating 3d deep learning with pytorch3d,â€ <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv:2007.08501</em>, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
D.Â P. Kingma and J.Â Ba, â€œAdam: A method for stochastic optimization,â€ in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings</em>, Y.Â Bengio and Y.Â LeCun, Eds., 2015. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1412.6980" title="" class="ltx_ref ltx_url">http://arxiv.org/abs/1412.6980</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Z.Â Jiang, Y.Â Zhu, M.Â Svetlik, K.Â Fang, and Y.Â Zhu, â€œSynergies between affordance and geometry: 6-dof grasp detection via implicit representations,â€ in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Robotics: Science and Systems XVII, Virtual Event, July 12-16, 2021</em>, D.Â A. Shell, M.Â Toussaint, and M.Â A. Hsieh, Eds., 2021. [Online]. Available: <a target="_blank" href="https://doi.org/10.15607/RSS.2021.XVII.024" title="" class="ltx_ref ltx_url">https://doi.org/10.15607/RSS.2021.XVII.024</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
H.-S. Fang, C.Â Wang, M.Â Gou, and C.Â Lu, â€œGraspnet-1billion: A large-scale benchmark for general object grasping,â€ in <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, June 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
A.Â Zeng, S.Â Song, M.Â Niessner, M.Â Fisher, J.Â Xiao, and T.Â Funkhouser, â€œ3dmatch: Learning local geometric descriptors from rgb-d reconstructions,â€ in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, July 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
G.Â Jocher, A.Â Chaurasia, and J.Â Qiu, â€œYOLO by Ultralytics,â€ Jan. 2023. [Online]. Available: <a target="_blank" href="https://github.com/ultralytics/ultralytics" title="" class="ltx_ref ltx_url">https://github.com/ultralytics/ultralytics</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.05715" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.05717" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.05717">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.05717" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.05718" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 01:21:32 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
