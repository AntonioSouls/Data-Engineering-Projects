<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2304.01838] BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection</title><meta property="og:description" content="Progress in 3D volumetric image analysis research is limited by the lack of datasets and most advances in analysis methods for volumetric images are based on medical data. However, medical data do not necessarily resem…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2304.01838">

<!--Generated on Thu Feb 29 16:14:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">BugNIST: A New Large Scale Volumetric 3D Image Dataset 
<br class="ltx_break">for Classification and Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anders Bjorholm Dahl
<br class="ltx_break">Technical University of Denmark
<br class="ltx_break">Richard Petersens Plads
<br class="ltx_break"><span id="id3.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">abda@dtu.dk</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Patrick Møller Jensen
<br class="ltx_break"><span id="id4.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">patmjen@dtu.dk</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Carsten Gundlach
<br class="ltx_break"><span id="id5.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">cagu@fysik.dtu.dk</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rebecca Engberg
<br class="ltx_break"><span id="id6.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">reen@dtu.dk</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hans Martin Kjer
<br class="ltx_break"><span id="id7.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">hmkj@dtu.dk</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vedrana Andersen Dahl
<br class="ltx_break"><span id="id8.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">vand@dtu.dk</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">Progress in 3D volumetric image analysis research is limited by the lack of datasets and most advances in analysis methods for volumetric images are based on medical data. However, medical data do not necessarily resemble the characteristics of other volumetric images such as µCT. To promote research in 3D volumetric image analysis beyond medical data, we have created the BugNIST dataset and made it freely available. BugNIST is an extensive dataset of µCT scans of 12 types of bugs, such as insects and larvae. BugNIST contains 9437 volumes where 9087 are of individual bugs and 350 are mixtures of bugs and other material. The goal of BugNIST is to benchmark classification and detection methods, and we have designed the detection challenge such that detection models are trained on scans of individual bugs and tested on bug mixtures. Models capable of solving this task will be independent of the context, i.e., the surrounding material. This is a great advantage if the context is unknown or changing, as is often the case in µCT. Our initial baseline analysis shows that current state-of-the-art deep learning methods classify individual bugs very well, but has great difficulty with the detection challenge. Hereby, BugNIST enables research in image analysis areas that until now have missed relevant data — both classification, detection, and hopefully more.</p>
</div>
<div id="id2" class="ltx_logical-block">
<div id="id2.p1" class="ltx_para">
<svg id="id1.pic1" class="ltx_picture ltx_centering" height="300.75" overflow="visible" version="1.1" width="675.28"><g transform="translate(0,300.75) matrix(1 0 0 -1 0 0) translate(-26.56,0) translate(0,224.48)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#000000" fill="#000000" color="#000000"><path d="M 32.1 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 46.11 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="19.99" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.37.37.37.1.1" class="ltx_text ltx_font_bold">AC</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 32.1 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/AC_crop.png" id="id1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 32.1 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_AC.png" id="id1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 32.1 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_AC.png" id="id1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 88.2 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 102.31 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="19.79" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.38.38.38.1.1" class="ltx_text ltx_font_bold">BC</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 88.2 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/BC_crop.png" id="id1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 88.2 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_BC.png" id="id1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 88.2 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_BC.png" id="id1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 144.31 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 158.89 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="18.83" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.39.39.39.1.1" class="ltx_text ltx_font_bold">BF</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 144.31 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/BF_crop.png" id="id1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 144.31 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_BF.png" id="id1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 144.31 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_BF.png" id="id1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 200.41 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 215.18 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="18.45" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.40.40.40.1.1" class="ltx_text ltx_font_bold">BL</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 200.41 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/BL_crop.png" id="id1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 200.41 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_BL.png" id="id1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 200.41 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_BL.png" id="id1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 256.51 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 270.9 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="19.22" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.41.41.41.1.1" class="ltx_text ltx_font_bold">BP</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 256.51 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/BP_crop.png" id="id1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 256.51 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_BP.png" id="id1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 256.51 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_BP.png" id="id1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 312.61 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 327.1 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="19.03" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.42.42.42.1.1" class="ltx_text ltx_font_bold">CF</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 312.61 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/CF_crop.png" id="id1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 312.61 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_CF.png" id="id1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 312.61 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_CF.png" id="id1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 368.72 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 382.1 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="21.24" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.43.43.43.1.1" class="ltx_text ltx_font_bold">GH</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 368.72 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/GH_crop.png" id="id1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 368.72 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_GH.png" id="id1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 368.72 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_GH.png" id="id1.pic1.21.21.21.21.21.21.21.21.21.21.21.21.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 424.82 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 437.29 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="23.06" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.44.44.44.1.1" class="ltx_text ltx_font_bold">MA</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 424.82 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/MA_crop.png" id="id1.pic1.22.22.22.22.22.22.22.22.22.22.22.22.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 424.82 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_MA.png" id="id1.pic1.23.23.23.23.23.23.23.23.23.23.23.23.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 424.82 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_MA.png" id="id1.pic1.24.24.24.24.24.24.24.24.24.24.24.24.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 480.92 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 494.26 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="21.33" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.45.45.45.1.1" class="ltx_text ltx_font_bold">ML</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 480.92 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/ML_crop.png" id="id1.pic1.25.25.25.25.25.25.25.25.25.25.25.25.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 480.92 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_ML.png" id="id1.pic1.26.26.26.26.26.26.26.26.26.26.26.26.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 480.92 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_ML.png" id="id1.pic1.27.27.27.27.27.27.27.27.27.27.27.27.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 537.02 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 551.61 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="18.83" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.46.46.46.1.1" class="ltx_text ltx_font_bold">PP</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 537.02 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/PP_crop.png" id="id1.pic1.28.28.28.28.28.28.28.28.28.28.28.28.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 537.02 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_PP.png" id="id1.pic1.29.29.29.29.29.29.29.29.29.29.29.29.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 537.02 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_PP.png" id="id1.pic1.30.30.30.30.30.30.30.30.30.30.30.30.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 593.13 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 608.96 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="16.34" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.47.47.47.1.1" class="ltx_text ltx_font_bold">SL</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 593.13 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/SL_crop.png" id="id1.pic1.31.31.31.31.31.31.31.31.31.31.31.31.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 593.13 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_SL.png" id="id1.pic1.32.32.32.32.32.32.32.32.32.32.32.32.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 593.13 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_SL.png" id="id1.pic1.33.33.33.33.33.33.33.33.33.33.33.33.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g stroke="#000000" fill="#000000" color="#000000"><path d="M 649.23 57.59 h 48 v 18.68 h -48 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 660.93 62.2)" fill="#FFFFFF" stroke="#FFFFFF" color="#000000"><foreignObject width="24.6" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="id1.pic1.48.48.48.1.1" class="ltx_text ltx_font_bold">WO</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 649.23 -48)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/cropped/WO_crop.png" id="id1.pic1.34.34.34.34.34.34.34.34.34.34.34.34.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 649.23 -160.2)" fill="#000000" stroke="#000000"><foreignObject width="48" height="96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/max_WO.png" id="id1.pic1.35.35.35.35.35.35.35.35.35.35.35.35.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="48" height="96" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 649.23 -219.87)" fill="#000000" stroke="#000000"><foreignObject width="48" height="48" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration2/slices/crossmax_WO.png" id="id1.pic1.36.36.36.36.36.36.36.36.36.36.36.36.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="48" height="48" alt="[Uncaptioned image]"></foreignObject></g><g transform="matrix(0.8 0.0 0.0 0.8 30.25 43.82)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(brown cricket)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 87.98 43.82)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(black cricket)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 151.84 43.82)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(blow fly)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 203.3 36.07)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 16.535)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 11.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 9.97 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(buffalo</text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 18.95)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">beetle larva)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 254.36 43.82)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(blow fly pupa)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 310.24 43.82)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(curly-wing fly)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 369.51 43.82)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(grasshopper)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 433.32 43.82)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(maggot)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 484.57 43.82)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(mealworm)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 539.17 36.07)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 16.535)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 11.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(green bottle</text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 18.95)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 7.95 0)"><text transform="matrix(1 0 0 -1 0 0)">fly pupa)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 601.73 36.07)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 16.535)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 11.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 1.99 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(soldier </text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 18.95)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">fly larva)</text></g></g></g></g><g transform="matrix(0.8 0.0 0.0 0.8 655.69 43.82)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.845)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">(woodlice)</text></g></g></g></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 38.1 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 46.76 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.49.49.49.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">724</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 94.2 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 102.86 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.50.50.50.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">804</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 150.31 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 158.97 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.51.51.51.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">734</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 206.41 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 215.07 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.52.52.52.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">780</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 262.51 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 271.17 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.53.53.53.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">752</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 318.61 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 327.27 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.54.54.54.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">756</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 374.72 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 383.38 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.55.55.55.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">760</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 430.82 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 439.48 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.56.56.56.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">765</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 486.92 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 495.58 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.57.57.57.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">738</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 543.02 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 551.68 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.58.58.58.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">769</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 599.13 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 607.79 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.59.59.59.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">740</span></foreignObject></g><g fill="#FFFFFF" fill-opacity="0.5" stroke-opacity="0.5"><path d="M 655.23 -52.64 h 36 v 10.79 h -36 Z" style="stroke:none"></path></g><g stroke-opacity="0.5" fill="#000000" fill-opacity="0.5" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 663.89 -51.26)"><foreignObject width="18.68" height="8.03" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="id1.pic1.60.60.60.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">765</span></foreignObject></g></g></svg>
</div>
<figure id="S0.F1" class="ltx_figure ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S0.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S0.F1.3.2" class="ltx_text" style="font-size:90%;">Overview of the BugNIST classification data. Each column is one of the 12 classes. Under class abbreviation are (top to bottom) volume rendering, frontal max projection, and top-view max projection of a representative bug. In red is the number of bugs in each class.</span></figcaption>
</figure>
</div>
<figure id="S0.F2" class="ltx_figure"><svg id="S0.F2.1.pic1" class="ltx_picture ltx_centering" height="211.96" overflow="visible" version="1.1" width="652"><g transform="translate(0,211.96) matrix(1 0 0 -1 0 0) translate(75.67,0) translate(0,105.98)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -71.06 -92.5)" fill="#000000" stroke="#000000"><foreignObject width="150" height="185" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partA_try2.png" id="S0.F2.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="150" height="185" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 101.61 -100.87)" fill="#000000" stroke="#000000"><foreignObject width="33" height="60" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partB_G000.png" id="S0.F2.1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="33" height="60" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 101.61 -30)" fill="#000000" stroke="#000000"><foreignObject width="33" height="60" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partB_G001.png" id="S0.F2.1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="33" height="60" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 101.61 40.87)" fill="#000000" stroke="#000000"><foreignObject width="33" height="60" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partB_G002.png" id="S0.F2.1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="33" height="60" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 142.95 -100.87)" fill="#000000" stroke="#000000"><foreignObject width="33" height="60" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partB_G003.png" id="S0.F2.1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="33" height="60" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 142.95 -30)" fill="#000000" stroke="#000000"><foreignObject width="33" height="60" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partB_G004.png" id="S0.F2.1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="33" height="60" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 142.95 40.87)" fill="#000000" stroke="#000000"><foreignObject width="33" height="60" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partB_G005.png" id="S0.F2.1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="33" height="60" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 184.29 -100.87)" fill="#000000" stroke="#000000"><foreignObject width="33" height="60" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partB_G006.png" id="S0.F2.1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="33" height="60" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 184.29 -30)" fill="#000000" stroke="#000000"><foreignObject width="33" height="60" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partB_G007.png" id="S0.F2.1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="33" height="60" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 184.29 40.87)" fill="#000000" stroke="#000000"><foreignObject width="33" height="60" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partB_G008.png" id="S0.F2.1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="33" height="60" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 255.71 -92.5)" fill="#000000" stroke="#000000"><foreignObject width="150" height="185" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partC_try1.png" id="S0.F2.1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="150" height="185" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 420.41 40.37)" fill="#000000" stroke="#000000"><foreignObject width="45" height="61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partD_M000.png" id="S0.F2.1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="45" height="61" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 420.41 -30.5)" fill="#000000" stroke="#000000"><foreignObject width="45" height="61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partD_M009.png" id="S0.F2.1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="45" height="61" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 420.41 -101.37)" fill="#000000" stroke="#000000"><foreignObject width="45" height="61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partD_M002.png" id="S0.F2.1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="45" height="61" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 473.56 40.37)" fill="#000000" stroke="#000000"><foreignObject width="45" height="61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partD_M003.png" id="S0.F2.1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="45" height="61" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 473.56 -30.5)" fill="#000000" stroke="#000000"><foreignObject width="45" height="61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partD_M004.png" id="S0.F2.1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="45" height="61" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 473.56 -101.37)" fill="#000000" stroke="#000000"><foreignObject width="45" height="61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partD_M010.png" id="S0.F2.1.pic1.17.17.17.17.17.17.17.17.17.17.17.17.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="45" height="61" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 526.71 40.37)" fill="#000000" stroke="#000000"><foreignObject width="45" height="61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partD_M006.png" id="S0.F2.1.pic1.18.18.18.18.18.18.18.18.18.18.18.18.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="45" height="61" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 526.71 -30.5)" fill="#000000" stroke="#000000"><foreignObject width="45" height="61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partD_M007.png" id="S0.F2.1.pic1.19.19.19.19.19.19.19.19.19.19.19.19.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="45" height="61" alt="Refer to caption"></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 526.71 -101.37)" fill="#000000" stroke="#000000"><foreignObject width="45" height="61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><img src="/html/2304.01838/assets/images/illustration1/partD_M008.png" id="S0.F2.1.pic1.20.20.20.20.20.20.20.20.20.20.20.20.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="45" height="61" alt="Refer to caption"></foreignObject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S0.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S0.F2.4.2" class="ltx_text" style="font-size:90%;">Illustration of the setup for data acquisition. The left image shows the volume of straws containing the bugs, here grasshoppers, which are segmented into the volumes shown as small volumes. The cotton is seen as a gray shadow. The middle right image shows the setup with mixtures and how they are segmented into individual volumes shown far right. In the example shown here, the mixtures are made of only cotton and bugs. </span></figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">We contribute BugNIST <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The BugNIST dataset is available from: <a target="_blank" href="https://qim.dk/bugnist/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://qim.dk/bugnist/</a></span></span></span> – a comprehensive and freely available 3D volumetric image dataset aimed at benchmarking deep learning algorithms. The name, BugNIST, is inspired by the influential MNIST dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>. MNIST has been a driver for developing and testing deep learning methods, especially because of the small size and large number of images. BugNIST is made up of 3D µCT scans of 12 types of bugs. Besides being 3D, the scans are also significantly larger than the small MNIST images, but due to modern hardware, BugNIST volumes are still easily accessible. The bugs we have scanned include insects, larvae, pupae, and woodlice, both as individual bugs and in mixtures. With 9437 volumes, BugNIST is, to our knowledge, the first large-size non-medical volumetric image dataset targeted for benchmarking deep learning methods. Hereby, BugNIST can be a foundation for advancing the field of volumetric 3D deep learning methods.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">There is currently a shortage of volumetric 3D data for benchmarking deep neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>]</cite>, and the most available 3D data is medical. This limits the options in developing new deep learning-based methods for analyzing 3D volumes, especially on non-medical data. There is, however, a great need for efficient techniques to analyze volumetric imaging data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">42</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite>. BugNIST is created to meet this need and is developed specifically for object classification and detection in 3D volumetric images.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The 12 groups of individually scanned bugs in BugNIST are evenly distributed with 700-800 volumes of each group, see <a href="#S0.F1" title="In BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>. In the additional 350 volumes with mixtures of bugs and other materials, we have counted the number of bugs and their type. For 45 of the mixtures, we have also annotated the center positions of the bugs. For the individual bugs, the challenge is to classify volumes into the respective groups, and for the mixed volumes, the challenge is to detect, classify, and count the bugs.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The detection and counting challenge that we pose here is special in that the detection algorithm should be trained on the scans of individual bugs alone and tested on counting and detecting bugs in the mixtures. This makes BugNIST unique and the first to pose a detection challenge in volumetric images using this approach with such an extensive set of training data. The benefit of posing the challenge this way is model generalizability. When solving the BugNIST detection problem, methods will be forced to learn the object’s appearance and not the appearance of the context surrounding the objects, which will make the detection invariant to changes in the surrounding context. As we will show, this dramatically challenges state-of-the-art deep learning detection methods.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Data is a driver for developing machine learning and especially deep learning methods. Since research in data-driven methods is dominating computer vision, most advances are seen in areas with good datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite>. This also means that less attention is given to areas with limited or no data available.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The generic nature of deep learning allows models created for one type of data to be applied to other data types. E.g. methods developed for solving problems related to ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>]</cite> or COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite> have been applied to volumetric data. However, this transfer of domains is sub-optimal as the characteristics of volumetric data are different from photographs. Volumetric data is obtained by scanning and the voxel size is typically given by the scanning setup. In most cases, there will also be much knowledge about the sample and expected voxel intensities. This is not the case in photographs, where illumination and scale typically vary. In this respect, volumes are simpler than photos, but the fact that the volumes are 3D adds complexity. Furthermore, volumetric data is often limited by noise and resolution. From a user perspective, the 3D property makes volumetric images complex to visualize and inspect. Considering these characteristics when developing volumetric analysis methods has the potential for better-performing methods.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The majority of volumetric image datasets come from the medical domain, especially from clinical 3D CT and MRI scanners. Deep learning methods for the analysis of volumetric images are primarily developed for medical problems and there is extensive research in deep learning for medical volumetric images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>. Much medical data is difficult to use due to privacy concerns making data-handling cumbersome. To some extent, one would assume that the methods developed for volumetric medical data also can be applied to other types of 3D data. But it turns out that the use of deep learning for non-medical volumetric data is limited <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite>, and the question is why this is the case.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">There are important differences in structures and analysis problems between medical data and for example µCT data, which might be one reason for the limited use of deep learning. Medical data is acquired following specific protocols that allow for investigating and diagnosing patients, whereas µCT or electron microscopy is often used for inspecting new structures, making this type of data unique. To provide solutions for such problems based on deep learning, there is a need for a new type of volumetric datasets that will allow for developing deep learning methods targeting new types of problems.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">There is already much volumetric image data available, and it is easy to find datasets on platforms like Zenodo<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://zenodo.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://zenodo.org/</a></span></span></span> or TomoBank<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://tomobank.readthedocs.io/en/latest/index.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://tomobank.readthedocs.io/en/latest/index.html</a></span></span></span>. However, most of this data is not in a processed format nor of a type that makes it easy to use for deep learning. Often this data comes with no clear problem formulation or well-defined tasks that allow for a comparison of methods, and the data is typically very large volumes that are difficult to access. It can also be difficult to judge the complexity of the data, and analysis might either be very easy or extremely difficult. This makes it less suitable to use for developing new deep learning methods, and therefore much less attractive to employ for developing new analysis methods compared to standard benchmark data.</p>
</div>
<div id="S1.p10" class="ltx_para">
<p id="S1.p10.1" class="ltx_p">Many 2D computer vision datasets address challenges for classification, detection, segmentation, etc., but for 3D volumetric data, most datasets focus on segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite>. Segmentation has the advantage that it allows for solving many problems, but it typically comes with the price of expensive annotations. But similar to 2D computer vision, one would also like to answer questions such as if an object is present and where it is. Datasets for object detection in volumetric data are less common than segmentation datasets, especially for non-medical data. The BugNIST dataset, which is the main contribution of this paper, provides a challenge for classification and detection, and there are other uses such as segmentation, geometric analysis, 3D generative models (GANs), etc. that we have not explored in this paper. Often, classification and detection tasks are useful for pretraining models, and the size of BugNIST could be useful for that.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In computer vision, the term 3D images cover different types of data and include point clouds, surfaces, volumes, color+depth, etc. Here we are only concerned with 3D volumes, i.e. images represented on a voxel grid.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">BugNIST is created to test classification and object counting and detection. Classification is a well-defined problem with a clear goal, but for volumetric data, classification is less common than detection and especially segmentation. In, for example, medical image datasets, classification makes up 10% of tasks, whereas segmentation accounts for 70% of tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>. In volumetric medical data, classification is used, for example, for diagnosis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>, <a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>, <a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>]</cite>. One classification example outside the medical field is baggage security screening <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>, <a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite> where object classification of prohibited items is used. When it is possible to formulate an analysis problem as a classification task, performance is usually high and
often with an accuracy above 90%. However, object detection is difficult to formulate as a classification problem. Instead, we need to employ a model that is targeted for object detection.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Counting is done by assessing the number and type of the objects whereas, for object detection, each object must also be located. Object detection is extensively explored for 2D images, where it has numerous applications. Deep learning models are dominating, and most models either use a two-stage detector such as R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>, <a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite>, with a region proposal and a classifier to choose among the proposed regions, or a one-stage detector such as YOLO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>]</cite>, where regions and classes are proposed in a single network. Object detection in volumetric images is less common.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">3D object detection can be formulated as a segmentation task using, for example, a 3D U-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite> where each connected component of the foreground label class is a detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>. An example is lung nodule detection in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite>. Employing segmentation for object detection comes with the problem of separating out objects that may be connected or combining separated segments into one object. To avoid this problem, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">Jaeger et al.</span> [<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite> propose the Retina U-Net: a one-shot 3D detection algorithm that combines the Retina Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite> and U-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a>]</cite> giving detections with 3D bounding boxes. Despite the good performance of Retina U-Net, changing to a new 3D detection problem requires a time-consuming method configuration. This has been addressed in nnDetection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite>. Inspired by the nnU-Net (no new U-Net) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>, they propose a no new 3D detection method.
On the BugNIST data, we test detection with 3D U-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite> and the nnDetection method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite>.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Most 3D datasets for benchmarking image analysis algorithms are medical. A lightweight dataset is MedMNIST by <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">Yang et al.</span> [<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>, <a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite>, which, similar to MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>, is comprised of <math id="S2.p5.1.m1.1" class="ltx_math_unparsed" alttext="28\times 28(\times 28)" display="inline"><semantics id="S2.p5.1.m1.1a"><mrow id="S2.p5.1.m1.1b"><mn id="S2.p5.1.m1.1.1">28</mn><mo lspace="0.222em" rspace="0.222em" id="S2.p5.1.m1.1.2">×</mo><mn id="S2.p5.1.m1.1.3">28</mn><mrow id="S2.p5.1.m1.1.4"><mo stretchy="false" id="S2.p5.1.m1.1.4.1">(</mo><mo lspace="0em" rspace="0.222em" id="S2.p5.1.m1.1.4.2">×</mo><mn id="S2.p5.1.m1.1.4.3">28</mn><mo stretchy="false" id="S2.p5.1.m1.1.4.4">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">28\times 28(\times 28)</annotation></semantics></math> images. Six of the 18 datasets are 3D and have 1370 and 1909 volumes in 2-11 classes. There are other datasets, such as the PROSTATEx dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite> containing 720 MRI scans and tissue samples, the COVID-CT-MD dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite> containing 305 CT scans, the Mossmeddata <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite> containing 1110 CT scans of covid lungs, and more classifications challenges with 2-4 classes such as health, covid19, or pneumonia as is the case for the COVID-CT-MD dataset.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">For 3D object detection, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">Baumgartner et al.</span> [<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> use 13 datasets to develop the nnDetection method. Two of these datasets were originally targeted 3D detection and include the LUNA16 for nodule detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite>, which is a subset of the LIDC dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite> and contains 888 CT scans of lungs, and the ADAM dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite> for detecting aneurysms in MRI scans. ADAM is made up of 254 MRI scans. The rest of the detection datasets are medical segmentation datasets such as data from the Medical Segmentation Decathlon <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite>, the rib fracture detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite>, the PROSTATEx dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite>, and others. The segmentation datasets have been transformed into detection data by identifying center positions and bounding boxes for the segments.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The BugNIST dataset has a classification and detection task. It consists of 9087 volumes of individual bugs of 12 types (species and stages) and an additional 350 volumes with mixtures of bugs, leaves, cotton, shredded paper, and wood shaving, where the number of bugs and other materials varies. We have used the dataset to investigate the problems of classifying species of scans that contain individual bugs, as well as counting, classifying and localizing species in the mixtures. To classify, count, and localize the bugs in the mixtures, the task is to learn the bug appearance from the scans of individual bugs and use this on the mixtures.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Our data is obtained using a laboratory µCT scanner (Nikon metrology scanner) that records volumes of 2000 voxels cubed with an isotropic voxel size of 26.62 µm. These large volumes have allowed us to scan multiple bugs at once, and then crop them into smaller volumes. To scan individual bugs, we made a setup with the bugs placed in plastic straws spaced with cotton. Each straw was 6 cm long and contained 2-3 bugs with cotton in between. By bundling the straws, we scanned between 40 and 150 bugs at once.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">We used two types of straws, one with a diameter of 5 mm and another with a diameter of 9 mm, depending on the size of each bug type. The cylindrical shape of the straws was easy to segment using a circular Hough-transform <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite> and sparse layered graphs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite>, leaving us with a cylinder of only bugs and cotton. The X-ray absorption of cotton is low, which makes it almost transparent compared to the bugs, so we just kept the cotton and air part in the cylinder.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">A similar setup was applied for the mixtures, but instead of straws, we used test tubes with a diameter of 14 mm. With this setup we can obtain 14 mixtures from each µCT scan. To vary the difficulty of the bug counting and detection problem in the mixtures, we added either leaves, shredded paper, or wood shavings to some of the mixtures together with cotton, which was used for spacing. We also varied the number of bugs, their species, and how dense they were packed.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.3" class="ltx_p">The final volumes of scans of individual bugs are <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="450\times 450\times 900" display="inline"><semantics id="S3.p5.1.m1.1a"><mrow id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml"><mn id="S3.p5.1.m1.1.1.2" xref="S3.p5.1.m1.1.1.2.cmml">450</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p5.1.m1.1.1.1" xref="S3.p5.1.m1.1.1.1.cmml">×</mo><mn id="S3.p5.1.m1.1.1.3" xref="S3.p5.1.m1.1.1.3.cmml">450</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p5.1.m1.1.1.1a" xref="S3.p5.1.m1.1.1.1.cmml">×</mo><mn id="S3.p5.1.m1.1.1.4" xref="S3.p5.1.m1.1.1.4.cmml">900</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><apply id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1"><times id="S3.p5.1.m1.1.1.1.cmml" xref="S3.p5.1.m1.1.1.1"></times><cn type="integer" id="S3.p5.1.m1.1.1.2.cmml" xref="S3.p5.1.m1.1.1.2">450</cn><cn type="integer" id="S3.p5.1.m1.1.1.3.cmml" xref="S3.p5.1.m1.1.1.3">450</cn><cn type="integer" id="S3.p5.1.m1.1.1.4.cmml" xref="S3.p5.1.m1.1.1.4">900</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">450\times 450\times 900</annotation></semantics></math> voxels. They were obtained by placing the segmented cylinder centered in the volume and along the full <math id="S3.p5.2.m2.1" class="ltx_Math" alttext="900" display="inline"><semantics id="S3.p5.2.m2.1a"><mn id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml">900</mn><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.1b"><cn type="integer" id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1">900</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.1c">900</annotation></semantics></math> voxels length of the volume. Areas outside the cylinder were set to zero. The mixtures were segmented in the same way and the resulting volumes are <math id="S3.p5.3.m3.1" class="ltx_Math" alttext="650\times 650\times 900" display="inline"><semantics id="S3.p5.3.m3.1a"><mrow id="S3.p5.3.m3.1.1" xref="S3.p5.3.m3.1.1.cmml"><mn id="S3.p5.3.m3.1.1.2" xref="S3.p5.3.m3.1.1.2.cmml">650</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p5.3.m3.1.1.1" xref="S3.p5.3.m3.1.1.1.cmml">×</mo><mn id="S3.p5.3.m3.1.1.3" xref="S3.p5.3.m3.1.1.3.cmml">650</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p5.3.m3.1.1.1a" xref="S3.p5.3.m3.1.1.1.cmml">×</mo><mn id="S3.p5.3.m3.1.1.4" xref="S3.p5.3.m3.1.1.4.cmml">900</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.3.m3.1b"><apply id="S3.p5.3.m3.1.1.cmml" xref="S3.p5.3.m3.1.1"><times id="S3.p5.3.m3.1.1.1.cmml" xref="S3.p5.3.m3.1.1.1"></times><cn type="integer" id="S3.p5.3.m3.1.1.2.cmml" xref="S3.p5.3.m3.1.1.2">650</cn><cn type="integer" id="S3.p5.3.m3.1.1.3.cmml" xref="S3.p5.3.m3.1.1.3">650</cn><cn type="integer" id="S3.p5.3.m3.1.1.4.cmml" xref="S3.p5.3.m3.1.1.4">900</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.3.m3.1c">650\times 650\times 900</annotation></semantics></math> voxels. All the volumes are stored as 8-bit unsigned integers, but with their original spatial resolution (physical voxel size). The scans are illustrated in <a href="#S0.F2" title="In BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">The bugs included in the BugNIST data are bred as fodder for pets and have been frozen before being packed for scanning. Despite careful packing, the scanned bugs may appear damaged, e.g. some of the crickets have broken off antennas or miss a leg. We have chosen to accept these defects because this also reflects w—hat you would expect to meet in a normal population, and add to the challenge of the dataset. In the 5 mm straws, i.e., for the two types of fly pupae, buffalo beetle larvae, maggots, curly-wing flies, and woodlice, we packed three bugs into each straw. This means that bugs were placed close together, and due to variations in the packing, some volumes have parts of the bug above or below the cropped-out volume.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.2" class="ltx_p">To create lightweight datasets for classification, we downsized the volumes to the datasets x64, x128, x256, and x512, where x64 is of size <math id="S3.p7.1.m1.1" class="ltx_Math" alttext="64\times 32\times 32" display="inline"><semantics id="S3.p7.1.m1.1a"><mrow id="S3.p7.1.m1.1.1" xref="S3.p7.1.m1.1.1.cmml"><mn id="S3.p7.1.m1.1.1.2" xref="S3.p7.1.m1.1.1.2.cmml">64</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p7.1.m1.1.1.1" xref="S3.p7.1.m1.1.1.1.cmml">×</mo><mn id="S3.p7.1.m1.1.1.3" xref="S3.p7.1.m1.1.1.3.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p7.1.m1.1.1.1a" xref="S3.p7.1.m1.1.1.1.cmml">×</mo><mn id="S3.p7.1.m1.1.1.4" xref="S3.p7.1.m1.1.1.4.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p7.1.m1.1b"><apply id="S3.p7.1.m1.1.1.cmml" xref="S3.p7.1.m1.1.1"><times id="S3.p7.1.m1.1.1.1.cmml" xref="S3.p7.1.m1.1.1.1"></times><cn type="integer" id="S3.p7.1.m1.1.1.2.cmml" xref="S3.p7.1.m1.1.1.2">64</cn><cn type="integer" id="S3.p7.1.m1.1.1.3.cmml" xref="S3.p7.1.m1.1.1.3">32</cn><cn type="integer" id="S3.p7.1.m1.1.1.4.cmml" xref="S3.p7.1.m1.1.1.4">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.1.m1.1c">64\times 32\times 32</annotation></semantics></math>, x128 is <math id="S3.p7.2.m2.1" class="ltx_Math" alttext="128\times 64\times 64" display="inline"><semantics id="S3.p7.2.m2.1a"><mrow id="S3.p7.2.m2.1.1" xref="S3.p7.2.m2.1.1.cmml"><mn id="S3.p7.2.m2.1.1.2" xref="S3.p7.2.m2.1.1.2.cmml">128</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p7.2.m2.1.1.1" xref="S3.p7.2.m2.1.1.1.cmml">×</mo><mn id="S3.p7.2.m2.1.1.3" xref="S3.p7.2.m2.1.1.3.cmml">64</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p7.2.m2.1.1.1a" xref="S3.p7.2.m2.1.1.1.cmml">×</mo><mn id="S3.p7.2.m2.1.1.4" xref="S3.p7.2.m2.1.1.4.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p7.2.m2.1b"><apply id="S3.p7.2.m2.1.1.cmml" xref="S3.p7.2.m2.1.1"><times id="S3.p7.2.m2.1.1.1.cmml" xref="S3.p7.2.m2.1.1.1"></times><cn type="integer" id="S3.p7.2.m2.1.1.2.cmml" xref="S3.p7.2.m2.1.1.2">128</cn><cn type="integer" id="S3.p7.2.m2.1.1.3.cmml" xref="S3.p7.2.m2.1.1.3">64</cn><cn type="integer" id="S3.p7.2.m2.1.1.4.cmml" xref="S3.p7.2.m2.1.1.4">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.2.m2.1c">128\times 64\times 64</annotation></semantics></math>, etc. These datasets have further been split into training (60%), validation (10%), and test sets (30%). We also made another variation of the datasets where the bugs were aligned and resized to approximately the same size. The axis alignment was done by aligning the bugs along the principal directions of thresholded bug volumes. The size of the bugs was determined by the lengths of the principal axes.</p>
</div>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.1" class="ltx_p">For the mixtures, we counted the bugs that were placed in the mixtures when we packed them. This gives a ground truth for the models trained to predict the number of bugs in a mixture and their species. This can, however, not be used to determine where in the volume the bugs are detected. To facilitate that the BugNIST data can be used for detection, we have manually marked the center positions of the bugs in a subset of 45 mixed volumes. We have only marked the center position and not bounding boxes because some of the bugs, e.g. mealworms, are very elongated. If such a bug lies diagonal to the volume axis, its bounding box could take up most of the volume, and therefore contain much more than that bug. Manually annotating the center position of the bugs is time-consuming, which is the reason for only annotating a smaller fraction of the mixtures. Since the annotations are used for testing, and not for training and validation, this number of annotations is sufficient for evaluating a method.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">To illustrate the use of the BugNIST dataset, we have made baseline results for the proposed tasks including classification, counting, and detection. To classify scans of individual bugs, we have selected a set of high-performing classification methods. The detection problem has been solved based on a multi-label segmentation approach.</p>
</div>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Classification</h3>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">The investigated classification methods are DenseNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>, ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>, SEResNet50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite> and Vision Transformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite> from MONAI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite> and Swin Transformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite> and ConvNext <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite> from <span id="S4.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_typewriter">torchvision</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>. The <span id="S4.SS0.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_typewriter">torchvision</span> models were adapted to 3D by us. These models are selected because they are well-known for their high performance and span both older tried-and-tested methods and new state-of-the-art models. We train the models on the non-mix volumes to predict the bug species. After every epoch, we evaluate the models on the validation set and keep the best model. After training, we evaluate the model on the test set. We provide the remaining details on the training setup in the supplementary materials.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Detection</h3>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">For detection, we investigate two methods. First, a simple baseline using U-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite> from MONAI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite> which is trained to segment bugs in the classification data. We extract semantic segmentation masks by first smoothing each image with a Gaussian kernel of std. 2 voxels, thresholding, and then adding the known label to the mask. Thus, each voxel has one of 13 labels: background or one of the twelve bugs. We train the model on the training and validation set, and evaluate on the test set after every epoch. After training, we apply the best model to the mixture images where each connected component is counted as a detection. Full details are in the supplementary materials.</p>
</div>
<div id="S4.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p2.1" class="ltx_p">The second method is the nnDetection (nnDet) framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> using a Retina U-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>. This is trained to detect bugs in the classification data by outputting bounding boxes. We extract segmentation masks as before, and then also extracts a bounding box for each foreground connected component for training. We then train the model on the training and validation set, and evaluate on the test set after every epoch. After training, we apply the best model to the mixture images. Again, full details are in the supplementary materials.</p>
</div>
<div id="S4.SS0.SSS0.Px2.p3" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p3.1" class="ltx_p">We evaluate the mixture data detections on the following metrics: Precision and recall, detection-L1, and count error. Precision and recall are computed by matching detections with center point annotations based on their distances. For U-Net, we use the distances from an annotation to the nearest voxel in the connected component of the detection. For nnDet, we use the distance between an annotation and the bounding box centroid. Munkres’ algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite> then computes the optimal matching. For U-Net, we allow matches with distances under 8 voxels and for nnDet we require that an annotation must be contained in the detection bounding box. Precision is then computed as the ratio of matched detections and total annotations and recall as the ratio of matched annotations and total annotations.</p>
</div>
<div id="S4.SS0.SSS0.Px2.p4" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p4.1" class="ltx_p">For detection-L1, we compute the absolute error in the number of detections for each class and then sum these. We then normalize this error by the total number of bugs. Finally, count error is simply absolute error on the total number of detected bugs normalized by the true number of bugs.</p>
</div>
<div id="S4.SS0.SSS0.Px2.p5" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p5.1" class="ltx_p">Notice that precision and recall only asses the location of each detection but not the classes whereas detection-L1 assess the detected classes but not their location. Together, they allow a useful assessment of the detection quality with low annotation effort.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Classification</h3>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.1" class="ltx_p">We show accuracy and AUC metrics for the classification results in <a href="#S5.T1" title="In Classification ‣ 5 Results ‣ BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">table</span> <span class="ltx_text ltx_ref_tag">1</span></a>. Due to computational limitations, we only trained a few models on the largest versions. However, the smaller datasets still give a good assessment of the models, as they perform consistently over the dataset sizes.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Classification results on the BugNIST test data. BugNISTxN refers to the non-aligned data and BugNIST_AxN to the aligned data.</figcaption>
<table id="S5.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.4.1.1" class="ltx_tr">
<th id="S5.T1.4.1.1.1" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.1.1.1.1.1" class="ltx_p"><span id="S5.T1.4.1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">BugNIST</span></span>
</span>
</th>
<th id="S5.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="S5.T1.4.1.1.2.1" class="ltx_text" style="font-size:90%;">x64</span></th>
<th id="S5.T1.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="S5.T1.4.1.1.3.1" class="ltx_text" style="font-size:90%;">x128</span></th>
<th id="S5.T1.4.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="S5.T1.4.1.1.4.1" class="ltx_text" style="font-size:90%;">x256</span></th>
<th id="S5.T1.4.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="S5.T1.4.1.1.5.1" class="ltx_text" style="font-size:90%;">x512</span></th>
<th id="S5.T1.4.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="S5.T1.4.1.1.6.1" class="ltx_text" style="font-size:90%;">_Ax64</span></th>
<th id="S5.T1.4.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="S5.T1.4.1.1.7.1" class="ltx_text" style="font-size:90%;">_Ax128</span></th>
<th id="S5.T1.4.1.1.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="S5.T1.4.1.1.8.1" class="ltx_text" style="font-size:90%;">_Ax256</span></th>
<th id="S5.T1.4.1.1.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="S5.T1.4.1.1.9.1" class="ltx_text" style="font-size:90%;">_Ax512</span></th>
</tr>
<tr id="S5.T1.4.2.2" class="ltx_tr">
<th id="S5.T1.4.2.2.1" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_th_row" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.2.2.1.1.1" class="ltx_p"><span id="S5.T1.4.2.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></span>
</span>
</th>
<th id="S5.T1.4.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.2.1" class="ltx_text" style="font-size:90%;">Acc.</span></th>
<th id="S5.T1.4.2.2.3" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.3.1" class="ltx_text" style="font-size:90%;">AUC</span></th>
<th id="S5.T1.4.2.2.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.4.1" class="ltx_text" style="font-size:90%;">Acc.</span></th>
<th id="S5.T1.4.2.2.5" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.5.1" class="ltx_text" style="font-size:90%;">AUC</span></th>
<th id="S5.T1.4.2.2.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.6.1" class="ltx_text" style="font-size:90%;">Acc.</span></th>
<th id="S5.T1.4.2.2.7" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.7.1" class="ltx_text" style="font-size:90%;">AUC</span></th>
<th id="S5.T1.4.2.2.8" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.8.1" class="ltx_text" style="font-size:90%;">Acc.</span></th>
<th id="S5.T1.4.2.2.9" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.9.1" class="ltx_text" style="font-size:90%;">AUC</span></th>
<th id="S5.T1.4.2.2.10" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.10.1" class="ltx_text" style="font-size:90%;">Acc.</span></th>
<th id="S5.T1.4.2.2.11" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.11.1" class="ltx_text" style="font-size:90%;">AUC</span></th>
<th id="S5.T1.4.2.2.12" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.12.1" class="ltx_text" style="font-size:90%;">Acc.</span></th>
<th id="S5.T1.4.2.2.13" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.13.1" class="ltx_text" style="font-size:90%;">AUC</span></th>
<th id="S5.T1.4.2.2.14" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.14.1" class="ltx_text" style="font-size:90%;">Acc.</span></th>
<th id="S5.T1.4.2.2.15" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.15.1" class="ltx_text" style="font-size:90%;">AUC</span></th>
<th id="S5.T1.4.2.2.16" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.16.1" class="ltx_text" style="font-size:90%;">Acc.</span></th>
<th id="S5.T1.4.2.2.17" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.2.2.17.1" class="ltx_text" style="font-size:90%;">AUC</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.4.3.1" class="ltx_tr">
<th id="S5.T1.4.3.1.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.3.1.1.1.1" class="ltx_p"><span id="S5.T1.4.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">DenseNet121 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.3.1.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a><span id="S5.T1.4.3.1.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.3.1.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.2.1" class="ltx_text" style="font-size:90%;">0.94</span></td>
<td id="S5.T1.4.3.1.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.3.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.3.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.4.1" class="ltx_text" style="font-size:90%;">0.96</span></td>
<td id="S5.T1.4.3.1.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.5.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.3.1.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.6.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.3.1.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.7.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.3.1.8" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.8.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.3.1.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.9.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.3.1.10" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.10.1" class="ltx_text" style="font-size:90%;">0.95</span></td>
<td id="S5.T1.4.3.1.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.11.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.3.1.12" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.12.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.3.1.13" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.13.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.3.1.14" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.14.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.3.1.15" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.15.1" class="ltx_text" style="font-size:90%;">1.000</span></td>
<td id="S5.T1.4.3.1.16" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.16.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.3.1.17" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.3.1.17.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
</tr>
<tr id="S5.T1.4.4.2" class="ltx_tr">
<th id="S5.T1.4.4.2.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.4.2.1.1.1" class="ltx_p"><span id="S5.T1.4.4.2.1.1.1.1" class="ltx_text" style="font-size:90%;">DenseNet169 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.4.2.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a><span id="S5.T1.4.4.2.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.4.2.2" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.2.1" class="ltx_text" style="font-size:90%;">0.95</span></td>
<td id="S5.T1.4.4.2.3" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.3.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.4.2.4" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.4.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.4.2.5" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.5.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.4.2.6" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.6.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.4.2.7" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.7.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.4.2.8" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.8.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.4.2.9" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.9.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.4.2.10" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.10.1" class="ltx_text" style="font-size:90%;">0.94</span></td>
<td id="S5.T1.4.4.2.11" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.11.1" class="ltx_text" style="font-size:90%;">0.997</span></td>
<td id="S5.T1.4.4.2.12" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.12.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.4.2.13" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.13.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.4.2.14" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.14.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.4.2.15" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.15.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.4.2.16" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.16.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.4.2.17" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.4.2.17.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
</tr>
<tr id="S5.T1.4.5.3" class="ltx_tr">
<th id="S5.T1.4.5.3.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.5.3.1.1.1" class="ltx_p"><span id="S5.T1.4.5.3.1.1.1.1" class="ltx_text" style="font-size:90%;">DenseNet201 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.5.3.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a><span id="S5.T1.4.5.3.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.5.3.2" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.2.1" class="ltx_text" style="font-size:90%;">0.95</span></td>
<td id="S5.T1.4.5.3.3" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.3.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.5.3.4" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.4.1" class="ltx_text" style="font-size:90%;">0.96</span></td>
<td id="S5.T1.4.5.3.5" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.5.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.5.3.6" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.6.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.5.3.7" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.7.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.5.3.8" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.5.3.9" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.5.3.10" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.10.1" class="ltx_text" style="font-size:90%;">0.94</span></td>
<td id="S5.T1.4.5.3.11" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.11.1" class="ltx_text" style="font-size:90%;">0.997</span></td>
<td id="S5.T1.4.5.3.12" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.12.1" class="ltx_text" style="font-size:90%;">0.96</span></td>
<td id="S5.T1.4.5.3.13" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.13.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.5.3.14" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.14.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.5.3.15" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.15.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.5.3.16" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.5.3.17" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.5.3.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.6.4" class="ltx_tr">
<th id="S5.T1.4.6.4.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.6.4.1.1.1" class="ltx_p"><span id="S5.T1.4.6.4.1.1.1.1" class="ltx_text" style="font-size:90%;">ResNet18 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.6.4.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a><span id="S5.T1.4.6.4.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.6.4.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.2.1" class="ltx_text" style="font-size:90%;">0.94</span></td>
<td id="S5.T1.4.6.4.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.3.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.6.4.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.4.1" class="ltx_text" style="font-size:90%;">0.96</span></td>
<td id="S5.T1.4.6.4.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.5.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.6.4.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.6.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.6.4.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.7.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.6.4.8" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.6.4.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.6.4.10" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.10.1" class="ltx_text" style="font-size:90%;">0.94</span></td>
<td id="S5.T1.4.6.4.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.11.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.6.4.12" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.12.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.6.4.13" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.13.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.6.4.14" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.14.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.6.4.15" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.15.1" class="ltx_text" style="font-size:90%;">1.000</span></td>
<td id="S5.T1.4.6.4.16" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.6.4.17" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.6.4.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.7.5" class="ltx_tr">
<th id="S5.T1.4.7.5.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.7.5.1.1.1" class="ltx_p"><span id="S5.T1.4.7.5.1.1.1.1" class="ltx_text" style="font-size:90%;">ResNet34 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.7.5.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a><span id="S5.T1.4.7.5.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.7.5.2" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.2.1" class="ltx_text" style="font-size:90%;">0.94</span></td>
<td id="S5.T1.4.7.5.3" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.3.1" class="ltx_text" style="font-size:90%;">0.997</span></td>
<td id="S5.T1.4.7.5.4" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.4.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.7.5.5" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.5.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.7.5.6" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.6.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.7.5.7" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.7.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.7.5.8" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.7.5.9" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.7.5.10" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.10.1" class="ltx_text" style="font-size:90%;">0.94</span></td>
<td id="S5.T1.4.7.5.11" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.11.1" class="ltx_text" style="font-size:90%;">0.997</span></td>
<td id="S5.T1.4.7.5.12" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.12.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.7.5.13" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.13.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.7.5.14" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.14.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.7.5.15" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.15.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.7.5.16" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.7.5.17" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.7.5.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.8.6" class="ltx_tr">
<th id="S5.T1.4.8.6.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.8.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.8.6.1.1.1" class="ltx_p"><span id="S5.T1.4.8.6.1.1.1.1" class="ltx_text" style="font-size:90%;">ResNet50 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.8.6.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a><span id="S5.T1.4.8.6.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.8.6.2" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.2.1" class="ltx_text" style="font-size:90%;">0.95</span></td>
<td id="S5.T1.4.8.6.3" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.3.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.8.6.4" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.4.1" class="ltx_text" style="font-size:90%;">0.96</span></td>
<td id="S5.T1.4.8.6.5" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.5.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.8.6.6" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.6.1" class="ltx_text" style="font-size:90%;">0.98</span></td>
<td id="S5.T1.4.8.6.7" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.7.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.8.6.8" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.8.6.9" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.8.6.10" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.10.1" class="ltx_text" style="font-size:90%;">0.95</span></td>
<td id="S5.T1.4.8.6.11" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.11.1" class="ltx_text" style="font-size:90%;">0.997</span></td>
<td id="S5.T1.4.8.6.12" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.12.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.8.6.13" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.13.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.8.6.14" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.14.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.8.6.15" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.15.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.8.6.16" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.8.6.17" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.8.6.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.9.7" class="ltx_tr">
<th id="S5.T1.4.9.7.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.9.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.9.7.1.1.1" class="ltx_p"><span id="S5.T1.4.9.7.1.1.1.1" class="ltx_text" style="font-size:90%;">SEResNet34 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.9.7.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a><span id="S5.T1.4.9.7.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.9.7.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.2.1" class="ltx_text" style="font-size:90%;">0.93</span></td>
<td id="S5.T1.4.9.7.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.3.1" class="ltx_text" style="font-size:90%;">0.997</span></td>
<td id="S5.T1.4.9.7.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.4.1" class="ltx_text" style="font-size:90%;">0.94</span></td>
<td id="S5.T1.4.9.7.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.5.1" class="ltx_text" style="font-size:90%;">0.997</span></td>
<td id="S5.T1.4.9.7.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.6.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.9.7.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.7.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.9.7.8" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.9.7.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.9.7.10" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.10.1" class="ltx_text" style="font-size:90%;">0.92</span></td>
<td id="S5.T1.4.9.7.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.11.1" class="ltx_text" style="font-size:90%;">0.995</span></td>
<td id="S5.T1.4.9.7.12" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.12.1" class="ltx_text" style="font-size:90%;">0.94</span></td>
<td id="S5.T1.4.9.7.13" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.13.1" class="ltx_text" style="font-size:90%;">0.997</span></td>
<td id="S5.T1.4.9.7.14" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.14.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.9.7.15" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.15.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.9.7.16" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.9.7.17" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.9.7.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.10.8" class="ltx_tr">
<th id="S5.T1.4.10.8.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.10.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.10.8.1.1.1" class="ltx_p"><span id="S5.T1.4.10.8.1.1.1.1" class="ltx_text" style="font-size:90%;">SEResNet50 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.10.8.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a><span id="S5.T1.4.10.8.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.10.8.2" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.2.1" class="ltx_text" style="font-size:90%;">0.92</span></td>
<td id="S5.T1.4.10.8.3" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.3.1" class="ltx_text" style="font-size:90%;">0.996</span></td>
<td id="S5.T1.4.10.8.4" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.4.1" class="ltx_text" style="font-size:90%;">0.96</span></td>
<td id="S5.T1.4.10.8.5" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.5.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.10.8.6" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.6.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.10.8.7" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.7.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.10.8.8" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.10.8.9" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.10.8.10" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.10.1" class="ltx_text" style="font-size:90%;">0.91</span></td>
<td id="S5.T1.4.10.8.11" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.11.1" class="ltx_text" style="font-size:90%;">0.995</span></td>
<td id="S5.T1.4.10.8.12" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.12.1" class="ltx_text" style="font-size:90%;">0.95</span></td>
<td id="S5.T1.4.10.8.13" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.13.1" class="ltx_text" style="font-size:90%;">0.998</span></td>
<td id="S5.T1.4.10.8.14" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.14.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S5.T1.4.10.8.15" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.15.1" class="ltx_text" style="font-size:90%;">0.999</span></td>
<td id="S5.T1.4.10.8.16" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.10.8.17" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.10.8.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.11.9" class="ltx_tr">
<th id="S5.T1.4.11.9.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.11.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.11.9.1.1.1" class="ltx_p"><span id="S5.T1.4.11.9.1.1.1.1" class="ltx_text" style="font-size:90%;">ConvNext-T </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.11.9.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a><span id="S5.T1.4.11.9.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.11.9.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.2.1" class="ltx_text" style="font-size:90%;">0.82</span></td>
<td id="S5.T1.4.11.9.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.3.1" class="ltx_text" style="font-size:90%;">0.983</span></td>
<td id="S5.T1.4.11.9.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.4.1" class="ltx_text" style="font-size:90%;">0.90</span></td>
<td id="S5.T1.4.11.9.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.5.1" class="ltx_text" style="font-size:90%;">0.993</span></td>
<td id="S5.T1.4.11.9.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.11.9.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.7.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.11.9.8" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.11.9.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.11.9.10" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.10.1" class="ltx_text" style="font-size:90%;">0.77</span></td>
<td id="S5.T1.4.11.9.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.11.1" class="ltx_text" style="font-size:90%;">0.976</span></td>
<td id="S5.T1.4.11.9.12" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.12.1" class="ltx_text" style="font-size:90%;">0.90</span></td>
<td id="S5.T1.4.11.9.13" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.13.1" class="ltx_text" style="font-size:90%;">0.992</span></td>
<td id="S5.T1.4.11.9.14" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.14.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.11.9.15" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.15.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.11.9.16" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.11.9.17" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.11.9.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.12.10" class="ltx_tr">
<th id="S5.T1.4.12.10.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.12.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.12.10.1.1.1" class="ltx_p"><span id="S5.T1.4.12.10.1.1.1.1" class="ltx_text" style="font-size:90%;">ConvNext-B </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.12.10.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a><span id="S5.T1.4.12.10.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.12.10.2" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.2.1" class="ltx_text" style="font-size:90%;">0.84</span></td>
<td id="S5.T1.4.12.10.3" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.3.1" class="ltx_text" style="font-size:90%;">0.988</span></td>
<td id="S5.T1.4.12.10.4" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.4.1" class="ltx_text" style="font-size:90%;">0.90</span></td>
<td id="S5.T1.4.12.10.5" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.5.1" class="ltx_text" style="font-size:90%;">0.994</span></td>
<td id="S5.T1.4.12.10.6" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.12.10.7" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.7.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.12.10.8" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.12.10.9" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.12.10.10" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.10.1" class="ltx_text" style="font-size:90%;">0.78</span></td>
<td id="S5.T1.4.12.10.11" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.11.1" class="ltx_text" style="font-size:90%;">0.980</span></td>
<td id="S5.T1.4.12.10.12" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.12.1" class="ltx_text" style="font-size:90%;">0.89</span></td>
<td id="S5.T1.4.12.10.13" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.13.1" class="ltx_text" style="font-size:90%;">0.992</span></td>
<td id="S5.T1.4.12.10.14" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.14.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.12.10.15" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.15.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.12.10.16" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.12.10.17" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.12.10.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.13.11" class="ltx_tr">
<th id="S5.T1.4.13.11.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.13.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.13.11.1.1.1" class="ltx_p"><span id="S5.T1.4.13.11.1.1.1.1" class="ltx_text" style="font-size:90%;">ViT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.13.11.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a><span id="S5.T1.4.13.11.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.13.11.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.2.1" class="ltx_text" style="font-size:90%;">0.86</span></td>
<td id="S5.T1.4.13.11.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.3.1" class="ltx_text" style="font-size:90%;">0.979</span></td>
<td id="S5.T1.4.13.11.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.4.1" class="ltx_text" style="font-size:90%;">0.87</span></td>
<td id="S5.T1.4.13.11.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.5.1" class="ltx_text" style="font-size:90%;">0.980</span></td>
<td id="S5.T1.4.13.11.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.13.11.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.7.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.13.11.8" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.13.11.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.13.11.10" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.10.1" class="ltx_text" style="font-size:90%;">0.81</span></td>
<td id="S5.T1.4.13.11.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.11.1" class="ltx_text" style="font-size:90%;">0.964</span></td>
<td id="S5.T1.4.13.11.12" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.12.1" class="ltx_text" style="font-size:90%;">0.82</span></td>
<td id="S5.T1.4.13.11.13" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.13.1" class="ltx_text" style="font-size:90%;">0.965</span></td>
<td id="S5.T1.4.13.11.14" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.14.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.13.11.15" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.15.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.13.11.16" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.13.11.17" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.13.11.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.14.12" class="ltx_tr">
<th id="S5.T1.4.14.12.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.14.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.14.12.1.1.1" class="ltx_p"><span id="S5.T1.4.14.12.1.1.1.1" class="ltx_text" style="font-size:90%;">SwinT-v2-T </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.14.12.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a><span id="S5.T1.4.14.12.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.14.12.2" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.2.1" class="ltx_text" style="font-size:90%;">0.88</span></td>
<td id="S5.T1.4.14.12.3" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.3.1" class="ltx_text" style="font-size:90%;">0.987</span></td>
<td id="S5.T1.4.14.12.4" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.4.1" class="ltx_text" style="font-size:90%;">0.86</span></td>
<td id="S5.T1.4.14.12.5" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.5.1" class="ltx_text" style="font-size:90%;">0.984</span></td>
<td id="S5.T1.4.14.12.6" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.14.12.7" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.7.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.14.12.8" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.14.12.9" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.14.12.10" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.10.1" class="ltx_text" style="font-size:90%;">0.84</span></td>
<td id="S5.T1.4.14.12.11" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.11.1" class="ltx_text" style="font-size:90%;">0.982</span></td>
<td id="S5.T1.4.14.12.12" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.12.1" class="ltx_text" style="font-size:90%;">0.82</span></td>
<td id="S5.T1.4.14.12.13" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.13.1" class="ltx_text" style="font-size:90%;">0.976</span></td>
<td id="S5.T1.4.14.12.14" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.14.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.14.12.15" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.15.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.14.12.16" class="ltx_td ltx_nopad_l ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.14.12.17" class="ltx_td ltx_align_right" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.14.12.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S5.T1.4.15.13" class="ltx_tr">
<th id="S5.T1.4.15.13.1" class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T1.4.15.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.15.13.1.1.1" class="ltx_p"><span id="S5.T1.4.15.13.1.1.1.1" class="ltx_text" style="font-size:90%;">SwinT-v2-S </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T1.4.15.13.1.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a><span id="S5.T1.4.15.13.1.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T1.4.15.13.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.2.1" class="ltx_text" style="font-size:90%;">0.90</span></td>
<td id="S5.T1.4.15.13.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.3.1" class="ltx_text" style="font-size:90%;">0.992</span></td>
<td id="S5.T1.4.15.13.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.4.1" class="ltx_text" style="font-size:90%;">0.90</span></td>
<td id="S5.T1.4.15.13.5" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.5.1" class="ltx_text" style="font-size:90%;">0.993</span></td>
<td id="S5.T1.4.15.13.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.15.13.7" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.7.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.15.13.8" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.15.13.9" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.15.13.10" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.10.1" class="ltx_text" style="font-size:90%;">0.88</span></td>
<td id="S5.T1.4.15.13.11" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.11.1" class="ltx_text" style="font-size:90%;">0.989</span></td>
<td id="S5.T1.4.15.13.12" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.12.1" class="ltx_text" style="font-size:90%;">0.90</span></td>
<td id="S5.T1.4.15.13.13" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.13.1" class="ltx_text" style="font-size:90%;">0.992</span></td>
<td id="S5.T1.4.15.13.14" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.14.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.15.13.15" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.15.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.15.13.16" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.16.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T1.4.15.13.17" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.4.15.13.17.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2304.01838/assets/x1.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="368" height="327" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S5.F3.3.2" class="ltx_text" style="font-size:90%;">Confusion matrix for BugNISTx64.</span></figcaption>
</figure>
<div id="S5.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p2.1" class="ltx_p">We also show a confusion matrix in <a href="#S5.F3" title="In Classification ‣ 5 Results ‣ BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a> for a selection of models on the BugNISTx64 data.</p>
</div>
<div id="S5.SS0.SSS0.Px1.p3" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p3.1" class="ltx_p">As shown in <a href="#S5.T1" title="In Classification ‣ 5 Results ‣ BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">table</span> <span class="ltx_text ltx_ref_tag">1</span></a>, all models perform well. It is only the fine grained classification of brown and black crickets (classes AC and BC) that cause issues. Looking at just these classes, the accuracy is between 0.70 and 0.86.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Detection</h3>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p1.1" class="ltx_p">We show the performance of the detection methods in <a href="#S5.T2" title="In Detection ‣ 5 Results ‣ BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">table</span> <span class="ltx_text ltx_ref_tag">2</span></a>, illustrate detection examples on the classification data in <a href="#S5.F4" title="In Detection ‣ 5 Results ‣ BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, and show detection examples in <a href="#S5.F5" title="In Detection ‣ 5 Results ‣ BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a>. U-Net outperforms nnDet for localizing the bugs in the mixtures but has is slightly worse when it comes to counting. Furthermore, nnDet has more misclassifications than the U-Net method, despite being good at localizing in the classification images.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Detection results on BugNIST mixtures.</figcaption>
<table id="S5.T2.12" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.4.4" class="ltx_tr">
<th id="S5.T2.4.4.5" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T2.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.4.5.1.1" class="ltx_p"><span id="S5.T2.4.4.5.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></span>
</span>
</th>
<th id="S5.T2.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T2.1.1.1.1" class="ltx_text" style="font-size:90%;">Precision</span><math id="S5.T2.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T2.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S5.T2.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T2.2.2.2.1" class="ltx_text" style="font-size:90%;">Recall</span><math id="S5.T2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T2.2.2.2.m1.1a"><mo mathsize="90%" stretchy="false" id="S5.T2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b"><ci id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S5.T2.3.3.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T2.3.3.3.1" class="ltx_text" style="font-size:90%;">Det-L1</span><math id="S5.T2.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.3.3.3.m1.1a"><mo mathsize="90%" stretchy="false" id="S5.T2.3.3.3.m1.1.1" xref="S5.T2.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.m1.1b"><ci id="S5.T2.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S5.T2.4.4.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T2.4.4.4.1" class="ltx_text" style="font-size:90%;">Count Err.</span><math id="S5.T2.4.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.4.4.4.m1.1a"><mo mathsize="90%" stretchy="false" id="S5.T2.4.4.4.m1.1.1" xref="S5.T2.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.m1.1b"><ci id="S5.T2.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.m1.1c">\downarrow</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.8.8" class="ltx_tr">
<th id="S5.T2.8.8.5" class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T2.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.8.8.5.1.1" class="ltx_p"><span id="S5.T2.8.8.5.1.1.1" class="ltx_text" style="font-size:90%;">U-Net </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T2.8.8.5.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a><span id="S5.T2.8.8.5.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T2.5.5.1" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S5.T2.5.5.1.m1.1" class="ltx_Math" alttext="0.70\pm 0.26" display="inline"><semantics id="S5.T2.5.5.1.m1.1a"><mrow id="S5.T2.5.5.1.m1.1.1" xref="S5.T2.5.5.1.m1.1.1.cmml"><mn mathsize="90%" id="S5.T2.5.5.1.m1.1.1.2" xref="S5.T2.5.5.1.m1.1.1.2.cmml">0.70</mn><mo mathsize="90%" id="S5.T2.5.5.1.m1.1.1.1" xref="S5.T2.5.5.1.m1.1.1.1.cmml">±</mo><mn mathsize="90%" id="S5.T2.5.5.1.m1.1.1.3" xref="S5.T2.5.5.1.m1.1.1.3.cmml">0.26</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.1.m1.1b"><apply id="S5.T2.5.5.1.m1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.5.5.1.m1.1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.5.5.1.m1.1.1.2.cmml" xref="S5.T2.5.5.1.m1.1.1.2">0.70</cn><cn type="float" id="S5.T2.5.5.1.m1.1.1.3.cmml" xref="S5.T2.5.5.1.m1.1.1.3">0.26</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.1.m1.1c">0.70\pm 0.26</annotation></semantics></math></td>
<td id="S5.T2.6.6.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S5.T2.6.6.2.m1.1" class="ltx_Math" alttext="0.39\pm 0.21" display="inline"><semantics id="S5.T2.6.6.2.m1.1a"><mrow id="S5.T2.6.6.2.m1.1.1" xref="S5.T2.6.6.2.m1.1.1.cmml"><mn mathsize="90%" id="S5.T2.6.6.2.m1.1.1.2" xref="S5.T2.6.6.2.m1.1.1.2.cmml">0.39</mn><mo mathsize="90%" id="S5.T2.6.6.2.m1.1.1.1" xref="S5.T2.6.6.2.m1.1.1.1.cmml">±</mo><mn mathsize="90%" id="S5.T2.6.6.2.m1.1.1.3" xref="S5.T2.6.6.2.m1.1.1.3.cmml">0.21</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.2.m1.1b"><apply id="S5.T2.6.6.2.m1.1.1.cmml" xref="S5.T2.6.6.2.m1.1.1"><csymbol cd="latexml" id="S5.T2.6.6.2.m1.1.1.1.cmml" xref="S5.T2.6.6.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.6.6.2.m1.1.1.2.cmml" xref="S5.T2.6.6.2.m1.1.1.2">0.39</cn><cn type="float" id="S5.T2.6.6.2.m1.1.1.3.cmml" xref="S5.T2.6.6.2.m1.1.1.3">0.21</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.2.m1.1c">0.39\pm 0.21</annotation></semantics></math></td>
<td id="S5.T2.7.7.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S5.T2.7.7.3.m1.1" class="ltx_Math" alttext="1.37\pm 0.45" display="inline"><semantics id="S5.T2.7.7.3.m1.1a"><mrow id="S5.T2.7.7.3.m1.1.1" xref="S5.T2.7.7.3.m1.1.1.cmml"><mn mathsize="90%" id="S5.T2.7.7.3.m1.1.1.2" xref="S5.T2.7.7.3.m1.1.1.2.cmml">1.37</mn><mo mathsize="90%" id="S5.T2.7.7.3.m1.1.1.1" xref="S5.T2.7.7.3.m1.1.1.1.cmml">±</mo><mn mathsize="90%" id="S5.T2.7.7.3.m1.1.1.3" xref="S5.T2.7.7.3.m1.1.1.3.cmml">0.45</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.3.m1.1b"><apply id="S5.T2.7.7.3.m1.1.1.cmml" xref="S5.T2.7.7.3.m1.1.1"><csymbol cd="latexml" id="S5.T2.7.7.3.m1.1.1.1.cmml" xref="S5.T2.7.7.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.7.7.3.m1.1.1.2.cmml" xref="S5.T2.7.7.3.m1.1.1.2">1.37</cn><cn type="float" id="S5.T2.7.7.3.m1.1.1.3.cmml" xref="S5.T2.7.7.3.m1.1.1.3">0.45</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.3.m1.1c">1.37\pm 0.45</annotation></semantics></math></td>
<td id="S5.T2.8.8.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S5.T2.8.8.4.m1.1" class="ltx_Math" alttext="0.55\pm 0.32" display="inline"><semantics id="S5.T2.8.8.4.m1.1a"><mrow id="S5.T2.8.8.4.m1.1.1" xref="S5.T2.8.8.4.m1.1.1.cmml"><mn mathsize="90%" id="S5.T2.8.8.4.m1.1.1.2" xref="S5.T2.8.8.4.m1.1.1.2.cmml">0.55</mn><mo mathsize="90%" id="S5.T2.8.8.4.m1.1.1.1" xref="S5.T2.8.8.4.m1.1.1.1.cmml">±</mo><mn mathsize="90%" id="S5.T2.8.8.4.m1.1.1.3" xref="S5.T2.8.8.4.m1.1.1.3.cmml">0.32</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.4.m1.1b"><apply id="S5.T2.8.8.4.m1.1.1.cmml" xref="S5.T2.8.8.4.m1.1.1"><csymbol cd="latexml" id="S5.T2.8.8.4.m1.1.1.1.cmml" xref="S5.T2.8.8.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.8.8.4.m1.1.1.2.cmml" xref="S5.T2.8.8.4.m1.1.1.2">0.55</cn><cn type="float" id="S5.T2.8.8.4.m1.1.1.3.cmml" xref="S5.T2.8.8.4.m1.1.1.3">0.32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.4.m1.1c">0.55\pm 0.32</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.12.12" class="ltx_tr">
<th id="S5.T2.12.12.5" class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S5.T2.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.12.12.5.1.1" class="ltx_p"><span id="S5.T2.12.12.5.1.1.1" class="ltx_text" style="font-size:90%;">nnDet </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.T2.12.12.5.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a><span id="S5.T2.12.12.5.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite></span>
</span>
</th>
<td id="S5.T2.9.9.1" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S5.T2.9.9.1.m1.1" class="ltx_Math" alttext="0.15\pm 0.09" display="inline"><semantics id="S5.T2.9.9.1.m1.1a"><mrow id="S5.T2.9.9.1.m1.1.1" xref="S5.T2.9.9.1.m1.1.1.cmml"><mn mathsize="90%" id="S5.T2.9.9.1.m1.1.1.2" xref="S5.T2.9.9.1.m1.1.1.2.cmml">0.15</mn><mo mathsize="90%" id="S5.T2.9.9.1.m1.1.1.1" xref="S5.T2.9.9.1.m1.1.1.1.cmml">±</mo><mn mathsize="90%" id="S5.T2.9.9.1.m1.1.1.3" xref="S5.T2.9.9.1.m1.1.1.3.cmml">0.09</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.9.9.1.m1.1b"><apply id="S5.T2.9.9.1.m1.1.1.cmml" xref="S5.T2.9.9.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.9.9.1.m1.1.1.1.cmml" xref="S5.T2.9.9.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.9.9.1.m1.1.1.2.cmml" xref="S5.T2.9.9.1.m1.1.1.2">0.15</cn><cn type="float" id="S5.T2.9.9.1.m1.1.1.3.cmml" xref="S5.T2.9.9.1.m1.1.1.3">0.09</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.9.1.m1.1c">0.15\pm 0.09</annotation></semantics></math></td>
<td id="S5.T2.10.10.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S5.T2.10.10.2.m1.1" class="ltx_Math" alttext="0.16\pm 0.09" display="inline"><semantics id="S5.T2.10.10.2.m1.1a"><mrow id="S5.T2.10.10.2.m1.1.1" xref="S5.T2.10.10.2.m1.1.1.cmml"><mn mathsize="90%" id="S5.T2.10.10.2.m1.1.1.2" xref="S5.T2.10.10.2.m1.1.1.2.cmml">0.16</mn><mo mathsize="90%" id="S5.T2.10.10.2.m1.1.1.1" xref="S5.T2.10.10.2.m1.1.1.1.cmml">±</mo><mn mathsize="90%" id="S5.T2.10.10.2.m1.1.1.3" xref="S5.T2.10.10.2.m1.1.1.3.cmml">0.09</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.10.10.2.m1.1b"><apply id="S5.T2.10.10.2.m1.1.1.cmml" xref="S5.T2.10.10.2.m1.1.1"><csymbol cd="latexml" id="S5.T2.10.10.2.m1.1.1.1.cmml" xref="S5.T2.10.10.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.10.10.2.m1.1.1.2.cmml" xref="S5.T2.10.10.2.m1.1.1.2">0.16</cn><cn type="float" id="S5.T2.10.10.2.m1.1.1.3.cmml" xref="S5.T2.10.10.2.m1.1.1.3">0.09</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.10.2.m1.1c">0.16\pm 0.09</annotation></semantics></math></td>
<td id="S5.T2.11.11.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S5.T2.11.11.3.m1.1" class="ltx_Math" alttext="1.71\pm 0.55" display="inline"><semantics id="S5.T2.11.11.3.m1.1a"><mrow id="S5.T2.11.11.3.m1.1.1" xref="S5.T2.11.11.3.m1.1.1.cmml"><mn mathsize="90%" id="S5.T2.11.11.3.m1.1.1.2" xref="S5.T2.11.11.3.m1.1.1.2.cmml">1.71</mn><mo mathsize="90%" id="S5.T2.11.11.3.m1.1.1.1" xref="S5.T2.11.11.3.m1.1.1.1.cmml">±</mo><mn mathsize="90%" id="S5.T2.11.11.3.m1.1.1.3" xref="S5.T2.11.11.3.m1.1.1.3.cmml">0.55</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.11.11.3.m1.1b"><apply id="S5.T2.11.11.3.m1.1.1.cmml" xref="S5.T2.11.11.3.m1.1.1"><csymbol cd="latexml" id="S5.T2.11.11.3.m1.1.1.1.cmml" xref="S5.T2.11.11.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.11.11.3.m1.1.1.2.cmml" xref="S5.T2.11.11.3.m1.1.1.2">1.71</cn><cn type="float" id="S5.T2.11.11.3.m1.1.1.3.cmml" xref="S5.T2.11.11.3.m1.1.1.3">0.55</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.11.11.3.m1.1c">1.71\pm 0.55</annotation></semantics></math></td>
<td id="S5.T2.12.12.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><math id="S5.T2.12.12.4.m1.1" class="ltx_Math" alttext="0.42\pm 0.35" display="inline"><semantics id="S5.T2.12.12.4.m1.1a"><mrow id="S5.T2.12.12.4.m1.1.1" xref="S5.T2.12.12.4.m1.1.1.cmml"><mn mathsize="90%" id="S5.T2.12.12.4.m1.1.1.2" xref="S5.T2.12.12.4.m1.1.1.2.cmml">0.42</mn><mo mathsize="90%" id="S5.T2.12.12.4.m1.1.1.1" xref="S5.T2.12.12.4.m1.1.1.1.cmml">±</mo><mn mathsize="90%" id="S5.T2.12.12.4.m1.1.1.3" xref="S5.T2.12.12.4.m1.1.1.3.cmml">0.35</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.12.12.4.m1.1b"><apply id="S5.T2.12.12.4.m1.1.1.cmml" xref="S5.T2.12.12.4.m1.1.1"><csymbol cd="latexml" id="S5.T2.12.12.4.m1.1.1.1.cmml" xref="S5.T2.12.12.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.12.12.4.m1.1.1.2.cmml" xref="S5.T2.12.12.4.m1.1.1.2">0.42</cn><cn type="float" id="S5.T2.12.12.4.m1.1.1.3.cmml" xref="S5.T2.12.12.4.m1.1.1.3">0.35</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.12.12.4.m1.1c">0.42\pm 0.35</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x2.png" id="S5.F4.sf1.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x3.png" id="S5.F4.sf1.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x4.png" id="S5.F4.sf1.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x5.png" id="S5.F4.sf1.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F4.sf1.3.2" class="ltx_text" style="font-size:90%;">AC</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x6.png" id="S5.F4.sf2.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x7.png" id="S5.F4.sf2.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x8.png" id="S5.F4.sf2.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x9.png" id="S5.F4.sf2.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F4.sf2.3.2" class="ltx_text" style="font-size:90%;">BC</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x10.png" id="S5.F4.sf3.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x11.png" id="S5.F4.sf3.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x12.png" id="S5.F4.sf3.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x13.png" id="S5.F4.sf3.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F4.sf3.3.2" class="ltx_text" style="font-size:90%;">BF</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x14.png" id="S5.F4.sf4.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x15.png" id="S5.F4.sf4.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x16.png" id="S5.F4.sf4.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x17.png" id="S5.F4.sf4.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F4.sf4.3.2" class="ltx_text" style="font-size:90%;">BL</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x18.png" id="S5.F4.sf5.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x19.png" id="S5.F4.sf5.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x20.png" id="S5.F4.sf5.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x21.png" id="S5.F4.sf5.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S5.F4.sf5.3.2" class="ltx_text" style="font-size:90%;">BP</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf6" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x22.png" id="S5.F4.sf6.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x23.png" id="S5.F4.sf6.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x24.png" id="S5.F4.sf6.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x25.png" id="S5.F4.sf6.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf6.2.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><span id="S5.F4.sf6.3.2" class="ltx_text" style="font-size:90%;">CF</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf7" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x26.png" id="S5.F4.sf7.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x27.png" id="S5.F4.sf7.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x28.png" id="S5.F4.sf7.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x29.png" id="S5.F4.sf7.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf7.2.1.1" class="ltx_text" style="font-size:90%;">(g)</span> </span><span id="S5.F4.sf7.3.2" class="ltx_text" style="font-size:90%;">GH</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf8" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x30.png" id="S5.F4.sf8.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x31.png" id="S5.F4.sf8.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x32.png" id="S5.F4.sf8.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x33.png" id="S5.F4.sf8.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf8.2.1.1" class="ltx_text" style="font-size:90%;">(h)</span> </span><span id="S5.F4.sf8.3.2" class="ltx_text" style="font-size:90%;">MA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf9" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x34.png" id="S5.F4.sf9.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x35.png" id="S5.F4.sf9.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x36.png" id="S5.F4.sf9.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x37.png" id="S5.F4.sf9.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf9.2.1.1" class="ltx_text" style="font-size:90%;">(i)</span> </span><span id="S5.F4.sf9.3.2" class="ltx_text" style="font-size:90%;">ML</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf10" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x38.png" id="S5.F4.sf10.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x39.png" id="S5.F4.sf10.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x40.png" id="S5.F4.sf10.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x41.png" id="S5.F4.sf10.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf10.2.1.1" class="ltx_text" style="font-size:90%;">(j)</span> </span><span id="S5.F4.sf10.3.2" class="ltx_text" style="font-size:90%;">PP</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf11" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x42.png" id="S5.F4.sf11.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x43.png" id="S5.F4.sf11.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x44.png" id="S5.F4.sf11.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x45.png" id="S5.F4.sf11.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf11.2.1.1" class="ltx_text" style="font-size:90%;">(k)</span> </span><span id="S5.F4.sf11.3.2" class="ltx_text" style="font-size:90%;">SL</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S5.F4.sf12" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x46.png" id="S5.F4.sf12.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x47.png" id="S5.F4.sf12.g2" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x48.png" id="S5.F4.sf12.g3" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2304.01838/assets/x49.png" id="S5.F4.sf12.g4" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="664" height="1278" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf12.2.1.1" class="ltx_text" style="font-size:90%;">(l)</span> </span><span id="S5.F4.sf12.3.2" class="ltx_text" style="font-size:90%;">WO</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S5.F4.3.2" class="ltx_text" style="font-size:90%;">Example detections in the BugNIST classification images used for training the detection models. Rows show (top to bottom) the image, the training mask, the U-Net output and the nnDet output. Only the bounding box with the highest confidence is shown for nnDet. All images show a maximum projection of the 3D volume.</span></figcaption>
</figure>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.01838/assets/images/mix_detection/Mix_Unet_im.png" id="S5.F5.sf1.g1" class="ltx_graphics ltx_img_portrait" width="598" height="828" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F5.sf1.3.2" class="ltx_text" style="font-size:90%;">Data
<br class="ltx_break"> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.01838/assets/images/mix_detection/Mix_Unet_det.png" id="S5.F5.sf2.g1" class="ltx_graphics ltx_img_portrait" width="598" height="828" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F5.sf2.3.2" class="ltx_text" style="font-size:90%;">U-Net detections</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.01838/assets/images/mix_detection/Mix_nnDet_det.png" id="S5.F5.sf3.g1" class="ltx_graphics ltx_img_portrait" width="598" height="828" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F5.sf3.3.2" class="ltx_text" style="font-size:90%;">nnDet detections</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S5.F5.3.2" class="ltx_text" style="font-size:90%;">Example detection results on the mixture data. Each image shows a maximum projection of the 3D volume. Center point annotations are shown as black dots. See <a href="#S5.F4" title="In Detection ‣ 5 Results ‣ BugNIST: A New Large Scale Volumetric 3D Image Dataset for Classification and Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a> for color codes.</span></figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion and Conclusion</h2>

<section id="S6.SS0.SSS0.Px1" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Classification</h3>

<div id="S6.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p1.1" class="ltx_p">When creating the BugNIST dataset, the initial idea was to make a lightweight dataset for 3D volumetric image classification to create interest in volumetric data outside the medical domain. Our aim is to promote the development of methods for volumetric data with a different appearance than typical clinical data. Non-medical data is becoming more frequent and has received less attention than volumetric data from medical scanners.</p>
</div>
<div id="S6.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p2.1" class="ltx_p">When planning the data acquisition, we wanted to make sure that the data spanned a wide variety of shapes with natural variation. Therefore, we chose to scan bugs, because their morphology is both varied and relatively complex, and they have good contrast and small details like legs and antennae. We also wanted to ensure that the dataset was sufficiently large to capture the complexity and variance of the chosen types of bugs, and therefore we settled on approximately 750 individuals of each type. We also wanted to utilize the capability of the µCT scanner to ensure that the specimens were imaged at a resolution that was high enough to capture the morphological details of the bugs, such as wings, legs, antennas, hairs, etc., but with a scan time that was not too long. Therefore, we settled with the described setup of scanning multiple bugs together and segmenting them out to individual volumes afterwards.</p>
</div>
<div id="S6.SS0.SSS0.Px1.p3" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p3.1" class="ltx_p">We classified the individual bugs at varying resolutions with various models, and in all cases, the number of correctly classified bugs was surprisingly high. It seems that the task is easier than we expected. Our initial suspicion was that the different-sized straws and orientation of the bugs were determining the classification. To counteract that, the bugs were aligned and rescaled to have approximately the same size. This did not influence the results much, and we still obtained high classification rates.</p>
</div>
<div id="S6.SS0.SSS0.Px1.p4" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p4.1" class="ltx_p">Taking a closer look at the chosen bug types, there are significant morphological differences between most bugs. The most similar bugs are the brown and black cricket, the mealworm and the buffalo beetle larvae, and the two types of fly pupae. This was, however, only apparent from the classification of the crickets, which has an accuracy of around 80%. From this, we can conclude that a classification challenge for volumetric data must be more fine-grained for current state-of-the-art classification models to be challenged.</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px2" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Detection</h3>

<div id="S6.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px2.p1.1" class="ltx_p">To challenge the current deep learning models, we created a detection dataset. It is made up of volumes that contain mixtures of several bugs of the same or different species and are combined with other materials to ensure a variation in appearance. Here, the challenge is to determine how many bugs there are in a mixture and their location. But instead of training the model for detection and counting directly on the mixtures, the dataset is designed such that the models must be trained on the volumes of individual bugs and applied to the mixtures.</p>
</div>
<div id="S6.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S6.SS0.SSS0.Px2.p2.1" class="ltx_p">This shift in domain significantly increases how difficult the analysis problem is. Methods that can solve this problem will, however, also be applicable to solving a wider range of detection problems, where it is essential to learn the appearance of the features that characterize the individually scanned items. Furthermore, this task forces the model to learn different image features than what is needed for classifying the volumes of individually scanned bugs. In the classification problem, the bugs are placed in a volume with practically empty space around them. Here, the models can utilize the shape of the empty space as a feature for the classification. This is not possible in mixtures where several bugs are densely packed and mixed with material that is not present in the training data. Therefore, the detection model must focus on the appearance of the imaged bug and cannot rely on features of the surrounding space.</p>
</div>
<div id="S6.SS0.SSS0.Px2.p3" class="ltx_para">
<p id="S6.SS0.SSS0.Px2.p3.1" class="ltx_p">As an initial investigation for the detection problem, we have tested a multi-class segmentation using a U-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite>. Since the individual bug scans are trivially segmented using a threshold and a little image smoothing, the basis for training a U-Net on these images can easily be obtained. Training a U-Net turned out to be significantly more difficult than training a classifier, which is not that surprising since the model must now make pixel-wise labeling using the 13 labels (12 bugs and a background label). We also attempted to use the U-Net to detect bugs in the mixtures. Here, we saw that the model could segment the bugs, but often the label was wrong, and we also ran into the problem of multiple bugs being segmented as one connected component, which was difficult to separate into individual bugs.</p>
</div>
<div id="S6.SS0.SSS0.Px2.p4" class="ltx_para">
<p id="S6.SS0.SSS0.Px2.p4.1" class="ltx_p">Employing the nnDetect <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> as an alternative to U-Net, we saw a decrease in performance. This model is not designed for the type of problem posed here with the built-in domain shift. Based on the results from the detection and counting problem, we can conclude that current state-of-the-art models cannot solve a detection problem that is set up the way that we propose.</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px3" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Use of BugNIST </h3>

<div id="S6.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p1.1" class="ltx_p">Our findings are quite surprising. We did not expect that the classification of 3D data would be so easy, and we did not expect the counting and detection of 3D data would be so difficult.</p>
</div>
<div id="S6.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p2.1" class="ltx_p">For a human, 3D volumes are typically difficult to handle. Whether you visualize them as slices, volume- or surface renderings, it requires much manual interaction and handling to get a complete understanding. This is not the case for a 3D deep learning-based classifier that can utilize the full 3D information. The complexity of the individual bug scans is therefore much less than one would expect, meaning that the variation within a class is much smaller than between classes, which is demonstrated by the high classification rates obtained for a range of standard methods.</p>
</div>
<div id="S6.SS0.SSS0.Px3.p3" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p3.1" class="ltx_p">From the observation of how easy classifying 12 species of bugs is, we expect that more fine-grained classification of volumetric data can also be solved. By more fine-grained, we mean specimens that have high similarity but still belong to different classes. Fine-grained classification would also entail more classes with fewer training samples from each class than we have recorded in the BugNIST dataset. This will, however, require that objects can be scanned as individual specimens, which is possible for objects like bugs.</p>
</div>
<div id="S6.SS0.SSS0.Px3.p4" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p4.1" class="ltx_p">The most common situation, however, is that you need to detect objects in 3D volumes with other materials. In these cases, it can be a great advantage to have models that can learn to focus on the object of interest and ignore the other materials, like we have set up the challenge for the mixtures in the BugNIST dataset. Other datasets do not pose the detection challenge this way. In other volumetric datasets, the detection is learned in the same domain. The objects of interest are annotated in volumes and the task is to detect objects with the appearance of the context where they are placed. Therefore, the detection models will have both the object’s appearance and its context as input for learning the detection. Separating the two will ensure that the detection model learns the appearance of the object. As we have shown, this is surprisingly difficult, but with BugNIST it is now possible to start investigating and developing models that can handle this challenge.</p>
</div>
<div id="S6.SS0.SSS0.Px3.p5" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p5.1" class="ltx_p">BugNIST is an extensive dataset that can have other valuable use cases than what we have explored in this paper. It could be used for exploring segmentation methods, generative models, or image registration. The fact that we have scanned many specimens of each species also makes it possible to investigate methods for analyzing the morphological variation of the scanned bugs. Despite the limited scientific interest of the scanned bugs, the methodological developments can be significant. There might be many other uses, that add to the value of the BugNIST dataset.</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px4" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Conclusion</h3>

<div id="S6.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px4.p1.1" class="ltx_p">Creating the BugNIST dataset and investigating its use for classification and detection has given important insights that set the direction for future research. Current state-of-the-art methods are able to classify 3D volumes of individual objects to a high degree of precision, and the expected methodological improvements for classification models that can be obtained from BugNIST will be marginal. This shows that there is a need for a fine-grained volumetric classification dataset. We also find that object detection in volumetric data is much more difficult than classification. This is especially the case when posing the detection problem as we have done in the BugNIST dataset, where there is a set of individually scanned bugs for training the detector and another set of mixed volumes for detecting the bugs. This illustrates that for volumetric image analysis, there are still many unsolved problems and a great need for standard benchmark data for promoting this research. BugNIST is a dataset, that fills out some of this gap and hereby promotes research in deep learning-based methods for 3D volumetric images.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.5.5.1" class="ltx_text" style="font-size:90%;">Afshar et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.7.1" class="ltx_text" style="font-size:90%;">
P. Afshar, S. Heidarian, N. Enshaei, F. Naderkhani, M. J. Rafiee, A. Oikonomou,
F. B. Fard, K. Samimi, K. N. Plataniotis, and A. Mohammadi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.8.1" class="ltx_text" style="font-size:90%;">Covid-ct-md, covid-19 computed tomography scan dataset applicable in
machine learning and deep learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib1.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Scientific Data</em><span id="bib.bib1.10.2" class="ltx_text" style="font-size:90%;">, 8(1):121, 2021.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:90%;">Antonelli et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:90%;">
M. Antonelli, A. Reinke, S. Bakas, K. Farahani, A. Kopp-Schneider, B. A.
Landman, G. Litjens, B. Menze, O. Ronneberger, R. M. Summers, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">The medical segmentation decathlon.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib2.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Nature communications</em><span id="bib.bib2.10.2" class="ltx_text" style="font-size:90%;">, 13(1):4128, 2022.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">Armato III et al. [2011]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:90%;">
S. G. Armato III, G. McLennan, L. Bidaut, M. F. McNitt-Gray, C. R. Meyer, A. P.
Reeves, B. Zhao, D. R. Aberle, C. I. Henschke, E. A. Hoffman, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:90%;">The lung image database consortium (lidc) and image database resource
initiative (idri): a completed reference database of lung nodules on ct
scans.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib3.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Medical physics</em><span id="bib.bib3.10.2" class="ltx_text" style="font-size:90%;">, 38(2):915–931, 2011.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:90%;">Armato III et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:90%;">
S. G. Armato III, H. Huisman, K. Drukker, L. Hadjiiski, J. S. Kirby,
N. Petrick, G. Redmond, M. L. Giger, K. Cha, A. Mamonov, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text" style="font-size:90%;">Prostatex challenges for computerized classification of prostate
lesions from multiparametric magnetic resonance images.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib4.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of Medical Imaging</em><span id="bib.bib4.10.2" class="ltx_text" style="font-size:90%;">, 5(4):044501–044501, 2018.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">Baumgartner et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:90%;">
M. Baumgartner, P. F. Jäger, F. Isensee, and K. H. Maier-Hein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:90%;">nndetection: a self-configuring method for medical object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib5.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Medical Image Computing and Computer Assisted
Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France,
September 27–October 1, 2021, Proceedings, Part V 24</em><span id="bib.bib5.11.3" class="ltx_text" style="font-size:90%;">, pages 530–539.
Springer, 2021.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Cardoso et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:90%;">
M. J. Cardoso, W. Li, R. Brown, N. Ma, E. Kerfoot, Y. Wang, B. Murrey,
A. Myronenko, C. Zhao, D. Yang, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text" style="font-size:90%;">Monai: An open-source framework for deep learning in healthcare.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib6.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2211.02701</em><span id="bib.bib6.10.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:90%;">Chaudhary et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:90%;">
S. Chaudhary, S. Sadbhawna, V. Jakhetiya, B. N. Subudhi, U. Baid, and S. C.
Guntuku.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.8.1" class="ltx_text" style="font-size:90%;">Detecting covid-19 and community acquired pneumonia using chest ct
scan images with deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib7.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICASSP 2021-2021 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</em><span id="bib.bib7.11.3" class="ltx_text" style="font-size:90%;">, pages 8583–8587. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Cheng et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:90%;">
D. Cheng, M. Liu, J. Fu, and Y. Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:90%;">Classification of mr brain images by combination of multi-cnns for ad
diagnosis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib8.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Ninth international conference on digital image processing
(ICDIP 2017)</em><span id="bib.bib8.11.3" class="ltx_text" style="font-size:90%;">, volume 10420, pages 875–879. SPIE, 2017.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Çiçek et al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:90%;">
Ö. Çiçek, A. Abdulkadir, S. S. Lienkamp, T. Brox, and
O. Ronneberger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.8.1" class="ltx_text" style="font-size:90%;">3d u-net: learning dense volumetric segmentation from sparse
annotation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib9.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Medical Image Computing and Computer-Assisted
Intervention–MICCAI 2016: 19th International Conference, Athens, Greece,
October 17-21, 2016, Proceedings, Part II 19</em><span id="bib.bib9.11.3" class="ltx_text" style="font-size:90%;">, pages 424–432. Springer,
2016.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Dosovitskiy et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:90%;">
A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,
T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit,
and N. Houlsby.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text" style="font-size:90%;">An image is worth 16x16 words: Transformers for image recognition at
scale.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib10.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib10.11.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Flitton et al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:90%;">
G. Flitton, A. Mouton, and T. P. Breckon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:90%;">Object classification in 3d baggage security computed tomography
imagery using visual codebooks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib11.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Pattern Recognition</em><span id="bib.bib11.10.2" class="ltx_text" style="font-size:90%;">, 48(8):2489–2499,
2015.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.4.4.1" class="ltx_text" style="font-size:90%;">Girshick [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text" style="font-size:90%;">
R. Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:90%;">Fast r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib12.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</em><span id="bib.bib12.10.3" class="ltx_text" style="font-size:90%;">, pages 1440–1448, 2015.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text" style="font-size:90%;">Girshick et al. [2014]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:90%;">
R. Girshick, J. Donahue, T. Darrell, and J. Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text" style="font-size:90%;">Rich feature hierarchies for accurate object detection and semantic
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib13.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</em><span id="bib.bib13.11.3" class="ltx_text" style="font-size:90%;">, pages 580–587, 2014.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:90%;">Harmon et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">
S. A. Harmon, T. H. Sanford, S. Xu, E. B. Turkbey, H. Roth, Z. Xu, D. Yang,
A. Myronenko, V. Anderson, A. Amalou, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:90%;">Artificial intelligence for the detection of covid-19 pneumonia on
chest ct using multinational datasets.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib14.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Nature communications</em><span id="bib.bib14.10.2" class="ltx_text" style="font-size:90%;">, 11(1):4080, 2020.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:90%;">He et al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:90%;">
K. He, X. Zhang, S. Ren, and J. Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib15.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</em><span id="bib.bib15.11.3" class="ltx_text" style="font-size:90%;">, pages 770–778, 2016.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:90%;">Hu et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:90%;">
J. Hu, L. Shen, and G. Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:90%;">Squeeze-and-excitation networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib16.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</em><span id="bib.bib16.11.3" class="ltx_text" style="font-size:90%;">, pages 7132–7141, 2018.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:90%;">Huang et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:90%;">
G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:90%;">Densely connected convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib17.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</em><span id="bib.bib17.11.3" class="ltx_text" style="font-size:90%;">, pages 4700–4708, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:90%;">Isensee et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:90%;">
F. Isensee, P. F. Jaeger, S. A. Kohl, J. Petersen, and K. H. Maier-Hein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text" style="font-size:90%;">nnu-net: a self-configuring method for deep learning-based biomedical
image segmentation.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib18.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Nature methods</em><span id="bib.bib18.10.2" class="ltx_text" style="font-size:90%;">, 18(2):203–211, 2021.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:90%;">Jaeger et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:90%;">
P. F. Jaeger, S. A. Kohl, S. Bickelhaupt, F. Isensee, T. A. Kuder, H.-P.
Schlemmer, and K. H. Maier-Hein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text" style="font-size:90%;">Retina u-net: Embarrassingly simple exploitation of segmentation
supervision for medical object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib19.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Machine Learning for Health Workshop</em><span id="bib.bib19.11.3" class="ltx_text" style="font-size:90%;">, pages 171–183. PMLR,
2020.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:90%;">Jeppesen et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:90%;">
N. Jeppesen, A. N. Christensen, V. A. Dahl, and A. B. Dahl.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text" style="font-size:90%;">Sparse layered graphs for multi-object segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib20.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib20.11.3" class="ltx_text" style="font-size:90%;">, pages 12777–12785, 2020.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:90%;">Jin et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:90%;">
L. Jin, J. Yang, K. Kuang, B. Ni, Y. Gao, Y. Sun, P. Gao, W. Ma, M. Tan,
H. Kang, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:90%;">Deep-learning-assisted detection and segmentation of rib fractures
from ct scans: Development and validation of fracnet.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib21.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">EBioMedicine</em><span id="bib.bib21.10.2" class="ltx_text" style="font-size:90%;">, 62:103106, 2020.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:90%;">Ker et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:90%;">
J. Ker, S. P. Singh, Y. Bai, J. Rao, T. Lim, and L. Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text" style="font-size:90%;">Image thresholding improves 3-dimensional convolutional neural
network diagnosis of different acute brain hemorrhages on computed tomography
scans.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib22.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Sensors</em><span id="bib.bib22.10.2" class="ltx_text" style="font-size:90%;">, 19(9):2167, 2019.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">LeCun et al. [1998]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:90%;">
Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:90%;">Gradient-based learning applied to document recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib23.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE</em><span id="bib.bib23.10.2" class="ltx_text" style="font-size:90%;">, 86(11):2278–2324, 1998.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:90%;">Lin et al. [2014]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:90%;">
T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,
P. Dollár, and C. L. Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib24.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European conference on computer vision</em><span id="bib.bib24.11.3" class="ltx_text" style="font-size:90%;">, pages 740–755.
Springer, 2014.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:90%;">Lin et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:90%;">
T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text" style="font-size:90%;">Focal loss for dense object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib25.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</em><span id="bib.bib25.11.3" class="ltx_text" style="font-size:90%;">, pages 2980–2988, 2017.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Liu et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text" style="font-size:90%;">
Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text" style="font-size:90%;">Swin transformer: Hierarchical vision transformer using shifted
windows.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib26.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on
computer vision</em><span id="bib.bib26.11.3" class="ltx_text" style="font-size:90%;">, pages 10012–10022, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:90%;">Liu et al. [2022a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text" style="font-size:90%;">
Z. Liu, H. Hu, Y. Lin, Z. Yao, Z. Xie, Y. Wei, J. Ning, Y. Cao, Z. Zhang,
L. Dong, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.8.1" class="ltx_text" style="font-size:90%;">Swin transformer v2: Scaling up capacity and resolution.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib27.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em><span id="bib.bib27.11.3" class="ltx_text" style="font-size:90%;">, pages 12009–12019, 2022a.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:90%;">Liu et al. [2022b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:90%;">
Z. Liu, H. Mao, C.-Y. Wu, C. Feichtenhofer, T. Darrell, and S. Xie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text" style="font-size:90%;">A convnet for the 2020s.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib28.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib28.11.3" class="ltx_text" style="font-size:90%;">, pages 11976–11986, 2022b.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:90%;">Maier-Hein et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:90%;">
L. Maier-Hein, M. Eisenmann, A. Reinke, S. Onogur, M. Stankovic, P. Scholz,
T. Arbel, H. Bogunovic, A. P. Bradley, A. Carass, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text" style="font-size:90%;">Why rankings of biomedical image analysis competitions should be
interpreted with care.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib29.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Nature communications</em><span id="bib.bib29.10.2" class="ltx_text" style="font-size:90%;">, 9(1):5217, 2018.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.4.4.1" class="ltx_text" style="font-size:90%;">maintainers and contributors [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.6.1" class="ltx_text" style="font-size:90%;">
T. maintainers and contributors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text" style="font-size:90%;">Torchvision: Pytorch’s computer vision library.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/pytorch/vision" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/pytorch/vision</a><span id="bib.bib30.8.1" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:90%;">Minaee et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:90%;">
S. Minaee, Y. Y. Boykov, F. Porikli, A. J. Plaza, N. Kehtarnavaz, and
D. Terzopoulos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:90%;">Image segmentation using deep learning: A survey.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib31.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine
intelligence</em><span id="bib.bib31.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:90%;">Morozov et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text" style="font-size:90%;">
S. P. Morozov, A. Andreychenko, N. Pavlov, A. Vladzymyrskyy, N. Ledikhova,
V. Gombolevskiy, I. A. Blokhin, P. Gelezhe, A. Gonchar, and V. Y. Chernina.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text" style="font-size:90%;">Mosmeddata: Chest ct scans with covid-19 related findings dataset.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib32.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2005.06465</em><span id="bib.bib32.10.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.4.4.1" class="ltx_text" style="font-size:90%;">Munkres [1957]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.6.1" class="ltx_text" style="font-size:90%;">
J. Munkres.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text" style="font-size:90%;">Algorithms for the assignment and transportation problems.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib33.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of the society for industrial and applied mathematics</em><span id="bib.bib33.9.2" class="ltx_text" style="font-size:90%;">,
5(1):32–38, 1957.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.5.5.1" class="ltx_text" style="font-size:90%;">Redmon et al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text" style="font-size:90%;">
J. Redmon, S. Divvala, R. Girshick, and A. Farhadi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.8.1" class="ltx_text" style="font-size:90%;">You only look once: Unified, real-time object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib34.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</em><span id="bib.bib34.11.3" class="ltx_text" style="font-size:90%;">, pages 779–788, 2016.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:90%;">Ren et al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text" style="font-size:90%;">
S. Ren, K. He, R. Girshick, and J. Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text" style="font-size:90%;">Faster r-cnn: Towards real-time object detection with region proposal
networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib35.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib35.10.2" class="ltx_text" style="font-size:90%;">, 28, 2015.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:90%;">Ronneberger et al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text" style="font-size:90%;">
O. Ronneberger, P. Fischer, and T. Brox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text" style="font-size:90%;">U-net: Convolutional networks for biomedical image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib36.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Medical Image Computing and Computer-Assisted
Intervention–MICCAI 2015: 18th International Conference, Munich, Germany,
October 5-9, 2015, Proceedings, Part III 18</em><span id="bib.bib36.11.3" class="ltx_text" style="font-size:90%;">, pages 234–241. Springer, 2015.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text" style="font-size:90%;">Russakovsky et al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text" style="font-size:90%;">
O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang,
A. Karpathy, A. Khosla, M. Bernstein, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text" style="font-size:90%;">Imagenet large scale visual recognition challenge.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib37.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">International journal of computer vision</em><span id="bib.bib37.10.2" class="ltx_text" style="font-size:90%;">, 115(3):211–252, 2015.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.4.4.1" class="ltx_text" style="font-size:90%;">Serte and Demirel [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.6.1" class="ltx_text" style="font-size:90%;">
S. Serte and H. Demirel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text" style="font-size:90%;">Deep learning for diagnosis of covid-19 using 3d ct scans.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib38.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computers in biology and medicine</em><span id="bib.bib38.9.2" class="ltx_text" style="font-size:90%;">, 132:104306, 2021.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:90%;">Setio et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text" style="font-size:90%;">
A. A. A. Setio, A. Traverso, T. De Bel, M. S. Berens, C. Van Den Bogaard,
P. Cerello, H. Chen, Q. Dou, M. E. Fantacci, B. Geurts, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.8.1" class="ltx_text" style="font-size:90%;">Validation, comparison, and combination of algorithms for automatic
detection of pulmonary nodules in computed tomography images: the luna16
challenge.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib39.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Medical image analysis</em><span id="bib.bib39.10.2" class="ltx_text" style="font-size:90%;">, 42:1–13, 2017.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:90%;">Simpson et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text" style="font-size:90%;">
A. L. Simpson, M. Antonelli, S. Bakas, M. Bilello, K. Farahani, B. van
Ginneken, A. Kopp-Schneider, B. A. Landman, G. Litjens, B. H. Menze,
O. Ronneberger, R. M. Summers, P. Bilic, P. F. Christ, R. K. G. Do,
M. Gollub, J. Golia-Pernicka, S. Heckers, W. R. Jarnagin, M. McHugo,
S. Napel, E. Vorontsov, L. Maier-Hein, and M. J. Cardoso.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.8.1" class="ltx_text" style="font-size:90%;">A large annotated medical image dataset for the development and
evaluation of segmentation algorithms.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib40.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib40.10.2" class="ltx_text" style="font-size:90%;">, abs/1902.09063, 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.11.1" class="ltx_text" style="font-size:90%;">URL </span><a target="_blank" href="http://arxiv.org/abs/1902.09063" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">http://arxiv.org/abs/1902.09063</a><span id="bib.bib40.12.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.5.5.1" class="ltx_text" style="font-size:90%;">Timmins et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text" style="font-size:90%;">
K. M. Timmins, I. C. van der Schaaf, E. Bennink, Y. M. Ruigrok, X. An,
M. Baumgartner, P. Bourdon, R. De Feo, T. Di Noto, F. Dubost, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.8.1" class="ltx_text" style="font-size:90%;">Comparing methods of detecting and segmenting unruptured intracranial
aneurysms on tof-mras: The adam challenge.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib41.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Neuroimage</em><span id="bib.bib41.10.2" class="ltx_text" style="font-size:90%;">, 238:118216, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text" style="font-size:90%;">Walsh et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.7.1" class="ltx_text" style="font-size:90%;">
C. Walsh, P. Tafforeau, W. Wagner, D. Jafree, A. Bellier, C. Werlein,
M. Kühnel, E. Boller, S. Walker-Samuel, J. Robertus, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.8.1" class="ltx_text" style="font-size:90%;">Imaging intact human organs with local resolution of cellular
structures using hierarchical phase-contrast tomography.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib42.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Nature methods</em><span id="bib.bib42.10.2" class="ltx_text" style="font-size:90%;">, 18(12):1532–1541, 2021.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text" style="font-size:90%;">Wang et al. [2020a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text" style="font-size:90%;">
Q. Wang, N. Bhowmik, and T. P. Breckon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.8.1" class="ltx_text" style="font-size:90%;">On the evaluation of prohibited item classification and detection in
volumetric 3d computed tomography baggage security screening imagery.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib43.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 International Joint Conference on Neural Networks
(IJCNN)</em><span id="bib.bib43.11.3" class="ltx_text" style="font-size:90%;">, pages 1–8. IEEE, 2020a.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text" style="font-size:90%;">Wang et al. [2020b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text" style="font-size:90%;">
Q. Wang, N. Bhowmik, and T. P. Breckon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text" style="font-size:90%;">Multi-class 3d object detection within volumetric 3d computed
tomography baggage security screening imagery.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib44.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 19th IEEE International Conference on Machine Learning
and Applications (ICMLA)</em><span id="bib.bib44.11.3" class="ltx_text" style="font-size:90%;">, pages 13–18. IEEE, 2020b.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text" style="font-size:90%;">Withers et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text" style="font-size:90%;">
P. J. Withers, C. Bouman, S. Carmignato, V. Cnudde, D. Grimaldi, C. K. Hagen,
E. Maire, M. Manley, A. Du Plessis, and S. R. Stock.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text" style="font-size:90%;">X-ray computed tomography.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib45.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Nature Reviews Methods Primers</em><span id="bib.bib45.10.2" class="ltx_text" style="font-size:90%;">, 1(1):18,
2021.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text" style="font-size:90%;">Xiao et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text" style="font-size:90%;">
Z. Xiao, B. Liu, L. Geng, F. Zhang, and Y. Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.8.1" class="ltx_text" style="font-size:90%;">Segmentation of lung nodules using improved 3d-unet neural network.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib46.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Symmetry</em><span id="bib.bib46.10.2" class="ltx_text" style="font-size:90%;">, 12(11):1787, 2020.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.4.4.1" class="ltx_text" style="font-size:90%;">Xie and Ji [2002]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.6.1" class="ltx_text" style="font-size:90%;">
Y. Xie and Q. Ji.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text" style="font-size:90%;">A new efficient ellipse detection method.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib47.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2002 International Conference on Pattern Recognition</em><span id="bib.bib47.10.3" class="ltx_text" style="font-size:90%;">,
volume 2, pages 957–960. IEEE, 2002.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.5.5.1" class="ltx_text" style="font-size:90%;">Yang et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text" style="font-size:90%;">
J. Yang, R. Shi, and B. Ni.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.8.1" class="ltx_text" style="font-size:90%;">Medmnist classification decathlon: A lightweight automl benchmark for
medical image analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib48.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 IEEE 18th International Symposium on Biomedical Imaging
(ISBI)</em><span id="bib.bib48.11.3" class="ltx_text" style="font-size:90%;">, pages 191–195. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text" style="font-size:90%;">Yang et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.7.1" class="ltx_text" style="font-size:90%;">
J. Yang, R. Shi, D. Wei, Z. Liu, L. Zhao, B. Ke, H. Pfister, and B. Ni.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.8.1" class="ltx_text" style="font-size:90%;">Medmnist v2-a large-scale lightweight benchmark for 2d and 3d
biomedical image classification.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib49.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Scientific Data</em><span id="bib.bib49.10.2" class="ltx_text" style="font-size:90%;">, 10(1):41, 2023.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.5.5.1" class="ltx_text" style="font-size:90%;">Zhou et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.7.1" class="ltx_text" style="font-size:90%;">
S. K. Zhou, H. Greenspan, C. Davatzikos, J. S. Duncan, B. Van Ginneken,
A. Madabhushi, J. L. Prince, D. Rueckert, and R. M. Summers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.8.1" class="ltx_text" style="font-size:90%;">A review of deep learning in medical imaging: Imaging traits,
technology trends, case studies with progress highlights, and future
promises.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib50.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE</em><span id="bib.bib50.10.2" class="ltx_text" style="font-size:90%;">, 109(5):820–838,
2021.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2304.01837" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2304.01838" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2304.01838">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2304.01838" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2304.01839" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 16:14:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
