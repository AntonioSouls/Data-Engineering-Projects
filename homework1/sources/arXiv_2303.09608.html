<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.09608] VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection</title><meta property="og:description" content="The use of large-scale vision-language datasets is limited for object detection due to the negative impact of label noise on localization. Prior methods have shown how such large-scale datasets can be used for pretrain…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.09608">

<!--Generated on Thu Feb 29 19:32:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arushi Rai
<br class="ltx_break">University of Pittsburgh
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">arr159@pitt.edu</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Adriana Kovashka
<br class="ltx_break">University of Pittsburgh
<br class="ltx_break"><span id="id2.1.id1" class="ltx_text ltx_font_typewriter">kovashka@cs.pitt.edu</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">The use of large-scale vision-language datasets is limited for object detection due to the negative impact of label noise on localization. Prior methods have shown how such large-scale datasets can be used for pretraining, which can provide initial signal for localization, but is insufficient without clean bounding-box data for at least some categories. We propose a technique to “vet” labels extracted from noisy captions, and use them for weakly-supervised object detection (WSOD). We conduct analysis of the types of label noise in captions, and train a classifier that predicts if an extracted label is actually present in the image or not. Our classifier generalizes across dataset boundaries and across categories. We compare the classifier to eleven baselines on five datasets, and demonstrate that it can improve WSOD without label vetting by 30% (31.2 to 40.5 mAP when evaluated on PASCAL VOC).</p>
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Introduction</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Freely available vision-language (VL) data has shown great promise to advance vision tasks <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>; Mahajan et al. <a href="#bib.bib21" title="" class="ltx_ref">2018</a>; Jia et al. <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>. However, the same advances have not been observed in weakly-supervised object detection.
Unlike smaller, curated vision-language datasets like MS COCO <cite class="ltx_cite ltx_citemacro_citep">(Lin et al. <a href="#bib.bib20" title="" class="ltx_ref">2014</a>)</cite>,
captions on the web <cite class="ltx_cite ltx_citemacro_citep">(Ordonez, Kulkarni, and Berg <a href="#bib.bib23" title="" class="ltx_ref">2011</a>; Desai et al. <a href="#bib.bib4" title="" class="ltx_ref">2021</a>; Changpinyo et al. <a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite> only <span id="Sx1.p1.1.1" class="ltx_text ltx_font_italic">partially</span> describe the corresponding image, and often describe the <span id="Sx1.p1.1.2" class="ltx_text ltx_font_italic">context</span> behind the image. Thus, not only do these datasets contain user-uploaded images with significant visual diversity, but captions contain mentions of objects that do not actually appear in the image. We hypothesize this poses a greater challenge for implicitly learning localization through weakly-supervised object detection (WSOD), than learning cross-modal representations and image recognition. Thus, WSOD has primarily been applied <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib39" title="" class="ltx_ref">2019a</a>; Fang et al. <a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite> to smaller-scale paid-for crowdsourced vision-language datasets like COCO <cite class="ltx_cite ltx_citemacro_citep">(Lin et al. <a href="#bib.bib20" title="" class="ltx_ref">2014</a>)</cite> and Flickr30K <cite class="ltx_cite ltx_citemacro_citep">(Young et al. <a href="#bib.bib41" title="" class="ltx_ref">2014</a>)</cite> until recently <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al. <a href="#bib.bib46" title="" class="ltx_ref">2022</a>; Gao et al. <a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<figure id="Sx1.F1" class="ltx_figure"><img src="/html/2303.09608/assets/iccv2023AuthorKit/figures/images/concept_fig_underlined.png" id="Sx1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="330" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Extracted labels from captions can raise various challenges. Linguistic indicators explaining missing objects or defects are annotated in our dataset, <span id="Sx1.F1.4.1" class="ltx_text ltx_font_bold">C</span>aption <span id="Sx1.F1.5.2" class="ltx_text ltx_font_bold">La</span>bel <span id="Sx1.F1.6.3" class="ltx_text ltx_font_bold">N</span>oise.</figcaption>
</figure>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">Unlike captions written by annotators for the purpose of faithfully describing an image, captions on the web go beyond a redundant, descriptive relationship with their corresponding image. Language is colorful, a word can be used in literal or metaphorical ways (“that was a piece of <span id="Sx1.p2.1.1" class="ltx_text ltx_framed ltx_framed_underline">cake</span>”). A word can have multiple senses, of which only one corresponds to the sense intended by the object detection vocabulary. Frequently, a caption could share a story by including context that goes beyond the visual contents of the image but mention the object, like providing location names and unpictured interactions with objects as shown in Figure <a href="#Sx1.F1" title="Figure 1 ‣ Introduction ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
User-uploaded content feature diverse object presentations, including photos taken from within vehicles, and intriguing atypical presentations of deformed objects and hand-drawn objects; all of this is relevant for narration for the image but not as supervision for precise localization. We refer to image-level labels extracted from captions, that are incorrect (object not present in corresponding image), as <span id="Sx1.p2.1.2" class="ltx_text ltx_font_bold">v</span>isually <span id="Sx1.p2.1.3" class="ltx_text ltx_font_bold">a</span>bsent <span id="Sx1.p2.1.4" class="ltx_text ltx_font_bold">e</span>xtracted <span id="Sx1.p2.1.5" class="ltx_text ltx_font_bold">l</span>abels (VAELs). We show that VAELs pose a challenge for weakly-supervised detection.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p id="Sx1.p3.1" class="ltx_p">To cope with this challenge and mitigate this noise, we propose <span id="Sx1.p3.1.1" class="ltx_text ltx_font_bold">VEIL</span>, short for <span id="Sx1.p3.1.2" class="ltx_text ltx_font_bold">V</span>etting <span id="Sx1.p3.1.3" class="ltx_text ltx_font_bold">E</span>xtracted <span id="Sx1.p3.1.4" class="ltx_text ltx_font_bold">I</span>mage <span id="Sx1.p3.1.5" class="ltx_text ltx_font_bold">L</span>abels, to directly learn whether a label is clean or not from <span id="Sx1.p3.1.6" class="ltx_text ltx_font_italic">caption context</span>.
We first extract potential labels from each caption using substring matching or exact match <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib40" title="" class="ltx_ref">2019b</a>; Fang et al. <a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>.
We then use a transformer to
predict whether each extracted label is visually present or absent. We refer to this prediction <em id="Sx1.p3.1.7" class="ltx_emph ltx_font_italic">task</em> as extracted label vetting (ELV or vetting for short).
We bootstrap labels from an ensemble of two pretrained object recognition models <cite class="ltx_cite ltx_citemacro_citep">(Jocher et al. <a href="#bib.bib15" title="" class="ltx_ref">2021</a>; Zhang et al. <a href="#bib.bib44" title="" class="ltx_ref">2021</a>)</cite>, to predict pseudo-ground-truth visual presence labels on a variety of large-scale, noisy datasets: Conceptual Captions <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al. <a href="#bib.bib31" title="" class="ltx_ref">2018</a>)</cite>, RedCaps <cite class="ltx_cite ltx_citemacro_citep">(Desai et al. <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>, and SBUCaps <cite class="ltx_cite ltx_citemacro_citep">(Ordonez, Kulkarni, and Berg <a href="#bib.bib23" title="" class="ltx_ref">2011</a>)</cite>. While
these detectors are trained on COCO <cite class="ltx_cite ltx_citemacro_citep">(Lin et al. <a href="#bib.bib20" title="" class="ltx_ref">2014</a>)</cite>,
VisualGenome <cite class="ltx_cite ltx_citemacro_citep">(Krishna et al. <a href="#bib.bib17" title="" class="ltx_ref">2016</a>)</cite>, OpenImages <cite class="ltx_cite ltx_citemacro_citep">(Kuznetsova et al. <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite>, and Objects365 <cite class="ltx_cite ltx_citemacro_citep">(Shao et al. <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite>, they generalize well to estimating extracted label visual presence on the VL datasets we used.
Once we vet the extracted labels, we use them to train a weakly-supervised object detector.</p>
</div>
<div id="Sx1.p4" class="ltx_para">
<p id="Sx1.p4.1" class="ltx_p">We investigate sources of noise across three in-the-wild datasets from diverse sources: photo-sharing platform, social media platform, and images with alt-text (typically used for VL pretraining). We collect and will release a small dataset with annotations on object visibility (label noise) and object appearance defects (visual noise such as occlusion, missing key parts, and atypical appearance). To further show support for using language context to filter object labels, we annotate linguistic indicators of noise which
explain why a VAEL is absent from the image but included in the caption, such as describing context outside the image, non-literal use, different word sense, etc. We find prevalent structured noise (there is a pattern to the images associated with a particular noisy label) from linguistic indicators like “noun modifier” and “prepositional phrase”.
</p>
</div>
<div id="Sx1.p5" class="ltx_para">
<p id="Sx1.p5.1" class="ltx_p">We compare our label vetting method to eleven baselines, including standard cross-modal alignment prediction methods (CLIP), adaptive noise reduction methods, pseudo-label prediction, simple rule-based methods, and no vetting. Our method improves upon the baselines both in terms of predicting extracted label visual presence (measured with F1) and producing cleaner training data for object detection leading to an improvement of +10 mAP over Large Loss Matters <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite> and +3 mAP improvement over using CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite> for filtering.
Additionally, we show that VEIL generalizes across dataset and vocabulary.
We show a significant improvement when training WSOD with both clean labels from Pascal VOC 07 (annotated) and noisy, but vetted labels from SBUCaps (51.31 mAP) compared to combining clean labels with the noisy labels without vetting (42.06 mAP) or only using clean labels (43.48 mAP). Lastly, we show that WSOD performance improves with vetting over no vetting as the train dataset is scaled.
</p>
</div>
<div id="Sx1.p6" class="ltx_para">
<p id="Sx1.p6.1" class="ltx_p">Our contributions are as follows:</p>
<ol id="Sx1.I1" class="ltx_enumerate">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i1.p1.1" class="ltx_p">We propose VEIL, a transformer-based extracted label, visual presence classifier.</p>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i2.p1.1" class="ltx_p">We apply VEIL and compare both across constructed-for-pay image caption datasets <cite class="ltx_cite ltx_citemacro_citep">(Huang et al. <a href="#bib.bib13" title="" class="ltx_ref">2016</a>; Lin et al. <a href="#bib.bib20" title="" class="ltx_ref">2014</a>)</cite> and a wide set of in-the-wild datasets whose sources span social media <cite class="ltx_cite ltx_citemacro_citep">(Desai et al. <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>, photo-sharing platforms <cite class="ltx_cite ltx_citemacro_citep">(Ordonez, Kulkarni, and Berg <a href="#bib.bib23" title="" class="ltx_ref">2011</a>)</cite>, and image-alt-text pairs <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al. <a href="#bib.bib31" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i3.p1.1" class="ltx_p">VEIL performs better than language-conditioned and language-agnostic label noise detection/correction approaches
in recognizing visually present extracted labels and when vetting labels for weakly-supervised object detection.
</p>
</div>
</li>
<li id="Sx1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="Sx1.I1.i4.p1" class="ltx_para">
<p id="Sx1.I1.i4.p1.1" class="ltx_p">Even when VEIL is trained on one dataset, but applied to another dataset, there are similar gains in WSOD.</p>
</div>
</li>
<li id="Sx1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="Sx1.I1.i5.p1" class="ltx_para">
<p id="Sx1.I1.i5.p1.1" class="ltx_p">VEIL shows potential to generalize across categories.</p>
</div>
</li>
<li id="Sx1.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span> 
<div id="Sx1.I1.i6.p1" class="ltx_para">
<p id="Sx1.I1.i6.p1.1" class="ltx_p">Vetting with VEIL improves WSOD performance when scaling training data and effectively combines extracted labels (noisy) with clean labels.</p>
</div>
</li>
<li id="Sx1.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span> 
<div id="Sx1.I1.i7.p1" class="ltx_para">
<p id="Sx1.I1.i7.p1.1" class="ltx_p">We annotate 300 samples from three in-the-wild datasets and release the <span id="Sx1.I1.i7.p1.1.1" class="ltx_text ltx_font_bold">C</span>aption <span id="Sx1.I1.i7.p1.1.2" class="ltx_text ltx_font_bold">La</span>bel <span id="Sx1.I1.i7.p1.1.3" class="ltx_text ltx_font_bold">N</span>oise (CLaN) dataset.
</p>
</div>
</li>
</ol>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Related Work</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p"><span id="Sx2.p1.1.1" class="ltx_text ltx_font_bold">Vision-language datasets.</span>
Common datasets <cite class="ltx_cite ltx_citemacro_citep">(Young et al. <a href="#bib.bib41" title="" class="ltx_ref">2014</a>; Lin et al. <a href="#bib.bib20" title="" class="ltx_ref">2014</a>; Huang et al. <a href="#bib.bib13" title="" class="ltx_ref">2016</a>)</cite> contain high-level multiple crowdsourced captions per image, including dense captions <cite class="ltx_cite ltx_citemacro_citep">(Krishna et al. <a href="#bib.bib17" title="" class="ltx_ref">2016</a>)</cite>.
Alt-text written by users to aid visually impaired readers <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al. <a href="#bib.bib31" title="" class="ltx_ref">2018</a>; Changpinyo et al. <a href="#bib.bib2" title="" class="ltx_ref">2021</a>; Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>; Schuhmann et al. <a href="#bib.bib29" title="" class="ltx_ref">2021</a>)</cite> is widely used for vision-language grounding due to its abundance and assumed visual-text alignment <cite class="ltx_cite ltx_citemacro_citep">(Zareian et al. <a href="#bib.bib42" title="" class="ltx_ref">2021</a>; Zhong et al. <a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>. There are also large in-the-wild datasets sourced from social media like Reddit posts <cite class="ltx_cite ltx_citemacro_citep">(Desai et al. <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> and user-uploaded captions for publicly shared photos on Flickr <cite class="ltx_cite ltx_citemacro_citep">(Ordonez, Kulkarni, and Berg <a href="#bib.bib23" title="" class="ltx_ref">2011</a>)</cite>.
We show the narrative element found in these, captured by several linguistic cues we investigate, can impact the ability to successfully train an object detection model.
</p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p id="Sx2.p2.1" class="ltx_p"><span id="Sx2.p2.1.1" class="ltx_text ltx_font_bold">Weakly-supervised object detection</span> (WSOD) is a multiple instance learning problem to train a model to localize and classify objects from image-level labels <cite class="ltx_cite ltx_citemacro_citep">(Bilen and Vedaldi <a href="#bib.bib1" title="" class="ltx_ref">2016</a>; Tang et al. <a href="#bib.bib34" title="" class="ltx_ref">2017a</a>; Wan et al. <a href="#bib.bib37" title="" class="ltx_ref">2019</a>; Gao et al. <a href="#bib.bib10" title="" class="ltx_ref">2019</a>; Ren et al. <a href="#bib.bib28" title="" class="ltx_ref">2020</a>)</cite>.
The first work to leverage unstructured text accompanying an image for WSOD, Cap2Det, predicted pseudo image-level labels from captions <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib40" title="" class="ltx_ref">2019b</a>; Unal et al. <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>.
However, Cap2Det cannot operate across categories as it requires observing training data to predict any particular category.
The text classifier in Cap2Det was only used when exact string matching produced no labels, which means it mainly corrects false negatives (visually present, not extracted labels), not visually absent extracted labels. Detic <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al. <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite> uses weak supervision from
ImageNet <cite class="ltx_cite ltx_citemacro_citep">(Deng et al. <a href="#bib.bib3" title="" class="ltx_ref">2009</a>)</cite> and extracted labels from Conceptual Captions (CC) to pretrain an open vocabulary object detection model with a CLIP classifier head. While these approaches succeed in leveraging relatively clean, crowdsourced datasets like COCO. Flickr30K and ImageNet, both approaches see lower performance in training with CC. Other prior work <cite class="ltx_cite ltx_citemacro_citep">(Gao et al. <a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite> uses a pretrained vision-language multimodal model (on 14M data) <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite> to generate pseudo-bounding box annotations using cross-attention between caption (including the mentioned object of interest) and image regions. While it is trained on COCO, Visual Genome, and SBUCaps, it does not explicitly study the contribution of SBUCaps.</p>
</div>
<figure id="Sx2.T1" class="ltx_table">
<div id="Sx2.T1.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:57.1pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-128.4pt,16.7pt) scale(0.628003948300477,0.628003948300477) ;">
<table id="Sx2.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx2.T1.1.1.1.1" class="ltx_tr">
<td id="Sx2.T1.1.1.1.1.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx2.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Label noise</td>
<td id="Sx2.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">Similar context</td>
<td id="Sx2.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Visual defects</td>
<td id="Sx2.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t" colspan="7">Linguistic indicators</td>
</tr>
<tr id="Sx2.T1.1.1.2.2" class="ltx_tr">
<td id="Sx2.T1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Dataset</td>
<td id="Sx2.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Vis</td>
<td id="Sx2.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Part</td>
<td id="Sx2.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Abs</td>
<td id="Sx2.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Co-occ</td>
<td id="Sx2.T1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Sim</td>
<td id="Sx2.T1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Occl</td>
<td id="Sx2.T1.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Parts</td>
<td id="Sx2.T1.1.1.2.2.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Atyp</td>
<td id="Sx2.T1.1.1.2.2.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Beyond</td>
<td id="Sx2.T1.1.1.2.2.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Past</td>
<td id="Sx2.T1.1.1.2.2.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Non-lit</td>
<td id="Sx2.T1.1.1.2.2.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Prep</td>
<td id="Sx2.T1.1.1.2.2.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Mod</td>
<td id="Sx2.T1.1.1.2.2.15" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Sense</td>
<td id="Sx2.T1.1.1.2.2.16" class="ltx_td ltx_align_center ltx_border_t">%Named</td>
</tr>
<tr id="Sx2.T1.1.1.3.3" class="ltx_tr">
<td id="Sx2.T1.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">S</td>
<td id="Sx2.T1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">21.5</td>
<td id="Sx2.T1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.0</td>
<td id="Sx2.T1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">58.5</td>
<td id="Sx2.T1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">42.5</td>
<td id="Sx2.T1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13.2</td>
<td id="Sx2.T1.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.6</td>
<td id="Sx2.T1.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">46.3</td>
<td id="Sx2.T1.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">44.6</td>
<td id="Sx2.T1.1.1.3.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.0</td>
<td id="Sx2.T1.1.1.3.3.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.0</td>
<td id="Sx2.T1.1.1.3.3.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.0</td>
<td id="Sx2.T1.1.1.3.3.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.5</td>
<td id="Sx2.T1.1.1.3.3.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.0</td>
<td id="Sx2.T1.1.1.3.3.15" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">12.0</td>
<td id="Sx2.T1.1.1.3.3.16" class="ltx_td ltx_align_center ltx_border_t">5.0</td>
</tr>
<tr id="Sx2.T1.1.1.4.4" class="ltx_tr">
<td id="Sx2.T1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r">R</td>
<td id="Sx2.T1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">29.2</td>
<td id="Sx2.T1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r">12.8</td>
<td id="Sx2.T1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">57.5</td>
<td id="Sx2.T1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r">15.0</td>
<td id="Sx2.T1.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r">4.0</td>
<td id="Sx2.T1.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r">21.8</td>
<td id="Sx2.T1.1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r">22.2</td>
<td id="Sx2.T1.1.1.4.4.9" class="ltx_td ltx_align_center ltx_border_r">49.0</td>
<td id="Sx2.T1.1.1.4.4.10" class="ltx_td ltx_align_center ltx_border_r">19.8</td>
<td id="Sx2.T1.1.1.4.4.11" class="ltx_td ltx_align_center ltx_border_r">3.1</td>
<td id="Sx2.T1.1.1.4.4.12" class="ltx_td ltx_align_center ltx_border_r">9.3</td>
<td id="Sx2.T1.1.1.4.4.13" class="ltx_td ltx_align_center ltx_border_r">5.7</td>
<td id="Sx2.T1.1.1.4.4.14" class="ltx_td ltx_align_center ltx_border_r">26.6</td>
<td id="Sx2.T1.1.1.4.4.15" class="ltx_td ltx_align_center ltx_border_r">18.2</td>
<td id="Sx2.T1.1.1.4.4.16" class="ltx_td ltx_align_center">10.9</td>
</tr>
<tr id="Sx2.T1.1.1.5.5" class="ltx_tr">
<td id="Sx2.T1.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">CC</td>
<td id="Sx2.T1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">32.8</td>
<td id="Sx2.T1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">16.6</td>
<td id="Sx2.T1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">50.5</td>
<td id="Sx2.T1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">30.9</td>
<td id="Sx2.T1.1.1.5.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">12.8</td>
<td id="Sx2.T1.1.1.5.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">36.3</td>
<td id="Sx2.T1.1.1.5.5.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">24.2</td>
<td id="Sx2.T1.1.1.5.5.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">57.3</td>
<td id="Sx2.T1.1.1.5.5.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">27.6</td>
<td id="Sx2.T1.1.1.5.5.11" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">2.6</td>
<td id="Sx2.T1.1.1.5.5.12" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">5.7</td>
<td id="Sx2.T1.1.1.5.5.13" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">31.3</td>
<td id="Sx2.T1.1.1.5.5.14" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">25.0</td>
<td id="Sx2.T1.1.1.5.5.15" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">8.3</td>
<td id="Sx2.T1.1.1.5.5.16" class="ltx_td ltx_align_center ltx_border_b">2.1</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Label noise distributions; “other”/uncommon categories skipped.
Similar context is only annotated for absent objects agreed by both annotators. Visual defects are annotated over examples with full or partial visibility. Linguistic indicators are annotated
over examples with visual defects or partial/no visibility. S = SBUCaps, R = RedCaps, and CC = Conceptual Captions.</figcaption>
</figure>
<div id="Sx2.p3" class="ltx_para">
<p id="Sx2.p3.1" class="ltx_p"><span id="Sx2.p3.1.1" class="ltx_text ltx_font_bold">Vision-language pre-training for object detection.</span>
Image-text grounding has been leveraged as a pretraining task for open vocabulary object detection <cite class="ltx_cite ltx_citemacro_citep">(Zareian et al. <a href="#bib.bib42" title="" class="ltx_ref">2021</a>; Gu et al. <a href="#bib.bib11" title="" class="ltx_ref">2022</a>; Rahman, Khan, and Barnes <a href="#bib.bib26" title="" class="ltx_ref">2020</a>; Rahman, Khan, and
Porikli <a href="#bib.bib27" title="" class="ltx_ref">2020</a>; Zhong et al. <a href="#bib.bib45" title="" class="ltx_ref">2022</a>; Du et al. <a href="#bib.bib6" title="" class="ltx_ref">2022</a>)</cite>, followed by supervision from bounding boxes from base classes.
Some methods distill knowledge from existing pretrained vision-language grounding models like CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite> and ALIGN <cite class="ltx_cite ltx_citemacro_citep">(Jia et al. <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite> to get proposals <cite class="ltx_cite ltx_citemacro_citep">(Shi et al. <a href="#bib.bib32" title="" class="ltx_ref">2022</a>)</cite> and supervision for object detection <cite class="ltx_cite ltx_citemacro_citep">(Du et al. <a href="#bib.bib6" title="" class="ltx_ref">2022</a>; Zhong et al. <a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>; however the latter do not compare clean vs noisy supervision in a setting without bounding boxes.
Our work differs in that we
focus on rejecting samples that are harmful for localization, and perform WSOD using noisy samples from captions only, without any bounding box annotations.</p>
</div>
<div id="Sx2.p4" class="ltx_para">
<p id="Sx2.p4.1" class="ltx_p"><span id="Sx2.p4.1.1" class="ltx_text ltx_font_bold">Adaptive label noise reduction in classification.</span>
Adaptive methods reject or correct noisy labels ad-hoc during training.
These methods exploit a network’s ability to learn representations of clean labels earlier in training, thus assuming noisy samples have little visual pattern with the corrupted label and are learnt later in training <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a href="#bib.bib43" title="" class="ltx_ref">2017</a>)</cite>.
We instead show diverse real-world datasets contain naturally occurring <em id="Sx2.p4.1.2" class="ltx_emph ltx_font_italic">structured</em> noise, where in many cases there are visual patterns to the corrupted label.
Large Loss Matters <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite> is representative of such adaptive noise reduction methods and we find that it struggles with noisy labels extracted from in-the-wild captions.</p>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Label Noise Analysis and Dataset</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">We analyze what makes large-scale in-the-wild datasets a challenging source of labels for object detection methods.</p>
</div>
<div id="Sx3.p2" class="ltx_para">
<p id="Sx3.p2.1" class="ltx_p"><span id="Sx3.p2.1.1" class="ltx_text ltx_font_bold">Datasets analysed.</span>
Conceptual Captions (CC) <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al. <a href="#bib.bib31" title="" class="ltx_ref">2018</a>)</cite>, RedCaps <cite class="ltx_cite ltx_citemacro_citep">(Desai et al. <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>, and SBUCaps <cite class="ltx_cite ltx_citemacro_citep">(Ordonez, Kulkarni, and Berg <a href="#bib.bib23" title="" class="ltx_ref">2011</a>)</cite>, are collected from in-the-wild data sources. <span id="Sx3.p2.1.2" class="ltx_text ltx_font_bold">CC</span> contains 3 million image-alt-text pairs after heavy post-processing; named entities in captions were hypernymized and image-text pairs were accepted if there was an overlap between Google Cloud Vision API class predictions and the caption.
<span id="Sx3.p2.1.3" class="ltx_text ltx_font_bold">RedCaps</span> consists of 12M image-text pairs collected from Reddit by crawling a manually curated list of subreddits with heavy visual content.
<span id="Sx3.p2.1.4" class="ltx_text ltx_font_bold">SBUCaps</span> consists of 1 million Flickr photos with text descriptions written by their owners.
Only captions with at least one prepositional phrase and at least 2 matches with a predefined vocabulary were accepted.
These in-the-wild datasets exhibit very low precision of the extracted labels, ranging from 0.463 for SBUCaps, 0.596 for RedCaps, to 0.737 for CC, all much lower than the 0.948 for COCO (shown in supp).</p>
</div>
<div id="Sx3.p3" class="ltx_para">
<p id="Sx3.p3.1" class="ltx_p"><span id="Sx3.p3.1.1" class="ltx_text ltx_font_bold">Extracted object labels.</span> Given a vocabulary of object classes, we extract a label for an image if there is exact match between the object name and the corresponding caption ignoring punctuation, as in <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib40" title="" class="ltx_ref">2019b</a>; Fang et al. <a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="Sx3.p4" class="ltx_para">
<p id="Sx3.p4.1" class="ltx_p"><span id="Sx3.p4.1.1" class="ltx_text ltx_font_bold">Gold standard object labels.</span> We use pseudo-ground-truth predictions from a pretrained image recognition model to estimate visual presence <span id="Sx3.p4.1.2" class="ltx_text ltx_font_italic">gold standard</span> labels because these in-the-wild datasets do not have image-level object annotations.
We use an object recognition ensemble with the X152-C4 object-attribute model <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a href="#bib.bib44" title="" class="ltx_ref">2021</a>)</cite>
and the Ultralytic YOLOv5-XL <cite class="ltx_cite ltx_citemacro_citep">(Jocher et al. <a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>.
This ensemble achieves strong accuracy, 82.2% on SBUCaps, 85.6% on RedCaps, and 86.8% on CC.
We extract VAELs by selecting images where extracted and gold-standard labels disagree.
</p>
</div>
<div id="Sx3.p5" class="ltx_para">
<p id="Sx3.p5.1" class="ltx_p"><span id="Sx3.p5.1.1" class="ltx_text ltx_font_bold">Noise annotations collected.</span>
We select 100 VAEL examples per dataset (RedCaps, SBUCaps, CC).
We annotate four types of information for these examples:</p>
<ul id="Sx3.I2" class="ltx_itemize">
<li id="Sx3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i1.p1" class="ltx_para">
<p id="Sx3.I2.i1.p1.1" class="ltx_p">(Q1: Label Noise) How much of the VAEL object is present (<span id="Sx3.I2.i1.p1.1.1" class="ltx_text ltx_framed ltx_framed_underline">vis</span>ible, <span id="Sx3.I2.i1.p1.1.2" class="ltx_text ltx_framed ltx_framed_underline">part</span>ially visible, completely <span id="Sx3.I2.i1.p1.1.3" class="ltx_text ltx_framed ltx_framed_underline">abs</span>ent);</p>
</div>
</li>
<li id="Sx3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i2.p1" class="ltx_para">
<p id="Sx3.I2.i2.p1.1" class="ltx_p">(Q2: Similar Context) If the VAEL object is completely missing, whether a traditionally co-occurring context (“boat” and “water”), or semantically similar object (e.g. “cake” and “bread”, “car” and “truck”) is present;</p>
</div>
</li>
<li id="Sx3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i3.p1" class="ltx_para">
<p id="Sx3.I2.i3.p1.1" class="ltx_p">(Q3: Visual Defects) If visible/partially visible, whether the VAEL object is occluded, has key parts missing, or atypical appearance (e.g. knitted animal); and</p>
</div>
</li>
<li id="Sx3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I2.i4.p1" class="ltx_para">
<p id="Sx3.I2.i4.p1.1" class="ltx_p">(Q4: Linguistic Indicators) What linguistic cues, if any, explain why the VAEL object is mentioned but absent, e.g. the caption discusses events or information beyond what the image shows (“beyond” in Table <a href="#Sx2.T1" title="Table 1 ‣ Related Work ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), describes the past (“past”), the extracted label is part of a prepositional phrase and likely to describe the setting and not objects (“on a train”), is a noun modifying another noun, is used in a non-literal way, has a different word sense (e.g. “bed” vs “river bed”), or is part of a named entity.</p>
</div>
</li>
</ul>
</div>
<div id="Sx3.p6" class="ltx_para">
<p id="Sx3.p6.1" class="ltx_p">Two annotators (authors) provide the annotations, with high agreement: 0.76 for Q1, 0.33 for Q2, 0.45 for Q3, and 0.58 for Q4. We calculate Cohen’s Kappa for each option and aggregate agreement through a weighted average for each question, with weights derived from average option counts between the two annotators across the three datasets. We label the dataset Caption Label Noise, or CLaN.</p>
</div>
<div id="Sx3.p7" class="ltx_para">
<p id="Sx3.p7.1" class="ltx_p">In Table <a href="#Sx2.T1" title="Table 1 ‣ Related Work ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we show what fraction of samples fall into each annotated category, excluding “Other”, “Unclear” and uncommon categories. We average the distribution between the two annotators.</p>
</div>
<div id="Sx3.p8" class="ltx_para">
<p id="Sx3.p8.1" class="ltx_p"><span id="Sx3.p8.1.1" class="ltx_text ltx_font_bold">Statistics: Label noise.</span>
We first characterize the visibility of objects flagged as VAELs by the recognition ensemble. We find that SBUCaps has the highest rate of completely absent images (58.5%), followed closely by RedCaps.
CC has the highest full visibility (32.8%),
defined as the object from a given viewpoint having 75% or more visibility.
SBUCaps also has the highest rate of partially visible objects (20%).
The high rate of absent and partially-visible objects justifies the use of pseudo-ground-truth labels from the recognition ensemble; these both constitute poor training data for WSOD.
We investigate the fully-visible objects flagged as VAELs shortly, through our visual defect annotations.
</p>
</div>
<div id="Sx3.p9" class="ltx_para">
<p id="Sx3.p9.1" class="ltx_p"><span id="Sx3.p9.1.1" class="ltx_text ltx_font_bold">Statistics: Similar context.</span>
Certain images with absent objects may be more harmful than others. Prior work has shown that models exploit co-occurrences between an object and its context which helps overall recognition accuracy, but can hurt performance when that context is absent <cite class="ltx_cite ltx_citemacro_citep">(Singh et al. <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>. We hypothesize the inclusion of images with this context bias without the actual object present could affect localization especially when supervising detection <span id="Sx3.p9.1.2" class="ltx_text ltx_font_italic">implicitly</span>, and semantically similar context may blur decision boundaries.
Different annotators may have different references for similarity or co-occurrence frequency, but our annotators achieve fair agreement (<math id="Sx3.p9.1.m1.1" class="ltx_Math" alttext="\kappa=0.33" display="inline"><semantics id="Sx3.p9.1.m1.1a"><mrow id="Sx3.p9.1.m1.1.1" xref="Sx3.p9.1.m1.1.1.cmml"><mi id="Sx3.p9.1.m1.1.1.2" xref="Sx3.p9.1.m1.1.1.2.cmml">κ</mi><mo id="Sx3.p9.1.m1.1.1.1" xref="Sx3.p9.1.m1.1.1.1.cmml">=</mo><mn id="Sx3.p9.1.m1.1.1.3" xref="Sx3.p9.1.m1.1.1.3.cmml">0.33</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx3.p9.1.m1.1b"><apply id="Sx3.p9.1.m1.1.1.cmml" xref="Sx3.p9.1.m1.1.1"><eq id="Sx3.p9.1.m1.1.1.1.cmml" xref="Sx3.p9.1.m1.1.1.1"></eq><ci id="Sx3.p9.1.m1.1.1.2.cmml" xref="Sx3.p9.1.m1.1.1.2">𝜅</ci><cn type="float" id="Sx3.p9.1.m1.1.1.3.cmml" xref="Sx3.p9.1.m1.1.1.3">0.33</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p9.1.m1.1c">\kappa=0.33</annotation></semantics></math>). In Table <a href="#Sx2.T1" title="Table 1 ‣ Related Work ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we find high rates of co-occurring contexts in samples with completely absent VAELs for SBUCaps (42.5%) and CC (30.9%).
Across all datasets, we see a similar rate, 12%-15%, of similar context being present instead of the VAEL.</p>
</div>
<div id="Sx3.p10" class="ltx_para">
<p id="Sx3.p10.1" class="ltx_p"><span id="Sx3.p10.1.1" class="ltx_text ltx_font_bold">Statistics: Visual defects.</span>
We hypothesize there may be visual defects which caused the recognition ensemble to miss fully-visible objects.
Over the fully or partially visible subset, in CC 79% of fully or partially visible objects have a visual defect, 87% for SBUCaps, and 69% for RedCaps.
The most common defect for RedCaps and CC is atypical (49% and 57.3%); we argue these atypical examples constitute poor training data for WSOD.
We find that the caption context (e.g. “acrylic illustration of the funny mouse”) may indicate the possibility of a visual defect, which further motivates the VEIL design.
</p>
</div>
<div id="Sx3.p11" class="ltx_para">
<p id="Sx3.p11.1" class="ltx_p"><span id="Sx3.p11.1.1" class="ltx_text ltx_font_bold">Statistics: Linguistic indicators.</span> Noun modifier is one of the most frequently occurring linguistic indicator. Prepositional phrase is also significant in SBUCaps (40.5%) and CC (31.3%).
All datasets contain many VAELs which are mentioned in contexts going beyond the image; for example:
“just got back from the river. friend <span id="Sx3.p11.1.2" class="ltx_text ltx_font_bold">sank his truck pulling his <span id="Sx3.p11.1.2.1" class="ltx_text ltx_framed ltx_framed_underline">boat</span> out</span>. long story short, rip this beast” (RedCaps). 
</p>
</div>
</section>
<section id="Sx4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Method</h2>

<figure id="Sx4.F2" class="ltx_figure"><img src="/html/2303.09608/assets/iccv2023AuthorKit/figures/images/veil_architecture_gdoc_real_example2.png" id="Sx4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="239" height="96" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>VEIL model architecture.
The masking layer masks visual presence predictions after vetting layer of tokens not corresponding to a label. Example from SBUCaps.</figcaption>
</figure>
<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.5" class="ltx_p"><span id="Sx4.p1.5.1" class="ltx_text ltx_font_bold">Vetting labels (VEIL).</span> The extracted label vetting (ELV) task uses visual presence targets that are assigned based on predictions from a pretrained object recognition model for <span id="Sx4.p1.5.2" class="ltx_text ltx_font_italic">each</span> extracted label from the caption.
The method is overviewed in Fig. <a href="#Sx4.F2" title="Figure 2 ‣ Method ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Our model takes in a sequence of <math id="Sx4.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="Sx4.p1.1.m1.1a"><mi id="Sx4.p1.1.m1.1.1" xref="Sx4.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="Sx4.p1.1.m1.1b"><ci id="Sx4.p1.1.m1.1.1.cmml" xref="Sx4.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.1.m1.1c">C</annotation></semantics></math> word token-level caption embeddings. WordPiece <cite class="ltx_cite ltx_citemacro_citep">(Wu et al. <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite> tokenization breaks captions into subwords, and each subword is mapped to a corresponding embedding, resulting in <math id="Sx4.p1.2.m2.1" class="ltx_Math" alttext="e\in\mathbb{R}^{d\times C}" display="inline"><semantics id="Sx4.p1.2.m2.1a"><mrow id="Sx4.p1.2.m2.1.1" xref="Sx4.p1.2.m2.1.1.cmml"><mi id="Sx4.p1.2.m2.1.1.2" xref="Sx4.p1.2.m2.1.1.2.cmml">e</mi><mo id="Sx4.p1.2.m2.1.1.1" xref="Sx4.p1.2.m2.1.1.1.cmml">∈</mo><msup id="Sx4.p1.2.m2.1.1.3" xref="Sx4.p1.2.m2.1.1.3.cmml"><mi id="Sx4.p1.2.m2.1.1.3.2" xref="Sx4.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="Sx4.p1.2.m2.1.1.3.3" xref="Sx4.p1.2.m2.1.1.3.3.cmml"><mi id="Sx4.p1.2.m2.1.1.3.3.2" xref="Sx4.p1.2.m2.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="Sx4.p1.2.m2.1.1.3.3.1" xref="Sx4.p1.2.m2.1.1.3.3.1.cmml">×</mo><mi id="Sx4.p1.2.m2.1.1.3.3.3" xref="Sx4.p1.2.m2.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p1.2.m2.1b"><apply id="Sx4.p1.2.m2.1.1.cmml" xref="Sx4.p1.2.m2.1.1"><in id="Sx4.p1.2.m2.1.1.1.cmml" xref="Sx4.p1.2.m2.1.1.1"></in><ci id="Sx4.p1.2.m2.1.1.2.cmml" xref="Sx4.p1.2.m2.1.1.2">𝑒</ci><apply id="Sx4.p1.2.m2.1.1.3.cmml" xref="Sx4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="Sx4.p1.2.m2.1.1.3.1.cmml" xref="Sx4.p1.2.m2.1.1.3">superscript</csymbol><ci id="Sx4.p1.2.m2.1.1.3.2.cmml" xref="Sx4.p1.2.m2.1.1.3.2">ℝ</ci><apply id="Sx4.p1.2.m2.1.1.3.3.cmml" xref="Sx4.p1.2.m2.1.1.3.3"><times id="Sx4.p1.2.m2.1.1.3.3.1.cmml" xref="Sx4.p1.2.m2.1.1.3.3.1"></times><ci id="Sx4.p1.2.m2.1.1.3.3.2.cmml" xref="Sx4.p1.2.m2.1.1.3.3.2">𝑑</ci><ci id="Sx4.p1.2.m2.1.1.3.3.3.cmml" xref="Sx4.p1.2.m2.1.1.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.2.m2.1c">e\in\mathbb{R}^{d\times C}</annotation></semantics></math>. These embeddings are passed through a language model, <math id="Sx4.p1.3.m3.1" class="ltx_Math" alttext="h" display="inline"><semantics id="Sx4.p1.3.m3.1a"><mi id="Sx4.p1.3.m3.1.1" xref="Sx4.p1.3.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="Sx4.p1.3.m3.1b"><ci id="Sx4.p1.3.m3.1.1.cmml" xref="Sx4.p1.3.m3.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.3.m3.1c">h</annotation></semantics></math>, which include multiple layers of multi-head self-attention over tokens in the caption to compute token-level output embeddings <math id="Sx4.p1.4.m4.1" class="ltx_Math" alttext="v\in\mathbb{R}^{d\times C}" display="inline"><semantics id="Sx4.p1.4.m4.1a"><mrow id="Sx4.p1.4.m4.1.1" xref="Sx4.p1.4.m4.1.1.cmml"><mi id="Sx4.p1.4.m4.1.1.2" xref="Sx4.p1.4.m4.1.1.2.cmml">v</mi><mo id="Sx4.p1.4.m4.1.1.1" xref="Sx4.p1.4.m4.1.1.1.cmml">∈</mo><msup id="Sx4.p1.4.m4.1.1.3" xref="Sx4.p1.4.m4.1.1.3.cmml"><mi id="Sx4.p1.4.m4.1.1.3.2" xref="Sx4.p1.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="Sx4.p1.4.m4.1.1.3.3" xref="Sx4.p1.4.m4.1.1.3.3.cmml"><mi id="Sx4.p1.4.m4.1.1.3.3.2" xref="Sx4.p1.4.m4.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="Sx4.p1.4.m4.1.1.3.3.1" xref="Sx4.p1.4.m4.1.1.3.3.1.cmml">×</mo><mi id="Sx4.p1.4.m4.1.1.3.3.3" xref="Sx4.p1.4.m4.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p1.4.m4.1b"><apply id="Sx4.p1.4.m4.1.1.cmml" xref="Sx4.p1.4.m4.1.1"><in id="Sx4.p1.4.m4.1.1.1.cmml" xref="Sx4.p1.4.m4.1.1.1"></in><ci id="Sx4.p1.4.m4.1.1.2.cmml" xref="Sx4.p1.4.m4.1.1.2">𝑣</ci><apply id="Sx4.p1.4.m4.1.1.3.cmml" xref="Sx4.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="Sx4.p1.4.m4.1.1.3.1.cmml" xref="Sx4.p1.4.m4.1.1.3">superscript</csymbol><ci id="Sx4.p1.4.m4.1.1.3.2.cmml" xref="Sx4.p1.4.m4.1.1.3.2">ℝ</ci><apply id="Sx4.p1.4.m4.1.1.3.3.cmml" xref="Sx4.p1.4.m4.1.1.3.3"><times id="Sx4.p1.4.m4.1.1.3.3.1.cmml" xref="Sx4.p1.4.m4.1.1.3.3.1"></times><ci id="Sx4.p1.4.m4.1.1.3.3.2.cmml" xref="Sx4.p1.4.m4.1.1.3.3.2">𝑑</ci><ci id="Sx4.p1.4.m4.1.1.3.3.3.cmml" xref="Sx4.p1.4.m4.1.1.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.4.m4.1c">v\in\mathbb{R}^{d\times C}</annotation></semantics></math>.
These embeddings are then passed to an MLP and the model outputs a sequence of visual presence predictions per token, <math id="Sx4.p1.5.m5.2" class="ltx_Math" alttext="r\in[0,1]^{C}" display="inline"><semantics id="Sx4.p1.5.m5.2a"><mrow id="Sx4.p1.5.m5.2.3" xref="Sx4.p1.5.m5.2.3.cmml"><mi id="Sx4.p1.5.m5.2.3.2" xref="Sx4.p1.5.m5.2.3.2.cmml">r</mi><mo id="Sx4.p1.5.m5.2.3.1" xref="Sx4.p1.5.m5.2.3.1.cmml">∈</mo><msup id="Sx4.p1.5.m5.2.3.3" xref="Sx4.p1.5.m5.2.3.3.cmml"><mrow id="Sx4.p1.5.m5.2.3.3.2.2" xref="Sx4.p1.5.m5.2.3.3.2.1.cmml"><mo stretchy="false" id="Sx4.p1.5.m5.2.3.3.2.2.1" xref="Sx4.p1.5.m5.2.3.3.2.1.cmml">[</mo><mn id="Sx4.p1.5.m5.1.1" xref="Sx4.p1.5.m5.1.1.cmml">0</mn><mo id="Sx4.p1.5.m5.2.3.3.2.2.2" xref="Sx4.p1.5.m5.2.3.3.2.1.cmml">,</mo><mn id="Sx4.p1.5.m5.2.2" xref="Sx4.p1.5.m5.2.2.cmml">1</mn><mo stretchy="false" id="Sx4.p1.5.m5.2.3.3.2.2.3" xref="Sx4.p1.5.m5.2.3.3.2.1.cmml">]</mo></mrow><mi id="Sx4.p1.5.m5.2.3.3.3" xref="Sx4.p1.5.m5.2.3.3.3.cmml">C</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p1.5.m5.2b"><apply id="Sx4.p1.5.m5.2.3.cmml" xref="Sx4.p1.5.m5.2.3"><in id="Sx4.p1.5.m5.2.3.1.cmml" xref="Sx4.p1.5.m5.2.3.1"></in><ci id="Sx4.p1.5.m5.2.3.2.cmml" xref="Sx4.p1.5.m5.2.3.2">𝑟</ci><apply id="Sx4.p1.5.m5.2.3.3.cmml" xref="Sx4.p1.5.m5.2.3.3"><csymbol cd="ambiguous" id="Sx4.p1.5.m5.2.3.3.1.cmml" xref="Sx4.p1.5.m5.2.3.3">superscript</csymbol><interval closure="closed" id="Sx4.p1.5.m5.2.3.3.2.1.cmml" xref="Sx4.p1.5.m5.2.3.3.2.2"><cn type="integer" id="Sx4.p1.5.m5.1.1.cmml" xref="Sx4.p1.5.m5.1.1">0</cn><cn type="integer" id="Sx4.p1.5.m5.2.2.cmml" xref="Sx4.p1.5.m5.2.2">1</cn></interval><ci id="Sx4.p1.5.m5.2.3.3.3.cmml" xref="Sx4.p1.5.m5.2.3.3.3">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.5.m5.2c">r\in[0,1]^{C}</annotation></semantics></math>.</p>
<table id="Sx11.EGx1" class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table">

<tbody id="Sx4.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Sx4.E1.m1.1" class="ltx_Math" alttext="\displaystyle v=h(e)" display="block"><semantics id="Sx4.E1.m1.1a"><mrow id="Sx4.E1.m1.1.2" xref="Sx4.E1.m1.1.2.cmml"><mi id="Sx4.E1.m1.1.2.2" xref="Sx4.E1.m1.1.2.2.cmml">v</mi><mo id="Sx4.E1.m1.1.2.1" xref="Sx4.E1.m1.1.2.1.cmml">=</mo><mrow id="Sx4.E1.m1.1.2.3" xref="Sx4.E1.m1.1.2.3.cmml"><mi id="Sx4.E1.m1.1.2.3.2" xref="Sx4.E1.m1.1.2.3.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="Sx4.E1.m1.1.2.3.1" xref="Sx4.E1.m1.1.2.3.1.cmml">​</mo><mrow id="Sx4.E1.m1.1.2.3.3.2" xref="Sx4.E1.m1.1.2.3.cmml"><mo stretchy="false" id="Sx4.E1.m1.1.2.3.3.2.1" xref="Sx4.E1.m1.1.2.3.cmml">(</mo><mi id="Sx4.E1.m1.1.1" xref="Sx4.E1.m1.1.1.cmml">e</mi><mo stretchy="false" id="Sx4.E1.m1.1.2.3.3.2.2" xref="Sx4.E1.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx4.E1.m1.1b"><apply id="Sx4.E1.m1.1.2.cmml" xref="Sx4.E1.m1.1.2"><eq id="Sx4.E1.m1.1.2.1.cmml" xref="Sx4.E1.m1.1.2.1"></eq><ci id="Sx4.E1.m1.1.2.2.cmml" xref="Sx4.E1.m1.1.2.2">𝑣</ci><apply id="Sx4.E1.m1.1.2.3.cmml" xref="Sx4.E1.m1.1.2.3"><times id="Sx4.E1.m1.1.2.3.1.cmml" xref="Sx4.E1.m1.1.2.3.1"></times><ci id="Sx4.E1.m1.1.2.3.2.cmml" xref="Sx4.E1.m1.1.2.3.2">ℎ</ci><ci id="Sx4.E1.m1.1.1.cmml" xref="Sx4.E1.m1.1.1">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.E1.m1.1c">\displaystyle v=h(e)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="Sx4.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Sx4.E2.m1.1" class="ltx_math_unparsed" alttext="\displaystyle r=\sigma(W_{2}(\tanh(W_{1}v))" display="block"><semantics id="Sx4.E2.m1.1a"><mrow id="Sx4.E2.m1.1b"><mi id="Sx4.E2.m1.1.2">r</mi><mo id="Sx4.E2.m1.1.3">=</mo><mi id="Sx4.E2.m1.1.4">σ</mi><mrow id="Sx4.E2.m1.1.5"><mo stretchy="false" id="Sx4.E2.m1.1.5.1">(</mo><msub id="Sx4.E2.m1.1.5.2"><mi id="Sx4.E2.m1.1.5.2.2">W</mi><mn id="Sx4.E2.m1.1.5.2.3">2</mn></msub><mrow id="Sx4.E2.m1.1.5.3"><mo stretchy="false" id="Sx4.E2.m1.1.5.3.1">(</mo><mi id="Sx4.E2.m1.1.1">tanh</mi><mrow id="Sx4.E2.m1.1.5.3.2"><mo stretchy="false" id="Sx4.E2.m1.1.5.3.2.1">(</mo><msub id="Sx4.E2.m1.1.5.3.2.2"><mi id="Sx4.E2.m1.1.5.3.2.2.2">W</mi><mn id="Sx4.E2.m1.1.5.3.2.2.3">1</mn></msub><mi id="Sx4.E2.m1.1.5.3.2.3">v</mi><mo stretchy="false" id="Sx4.E2.m1.1.5.3.2.4">)</mo></mrow><mo stretchy="false" id="Sx4.E2.m1.1.5.3.3">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex" id="Sx4.E2.m1.1c">\displaystyle r=\sigma(W_{2}(\tanh(W_{1}v))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="Sx4.p1.7" class="ltx_p">where <math id="Sx4.p1.6.m1.1" class="ltx_Math" alttext="W_{1}\in\mathbb{R}^{d\times d}" display="inline"><semantics id="Sx4.p1.6.m1.1a"><mrow id="Sx4.p1.6.m1.1.1" xref="Sx4.p1.6.m1.1.1.cmml"><msub id="Sx4.p1.6.m1.1.1.2" xref="Sx4.p1.6.m1.1.1.2.cmml"><mi id="Sx4.p1.6.m1.1.1.2.2" xref="Sx4.p1.6.m1.1.1.2.2.cmml">W</mi><mn id="Sx4.p1.6.m1.1.1.2.3" xref="Sx4.p1.6.m1.1.1.2.3.cmml">1</mn></msub><mo id="Sx4.p1.6.m1.1.1.1" xref="Sx4.p1.6.m1.1.1.1.cmml">∈</mo><msup id="Sx4.p1.6.m1.1.1.3" xref="Sx4.p1.6.m1.1.1.3.cmml"><mi id="Sx4.p1.6.m1.1.1.3.2" xref="Sx4.p1.6.m1.1.1.3.2.cmml">ℝ</mi><mrow id="Sx4.p1.6.m1.1.1.3.3" xref="Sx4.p1.6.m1.1.1.3.3.cmml"><mi id="Sx4.p1.6.m1.1.1.3.3.2" xref="Sx4.p1.6.m1.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="Sx4.p1.6.m1.1.1.3.3.1" xref="Sx4.p1.6.m1.1.1.3.3.1.cmml">×</mo><mi id="Sx4.p1.6.m1.1.1.3.3.3" xref="Sx4.p1.6.m1.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p1.6.m1.1b"><apply id="Sx4.p1.6.m1.1.1.cmml" xref="Sx4.p1.6.m1.1.1"><in id="Sx4.p1.6.m1.1.1.1.cmml" xref="Sx4.p1.6.m1.1.1.1"></in><apply id="Sx4.p1.6.m1.1.1.2.cmml" xref="Sx4.p1.6.m1.1.1.2"><csymbol cd="ambiguous" id="Sx4.p1.6.m1.1.1.2.1.cmml" xref="Sx4.p1.6.m1.1.1.2">subscript</csymbol><ci id="Sx4.p1.6.m1.1.1.2.2.cmml" xref="Sx4.p1.6.m1.1.1.2.2">𝑊</ci><cn type="integer" id="Sx4.p1.6.m1.1.1.2.3.cmml" xref="Sx4.p1.6.m1.1.1.2.3">1</cn></apply><apply id="Sx4.p1.6.m1.1.1.3.cmml" xref="Sx4.p1.6.m1.1.1.3"><csymbol cd="ambiguous" id="Sx4.p1.6.m1.1.1.3.1.cmml" xref="Sx4.p1.6.m1.1.1.3">superscript</csymbol><ci id="Sx4.p1.6.m1.1.1.3.2.cmml" xref="Sx4.p1.6.m1.1.1.3.2">ℝ</ci><apply id="Sx4.p1.6.m1.1.1.3.3.cmml" xref="Sx4.p1.6.m1.1.1.3.3"><times id="Sx4.p1.6.m1.1.1.3.3.1.cmml" xref="Sx4.p1.6.m1.1.1.3.3.1"></times><ci id="Sx4.p1.6.m1.1.1.3.3.2.cmml" xref="Sx4.p1.6.m1.1.1.3.3.2">𝑑</ci><ci id="Sx4.p1.6.m1.1.1.3.3.3.cmml" xref="Sx4.p1.6.m1.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.6.m1.1c">W_{1}\in\mathbb{R}^{d\times d}</annotation></semantics></math> and <math id="Sx4.p1.7.m2.1" class="ltx_Math" alttext="W_{2}\in\mathbb{R}^{1\times d}" display="inline"><semantics id="Sx4.p1.7.m2.1a"><mrow id="Sx4.p1.7.m2.1.1" xref="Sx4.p1.7.m2.1.1.cmml"><msub id="Sx4.p1.7.m2.1.1.2" xref="Sx4.p1.7.m2.1.1.2.cmml"><mi id="Sx4.p1.7.m2.1.1.2.2" xref="Sx4.p1.7.m2.1.1.2.2.cmml">W</mi><mn id="Sx4.p1.7.m2.1.1.2.3" xref="Sx4.p1.7.m2.1.1.2.3.cmml">2</mn></msub><mo id="Sx4.p1.7.m2.1.1.1" xref="Sx4.p1.7.m2.1.1.1.cmml">∈</mo><msup id="Sx4.p1.7.m2.1.1.3" xref="Sx4.p1.7.m2.1.1.3.cmml"><mi id="Sx4.p1.7.m2.1.1.3.2" xref="Sx4.p1.7.m2.1.1.3.2.cmml">ℝ</mi><mrow id="Sx4.p1.7.m2.1.1.3.3" xref="Sx4.p1.7.m2.1.1.3.3.cmml"><mn id="Sx4.p1.7.m2.1.1.3.3.2" xref="Sx4.p1.7.m2.1.1.3.3.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="Sx4.p1.7.m2.1.1.3.3.1" xref="Sx4.p1.7.m2.1.1.3.3.1.cmml">×</mo><mi id="Sx4.p1.7.m2.1.1.3.3.3" xref="Sx4.p1.7.m2.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p1.7.m2.1b"><apply id="Sx4.p1.7.m2.1.1.cmml" xref="Sx4.p1.7.m2.1.1"><in id="Sx4.p1.7.m2.1.1.1.cmml" xref="Sx4.p1.7.m2.1.1.1"></in><apply id="Sx4.p1.7.m2.1.1.2.cmml" xref="Sx4.p1.7.m2.1.1.2"><csymbol cd="ambiguous" id="Sx4.p1.7.m2.1.1.2.1.cmml" xref="Sx4.p1.7.m2.1.1.2">subscript</csymbol><ci id="Sx4.p1.7.m2.1.1.2.2.cmml" xref="Sx4.p1.7.m2.1.1.2.2">𝑊</ci><cn type="integer" id="Sx4.p1.7.m2.1.1.2.3.cmml" xref="Sx4.p1.7.m2.1.1.2.3">2</cn></apply><apply id="Sx4.p1.7.m2.1.1.3.cmml" xref="Sx4.p1.7.m2.1.1.3"><csymbol cd="ambiguous" id="Sx4.p1.7.m2.1.1.3.1.cmml" xref="Sx4.p1.7.m2.1.1.3">superscript</csymbol><ci id="Sx4.p1.7.m2.1.1.3.2.cmml" xref="Sx4.p1.7.m2.1.1.3.2">ℝ</ci><apply id="Sx4.p1.7.m2.1.1.3.3.cmml" xref="Sx4.p1.7.m2.1.1.3.3"><times id="Sx4.p1.7.m2.1.1.3.3.1.cmml" xref="Sx4.p1.7.m2.1.1.3.3.1"></times><cn type="integer" id="Sx4.p1.7.m2.1.1.3.3.2.cmml" xref="Sx4.p1.7.m2.1.1.3.3.2">1</cn><ci id="Sx4.p1.7.m2.1.1.3.3.3.cmml" xref="Sx4.p1.7.m2.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p1.7.m2.1c">W_{2}\in\mathbb{R}^{1\times d}</annotation></semantics></math>.</p>
</div>
<div id="Sx4.p2" class="ltx_para">
<p id="Sx4.p2.3" class="ltx_p">Not all predictions in <math id="Sx4.p2.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="Sx4.p2.1.m1.1a"><mi id="Sx4.p2.1.m1.1.1" xref="Sx4.p2.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="Sx4.p2.1.m1.1b"><ci id="Sx4.p2.1.m1.1.1.cmml" xref="Sx4.p2.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p2.1.m1.1c">r</annotation></semantics></math> correspond to an extracted label, so we use a mask, <math id="Sx4.p2.2.m2.2" class="ltx_Math" alttext="M\in[0,1]^{C}" display="inline"><semantics id="Sx4.p2.2.m2.2a"><mrow id="Sx4.p2.2.m2.2.3" xref="Sx4.p2.2.m2.2.3.cmml"><mi id="Sx4.p2.2.m2.2.3.2" xref="Sx4.p2.2.m2.2.3.2.cmml">M</mi><mo id="Sx4.p2.2.m2.2.3.1" xref="Sx4.p2.2.m2.2.3.1.cmml">∈</mo><msup id="Sx4.p2.2.m2.2.3.3" xref="Sx4.p2.2.m2.2.3.3.cmml"><mrow id="Sx4.p2.2.m2.2.3.3.2.2" xref="Sx4.p2.2.m2.2.3.3.2.1.cmml"><mo stretchy="false" id="Sx4.p2.2.m2.2.3.3.2.2.1" xref="Sx4.p2.2.m2.2.3.3.2.1.cmml">[</mo><mn id="Sx4.p2.2.m2.1.1" xref="Sx4.p2.2.m2.1.1.cmml">0</mn><mo id="Sx4.p2.2.m2.2.3.3.2.2.2" xref="Sx4.p2.2.m2.2.3.3.2.1.cmml">,</mo><mn id="Sx4.p2.2.m2.2.2" xref="Sx4.p2.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="Sx4.p2.2.m2.2.3.3.2.2.3" xref="Sx4.p2.2.m2.2.3.3.2.1.cmml">]</mo></mrow><mi id="Sx4.p2.2.m2.2.3.3.3" xref="Sx4.p2.2.m2.2.3.3.3.cmml">C</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p2.2.m2.2b"><apply id="Sx4.p2.2.m2.2.3.cmml" xref="Sx4.p2.2.m2.2.3"><in id="Sx4.p2.2.m2.2.3.1.cmml" xref="Sx4.p2.2.m2.2.3.1"></in><ci id="Sx4.p2.2.m2.2.3.2.cmml" xref="Sx4.p2.2.m2.2.3.2">𝑀</ci><apply id="Sx4.p2.2.m2.2.3.3.cmml" xref="Sx4.p2.2.m2.2.3.3"><csymbol cd="ambiguous" id="Sx4.p2.2.m2.2.3.3.1.cmml" xref="Sx4.p2.2.m2.2.3.3">superscript</csymbol><interval closure="closed" id="Sx4.p2.2.m2.2.3.3.2.1.cmml" xref="Sx4.p2.2.m2.2.3.3.2.2"><cn type="integer" id="Sx4.p2.2.m2.1.1.cmml" xref="Sx4.p2.2.m2.1.1">0</cn><cn type="integer" id="Sx4.p2.2.m2.2.2.cmml" xref="Sx4.p2.2.m2.2.2">1</cn></interval><ci id="Sx4.p2.2.m2.2.3.3.3.cmml" xref="Sx4.p2.2.m2.2.3.3.3">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p2.2.m2.2c">M\in[0,1]^{C}</annotation></semantics></math>, such that only the predictions associated with the extracted labels are used in binary cross entropy loss.
To train this network, the pseudo-label targets are present, <math id="Sx4.p2.3.m3.1" class="ltx_Math" alttext="y_{i}=1" display="inline"><semantics id="Sx4.p2.3.m3.1a"><mrow id="Sx4.p2.3.m3.1.1" xref="Sx4.p2.3.m3.1.1.cmml"><msub id="Sx4.p2.3.m3.1.1.2" xref="Sx4.p2.3.m3.1.1.2.cmml"><mi id="Sx4.p2.3.m3.1.1.2.2" xref="Sx4.p2.3.m3.1.1.2.2.cmml">y</mi><mi id="Sx4.p2.3.m3.1.1.2.3" xref="Sx4.p2.3.m3.1.1.2.3.cmml">i</mi></msub><mo id="Sx4.p2.3.m3.1.1.1" xref="Sx4.p2.3.m3.1.1.1.cmml">=</mo><mn id="Sx4.p2.3.m3.1.1.3" xref="Sx4.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p2.3.m3.1b"><apply id="Sx4.p2.3.m3.1.1.cmml" xref="Sx4.p2.3.m3.1.1"><eq id="Sx4.p2.3.m3.1.1.1.cmml" xref="Sx4.p2.3.m3.1.1.1"></eq><apply id="Sx4.p2.3.m3.1.1.2.cmml" xref="Sx4.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="Sx4.p2.3.m3.1.1.2.1.cmml" xref="Sx4.p2.3.m3.1.1.2">subscript</csymbol><ci id="Sx4.p2.3.m3.1.1.2.2.cmml" xref="Sx4.p2.3.m3.1.1.2.2">𝑦</ci><ci id="Sx4.p2.3.m3.1.1.2.3.cmml" xref="Sx4.p2.3.m3.1.1.2.3">𝑖</ci></apply><cn type="integer" id="Sx4.p2.3.m3.1.1.3.cmml" xref="Sx4.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p2.3.m3.1c">y_{i}=1</annotation></semantics></math>, if a pretrained object detector also predicts the same category as the extracted label.</p>
<table id="Sx11.EGx2" class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table">

<tbody id="Sx4.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Sx4.E3.m1.2" class="ltx_Math" alttext="\displaystyle L=\frac{1}{M^{T}M}\sum_{i=1}^{C}M_{i}\Big{[}y_{i}\log r_{i}+(1-y_{i})\log(1-r_{i})\Big{]}" display="block"><semantics id="Sx4.E3.m1.2a"><mrow id="Sx4.E3.m1.2.2" xref="Sx4.E3.m1.2.2.cmml"><mi id="Sx4.E3.m1.2.2.3" xref="Sx4.E3.m1.2.2.3.cmml">L</mi><mo id="Sx4.E3.m1.2.2.2" xref="Sx4.E3.m1.2.2.2.cmml">=</mo><mrow id="Sx4.E3.m1.2.2.1" xref="Sx4.E3.m1.2.2.1.cmml"><mfrac id="Sx4.E3.m1.2.2.1.3" xref="Sx4.E3.m1.2.2.1.3.cmml"><mn id="Sx4.E3.m1.2.2.1.3.2" xref="Sx4.E3.m1.2.2.1.3.2.cmml">1</mn><mrow id="Sx4.E3.m1.2.2.1.3.3" xref="Sx4.E3.m1.2.2.1.3.3.cmml"><msup id="Sx4.E3.m1.2.2.1.3.3.2" xref="Sx4.E3.m1.2.2.1.3.3.2.cmml"><mi id="Sx4.E3.m1.2.2.1.3.3.2.2" xref="Sx4.E3.m1.2.2.1.3.3.2.2.cmml">M</mi><mi id="Sx4.E3.m1.2.2.1.3.3.2.3" xref="Sx4.E3.m1.2.2.1.3.3.2.3.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="Sx4.E3.m1.2.2.1.3.3.1" xref="Sx4.E3.m1.2.2.1.3.3.1.cmml">​</mo><mi id="Sx4.E3.m1.2.2.1.3.3.3" xref="Sx4.E3.m1.2.2.1.3.3.3.cmml">M</mi></mrow></mfrac><mo lspace="0em" rspace="0em" id="Sx4.E3.m1.2.2.1.2" xref="Sx4.E3.m1.2.2.1.2.cmml">​</mo><mrow id="Sx4.E3.m1.2.2.1.1" xref="Sx4.E3.m1.2.2.1.1.cmml"><munderover id="Sx4.E3.m1.2.2.1.1.2" xref="Sx4.E3.m1.2.2.1.1.2.cmml"><mo movablelimits="false" id="Sx4.E3.m1.2.2.1.1.2.2.2" xref="Sx4.E3.m1.2.2.1.1.2.2.2.cmml">∑</mo><mrow id="Sx4.E3.m1.2.2.1.1.2.2.3" xref="Sx4.E3.m1.2.2.1.1.2.2.3.cmml"><mi id="Sx4.E3.m1.2.2.1.1.2.2.3.2" xref="Sx4.E3.m1.2.2.1.1.2.2.3.2.cmml">i</mi><mo id="Sx4.E3.m1.2.2.1.1.2.2.3.1" xref="Sx4.E3.m1.2.2.1.1.2.2.3.1.cmml">=</mo><mn id="Sx4.E3.m1.2.2.1.1.2.2.3.3" xref="Sx4.E3.m1.2.2.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="Sx4.E3.m1.2.2.1.1.2.3" xref="Sx4.E3.m1.2.2.1.1.2.3.cmml">C</mi></munderover><mrow id="Sx4.E3.m1.2.2.1.1.1" xref="Sx4.E3.m1.2.2.1.1.1.cmml"><msub id="Sx4.E3.m1.2.2.1.1.1.3" xref="Sx4.E3.m1.2.2.1.1.1.3.cmml"><mi id="Sx4.E3.m1.2.2.1.1.1.3.2" xref="Sx4.E3.m1.2.2.1.1.1.3.2.cmml">M</mi><mi id="Sx4.E3.m1.2.2.1.1.1.3.3" xref="Sx4.E3.m1.2.2.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="Sx4.E3.m1.2.2.1.1.1.2" xref="Sx4.E3.m1.2.2.1.1.1.2.cmml">​</mo><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1" xref="Sx4.E3.m1.2.2.1.1.1.1.2.cmml"><mo maxsize="160%" minsize="160%" id="Sx4.E3.m1.2.2.1.1.1.1.1.2" xref="Sx4.E3.m1.2.2.1.1.1.1.2.1.cmml">[</mo><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.cmml"><msub id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.cmml"><mi id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.2.cmml">y</mi><mi id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.3.cmml">i</mi></msub><mo lspace="0.167em" rspace="0em" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.1.cmml">​</mo><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.cmml"><mi id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.1.cmml">log</mi><mo lspace="0.167em" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3a" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.cmml">⁡</mo><msub id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.cmml"><mi id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.2.cmml">r</mi><mi id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.3.cmml">i</mi></msub></mrow></mrow><mo id="Sx4.E3.m1.2.2.1.1.1.1.1.1.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.3.cmml">+</mo><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.cmml"><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mn id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml">y</mi><mi id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0.167em" rspace="0em" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.3.cmml">​</mo><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.2.cmml"><mi id="Sx4.E3.m1.1.1" xref="Sx4.E3.m1.1.1.cmml">log</mi><mo id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1a" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.2.cmml">⁡</mo><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.2.cmml"><mo stretchy="false" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.2.cmml">(</mo><mrow id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.cmml"><mn id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.2.cmml">1</mn><mo id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.1" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.1.cmml">−</mo><msub id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.cmml"><mi id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.2" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.2.cmml">r</mi><mi id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.3" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo maxsize="160%" minsize="160%" id="Sx4.E3.m1.2.2.1.1.1.1.1.3" xref="Sx4.E3.m1.2.2.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx4.E3.m1.2b"><apply id="Sx4.E3.m1.2.2.cmml" xref="Sx4.E3.m1.2.2"><eq id="Sx4.E3.m1.2.2.2.cmml" xref="Sx4.E3.m1.2.2.2"></eq><ci id="Sx4.E3.m1.2.2.3.cmml" xref="Sx4.E3.m1.2.2.3">𝐿</ci><apply id="Sx4.E3.m1.2.2.1.cmml" xref="Sx4.E3.m1.2.2.1"><times id="Sx4.E3.m1.2.2.1.2.cmml" xref="Sx4.E3.m1.2.2.1.2"></times><apply id="Sx4.E3.m1.2.2.1.3.cmml" xref="Sx4.E3.m1.2.2.1.3"><divide id="Sx4.E3.m1.2.2.1.3.1.cmml" xref="Sx4.E3.m1.2.2.1.3"></divide><cn type="integer" id="Sx4.E3.m1.2.2.1.3.2.cmml" xref="Sx4.E3.m1.2.2.1.3.2">1</cn><apply id="Sx4.E3.m1.2.2.1.3.3.cmml" xref="Sx4.E3.m1.2.2.1.3.3"><times id="Sx4.E3.m1.2.2.1.3.3.1.cmml" xref="Sx4.E3.m1.2.2.1.3.3.1"></times><apply id="Sx4.E3.m1.2.2.1.3.3.2.cmml" xref="Sx4.E3.m1.2.2.1.3.3.2"><csymbol cd="ambiguous" id="Sx4.E3.m1.2.2.1.3.3.2.1.cmml" xref="Sx4.E3.m1.2.2.1.3.3.2">superscript</csymbol><ci id="Sx4.E3.m1.2.2.1.3.3.2.2.cmml" xref="Sx4.E3.m1.2.2.1.3.3.2.2">𝑀</ci><ci id="Sx4.E3.m1.2.2.1.3.3.2.3.cmml" xref="Sx4.E3.m1.2.2.1.3.3.2.3">𝑇</ci></apply><ci id="Sx4.E3.m1.2.2.1.3.3.3.cmml" xref="Sx4.E3.m1.2.2.1.3.3.3">𝑀</ci></apply></apply><apply id="Sx4.E3.m1.2.2.1.1.cmml" xref="Sx4.E3.m1.2.2.1.1"><apply id="Sx4.E3.m1.2.2.1.1.2.cmml" xref="Sx4.E3.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="Sx4.E3.m1.2.2.1.1.2.1.cmml" xref="Sx4.E3.m1.2.2.1.1.2">superscript</csymbol><apply id="Sx4.E3.m1.2.2.1.1.2.2.cmml" xref="Sx4.E3.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="Sx4.E3.m1.2.2.1.1.2.2.1.cmml" xref="Sx4.E3.m1.2.2.1.1.2">subscript</csymbol><sum id="Sx4.E3.m1.2.2.1.1.2.2.2.cmml" xref="Sx4.E3.m1.2.2.1.1.2.2.2"></sum><apply id="Sx4.E3.m1.2.2.1.1.2.2.3.cmml" xref="Sx4.E3.m1.2.2.1.1.2.2.3"><eq id="Sx4.E3.m1.2.2.1.1.2.2.3.1.cmml" xref="Sx4.E3.m1.2.2.1.1.2.2.3.1"></eq><ci id="Sx4.E3.m1.2.2.1.1.2.2.3.2.cmml" xref="Sx4.E3.m1.2.2.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="Sx4.E3.m1.2.2.1.1.2.2.3.3.cmml" xref="Sx4.E3.m1.2.2.1.1.2.2.3.3">1</cn></apply></apply><ci id="Sx4.E3.m1.2.2.1.1.2.3.cmml" xref="Sx4.E3.m1.2.2.1.1.2.3">𝐶</ci></apply><apply id="Sx4.E3.m1.2.2.1.1.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1"><times id="Sx4.E3.m1.2.2.1.1.1.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.2"></times><apply id="Sx4.E3.m1.2.2.1.1.1.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="Sx4.E3.m1.2.2.1.1.1.3.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.3">subscript</csymbol><ci id="Sx4.E3.m1.2.2.1.1.1.3.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.3.2">𝑀</ci><ci id="Sx4.E3.m1.2.2.1.1.1.3.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.3.3">𝑖</ci></apply><apply id="Sx4.E3.m1.2.2.1.1.1.1.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="Sx4.E3.m1.2.2.1.1.1.1.2.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.2">delimited-[]</csymbol><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1"><plus id="Sx4.E3.m1.2.2.1.1.1.1.1.1.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.3"></plus><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4"><times id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.1"></times><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2"><csymbol cd="ambiguous" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2">subscript</csymbol><ci id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.2">𝑦</ci><ci id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.2.3">𝑖</ci></apply><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3"><log id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.1"></log><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2"><csymbol cd="ambiguous" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2">subscript</csymbol><ci id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.2">𝑟</ci><ci id="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.4.3.2.3">𝑖</ci></apply></apply></apply><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2"><times id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.3"></times><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1"><minus id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.2">1</cn><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2">𝑦</ci><ci id="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1"><log id="Sx4.E3.m1.1.1.cmml" xref="Sx4.E3.m1.1.1"></log><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1"><minus id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.1"></minus><cn type="integer" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.2">1</cn><apply id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.1.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3">subscript</csymbol><ci id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.2.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.2">𝑟</ci><ci id="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.3.cmml" xref="Sx4.E3.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.E3.m1.2c">\displaystyle L=\frac{1}{M^{T}M}\sum_{i=1}^{C}M_{i}\Big{[}y_{i}\log r_{i}+(1-y_{i})\log(1-r_{i})\Big{]}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="Sx4.p2.4" class="ltx_p">During <em id="Sx4.p2.4.1" class="ltx_emph ltx_font_italic">inference</em>, if an extracted label
was mapped to multiple tokens (e.g. “teddy bear”), the predictions are averaged.
</p>
</div>
<div id="Sx4.p3" class="ltx_para">
<p id="Sx4.p3.1" class="ltx_p"><span id="Sx4.p3.1.1" class="ltx_text ltx_font_bold">Special token.</span> We test VEIL<math id="Sx4.p3.1.m1.1" class="ltx_Math" alttext="{}_{\text{ST}}" display="inline"><semantics id="Sx4.p3.1.m1.1a"><msub id="Sx4.p3.1.m1.1.1" xref="Sx4.p3.1.m1.1.1.cmml"><mi id="Sx4.p3.1.m1.1.1a" xref="Sx4.p3.1.m1.1.1.cmml"></mi><mtext id="Sx4.p3.1.m1.1.1.1" xref="Sx4.p3.1.m1.1.1.1a.cmml">ST</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx4.p3.1.m1.1b"><apply id="Sx4.p3.1.m1.1.1.cmml" xref="Sx4.p3.1.m1.1.1"><ci id="Sx4.p3.1.m1.1.1.1a.cmml" xref="Sx4.p3.1.m1.1.1.1"><mtext mathsize="70%" id="Sx4.p3.1.m1.1.1.1.cmml" xref="Sx4.p3.1.m1.1.1.1">ST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p3.1.m1.1c">{}_{\text{ST}}</annotation></semantics></math> which inserts a special token <span id="Sx4.p3.1.2" class="ltx_text ltx_font_typewriter">[EM_LABEL]</span> before each extracted label in the caption to reduce the model’s reliance on category-specific cues and improve generalization to other datasets. We find that it helps only the latter.</p>
</div>
<div id="Sx4.p4" class="ltx_para">
<p id="Sx4.p4.1" class="ltx_p"><span id="Sx4.p4.1.1" class="ltx_text ltx_font_bold">Weakly-supervised object detection.</span>
To test the ability of extracted label filtering or correction methods for weakly-supervised object detection, we train MIST <cite class="ltx_cite ltx_citemacro_citep">(Ren et al. <a href="#bib.bib28" title="" class="ltx_ref">2020</a>)</cite>. MIST extends WSDDN <cite class="ltx_cite ltx_citemacro_citep">(Bilen and Vedaldi <a href="#bib.bib1" title="" class="ltx_ref">2016</a>)</cite> and OICR <cite class="ltx_cite ltx_citemacro_citep">(Tang et al. <a href="#bib.bib35" title="" class="ltx_ref">2017b</a>)</cite> to mine pseudo-ground truth boxes prior to iterative refinement such that multiple instances are not grouped as one.
VEIL uses training data from the in-the-wild datasets to train the vetting model, and we want to see how its ability to vet labels generalizes to unseen data. Thus, we use the test splits of the in-the-wild datasets to train MIST, as they are unseen by all vetting methods. We do not evaluate the WSOD model on these in-the-wild datasets, but rather on disjoint datasets, VOC-07 <cite class="ltx_cite ltx_citemacro_citep">(Everingham et al. <a href="#bib.bib7" title="" class="ltx_ref">2010</a>)</cite> and COCO 2014 <cite class="ltx_cite ltx_citemacro_citep">(Lin et al. <a href="#bib.bib20" title="" class="ltx_ref">2014</a>)</cite>.</p>
</div>
<div id="Sx4.p5" class="ltx_para">
<p id="Sx4.p5.1" class="ltx_p"><span id="Sx4.p5.1.1" class="ltx_text ltx_font_bold">Implementation details.</span>
VEIL is implemented in PyTorch <cite class="ltx_cite ltx_citemacro_citep">(Paszke et al. <a href="#bib.bib24" title="" class="ltx_ref">2019</a>)</cite> and uses a pretrained BERT encoder <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al. <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite> prior to the per-token visual presence classification layer.
We simulate a batch size of 8 for all experiments unless specified otherwise. To address class imbalance during WSOD,
we use the complement of the sub-sampling probability introduced in Word2Vec <cite class="ltx_cite ltx_citemacro_citep">(Mikolov et al. <a href="#bib.bib22" title="" class="ltx_ref">2013</a>)</cite> as weights.
We used 4 RTX A5000 GPUs and trained for 50k iterations with a batch size of 8, or 100k iterations on 4 Quadro RTX 5000 GPUs with a batch size of 4 and gradient accumulation (parameters updated every two iterations to simulate a batch size of 8).</p>
</div>
</section>
<section id="Sx5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Experiments</h2>

<figure id="Sx5.T2" class="ltx_table">
<table id="Sx5.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx5.T2.1.1.1" class="ltx_tr">
<td id="Sx5.T2.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.1.1.2.1.1" class="ltx_p" style="width:122.9pt;"><span id="Sx5.T2.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Method</span></span>
</span>
</td>
<td id="Sx5.T2.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.1.1.3.1.1" class="ltx_p" style="width:36.1pt;"><span id="Sx5.T2.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">SBUCaps</span></span>
</span>
</td>
<td id="Sx5.T2.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.1.1.4.1.1" class="ltx_p" style="width:36.1pt;"><span id="Sx5.T2.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">RedCaps</span></span>
</span>
</td>
<td id="Sx5.T2.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.1.1.5.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold">CC</span></span>
</span>
</td>
<td id="Sx5.T2.1.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.1.1.6.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.1.1.6.1.1.1" class="ltx_text ltx_font_bold">VIST</span></span>
</span>
</td>
<td id="Sx5.T2.1.1.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.1.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.1.1.7.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.1.1.7.1.1.1" class="ltx_text ltx_font_bold">VIST-DII</span></span>
</span>
</td>
<td id="Sx5.T2.1.1.1.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.1.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.1.1.8.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.1.1.8.1.1.1" class="ltx_text ltx_font_bold">VIST-SIS</span></span>
</span>
</td>
<td id="Sx5.T2.1.1.1.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.1.1.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.1.1.9.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.1.1.9.1.1.1" class="ltx_text ltx_font_bold">COCO</span></span>
</span>
</td>
<td id="Sx5.T2.1.1.1.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx5.T2.1.1.1.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.1.1.10.1.1" class="ltx_p" style="width:21.7pt;"><span id="Sx5.T2.1.1.1.10.1.1.1" class="ltx_text ltx_font_bold">AVG</span></span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.2.2" class="ltx_tr">
<td id="Sx5.T2.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.2.2.2.1.1" class="ltx_p" style="width:122.9pt;">No Vetting</span>
</span>
</td>
<td id="Sx5.T2.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.2.2.3.1.1" class="ltx_p" style="width:36.1pt;">0.633</span>
</span>
</td>
<td id="Sx5.T2.1.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.2.2.4.1.1" class="ltx_p" style="width:36.1pt;">0.747</span>
</span>
</td>
<td id="Sx5.T2.1.2.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.2.2.5.1.1" class="ltx_p" style="width:25.3pt;">0.849</span>
</span>
</td>
<td id="Sx5.T2.1.2.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.2.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.2.2.6.1.1" class="ltx_p" style="width:25.3pt;">0.853</span>
</span>
</td>
<td id="Sx5.T2.1.2.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.2.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.2.2.7.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.2.2.7.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">0.876</span></span>
</span>
</td>
<td id="Sx5.T2.1.2.2.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.2.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.2.2.8.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.2.2.8.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">0.820</span></span>
</span>
</td>
<td id="Sx5.T2.1.2.2.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.2.2.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.2.2.9.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.2.2.9.1.1.1" class="ltx_text ltx_font_bold">0.973</span></span>
</span>
</td>
<td id="Sx5.T2.1.2.2.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx5.T2.1.2.2.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.2.2.10.1.1" class="ltx_p" style="width:21.7pt;">0.822</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.3.3" class="ltx_tr">
<td id="Sx5.T2.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.3.3.2.1.1" class="ltx_p" style="width:122.9pt;">Global CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="Sx5.T2.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.3.3.3.1.1" class="ltx_p" style="width:36.1pt;">0.604</span>
</span>
</td>
<td id="Sx5.T2.1.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.3.3.4.1.1" class="ltx_p" style="width:36.1pt;">0.583</span>
</span>
</td>
<td id="Sx5.T2.1.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.3.3.5.1.1" class="ltx_p" style="width:25.3pt;">0.569</span>
</span>
</td>
<td id="Sx5.T2.1.3.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.3.3.6.1.1" class="ltx_p" style="width:25.3pt;">0.668</span>
</span>
</td>
<td id="Sx5.T2.1.3.3.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.3.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.3.3.7.1.1" class="ltx_p" style="width:25.3pt;">0.625</span>
</span>
</td>
<td id="Sx5.T2.1.3.3.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.3.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.3.3.8.1.1" class="ltx_p" style="width:25.3pt;">0.683</span>
</span>
</td>
<td id="Sx5.T2.1.3.3.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.3.3.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.3.3.9.1.1" class="ltx_p" style="width:25.3pt;">0.662</span>
</span>
</td>
<td id="Sx5.T2.1.3.3.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx5.T2.1.3.3.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.3.3.10.1.1" class="ltx_p" style="width:21.7pt;">0.628</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.4.4" class="ltx_tr">
<td id="Sx5.T2.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:50.6pt;">
<span id="Sx5.T2.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.1.1.1" class="ltx_p">Img + Lang</span>
</span>
</td>
<td id="Sx5.T2.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.2.1.1" class="ltx_p" style="width:122.9pt;">Global CLIP - E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="Sx5.T2.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.3.1.1" class="ltx_p" style="width:36.1pt;">0.594</span>
</span>
</td>
<td id="Sx5.T2.1.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.4.1.1" class="ltx_p" style="width:36.1pt;">0.569</span>
</span>
</td>
<td id="Sx5.T2.1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.5.1.1" class="ltx_p" style="width:25.3pt;">0.534</span>
</span>
</td>
<td id="Sx5.T2.1.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.6.1.1" class="ltx_p" style="width:25.3pt;">0.654</span>
</span>
</td>
<td id="Sx5.T2.1.4.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.4.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.7.1.1" class="ltx_p" style="width:25.3pt;">0.613</span>
</span>
</td>
<td id="Sx5.T2.1.4.4.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.4.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.8.1.1" class="ltx_p" style="width:25.3pt;">0.660</span>
</span>
</td>
<td id="Sx5.T2.1.4.4.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.4.4.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.9.1.1" class="ltx_p" style="width:25.3pt;">0.640</span>
</span>
</td>
<td id="Sx5.T2.1.4.4.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T2.1.4.4.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.4.4.10.1.1" class="ltx_p" style="width:21.7pt;">0.609</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.5.5" class="ltx_tr">
<td id="Sx5.T2.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.5.5.2.1.1" class="ltx_p" style="width:122.9pt;">Local CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="Sx5.T2.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.5.5.3.1.1" class="ltx_p" style="width:36.1pt;">0.347</span>
</span>
</td>
<td id="Sx5.T2.1.5.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.5.5.4.1.1" class="ltx_p" style="width:36.1pt;">0.651</span>
</span>
</td>
<td id="Sx5.T2.1.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.5.5.5.1.1" class="ltx_p" style="width:25.3pt;">0.363</span>
</span>
</td>
<td id="Sx5.T2.1.5.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.5.5.6.1.1" class="ltx_p" style="width:25.3pt;">0.427</span>
</span>
</td>
<td id="Sx5.T2.1.5.5.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.5.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.5.5.7.1.1" class="ltx_p" style="width:25.3pt;">0.476</span>
</span>
</td>
<td id="Sx5.T2.1.5.5.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.5.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.5.5.8.1.1" class="ltx_p" style="width:25.3pt;">0.418</span>
</span>
</td>
<td id="Sx5.T2.1.5.5.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.5.5.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.5.5.9.1.1" class="ltx_p" style="width:25.3pt;">0.464</span>
</span>
</td>
<td id="Sx5.T2.1.5.5.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx5.T2.1.5.5.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.5.5.10.1.1" class="ltx_p" style="width:21.7pt;">0.449</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.6.6" class="ltx_tr">
<td id="Sx5.T2.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.6.6.2.1.1" class="ltx_p" style="width:122.9pt;">Local CLIP - E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="Sx5.T2.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.6.6.3.1.1" class="ltx_p" style="width:36.1pt;"><span id="Sx5.T2.1.6.6.3.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">0.760</span></span>
</span>
</td>
<td id="Sx5.T2.1.6.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.6.6.4.1.1" class="ltx_p" style="width:36.1pt;"><span id="Sx5.T2.1.6.6.4.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">0.840</span></span>
</span>
</td>
<td id="Sx5.T2.1.6.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.6.6.5.1.1" class="ltx_p" style="width:25.3pt;">0.597</span>
</span>
</td>
<td id="Sx5.T2.1.6.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.6.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.6.6.6.1.1" class="ltx_p" style="width:25.3pt;">0.759</span>
</span>
</td>
<td id="Sx5.T2.1.6.6.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.6.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.6.6.7.1.1" class="ltx_p" style="width:25.3pt;">0.695</span>
</span>
</td>
<td id="Sx5.T2.1.6.6.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.6.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.6.6.8.1.1" class="ltx_p" style="width:25.3pt;">0.812</span>
</span>
</td>
<td id="Sx5.T2.1.6.6.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.6.6.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.6.6.9.1.1" class="ltx_p" style="width:25.3pt;">0.788</span>
</span>
</td>
<td id="Sx5.T2.1.6.6.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T2.1.6.6.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.6.6.10.1.1" class="ltx_p" style="width:21.7pt;">0.750</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.7.7" class="ltx_tr">
<td id="Sx5.T2.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:50.6pt;">
<span id="Sx5.T2.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.1.1.1" class="ltx_p">Image</span>
</span>
</td>
<td id="Sx5.T2.1.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.2.1.1" class="ltx_p" style="width:122.9pt;">Reject Large Loss <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite></span>
</span>
</td>
<td id="Sx5.T2.1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.3.1.1" class="ltx_p" style="width:36.1pt;">0.667</span>
</span>
</td>
<td id="Sx5.T2.1.7.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.4.1.1" class="ltx_p" style="width:36.1pt;">0.790</span>
</span>
</td>
<td id="Sx5.T2.1.7.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.5.1.1" class="ltx_p" style="width:25.3pt;">0.831</span>
</span>
</td>
<td id="Sx5.T2.1.7.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.6.1.1" class="ltx_p" style="width:25.3pt;">0.782</span>
</span>
</td>
<td id="Sx5.T2.1.7.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.7.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.7.1.1" class="ltx_p" style="width:25.3pt;">0.794</span>
</span>
</td>
<td id="Sx5.T2.1.7.7.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.7.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.8.1.1" class="ltx_p" style="width:25.3pt;">0.743</span>
</span>
</td>
<td id="Sx5.T2.1.7.7.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.7.7.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.9.1.1" class="ltx_p" style="width:25.3pt;">0.896</span>
</span>
</td>
<td id="Sx5.T2.1.7.7.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T2.1.7.7.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.7.7.10.1.1" class="ltx_p" style="width:21.7pt;">0.786</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.8.8" class="ltx_tr">
<td id="Sx5.T2.1.8.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.8.8.2.1.1" class="ltx_p" style="width:122.9pt;">Accept Descriptive</span>
</span>
</td>
<td id="Sx5.T2.1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.8.8.3.1.1" class="ltx_p" style="width:36.1pt;">0.491</span>
</span>
</td>
<td id="Sx5.T2.1.8.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.8.8.4.1.1" class="ltx_p" style="width:36.1pt;">0.413</span>
</span>
</td>
<td id="Sx5.T2.1.8.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.8.8.5.1.1" class="ltx_p" style="width:25.3pt;">0.740</span>
</span>
</td>
<td id="Sx5.T2.1.8.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.8.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.8.8.6.1.1" class="ltx_p" style="width:25.3pt;">0.687</span>
</span>
</td>
<td id="Sx5.T2.1.8.8.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.8.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.8.8.7.1.1" class="ltx_p" style="width:25.3pt;">0.844</span>
</span>
</td>
<td id="Sx5.T2.1.8.8.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.8.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.8.8.8.1.1" class="ltx_p" style="width:25.3pt;">0.264</span>
</span>
</td>
<td id="Sx5.T2.1.8.8.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.8.8.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.8.8.9.1.1" class="ltx_p" style="width:25.3pt;">0.935</span>
</span>
</td>
<td id="Sx5.T2.1.8.8.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx5.T2.1.8.8.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.8.8.10.1.1" class="ltx_p" style="width:21.7pt;">0.625</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.9.9" class="ltx_tr">
<td id="Sx5.T2.1.9.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.9.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.9.9.2.1.1" class="ltx_p" style="width:122.9pt;">Accept Narrative</span>
</span>
</td>
<td id="Sx5.T2.1.9.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.9.9.3.1.1" class="ltx_p" style="width:36.1pt;">0.470</span>
</span>
</td>
<td id="Sx5.T2.1.9.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.9.9.4.1.1" class="ltx_p" style="width:36.1pt;">0.645</span>
</span>
</td>
<td id="Sx5.T2.1.9.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.9.9.5.1.1" class="ltx_p" style="width:25.3pt;">0.383</span>
</span>
</td>
<td id="Sx5.T2.1.9.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.9.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.9.9.6.1.1" class="ltx_p" style="width:25.3pt;">0.487</span>
</span>
</td>
<td id="Sx5.T2.1.9.9.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.9.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.9.9.7.1.1" class="ltx_p" style="width:25.3pt;">0.154</span>
</span>
</td>
<td id="Sx5.T2.1.9.9.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.9.9.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.9.9.8.1.1" class="ltx_p" style="width:25.3pt;">0.757</span>
</span>
</td>
<td id="Sx5.T2.1.9.9.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.9.9.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.9.9.9.1.1" class="ltx_p" style="width:25.3pt;">0.143</span>
</span>
</td>
<td id="Sx5.T2.1.9.9.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T2.1.9.9.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.9.9.10.1.1" class="ltx_p" style="width:21.7pt;">0.434</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.10.10" class="ltx_tr">
<td id="Sx5.T2.1.10.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.10.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.10.10.2.1.1" class="ltx_p" style="width:122.9pt;">Reject Noun Mod. (Adj)</span>
</span>
</td>
<td id="Sx5.T2.1.10.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.10.10.3.1.1" class="ltx_p" style="width:36.1pt;">0.618</span>
</span>
</td>
<td id="Sx5.T2.1.10.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.10.10.4.1.1" class="ltx_p" style="width:36.1pt;">0.703</span>
</span>
</td>
<td id="Sx5.T2.1.10.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.10.10.5.1.1" class="ltx_p" style="width:25.3pt;">0.814</span>
</span>
</td>
<td id="Sx5.T2.1.10.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.10.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.10.10.6.1.1" class="ltx_p" style="width:25.3pt;">0.823</span>
</span>
</td>
<td id="Sx5.T2.1.10.10.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.10.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.10.10.7.1.1" class="ltx_p" style="width:25.3pt;">0.847</span>
</span>
</td>
<td id="Sx5.T2.1.10.10.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.10.10.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.10.10.8.1.1" class="ltx_p" style="width:25.3pt;">0.788</span>
</span>
</td>
<td id="Sx5.T2.1.10.10.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.10.10.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.10.10.9.1.1" class="ltx_p" style="width:25.3pt;">0.906</span>
</span>
</td>
<td id="Sx5.T2.1.10.10.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T2.1.10.10.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.10.10.10.1.1" class="ltx_p" style="width:21.7pt;">0.786</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.11.11" class="ltx_tr">
<td id="Sx5.T2.1.11.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.11.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.11.11.2.1.1" class="ltx_p" style="width:122.9pt;">Reject Noun Mod. (Any)</span>
</span>
</td>
<td id="Sx5.T2.1.11.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.11.11.3.1.1" class="ltx_p" style="width:36.1pt;">0.616</span>
</span>
</td>
<td id="Sx5.T2.1.11.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.11.11.4.1.1" class="ltx_p" style="width:36.1pt;">0.689</span>
</span>
</td>
<td id="Sx5.T2.1.11.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.11.11.5.1.1" class="ltx_p" style="width:25.3pt;">0.812</span>
</span>
</td>
<td id="Sx5.T2.1.11.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.11.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.11.11.6.1.1" class="ltx_p" style="width:25.3pt;">0.821</span>
</span>
</td>
<td id="Sx5.T2.1.11.11.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.11.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.11.11.7.1.1" class="ltx_p" style="width:25.3pt;">0.842</span>
</span>
</td>
<td id="Sx5.T2.1.11.11.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.11.11.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.11.11.8.1.1" class="ltx_p" style="width:25.3pt;">0.782</span>
</span>
</td>
<td id="Sx5.T2.1.11.11.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.11.11.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.11.11.9.1.1" class="ltx_p" style="width:25.3pt;">0.900</span>
</span>
</td>
<td id="Sx5.T2.1.11.11.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T2.1.11.11.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.11.11.10.1.1" class="ltx_p" style="width:21.7pt;">0.780</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.12.12" class="ltx_tr">
<td id="Sx5.T2.1.12.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.12.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.12.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.12.12.2.1.1" class="ltx_p" style="width:122.9pt;">Cap2Det <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib40" title="" class="ltx_ref">2019b</a>)</cite></span>
</span>
</td>
<td id="Sx5.T2.1.12.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.12.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.12.12.3.1.1" class="ltx_p" style="width:36.1pt;">0.639</span>
</span>
</td>
<td id="Sx5.T2.1.12.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.12.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.12.12.4.1.1" class="ltx_p" style="width:36.1pt;">0.758</span>
</span>
</td>
<td id="Sx5.T2.1.12.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.12.12.5.1.1" class="ltx_p" style="width:25.3pt;">0.846</span>
</span>
</td>
<td id="Sx5.T2.1.12.12.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.12.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.12.12.6.1.1" class="ltx_p" style="width:25.3pt;">0.826</span>
</span>
</td>
<td id="Sx5.T2.1.12.12.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.12.12.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.12.12.7.1.1" class="ltx_p" style="width:25.3pt;">0.854</span>
</span>
</td>
<td id="Sx5.T2.1.12.12.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.12.12.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.12.12.8.1.1" class="ltx_p" style="width:25.3pt;">0.774</span>
</span>
</td>
<td id="Sx5.T2.1.12.12.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T2.1.12.12.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.12.12.9.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.12.12.9.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">0.964</span></span>
</span>
</td>
<td id="Sx5.T2.1.12.12.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T2.1.12.12.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.12.12.10.1.1" class="ltx_p" style="width:21.7pt;">0.809</span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.13.13" class="ltx_tr">
<td id="Sx5.T2.1.13.13.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:50.6pt;"></td>
<td id="Sx5.T2.1.13.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.13.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.13.13.2.1.1" class="ltx_p" style="width:122.9pt;">VEIL-Same Dataset</span>
</span>
</td>
<td id="Sx5.T2.1.13.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.13.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.13.13.3.1.1" class="ltx_p" style="width:36.1pt;"><span id="Sx5.T2.1.13.13.3.1.1.1" class="ltx_text ltx_font_bold">0.809</span></span>
</span>
</td>
<td id="Sx5.T2.1.13.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.13.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.13.13.4.1.1" class="ltx_p" style="width:36.1pt;"><span id="Sx5.T2.1.13.13.4.1.1.1" class="ltx_text ltx_font_bold">0.890</span></span>
</span>
</td>
<td id="Sx5.T2.1.13.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.13.13.5.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.13.13.5.1.1.1" class="ltx_text ltx_font_bold">0.909</span></span>
</span>
</td>
<td id="Sx5.T2.1.13.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.13.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.13.13.6.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.13.13.6.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">0.871</span></span>
</span>
</td>
<td id="Sx5.T2.1.13.13.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.13.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.13.13.7.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.13.13.7.1.1.1" class="ltx_text ltx_font_bold">0.892</span></span>
</span>
</td>
<td id="Sx5.T2.1.13.13.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.13.13.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.13.13.8.1.1" class="ltx_p" style="width:25.3pt;">0.816</span>
</span>
</td>
<td id="Sx5.T2.1.13.13.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T2.1.13.13.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.13.13.9.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.13.13.9.1.1.1" class="ltx_text ltx_font_bold">0.973</span></span>
</span>
</td>
<td id="Sx5.T2.1.13.13.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx5.T2.1.13.13.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.13.13.10.1.1" class="ltx_p" style="width:21.7pt;"><span id="Sx5.T2.1.13.13.10.1.1.1" class="ltx_text ltx_font_bold">0.884</span></span>
</span>
</td>
</tr>
<tr id="Sx5.T2.1.14.14" class="ltx_tr">
<td id="Sx5.T2.1.14.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r" style="width:50.6pt;">
<span id="Sx5.T2.1.14.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.1.1.1" class="ltx_p">Lang</span>
</span>
</td>
<td id="Sx5.T2.1.14.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T2.1.14.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.2.1.1" class="ltx_p" style="width:122.9pt;">VEIL-Cross Dataset</span>
</span>
</td>
<td id="Sx5.T2.1.14.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T2.1.14.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.3.1.1" class="ltx_p" style="width:36.1pt;">0.716</span>
</span>
</td>
<td id="Sx5.T2.1.14.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T2.1.14.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.4.1.1" class="ltx_p" style="width:36.1pt;">0.793</span>
</span>
</td>
<td id="Sx5.T2.1.14.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T2.1.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.5.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.14.14.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">0.850</span></span>
</span>
</td>
<td id="Sx5.T2.1.14.14.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T2.1.14.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.6.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.14.14.6.1.1.1" class="ltx_text ltx_font_bold">0.875</span></span>
</span>
</td>
<td id="Sx5.T2.1.14.14.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T2.1.14.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.7.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.14.14.7.1.1.1" class="ltx_text ltx_font_bold">0.892</span></span>
</span>
</td>
<td id="Sx5.T2.1.14.14.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T2.1.14.14.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.8.1.1" class="ltx_p" style="width:25.3pt;"><span id="Sx5.T2.1.14.14.8.1.1.1" class="ltx_text ltx_font_bold">0.830</span></span>
</span>
</td>
<td id="Sx5.T2.1.14.14.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T2.1.14.14.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.9.1.1" class="ltx_p" style="width:25.3pt;">0.958</span>
</span>
</td>
<td id="Sx5.T2.1.14.14.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="Sx5.T2.1.14.14.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T2.1.14.14.10.1.1" class="ltx_p" style="width:21.7pt;"><span id="Sx5.T2.1.14.14.10.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">0.842</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Extracted Label Vetting F1 Performance. <span id="Sx5.T2.4.1" class="ltx_text ltx_font_bold">Bold</span> indicates best performance in each column, and <span id="Sx5.T2.5.2" class="ltx_text ltx_framed ltx_framed_underline">underlined</span> second-best.</figcaption>
</figure>
<div id="Sx5.p1" class="ltx_para">
<p id="Sx5.p1.1" class="ltx_p">We show the ability of VEIL to match and exceed language-agnostic filtering and image-based filtering methods in extracted label vetting (ELV). Next, we highlight the promising ability of VEIL to vet noisy extracted labels prior to weakly-supervised object detection training and remove structured noise.
Lastly, we benchmark the generalization ability of VEIL in cross-dataset and cross-category settings.
</p>
</div>
<section id="Sx5.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Experiment Details</h3>

<div id="Sx5.SSx1.p1" class="ltx_para">
<p id="Sx5.SSx1.p1.1" class="ltx_p">We use three in-the-wild image-caption datasets (SBUCaps <cite class="ltx_cite ltx_citemacro_citep">(Ordonez, Kulkarni, and Berg <a href="#bib.bib23" title="" class="ltx_ref">2011</a>)</cite>, RedCaps <cite class="ltx_cite ltx_citemacro_citep">(Desai et al. <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>, Conceptual Captions <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al. <a href="#bib.bib31" title="" class="ltx_ref">2018</a>)</cite>) and three human annotated datasets that fall into descriptive (COCO <cite class="ltx_cite ltx_citemacro_citep">(Lin et al. <a href="#bib.bib20" title="" class="ltx_ref">2014</a>)</cite>, VIST-DII <cite class="ltx_cite ltx_citemacro_citep">(Huang et al. <a href="#bib.bib13" title="" class="ltx_ref">2016</a>)</cite>) and narrative (VIST-SIS <cite class="ltx_cite ltx_citemacro_citep">(Huang et al. <a href="#bib.bib13" title="" class="ltx_ref">2016</a>)</cite>).
Each in-the-wild dataset and VIST are first reduced to a subset of image-caption pairs where a COCO category is explicitly mentioned in the caption. This subset is split into 80-20 train-test split.
The WSOD models are trained on SBUCaps with labels vetted by different methods, and evaluated on PASCAL VOC 2007 test <cite class="ltx_cite ltx_citemacro_citep">(Everingham et al. <a href="#bib.bib7" title="" class="ltx_ref">2010</a>)</cite> and COCO val 2014 <cite class="ltx_cite ltx_citemacro_citep">(Lin et al. <a href="#bib.bib20" title="" class="ltx_ref">2014</a>)</cite>. The mAP metric uses <math id="Sx5.SSx1.p1.1.m1.1" class="ltx_Math" alttext="IOU=0.5" display="inline"><semantics id="Sx5.SSx1.p1.1.m1.1a"><mrow id="Sx5.SSx1.p1.1.m1.1.1" xref="Sx5.SSx1.p1.1.m1.1.1.cmml"><mrow id="Sx5.SSx1.p1.1.m1.1.1.2" xref="Sx5.SSx1.p1.1.m1.1.1.2.cmml"><mi id="Sx5.SSx1.p1.1.m1.1.1.2.2" xref="Sx5.SSx1.p1.1.m1.1.1.2.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="Sx5.SSx1.p1.1.m1.1.1.2.1" xref="Sx5.SSx1.p1.1.m1.1.1.2.1.cmml">​</mo><mi id="Sx5.SSx1.p1.1.m1.1.1.2.3" xref="Sx5.SSx1.p1.1.m1.1.1.2.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="Sx5.SSx1.p1.1.m1.1.1.2.1a" xref="Sx5.SSx1.p1.1.m1.1.1.2.1.cmml">​</mo><mi id="Sx5.SSx1.p1.1.m1.1.1.2.4" xref="Sx5.SSx1.p1.1.m1.1.1.2.4.cmml">U</mi></mrow><mo id="Sx5.SSx1.p1.1.m1.1.1.1" xref="Sx5.SSx1.p1.1.m1.1.1.1.cmml">=</mo><mn id="Sx5.SSx1.p1.1.m1.1.1.3" xref="Sx5.SSx1.p1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx5.SSx1.p1.1.m1.1b"><apply id="Sx5.SSx1.p1.1.m1.1.1.cmml" xref="Sx5.SSx1.p1.1.m1.1.1"><eq id="Sx5.SSx1.p1.1.m1.1.1.1.cmml" xref="Sx5.SSx1.p1.1.m1.1.1.1"></eq><apply id="Sx5.SSx1.p1.1.m1.1.1.2.cmml" xref="Sx5.SSx1.p1.1.m1.1.1.2"><times id="Sx5.SSx1.p1.1.m1.1.1.2.1.cmml" xref="Sx5.SSx1.p1.1.m1.1.1.2.1"></times><ci id="Sx5.SSx1.p1.1.m1.1.1.2.2.cmml" xref="Sx5.SSx1.p1.1.m1.1.1.2.2">𝐼</ci><ci id="Sx5.SSx1.p1.1.m1.1.1.2.3.cmml" xref="Sx5.SSx1.p1.1.m1.1.1.2.3">𝑂</ci><ci id="Sx5.SSx1.p1.1.m1.1.1.2.4.cmml" xref="Sx5.SSx1.p1.1.m1.1.1.2.4">𝑈</ci></apply><cn type="float" id="Sx5.SSx1.p1.1.m1.1.1.3.cmml" xref="Sx5.SSx1.p1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.SSx1.p1.1.m1.1c">IOU=0.5</annotation></semantics></math>.
However, when contrasting the image-level classification performance and detection performance we refer to them as Recognition maP and Detection mAP, respectively.
</p>
</div>
</section>
<section id="Sx5.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Methods Compared</h3>

<div id="Sx5.SSx2.p1" class="ltx_para">
<p id="Sx5.SSx2.p1.1" class="ltx_p">For VEIL, we use the convention VEIL-DatasetX to signify that VEIL is trained on the train-split of DatasetX. Next, we describe the methods we compare against.
We group these into language-based, image-based, and image-language methods. They are category-agnostic, except for Cap2Det <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib40" title="" class="ltx_ref">2019b</a>)</cite> and LLM <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite> which must be applied on closed vocabularies.

<br class="ltx_break"><span id="Sx5.SSx2.p1.1.1" class="ltx_text ltx_font_bold">No Vetting.</span> Accept all extracted labels (has <em id="Sx5.SSx2.p1.1.2" class="ltx_emph ltx_font_italic">perfect recall</em>).

<br class="ltx_break"><span id="Sx5.SSx2.p1.1.3" class="ltx_text ltx_font_bold">Global CLIP and CLIP-E.</span> We use the ViT-B/32 pretrained CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite> model. To enhance alignment <cite class="ltx_cite ltx_citemacro_citep">(Hessel et al. <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>, we add the prompt “A photo depicts” to the caption and calculate the cosine similarity between the image and text embeddings generated by CLIP. Since the cosine similarity distribution varies per dataset, we train a Gaussian Mixture Model with two components on the train datasets and select image-text pairs predicted to the component with higher visual-caption alignment.
For the ensemble variant (CLIP-E), we prepend multiple prompts to the caption,
and use the score from the highest-scoring prompt.

<br class="ltx_break"><span id="Sx5.SSx2.p1.1.4" class="ltx_text ltx_font_bold">Local CLIP and CLIP-E</span> follow a similar process but use cosine similarity between the image and the prompt “this is a photo of a” followed by the extracted label. Extracted labels are filtered by Local CLIP, not entire captions, making this image-conditioned, not image-language conditioned vetting like Global CLIP. Local CLIP-E ensembles prompts.

<br class="ltx_break"><span id="Sx5.SSx2.p1.1.5" class="ltx_text ltx_font_bold">Reject Large Loss.</span> LLM <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite> is language-agnostic adaptive noise rejection and correction method. To test its ELV ability, we simulate five epochs of WSOD training <cite class="ltx_cite ltx_citemacro_citep">(Bilen and Vedaldi <a href="#bib.bib1" title="" class="ltx_ref">2016</a>)</cite> and consider label targets with a loss exceeding the large loss threshold as “predicted to be visually absent” after the first epoch. The large loss threshold uses a relative delta hyperparameter controlling the rejection rate (set as 0.002 in <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>).

<br class="ltx_break"><span id="Sx5.SSx2.p1.1.6" class="ltx_text ltx_font_bold">Accept Descriptive / Narrative.</span> We train a logistic regression model to predict whether a VIST <cite class="ltx_cite ltx_citemacro_citep">(Huang et al. <a href="#bib.bib13" title="" class="ltx_ref">2016</a>)</cite> caption comes from the DII (descriptive) or SIS (narrative) split. The input vector to this logistic regression model contains binary variables corresponding to the presence of a part of speech vector (e.g. proper noun, adjective, verb - past tense, etc) in the caption. We accept extracted labels from a caption if it yields a score higher than 0.5 for descriptiveness or narrativeness, respectively.

<br class="ltx_break"><span id="Sx5.SSx2.p1.1.7" class="ltx_text ltx_font_bold">Reject Noun Mod. (Adj/Any).</span> Since an extracted label could be modifying another noun (“<span id="Sx5.SSx2.p1.1.8" class="ltx_text ltx_framed ltx_framed_underline">car</span> park”), a very simple baseline would reject such labels. We try two variants, the first noun modifier rule rejects an extracted label if the POS label is an adjective or is followed by a noun. The second rule rejects if the extracted label is not a noun.

<br class="ltx_break"><span id="Sx5.SSx2.p1.1.9" class="ltx_text ltx_font_bold">Cap2Det.</span> We reject a label if it is not predicted by the Cap2Det <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib40" title="" class="ltx_ref">2019b</a>)</cite> classifier.</p>
</div>
<figure id="Sx5.T3" class="ltx_table">
<div id="Sx5.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:89.3pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-135.1pt,27.6pt) scale(0.616009378313863,0.616009378313863) ;">
<table id="Sx5.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx5.T3.1.1.1.1" class="ltx_tr">
<th id="Sx5.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Data</th>
<th id="Sx5.T3.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Vetting Method</th>
<td id="Sx5.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">Label noise</td>
<td id="Sx5.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">Similar context</td>
<td id="Sx5.T3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Visual defects</td>
<td id="Sx5.T3.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t" colspan="6">Linguistic indicators</td>
</tr>
<tr id="Sx5.T3.1.1.2.2" class="ltx_tr">
<th id="Sx5.T3.1.1.2.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<th id="Sx5.T3.1.1.2.2.2" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<td id="Sx5.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Part</td>
<td id="Sx5.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Abs</td>
<td id="Sx5.T3.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Co-occ</td>
<td id="Sx5.T3.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Sim</td>
<td id="Sx5.T3.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Occl</td>
<td id="Sx5.T3.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Parts</td>
<td id="Sx5.T3.1.1.2.2.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Atyp</td>
<td id="Sx5.T3.1.1.2.2.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Mod</td>
<td id="Sx5.T3.1.1.2.2.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Prep</td>
<td id="Sx5.T3.1.1.2.2.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Non-lit</td>
<td id="Sx5.T3.1.1.2.2.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Sense</td>
<td id="Sx5.T3.1.1.2.2.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">%Named</td>
<td id="Sx5.T3.1.1.2.2.15" class="ltx_td ltx_align_center ltx_border_t">%Beyond</td>
</tr>
<tr id="Sx5.T3.1.1.3.3" class="ltx_tr">
<th id="Sx5.T3.1.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="Sx5.T3.1.1.3.3.1.1" class="ltx_text">S</span></th>
<th id="Sx5.T3.1.1.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">VEIL-Same Dataset</th>
<td id="Sx5.T3.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.3.1" class="ltx_text ltx_font_bold">85.0</span></td>
<td id="Sx5.T3.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.4.1" class="ltx_text ltx_font_bold">94.7</span></td>
<td id="Sx5.T3.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.5.1" class="ltx_text ltx_font_bold">87.0</span></td>
<td id="Sx5.T3.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.6.1" class="ltx_text ltx_font_bold">80.0</span></td>
<td id="Sx5.T3.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.7.1" class="ltx_text ltx_font_bold">81.1</span></td>
<td id="Sx5.T3.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.8.1" class="ltx_text ltx_font_bold">90.6</span></td>
<td id="Sx5.T3.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.9.1" class="ltx_text ltx_font_bold">87.2</span></td>
<td id="Sx5.T3.1.1.3.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.10.1" class="ltx_text ltx_font_bold">95.2</span></td>
<td id="Sx5.T3.1.1.3.3.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.11.1" class="ltx_text ltx_font_bold">93.9</span></td>
<td id="Sx5.T3.1.1.3.3.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.12.1" class="ltx_text ltx_font_bold">90.6</span></td>
<td id="Sx5.T3.1.1.3.3.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.13.1" class="ltx_text ltx_font_bold">100.0</span></td>
<td id="Sx5.T3.1.1.3.3.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.3.3.14.1" class="ltx_text ltx_font_bold">100.0</span></td>
<td id="Sx5.T3.1.1.3.3.15" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx5.T3.1.1.3.3.15.1" class="ltx_text ltx_font_bold">88.8</span></td>
</tr>
<tr id="Sx5.T3.1.1.4.4" class="ltx_tr">
<th id="Sx5.T3.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">LocalCLIP-E</th>
<td id="Sx5.T3.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">51.5</td>
<td id="Sx5.T3.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r">80.7</td>
<td id="Sx5.T3.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">71.3</td>
<td id="Sx5.T3.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r">70.0</td>
<td id="Sx5.T3.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r">52.7</td>
<td id="Sx5.T3.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r">52.1</td>
<td id="Sx5.T3.1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r">65.6</td>
<td id="Sx5.T3.1.1.4.4.9" class="ltx_td ltx_align_center ltx_border_r">63.8</td>
<td id="Sx5.T3.1.1.4.4.10" class="ltx_td ltx_align_center ltx_border_r">70.6</td>
<td id="Sx5.T3.1.1.4.4.11" class="ltx_td ltx_align_center ltx_border_r">82.9</td>
<td id="Sx5.T3.1.1.4.4.12" class="ltx_td ltx_align_center ltx_border_r">96.2</td>
<td id="Sx5.T3.1.1.4.4.13" class="ltx_td ltx_align_center ltx_border_r">62.5</td>
<td id="Sx5.T3.1.1.4.4.14" class="ltx_td ltx_align_center">82.4</td>
</tr>
<tr id="Sx5.T3.1.1.5.5" class="ltx_tr">
<th id="Sx5.T3.1.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="Sx5.T3.1.1.5.5.1.1" class="ltx_text">R</span></th>
<th id="Sx5.T3.1.1.5.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">VEIL-Same Dataset</th>
<td id="Sx5.T3.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.5.5.3.1" class="ltx_text ltx_font_bold">91.7</span></td>
<td id="Sx5.T3.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.1</td>
<td id="Sx5.T3.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.5.5.5.1" class="ltx_text ltx_font_bold">71.4</span></td>
<td id="Sx5.T3.1.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.5.5.6.1" class="ltx_text ltx_font_bold">85.7</span></td>
<td id="Sx5.T3.1.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.5.5.7.1" class="ltx_text ltx_font_bold">83.3</span></td>
<td id="Sx5.T3.1.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.5.5.8.1" class="ltx_text ltx_font_bold">89.0</span></td>
<td id="Sx5.T3.1.1.5.5.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.5.5.9.1" class="ltx_text ltx_font_bold">68.3</span></td>
<td id="Sx5.T3.1.1.5.5.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.5.5.10.1" class="ltx_text ltx_font_bold">74.8</span></td>
<td id="Sx5.T3.1.1.5.5.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.5.5.11.1" class="ltx_text ltx_font_bold">90.0</span></td>
<td id="Sx5.T3.1.1.5.5.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66.7</td>
<td id="Sx5.T3.1.1.5.5.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.5.5.13.1" class="ltx_text ltx_font_bold">88.9</span></td>
<td id="Sx5.T3.1.1.5.5.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.9</td>
<td id="Sx5.T3.1.1.5.5.15" class="ltx_td ltx_align_center ltx_border_t">76.3</td>
</tr>
<tr id="Sx5.T3.1.1.6.6" class="ltx_tr">
<th id="Sx5.T3.1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">LocalCLIP-E</th>
<td id="Sx5.T3.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">52.8</td>
<td id="Sx5.T3.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="Sx5.T3.1.1.6.6.3.1" class="ltx_text ltx_font_bold">78.4</span></td>
<td id="Sx5.T3.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">40.0</td>
<td id="Sx5.T3.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r">38.1</td>
<td id="Sx5.T3.1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r">47.0</td>
<td id="Sx5.T3.1.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r">45.0</td>
<td id="Sx5.T3.1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r">23.2</td>
<td id="Sx5.T3.1.1.6.6.9" class="ltx_td ltx_align_center ltx_border_r">68.4</td>
<td id="Sx5.T3.1.1.6.6.10" class="ltx_td ltx_align_center ltx_border_r">63.3</td>
<td id="Sx5.T3.1.1.6.6.11" class="ltx_td ltx_align_center ltx_border_r"><span id="Sx5.T3.1.1.6.6.11.1" class="ltx_text ltx_font_bold">70.8</span></td>
<td id="Sx5.T3.1.1.6.6.12" class="ltx_td ltx_align_center ltx_border_r">70.6</td>
<td id="Sx5.T3.1.1.6.6.13" class="ltx_td ltx_align_center ltx_border_r"><span id="Sx5.T3.1.1.6.6.13.1" class="ltx_text ltx_font_bold">90.0</span></td>
<td id="Sx5.T3.1.1.6.6.14" class="ltx_td ltx_align_center"><span id="Sx5.T3.1.1.6.6.14.1" class="ltx_text ltx_font_bold">76.7</span></td>
</tr>
<tr id="Sx5.T3.1.1.7.7" class="ltx_tr">
<th id="Sx5.T3.1.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="Sx5.T3.1.1.7.7.1.1" class="ltx_text">CC</span></th>
<th id="Sx5.T3.1.1.7.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">VEIL-Same Dataset</th>
<td id="Sx5.T3.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.7.7.3.1" class="ltx_text ltx_font_bold">60.6</span></td>
<td id="Sx5.T3.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">83.0</td>
<td id="Sx5.T3.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.7.7.5.1" class="ltx_text ltx_font_bold">81.2</span></td>
<td id="Sx5.T3.1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">55.0</td>
<td id="Sx5.T3.1.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.7.7.7.1" class="ltx_text ltx_font_bold">54.9</span></td>
<td id="Sx5.T3.1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.7.7.8.1" class="ltx_text ltx_font_bold">53.6</span></td>
<td id="Sx5.T3.1.1.7.7.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.7.7.9.1" class="ltx_text ltx_font_bold">56.3</span></td>
<td id="Sx5.T3.1.1.7.7.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.2</td>
<td id="Sx5.T3.1.1.7.7.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.7.7.11.1" class="ltx_text ltx_font_bold">73.7</span></td>
<td id="Sx5.T3.1.1.7.7.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">81.7</td>
<td id="Sx5.T3.1.1.7.7.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx5.T3.1.1.7.7.13.1" class="ltx_text ltx_font_bold">100.0</span></td>
<td id="Sx5.T3.1.1.7.7.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="Sx5.T3.1.1.7.7.15" class="ltx_td ltx_align_center ltx_border_t">77.4</td>
</tr>
<tr id="Sx5.T3.1.1.8.8" class="ltx_tr">
<th id="Sx5.T3.1.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">LocalCLIP-E</th>
<td id="Sx5.T3.1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">45.0</td>
<td id="Sx5.T3.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="Sx5.T3.1.1.8.8.3.1" class="ltx_text ltx_font_bold">89.1</span></td>
<td id="Sx5.T3.1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">74.9</td>
<td id="Sx5.T3.1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="Sx5.T3.1.1.8.8.5.1" class="ltx_text ltx_font_bold">57.5</span></td>
<td id="Sx5.T3.1.1.8.8.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">49.9</td>
<td id="Sx5.T3.1.1.8.8.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">50.0</td>
<td id="Sx5.T3.1.1.8.8.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">24.1</td>
<td id="Sx5.T3.1.1.8.8.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="Sx5.T3.1.1.8.8.9.1" class="ltx_text ltx_font_bold">73.3</span></td>
<td id="Sx5.T3.1.1.8.8.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">63.9</td>
<td id="Sx5.T3.1.1.8.8.11" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="Sx5.T3.1.1.8.8.11.1" class="ltx_text ltx_font_bold">91.7</span></td>
<td id="Sx5.T3.1.1.8.8.12" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="Sx5.T3.1.1.8.8.12.1" class="ltx_text ltx_font_bold">100.0</span></td>
<td id="Sx5.T3.1.1.8.8.13" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">-</td>
<td id="Sx5.T3.1.1.8.8.14" class="ltx_td ltx_align_center ltx_border_b"><span id="Sx5.T3.1.1.8.8.14.1" class="ltx_text ltx_font_bold">86.8</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>
VAEL recall performance on CLaN. Bold indicates best performance per column/dataset. We omit named entity results for CC as it substitutes them with predefined categories (e.g. person, org.). Top = SBUCaps, middle = RedCaps, bottom = CC.</figcaption>
</figure>
</section>
<section id="Sx5.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Extracted Label Vetting Evaluation</h3>

<div id="Sx5.SSx3.p1" class="ltx_para">
<p id="Sx5.SSx3.p1.1" class="ltx_p">Table <a href="#Sx7.T8" title="Table 8 ‣ Vetting Precision/Recall ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows the F1 score which combines the precision and recall of their vetting (shown separately in supp).
Most language-based methods improve or maintain the F1 score of No Vetting, even though it has perfect recall, except for Accept Descriptive/Narrative.</p>
</div>
<div id="Sx5.SSx3.p2" class="ltx_para">
<p id="Sx5.SSx3.p2.1" class="ltx_p">Rule-based methods and Cap2Det perform strongly, but are outperformed by both VEIL-Same Dataset (trained and tested on the same dataset, without a special token) and VEIL-Cross Dataset (trained on a different dataset than that shown in the column; we show the best cross-dataset result).</p>
</div>
<div id="Sx5.SSx3.p3" class="ltx_para">
<p id="Sx5.SSx3.p3.1" class="ltx_p">VEIL-Cross Dataset outperforms language-based approaches,
showing VEIL’s generalization potential, except COCO where Cap2Det does slightly better.</p>
</div>
<div id="Sx5.SSx3.p4" class="ltx_para">
<p id="Sx5.SSx3.p4.1" class="ltx_p">Image-and-language-conditioned approaches (Global CLIP/CLIP-E) make label decisions based on the overall caption, so if it contains certain language, it can affect the alignment even if the object is actually visually present. Table <a href="#Sx7.T8" title="Table 8 ‣ Vetting Precision/Recall ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows these methods obtain low F1 scores.</p>
</div>
<div id="Sx5.SSx3.p5" class="ltx_para">
<p id="Sx5.SSx3.p5.1" class="ltx_p">Among image-based approaches for label vetting, we observe that Local CLIP benefits significantly from using an ensemble of prompts compared to Global CLIP; ensembling is well documented in improving zero-shot image recognition in prior work <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite>.
Reject Large Loss has the strongest F1 score among the image-based methods, and in supp we show it has strong recall but limited precision improvement over No Vetting, indicating the presence of false positives that do not lead to a large loss.</p>
</div>
<div id="Sx5.SSx3.p6" class="ltx_para">
<p id="Sx5.SSx3.p6.1" class="ltx_p"><span id="Sx5.SSx3.p6.1.1" class="ltx_text ltx_font_bold">Vetting performance on CLaN.</span> We hypothesize that LocalCLIP-E would do well at vetting VAELs explained by linguistic cues like non-literal and beyond the image as they are likely to have little to no visual similarity with the extracted category representation.
We also hypothesize that VEIL would do better than LocalCLIP-E at vetting VAELs that are noun modifiers or in prepositional phrases.
Further, similar context can sometimes be explained by linguistic cues like noun modifiers and prepositional phrases which can be easily picked up from the caption, but LocalCLIP-E may be oblivious to them differing from the true VAEL category.
We evaluate these hypotheses on the CLaN dataset in Table <a href="#Sx5.T3" title="Table 3 ‣ Methods Compared ‣ Experiments ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We omit “visible” VAEL samples as there are pseudo-label errors, and the “past” linguistic indicator due to too few samples.
We find that VEIL vets truly absent objects for SBUCaps much better than LocalCLIP-E, and comparably for RedCaps or CC. It vets partially visible objects better than LocalCLIP-E by a significant margin; these can be harmful in WSOD which is already prone to part domination <cite class="ltx_cite ltx_citemacro_citep">(Ren et al. <a href="#bib.bib28" title="" class="ltx_ref">2020</a>)</cite>.
VEIL also recognizes that similar context to, rather than the actual VAEL category, are present.
VEIL performs better at vetting visible objects that have visual defects
which can be mentioned in caption context
(“acryllic illustration of <span id="Sx5.SSx3.p6.1.2" class="ltx_text ltx_framed ltx_framed_underline">dog</span>”), and
CLIP being trained on 400M diverse images with atypical objects and other defects.
As expected, we find that for all datasets, VEIL vets VAELs from prepositional phrases better than LocalCLIP-E, and noun modifiers for SBUCaps and RedCaps. LocalCLIP-E does better on “beyond the image” and non-literal VAELs, except on SBUCaps, where VEIL still excels.</p>
</div>
<figure id="Sx5.T4" class="ltx_table">
<table id="Sx5.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx5.T4.1.2.1" class="ltx_tr">
<th id="Sx5.T4.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx5.T4.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.2.1.1.1.1" class="ltx_p" style="width:60.0pt;">Method</span>
</span>
</th>
<th id="Sx5.T4.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx5.T4.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.2.1.2.1.1" class="ltx_p" style="width:52.0pt;">Train Dataset</span>
</span>
</th>
<th id="Sx5.T4.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Prec/Rec</th>
<th id="Sx5.T4.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx5.T4.1.3.1" class="ltx_tr">
<th id="Sx5.T4.1.3.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx5.T4.1.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.3.1.1.1.1" class="ltx_p" style="width:60.0pt;">No Vetting</span>
</span>
</th>
<th id="Sx5.T4.1.3.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx5.T4.1.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.3.1.2.1.1" class="ltx_p" style="width:52.0pt;">-</span>
</span>
</th>
<td id="Sx5.T4.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.463 / 1.000</td>
<td id="Sx5.T4.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.633</td>
</tr>
<tr id="Sx5.T4.1.4.2" class="ltx_tr">
<th id="Sx5.T4.1.4.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx5.T4.1.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.4.2.1.1.1" class="ltx_p" style="width:60.0pt;">VEIL</span>
</span>
</th>
<th id="Sx5.T4.1.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx5.T4.1.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.4.2.2.1.1" class="ltx_p" style="width:52.0pt;">SBUCaps</span>
</span>
</th>
<td id="Sx5.T4.1.4.2.3" class="ltx_td ltx_align_center ltx_border_r">0.828 / 0.791</td>
<td id="Sx5.T4.1.4.2.4" class="ltx_td ltx_align_center">0.809</td>
</tr>
<tr id="Sx5.T4.1.5.3" class="ltx_tr">
<th id="Sx5.T4.1.5.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx5.T4.1.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.5.3.1.1.1" class="ltx_p" style="width:60.0pt;">VEIL</span>
</span>
</th>
<th id="Sx5.T4.1.5.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx5.T4.1.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.5.3.2.1.1" class="ltx_p" style="width:52.0pt;">RedCaps (R)</span>
</span>
</th>
<td id="Sx5.T4.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.668 / 0.759</td>
<td id="Sx5.T4.1.5.3.4" class="ltx_td ltx_align_center ltx_border_t">0.710</td>
</tr>
<tr id="Sx5.T4.1.6.4" class="ltx_tr">
<th id="Sx5.T4.1.6.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx5.T4.1.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.6.4.1.1.1" class="ltx_p" style="width:60.0pt;">VEIL</span>
</span>
</th>
<th id="Sx5.T4.1.6.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx5.T4.1.6.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.6.4.2.1.1" class="ltx_p" style="width:52.0pt;">CC</span>
</span>
</th>
<td id="Sx5.T4.1.6.4.3" class="ltx_td ltx_align_center ltx_border_r">0.585 / 0.846</td>
<td id="Sx5.T4.1.6.4.4" class="ltx_td ltx_align_center">0.692</td>
</tr>
<tr id="Sx5.T4.1.7.5" class="ltx_tr">
<th id="Sx5.T4.1.7.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx5.T4.1.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.7.5.1.1.1" class="ltx_p" style="width:60.0pt;">VEIL</span>
</span>
</th>
<th id="Sx5.T4.1.7.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx5.T4.1.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.7.5.2.1.1" class="ltx_p" style="width:52.0pt;">R, CC</span>
</span>
</th>
<td id="Sx5.T4.1.7.5.3" class="ltx_td ltx_align_center ltx_border_r">0.689 / 0.722</td>
<td id="Sx5.T4.1.7.5.4" class="ltx_td ltx_align_center">0.705</td>
</tr>
<tr id="Sx5.T4.1.1" class="ltx_tr">
<th id="Sx5.T4.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx5.T4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.1.1.1.1" class="ltx_p" style="width:60.0pt;">VEIL<math id="Sx5.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{ST}}" display="inline"><semantics id="Sx5.T4.1.1.1.1.1.m1.1a"><msub id="Sx5.T4.1.1.1.1.1.m1.1.1" xref="Sx5.T4.1.1.1.1.1.m1.1.1.cmml"><mi id="Sx5.T4.1.1.1.1.1.m1.1.1a" xref="Sx5.T4.1.1.1.1.1.m1.1.1.cmml"></mi><mtext id="Sx5.T4.1.1.1.1.1.m1.1.1.1" xref="Sx5.T4.1.1.1.1.1.m1.1.1.1a.cmml">ST</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.T4.1.1.1.1.1.m1.1b"><apply id="Sx5.T4.1.1.1.1.1.m1.1.1.cmml" xref="Sx5.T4.1.1.1.1.1.m1.1.1"><ci id="Sx5.T4.1.1.1.1.1.m1.1.1.1a.cmml" xref="Sx5.T4.1.1.1.1.1.m1.1.1.1"><mtext mathsize="70%" id="Sx5.T4.1.1.1.1.1.m1.1.1.1.cmml" xref="Sx5.T4.1.1.1.1.1.m1.1.1.1">ST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T4.1.1.1.1.1.m1.1c">{}_{\text{ST}}</annotation></semantics></math></span>
</span>
</th>
<th id="Sx5.T4.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx5.T4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.1.2.1.1" class="ltx_p" style="width:52.0pt;">R, CC</span>
</span>
</th>
<td id="Sx5.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_r">0.649 / 0.797</td>
<td id="Sx5.T4.1.1.4" class="ltx_td ltx_align_center">0.716</td>
</tr>
<tr id="Sx5.T4.1.8.6" class="ltx_tr">
<th id="Sx5.T4.1.8.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx5.T4.1.8.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.8.6.1.1.1" class="ltx_p" style="width:60.0pt;">LCLIP-E</span>
</span>
</th>
<th id="Sx5.T4.1.8.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx5.T4.1.8.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.8.6.2.1.1" class="ltx_p" style="width:52.0pt;">WIT</span>
</span>
</th>
<td id="Sx5.T4.1.8.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.708 / 0.820</td>
<td id="Sx5.T4.1.8.6.4" class="ltx_td ltx_align_center ltx_border_t">0.760</td>
</tr>
<tr id="Sx5.T4.1.9.7" class="ltx_tr">
<th id="Sx5.T4.1.9.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_b ltx_border_r">
<span id="Sx5.T4.1.9.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.9.7.1.1.1" class="ltx_p" style="width:60.0pt;">VEIL+LCLIP-E</span>
</span>
</th>
<th id="Sx5.T4.1.9.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_b ltx_border_r">
<span id="Sx5.T4.1.9.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T4.1.9.7.2.1.1" class="ltx_p" style="width:52.0pt;">R,CC,WIT</span>
</span>
</th>
<td id="Sx5.T4.1.9.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.733 / 0.848</td>
<td id="Sx5.T4.1.9.7.4" class="ltx_td ltx_align_center ltx_border_b">0.786</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Source generalization of VEIL; vetting on SBUCaps. LCLIP-E is LocalCLIP-E. CLIP is trained on WIT.</figcaption>
</figure>
<figure id="Sx5.T5" class="ltx_table">
<table id="Sx5.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx5.T5.1.1.1" class="ltx_tr">
<th id="Sx5.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Method</th>
<th id="Sx5.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Prec/Rec</th>
<th id="Sx5.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx5.T5.1.2.1" class="ltx_tr">
<td id="Sx5.T5.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">No Vetting</td>
<td id="Sx5.T5.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.323 / 1.000</td>
<td id="Sx5.T5.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">0.488</td>
</tr>
<tr id="Sx5.T5.1.3.2" class="ltx_tr">
<td id="Sx5.T5.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ID</td>
<td id="Sx5.T5.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.651 / 0.656</td>
<td id="Sx5.T5.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">0.654</td>
</tr>
<tr id="Sx5.T5.1.4.3" class="ltx_tr">
<td id="Sx5.T5.1.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">OOD</td>
<td id="Sx5.T5.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.585 / 0.556</td>
<td id="Sx5.T5.1.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">0.570</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>VEIL category generalization on SBUCaps-ID. </figcaption>
</figure>
<figure id="Sx5.T6" class="ltx_table">
<table id="Sx5.T6.3.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx5.T6.2.2.2" class="ltx_tr">
<th id="Sx5.T6.2.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="Sx5.T6.2.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.2.2.2.3.1.1" class="ltx_p" style="width:124.3pt;"><span id="Sx5.T6.2.2.2.3.1.1.1" class="ltx_text ltx_font_bold">Method</span></span>
</span>
</th>
<th id="Sx5.T6.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="Sx5.T6.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.1.1.1.1.1.1" class="ltx_p" style="width:21.7pt;">VOC Det. <math id="Sx5.T6.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\text{mAP}_{50}" display="inline"><semantics id="Sx5.T6.1.1.1.1.1.1.m1.1a"><msub id="Sx5.T6.1.1.1.1.1.1.m1.1.1" xref="Sx5.T6.1.1.1.1.1.1.m1.1.1.cmml"><mtext id="Sx5.T6.1.1.1.1.1.1.m1.1.1.2" xref="Sx5.T6.1.1.1.1.1.1.m1.1.1.2a.cmml">mAP</mtext><mn id="Sx5.T6.1.1.1.1.1.1.m1.1.1.3" xref="Sx5.T6.1.1.1.1.1.1.m1.1.1.3.cmml">50</mn></msub><annotation-xml encoding="MathML-Content" id="Sx5.T6.1.1.1.1.1.1.m1.1b"><apply id="Sx5.T6.1.1.1.1.1.1.m1.1.1.cmml" xref="Sx5.T6.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx5.T6.1.1.1.1.1.1.m1.1.1.1.cmml" xref="Sx5.T6.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="Sx5.T6.1.1.1.1.1.1.m1.1.1.2a.cmml" xref="Sx5.T6.1.1.1.1.1.1.m1.1.1.2"><mtext id="Sx5.T6.1.1.1.1.1.1.m1.1.1.2.cmml" xref="Sx5.T6.1.1.1.1.1.1.m1.1.1.2">mAP</mtext></ci><cn type="integer" id="Sx5.T6.1.1.1.1.1.1.m1.1.1.3.cmml" xref="Sx5.T6.1.1.1.1.1.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T6.1.1.1.1.1.1.m1.1c">\text{mAP}_{50}</annotation></semantics></math></span>
</span>
</th>
<th id="Sx5.T6.2.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="Sx5.T6.2.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.2.2.2.4.1.1" class="ltx_p" style="width:21.7pt;">VOC Rec. mAP</span>
</span>
</th>
<th id="Sx5.T6.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="Sx5.T6.2.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.2.2.2.2.1.1" class="ltx_p" style="width:21.7pt;">COCO Det <math id="Sx5.T6.2.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\text{mAP}_{50}" display="inline"><semantics id="Sx5.T6.2.2.2.2.1.1.m1.1a"><msub id="Sx5.T6.2.2.2.2.1.1.m1.1.1" xref="Sx5.T6.2.2.2.2.1.1.m1.1.1.cmml"><mtext id="Sx5.T6.2.2.2.2.1.1.m1.1.1.2" xref="Sx5.T6.2.2.2.2.1.1.m1.1.1.2a.cmml">mAP</mtext><mn id="Sx5.T6.2.2.2.2.1.1.m1.1.1.3" xref="Sx5.T6.2.2.2.2.1.1.m1.1.1.3.cmml">50</mn></msub><annotation-xml encoding="MathML-Content" id="Sx5.T6.2.2.2.2.1.1.m1.1b"><apply id="Sx5.T6.2.2.2.2.1.1.m1.1.1.cmml" xref="Sx5.T6.2.2.2.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx5.T6.2.2.2.2.1.1.m1.1.1.1.cmml" xref="Sx5.T6.2.2.2.2.1.1.m1.1.1">subscript</csymbol><ci id="Sx5.T6.2.2.2.2.1.1.m1.1.1.2a.cmml" xref="Sx5.T6.2.2.2.2.1.1.m1.1.1.2"><mtext id="Sx5.T6.2.2.2.2.1.1.m1.1.1.2.cmml" xref="Sx5.T6.2.2.2.2.1.1.m1.1.1.2">mAP</mtext></ci><cn type="integer" id="Sx5.T6.2.2.2.2.1.1.m1.1.1.3.cmml" xref="Sx5.T6.2.2.2.2.1.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T6.2.2.2.2.1.1.m1.1c">\text{mAP}_{50}</annotation></semantics></math></span>
</span>
</th>
</tr>
<tr id="Sx5.T6.3.3.4.1" class="ltx_tr">
<th id="Sx5.T6.3.3.4.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="Sx5.T6.3.3.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.4.1.1.1.1" class="ltx_p" style="width:124.3pt;">GT* (upper bound)</span>
</span>
</th>
<th id="Sx5.T6.3.3.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="Sx5.T6.3.3.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.4.1.2.1.1" class="ltx_p" style="width:21.7pt;">40.0</span>
</span>
</th>
<th id="Sx5.T6.3.3.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="Sx5.T6.3.3.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.4.1.3.1.1" class="ltx_p" style="width:21.7pt;">69.0</span>
</span>
</th>
<th id="Sx5.T6.3.3.4.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="Sx5.T6.3.3.4.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.4.1.4.1.1" class="ltx_p" style="width:21.7pt;">9.2</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx5.T6.3.3.5.1" class="ltx_tr">
<td id="Sx5.T6.3.3.5.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T6.3.3.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.5.1.1.1.1" class="ltx_p" style="width:124.3pt;">No Vetting</span>
</span>
</td>
<td id="Sx5.T6.3.3.5.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T6.3.3.5.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.5.1.2.1.1" class="ltx_p" style="width:21.7pt;">31.2</span>
</span>
</td>
<td id="Sx5.T6.3.3.5.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="Sx5.T6.3.3.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.5.1.3.1.1" class="ltx_p" style="width:21.7pt;">65.3</span>
</span>
</td>
<td id="Sx5.T6.3.3.5.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx5.T6.3.3.5.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.5.1.4.1.1" class="ltx_p" style="width:21.7pt;">7.7</span>
</span>
</td>
</tr>
<tr id="Sx5.T6.3.3.6.2" class="ltx_tr">
<td id="Sx5.T6.3.3.6.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T6.3.3.6.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.6.2.1.1.1" class="ltx_p" style="width:124.3pt;">Large Loss <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite></span>
</span>
</td>
<td id="Sx5.T6.3.3.6.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T6.3.3.6.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.6.2.2.1.1" class="ltx_p" style="width:21.7pt;">30.9</span>
</span>
</td>
<td id="Sx5.T6.3.3.6.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T6.3.3.6.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.6.2.3.1.1" class="ltx_p" style="width:21.7pt;">65.3</span>
</span>
</td>
<td id="Sx5.T6.3.3.6.2.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T6.3.3.6.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.6.2.4.1.1" class="ltx_p" style="width:21.7pt;">7.5</span>
</span>
</td>
</tr>
<tr id="Sx5.T6.3.3.7.3" class="ltx_tr">
<td id="Sx5.T6.3.3.7.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T6.3.3.7.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.7.3.1.1.1" class="ltx_p" style="width:124.3pt;">LocalCLIP-E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="Sx5.T6.3.3.7.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T6.3.3.7.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.7.3.2.1.1" class="ltx_p" style="width:21.7pt;">37.1</span>
</span>
</td>
<td id="Sx5.T6.3.3.7.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T6.3.3.7.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.7.3.3.1.1" class="ltx_p" style="width:21.7pt;">70.7</span>
</span>
</td>
<td id="Sx5.T6.3.3.7.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T6.3.3.7.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.7.3.4.1.1" class="ltx_p" style="width:21.7pt;">7.9</span>
</span>
</td>
</tr>
<tr id="Sx5.T6.3.3.3" class="ltx_tr">
<td id="Sx5.T6.3.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T6.3.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.3.1.1.1" class="ltx_p" style="width:124.3pt;">VEIL<math id="Sx5.T6.3.3.3.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{ST}}" display="inline"><semantics id="Sx5.T6.3.3.3.1.1.1.m1.1a"><msub id="Sx5.T6.3.3.3.1.1.1.m1.1.1" xref="Sx5.T6.3.3.3.1.1.1.m1.1.1.cmml"><mi id="Sx5.T6.3.3.3.1.1.1.m1.1.1a" xref="Sx5.T6.3.3.3.1.1.1.m1.1.1.cmml"></mi><mtext id="Sx5.T6.3.3.3.1.1.1.m1.1.1.1" xref="Sx5.T6.3.3.3.1.1.1.m1.1.1.1a.cmml">ST</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.T6.3.3.3.1.1.1.m1.1b"><apply id="Sx5.T6.3.3.3.1.1.1.m1.1.1.cmml" xref="Sx5.T6.3.3.3.1.1.1.m1.1.1"><ci id="Sx5.T6.3.3.3.1.1.1.m1.1.1.1a.cmml" xref="Sx5.T6.3.3.3.1.1.1.m1.1.1.1"><mtext mathsize="70%" id="Sx5.T6.3.3.3.1.1.1.m1.1.1.1.cmml" xref="Sx5.T6.3.3.3.1.1.1.m1.1.1.1">ST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T6.3.3.3.1.1.1.m1.1c">{}_{\text{ST}}</annotation></semantics></math>-R,CC</span>
</span>
</td>
<td id="Sx5.T6.3.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T6.3.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.3.2.1.1" class="ltx_p" style="width:21.7pt;"><span id="Sx5.T6.3.3.3.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">37.8</span></span>
</span>
</td>
<td id="Sx5.T6.3.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="Sx5.T6.3.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.3.3.1.1" class="ltx_p" style="width:21.7pt;"><span id="Sx5.T6.3.3.3.3.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">71.4</span></span>
</span>
</td>
<td id="Sx5.T6.3.3.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx5.T6.3.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.3.4.1.1" class="ltx_p" style="width:21.7pt;"><span id="Sx5.T6.3.3.3.4.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">8.6</span></span>
</span>
</td>
</tr>
<tr id="Sx5.T6.3.3.8.4" class="ltx_tr">
<td id="Sx5.T6.3.3.8.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T6.3.3.8.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.8.4.1.1.1" class="ltx_p" style="width:124.3pt;">VEIL-SBUCaps</span>
</span>
</td>
<td id="Sx5.T6.3.3.8.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T6.3.3.8.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.8.4.2.1.1" class="ltx_p" style="width:21.7pt;"><span id="Sx5.T6.3.3.8.4.2.1.1.1" class="ltx_text ltx_font_bold">40.5</span></span>
</span>
</td>
<td id="Sx5.T6.3.3.8.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="Sx5.T6.3.3.8.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.8.4.3.1.1" class="ltx_p" style="width:21.7pt;"><span id="Sx5.T6.3.3.8.4.3.1.1.1" class="ltx_text ltx_font_bold">74.3</span></span>
</span>
</td>
<td id="Sx5.T6.3.3.8.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="Sx5.T6.3.3.8.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx5.T6.3.3.8.4.4.1.1" class="ltx_p" style="width:21.7pt;"><span id="Sx5.T6.3.3.8.4.4.1.1.1" class="ltx_text ltx_font_bold">10.4</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Impact of vetting on WSOD performance on VOC-07 and COCO-14.
(GT*) directly vets labels using the pretrained recognition models used to train VEIL. Bold indicates best performance in column excluding GT*.</figcaption>
</figure>
<div id="Sx5.SSx3.p7" class="ltx_para">
<p id="Sx5.SSx3.p7.1" class="ltx_p"><span id="Sx5.SSx3.p7.1.1" class="ltx_text ltx_font_bold">Cross dataset source generalization.</span>
We train VEIL on one dataset (or multiple) and evaluate on an unseen target. We find that combining multiple sources improves precision in Table <a href="#Sx5.T4" title="Table 4 ‣ Extracted Label Vetting Evaluation ‣ Experiments ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. To better utilize caption context, we test VEIL<math id="Sx5.SSx3.p7.1.m1.1" class="ltx_Math" alttext="{}_{\text{ST}}" display="inline"><semantics id="Sx5.SSx3.p7.1.m1.1a"><msub id="Sx5.SSx3.p7.1.m1.1.1" xref="Sx5.SSx3.p7.1.m1.1.1.cmml"><mi id="Sx5.SSx3.p7.1.m1.1.1a" xref="Sx5.SSx3.p7.1.m1.1.1.cmml"></mi><mtext id="Sx5.SSx3.p7.1.m1.1.1.1" xref="Sx5.SSx3.p7.1.m1.1.1.1a.cmml">ST</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.SSx3.p7.1.m1.1b"><apply id="Sx5.SSx3.p7.1.m1.1.1.cmml" xref="Sx5.SSx3.p7.1.m1.1.1"><ci id="Sx5.SSx3.p7.1.m1.1.1.1a.cmml" xref="Sx5.SSx3.p7.1.m1.1.1.1"><mtext mathsize="70%" id="Sx5.SSx3.p7.1.m1.1.1.1.cmml" xref="Sx5.SSx3.p7.1.m1.1.1.1">ST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.SSx3.p7.1.m1.1c">{}_{\text{ST}}</annotation></semantics></math> which predicts visual presence using a special token <span id="Sx5.SSx3.p7.1.2" class="ltx_text ltx_font_typewriter">[EM_LABEL]</span>. We find that this improves F1 performance. Lastly, we try ensembling by averaging predictions between LocalCLIP-E and VEIL-Cross Dataset, and find that its precision and recall is highest among the VEIL variants and LocalCLIP-E. This means that VEIL and LocalCLIP-E can be used together. There is still a significant gap between VEIL-Same Dataset and even the ensembled model in terms of precision and F1. We leave improving source generalizability to future research.</p>
</div>
<div id="Sx5.SSx3.p8" class="ltx_para">
<p id="Sx5.SSx3.p8.1" class="ltx_p"><span id="Sx5.SSx3.p8.1.1" class="ltx_text ltx_font_bold">Cross-category generalization.</span> We define an in-domain category set (ID) of 20 randomly picked categories from COCO <cite class="ltx_cite ltx_citemacro_citep">(Lin et al. <a href="#bib.bib20" title="" class="ltx_ref">2014</a>)</cite>, and an out-of-domain category set (OOD) consisting of the 60 remaining categories. We restrict the labels using these limited category sets and create two train subsets, ID and OOD from SBUCaps <span id="Sx5.SSx3.p8.1.2" class="ltx_text ltx_font_italic">train</span> and one ID test subset from SBUCaps <span id="Sx5.SSx3.p8.1.3" class="ltx_text ltx_font_italic">test</span>. We find that transferring VEIL-OOD to unseen categories improves F1 score compared to no vetting as shown in Table <a href="#Sx5.T5" title="Table 5 ‣ Extracted Label Vetting Evaluation ‣ Experiments ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We hypothesize training on more categories could improve category generalization, but leave further experiments to future research.</p>
</div>
</section>
<section id="Sx5.SSx4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Impact on Weakly Supervised Object Detection</h3>

<div id="Sx5.SSx4.p1" class="ltx_para">
<p id="Sx5.SSx4.p1.1" class="ltx_p">We select the most promising vetting methods from the previous section and use them to vet labels from the SBUCaps <span id="Sx5.SSx4.p1.1.1" class="ltx_text ltx_font_italic">test</span> split since CLIP-based and VEIL-based methods use the train set for threshold and model training respectively.
We show two different VEIL methods, VEIL-SBUCaps and VEIL<math id="Sx5.SSx4.p1.1.m1.1" class="ltx_Math" alttext="{}_{\text{ST}}" display="inline"><semantics id="Sx5.SSx4.p1.1.m1.1a"><msub id="Sx5.SSx4.p1.1.m1.1.1" xref="Sx5.SSx4.p1.1.m1.1.1.cmml"><mi id="Sx5.SSx4.p1.1.m1.1.1a" xref="Sx5.SSx4.p1.1.m1.1.1.cmml"></mi><mtext id="Sx5.SSx4.p1.1.m1.1.1.1" xref="Sx5.SSx4.p1.1.m1.1.1.1a.cmml">ST</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.SSx4.p1.1.m1.1b"><apply id="Sx5.SSx4.p1.1.m1.1.1.cmml" xref="Sx5.SSx4.p1.1.m1.1.1"><ci id="Sx5.SSx4.p1.1.m1.1.1.1a.cmml" xref="Sx5.SSx4.p1.1.m1.1.1.1"><mtext mathsize="70%" id="Sx5.SSx4.p1.1.m1.1.1.1.cmml" xref="Sx5.SSx4.p1.1.m1.1.1.1">ST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.SSx4.p1.1.m1.1c">{}_{\text{ST}}</annotation></semantics></math>-RedCaps,CC. Both vet labels from SBUCaps and use them to train WSOD, but the vetting method is trained on either (1) SBUCaps or (2) RedCaps and CC, using the special token. We show both methods to demonstrate the generalizability of the vetting model.
Note that Large Loss Matters <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite> has been relaxed to also <span id="Sx5.SSx4.p1.1.2" class="ltx_text ltx_font_italic">correct</span> visually absent extracted labels, instead of only unmentioned but present objects (false negatives).
After vetting, we remove any images without labels and since category distribution follows a long-tail distribution, we apply weighted sampling.
We train MIST <cite class="ltx_cite ltx_citemacro_citep">(Ren et al. <a href="#bib.bib28" title="" class="ltx_ref">2020</a>)</cite> for 50K iterations with a batch size of 8 for each method.</p>
</div>
<div id="Sx5.SSx4.p2" class="ltx_para">
<p id="Sx5.SSx4.p2.2" class="ltx_p">We find that VEIL-SBUCaps performs the best as shown in Table <a href="#Sx5.T6" title="Table 6 ‣ Extracted Label Vetting Evaluation ‣ Experiments ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.
In particular, it boosts the detection performance of No Vetting by 9.3% absolute and 29.8% relative gain (40.5/31.2% mAP) on VOC-07 and by 35% relative gain (10.4/7.7% mAP) on COCO.
Interestingly, VEIL-SBUCaps and VEIL<math id="Sx5.SSx4.p2.1.m1.1" class="ltx_Math" alttext="{}_{\text{ST}}" display="inline"><semantics id="Sx5.SSx4.p2.1.m1.1a"><msub id="Sx5.SSx4.p2.1.m1.1.1" xref="Sx5.SSx4.p2.1.m1.1.1.cmml"><mi id="Sx5.SSx4.p2.1.m1.1.1a" xref="Sx5.SSx4.p2.1.m1.1.1.cmml"></mi><mtext id="Sx5.SSx4.p2.1.m1.1.1.1" xref="Sx5.SSx4.p2.1.m1.1.1.1a.cmml">ST</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.SSx4.p2.1.m1.1b"><apply id="Sx5.SSx4.p2.1.m1.1.1.cmml" xref="Sx5.SSx4.p2.1.m1.1.1"><ci id="Sx5.SSx4.p2.1.m1.1.1.1a.cmml" xref="Sx5.SSx4.p2.1.m1.1.1.1"><mtext mathsize="70%" id="Sx5.SSx4.p2.1.m1.1.1.1.cmml" xref="Sx5.SSx4.p2.1.m1.1.1.1">ST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.SSx4.p2.1.m1.1c">{}_{\text{ST}}</annotation></semantics></math>-Redcaps,CC both seem to have a similar performance improvement, despite VEIL<math id="Sx5.SSx4.p2.2.m2.1" class="ltx_Math" alttext="{}_{\text{ST}}" display="inline"><semantics id="Sx5.SSx4.p2.2.m2.1a"><msub id="Sx5.SSx4.p2.2.m2.1.1" xref="Sx5.SSx4.p2.2.m2.1.1.cmml"><mi id="Sx5.SSx4.p2.2.m2.1.1a" xref="Sx5.SSx4.p2.2.m2.1.1.cmml"></mi><mtext id="Sx5.SSx4.p2.2.m2.1.1.1" xref="Sx5.SSx4.p2.2.m2.1.1.1a.cmml">ST</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx5.SSx4.p2.2.m2.1b"><apply id="Sx5.SSx4.p2.2.m2.1.1.cmml" xref="Sx5.SSx4.p2.2.m2.1.1"><ci id="Sx5.SSx4.p2.2.m2.1.1.1a.cmml" xref="Sx5.SSx4.p2.2.m2.1.1.1"><mtext mathsize="70%" id="Sx5.SSx4.p2.2.m2.1.1.1.cmml" xref="Sx5.SSx4.p2.2.m2.1.1.1">ST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.SSx4.p2.2.m2.1c">{}_{\text{ST}}</annotation></semantics></math>-Redcaps,CC (best VEIL cross-dataset result on SBUCaps) having poorer performance than Local CLIP-E in Table <a href="#Sx5.T4" title="Table 4 ‣ Extracted Label Vetting Evaluation ‣ Experiments ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Additionally, directly using the pretrained object recognition model (used to produce visual presence targets for VEIL) predictions to vet (GT* method in the table) performs worse than VEIL in both detection and recognition. This suggests VEIL <span id="Sx5.SSx4.p2.2.1" class="ltx_text ltx_font_bold">generalizes from its bootstrapped data</span>.</p>
</div>
<div id="Sx5.SSx4.p3" class="ltx_para">
<p id="Sx5.SSx4.p3.1" class="ltx_p">Using the CLaN dataset, we observe
one type of structured noise found from extracting labels from prepositional phrases, specifically where images were taken inside vehicles. We hypothesize such structured noise would have significant impact on localization for the vehicle objects. We use CorLoc to estimate the localization ability for vehicles in VOC-07 (“aeroplane”, ‘bicycle”, “boat”, “car”, “bus”, “motorbike”, “train”). We observe a CorLoc of 60.2% and 54.1% for VEIL-SBUCaps and LocalCLIP-E, respectively.
This shows structured noise can have strong impact on localization.
</p>
</div>
<figure id="Sx5.F3" class="ltx_figure"><img src="/html/2303.09608/assets/iccv2023AuthorKit/figures/images/scale_wsod.png" id="Sx5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="210" height="87" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Pascal VOC-07 detection performance of WSOD models trained on RedCaps.</figcaption>
</figure>
<div id="Sx5.SSx4.p4" class="ltx_para">
<p id="Sx5.SSx4.p4.1" class="ltx_p"><span id="Sx5.SSx4.p4.1.1" class="ltx_text ltx_font_bold">Impact of scale on WSOD.</span> To assess the impact of scaling the noisy training set, we progressively sampled the held-out RedCaps dataset in increments of 50K samples up to a total of 200K samples. For each scale, we train two WSOD models with weighted sampling using the unfiltered samples and those vetted with VEIL-SBUCaps,CC. The 200K-sample model trained for 120K iterations, and subsets trained for iterations proportional to their sample size. Figure <a href="#Sx5.F3" title="Figure 3 ‣ Impact on Weakly Supervised Object Detection ‣ Experiments ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows consistent improvement with vetting as the sample size scales. The non-vetted model’s performance declines after 150K samples; more unvetted samples has diminishing or worse, negative returns. This indicates that vetting can adapt to scale better even when VEIL is trained on other datasets. The trend suggests that vetting will continue outperforming no-vetting even when dataset sizes increase.</p>
</div>
<figure id="Sx5.T7" class="ltx_table">
<table id="Sx5.T7.9" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx5.T7.1.1" class="ltx_tr">
<td id="Sx5.T7.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Clean Labels</td>
<td id="Sx5.T7.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Noisy Labels</td>
<td id="Sx5.T7.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">w/ WS</td>
<td id="Sx5.T7.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Vetting</td>
<td id="Sx5.T7.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="Sx5.T7.1.1.1.m1.1" class="ltx_Math" alttext="\text{mAP}_{50}" display="inline"><semantics id="Sx5.T7.1.1.1.m1.1a"><msub id="Sx5.T7.1.1.1.m1.1.1" xref="Sx5.T7.1.1.1.m1.1.1.cmml"><mtext id="Sx5.T7.1.1.1.m1.1.1.2" xref="Sx5.T7.1.1.1.m1.1.1.2a.cmml">mAP</mtext><mn id="Sx5.T7.1.1.1.m1.1.1.3" xref="Sx5.T7.1.1.1.m1.1.1.3.cmml">50</mn></msub><annotation-xml encoding="MathML-Content" id="Sx5.T7.1.1.1.m1.1b"><apply id="Sx5.T7.1.1.1.m1.1.1.cmml" xref="Sx5.T7.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx5.T7.1.1.1.m1.1.1.1.cmml" xref="Sx5.T7.1.1.1.m1.1.1">subscript</csymbol><ci id="Sx5.T7.1.1.1.m1.1.1.2a.cmml" xref="Sx5.T7.1.1.1.m1.1.1.2"><mtext id="Sx5.T7.1.1.1.m1.1.1.2.cmml" xref="Sx5.T7.1.1.1.m1.1.1.2">mAP</mtext></ci><cn type="integer" id="Sx5.T7.1.1.1.m1.1.1.3.cmml" xref="Sx5.T7.1.1.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T7.1.1.1.m1.1c">\text{mAP}_{50}</annotation></semantics></math></td>
</tr>
<tr id="Sx5.T7.9.10.1" class="ltx_tr">
<td id="Sx5.T7.9.10.1.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx5.T7.9.10.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx5.T7.9.10.1.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx5.T7.9.10.1.4" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx5.T7.9.10.1.5" class="ltx_td ltx_align_center ltx_border_t">16.67</td>
</tr>
<tr id="Sx5.T7.9.11.2" class="ltx_tr">
<td id="Sx5.T7.9.11.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx5.T7.9.11.2.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx5.T7.9.11.2.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx5.T7.9.11.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">n/a</td>
<td id="Sx5.T7.9.11.2.5" class="ltx_td ltx_align_center ltx_border_t">43.48</td>
</tr>
<tr id="Sx5.T7.2.2" class="ltx_tr">
<td id="Sx5.T7.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="Sx5.T7.2.2.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="Sx5.T7.2.2.1.m1.1a"><mi mathvariant="normal" id="Sx5.T7.2.2.1.m1.1.1" xref="Sx5.T7.2.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="Sx5.T7.2.2.1.m1.1b"><ci id="Sx5.T7.2.2.1.m1.1.1.cmml" xref="Sx5.T7.2.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T7.2.2.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="Sx5.T7.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx5.T7.2.2.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx5.T7.2.2.4" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx5.T7.2.2.5" class="ltx_td ltx_align_center ltx_border_t">42.06</td>
</tr>
<tr id="Sx5.T7.5.5" class="ltx_tr">
<td id="Sx5.T7.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="Sx5.T7.3.3.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="Sx5.T7.3.3.1.m1.1a"><mi mathvariant="normal" id="Sx5.T7.3.3.1.m1.1.1" xref="Sx5.T7.3.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="Sx5.T7.3.3.1.m1.1b"><ci id="Sx5.T7.3.3.1.m1.1.1.cmml" xref="Sx5.T7.3.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T7.3.3.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="Sx5.T7.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="Sx5.T7.4.4.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="Sx5.T7.4.4.2.m1.1a"><mi mathvariant="normal" id="Sx5.T7.4.4.2.m1.1.1" xref="Sx5.T7.4.4.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="Sx5.T7.4.4.2.m1.1b"><ci id="Sx5.T7.4.4.2.m1.1.1.cmml" xref="Sx5.T7.4.4.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T7.4.4.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="Sx5.T7.5.5.4" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx5.T7.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="Sx5.T7.5.5.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="Sx5.T7.5.5.3.m1.1a"><mi mathvariant="normal" id="Sx5.T7.5.5.3.m1.1.1" xref="Sx5.T7.5.5.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="Sx5.T7.5.5.3.m1.1b"><ci id="Sx5.T7.5.5.3.m1.1.1.cmml" xref="Sx5.T7.5.5.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T7.5.5.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="Sx5.T7.5.5.5" class="ltx_td ltx_align_center ltx_border_t">51.31</td>
</tr>
<tr id="Sx5.T7.9.9" class="ltx_tr">
<td id="Sx5.T7.6.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="Sx5.T7.6.6.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="Sx5.T7.6.6.1.m1.1a"><mi mathvariant="normal" id="Sx5.T7.6.6.1.m1.1.1" xref="Sx5.T7.6.6.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="Sx5.T7.6.6.1.m1.1b"><ci id="Sx5.T7.6.6.1.m1.1.1.cmml" xref="Sx5.T7.6.6.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T7.6.6.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="Sx5.T7.7.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="Sx5.T7.7.7.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="Sx5.T7.7.7.2.m1.1a"><mi mathvariant="normal" id="Sx5.T7.7.7.2.m1.1.1" xref="Sx5.T7.7.7.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="Sx5.T7.7.7.2.m1.1b"><ci id="Sx5.T7.7.7.2.m1.1.1.cmml" xref="Sx5.T7.7.7.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T7.7.7.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="Sx5.T7.8.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="Sx5.T7.8.8.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="Sx5.T7.8.8.3.m1.1a"><mi mathvariant="normal" id="Sx5.T7.8.8.3.m1.1.1" xref="Sx5.T7.8.8.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="Sx5.T7.8.8.3.m1.1b"><ci id="Sx5.T7.8.8.3.m1.1.1.cmml" xref="Sx5.T7.8.8.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T7.8.8.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="Sx5.T7.9.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="Sx5.T7.9.9.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="Sx5.T7.9.9.4.m1.1a"><mi mathvariant="normal" id="Sx5.T7.9.9.4.m1.1.1" xref="Sx5.T7.9.9.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="Sx5.T7.9.9.4.m1.1b"><ci id="Sx5.T7.9.9.4.m1.1.1.cmml" xref="Sx5.T7.9.9.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx5.T7.9.9.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="Sx5.T7.9.9.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">54.76</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Mixed supervision from clean (VOC-07 trainval) and noisy labels (SBUCaps).
Evaluated on VOC-07 test. WS stands for weighted sampling.</figcaption>
</figure>
<div id="Sx5.SSx4.p5" class="ltx_para">
<p id="Sx5.SSx4.p5.1" class="ltx_p"><span id="Sx5.SSx4.p5.1.1" class="ltx_text ltx_font_bold">Effect of mixing clean and noisy samples for WSOD.</span> We study how vetting impacts a setting where labels are drawn from both annotated image-level labels from 5K VOC-07 train-val <cite class="ltx_cite ltx_citemacro_citep">(Everingham et al. <a href="#bib.bib7" title="" class="ltx_ref">2010</a>)</cite> (clean) and 50K in-the-wild SBUCaps <cite class="ltx_cite ltx_citemacro_citep">(Ordonez, Kulkarni, and Berg <a href="#bib.bib23" title="" class="ltx_ref">2011</a>)</cite> captions (noisy). In Table <a href="#Sx5.T7" title="Table 7 ‣ Impact on Weakly Supervised Object Detection ‣ Experiments ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> we observe that adding noisy supervision to clean supervision actually hurts performance compared to only using clean supervision. After vetting the labels extracted from SBUCaps <cite class="ltx_cite ltx_citemacro_citep">(Ordonez, Kulkarni, and Berg <a href="#bib.bib23" title="" class="ltx_ref">2011</a>)</cite> using VEIL-SBUCaps, we observe that the model sees a 17.9% relative improvement (51.31/43.48% mAP) to using only clean supervision from VOC-07. We see further improvements when applying weighted sampling to the added, class imbalanced data (54.76/51.31% mAP).</p>
</div>
<div id="Sx5.SSx4.p6" class="ltx_para">
<p id="Sx5.SSx4.p6.1" class="ltx_p"><span id="Sx5.SSx4.p6.1.1" class="ltx_text ltx_font_bold">Conclusion.</span> We showed visually absent extracted labels are common in in-the-wild datasets.
We proposed VEIL which uses language context to infer whether mentioned objects are visually present. It outperforms other vetting strategies, generalizes across datasets and categories, and its benefits persist when adding noisy to clean data.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bilen and Vedaldi (2016)</span>
<span class="ltx_bibblock">
Bilen, H.; and Vedaldi, A. 2016.

</span>
<span class="ltx_bibblock">Weakly supervised deep detection networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em>, 2846–2854.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Changpinyo et al. (2021)</span>
<span class="ltx_bibblock">
Changpinyo, S.; Sharma, P. K.; Ding, N.; and Soricut, R. 2021.

</span>
<span class="ltx_bibblock">Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To
Recognize Long-Tail Visual Concepts.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 3557–3567.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. (2009)</span>
<span class="ltx_bibblock">
Deng, J.; Dong, W.; Socher, R.; Li, L.-J.; Li, K.; and Fei-Fei, L. 2009.

</span>
<span class="ltx_bibblock">ImageNet: A large-scale hierarchical image database.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Desai et al. (2021)</span>
<span class="ltx_bibblock">
Desai, K.; Kaul, G.; Aysola, Z.; and Johnson, J. 2021.

</span>
<span class="ltx_bibblock">RedCaps: Web-curated image-text data created by the people, for the
people.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">NeurIPS Datasets and Benchmarks</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Devlin, J.; Chang, M.; Lee, K.; and Toutanova, K. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language
Understanding.

</span>
<span class="ltx_bibblock">In Burstein, J.; Doran, C.; and Solorio, T., eds., <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2019 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, NAACL-HLT 2019,
Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>,
4171–4186. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2022)</span>
<span class="ltx_bibblock">
Du, Y.; Wei, F.; Zhang, Z.; Shi, M.; Gao, Y.; and Li, G. C. 2022.

</span>
<span class="ltx_bibblock">Learning to Prompt for Open-Vocabulary Object Detection with
Vision-Language Model.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">2022 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 14064–14073.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Everingham et al. (2010)</span>
<span class="ltx_bibblock">
Everingham, M.; Gool, L. V.; Williams, C. K. I.; Winn, J. M.; and Zisserman, A.
2010.

</span>
<span class="ltx_bibblock">The Pascal Visual Object Classes (VOC) Challenge.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 88: 303–338.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al. (2022)</span>
<span class="ltx_bibblock">
Fang, A.; Ilharco, G.; Wortsman, M.; Wan, Y.; Shankar, V.; Dave, A.; and
Schmidt, L. 2022.

</span>
<span class="ltx_bibblock">Data Determines Distributional Robustness in Contrastive Language
Image Pre-training (CLIP).

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2022)</span>
<span class="ltx_bibblock">
Gao, M.; Xing, C.; Niebles, J. C.; Li, J.; Xu, R.; Liu, W.; and Xiong, C. 2022.

</span>
<span class="ltx_bibblock">Open Vocabulary Object Detection with Pseudo Bounding-Box Labels.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2019)</span>
<span class="ltx_bibblock">
Gao, Y.; Liu, B.; Guo, N.; Ye, X.; Wan, F.; You, H.; and Fan, D. 2019.

</span>
<span class="ltx_bibblock">C-MIDN: Coupled Multiple Instance Detection Network With Segmentation
Guidance for Weakly Supervised Object Detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision (ICCV)</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2022)</span>
<span class="ltx_bibblock">
Gu, X.; Lin, T.-Y.; Kuo, W.; and Cui, Y. 2022.

</span>
<span class="ltx_bibblock">Open-vocabulary Object Detection via Vision and Language Knowledge
Distillation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hessel et al. (2021)</span>
<span class="ltx_bibblock">
Hessel, J.; Holtzman, A.; Forbes, M.; Bras, R. J. L.; and Choi, Y. 2021.

</span>
<span class="ltx_bibblock">CLIPScore: A Reference-free Evaluation Metric for Image Captioning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2016)</span>
<span class="ltx_bibblock">
Huang, T.-H. K.; Ferraro, F.; Mostafazadeh, N.; Misra, I.; Devlin, J.; Agrawal,
A.; Girshick, R.; He, X.; Kohli, P.; Batra, D.; et al. 2016.

</span>
<span class="ltx_bibblock">Visual Storytelling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">15th Annual Conference of the North American Chapter of the
Association for Computational Linguistics (NAACL 2016)</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al. (2021)</span>
<span class="ltx_bibblock">
Jia, C.; Yang, Y.; Xia, Y.; Chen, Y.-T.; Parekh, Z.; Pham, H.; Le, Q. V.; Sung,
Y.-H.; Li, Z.; and Duerig, T. 2021.

</span>
<span class="ltx_bibblock">Scaling Up Visual and Vision-Language Representation Learning With
Noisy Text Supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jocher et al. (2021)</span>
<span class="ltx_bibblock">
Jocher, G.; Stoken, A.; Borovec, J.; NanoCode012; Ayush Chaurasia;
TaoXie; Changyu, L.; Abhiram V; Laughing; Tkianai; YxNONG; Hogan,
A.; Lorenzomammana; AlexWang1900; Hajek, J.; Diaconu, L.; , Marc;
Yonghye Kwon; , Oleg; Wanghaoyang0106; Defretin, Y.; Lohia, A.;
Ml5ah; Milanko, B.; Fineran, B.; Khromov, D.; Yiwei, D.; , Doug;
Durgesh; and Ingham, F. 2021.

</span>
<span class="ltx_bibblock">ultralytics/yolov5: v5.0 - YOLOv5-P6 1280 models, AWS, Supervise.ly
and YouTube integrations.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2022)</span>
<span class="ltx_bibblock">
Kim, Y.; Kim, J. M.; Akata, Z.; and Lee, J. 2022.

</span>
<span class="ltx_bibblock">Large Loss Matters in Weakly Supervised Multi-Label Classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">2022 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 14136–14145.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishna et al. (2016)</span>
<span class="ltx_bibblock">
Krishna, R.; Zhu, Y.; Groth, O.; Johnson, J.; Hata, K.; Kravitz, J.; Chen, S.;
Kalantidis, Y.; Li, L.-J.; Shamma, D. A.; Bernstein, M. S.; and Fei-Fei, L.
2016.

</span>
<span class="ltx_bibblock">Visual Genome: Connecting Language and Vision Using Crowdsourced
Dense Image Annotations.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 123: 32–73.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuznetsova et al. (2018)</span>
<span class="ltx_bibblock">
Kuznetsova, A.; Rom, H.; Alldrin, N. G.; Uijlings, J. R. R.; Krasin, I.;
Pont-Tuset, J.; Kamali, S.; Popov, S.; Malloci, M.; Duerig, T.; and Ferrari,
V. 2018.

</span>
<span class="ltx_bibblock">Dataset V 4 Unified image classification , object detection , and
visual relationship detection at scale.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2021)</span>
<span class="ltx_bibblock">
Li, J.; Selvaraju, R. R.; Gotmare, A. D.; Joty, S. R.; Xiong, C.; and Hoi, S.
C. H. 2021.

</span>
<span class="ltx_bibblock">Align before Fuse: Vision and Language Representation Learning with
Momentum Distillation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Neural Information Processing Systems</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2014)</span>
<span class="ltx_bibblock">
Lin, T.-Y.; Maire, M.; Belongie, S. J.; Hays, J.; Perona, P.; Ramanan, D.;
Dollár, P.; and Zitnick, C. L. 2014.

</span>
<span class="ltx_bibblock">Microsoft COCO: Common Objects in Context.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ECCV</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mahajan et al. (2018)</span>
<span class="ltx_bibblock">
Mahajan, D. K.; Girshick, R. B.; Ramanathan, V.; He, K.; Paluri, M.; Li, Y.;
Bharambe, A.; and van der Maaten, L. 2018.

</span>
<span class="ltx_bibblock">Exploring the Limits of Weakly Supervised Pretraining.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ECCV</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mikolov et al. (2013)</span>
<span class="ltx_bibblock">
Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J. 2013.

</span>
<span class="ltx_bibblock">Distributed Representations of Words and Phrases and their
Compositionality.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">NIPS</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ordonez, Kulkarni, and Berg (2011)</span>
<span class="ltx_bibblock">
Ordonez, V.; Kulkarni, G.; and Berg, T. L. 2011.

</span>
<span class="ltx_bibblock">Im2Text: Describing Images Using 1 Million Captioned Photographs.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">NIPS</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke et al. (2019)</span>
<span class="ltx_bibblock">
Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.; Chanan, G.; Killeen,
T.; Lin, Z.; Gimelshein, N.; Antiga, L.; Desmaison, A.; Kopf, A.; Yang, E.;
DeVito, Z.; Raison, M.; Tejani, A.; Chilamkurthy, S.; Steiner, B.; Fang, L.;
Bai, J.; and Chintala, S. 2019.

</span>
<span class="ltx_bibblock">PyTorch: An Imperative Style, High-Performance Deep Learning Library.

</span>
<span class="ltx_bibblock">In Wallach, H.; Larochelle, H.; Beygelzimer, A.; d'Alché-Buc, F.; Fox, E.; and Garnett, R., eds., <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems 32</em>, 8024–8035.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry,
G.; Askell, A.; Mishkin, P.; Clark, J.; Krueger, G.; and Sutskever, I. 2021.

</span>
<span class="ltx_bibblock">Learning Transferable Visual Models From Natural Language
Supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rahman, Khan, and Barnes (2020)</span>
<span class="ltx_bibblock">
Rahman, S.; Khan, S. H.; and Barnes, N. 2020.

</span>
<span class="ltx_bibblock">Improved Visual-Semantic Alignment for Zero-Shot Object Detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">AAAI Conference on Artificial Intelligence</em>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rahman, Khan, and
Porikli (2020)</span>
<span class="ltx_bibblock">
Rahman, S.; Khan, S. H.; and Porikli, F. M. 2020.

</span>
<span class="ltx_bibblock">Zero-Shot Object Detection: Joint Recognition and Localization of
Novel Concepts.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 128: 2979 – 2999.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al. (2020)</span>
<span class="ltx_bibblock">
Ren, Z.; Yu, Z.; Yang, X.; Liu, M.-Y.; Lee, Y. J.; Schwing, A. G.; and Kautz,
J. 2020.

</span>
<span class="ltx_bibblock">Instance-Aware, Context-Focused, and Memory-Efficient Weakly
Supervised Object Detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR)</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schuhmann et al. (2021)</span>
<span class="ltx_bibblock">
Schuhmann, C.; Vencu, R.; Beaumont, R.; Kaczmarczyk, R.; Mullis, C.; Katta, A.;
Coombes, T.; Jitsev, J.; and Komatsuzaki, A. 2021.

</span>
<span class="ltx_bibblock">LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text
Pairs.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Data Centric AI NeurIPS Workshop 2021</em>, abs/2111.02114.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao et al. (2019)</span>
<span class="ltx_bibblock">
Shao, S.; Li, Z.; Zhang, T.; Peng, C.; Yu, G.; Zhang, X.; Li, J.; and Sun, J.
2019.

</span>
<span class="ltx_bibblock">Objects365: A Large-Scale, High-Quality Dataset for Object Detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF International Conference on Computer Vision
(ICCV)</em>, 8429–8438.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et al. (2018)</span>
<span class="ltx_bibblock">
Sharma, P.; Ding, N.; Goodman, S.; and Soricut, R. 2018.

</span>
<span class="ltx_bibblock">Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset
For Automatic Image Captioning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">ACL</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2022)</span>
<span class="ltx_bibblock">
Shi, H.; Hayat, M.; Wu, Y.; and Cai, J. 2022.

</span>
<span class="ltx_bibblock">ProposalCLIP: Unsupervised Open-Category Object Proposal Generation
via Exploiting CLIP Cues.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">2022 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 9601–9610.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et al. (2020)</span>
<span class="ltx_bibblock">
Singh, K. K.; Mahajan, D.; Grauman, K.; Lee, Y. J.; Feiszli, M.; and
Ghadiyaram, D. 2020.

</span>
<span class="ltx_bibblock">Don’t Judge an Object by Its Context: Learning to Overcome
Contextual Bias.

</span>
<span class="ltx_bibblock">11070–11078.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2017a)</span>
<span class="ltx_bibblock">
Tang, P.; Wang, X.; Bai, X.; and Liu, W. 2017a.

</span>
<span class="ltx_bibblock">Multiple instance detection network with online instance classifier
refinement.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2017b)</span>
<span class="ltx_bibblock">
Tang, P.; Wang, X.; Bai, X.; and Liu, W. 2017b.

</span>
<span class="ltx_bibblock">Multiple Instance Detection Network with Online Instance Classifier
Refinement.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">2017 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</em>, 3059–3067.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Unal et al. (2022)</span>
<span class="ltx_bibblock">
Unal, M. E.; Ye, K.; Zhang, M.; Thomas, C.; Kovashka, A.; Li, W.; Qin, D.; and
Berent, J. 2022.

</span>
<span class="ltx_bibblock">Learning to Overcome Noise in Weak Caption Supervision for Object
Detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, PP.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. (2019)</span>
<span class="ltx_bibblock">
Wan, F.; Liu, C.; Ke, W.; Ji, X.; Jiao, J.; and Ye, Q. 2019.

</span>
<span class="ltx_bibblock">C-mil: Continuation multiple instance learning for weakly supervised
object detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2016)</span>
<span class="ltx_bibblock">
Wu, Y.; Schuster, M.; Chen, Z.; Le, Q. V.; Norouzi, M.; Macherey, W.; Krikun,
M.; Cao, Y.; Gao, Q.; Macherey, K.; et al. 2016.

</span>
<span class="ltx_bibblock">Google’s neural machine translation system: Bridging the gap between
human and machine translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1609.08144</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2019a)</span>
<span class="ltx_bibblock">
Ye, K.; Zhang, M.; Kovashka, A.; Li, W.; Qin, D.; and Berent, J.
2019a.

</span>
<span class="ltx_bibblock">Cap2Det: Learning to Amplify Weak Caption Supervision for Object
Detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">International Conference on Computer Vision (ICCV)</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2019b)</span>
<span class="ltx_bibblock">
Ye, K.; Zhang, M.; Kovashka, A.; Li, W.; Qin, D.; and Berent, J.
2019b.

</span>
<span class="ltx_bibblock">Cap2Det: Learning to Amplify Weak Caption Supervision for Object
Detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF International Conference on Computer Vision
(ICCV)</em>, 9685–9694.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Young et al. (2014)</span>
<span class="ltx_bibblock">
Young, P.; Lai, A.; Hodosh, M.; and Hockenmaier, J. 2014.

</span>
<span class="ltx_bibblock">From image descriptions to visual denotations: New similarity metrics
for semantic inference over event descriptions.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
2: 67–78.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zareian et al. (2021)</span>
<span class="ltx_bibblock">
Zareian, A.; Rosa, K. D.; Hu, D. H.; and Chang, S.-F. 2021.

</span>
<span class="ltx_bibblock">Open-vocabulary object detection using captions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, 14393–14402.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2017)</span>
<span class="ltx_bibblock">
Zhang, C.; Bengio, S.; Hardt, M.; Recht, B.; and Vinyals, O. 2017.

</span>
<span class="ltx_bibblock">Understanding deep learning requires rethinking generalization.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2021)</span>
<span class="ltx_bibblock">
Zhang, P.; Li, X.; Hu, X.; Yang, J.; Zhang, L.; Wang, L.; Choi, Y.; and Gao, J.
2021.

</span>
<span class="ltx_bibblock">VinVL: Making Visual Representations Matter in Vision-Language
Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">CVPR 2021</em>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2022)</span>
<span class="ltx_bibblock">
Zhong, Y.; Yang, J.; Zhang, P.; Li, C.; Codella, N.; Li, L. H.; Zhou, L.; Dai,
X.; Yuan, L.; Li, Y.; and Gao, J. 2022.

</span>
<span class="ltx_bibblock">RegionCLIP: Region-based Language-Image Pretraining.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF Conference on Computer Vision and Pattern
Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022</em>,
16772–16782. IEEE.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2022)</span>
<span class="ltx_bibblock">
Zhou, X.; Girdhar, R.; Joulin, A.; Krahenbuhl, P.; and Misra, I. 2022.

</span>
<span class="ltx_bibblock">Detecting Twenty-Thousand Classes Using Image-Level Supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>.

</span>
</li>
</ul>
</section>
<section id="Sx6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Supplementary Materials</h2>

<div id="Sx6.p1" class="ltx_para">
<p id="Sx6.p1.1" class="ltx_p">We provide supplemental materials to our main text.</p>
</div>
<div id="Sx6.p2" class="ltx_para">
<p id="Sx6.p2.1" class="ltx_p">We present a detailed table of the vetting precision and recall of all methods described in the main text, for which we show F1 performance in Table 2 of the main text. Furthermore, we show more comprehensive cross-dataset ablations, such as adding more training datasets and training with a special token.</p>
</div>
<div id="Sx6.p3" class="ltx_para">
<p id="Sx6.p3.1" class="ltx_p">We discuss our hyperparameter selection for WSOD in further detail and show additional metrics of the WSOD models on the COCO-14 benchmark presented in the main text.</p>
</div>
<div id="Sx6.p4" class="ltx_para">
<p id="Sx6.p4.1" class="ltx_p">Finally, we showcase the vetting ability of VEIL in comparison to other approaches through qualitative results, along with additional examples from the WSOD models trained using vetted training data.</p>
</div>
</section>
<section id="Sx7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Vetting Precision/Recall</h2>

<div id="Sx7.p1" class="ltx_para">
<p id="Sx7.p1.1" class="ltx_p">Table 2 in the main text showed the F1 on the extracted label vetting task, from twelve methods. In Table <a href="#Sx7.T8" title="Table 8 ‣ Vetting Precision/Recall ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> here, we separately show Precision and Recall on the same task.</p>
</div>
<figure id="Sx7.T8" class="ltx_table">
<table id="Sx7.T8.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx7.T8.1.1.1" class="ltx_tr">
<th id="Sx7.T8.1.1.1.1" class="ltx_td ltx_align_middle ltx_th ltx_th_row ltx_border_t"></th>
<th id="Sx7.T8.1.1.1.2" class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_t"></th>
<td id="Sx7.T8.1.1.1.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_t" colspan="2"><span id="Sx7.T8.1.1.1.3.1" class="ltx_text ltx_font_bold">SBUCaps</span></td>
<td id="Sx7.T8.1.1.1.4" class="ltx_td ltx_align_center ltx_border_l ltx_border_t" colspan="2"><span id="Sx7.T8.1.1.1.4.1" class="ltx_text ltx_font_bold">RedCaps</span></td>
<td id="Sx7.T8.1.1.1.5" class="ltx_td ltx_align_center ltx_border_l ltx_border_t" colspan="2"><span id="Sx7.T8.1.1.1.5.1" class="ltx_text ltx_font_bold">Conceptual Captions</span></td>
</tr>
<tr id="Sx7.T8.1.2.2" class="ltx_tr">
<th id="Sx7.T8.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.2.2.1.1.1" class="ltx_p"><span id="Sx7.T8.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Modalities</span></span>
</span>
</th>
<th id="Sx7.T8.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.2.2.2.1.1" class="ltx_p" style="width:101.2pt;"><span id="Sx7.T8.1.2.2.2.1.1.1" class="ltx_text ltx_font_bold">Method</span></span>
</span>
</th>
<td id="Sx7.T8.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.2.2.3.1" class="ltx_text ltx_font_bold">PREC / REC</span></td>
<td id="Sx7.T8.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.2.2.4.1" class="ltx_text ltx_font_bold">F1</span></td>
<td id="Sx7.T8.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.2.2.5.1" class="ltx_text ltx_font_bold">PREC / REC</span></td>
<td id="Sx7.T8.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.2.2.6.1" class="ltx_text ltx_font_bold">F1</span></td>
<td id="Sx7.T8.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.2.2.7.1" class="ltx_text ltx_font_bold">PREC / REC</span></td>
<td id="Sx7.T8.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx7.T8.1.2.2.8.1" class="ltx_text ltx_font_bold">F1</span></td>
</tr>
<tr id="Sx7.T8.1.3.3" class="ltx_tr">
<th id="Sx7.T8.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.3.3.2.1.1" class="ltx_p" style="width:101.2pt;">No Vetting</span>
</span>
</th>
<td id="Sx7.T8.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.463 / 1.000</td>
<td id="Sx7.T8.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.633</td>
<td id="Sx7.T8.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.596 / 1.000</td>
<td id="Sx7.T8.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.747</td>
<td id="Sx7.T8.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.737 / 1.000</td>
<td id="Sx7.T8.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx7.T8.1.3.3.8.1" class="ltx_text ltx_framed ltx_framed_underline">0.849</span></td>
</tr>
<tr id="Sx7.T8.1.4.4" class="ltx_tr">
<th id="Sx7.T8.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r ltx_border_t" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.4.4.2.1.1" class="ltx_p" style="width:101.2pt;">Global CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.531 / 0.700</td>
<td id="Sx7.T8.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.604</td>
<td id="Sx7.T8.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.618 / 0.551</td>
<td id="Sx7.T8.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.583</td>
<td id="Sx7.T8.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.753 / 0.458</td>
<td id="Sx7.T8.1.4.4.8" class="ltx_td ltx_align_center ltx_border_t">0.569</td>
</tr>
<tr id="Sx7.T8.1.5.5" class="ltx_tr">
<th id="Sx7.T8.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.5.5.1.1.1" class="ltx_p">Image, Language</span>
</span>
</th>
<th id="Sx7.T8.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.5.5.2.1.1" class="ltx_p" style="width:101.2pt;">Global CLIP - E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">0.526 / 0.683</td>
<td id="Sx7.T8.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">0.594</td>
<td id="Sx7.T8.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r">0.625 / 0.522</td>
<td id="Sx7.T8.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r">0.569</td>
<td id="Sx7.T8.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r">0.745 / 0.417</td>
<td id="Sx7.T8.1.5.5.8" class="ltx_td ltx_align_center">0.534</td>
</tr>
<tr id="Sx7.T8.1.6.6" class="ltx_tr">
<th id="Sx7.T8.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r ltx_border_t" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.6.6.2.1.1" class="ltx_p" style="width:101.2pt;">Local CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.588 / 0.246</td>
<td id="Sx7.T8.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.347</td>
<td id="Sx7.T8.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.723 / 0.591</td>
<td id="Sx7.T8.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.651</td>
<td id="Sx7.T8.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.750 / 0.240</td>
<td id="Sx7.T8.1.6.6.8" class="ltx_td ltx_align_center ltx_border_t">0.363</td>
</tr>
<tr id="Sx7.T8.1.7.7" class="ltx_tr">
<th id="Sx7.T8.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.7.7.2.1.1" class="ltx_p" style="width:101.2pt;">Local CLIP - E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.7.7.3.1" class="ltx_text ltx_framed ltx_framed_underline">0.708</span> / 0.820</td>
<td id="Sx7.T8.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="Sx7.T8.1.7.7.4.1" class="ltx_text ltx_framed ltx_framed_underline">0.760</span></td>
<td id="Sx7.T8.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.7.7.5.1" class="ltx_text ltx_framed ltx_framed_underline">0.770</span> / 0.924</td>
<td id="Sx7.T8.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r"><span id="Sx7.T8.1.7.7.6.1" class="ltx_text ltx_framed ltx_framed_underline">0.840</span></td>
<td id="Sx7.T8.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.7.7.7.1" class="ltx_text ltx_framed ltx_framed_underline">0.842</span> / 0.462</td>
<td id="Sx7.T8.1.7.7.8" class="ltx_td ltx_align_center">0.597</td>
</tr>
<tr id="Sx7.T8.1.8.8" class="ltx_tr">
<th id="Sx7.T8.1.8.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.8.8.1.1.1" class="ltx_p">Image</span>
</span>
</th>
<th id="Sx7.T8.1.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.8.8.2.1.1" class="ltx_p" style="width:101.2pt;">Reject Large Loss <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r">0.530 / <span id="Sx7.T8.1.8.8.3.1" class="ltx_text ltx_font_bold">0.898</span>
</td>
<td id="Sx7.T8.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">0.667</td>
<td id="Sx7.T8.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r">0.700 / 0.908</td>
<td id="Sx7.T8.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r">0.790</td>
<td id="Sx7.T8.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r">0.806 / 0.858</td>
<td id="Sx7.T8.1.8.8.8" class="ltx_td ltx_align_center">0.831</td>
</tr>
<tr id="Sx7.T8.1.9.9" class="ltx_tr">
<th id="Sx7.T8.1.9.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r ltx_border_t" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.9.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.9.9.2.1.1" class="ltx_p" style="width:101.2pt;">Accept Descriptive</span>
</span>
</th>
<td id="Sx7.T8.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.449 / 0.542</td>
<td id="Sx7.T8.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.491</td>
<td id="Sx7.T8.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.561 / 0.326</td>
<td id="Sx7.T8.1.9.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.413</td>
<td id="Sx7.T8.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.739 / 0.741</td>
<td id="Sx7.T8.1.9.9.8" class="ltx_td ltx_align_center ltx_border_t">0.740</td>
</tr>
<tr id="Sx7.T8.1.10.10" class="ltx_tr">
<th id="Sx7.T8.1.10.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.10.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.10.10.2.1.1" class="ltx_p" style="width:101.2pt;">Accept Narrative</span>
</span>
</th>
<td id="Sx7.T8.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r">0.482 / 0.458</td>
<td id="Sx7.T8.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">0.470</td>
<td id="Sx7.T8.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r">0.619 / 0.674</td>
<td id="Sx7.T8.1.10.10.6" class="ltx_td ltx_align_center ltx_border_r">0.645</td>
<td id="Sx7.T8.1.10.10.7" class="ltx_td ltx_align_center ltx_border_r">0.738 / 0.259</td>
<td id="Sx7.T8.1.10.10.8" class="ltx_td ltx_align_center">0.383</td>
</tr>
<tr id="Sx7.T8.1.11.11" class="ltx_tr">
<th id="Sx7.T8.1.11.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.11.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.11.11.2.1.1" class="ltx_p" style="width:101.2pt;">Reject Noun Mod. (Adj)</span>
</span>
</th>
<td id="Sx7.T8.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r">0.517 / 0.769</td>
<td id="Sx7.T8.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r">0.618</td>
<td id="Sx7.T8.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r">0.644 / 0.776</td>
<td id="Sx7.T8.1.11.11.6" class="ltx_td ltx_align_center ltx_border_r">0.703</td>
<td id="Sx7.T8.1.11.11.7" class="ltx_td ltx_align_center ltx_border_r">0.765 / 0.870</td>
<td id="Sx7.T8.1.11.11.8" class="ltx_td ltx_align_center">0.814</td>
</tr>
<tr id="Sx7.T8.1.12.12" class="ltx_tr">
<th id="Sx7.T8.1.12.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.12.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.12.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.12.12.2.1.1" class="ltx_p" style="width:101.2pt;">Reject Noun Mod. (Any)</span>
</span>
</th>
<td id="Sx7.T8.1.12.12.3" class="ltx_td ltx_align_center ltx_border_r">0.520 / 0.754</td>
<td id="Sx7.T8.1.12.12.4" class="ltx_td ltx_align_center ltx_border_r">0.616</td>
<td id="Sx7.T8.1.12.12.5" class="ltx_td ltx_align_center ltx_border_r">0.647 / 0.736</td>
<td id="Sx7.T8.1.12.12.6" class="ltx_td ltx_align_center ltx_border_r">0.689</td>
<td id="Sx7.T8.1.12.12.7" class="ltx_td ltx_align_center ltx_border_r">0.767 / 0.863</td>
<td id="Sx7.T8.1.12.12.8" class="ltx_td ltx_align_center">0.812</td>
</tr>
<tr id="Sx7.T8.1.13.13" class="ltx_tr">
<th id="Sx7.T8.1.13.13.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.13.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.13.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.13.13.2.1.1" class="ltx_p" style="width:101.2pt;">Cap2Det <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib39" title="" class="ltx_ref">2019a</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.13.13.3" class="ltx_td ltx_align_center ltx_border_r">0.500 / <span id="Sx7.T8.1.13.13.3.1" class="ltx_text ltx_framed ltx_framed_underline">0.884</span>
</td>
<td id="Sx7.T8.1.13.13.4" class="ltx_td ltx_align_center ltx_border_r">0.639</td>
<td id="Sx7.T8.1.13.13.5" class="ltx_td ltx_align_center ltx_border_r">0.633 / <span id="Sx7.T8.1.13.13.5.1" class="ltx_text ltx_font_bold">0.945</span>
</td>
<td id="Sx7.T8.1.13.13.6" class="ltx_td ltx_align_center ltx_border_r">0.758</td>
<td id="Sx7.T8.1.13.13.7" class="ltx_td ltx_align_center ltx_border_r">0.758 / <span id="Sx7.T8.1.13.13.7.1" class="ltx_text ltx_font_bold">0.956</span>
</td>
<td id="Sx7.T8.1.13.13.8" class="ltx_td ltx_align_center">0.846</td>
</tr>
<tr id="Sx7.T8.1.14.14" class="ltx_tr">
<th id="Sx7.T8.1.14.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.14.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.14.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.14.14.2.1.1" class="ltx_p" style="width:101.2pt;">VEIL-Same Dataset</span>
</span>
</th>
<td id="Sx7.T8.1.14.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.14.14.3.1" class="ltx_text ltx_font_bold">0.828</span> / 0.791</td>
<td id="Sx7.T8.1.14.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.14.14.4.1" class="ltx_text ltx_font_bold">0.809</span></td>
<td id="Sx7.T8.1.14.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.14.14.5.1" class="ltx_text ltx_font_bold">0.855</span> / <span id="Sx7.T8.1.14.14.5.2" class="ltx_text ltx_framed ltx_framed_underline">0.929</span>
</td>
<td id="Sx7.T8.1.14.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.14.14.6.1" class="ltx_text ltx_font_bold">0.890</span></td>
<td id="Sx7.T8.1.14.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.14.14.7.1" class="ltx_text ltx_font_bold">0.884</span> / <span id="Sx7.T8.1.14.14.7.2" class="ltx_text ltx_framed ltx_framed_underline">0.935</span>
</td>
<td id="Sx7.T8.1.14.14.8" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx7.T8.1.14.14.8.1" class="ltx_text ltx_font_bold">0.909</span></td>
</tr>
<tr id="Sx7.T8.1.15.15" class="ltx_tr">
<th id="Sx7.T8.1.15.15.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.15.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.15.15.1.1.1" class="ltx_p">Language</span>
</span>
</th>
<th id="Sx7.T8.1.15.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.15.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.15.15.2.1.1" class="ltx_p" style="width:101.2pt;">VEIL-Cross Dataset</span>
</span>
</th>
<td id="Sx7.T8.1.15.15.3" class="ltx_td ltx_align_center ltx_border_r">0.636 / 0.811</td>
<td id="Sx7.T8.1.15.15.4" class="ltx_td ltx_align_center ltx_border_r">0.713</td>
<td id="Sx7.T8.1.15.15.5" class="ltx_td ltx_align_center ltx_border_r">0.747 / 0.847</td>
<td id="Sx7.T8.1.15.15.6" class="ltx_td ltx_align_center ltx_border_r">0.793</td>
<td id="Sx7.T8.1.15.15.7" class="ltx_td ltx_align_center ltx_border_r">0.834 / 0.866</td>
<td id="Sx7.T8.1.15.15.8" class="ltx_td ltx_align_center"><span id="Sx7.T8.1.15.15.8.1" class="ltx_text ltx_framed ltx_framed_underline">0.850</span></td>
</tr>
<tr id="Sx7.T8.1.16.16" class="ltx_tr">
<th id="Sx7.T8.1.16.16.1" class="ltx_td ltx_align_middle ltx_th ltx_th_row ltx_border_tt"></th>
<th id="Sx7.T8.1.16.16.2" class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_tt"></th>
<td id="Sx7.T8.1.16.16.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_tt" colspan="2"><span id="Sx7.T8.1.16.16.3.1" class="ltx_text ltx_font_bold">VIST</span></td>
<td id="Sx7.T8.1.16.16.4" class="ltx_td ltx_align_center ltx_border_l ltx_border_tt" colspan="2"><span id="Sx7.T8.1.16.16.4.1" class="ltx_text ltx_font_bold">VIST-DII</span></td>
<td id="Sx7.T8.1.16.16.5" class="ltx_td ltx_align_center ltx_border_l ltx_border_tt" colspan="2"><span id="Sx7.T8.1.16.16.5.1" class="ltx_text ltx_font_bold">VIST-SIS</span></td>
</tr>
<tr id="Sx7.T8.1.17.17" class="ltx_tr">
<th id="Sx7.T8.1.17.17.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.17.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.17.17.1.1.1" class="ltx_p"><span id="Sx7.T8.1.17.17.1.1.1.1" class="ltx_text ltx_font_bold">Modalities</span></span>
</span>
</th>
<th id="Sx7.T8.1.17.17.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.17.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.17.17.2.1.1" class="ltx_p" style="width:101.2pt;"><span id="Sx7.T8.1.17.17.2.1.1.1" class="ltx_text ltx_font_bold">Method</span></span>
</span>
</th>
<td id="Sx7.T8.1.17.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.17.17.3.1" class="ltx_text ltx_font_bold">PREC / REC</span></td>
<td id="Sx7.T8.1.17.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.17.17.4.1" class="ltx_text ltx_font_bold">F1</span></td>
<td id="Sx7.T8.1.17.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.17.17.5.1" class="ltx_text ltx_font_bold">PREC / REC</span></td>
<td id="Sx7.T8.1.17.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.17.17.6.1" class="ltx_text ltx_font_bold">F1</span></td>
<td id="Sx7.T8.1.17.17.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.17.17.7.1" class="ltx_text ltx_font_bold">PREC / REC</span></td>
<td id="Sx7.T8.1.17.17.8" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx7.T8.1.17.17.8.1" class="ltx_text ltx_font_bold">F1</span></td>
</tr>
<tr id="Sx7.T8.1.18.18" class="ltx_tr">
<th id="Sx7.T8.1.18.18.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.18.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.18.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.18.18.2.1.1" class="ltx_p" style="width:101.2pt;">No Vetting</span>
</span>
</th>
<td id="Sx7.T8.1.18.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.744 / 1.000</td>
<td id="Sx7.T8.1.18.18.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.853</td>
<td id="Sx7.T8.1.18.18.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.779 / 1.000</td>
<td id="Sx7.T8.1.18.18.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.876</td>
<td id="Sx7.T8.1.18.18.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.695 / 1.000</td>
<td id="Sx7.T8.1.18.18.8" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx7.T8.1.18.18.8.1" class="ltx_text ltx_framed ltx_framed_underline">0.820</span></td>
</tr>
<tr id="Sx7.T8.1.19.19" class="ltx_tr">
<th id="Sx7.T8.1.19.19.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r ltx_border_t" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.19.19.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.19.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.19.19.2.1.1" class="ltx_p" style="width:101.2pt;">Global CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.19.19.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.772 / 0.589</td>
<td id="Sx7.T8.1.19.19.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.668</td>
<td id="Sx7.T8.1.19.19.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.788 / 0.518</td>
<td id="Sx7.T8.1.19.19.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.625</td>
<td id="Sx7.T8.1.19.19.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.754 / 0.624</td>
<td id="Sx7.T8.1.19.19.8" class="ltx_td ltx_align_center ltx_border_t">0.683</td>
</tr>
<tr id="Sx7.T8.1.20.20" class="ltx_tr">
<th id="Sx7.T8.1.20.20.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.20.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.20.20.1.1.1" class="ltx_p">Image, Language</span>
</span>
</th>
<th id="Sx7.T8.1.20.20.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.20.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.20.20.2.1.1" class="ltx_p" style="width:101.2pt;">Global CLIP - E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.20.20.3" class="ltx_td ltx_align_center ltx_border_r">0.769 / 0.569</td>
<td id="Sx7.T8.1.20.20.4" class="ltx_td ltx_align_center ltx_border_r">0.654</td>
<td id="Sx7.T8.1.20.20.5" class="ltx_td ltx_align_center ltx_border_r">0.785 / 0.504</td>
<td id="Sx7.T8.1.20.20.6" class="ltx_td ltx_align_center ltx_border_r">0.613</td>
<td id="Sx7.T8.1.20.20.7" class="ltx_td ltx_align_center ltx_border_r">0.741 / 0.595</td>
<td id="Sx7.T8.1.20.20.8" class="ltx_td ltx_align_center">0.660</td>
</tr>
<tr id="Sx7.T8.1.21.21" class="ltx_tr">
<th id="Sx7.T8.1.21.21.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r ltx_border_t" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.21.21.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.21.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.21.21.2.1.1" class="ltx_p" style="width:101.2pt;">Local CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.21.21.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.752 / 0.298</td>
<td id="Sx7.T8.1.21.21.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.427</td>
<td id="Sx7.T8.1.21.21.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.787 / 0.341</td>
<td id="Sx7.T8.1.21.21.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.476</td>
<td id="Sx7.T8.1.21.21.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.738 / 0.292</td>
<td id="Sx7.T8.1.21.21.8" class="ltx_td ltx_align_center ltx_border_t">0.418</td>
</tr>
<tr id="Sx7.T8.1.22.22" class="ltx_tr">
<th id="Sx7.T8.1.22.22.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.22.22.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.22.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.22.22.2.1.1" class="ltx_p" style="width:101.2pt;">Local CLIP - E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.22.22.3" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.22.22.3.1" class="ltx_text ltx_font_bold">0.874</span> / 0.671</td>
<td id="Sx7.T8.1.22.22.4" class="ltx_td ltx_align_center ltx_border_r">0.759</td>
<td id="Sx7.T8.1.22.22.5" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.22.22.5.1" class="ltx_text ltx_font_bold">0.886</span> / 0.572</td>
<td id="Sx7.T8.1.22.22.6" class="ltx_td ltx_align_center ltx_border_r">0.695</td>
<td id="Sx7.T8.1.22.22.7" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.22.22.7.1" class="ltx_text ltx_font_bold">0.833 </span>/ 0.793</td>
<td id="Sx7.T8.1.22.22.8" class="ltx_td ltx_align_center">0.812</td>
</tr>
<tr id="Sx7.T8.1.23.23" class="ltx_tr">
<th id="Sx7.T8.1.23.23.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.23.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.23.23.1.1.1" class="ltx_p">Image</span>
</span>
</th>
<th id="Sx7.T8.1.23.23.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.23.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.23.23.2.1.1" class="ltx_p" style="width:101.2pt;">Reject Large Loss <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.23.23.3" class="ltx_td ltx_align_center ltx_border_r">0.755 / 0.811</td>
<td id="Sx7.T8.1.23.23.4" class="ltx_td ltx_align_center ltx_border_r">0.782</td>
<td id="Sx7.T8.1.23.23.5" class="ltx_td ltx_align_center ltx_border_r">0.792 / 0.796</td>
<td id="Sx7.T8.1.23.23.6" class="ltx_td ltx_align_center ltx_border_r">0.794</td>
<td id="Sx7.T8.1.23.23.7" class="ltx_td ltx_align_center ltx_border_r">0.700 / 0.791</td>
<td id="Sx7.T8.1.23.23.8" class="ltx_td ltx_align_center">0.743</td>
</tr>
<tr id="Sx7.T8.1.24.24" class="ltx_tr">
<th id="Sx7.T8.1.24.24.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r ltx_border_t" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.24.24.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.24.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.24.24.2.1.1" class="ltx_p" style="width:101.2pt;">Accept Descriptive</span>
</span>
</th>
<td id="Sx7.T8.1.24.24.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.755 / 0.631</td>
<td id="Sx7.T8.1.24.24.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.687</td>
<td id="Sx7.T8.1.24.24.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.784 / 0.913</td>
<td id="Sx7.T8.1.24.24.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.24.24.6.1" class="ltx_text ltx_framed ltx_framed_underline">0.844</span></td>
<td id="Sx7.T8.1.24.24.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.686 / 0.163</td>
<td id="Sx7.T8.1.24.24.8" class="ltx_td ltx_align_center ltx_border_t">0.264</td>
</tr>
<tr id="Sx7.T8.1.25.25" class="ltx_tr">
<th id="Sx7.T8.1.25.25.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.25.25.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.25.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.25.25.2.1.1" class="ltx_p" style="width:101.2pt;">Accept Narrative</span>
</span>
</th>
<td id="Sx7.T8.1.25.25.3" class="ltx_td ltx_align_center ltx_border_r">0.717 / 0.369</td>
<td id="Sx7.T8.1.25.25.4" class="ltx_td ltx_align_center ltx_border_r">0.487</td>
<td id="Sx7.T8.1.25.25.5" class="ltx_td ltx_align_center ltx_border_r">0.697 / 0.087</td>
<td id="Sx7.T8.1.25.25.6" class="ltx_td ltx_align_center ltx_border_r">0.154</td>
<td id="Sx7.T8.1.25.25.7" class="ltx_td ltx_align_center ltx_border_r">0.691 / 0.837</td>
<td id="Sx7.T8.1.25.25.8" class="ltx_td ltx_align_center">0.757</td>
</tr>
<tr id="Sx7.T8.1.26.26" class="ltx_tr">
<th id="Sx7.T8.1.26.26.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.26.26.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.26.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.26.26.2.1.1" class="ltx_p" style="width:101.2pt;">Reject Noun Mod. (Adj)</span>
</span>
</th>
<td id="Sx7.T8.1.26.26.3" class="ltx_td ltx_align_center ltx_border_r">0.775 / 0.879</td>
<td id="Sx7.T8.1.26.26.4" class="ltx_td ltx_align_center ltx_border_r">0.823</td>
<td id="Sx7.T8.1.26.26.5" class="ltx_td ltx_align_center ltx_border_r">0.813 / 0.883</td>
<td id="Sx7.T8.1.26.26.6" class="ltx_td ltx_align_center ltx_border_r">0.847</td>
<td id="Sx7.T8.1.26.26.7" class="ltx_td ltx_align_center ltx_border_r">0.716 / 0.875</td>
<td id="Sx7.T8.1.26.26.8" class="ltx_td ltx_align_center">0.788</td>
</tr>
<tr id="Sx7.T8.1.27.27" class="ltx_tr">
<th id="Sx7.T8.1.27.27.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.27.27.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.27.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.27.27.2.1.1" class="ltx_p" style="width:101.2pt;">Reject Noun Mod. (Any)</span>
</span>
</th>
<td id="Sx7.T8.1.27.27.3" class="ltx_td ltx_align_center ltx_border_r">0.776 / 0.871</td>
<td id="Sx7.T8.1.27.27.4" class="ltx_td ltx_align_center ltx_border_r">0.821</td>
<td id="Sx7.T8.1.27.27.5" class="ltx_td ltx_align_center ltx_border_r">0.813 / 0.873</td>
<td id="Sx7.T8.1.27.27.6" class="ltx_td ltx_align_center ltx_border_r">0.842</td>
<td id="Sx7.T8.1.27.27.7" class="ltx_td ltx_align_center ltx_border_r">0.718 / 0.859</td>
<td id="Sx7.T8.1.27.27.8" class="ltx_td ltx_align_center">0.782</td>
</tr>
<tr id="Sx7.T8.1.28.28" class="ltx_tr">
<th id="Sx7.T8.1.28.28.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.28.28.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.28.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.28.28.2.1.1" class="ltx_p" style="width:101.2pt;">Cap2Det <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib39" title="" class="ltx_ref">2019a</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.28.28.3" class="ltx_td ltx_align_center ltx_border_r">0.781 / 0.877</td>
<td id="Sx7.T8.1.28.28.4" class="ltx_td ltx_align_center ltx_border_r">0.826</td>
<td id="Sx7.T8.1.28.28.5" class="ltx_td ltx_align_center ltx_border_r">0.823 / 0.887</td>
<td id="Sx7.T8.1.28.28.6" class="ltx_td ltx_align_center ltx_border_r">0.854</td>
<td id="Sx7.T8.1.28.28.7" class="ltx_td ltx_align_center ltx_border_r">0.704 / 0.859</td>
<td id="Sx7.T8.1.28.28.8" class="ltx_td ltx_align_center">0.774</td>
</tr>
<tr id="Sx7.T8.1.29.29" class="ltx_tr">
<th id="Sx7.T8.1.29.29.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.29.29.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.29.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.29.29.2.1.1" class="ltx_p" style="width:101.2pt;">VEIL-Same Dataset</span>
</span>
</th>
<td id="Sx7.T8.1.29.29.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.789 / <span id="Sx7.T8.1.29.29.3.1" class="ltx_text ltx_font_bold">0.971</span>
</td>
<td id="Sx7.T8.1.29.29.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.29.29.4.1" class="ltx_text ltx_framed ltx_framed_underline">0.871</span></td>
<td id="Sx7.T8.1.29.29.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.819 / <span id="Sx7.T8.1.29.29.5.1" class="ltx_text ltx_font_bold">0.992</span>
</td>
<td id="Sx7.T8.1.29.29.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.29.29.6.1" class="ltx_text ltx_font_bold">0.892</span></td>
<td id="Sx7.T8.1.29.29.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.690 / <span id="Sx7.T8.1.29.29.7.1" class="ltx_text ltx_font_bold">0.998</span>
</td>
<td id="Sx7.T8.1.29.29.8" class="ltx_td ltx_align_center ltx_border_t">0.816</td>
</tr>
<tr id="Sx7.T8.1.30.30" class="ltx_tr">
<th id="Sx7.T8.1.30.30.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.30.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.30.30.1.1.1" class="ltx_p">Language</span>
</span>
</th>
<th id="Sx7.T8.1.30.30.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.30.30.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.30.30.2.1.1" class="ltx_p" style="width:101.2pt;">VEIL-Cross Dataset</span>
</span>
</th>
<td id="Sx7.T8.1.30.30.3" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.30.30.3.1" class="ltx_text ltx_framed ltx_framed_underline">0.835 </span>/ <span id="Sx7.T8.1.30.30.3.2" class="ltx_text ltx_framed ltx_framed_underline">0.920</span>
</td>
<td id="Sx7.T8.1.30.30.4" class="ltx_td ltx_align_center ltx_border_r"><span id="Sx7.T8.1.30.30.4.1" class="ltx_text ltx_font_bold">0.875</span></td>
<td id="Sx7.T8.1.30.30.5" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.30.30.5.1" class="ltx_text ltx_framed ltx_framed_underline">0.870</span> / <span id="Sx7.T8.1.30.30.5.2" class="ltx_text ltx_framed ltx_framed_underline">0.915</span>
</td>
<td id="Sx7.T8.1.30.30.6" class="ltx_td ltx_align_center ltx_border_r"><span id="Sx7.T8.1.30.30.6.1" class="ltx_text ltx_font_bold">0.892</span></td>
<td id="Sx7.T8.1.30.30.7" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.30.30.7.1" class="ltx_text ltx_framed ltx_framed_underline">0.765 </span>/<span id="Sx7.T8.1.30.30.7.2" class="ltx_text ltx_framed ltx_framed_underline"> 0.920</span>
</td>
<td id="Sx7.T8.1.30.30.8" class="ltx_td ltx_align_center"><span id="Sx7.T8.1.30.30.8.1" class="ltx_text ltx_font_bold">0.830</span></td>
</tr>
<tr id="Sx7.T8.1.31.31" class="ltx_tr">
<th id="Sx7.T8.1.31.31.1" class="ltx_td ltx_align_middle ltx_th ltx_th_row ltx_border_tt"></th>
<th id="Sx7.T8.1.31.31.2" class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"></th>
<td id="Sx7.T8.1.31.31.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2"><span id="Sx7.T8.1.31.31.3.1" class="ltx_text ltx_font_bold">COCO</span></td>
<td id="Sx7.T8.1.31.31.4" class="ltx_td ltx_border_tt" colspan="4"></td>
</tr>
<tr id="Sx7.T8.1.32.32" class="ltx_tr">
<th id="Sx7.T8.1.32.32.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.32.32.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.32.32.1.1.1" class="ltx_p"><span id="Sx7.T8.1.32.32.1.1.1.1" class="ltx_text ltx_font_bold">Modalities</span></span>
</span>
</th>
<th id="Sx7.T8.1.32.32.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.32.32.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.32.32.2.1.1" class="ltx_p" style="width:101.2pt;"><span id="Sx7.T8.1.32.32.2.1.1.1" class="ltx_text ltx_font_bold">Method</span></span>
</span>
</th>
<td id="Sx7.T8.1.32.32.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.32.32.3.1" class="ltx_text ltx_font_bold">PREC / REC</span></td>
<td id="Sx7.T8.1.32.32.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.32.32.4.1" class="ltx_text ltx_font_bold">F1</span></td>
<td id="Sx7.T8.1.32.32.5" class="ltx_td"></td>
<td id="Sx7.T8.1.32.32.6" class="ltx_td"></td>
<td id="Sx7.T8.1.32.32.7" class="ltx_td"></td>
<td id="Sx7.T8.1.32.32.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.33.33" class="ltx_tr">
<th id="Sx7.T8.1.33.33.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.33.33.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.33.33.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.33.33.2.1.1" class="ltx_p" style="width:101.2pt;">No Vetting</span>
</span>
</th>
<td id="Sx7.T8.1.33.33.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.948 / 1.000</td>
<td id="Sx7.T8.1.33.33.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.33.33.4.1" class="ltx_text ltx_font_bold">0.973</span></td>
<td id="Sx7.T8.1.33.33.5" class="ltx_td"></td>
<td id="Sx7.T8.1.33.33.6" class="ltx_td"></td>
<td id="Sx7.T8.1.33.33.7" class="ltx_td"></td>
<td id="Sx7.T8.1.33.33.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.34.34" class="ltx_tr">
<th id="Sx7.T8.1.34.34.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r ltx_border_t" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.34.34.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.34.34.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.34.34.2.1.1" class="ltx_p" style="width:101.2pt;">Global CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.34.34.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.945 / 0.509</td>
<td id="Sx7.T8.1.34.34.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.662</td>
<td id="Sx7.T8.1.34.34.5" class="ltx_td"></td>
<td id="Sx7.T8.1.34.34.6" class="ltx_td"></td>
<td id="Sx7.T8.1.34.34.7" class="ltx_td"></td>
<td id="Sx7.T8.1.34.34.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.35.35" class="ltx_tr">
<th id="Sx7.T8.1.35.35.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.35.35.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.35.35.1.1.1" class="ltx_p">Image, Language</span>
</span>
</th>
<th id="Sx7.T8.1.35.35.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.35.35.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.35.35.2.1.1" class="ltx_p" style="width:101.2pt;">Global CLIP - E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.35.35.3" class="ltx_td ltx_align_center ltx_border_r">0.931 / 0.487</td>
<td id="Sx7.T8.1.35.35.4" class="ltx_td ltx_align_center ltx_border_r">0.640</td>
<td id="Sx7.T8.1.35.35.5" class="ltx_td"></td>
<td id="Sx7.T8.1.35.35.6" class="ltx_td"></td>
<td id="Sx7.T8.1.35.35.7" class="ltx_td"></td>
<td id="Sx7.T8.1.35.35.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.36.36" class="ltx_tr">
<th id="Sx7.T8.1.36.36.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r ltx_border_t" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.36.36.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.36.36.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.36.36.2.1.1" class="ltx_p" style="width:101.2pt;">Local CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.36.36.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.951 / 0.307</td>
<td id="Sx7.T8.1.36.36.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.464</td>
<td id="Sx7.T8.1.36.36.5" class="ltx_td"></td>
<td id="Sx7.T8.1.36.36.6" class="ltx_td"></td>
<td id="Sx7.T8.1.36.36.7" class="ltx_td"></td>
<td id="Sx7.T8.1.36.36.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.37.37" class="ltx_tr">
<th id="Sx7.T8.1.37.37.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.37.37.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.37.37.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.37.37.2.1.1" class="ltx_p" style="width:101.2pt;">Local CLIP - E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.37.37.3" class="ltx_td ltx_align_center ltx_border_r">0.972 / 0.663</td>
<td id="Sx7.T8.1.37.37.4" class="ltx_td ltx_align_center ltx_border_r">0.788</td>
<td id="Sx7.T8.1.37.37.5" class="ltx_td"></td>
<td id="Sx7.T8.1.37.37.6" class="ltx_td"></td>
<td id="Sx7.T8.1.37.37.7" class="ltx_td"></td>
<td id="Sx7.T8.1.37.37.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.38.38" class="ltx_tr">
<th id="Sx7.T8.1.38.38.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.38.38.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.38.38.1.1.1" class="ltx_p">Image</span>
</span>
</th>
<th id="Sx7.T8.1.38.38.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.38.38.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.38.38.2.1.1" class="ltx_p" style="width:101.2pt;">Reject Large Loss <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.38.38.3" class="ltx_td ltx_align_center ltx_border_r">0.963 / 0.837</td>
<td id="Sx7.T8.1.38.38.4" class="ltx_td ltx_align_center ltx_border_r">0.896</td>
<td id="Sx7.T8.1.38.38.5" class="ltx_td"></td>
<td id="Sx7.T8.1.38.38.6" class="ltx_td"></td>
<td id="Sx7.T8.1.38.38.7" class="ltx_td"></td>
<td id="Sx7.T8.1.38.38.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.39.39" class="ltx_tr">
<th id="Sx7.T8.1.39.39.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r ltx_border_t" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.39.39.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.39.39.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.39.39.2.1.1" class="ltx_p" style="width:101.2pt;">Accept Descriptive</span>
</span>
</th>
<td id="Sx7.T8.1.39.39.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.948 / 0.923</td>
<td id="Sx7.T8.1.39.39.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.935</td>
<td id="Sx7.T8.1.39.39.5" class="ltx_td"></td>
<td id="Sx7.T8.1.39.39.6" class="ltx_td"></td>
<td id="Sx7.T8.1.39.39.7" class="ltx_td"></td>
<td id="Sx7.T8.1.39.39.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.40.40" class="ltx_tr">
<th id="Sx7.T8.1.40.40.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.40.40.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.40.40.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.40.40.2.1.1" class="ltx_p" style="width:101.2pt;">Accept Narrative</span>
</span>
</th>
<td id="Sx7.T8.1.40.40.3" class="ltx_td ltx_align_center ltx_border_r">0.942 / 0.077</td>
<td id="Sx7.T8.1.40.40.4" class="ltx_td ltx_align_center ltx_border_r">0.143</td>
<td id="Sx7.T8.1.40.40.5" class="ltx_td"></td>
<td id="Sx7.T8.1.40.40.6" class="ltx_td"></td>
<td id="Sx7.T8.1.40.40.7" class="ltx_td"></td>
<td id="Sx7.T8.1.40.40.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.41.41" class="ltx_tr">
<th id="Sx7.T8.1.41.41.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.41.41.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.41.41.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.41.41.2.1.1" class="ltx_p" style="width:101.2pt;">Reject Noun Mod. (Adj)</span>
</span>
</th>
<td id="Sx7.T8.1.41.41.3" class="ltx_td ltx_align_center ltx_border_r">0.958 / 0.859</td>
<td id="Sx7.T8.1.41.41.4" class="ltx_td ltx_align_center ltx_border_r">0.906</td>
<td id="Sx7.T8.1.41.41.5" class="ltx_td"></td>
<td id="Sx7.T8.1.41.41.6" class="ltx_td"></td>
<td id="Sx7.T8.1.41.41.7" class="ltx_td"></td>
<td id="Sx7.T8.1.41.41.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.42.42" class="ltx_tr">
<th id="Sx7.T8.1.42.42.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.42.42.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.42.42.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.42.42.2.1.1" class="ltx_p" style="width:101.2pt;">Reject Noun Mod. (Any)</span>
</span>
</th>
<td id="Sx7.T8.1.42.42.3" class="ltx_td ltx_align_center ltx_border_r">0.959 / 0.849</td>
<td id="Sx7.T8.1.42.42.4" class="ltx_td ltx_align_center ltx_border_r">0.900</td>
<td id="Sx7.T8.1.42.42.5" class="ltx_td"></td>
<td id="Sx7.T8.1.42.42.6" class="ltx_td"></td>
<td id="Sx7.T8.1.42.42.7" class="ltx_td"></td>
<td id="Sx7.T8.1.42.42.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.43.43" class="ltx_tr">
<th id="Sx7.T8.1.43.43.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.43.43.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="Sx7.T8.1.43.43.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.43.43.2.1.1" class="ltx_p" style="width:101.2pt;">Cap2Det <cite class="ltx_cite ltx_citemacro_citep">(Ye et al. <a href="#bib.bib39" title="" class="ltx_ref">2019a</a>)</cite></span>
</span>
</th>
<td id="Sx7.T8.1.43.43.3" class="ltx_td ltx_align_center ltx_border_r">
<span id="Sx7.T8.1.43.43.3.1" class="ltx_text ltx_font_bold">0.978</span> / <span id="Sx7.T8.1.43.43.3.2" class="ltx_text ltx_framed ltx_framed_underline">0.950</span>
</td>
<td id="Sx7.T8.1.43.43.4" class="ltx_td ltx_align_center ltx_border_r"><span id="Sx7.T8.1.43.43.4.1" class="ltx_text ltx_framed ltx_framed_underline">0.964</span></td>
<td id="Sx7.T8.1.43.43.5" class="ltx_td"></td>
<td id="Sx7.T8.1.43.43.6" class="ltx_td"></td>
<td id="Sx7.T8.1.43.43.7" class="ltx_td"></td>
<td id="Sx7.T8.1.43.43.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.44.44" class="ltx_tr">
<th id="Sx7.T8.1.44.44.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_r" style="width:54.2pt;"></th>
<th id="Sx7.T8.1.44.44.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="Sx7.T8.1.44.44.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.44.44.2.1.1" class="ltx_p" style="width:101.2pt;">VEIL-Same Dataset</span>
</span>
</th>
<td id="Sx7.T8.1.44.44.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.948 / <span id="Sx7.T8.1.44.44.3.1" class="ltx_text ltx_font_bold">1.000</span>
</td>
<td id="Sx7.T8.1.44.44.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx7.T8.1.44.44.4.1" class="ltx_text ltx_font_bold">0.973</span></td>
<td id="Sx7.T8.1.44.44.5" class="ltx_td"></td>
<td id="Sx7.T8.1.44.44.6" class="ltx_td"></td>
<td id="Sx7.T8.1.44.44.7" class="ltx_td"></td>
<td id="Sx7.T8.1.44.44.8" class="ltx_td"></td>
</tr>
<tr id="Sx7.T8.1.45.45" class="ltx_tr">
<th id="Sx7.T8.1.45.45.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_row ltx_border_b ltx_border_r" style="width:54.2pt;">
<span id="Sx7.T8.1.45.45.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.45.45.1.1.1" class="ltx_p">Language</span>
</span>
</th>
<th id="Sx7.T8.1.45.45.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_b ltx_border_r">
<span id="Sx7.T8.1.45.45.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx7.T8.1.45.45.2.1.1" class="ltx_p" style="width:101.2pt;">VEIL-Cross Dataset</span>
</span>
</th>
<td id="Sx7.T8.1.45.45.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span id="Sx7.T8.1.45.45.3.1" class="ltx_text ltx_framed ltx_framed_underline">0.975</span> / 0.942</td>
<td id="Sx7.T8.1.45.45.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.958</td>
<td id="Sx7.T8.1.45.45.5" class="ltx_td"></td>
<td id="Sx7.T8.1.45.45.6" class="ltx_td"></td>
<td id="Sx7.T8.1.45.45.7" class="ltx_td"></td>
<td id="Sx7.T8.1.45.45.8" class="ltx_td"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Extracted Label Vetting Evaluation Metrics. Bold indicates best result in column, and in the recall columns No Vetting is excluded as it always has perfect recall.</figcaption>
</figure>
</section>
<section id="Sx8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Cross-Dataset Ablations</h2>

<figure id="Sx8.T9" class="ltx_table">
<table id="Sx8.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx8.T9.1.1.1" class="ltx_tr">
<td id="Sx8.T9.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T9.1.1.1.1.1" class="ltx_text ltx_font_bold">Train Dataset(s)</span></td>
<td id="Sx8.T9.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ST</td>
<td id="Sx8.T9.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T9.1.1.1.3.1" class="ltx_text ltx_font_bold">DII-VIST</span></td>
<td id="Sx8.T9.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T9.1.1.1.4.1" class="ltx_text ltx_font_bold">SIS-VIST</span></td>
<td id="Sx8.T9.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T9.1.1.1.5.1" class="ltx_text ltx_font_bold">COCO</span></td>
<td id="Sx8.T9.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T9.1.1.1.6.1" class="ltx_text ltx_font_bold">VIST</span></td>
<td id="Sx8.T9.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T9.1.1.1.7.1" class="ltx_text ltx_font_bold">SBUCaps</span></td>
<td id="Sx8.T9.1.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T9.1.1.1.8.1" class="ltx_text ltx_font_bold">RedCaps</span></td>
<td id="Sx8.T9.1.1.1.9" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx8.T9.1.1.1.9.1" class="ltx_text ltx_font_bold">CC</span></td>
</tr>
<tr id="Sx8.T9.1.2.2" class="ltx_tr">
<td id="Sx8.T9.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">No Vetting</td>
<td id="Sx8.T9.1.2.2.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.779 / 1.000</td>
<td id="Sx8.T9.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.695 / 1.000</td>
<td id="Sx8.T9.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.948 / 1.000</td>
<td id="Sx8.T9.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.741 / 1.000</td>
<td id="Sx8.T9.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.463 / 1.000</td>
<td id="Sx8.T9.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.596 / 1.000</td>
<td id="Sx8.T9.1.2.2.9" class="ltx_td ltx_align_center ltx_border_t">0.737 / 1.000</td>
</tr>
<tr id="Sx8.T9.1.3.3" class="ltx_tr">
<td id="Sx8.T9.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps</td>
<td id="Sx8.T9.1.3.3.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.895 / 0.717</td>
<td id="Sx8.T9.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.831 / 0.609</td>
<td id="Sx8.T9.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.979 / 0.647</td>
<td id="Sx8.T9.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.878 / 0.690</td>
<td id="Sx8.T9.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.828 / 0.791</td>
<td id="Sx8.T9.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.808 / 0.684</td>
<td id="Sx8.T9.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t">0.844 / 0.831</td>
</tr>
<tr id="Sx8.T9.1.4.4" class="ltx_tr">
<td id="Sx8.T9.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">RedCaps (R)</td>
<td id="Sx8.T9.1.4.4.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.865 / 0.794</td>
<td id="Sx8.T9.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.787 / 0.752</td>
<td id="Sx8.T9.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.975 / 0.824</td>
<td id="Sx8.T9.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.839 / 0.785</td>
<td id="Sx8.T9.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.668 / 0.759</td>
<td id="Sx8.T9.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.855 / 0.929</td>
<td id="Sx8.T9.1.4.4.9" class="ltx_td ltx_align_center ltx_border_t">0.837 / 0.709</td>
</tr>
<tr id="Sx8.T9.1.5.5" class="ltx_tr">
<td id="Sx8.T9.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CC</td>
<td id="Sx8.T9.1.5.5.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.863 / 0.902</td>
<td id="Sx8.T9.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.759 / 0.917</td>
<td id="Sx8.T9.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.974 / 0.925</td>
<td id="Sx8.T9.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.824 / 0.914</td>
<td id="Sx8.T9.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.585 / 0.846</td>
<td id="Sx8.T9.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.713 / 0.844</td>
<td id="Sx8.T9.1.5.5.9" class="ltx_td ltx_align_center ltx_border_t">0.884 / 0.935</td>
</tr>
<tr id="Sx8.T9.1.6.6" class="ltx_tr">
<td id="Sx8.T9.1.6.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">VIST</td>
<td id="Sx8.T9.1.6.6.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.826 / 0.978</td>
<td id="Sx8.T9.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.729 / 0.949</td>
<td id="Sx8.T9.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.958 / 0.926</td>
<td id="Sx8.T9.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.789 / 0.971</td>
<td id="Sx8.T9.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.518 / 0.939</td>
<td id="Sx8.T9.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.658 / 0.883</td>
<td id="Sx8.T9.1.6.6.9" class="ltx_td ltx_align_center ltx_border_t">0.771 / 0.981</td>
</tr>
<tr id="Sx8.T9.1.7.7" class="ltx_tr">
<td id="Sx8.T9.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">COCO</td>
<td id="Sx8.T9.1.7.7.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.779 / 1.000</td>
<td id="Sx8.T9.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.695 / 1.000</td>
<td id="Sx8.T9.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.948 / 1.000</td>
<td id="Sx8.T9.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.741 / 1.000</td>
<td id="Sx8.T9.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.463 / 1.000</td>
<td id="Sx8.T9.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.599 / 1.000</td>
<td id="Sx8.T9.1.7.7.9" class="ltx_td ltx_align_center ltx_border_t">0.739 / 1.000</td>
</tr>
<tr id="Sx8.T9.1.8.8" class="ltx_tr">
<td id="Sx8.T9.1.8.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps,CC</td>
<td id="Sx8.T9.1.8.8.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.885 / 0.840</td>
<td id="Sx8.T9.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.788 / 0.837</td>
<td id="Sx8.T9.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.978 / 0.893</td>
<td id="Sx8.T9.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.847 / 0.838</td>
<td id="Sx8.T9.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.923 / 0.950</td>
<td id="Sx8.T9.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.762 / 0.822</td>
<td id="Sx8.T9.1.8.8.9" class="ltx_td ltx_align_center ltx_border_t">0.965 / 0.978</td>
</tr>
<tr id="Sx8.T9.1.9.9" class="ltx_tr">
<td id="Sx8.T9.1.9.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">R,CC</td>
<td id="Sx8.T9.1.9.9.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.876 / 0.888</td>
<td id="Sx8.T9.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.801 / 0.784</td>
<td id="Sx8.T9.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.976 / 0.918</td>
<td id="Sx8.T9.1.9.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.855 / 0.852</td>
<td id="Sx8.T9.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.691 / 0.720</td>
<td id="Sx8.T9.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.845 / 0.836</td>
<td id="Sx8.T9.1.9.9.9" class="ltx_td ltx_align_center ltx_border_t">0.892 / 0.914</td>
</tr>
<tr id="Sx8.T9.1.10.10" class="ltx_tr">
<td id="Sx8.T9.1.10.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps,R</td>
<td id="Sx8.T9.1.10.10.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.876 / 0.779</td>
<td id="Sx8.T9.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.789 / 0.697</td>
<td id="Sx8.T9.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.976 / 0.791</td>
<td id="Sx8.T9.1.10.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.849 / 0.758</td>
<td id="Sx8.T9.1.10.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.892 / 0.940</td>
<td id="Sx8.T9.1.10.10.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.923 / 0.958</td>
<td id="Sx8.T9.1.10.10.9" class="ltx_td ltx_align_center ltx_border_t">0.846 / 0.785</td>
</tr>
<tr id="Sx8.T9.1.11.11" class="ltx_tr">
<td id="Sx8.T9.1.11.11.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps</td>
<td id="Sx8.T9.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T9.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.885 / 0.798</td>
<td id="Sx8.T9.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.817 / 0.719</td>
<td id="Sx8.T9.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.977 / 0.745</td>
<td id="Sx8.T9.1.11.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.866 / 0.768</td>
<td id="Sx8.T9.1.11.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.790 / 0.814</td>
<td id="Sx8.T9.1.11.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.782 / 0.754</td>
<td id="Sx8.T9.1.11.11.9" class="ltx_td ltx_align_center ltx_border_t">0.834 / 0.866</td>
</tr>
<tr id="Sx8.T9.1.12.12" class="ltx_tr">
<td id="Sx8.T9.1.12.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">R</td>
<td id="Sx8.T9.1.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T9.1.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.880 / 0.744</td>
<td id="Sx8.T9.1.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.809 / 0.697</td>
<td id="Sx8.T9.1.12.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.976 / 0.776</td>
<td id="Sx8.T9.1.12.12.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.856 / 0.721</td>
<td id="Sx8.T9.1.12.12.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.686 / 0.724</td>
<td id="Sx8.T9.1.12.12.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.843 / 0.901</td>
<td id="Sx8.T9.1.12.12.9" class="ltx_td ltx_align_center ltx_border_t">0.831 / 0.526</td>
</tr>
<tr id="Sx8.T9.1.13.13" class="ltx_tr">
<td id="Sx8.T9.1.13.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CC</td>
<td id="Sx8.T9.1.13.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T9.1.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.868 / 0.913</td>
<td id="Sx8.T9.1.13.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.765 / 0.920</td>
<td id="Sx8.T9.1.13.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.975 / 0.942</td>
<td id="Sx8.T9.1.13.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.835 / 0.920</td>
<td id="Sx8.T9.1.13.13.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.609 / 0.841</td>
<td id="Sx8.T9.1.13.13.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.721 / 0.862</td>
<td id="Sx8.T9.1.13.13.9" class="ltx_td ltx_align_center ltx_border_t">0.922 / 0.955</td>
</tr>
<tr id="Sx8.T9.1.14.14" class="ltx_tr">
<td id="Sx8.T9.1.14.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps,CC</td>
<td id="Sx8.T9.1.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T9.1.14.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.870 / 0.915</td>
<td id="Sx8.T9.1.14.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.776 / 0.881</td>
<td id="Sx8.T9.1.14.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.976 / 0.932</td>
<td id="Sx8.T9.1.14.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.830 / 0.905</td>
<td id="Sx8.T9.1.14.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.754 / 0.821</td>
<td id="Sx8.T9.1.14.14.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.747 / 0.847</td>
<td id="Sx8.T9.1.14.14.9" class="ltx_td ltx_align_center ltx_border_t">0.891 / 0.943</td>
</tr>
<tr id="Sx8.T9.1.15.15" class="ltx_tr">
<td id="Sx8.T9.1.15.15.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">R,CC</td>
<td id="Sx8.T9.1.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T9.1.15.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.862 / 0.922</td>
<td id="Sx8.T9.1.15.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.779 / 0.842</td>
<td id="Sx8.T9.1.15.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.971 / 0.944</td>
<td id="Sx8.T9.1.15.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.837 / 0.894</td>
<td id="Sx8.T9.1.15.15.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.649 / 0.797</td>
<td id="Sx8.T9.1.15.15.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.793 / 0.887</td>
<td id="Sx8.T9.1.15.15.9" class="ltx_td ltx_align_center ltx_border_t">0.868 / 0.931</td>
</tr>
<tr id="Sx8.T9.1.16.16" class="ltx_tr">
<td id="Sx8.T9.1.16.16.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps,R</td>
<td id="Sx8.T9.1.16.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T9.1.16.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.877 / 0.807</td>
<td id="Sx8.T9.1.16.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.805 / 0.712</td>
<td id="Sx8.T9.1.16.16.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.973 / 0.856</td>
<td id="Sx8.T9.1.16.16.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.844 / 0.828</td>
<td id="Sx8.T9.1.16.16.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.826 / 0.724</td>
<td id="Sx8.T9.1.16.16.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.804 / 0.905</td>
<td id="Sx8.T9.1.16.16.9" class="ltx_td ltx_align_center ltx_border_t">0.839 / 0.771</td>
</tr>
<tr id="Sx8.T9.1.17.17" class="ltx_tr">
<td id="Sx8.T9.1.17.17.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">ALL</td>
<td id="Sx8.T9.1.17.17.2" class="ltx_td ltx_border_b ltx_border_r ltx_border_t"></td>
<td id="Sx8.T9.1.17.17.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.860 / 0.969</td>
<td id="Sx8.T9.1.17.17.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.779 / 0.903</td>
<td id="Sx8.T9.1.17.17.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.973 / 0.990</td>
<td id="Sx8.T9.1.17.17.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.832 / 0.947</td>
<td id="Sx8.T9.1.17.17.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.713 / 0.829</td>
<td id="Sx8.T9.1.17.17.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.803 / 0.898</td>
<td id="Sx8.T9.1.17.17.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">0.874 / 0.941</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Cross Dataset Vetting Precision and Recall Performance on visual presence validations sets from different sources (DII-VIST…CC). All methods improve precision compared to no vetting.</figcaption>
</figure>
<figure id="Sx8.T10" class="ltx_table">
<table id="Sx8.T10.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx8.T10.1.1.1" class="ltx_tr">
<td id="Sx8.T10.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.1.1.1.1" class="ltx_text ltx_font_bold">Train Dataset</span></td>
<td id="Sx8.T10.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ST</td>
<td id="Sx8.T10.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.1.1.3.1" class="ltx_text ltx_font_bold">DII-VIST</span></td>
<td id="Sx8.T10.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.1.1.4.1" class="ltx_text ltx_font_bold">SIS-VIST</span></td>
<td id="Sx8.T10.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.1.1.5.1" class="ltx_text ltx_font_bold">COCO</span></td>
<td id="Sx8.T10.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.1.1.6.1" class="ltx_text ltx_font_bold">VIST</span></td>
<td id="Sx8.T10.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.1.1.7.1" class="ltx_text ltx_font_bold">SBUCaps</span></td>
<td id="Sx8.T10.1.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.1.1.8.1" class="ltx_text ltx_font_bold">RedCaps</span></td>
<td id="Sx8.T10.1.1.1.9" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx8.T10.1.1.1.9.1" class="ltx_text ltx_font_bold">CC</span></td>
</tr>
<tr id="Sx8.T10.1.2.2" class="ltx_tr">
<td id="Sx8.T10.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">No Vetting</td>
<td id="Sx8.T10.1.2.2.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.876</td>
<td id="Sx8.T10.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.820</td>
<td id="Sx8.T10.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.973</td>
<td id="Sx8.T10.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.851</td>
<td id="Sx8.T10.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.633</td>
<td id="Sx8.T10.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.747</td>
<td id="Sx8.T10.1.2.2.9" class="ltx_td ltx_align_center ltx_border_t">0.849</td>
</tr>
<tr id="Sx8.T10.1.3.3" class="ltx_tr">
<td id="Sx8.T10.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps</td>
<td id="Sx8.T10.1.3.3.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.796</td>
<td id="Sx8.T10.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.703</td>
<td id="Sx8.T10.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.779</td>
<td id="Sx8.T10.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.773</td>
<td id="Sx8.T10.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.3.3.7.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.3.3.7.1.1" class="ltx_text ltx_font_bold">0.809</span></span></td>
<td id="Sx8.T10.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.741</td>
<td id="Sx8.T10.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t">0.837</td>
</tr>
<tr id="Sx8.T10.1.4.4" class="ltx_tr">
<td id="Sx8.T10.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">R</td>
<td id="Sx8.T10.1.4.4.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.828</td>
<td id="Sx8.T10.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.769</td>
<td id="Sx8.T10.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.893</td>
<td id="Sx8.T10.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.811</td>
<td id="Sx8.T10.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.4.4.7.1" class="ltx_text ltx_font_bold">0.710</span></td>
<td id="Sx8.T10.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.4.4.8.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.4.4.8.1.1" class="ltx_text ltx_font_bold">0.890</span></span></td>
<td id="Sx8.T10.1.4.4.9" class="ltx_td ltx_align_center ltx_border_t">0.768</td>
</tr>
<tr id="Sx8.T10.1.5.5" class="ltx_tr">
<td id="Sx8.T10.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CC</td>
<td id="Sx8.T10.1.5.5.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.5.5.3.1" class="ltx_text ltx_font_bold">0.882</span></td>
<td id="Sx8.T10.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.5.5.4.1" class="ltx_text ltx_font_bold">0.830</span></td>
<td id="Sx8.T10.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.949</td>
<td id="Sx8.T10.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.5.5.6.1" class="ltx_text ltx_font_bold">0.867</span></td>
<td id="Sx8.T10.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.5.5.7.1" class="ltx_text ltx_font_bold">0.692</span></td>
<td id="Sx8.T10.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.5.5.8.1" class="ltx_text ltx_font_bold">0.773</span></td>
<td id="Sx8.T10.1.5.5.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.5.5.9.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.5.5.9.1.1" class="ltx_text ltx_font_bold">0.909</span></span></td>
</tr>
<tr id="Sx8.T10.1.6.6" class="ltx_tr">
<td id="Sx8.T10.1.6.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">VIST</td>
<td id="Sx8.T10.1.6.6.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.6.6.3.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.6.6.3.1.1" class="ltx_text ltx_font_bold">0.895</span></span></td>
<td id="Sx8.T10.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.6.6.4.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.6.6.4.1.1" class="ltx_text ltx_font_bold">0.825</span></span></td>
<td id="Sx8.T10.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.942</td>
<td id="Sx8.T10.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.6.6.6.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.6.6.6.1.1" class="ltx_text ltx_font_bold">0.871</span></span></td>
<td id="Sx8.T10.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.6.6.7.1" class="ltx_text ltx_font_bold">0.668</span></td>
<td id="Sx8.T10.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.6.6.8.1" class="ltx_text ltx_font_bold">0.754</span></td>
<td id="Sx8.T10.1.6.6.9" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx8.T10.1.6.6.9.1" class="ltx_text ltx_font_bold">0.863</span></td>
</tr>
<tr id="Sx8.T10.1.7.7" class="ltx_tr">
<td id="Sx8.T10.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">COCO</td>
<td id="Sx8.T10.1.7.7.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.876</td>
<td id="Sx8.T10.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.820</td>
<td id="Sx8.T10.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.7.7.5.1" class="ltx_text" style="background-color:#FFF2CC;">0.973</span></td>
<td id="Sx8.T10.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.851</td>
<td id="Sx8.T10.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.633</td>
<td id="Sx8.T10.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.7.7.8.1" class="ltx_text ltx_font_bold">0.749</span></td>
<td id="Sx8.T10.1.7.7.9" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx8.T10.1.7.7.9.1" class="ltx_text ltx_font_bold">0.850</span></td>
</tr>
<tr id="Sx8.T10.1.8.8" class="ltx_tr">
<td id="Sx8.T10.1.8.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps,CC</td>
<td id="Sx8.T10.1.8.8.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.862</td>
<td id="Sx8.T10.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.812</td>
<td id="Sx8.T10.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.933</td>
<td id="Sx8.T10.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.843</td>
<td id="Sx8.T10.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.8.8.7.1" class="ltx_text ltx_font_bold" style="background-color:#FFF2CC;">0.937</span></td>
<td id="Sx8.T10.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.8.8.8.1" class="ltx_text ltx_font_bold">0.791</span></td>
<td id="Sx8.T10.1.8.8.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.8.8.9.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.8.8.9.1.1" class="ltx_text ltx_font_bold">0.972</span></span></td>
</tr>
<tr id="Sx8.T10.1.9.9" class="ltx_tr">
<td id="Sx8.T10.1.9.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">R,CC</td>
<td id="Sx8.T10.1.9.9.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.9.9.3.1" class="ltx_text ltx_font_bold">0.882</span></td>
<td id="Sx8.T10.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.793</td>
<td id="Sx8.T10.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.946</td>
<td id="Sx8.T10.1.9.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.9.9.6.1" class="ltx_text ltx_font_bold">0.854</span></td>
<td id="Sx8.T10.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.9.9.7.1" class="ltx_text ltx_font_bold">0.705</span></td>
<td id="Sx8.T10.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.9.9.8.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.9.9.8.1.1" class="ltx_text ltx_font_bold">0.841</span></span></td>
<td id="Sx8.T10.1.9.9.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.9.9.9.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.9.9.9.1.1" class="ltx_text ltx_font_bold">0.903</span></span></td>
</tr>
<tr id="Sx8.T10.1.10.10" class="ltx_tr">
<td id="Sx8.T10.1.10.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps,R</td>
<td id="Sx8.T10.1.10.10.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.825</td>
<td id="Sx8.T10.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.741</td>
<td id="Sx8.T10.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.874</td>
<td id="Sx8.T10.1.10.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.801</td>
<td id="Sx8.T10.1.10.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.10.10.7.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.10.10.7.1.1" class="ltx_text ltx_font_bold"> 0.915</span></span></td>
<td id="Sx8.T10.1.10.10.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.10.10.8.1" class="ltx_text ltx_font_bold" style="background-color:#FFF2CC;">0.940</span></td>
<td id="Sx8.T10.1.10.10.9" class="ltx_td ltx_align_center ltx_border_t">0.810</td>
</tr>
<tr id="Sx8.T10.1.11.11" class="ltx_tr">
<td id="Sx8.T10.1.11.11.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps</td>
<td id="Sx8.T10.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T10.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.839</td>
<td id="Sx8.T10.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.765</td>
<td id="Sx8.T10.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.846</td>
<td id="Sx8.T10.1.11.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.814</td>
<td id="Sx8.T10.1.11.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.11.11.7.1" class="ltx_text ltx_font_bold" style="background-color:#FFF2CC;">0.802</span></td>
<td id="Sx8.T10.1.11.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.11.11.8.1" class="ltx_text ltx_font_bold">0.767</span></td>
<td id="Sx8.T10.1.11.11.9" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx8.T10.1.11.11.9.1" class="ltx_text ltx_font_bold">0.850</span></td>
</tr>
<tr id="Sx8.T10.1.12.12" class="ltx_tr">
<td id="Sx8.T10.1.12.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">R</td>
<td id="Sx8.T10.1.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T10.1.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.806</td>
<td id="Sx8.T10.1.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.749</td>
<td id="Sx8.T10.1.12.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.865</td>
<td id="Sx8.T10.1.12.12.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.783</td>
<td id="Sx8.T10.1.12.12.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.12.12.7.1" class="ltx_text ltx_font_bold">0.705</span></td>
<td id="Sx8.T10.1.12.12.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.12.12.8.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.12.12.8.1.1" class="ltx_text ltx_font_bold"> 0.871</span></span></td>
<td id="Sx8.T10.1.12.12.9" class="ltx_td ltx_align_center ltx_border_t">0.644</td>
</tr>
<tr id="Sx8.T10.1.13.13" class="ltx_tr">
<td id="Sx8.T10.1.13.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CC</td>
<td id="Sx8.T10.1.13.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T10.1.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.13.13.3.1" class="ltx_text ltx_font_bold">0.890</span></td>
<td id="Sx8.T10.1.13.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.13.13.4.1" class="ltx_text ltx_font_bold">0.836</span></td>
<td id="Sx8.T10.1.13.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.958</td>
<td id="Sx8.T10.1.13.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.13.13.6.1" class="ltx_text ltx_font_bold">0.875</span></td>
<td id="Sx8.T10.1.13.13.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.13.13.7.1" class="ltx_text ltx_font_bold">0.707</span></td>
<td id="Sx8.T10.1.13.13.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.13.13.8.1" class="ltx_text ltx_font_bold">0.785</span></td>
<td id="Sx8.T10.1.13.13.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.13.13.9.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.13.13.9.1.1" class="ltx_text ltx_font_bold">0.938</span></span></td>
</tr>
<tr id="Sx8.T10.1.14.14" class="ltx_tr">
<td id="Sx8.T10.1.14.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps,CC</td>
<td id="Sx8.T10.1.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T10.1.14.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.14.14.3.1" class="ltx_text ltx_font_bold">0.892</span></td>
<td id="Sx8.T10.1.14.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.14.14.4.1" class="ltx_text ltx_font_bold">0.825</span></td>
<td id="Sx8.T10.1.14.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.954</td>
<td id="Sx8.T10.1.14.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.14.14.6.1" class="ltx_text ltx_font_bold">0.866</span></td>
<td id="Sx8.T10.1.14.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.14.14.7.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.14.14.7.1.1" class="ltx_text ltx_font_bold">0.786</span></span></td>
<td id="Sx8.T10.1.14.14.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.14.14.8.1" class="ltx_text ltx_font_bold">0.793</span></td>
<td id="Sx8.T10.1.14.14.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.14.14.9.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.14.14.9.1.1" class="ltx_text ltx_font_bold">0.916</span></span></td>
</tr>
<tr id="Sx8.T10.1.15.15" class="ltx_tr">
<td id="Sx8.T10.1.15.15.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">R,CC</td>
<td id="Sx8.T10.1.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T10.1.15.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.15.15.3.1" class="ltx_text ltx_font_bold">0.891</span></td>
<td id="Sx8.T10.1.15.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.809</td>
<td id="Sx8.T10.1.15.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.957</td>
<td id="Sx8.T10.1.15.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.15.15.6.1" class="ltx_text ltx_font_bold">0.865</span></td>
<td id="Sx8.T10.1.15.15.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="Sx8.T10.1.15.15.7.1" class="ltx_text ltx_font_bold">0.716</span></td>
<td id="Sx8.T10.1.15.15.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.15.15.8.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.15.15.8.1.1" class="ltx_text ltx_font_bold">0.837</span></span></td>
<td id="Sx8.T10.1.15.15.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.15.15.9.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.15.15.9.1.1" class="ltx_text ltx_font_bold">0.899</span></span></td>
</tr>
<tr id="Sx8.T10.1.16.16" class="ltx_tr">
<td id="Sx8.T10.1.16.16.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SBUCaps,R</td>
<td id="Sx8.T10.1.16.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="Sx8.T10.1.16.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.841</td>
<td id="Sx8.T10.1.16.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.756</td>
<td id="Sx8.T10.1.16.16.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.911</td>
<td id="Sx8.T10.1.16.16.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.836</td>
<td id="Sx8.T10.1.16.16.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.16.16.7.1" class="ltx_text ltx_font_bold" style="background-color:#FFF2CC;">0.772</span></td>
<td id="Sx8.T10.1.16.16.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.16.16.8.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.16.16.8.1.1" class="ltx_text ltx_font_bold">0.851</span></span></td>
<td id="Sx8.T10.1.16.16.9" class="ltx_td ltx_align_center ltx_border_t">0.803</td>
</tr>
<tr id="Sx8.T10.1.17.17" class="ltx_tr">
<td id="Sx8.T10.1.17.17.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">ALL</td>
<td id="Sx8.T10.1.17.17.2" class="ltx_td ltx_border_b ltx_border_r ltx_border_t"></td>
<td id="Sx8.T10.1.17.17.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.3.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.3.1.1" class="ltx_text ltx_font_bold">0.911</span></span></td>
<td id="Sx8.T10.1.17.17.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.4.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.4.1.1" class="ltx_text ltx_font_bold">0.836</span></span></td>
<td id="Sx8.T10.1.17.17.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.5.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.5.1.1" class="ltx_text ltx_font_bold">0.981</span></span></td>
<td id="Sx8.T10.1.17.17.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.6.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.6.1.1" class="ltx_text ltx_font_bold">0.886</span></span></td>
<td id="Sx8.T10.1.17.17.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.7.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.7.1.1" class="ltx_text ltx_font_bold">0.767</span></span></td>
<td id="Sx8.T10.1.17.17.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.8.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.8.1.1" class="ltx_text ltx_font_bold">0.848</span></span></td>
<td id="Sx8.T10.1.17.17.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.9.1" class="ltx_text" style="background-color:#FFF2CC;"><span id="Sx8.T10.1.17.17.9.1.1" class="ltx_text ltx_font_bold">0.906</span></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Cross Dataset Vetting F1 Performance on visual presence validations sets from different sources (DII-VIST…CC). Bold indicates if result is better than no vetting. Train data containing the same source as the validation is highlighted in yellow.</figcaption>
</figure>
<div id="Sx8.p1" class="ltx_para">
<p id="Sx8.p1.1" class="ltx_p">Table <a href="#Sx8.T9" title="Table 9 ‣ Cross-Dataset Ablations ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> is included as reference which shows that precision in the cross dataset setting is always better than no vetting with the exception of COCO.</p>
</div>
<figure id="Sx8.F4" class="ltx_figure"><img src="/html/2303.09608/assets/iccv2023AuthorKit/figures/images/veil_quals.png" id="Sx8.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="335" height="196" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Qualitative examples of extracted labels after vetting on RedCaps-Test. These are additional completely absent VAEL examples from CLaN with their linguistic indicators and similar context annotations, and only VEIL-based methods are able to overcome these three noise types.</figcaption>
</figure>
<div id="Sx8.p2" class="ltx_para">
<p id="Sx8.p2.1" class="ltx_p"><span id="Sx8.p2.1.1" class="ltx_text ltx_font_bold">Combining multiple datasets.</span> We find that VEIL is able to leverage additional datasets to an extent. For example, combining SBUCaps and CC leads to significant improvements (7-16% relative) in F1 as shown in Table <a href="#Sx8.T10" title="Table 10 ‣ Cross-Dataset Ablations ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> and, combining SBUCaps and Redcaps in training improves performance on both validation sets. When combining all datasets, only the non-in the wild datasets see an improved performance.</p>
</div>
<div id="Sx8.p3" class="ltx_para">
<p id="Sx8.p3.1" class="ltx_p"><span id="Sx8.p3.1.1" class="ltx_text ltx_font_bold">Using special token.</span> We find that using VEIL w/ ST on average improves F1 by 1 pt compared to just VEIL when transferring to other datasets. This comes at a tradeoff with respect to the performance on the same dataset; however CC w/ ST improves performance on all datasets.</p>
</div>
<figure id="Sx8.T11" class="ltx_table">
<table id="Sx8.T11.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx8.T11.1.2.1" class="ltx_tr">
<th id="Sx8.T11.1.2.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<td id="Sx8.T11.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">mAP, IoU</td>
<td id="Sx8.T11.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" colspan="3">mAP, Area</td>
</tr>
<tr id="Sx8.T11.1.3.2" class="ltx_tr">
<th id="Sx8.T11.1.3.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<td id="Sx8.T11.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">0.5:0.95</td>
<td id="Sx8.T11.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">0.5</td>
<td id="Sx8.T11.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.75</td>
<td id="Sx8.T11.1.3.2.5" class="ltx_td ltx_align_center ltx_border_t">S</td>
<td id="Sx8.T11.1.3.2.6" class="ltx_td ltx_align_center ltx_border_t">M</td>
<td id="Sx8.T11.1.3.2.7" class="ltx_td ltx_align_center ltx_border_t">L</td>
</tr>
<tr id="Sx8.T11.1.4.3" class="ltx_tr">
<th id="Sx8.T11.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">GT*</th>
<td id="Sx8.T11.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t">4.19</td>
<td id="Sx8.T11.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">9.17</td>
<td id="Sx8.T11.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.40</td>
<td id="Sx8.T11.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t">1.10</td>
<td id="Sx8.T11.1.4.3.6" class="ltx_td ltx_align_center ltx_border_t">4.34</td>
<td id="Sx8.T11.1.4.3.7" class="ltx_td ltx_align_center ltx_border_t">6.76</td>
</tr>
<tr id="Sx8.T11.1.5.4" class="ltx_tr">
<th id="Sx8.T11.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">No Vetting</th>
<td id="Sx8.T11.1.5.4.2" class="ltx_td ltx_align_center ltx_border_t">3.24</td>
<td id="Sx8.T11.1.5.4.3" class="ltx_td ltx_align_center ltx_border_t">7.70</td>
<td id="Sx8.T11.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.37</td>
<td id="Sx8.T11.1.5.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="Sx8.T11.1.5.4.5.1" class="ltx_text ltx_framed ltx_framed_underline">1.06</span></td>
<td id="Sx8.T11.1.5.4.6" class="ltx_td ltx_align_center ltx_border_t">4.00</td>
<td id="Sx8.T11.1.5.4.7" class="ltx_td ltx_align_center ltx_border_t">5.08</td>
</tr>
<tr id="Sx8.T11.1.6.5" class="ltx_tr">
<th id="Sx8.T11.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Large Loss <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="Sx8.T11.1.6.5.2" class="ltx_td ltx_align_center">3.11</td>
<td id="Sx8.T11.1.6.5.3" class="ltx_td ltx_align_center">7.54</td>
<td id="Sx8.T11.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r">2.15</td>
<td id="Sx8.T11.1.6.5.5" class="ltx_td ltx_align_center">0.92</td>
<td id="Sx8.T11.1.6.5.6" class="ltx_td ltx_align_center">3.80</td>
<td id="Sx8.T11.1.6.5.7" class="ltx_td ltx_align_center">4.88</td>
</tr>
<tr id="Sx8.T11.1.7.6" class="ltx_tr">
<th id="Sx8.T11.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">LocalCLIP-E <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="Sx8.T11.1.7.6.2" class="ltx_td ltx_align_center">3.66</td>
<td id="Sx8.T11.1.7.6.3" class="ltx_td ltx_align_center">7.77</td>
<td id="Sx8.T11.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r">3.08</td>
<td id="Sx8.T11.1.7.6.5" class="ltx_td ltx_align_center">0.79</td>
<td id="Sx8.T11.1.7.6.6" class="ltx_td ltx_align_center">3.96</td>
<td id="Sx8.T11.1.7.6.7" class="ltx_td ltx_align_center">5.96</td>
</tr>
<tr id="Sx8.T11.1.1" class="ltx_tr">
<th id="Sx8.T11.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">VEIL<math id="Sx8.T11.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{ST}}" display="inline"><semantics id="Sx8.T11.1.1.1.m1.1a"><msub id="Sx8.T11.1.1.1.m1.1.1" xref="Sx8.T11.1.1.1.m1.1.1.cmml"><mi id="Sx8.T11.1.1.1.m1.1.1a" xref="Sx8.T11.1.1.1.m1.1.1.cmml"></mi><mtext id="Sx8.T11.1.1.1.m1.1.1.1" xref="Sx8.T11.1.1.1.m1.1.1.1a.cmml">ST</mtext></msub><annotation-xml encoding="MathML-Content" id="Sx8.T11.1.1.1.m1.1b"><apply id="Sx8.T11.1.1.1.m1.1.1.cmml" xref="Sx8.T11.1.1.1.m1.1.1"><ci id="Sx8.T11.1.1.1.m1.1.1.1a.cmml" xref="Sx8.T11.1.1.1.m1.1.1.1"><mtext mathsize="70%" id="Sx8.T11.1.1.1.m1.1.1.1.cmml" xref="Sx8.T11.1.1.1.m1.1.1.1">ST</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx8.T11.1.1.1.m1.1c">{}_{\text{ST}}</annotation></semantics></math>-R,CC</th>
<td id="Sx8.T11.1.1.2" class="ltx_td ltx_align_center"><span id="Sx8.T11.1.1.2.1" class="ltx_text ltx_framed ltx_framed_underline">3.90</span></td>
<td id="Sx8.T11.1.1.3" class="ltx_td ltx_align_center"><span id="Sx8.T11.1.1.3.1" class="ltx_text ltx_framed ltx_framed_underline">8.60</span></td>
<td id="Sx8.T11.1.1.4" class="ltx_td ltx_align_center ltx_border_r"><span id="Sx8.T11.1.1.4.1" class="ltx_text ltx_framed ltx_framed_underline">3.14</span></td>
<td id="Sx8.T11.1.1.5" class="ltx_td ltx_align_center">0.93</td>
<td id="Sx8.T11.1.1.6" class="ltx_td ltx_align_center"><span id="Sx8.T11.1.1.6.1" class="ltx_text ltx_framed ltx_framed_underline">4.25</span></td>
<td id="Sx8.T11.1.1.7" class="ltx_td ltx_align_center"><span id="Sx8.T11.1.1.7.1" class="ltx_text ltx_framed ltx_framed_underline">6.28</span></td>
</tr>
<tr id="Sx8.T11.1.8.7" class="ltx_tr">
<th id="Sx8.T11.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">VEIL-SBUCaps</th>
<td id="Sx8.T11.1.8.7.2" class="ltx_td ltx_align_center ltx_border_b"><span id="Sx8.T11.1.8.7.2.1" class="ltx_text ltx_font_bold">4.89</span></td>
<td id="Sx8.T11.1.8.7.3" class="ltx_td ltx_align_center ltx_border_b"><span id="Sx8.T11.1.8.7.3.1" class="ltx_text ltx_font_bold">10.37</span></td>
<td id="Sx8.T11.1.8.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="Sx8.T11.1.8.7.4.1" class="ltx_text ltx_font_bold">4.20</span></td>
<td id="Sx8.T11.1.8.7.5" class="ltx_td ltx_align_center ltx_border_b"><span id="Sx8.T11.1.8.7.5.1" class="ltx_text ltx_font_bold">1.26</span></td>
<td id="Sx8.T11.1.8.7.6" class="ltx_td ltx_align_center ltx_border_b"><span id="Sx8.T11.1.8.7.6.1" class="ltx_text ltx_font_bold">5.24</span></td>
<td id="Sx8.T11.1.8.7.7" class="ltx_td ltx_align_center ltx_border_b"><span id="Sx8.T11.1.8.7.7.1" class="ltx_text ltx_font_bold">7.53</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>COCO-14 benchmark for WSOD models trained with various vetting methods. (GT*) directly vets labels using the pretrained object detectors which were used to train VEIL. Bold indicates best performance in each column and underline indicates second best result in the column.</figcaption>
</figure>
</section>
<section id="Sx9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">WSOD Hyperparameters</h2>

<div id="Sx9.p1" class="ltx_para">
<p id="Sx9.p1.1" class="ltx_p"><span id="Sx9.p1.1.1" class="ltx_text ltx_font_bold">Learning Rates.</span> We trained four models without vetting on SBUCaps with learning rates from ‘1e-5’ till ‘1e-2’, for each order of magnitude, and observed that the model trained with a learning rate of ‘1e-2’ had substantially better Pascal VOC-07 detection performance and used this learning rate for all the WSOD models trained on SBUCaps. We applied a similar learning rate selection method for WSOD models trained on RedCaps, except we tested over every half order of magnitude and found that ‘5e-5’ was optimal when training on RedCaps.</p>
</div>
<figure id="Sx9.T12" class="ltx_table">
<table id="Sx9.T12.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx9.T12.1.1" class="ltx_tr">
<th id="Sx9.T12.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r">Relative Delta</th>
<th id="Sx9.T12.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Pascal VOC-07 <math id="Sx9.T12.1.1.1.m1.1" class="ltx_Math" alttext="\text{mAP}_{50}" display="inline"><semantics id="Sx9.T12.1.1.1.m1.1a"><msub id="Sx9.T12.1.1.1.m1.1.1" xref="Sx9.T12.1.1.1.m1.1.1.cmml"><mtext id="Sx9.T12.1.1.1.m1.1.1.2" xref="Sx9.T12.1.1.1.m1.1.1.2a.cmml">mAP</mtext><mn id="Sx9.T12.1.1.1.m1.1.1.3" xref="Sx9.T12.1.1.1.m1.1.1.3.cmml">50</mn></msub><annotation-xml encoding="MathML-Content" id="Sx9.T12.1.1.1.m1.1b"><apply id="Sx9.T12.1.1.1.m1.1.1.cmml" xref="Sx9.T12.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx9.T12.1.1.1.m1.1.1.1.cmml" xref="Sx9.T12.1.1.1.m1.1.1">subscript</csymbol><ci id="Sx9.T12.1.1.1.m1.1.1.2a.cmml" xref="Sx9.T12.1.1.1.m1.1.1.2"><mtext id="Sx9.T12.1.1.1.m1.1.1.2.cmml" xref="Sx9.T12.1.1.1.m1.1.1.2">mAP</mtext></ci><cn type="integer" id="Sx9.T12.1.1.1.m1.1.1.3.cmml" xref="Sx9.T12.1.1.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx9.T12.1.1.1.m1.1c">\text{mAP}_{50}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx9.T12.1.2.1" class="ltx_tr">
<th id="Sx9.T12.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">0.002</th>
<td id="Sx9.T12.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">28.25</td>
</tr>
<tr id="Sx9.T12.1.3.2" class="ltx_tr">
<th id="Sx9.T12.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.01</th>
<td id="Sx9.T12.1.3.2.2" class="ltx_td ltx_align_center">30.93</td>
</tr>
<tr id="Sx9.T12.1.4.3" class="ltx_tr">
<th id="Sx9.T12.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.05</th>
<td id="Sx9.T12.1.4.3.2" class="ltx_td ltx_align_center">28.11</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Relative delta hyperparameter ablation</figcaption>
</figure>
<div id="Sx9.p2" class="ltx_para">
<p id="Sx9.p2.1" class="ltx_p"><span id="Sx9.p2.1.1" class="ltx_text ltx_font_bold">Relative Delta.</span> In Large Loss Matters (LLM) <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>, relative delta controls how fast the rejection rate will increase over training. To find the best relative delta, we tested over three initializations, with <math id="Sx9.p2.1.m1.1" class="ltx_Math" alttext="rel\_delta=0.002" display="inline"><semantics id="Sx9.p2.1.m1.1a"><mrow id="Sx9.p2.1.m1.1.1" xref="Sx9.p2.1.m1.1.1.cmml"><mrow id="Sx9.p2.1.m1.1.1.2" xref="Sx9.p2.1.m1.1.1.2.cmml"><mi id="Sx9.p2.1.m1.1.1.2.2" xref="Sx9.p2.1.m1.1.1.2.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="Sx9.p2.1.m1.1.1.2.1" xref="Sx9.p2.1.m1.1.1.2.1.cmml">​</mo><mi id="Sx9.p2.1.m1.1.1.2.3" xref="Sx9.p2.1.m1.1.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="Sx9.p2.1.m1.1.1.2.1a" xref="Sx9.p2.1.m1.1.1.2.1.cmml">​</mo><mi id="Sx9.p2.1.m1.1.1.2.4" xref="Sx9.p2.1.m1.1.1.2.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="Sx9.p2.1.m1.1.1.2.1b" xref="Sx9.p2.1.m1.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="Sx9.p2.1.m1.1.1.2.5" xref="Sx9.p2.1.m1.1.1.2.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="Sx9.p2.1.m1.1.1.2.1c" xref="Sx9.p2.1.m1.1.1.2.1.cmml">​</mo><mi id="Sx9.p2.1.m1.1.1.2.6" xref="Sx9.p2.1.m1.1.1.2.6.cmml">d</mi><mo lspace="0em" rspace="0em" id="Sx9.p2.1.m1.1.1.2.1d" xref="Sx9.p2.1.m1.1.1.2.1.cmml">​</mo><mi id="Sx9.p2.1.m1.1.1.2.7" xref="Sx9.p2.1.m1.1.1.2.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="Sx9.p2.1.m1.1.1.2.1e" xref="Sx9.p2.1.m1.1.1.2.1.cmml">​</mo><mi id="Sx9.p2.1.m1.1.1.2.8" xref="Sx9.p2.1.m1.1.1.2.8.cmml">l</mi><mo lspace="0em" rspace="0em" id="Sx9.p2.1.m1.1.1.2.1f" xref="Sx9.p2.1.m1.1.1.2.1.cmml">​</mo><mi id="Sx9.p2.1.m1.1.1.2.9" xref="Sx9.p2.1.m1.1.1.2.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="Sx9.p2.1.m1.1.1.2.1g" xref="Sx9.p2.1.m1.1.1.2.1.cmml">​</mo><mi id="Sx9.p2.1.m1.1.1.2.10" xref="Sx9.p2.1.m1.1.1.2.10.cmml">a</mi></mrow><mo id="Sx9.p2.1.m1.1.1.1" xref="Sx9.p2.1.m1.1.1.1.cmml">=</mo><mn id="Sx9.p2.1.m1.1.1.3" xref="Sx9.p2.1.m1.1.1.3.cmml">0.002</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx9.p2.1.m1.1b"><apply id="Sx9.p2.1.m1.1.1.cmml" xref="Sx9.p2.1.m1.1.1"><eq id="Sx9.p2.1.m1.1.1.1.cmml" xref="Sx9.p2.1.m1.1.1.1"></eq><apply id="Sx9.p2.1.m1.1.1.2.cmml" xref="Sx9.p2.1.m1.1.1.2"><times id="Sx9.p2.1.m1.1.1.2.1.cmml" xref="Sx9.p2.1.m1.1.1.2.1"></times><ci id="Sx9.p2.1.m1.1.1.2.2.cmml" xref="Sx9.p2.1.m1.1.1.2.2">𝑟</ci><ci id="Sx9.p2.1.m1.1.1.2.3.cmml" xref="Sx9.p2.1.m1.1.1.2.3">𝑒</ci><ci id="Sx9.p2.1.m1.1.1.2.4.cmml" xref="Sx9.p2.1.m1.1.1.2.4">𝑙</ci><ci id="Sx9.p2.1.m1.1.1.2.5.cmml" xref="Sx9.p2.1.m1.1.1.2.5">_</ci><ci id="Sx9.p2.1.m1.1.1.2.6.cmml" xref="Sx9.p2.1.m1.1.1.2.6">𝑑</ci><ci id="Sx9.p2.1.m1.1.1.2.7.cmml" xref="Sx9.p2.1.m1.1.1.2.7">𝑒</ci><ci id="Sx9.p2.1.m1.1.1.2.8.cmml" xref="Sx9.p2.1.m1.1.1.2.8">𝑙</ci><ci id="Sx9.p2.1.m1.1.1.2.9.cmml" xref="Sx9.p2.1.m1.1.1.2.9">𝑡</ci><ci id="Sx9.p2.1.m1.1.1.2.10.cmml" xref="Sx9.p2.1.m1.1.1.2.10">𝑎</ci></apply><cn type="float" id="Sx9.p2.1.m1.1.1.3.cmml" xref="Sx9.p2.1.m1.1.1.3">0.002</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx9.p2.1.m1.1c">rel\_delta=0.002</annotation></semantics></math> as the setting recommended in <cite class="ltx_cite ltx_citemacro_citep">(Kim et al. <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>. We used the best result in Table <a href="#Sx9.T12" title="Table 12 ‣ WSOD Hyperparameters ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> when reporting results in the main paper.</p>
</div>
</section>
<section id="Sx10" class="ltx_section">
<h2 class="ltx_title ltx_title_section">WSOD Benchmarking on Additional COCO Metrics</h2>

<div id="Sx10.p1" class="ltx_para">
<p id="Sx10.p1.1" class="ltx_p">In our main text we compared the average precision of the model across all the classes and all the IoU (Intersection over Union) thresholds from 0.5 to 0.95. We show mAP at specific thresholds 0.5 and 0.75 in Table <a href="#Sx8.T11" title="Table 11 ‣ Cross-Dataset Ablations ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>. We see that cross dataset VEIL vetting performs relatively 32% better than no vetting in a stricter IoU (0.75). The mAP metric can be further broken down by area sizes of ground truth bounding boxes, which is denoted by S, M, and L. VEIL-based vetting outperforms the rest in Medium (6% better than best non-VEIL vetting) and Large objects (5% better than best non-VEIL vetting); while VEIL-Same Dataset still performs best on small objects, VEIL-Cross Dataset performs slightly worse than no vetting.</p>
</div>
</section>
<section id="Sx11" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Additional Qualitative Results</h2>

<figure id="Sx11.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2303.09608/assets/iccv2023AuthorKit/figures/wsod_qual_1.png" id="Sx11.F5.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="698" height="317" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2303.09608/assets/iccv2023AuthorKit/figures/wsod_qual_2.png" id="Sx11.F5.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="698" height="217" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Detections (blue bounding box) from WSOD models trained with various vetting methods (top row) indicate that training with either VEIL-based vetting method (two rightmost columns) leads to similar detection capability on VOC-07 <cite class="ltx_cite ltx_citemacro_citep">(Everingham et al. <a href="#bib.bib7" title="" class="ltx_ref">2010</a>)</cite>. The categories shown by row (from top to bottom) are: horse, car, boat, bicycle, chair.</figcaption>
</figure>
<div id="Sx11.p1" class="ltx_para">
<p id="Sx11.p1.1" class="ltx_p"><span id="Sx11.p1.1.1" class="ltx_text ltx_font_bold">Vetting Qualitative Examples.</span> Using annotations from CLaN, we provide qualitative examples comparing the vetting capability of methods on VAELs with common linguistic indicators (prepositional phrase, different word sense, non-literal) found in RedCaps in Figure <a href="#Sx8.F4" title="Figure 4 ‣ Cross-Dataset Ablations ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="Sx11.p2" class="ltx_para">
<p id="Sx11.p2.1" class="ltx_p"><span id="Sx11.p2.1.1" class="ltx_text ltx_font_bold">WSOD Qualitative Examples.</span> In Figure <a href="#Sx11.F5" title="Figure 5 ‣ Additional Qualitative Results ‣ VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we present further qualitative evidence on the impact of different vetting methods on weakly supervised object detection. There are varying degrees of part and contextual bias from all methods; however, No Vetting has the most pronounced part domination and context bias as shown by its detection of bicycle wheels and car doors (top two rows), and misidentifying a child as a chair (bottom row) and detections covering both boat and water. Both VEIL methods outperform the rest of the models in detecting smaller objects (see first two rows). LocalCLIP-E misses smaller objects in the background (first two rows) and also has part domination (bicycle).

</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2303.09607" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2303.09608" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2303.09608">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.09608" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2303.09609" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 19:32:52 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
