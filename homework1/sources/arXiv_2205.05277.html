<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2205.05277] AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation</title><meta property="og:description" content="Movement and pose assessment of newborns lets experienced pediatricians predict neurodevelopmental disorders, allowing early intervention for related diseases. However, most of the newest AI approaches for human pose eâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2205.05277">

<!--Generated on Mon Mar 11 13:26:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Xu Cao<sup id="id13.2.id1" class="ltx_sup"><span id="id13.2.id1.1" class="ltx_text ltx_font_italic">1,4</span></sup>
</span><span class="ltx_author_notes">project lead</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaoye Li<sup id="id14.2.id1" class="ltx_sup"><span id="id14.2.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>
</span><span class="ltx_author_notes">contributed equally to the first-author</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Liya Ma<sup id="id15.2.id1" class="ltx_sup"><span id="id15.2.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yi Huang<sup id="id16.2.id1" class="ltx_sup"><span id="id16.2.id1.1" class="ltx_text ltx_font_italic">1,3</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xuan Feng<sup id="id17.2.id1" class="ltx_sup"><span id="id17.2.id1.1" class="ltx_text ltx_font_italic">1,3</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zening Chen<sup id="id18.2.id1" class="ltx_sup"><span id="id18.2.id1.1" class="ltx_text ltx_font_italic">4</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break">Hongwu Zeng<sup id="id19.7.id1" class="ltx_sup"><span id="id19.7.id1.1" class="ltx_text ltx_font_italic">3</span></sup> &amp;Jianguo Cao<sup id="id20.8.id2" class="ltx_sup"><span id="id20.8.id2.1" class="ltx_text ltx_font_italic">1,3</span></sup>
<sup id="id21.9.id3" class="ltx_sup">1</sup>Shenzhen Automatic Rehabilitation Laboratory 
<br class="ltx_break"><sup id="id22.10.id4" class="ltx_sup">2</sup>Shenzhen Baoan Womenâ€™s and Childirenâ€™s Hospital, Jinan University 
<br class="ltx_break"><sup id="id23.11.id5" class="ltx_sup">3</sup>Shenzhen Childrenâ€™s Hospital 
<br class="ltx_break"><sup id="id24.12.id6" class="ltx_sup">4</sup>New York University 
<br class="ltx_break">xc2057@nyu.edu, caojgsz@126.com

</span><span class="ltx_author_notes">corresponding author</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id25.id1" class="ltx_p">Movement and pose assessment of newborns lets experienced pediatricians predict neurodevelopmental disorders, allowing early intervention for related diseases. However, most of the newest AI approaches for human pose estimation methods focus on adults, lacking publicly benchmark for infant pose estimation. In this paper, we fill this gap by proposing infant pose dataset and Deep Aggregation Vision Transformer for human pose estimation, which introduces a fast trained full transformer framework without using convolution operations to extract features in the early stages. It generalizes Transformer + MLP to high-resolution deep layer aggregation within feature maps, thus enabling information fusion between different vision levels. We pre-train AggPose on COCO pose dataset and apply it on our newly released large-scale infant pose estimation dataset. The results show that AggPose could effectively learn the multi-scale features among different resolutions and significantly improve the performance of infant pose estimation. We show that AggPose outperforms hybrid model HRFormer and TokenPose in the infant pose estimation dataset. Moreover, our AggPose outperforms HRFormer by 0.8 AP on COCO val pose estimation on average. Our code is available at <a target="_blank" href="https://github.com/SZAR-LAB/AggPose" title="" class="ltx_ref ltx_href">github.com/SZAR-LAB/AggPose</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Each year, approximately 5 million newborns around the world are suffering from neurodevelopmental disorder. Due to the lack of early diagnosis and intervention, many infants are severely disabled and abandoned by their parents, especially in countries with limited numbers of pediatricians with extensive experience in neurodevelopmental disorders. This has become a conundrum that plagues many families around the world.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recent developments in deep learning based approaches open possibilities for developing computer-aid movement assessment tools in early intervention for neurodevelopmental disorder. One of the most predictive tools for early cerebral palsy diagnosis is general movements assessment (GMA), as it needs to discriminate fidgety from non-fidgety movements in many small-amplitude movementsÂ <cite class="ltx_cite ltx_citemacro_cite">Silva <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>, where computers are more sensitive to detect such movements. Researchers used human pose estimation methods like OpenPoseÂ <cite class="ltx_cite ltx_citemacro_cite">Cao <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite> to capture infant pose and then generate infant motion sequence to detect cerebral palsy. Compared with manual GMA detection, computer-based approaches are much faster with low cost. However, this task is challenging in real applications considering complex scenarios for infant pose and there is a lack of large-scale public infant pose datasets around the world. Besides, the 17 adult keypoints defined by the COCO dataset do not support infant movement detection well due to the lack of clinical significance and actionability.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Another problem is the performance of the pose estimation methods. Although CNN-based methods have pushed human pose estimation to a new level thanks to the intense representation learning and semantics understanding ability, it is still not performing well to understand global constraint relationships between body partsÂ <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>. Researchers combined Vision Transformer with CNN into hybrid models to address this issue, let the ViT expand the receptive field, and enhance the modelâ€™s ability to capture constraint relationships between body parts. Among recent advancements, the local-window self-attention structure from Swin TransformerÂ <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>, and Mix Feed Forward Network (Mix-FNN) from SegFormerÂ <cite class="ltx_cite ltx_citemacro_cite">Xie <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> showed great potential in the direction of multi-scale feature representation learningÂ <cite class="ltx_cite ltx_citemacro_cite">Gu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">However, some issues still make it challenging to apply Transformer for human pose estimation: (1) The first stages of the hybrid models highly rely on the pretrained HRNet convolutional layers, which can not utilize large-scale unlabeled data with newest self-supervised masked autoencoderÂ <cite class="ltx_cite ltx_citemacro_cite">He <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite>; (2) Hard to converge during the training process; (3) Models are challenging to transfer from one domain to another domain.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this paper, we propose AggPose, a generalization of multi-scale transformer architecture to the deep aggregation network. Different from HRFormer, AggPose does not use convolutional layers for initial feature extractor and fusion modules. Instead, it uses layer-by-layer Mix Transformers and a cross-resolution MLP fusion module. The Transformer receives input from the former layer, applies self-attention operation and Mix-FNN, and sends the message to the next layer. The MLP fusion module integrates richer spatial information from different resolution levels and sends the result to the next stage.
We conduct experiments on COCO human pose estimation dataset and then fine-tune the model on our proposed large-scale labeled infant pose estimation dataset. AggPose achieves competitive performance on both benchmarks. For example, AggPose-L gains 0.8 AP and 0.6 AP over HRFormer and TokenPose on COCO val set. AggPose-Lâ€™s robustness and fast convergence make it easy to transfer from the COCO dataset to our infant pose dataset and achieve the highest 95.0 AP.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The contributions are summarized as follows:</p>
</div>
<div id="S1.p7" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose a new Transformer + MLP based aggregation architecture without using HRNetâ€™s CNN backbone and CNN-based multi-scale fusion modules.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">To enhance the efficiency of deep layer aggregation, we design a special deep aggregation MLP structure to fuse information across different resolutions.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">To facilitate research in early intervention for neurodevelopmental disorders, we present a large-scale infant challenging dataset including 20,748 pose labeled images. Experimental results show our frameworkâ€™s robustness in both COCO and this new dataset. To the best of our knowledge, this is the largest dataset constructed for infant pose estimation for clinical application.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Infant Pose Estimation</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Infant pose estimation has been found to have high application value in clinical research. Most commonly used cerebral palsy assessment tools such as GMA and CPVCÂ <cite class="ltx_cite ltx_citemacro_cite">Abbruzzese <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib1" title="" class="ltx_ref">2020</a>)</cite> are already using automatic pose estimation methods to aid diagnosis. However, most existing algorithms are based on traditional machine learning methods for automatic infant pose estimation, limiting their capability to deal with complex conditionsÂ <cite class="ltx_cite ltx_citemacro_cite">Silva <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>. Meanwhile, there are very few attempts initiated by the artificial intelligence community to handle infant images. Only <cite class="ltx_cite ltx_citemacro_cite">McCay <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>); Reich <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite> gave primacy attempts to adopt OpenPoseÂ <cite class="ltx_cite ltx_citemacro_cite">Cao <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite> to extract key-points for infants but lack a large and general dataset. MINI-RGBDÂ <cite class="ltx_cite ltx_citemacro_cite">Hesse <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2018</a>)</cite> is the most famous open-source dataset in this field, where it only contains 700 authentic infant images and a small set of synthesized infant images. All of these make automatic infant pose assessment methods unreliable in the real world clinical systems.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F1.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2205.05277/assets/x1.jpg" id="S2.F1.1.g1" class="ltx_graphics ltx_img_square" width="266" height="270" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F1.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2205.05277/assets/x2.jpg" id="S2.F1.2.g1" class="ltx_graphics ltx_img_square" width="266" height="318" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>(a) Examples for our proposed InfantPose dataset. (b) 21 infant body key-points</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Vision Transformers for Pose Estimation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">For many years, deep convolutional neural networks have been applied to human pose estimation. Among all CNN-based pose estimation algorithms, the schemes that maintain high-resolution representations throughout the network achieved great success. The most representative models are HRNetÂ <cite class="ltx_cite ltx_citemacro_cite">Wang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, HigherHRNetÂ <cite class="ltx_cite ltx_citemacro_cite">Cheng <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>, UDPÂ <cite class="ltx_cite ltx_citemacro_cite">Huang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>, DARKÂ <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>. However, it is still tricky for CNNs to capture constraint relationships between human keypoints, as CNNâ€™s receptive field restrict its ability to understand global spatial relationships.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Recent several works have introduced Transformer for human pose estimationÂ <cite class="ltx_cite ltx_citemacro_cite">Yuan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>); Yang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>); Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>. TokenPoseÂ <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite> introduced Transformer with representing key-points as token embeddings for human Pose estimation. HRFormerÂ <cite class="ltx_cite ltx_citemacro_cite">Yuan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> integrated HRNet with Swin TransformerÂ <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>, which makes full use of multi-resolution parallel information over different non-overlapping image windows. However, both HRFormer and TokenPose did not discard convolution operations to obtain initial features, as the first stage of HRFormer and TokenPose were fine-tuned on HRNetâ€™s CNN backbone. In this work, we propose Aggregation Vision Transformers (AViT), which provides a different way to solve the low-resolution problem of ViT and replace convolution operations with overlapping patch embedding to extract features in the early stages.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our goal is to propose a new infant pose dataset and build a new benchmark that can fast extract infant pose via vision transformers. FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.1 Infant Pose Detection Dataset â€£ 3 Proposed Method â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the pipeline of the model. Our infant pose estimation research have passed the ethics checks of Shenzhen Baoan Womenâ€™s and Childirenâ€™s Hospital.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Infant Pose Detection Dataset</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In this paper, we present a large-scale challenging dataset for newborn pose extraction and detection. It can be applied to predict infant movement sequence and design automatic clinical tools like automatic GMA. Despite the importance and difficulty of infant pose detection, existing datasets are either too small or too simple, and a large public annotated benchmark is needed to compare different methods. Besides, none of these datasets proposed suitable keypoints annotation for infant images, as they adopt the COCOâ€™s 17 keypoints format, while it loses many significant refined pose and movement features for the infant.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Dataset</th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Videos</th>
<th id="S3.T1.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Labeled Images</th>
<th id="S3.T1.1.1.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Unlabeled</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.2.1" class="ltx_tr">
<td id="S3.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">MINI RGBD</td>
<td id="S3.T1.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">12</td>
<td id="S3.T1.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">700</td>
<td id="S3.T1.1.2.1.4" class="ltx_td ltx_align_right ltx_border_t">-</td>
</tr>
<tr id="S3.T1.1.3.2" class="ltx_tr">
<td id="S3.T1.1.3.2.1" class="ltx_td ltx_align_left">COCO (infant)</td>
<td id="S3.T1.1.3.2.2" class="ltx_td ltx_align_right">0</td>
<td id="S3.T1.1.3.2.3" class="ltx_td ltx_align_right">1904</td>
<td id="S3.T1.1.3.2.4" class="ltx_td ltx_align_right">-</td>
</tr>
<tr id="S3.T1.1.4.3" class="ltx_tr">
<td id="S3.T1.1.4.3.1" class="ltx_td ltx_align_left">SyRIP</td>
<td id="S3.T1.1.4.3.2" class="ltx_td ltx_align_right">0</td>
<td id="S3.T1.1.4.3.3" class="ltx_td ltx_align_right">1700</td>
<td id="S3.T1.1.4.3.4" class="ltx_td ltx_align_right">-</td>
</tr>
<tr id="S3.T1.1.5.4" class="ltx_tr">
<td id="S3.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_border_bb">Ours</td>
<td id="S3.T1.1.5.4.2" class="ltx_td ltx_align_right ltx_border_bb">5187</td>
<td id="S3.T1.1.5.4.3" class="ltx_td ltx_align_right ltx_border_bb">20748</td>
<td id="S3.T1.1.5.4.4" class="ltx_td ltx_align_right ltx_border_bb">15 million</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison between other infant pose dataset.</figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Inspired by Â <cite class="ltx_cite ltx_citemacro_cite">Silva <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>); Huang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>, we publish our new open-source infant pose dataset and new infant keypoints format. To collect data, we adopt GMA devices to record infant movement videos from 2013 to now. More than 216 hours of videos were collected, and 15 million frames were extracted. Both the size and the scalability of our dataset are much better than the MINI-RGBD datasetÂ <cite class="ltx_cite ltx_citemacro_cite">Hesse <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2018</a>)</cite>. We randomly sampled 20,748 frames from the videos and let professional clinicians annotate infant keypoints. Then, we divided the dataset into 11,756 for the training set and validation set, 8,992 for the test set. The 21 keypoints format for infant pose is proposed by experienced clinicians who have researched neurodevelopmental disorders over 30 years.FigureÂ <a href="#S2.F1" title="Figure 1 â€£ 2.1 Infant Pose Estimation â€£ 2 Related Works â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows some examples, considering clinical application requirements and protection of patientâ€™s privacy, our dataset reduces keypoints on infantsâ€™ heads and comprises more refined body keypoints like fingers, toes, and navel. For public version, we will reformat the dataset to solve ethical issues: all infantsâ€™ heads will be covered with mosaics in the final published keypoint dataset to preserve the patientsâ€™ privacy. Commercial usage of infant pose dataset is prohibited.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2205.05277/assets/x3.jpg" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="210" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The proposed AggPose architecture. Each module consists of multiple successive Mix Transformer blocks. Features across different resolutions are connected by MLP layer (blue square in the figure).</figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In this paper, we focus on the human/infant supine position pose detection, which is the most straightforward application for the new presented dataset. However, this dataset can also be used in other clinical fields, as it contains over 200 hours of infant movement sequence and has a high relationship with the automated prediction of cerebral palsy and other neurodevelopmental disorders. We hope applying our dataset and AggPose to early diagnosis and intervene disorders, promoting well-being for all at all ages, especially the children. In the future, we will also release more than 200 hours of new infant pose sequences generated from AggPose, and associated GMA labels. The retrospective study was approved by our institutional review board.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Deep Aggregation Vision Transformers</h3>

<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Overlapped Patch Embedding</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Early convolutions were considered practical tools to extract low-level features for hybrid transformer architectures. It is due to that transformers in the early stage treat the input as 1D vectors and exclusively focus on modeling the global context, which lose detailed localization information. HRNet and its pre-trained CNN parameters are the cornerstones of almost all the latest models for human pose estimation. Inspired by SegFormerÂ <cite class="ltx_cite ltx_citemacro_cite">Xie <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite>, we adopt full Transformer with Overlapped Patch Embedding to replace HRNetâ€™s CNN feature extractor and down-sampling stem of each stage. Compared with the early convolutions in HRNet, HRFormer, and TokenPose, Overlapped Patch Embedding can obtain better low-level features, enhancing the high-resolution Transformerâ€™s feature representation, and reduce computation complexity.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Aggregation Vision Transformers (AViTs) Architecture</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">We follow the transformer module design from Mix TransformerÂ <cite class="ltx_cite ltx_citemacro_cite">Xie <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> and start from high-resolution feature maps generated by the overlapped patch embedding with patch size = 7, stride = 4, and padding size = 3 as the first stage. Then, we add high-to-low resolution streams one by one via overlapped patch embedding. We use multiple multi-head self-attention blocks for each resolution stream to update feature representation. To construct different depth of models, we propose small (AggPose-S), and large (AggPose-L) model, respectively. TableÂ <a href="#S3.T2" title="Table 2 â€£ 3.2.2 Aggregation Vision Transformers (AViTs) Architecture â€£ 3.2 Deep Aggregation Vision Transformers â€£ 3 Proposed Method â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the number of transformer layers for each stage in AggPose-L.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">Compared with Swin Transformer and HRFormer, we do not use local-window self-attention to augment local information understanding considering the usage of overlapped patches. Instead, we use the sequence reduction process refer to <cite class="ltx_cite ltx_citemacro_cite">Xie <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Wang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>, which significantly reduces the amount of calculation inside the transformer and accelerates the convergence process during model training. For each Transformer block, the self-attention is estimated as:</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<table id="Sx1.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.m1.1" class="ltx_math_unparsed" alttext="\displaystyle K=Linear(\gamma C,C)(K.Reshape(\frac{N}{\gamma},\gamma C))" display="inline"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1b"><mi id="S3.E1.m1.1.2">K</mi><mo id="S3.E1.m1.1.3">=</mo><mi id="S3.E1.m1.1.4">L</mi><mi id="S3.E1.m1.1.5">i</mi><mi id="S3.E1.m1.1.6">n</mi><mi id="S3.E1.m1.1.7">e</mi><mi id="S3.E1.m1.1.8">a</mi><mi id="S3.E1.m1.1.9">r</mi><mrow id="S3.E1.m1.1.10"><mo stretchy="false" id="S3.E1.m1.1.10.1">(</mo><mi id="S3.E1.m1.1.10.2">Î³</mi><mi id="S3.E1.m1.1.10.3">C</mi><mo id="S3.E1.m1.1.10.4">,</mo><mi id="S3.E1.m1.1.1">C</mi><mo stretchy="false" id="S3.E1.m1.1.10.5">)</mo></mrow><mrow id="S3.E1.m1.1.11"><mo stretchy="false" id="S3.E1.m1.1.11.1">(</mo><mi id="S3.E1.m1.1.11.2">K</mi><mo lspace="0em" rspace="0.167em" id="S3.E1.m1.1.11.3">.</mo><mi id="S3.E1.m1.1.11.4">R</mi><mi id="S3.E1.m1.1.11.5">e</mi><mi id="S3.E1.m1.1.11.6">s</mi><mi id="S3.E1.m1.1.11.7">h</mi><mi id="S3.E1.m1.1.11.8">a</mi><mi id="S3.E1.m1.1.11.9">p</mi><mi id="S3.E1.m1.1.11.10">e</mi><mrow id="S3.E1.m1.1.11.11"><mo stretchy="false" id="S3.E1.m1.1.11.11.1">(</mo><mstyle displaystyle="true" id="S3.E1.m1.1.11.11.2"><mfrac id="S3.E1.m1.1.11.11.2a"><mi id="S3.E1.m1.1.11.11.2.2">N</mi><mi id="S3.E1.m1.1.11.11.2.3">Î³</mi></mfrac></mstyle><mo id="S3.E1.m1.1.11.11.3">,</mo><mi id="S3.E1.m1.1.11.11.4">Î³</mi><mi id="S3.E1.m1.1.11.11.5">C</mi><mo stretchy="false" id="S3.E1.m1.1.11.11.6">)</mo></mrow><mo stretchy="false" id="S3.E1.m1.1.11.12">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\displaystyle K=Linear(\gamma C,C)(K.Reshape(\frac{N}{\gamma},\gamma C))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.4" class="ltx_Math" alttext="\displaystyle Attention(Q,K,V)=Softmax(\frac{QK^{T}}{\sqrt{d_{head}}})V" display="inline"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.5" xref="S3.E2.m1.4.5.cmml"><mrow id="S3.E2.m1.4.5.2" xref="S3.E2.m1.4.5.2.cmml"><mi id="S3.E2.m1.4.5.2.2" xref="S3.E2.m1.4.5.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1" xref="S3.E2.m1.4.5.2.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.2.3" xref="S3.E2.m1.4.5.2.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1a" xref="S3.E2.m1.4.5.2.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.2.4" xref="S3.E2.m1.4.5.2.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1b" xref="S3.E2.m1.4.5.2.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.2.5" xref="S3.E2.m1.4.5.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1c" xref="S3.E2.m1.4.5.2.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.2.6" xref="S3.E2.m1.4.5.2.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1d" xref="S3.E2.m1.4.5.2.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.2.7" xref="S3.E2.m1.4.5.2.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1e" xref="S3.E2.m1.4.5.2.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.2.8" xref="S3.E2.m1.4.5.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1f" xref="S3.E2.m1.4.5.2.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.2.9" xref="S3.E2.m1.4.5.2.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1g" xref="S3.E2.m1.4.5.2.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.2.10" xref="S3.E2.m1.4.5.2.10.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.2.1h" xref="S3.E2.m1.4.5.2.1.cmml">â€‹</mo><mrow id="S3.E2.m1.4.5.2.11.2" xref="S3.E2.m1.4.5.2.11.1.cmml"><mo stretchy="false" id="S3.E2.m1.4.5.2.11.2.1" xref="S3.E2.m1.4.5.2.11.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">Q</mi><mo id="S3.E2.m1.4.5.2.11.2.2" xref="S3.E2.m1.4.5.2.11.1.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">K</mi><mo id="S3.E2.m1.4.5.2.11.2.3" xref="S3.E2.m1.4.5.2.11.1.cmml">,</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">V</mi><mo stretchy="false" id="S3.E2.m1.4.5.2.11.2.4" xref="S3.E2.m1.4.5.2.11.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.5.1" xref="S3.E2.m1.4.5.1.cmml">=</mo><mrow id="S3.E2.m1.4.5.3" xref="S3.E2.m1.4.5.3.cmml"><mi id="S3.E2.m1.4.5.3.2" xref="S3.E2.m1.4.5.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1" xref="S3.E2.m1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.3.3" xref="S3.E2.m1.4.5.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1a" xref="S3.E2.m1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.3.4" xref="S3.E2.m1.4.5.3.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1b" xref="S3.E2.m1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.3.5" xref="S3.E2.m1.4.5.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1c" xref="S3.E2.m1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.3.6" xref="S3.E2.m1.4.5.3.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1d" xref="S3.E2.m1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.3.7" xref="S3.E2.m1.4.5.3.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1e" xref="S3.E2.m1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.3.8" xref="S3.E2.m1.4.5.3.8.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1f" xref="S3.E2.m1.4.5.3.1.cmml">â€‹</mo><mrow id="S3.E2.m1.4.5.3.9.2" xref="S3.E2.m1.4.4.cmml"><mo stretchy="false" id="S3.E2.m1.4.5.3.9.2.1" xref="S3.E2.m1.4.4.cmml">(</mo><mstyle displaystyle="true" id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><mfrac id="S3.E2.m1.4.4a" xref="S3.E2.m1.4.4.cmml"><mrow id="S3.E2.m1.4.4.2" xref="S3.E2.m1.4.4.2.cmml"><mi id="S3.E2.m1.4.4.2.2" xref="S3.E2.m1.4.4.2.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.2.1" xref="S3.E2.m1.4.4.2.1.cmml">â€‹</mo><msup id="S3.E2.m1.4.4.2.3" xref="S3.E2.m1.4.4.2.3.cmml"><mi id="S3.E2.m1.4.4.2.3.2" xref="S3.E2.m1.4.4.2.3.2.cmml">K</mi><mi id="S3.E2.m1.4.4.2.3.3" xref="S3.E2.m1.4.4.2.3.3.cmml">T</mi></msup></mrow><msqrt id="S3.E2.m1.4.4.3" xref="S3.E2.m1.4.4.3.cmml"><msub id="S3.E2.m1.4.4.3.2" xref="S3.E2.m1.4.4.3.2.cmml"><mi id="S3.E2.m1.4.4.3.2.2" xref="S3.E2.m1.4.4.3.2.2.cmml">d</mi><mrow id="S3.E2.m1.4.4.3.2.3" xref="S3.E2.m1.4.4.3.2.3.cmml"><mi id="S3.E2.m1.4.4.3.2.3.2" xref="S3.E2.m1.4.4.3.2.3.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.3.2.3.1" xref="S3.E2.m1.4.4.3.2.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.4.3.2.3.3" xref="S3.E2.m1.4.4.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.3.2.3.1a" xref="S3.E2.m1.4.4.3.2.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.4.3.2.3.4" xref="S3.E2.m1.4.4.3.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.3.2.3.1b" xref="S3.E2.m1.4.4.3.2.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.4.3.2.3.5" xref="S3.E2.m1.4.4.3.2.3.5.cmml">d</mi></mrow></msub></msqrt></mfrac></mstyle><mo stretchy="false" id="S3.E2.m1.4.5.3.9.2.2" xref="S3.E2.m1.4.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.5.3.1g" xref="S3.E2.m1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.4.5.3.10" xref="S3.E2.m1.4.5.3.10.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.5.cmml" xref="S3.E2.m1.4.5"><eq id="S3.E2.m1.4.5.1.cmml" xref="S3.E2.m1.4.5.1"></eq><apply id="S3.E2.m1.4.5.2.cmml" xref="S3.E2.m1.4.5.2"><times id="S3.E2.m1.4.5.2.1.cmml" xref="S3.E2.m1.4.5.2.1"></times><ci id="S3.E2.m1.4.5.2.2.cmml" xref="S3.E2.m1.4.5.2.2">ğ´</ci><ci id="S3.E2.m1.4.5.2.3.cmml" xref="S3.E2.m1.4.5.2.3">ğ‘¡</ci><ci id="S3.E2.m1.4.5.2.4.cmml" xref="S3.E2.m1.4.5.2.4">ğ‘¡</ci><ci id="S3.E2.m1.4.5.2.5.cmml" xref="S3.E2.m1.4.5.2.5">ğ‘’</ci><ci id="S3.E2.m1.4.5.2.6.cmml" xref="S3.E2.m1.4.5.2.6">ğ‘›</ci><ci id="S3.E2.m1.4.5.2.7.cmml" xref="S3.E2.m1.4.5.2.7">ğ‘¡</ci><ci id="S3.E2.m1.4.5.2.8.cmml" xref="S3.E2.m1.4.5.2.8">ğ‘–</ci><ci id="S3.E2.m1.4.5.2.9.cmml" xref="S3.E2.m1.4.5.2.9">ğ‘œ</ci><ci id="S3.E2.m1.4.5.2.10.cmml" xref="S3.E2.m1.4.5.2.10">ğ‘›</ci><vector id="S3.E2.m1.4.5.2.11.1.cmml" xref="S3.E2.m1.4.5.2.11.2"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ğ‘„</ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">ğ¾</ci><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">ğ‘‰</ci></vector></apply><apply id="S3.E2.m1.4.5.3.cmml" xref="S3.E2.m1.4.5.3"><times id="S3.E2.m1.4.5.3.1.cmml" xref="S3.E2.m1.4.5.3.1"></times><ci id="S3.E2.m1.4.5.3.2.cmml" xref="S3.E2.m1.4.5.3.2">ğ‘†</ci><ci id="S3.E2.m1.4.5.3.3.cmml" xref="S3.E2.m1.4.5.3.3">ğ‘œ</ci><ci id="S3.E2.m1.4.5.3.4.cmml" xref="S3.E2.m1.4.5.3.4">ğ‘“</ci><ci id="S3.E2.m1.4.5.3.5.cmml" xref="S3.E2.m1.4.5.3.5">ğ‘¡</ci><ci id="S3.E2.m1.4.5.3.6.cmml" xref="S3.E2.m1.4.5.3.6">ğ‘š</ci><ci id="S3.E2.m1.4.5.3.7.cmml" xref="S3.E2.m1.4.5.3.7">ğ‘</ci><ci id="S3.E2.m1.4.5.3.8.cmml" xref="S3.E2.m1.4.5.3.8">ğ‘¥</ci><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.5.3.9.2"><divide id="S3.E2.m1.4.4.1.cmml" xref="S3.E2.m1.4.5.3.9.2"></divide><apply id="S3.E2.m1.4.4.2.cmml" xref="S3.E2.m1.4.4.2"><times id="S3.E2.m1.4.4.2.1.cmml" xref="S3.E2.m1.4.4.2.1"></times><ci id="S3.E2.m1.4.4.2.2.cmml" xref="S3.E2.m1.4.4.2.2">ğ‘„</ci><apply id="S3.E2.m1.4.4.2.3.cmml" xref="S3.E2.m1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.2.3.1.cmml" xref="S3.E2.m1.4.4.2.3">superscript</csymbol><ci id="S3.E2.m1.4.4.2.3.2.cmml" xref="S3.E2.m1.4.4.2.3.2">ğ¾</ci><ci id="S3.E2.m1.4.4.2.3.3.cmml" xref="S3.E2.m1.4.4.2.3.3">ğ‘‡</ci></apply></apply><apply id="S3.E2.m1.4.4.3.cmml" xref="S3.E2.m1.4.4.3"><root id="S3.E2.m1.4.4.3a.cmml" xref="S3.E2.m1.4.4.3"></root><apply id="S3.E2.m1.4.4.3.2.cmml" xref="S3.E2.m1.4.4.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.2.1.cmml" xref="S3.E2.m1.4.4.3.2">subscript</csymbol><ci id="S3.E2.m1.4.4.3.2.2.cmml" xref="S3.E2.m1.4.4.3.2.2">ğ‘‘</ci><apply id="S3.E2.m1.4.4.3.2.3.cmml" xref="S3.E2.m1.4.4.3.2.3"><times id="S3.E2.m1.4.4.3.2.3.1.cmml" xref="S3.E2.m1.4.4.3.2.3.1"></times><ci id="S3.E2.m1.4.4.3.2.3.2.cmml" xref="S3.E2.m1.4.4.3.2.3.2">â„</ci><ci id="S3.E2.m1.4.4.3.2.3.3.cmml" xref="S3.E2.m1.4.4.3.2.3.3">ğ‘’</ci><ci id="S3.E2.m1.4.4.3.2.3.4.cmml" xref="S3.E2.m1.4.4.3.2.3.4">ğ‘</ci><ci id="S3.E2.m1.4.4.3.2.3.5.cmml" xref="S3.E2.m1.4.4.3.2.3.5">ğ‘‘</ci></apply></apply></apply></apply><ci id="S3.E2.m1.4.5.3.10.cmml" xref="S3.E2.m1.4.5.3.10">ğ‘‰</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\displaystyle Attention(Q,K,V)=Softmax(\frac{QK^{T}}{\sqrt{d_{head}}})V</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<p id="S3.SS2.SSS2.p4.4" class="ltx_p">,where K is the token representation with initial shape <math id="S3.SS2.SSS2.p4.1.m1.1" class="ltx_Math" alttext="N\times C" display="inline"><semantics id="S3.SS2.SSS2.p4.1.m1.1a"><mrow id="S3.SS2.SSS2.p4.1.m1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p4.1.m1.1.1.2" xref="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p4.1.m1.1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.SSS2.p4.1.m1.1.1.3" xref="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.1.m1.1b"><apply id="S3.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1"><times id="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.1"></times><ci id="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.2">ğ‘</ci><ci id="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.3">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.1.m1.1c">N\times C</annotation></semantics></math>. <math id="S3.SS2.SSS2.p4.2.m2.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.SS2.SSS2.p4.2.m2.1a"><mi id="S3.SS2.SSS2.p4.2.m2.1.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.2.m2.1b"><ci id="S3.SS2.SSS2.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.2.m2.1c">\gamma</annotation></semantics></math> is the reduction ratio that decrease the dimension of K from <math id="S3.SS2.SSS2.p4.3.m3.1" class="ltx_Math" alttext="N\times C" display="inline"><semantics id="S3.SS2.SSS2.p4.3.m3.1a"><mrow id="S3.SS2.SSS2.p4.3.m3.1.1" xref="S3.SS2.SSS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p4.3.m3.1.1.2" xref="S3.SS2.SSS2.p4.3.m3.1.1.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p4.3.m3.1.1.1" xref="S3.SS2.SSS2.p4.3.m3.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.SSS2.p4.3.m3.1.1.3" xref="S3.SS2.SSS2.p4.3.m3.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.3.m3.1b"><apply id="S3.SS2.SSS2.p4.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1"><times id="S3.SS2.SSS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1.1"></times><ci id="S3.SS2.SSS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1.2">ğ‘</ci><ci id="S3.SS2.SSS2.p4.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1.3">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.3.m3.1c">N\times C</annotation></semantics></math> to <math id="S3.SS2.SSS2.p4.4.m4.1" class="ltx_Math" alttext="N/\gamma\times C" display="inline"><semantics id="S3.SS2.SSS2.p4.4.m4.1a"><mrow id="S3.SS2.SSS2.p4.4.m4.1.1" xref="S3.SS2.SSS2.p4.4.m4.1.1.cmml"><mrow id="S3.SS2.SSS2.p4.4.m4.1.1.2" xref="S3.SS2.SSS2.p4.4.m4.1.1.2.cmml"><mi id="S3.SS2.SSS2.p4.4.m4.1.1.2.2" xref="S3.SS2.SSS2.p4.4.m4.1.1.2.2.cmml">N</mi><mo id="S3.SS2.SSS2.p4.4.m4.1.1.2.1" xref="S3.SS2.SSS2.p4.4.m4.1.1.2.1.cmml">/</mo><mi id="S3.SS2.SSS2.p4.4.m4.1.1.2.3" xref="S3.SS2.SSS2.p4.4.m4.1.1.2.3.cmml">Î³</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p4.4.m4.1.1.1" xref="S3.SS2.SSS2.p4.4.m4.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.SSS2.p4.4.m4.1.1.3" xref="S3.SS2.SSS2.p4.4.m4.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.4.m4.1b"><apply id="S3.SS2.SSS2.p4.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.1"><times id="S3.SS2.SSS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.1.1"></times><apply id="S3.SS2.SSS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.1.2"><divide id="S3.SS2.SSS2.p4.4.m4.1.1.2.1.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.1.2.1"></divide><ci id="S3.SS2.SSS2.p4.4.m4.1.1.2.2.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.1.2.2">ğ‘</ci><ci id="S3.SS2.SSS2.p4.4.m4.1.1.2.3.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.1.2.3">ğ›¾</ci></apply><ci id="S3.SS2.SSS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.1.3">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.4.m4.1c">N/\gamma\times C</annotation></semantics></math>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Features level</th>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_right ltx_border_tt">Stage 1</td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_right ltx_border_tt">Stage 2</td>
<td id="S3.T2.1.1.1.4" class="ltx_td ltx_align_right ltx_border_tt">Stage 3</td>
<td id="S3.T2.1.1.1.5" class="ltx_td ltx_align_right ltx_border_tt">Stage 4</td>
</tr>
<tr id="S3.T2.1.2.2" class="ltx_tr">
<th id="S3.T2.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">1/4</th>
<td id="S3.T2.1.2.2.2" class="ltx_td ltx_align_right ltx_border_t">3</td>
<td id="S3.T2.1.2.2.3" class="ltx_td ltx_align_right ltx_border_t">3</td>
<td id="S3.T2.1.2.2.4" class="ltx_td ltx_align_right ltx_border_t">3</td>
<td id="S3.T2.1.2.2.5" class="ltx_td ltx_align_right ltx_border_t">3</td>
</tr>
<tr id="S3.T2.1.3.3" class="ltx_tr">
<th id="S3.T2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1/8</th>
<td id="S3.T2.1.3.3.2" class="ltx_td"></td>
<td id="S3.T2.1.3.3.3" class="ltx_td ltx_align_right">6</td>
<td id="S3.T2.1.3.3.4" class="ltx_td ltx_align_right">3</td>
<td id="S3.T2.1.3.3.5" class="ltx_td ltx_align_right">3</td>
</tr>
<tr id="S3.T2.1.4.4" class="ltx_tr">
<th id="S3.T2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1/16</th>
<td id="S3.T2.1.4.4.2" class="ltx_td"></td>
<td id="S3.T2.1.4.4.3" class="ltx_td"></td>
<td id="S3.T2.1.4.4.4" class="ltx_td ltx_align_right">40</td>
<td id="S3.T2.1.4.4.5" class="ltx_td ltx_align_right">3</td>
</tr>
<tr id="S3.T2.1.5.5" class="ltx_tr">
<th id="S3.T2.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">1/32</th>
<td id="S3.T2.1.5.5.2" class="ltx_td ltx_border_bb"></td>
<td id="S3.T2.1.5.5.3" class="ltx_td ltx_border_bb"></td>
<td id="S3.T2.1.5.5.4" class="ltx_td ltx_border_bb"></td>
<td id="S3.T2.1.5.5.5" class="ltx_td ltx_align_right ltx_border_bb">3</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The number of Transformer layers for each stage.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>MLP Cross-Layer Aggregation</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">Both ViT and Swin Transformer uses positional embedding to introduce the location information across layers. However, the resolution of positional embedding is fixed. For the local-window Transformer, there is lacking information exchange across the windows. Thus, both SegFormer and HRFormer introduced <math id="S3.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S3.SS2.SSS3.p1.1.m1.1a"><mrow id="S3.SS2.SSS3.p1.1.m1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.cmml"><mn id="S3.SS2.SSS3.p1.1.m1.1.1.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS3.p1.1.m1.1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S3.SS2.SSS3.p1.1.m1.1.1.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.1.m1.1b"><apply id="S3.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1"><times id="S3.SS2.SSS3.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.2">3</cn><cn type="integer" id="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.1.m1.1c">3\times 3</annotation></semantics></math> depth-wise convolution into the feed-forward network (FFN) to expand the receptive field and reduce the harmful effect caused by positional embedding. The FFN with depth-wise convolution (HRFormer) and Mix-FFN (SegFormer) used a very similar calculation:</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<table id="Sx1.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.2" class="ltx_Math" alttext="\displaystyle y=MLP(Activation(DWConv(MLP(x))))+x" display="inline"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><mi id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">y</mi><mo id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml">=</mo><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.3" xref="S3.E3.m1.2.2.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2" xref="S3.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.4" xref="S3.E3.m1.2.2.1.1.4.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2a" xref="S3.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.5" xref="S3.E3.m1.2.2.1.1.5.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2b" xref="S3.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.3.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.4" xref="S3.E3.m1.2.2.1.1.1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2a" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.5" xref="S3.E3.m1.2.2.1.1.1.1.1.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2b" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.6" xref="S3.E3.m1.2.2.1.1.1.1.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2c" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.7" xref="S3.E3.m1.2.2.1.1.1.1.1.7.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2d" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.8" xref="S3.E3.m1.2.2.1.1.1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2e" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.9" xref="S3.E3.m1.2.2.1.1.1.1.1.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2f" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.10" xref="S3.E3.m1.2.2.1.1.1.1.1.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2g" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.11" xref="S3.E3.m1.2.2.1.1.1.1.1.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2h" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.12" xref="S3.E3.m1.2.2.1.1.1.1.1.12.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2i" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.4" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.4.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2a" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.5" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.5.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2b" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.6" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2c" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.7" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.7.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2d" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.8" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.8.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2e" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1a" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1b" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.5.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.5.2.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.5.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.2.cmml">+</mo><mi id="S3.E3.m1.2.2.1.3" xref="S3.E3.m1.2.2.1.3.cmml">x</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"></eq><ci id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3">ğ‘¦</ci><apply id="S3.E3.m1.2.2.1.cmml" xref="S3.E3.m1.2.2.1"><plus id="S3.E3.m1.2.2.1.2.cmml" xref="S3.E3.m1.2.2.1.2"></plus><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1.1"><times id="S3.E3.m1.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.2"></times><ci id="S3.E3.m1.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3">ğ‘€</ci><ci id="S3.E3.m1.2.2.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.4">ğ¿</ci><ci id="S3.E3.m1.2.2.1.1.5.cmml" xref="S3.E3.m1.2.2.1.1.5">ğ‘ƒ</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1"><times id="S3.E3.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2"></times><ci id="S3.E3.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3">ğ´</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.4">ğ‘</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.5.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.5">ğ‘¡</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.6.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.6">ğ‘–</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.7.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.7">ğ‘£</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.8.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.8">ğ‘</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.9.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.9">ğ‘¡</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.10.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.10">ğ‘–</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.11.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.11">ğ‘œ</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.12.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.12">ğ‘›</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.3">ğ·</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.4">ğ‘Š</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.5">ğ¶</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.6.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.6">ğ‘œ</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.7.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.7">ğ‘›</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.8.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.8">ğ‘£</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1"><times id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘€</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">ğ¿</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4">ğ‘ƒ</ci><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘¥</ci></apply></apply></apply></apply><ci id="S3.E3.m1.2.2.1.3.cmml" xref="S3.E3.m1.2.2.1.3">ğ‘¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">\displaystyle y=MLP(Activation(DWConv(MLP(x))))+x</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS3.p3" class="ltx_para">
<p id="S3.SS2.SSS3.p3.2" class="ltx_p">where <math id="S3.SS2.SSS3.p3.1.m1.1" class="ltx_Math" alttext="DWConv" display="inline"><semantics id="S3.SS2.SSS3.p3.1.m1.1a"><mrow id="S3.SS2.SSS3.p3.1.m1.1.1" xref="S3.SS2.SSS3.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p3.1.m1.1.1.2" xref="S3.SS2.SSS3.p3.1.m1.1.1.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p3.1.m1.1.1.1" xref="S3.SS2.SSS3.p3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p3.1.m1.1.1.3" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p3.1.m1.1.1.1a" xref="S3.SS2.SSS3.p3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p3.1.m1.1.1.4" xref="S3.SS2.SSS3.p3.1.m1.1.1.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p3.1.m1.1.1.1b" xref="S3.SS2.SSS3.p3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p3.1.m1.1.1.5" xref="S3.SS2.SSS3.p3.1.m1.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p3.1.m1.1.1.1c" xref="S3.SS2.SSS3.p3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p3.1.m1.1.1.6" xref="S3.SS2.SSS3.p3.1.m1.1.1.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p3.1.m1.1.1.1d" xref="S3.SS2.SSS3.p3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p3.1.m1.1.1.7" xref="S3.SS2.SSS3.p3.1.m1.1.1.7.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.1.m1.1b"><apply id="S3.SS2.SSS3.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1"><times id="S3.SS2.SSS3.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.1"></times><ci id="S3.SS2.SSS3.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.2">ğ·</ci><ci id="S3.SS2.SSS3.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.3">ğ‘Š</ci><ci id="S3.SS2.SSS3.p3.1.m1.1.1.4.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.4">ğ¶</ci><ci id="S3.SS2.SSS3.p3.1.m1.1.1.5.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.5">ğ‘œ</ci><ci id="S3.SS2.SSS3.p3.1.m1.1.1.6.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.6">ğ‘›</ci><ci id="S3.SS2.SSS3.p3.1.m1.1.1.7.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.7">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.1.m1.1c">DWConv</annotation></semantics></math> is a <math id="S3.SS2.SSS3.p3.2.m2.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S3.SS2.SSS3.p3.2.m2.1a"><mrow id="S3.SS2.SSS3.p3.2.m2.1.1" xref="S3.SS2.SSS3.p3.2.m2.1.1.cmml"><mn id="S3.SS2.SSS3.p3.2.m2.1.1.2" xref="S3.SS2.SSS3.p3.2.m2.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS3.p3.2.m2.1.1.1" xref="S3.SS2.SSS3.p3.2.m2.1.1.1.cmml">Ã—</mo><mn id="S3.SS2.SSS3.p3.2.m2.1.1.3" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.2.m2.1b"><apply id="S3.SS2.SSS3.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1"><times id="S3.SS2.SSS3.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.1"></times><cn type="integer" id="S3.SS2.SSS3.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.2">3</cn><cn type="integer" id="S3.SS2.SSS3.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.2.m2.1c">3\times 3</annotation></semantics></math> depth-wise convolution operation.</p>
</div>
<div id="S3.SS2.SSS3.p4" class="ltx_para">
<p id="S3.SS2.SSS3.p4.1" class="ltx_p">In AggPose, we expand the usage of Mix-FFN into the deep aggregation approach across different resolution layers. For deep aggregation in CNN such as CAggNetÂ <cite class="ltx_cite ltx_citemacro_cite">Cao and Lin (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite> and HRNet, the aggregation begins at the shallowest, high resolution layer and then iteratively merges deeper, low resolution layer. In this way, shallow features are refined as they are propagated through different stages of aggregation. Related research showed that deep aggregation structure propagates the aggregation of all resolutions instead of the preceding block alone to better preserve features. It is widely used for semantic segmentation tasks and to achieve competitive performance. In our work, the proposed cross-layer aggregation module consists of two main steps for each resolution level. First, multi-level features from different resolutions go through a mixed feed-forward network with <math id="S3.SS2.SSS3.p4.1.m1.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S3.SS2.SSS3.p4.1.m1.1a"><mrow id="S3.SS2.SSS3.p4.1.m1.1.1" xref="S3.SS2.SSS3.p4.1.m1.1.1.cmml"><mn id="S3.SS2.SSS3.p4.1.m1.1.1.2" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS3.p4.1.m1.1.1.1" xref="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml">Ã—</mo><mn id="S3.SS2.SSS3.p4.1.m1.1.1.3" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.1.m1.1b"><apply id="S3.SS2.SSS3.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1"><times id="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.SSS3.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2">3</cn><cn type="integer" id="S3.SS2.SSS3.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.1.m1.1c">3\times 3</annotation></semantics></math> depth-wise convolution to unify the channel dimension and upsample or downsample (overlapped patch embedding) the feature map to the same shape. Then, we concatenate the feature vector from adjacent levels together and adopt an additional FFN layer to fuse the cross-layer information. Compared to convolutional multi-scale fusion modules in HRFormer and HRNet, MLP fusion modules accelerate convergence while improving model performance.</p>
</div>
<div id="S3.SS2.SSS3.p5" class="ltx_para">
<table id="Sx1.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E7.m1.3" class="ltx_Math" alttext="\displaystyle x_{i,j}=\left\{\begin{array}[]{rcl}OverlappedPE_{i,j}(FFN(x_{i}))&amp;&amp;i&lt;j\\
x_{i}&amp;&amp;i=j\\
Upsample_{i,j}(FFN(x_{i}))&amp;&amp;i&gt;j\end{array}\right." display="inline"><semantics id="S3.E7.m1.3a"><mrow id="S3.E7.m1.3.4" xref="S3.E7.m1.3.4.cmml"><msub id="S3.E7.m1.3.4.2" xref="S3.E7.m1.3.4.2.cmml"><mi id="S3.E7.m1.3.4.2.2" xref="S3.E7.m1.3.4.2.2.cmml">x</mi><mrow id="S3.E7.m1.2.2.2.4" xref="S3.E7.m1.2.2.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml">i</mi><mo id="S3.E7.m1.2.2.2.4.1" xref="S3.E7.m1.2.2.2.3.cmml">,</mo><mi id="S3.E7.m1.2.2.2.2" xref="S3.E7.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S3.E7.m1.3.4.1" xref="S3.E7.m1.3.4.1.cmml">=</mo><mrow id="S3.E7.m1.3.4.3.2" xref="S3.E7.m1.3.4.3.1.cmml"><mo id="S3.E7.m1.3.4.3.2.1" xref="S3.E7.m1.3.4.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S3.E7.m1.3.3" xref="S3.E7.m1.3.3.cmml"><mtr id="S3.E7.m1.3.3a" xref="S3.E7.m1.3.3.cmml"><mtd class="ltx_align_right" columnalign="right" id="S3.E7.m1.3.3b" xref="S3.E7.m1.3.3.cmml"><mrow id="S3.E4.3.3" xref="S3.E4.3.3.cmml"><mi id="S3.E4.3.3.5" xref="S3.E4.3.3.5.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.6" xref="S3.E4.3.3.6.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4a" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.7" xref="S3.E4.3.3.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4b" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.8" xref="S3.E4.3.3.8.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4c" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.9" xref="S3.E4.3.3.9.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4d" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.10" xref="S3.E4.3.3.10.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4e" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.11" xref="S3.E4.3.3.11.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4f" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.12" xref="S3.E4.3.3.12.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4g" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.13" xref="S3.E4.3.3.13.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4h" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.14" xref="S3.E4.3.3.14.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4i" xref="S3.E4.3.3.4.cmml">â€‹</mo><mi id="S3.E4.3.3.15" xref="S3.E4.3.3.15.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4j" xref="S3.E4.3.3.4.cmml">â€‹</mo><msub id="S3.E4.3.3.16" xref="S3.E4.3.3.16.cmml"><mi id="S3.E4.3.3.16.2" xref="S3.E4.3.3.16.2.cmml">E</mi><mrow id="S3.E4.2.2.2.2.4" xref="S3.E4.2.2.2.2.3.cmml"><mi id="S3.E4.1.1.1.1.1" xref="S3.E4.1.1.1.1.1.cmml">i</mi><mo id="S3.E4.2.2.2.2.4.1" xref="S3.E4.2.2.2.2.3.cmml">,</mo><mi id="S3.E4.2.2.2.2.2" xref="S3.E4.2.2.2.2.2.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E4.3.3.4k" xref="S3.E4.3.3.4.cmml">â€‹</mo><mrow id="S3.E4.3.3.3.1" xref="S3.E4.3.3.3.1.1.cmml"><mo stretchy="false" id="S3.E4.3.3.3.1.2" xref="S3.E4.3.3.3.1.1.cmml">(</mo><mrow id="S3.E4.3.3.3.1.1" xref="S3.E4.3.3.3.1.1.cmml"><mi id="S3.E4.3.3.3.1.1.3" xref="S3.E4.3.3.3.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.3.1.1.2" xref="S3.E4.3.3.3.1.1.2.cmml">â€‹</mo><mi id="S3.E4.3.3.3.1.1.4" xref="S3.E4.3.3.3.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.3.1.1.2a" xref="S3.E4.3.3.3.1.1.2.cmml">â€‹</mo><mi id="S3.E4.3.3.3.1.1.5" xref="S3.E4.3.3.3.1.1.5.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E4.3.3.3.1.1.2b" xref="S3.E4.3.3.3.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.3.3.3.1.1.1.1" xref="S3.E4.3.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.3.3.3.1.1.1.1.2" xref="S3.E4.3.3.3.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.3.3.3.1.1.1.1.1" xref="S3.E4.3.3.3.1.1.1.1.1.cmml"><mi id="S3.E4.3.3.3.1.1.1.1.1.2" xref="S3.E4.3.3.3.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E4.3.3.3.1.1.1.1.1.3" xref="S3.E4.3.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E4.3.3.3.1.1.1.1.3" xref="S3.E4.3.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E4.3.3.3.1.3" xref="S3.E4.3.3.3.1.1.cmml">)</mo></mrow></mrow></mtd><mtd id="S3.E7.m1.3.3c" xref="S3.E7.m1.3.3.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E7.m1.3.3d" xref="S3.E7.m1.3.3.cmml"><mrow id="S3.E4.5.1" xref="S3.E4.5.1.cmml"><mi id="S3.E4.5.1.2" xref="S3.E4.5.1.2.cmml">i</mi><mo id="S3.E4.5.1.1" xref="S3.E4.5.1.1.cmml">&lt;</mo><mi id="S3.E4.5.1.3" xref="S3.E4.5.1.3.cmml">j</mi></mrow></mtd></mtr><mtr id="S3.E7.m1.3.3e" xref="S3.E7.m1.3.3.cmml"><mtd class="ltx_align_right" columnalign="right" id="S3.E7.m1.3.3f" xref="S3.E7.m1.3.3.cmml"><msub id="S3.E5.1.1" xref="S3.E5.1.1.cmml"><mi id="S3.E5.1.1.2" xref="S3.E5.1.1.2.cmml">x</mi><mi id="S3.E5.1.1.3" xref="S3.E5.1.1.3.cmml">i</mi></msub></mtd><mtd id="S3.E7.m1.3.3g" xref="S3.E7.m1.3.3.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E7.m1.3.3h" xref="S3.E7.m1.3.3.cmml"><mrow id="S3.E5.3.1" xref="S3.E5.3.1.cmml"><mi id="S3.E5.3.1.2" xref="S3.E5.3.1.2.cmml">i</mi><mo id="S3.E5.3.1.1" xref="S3.E5.3.1.1.cmml">=</mo><mi id="S3.E5.3.1.3" xref="S3.E5.3.1.3.cmml">j</mi></mrow></mtd></mtr><mtr id="S3.E7.m1.3.3i" xref="S3.E7.m1.3.3.cmml"><mtd class="ltx_align_right" columnalign="right" id="S3.E7.m1.3.3j" xref="S3.E7.m1.3.3.cmml"><mrow id="S3.E6.3.3" xref="S3.E6.3.3.cmml"><mi id="S3.E6.3.3.5" xref="S3.E6.3.3.5.cmml">U</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.4" xref="S3.E6.3.3.4.cmml">â€‹</mo><mi id="S3.E6.3.3.6" xref="S3.E6.3.3.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.4a" xref="S3.E6.3.3.4.cmml">â€‹</mo><mi id="S3.E6.3.3.7" xref="S3.E6.3.3.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.4b" xref="S3.E6.3.3.4.cmml">â€‹</mo><mi id="S3.E6.3.3.8" xref="S3.E6.3.3.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.4c" xref="S3.E6.3.3.4.cmml">â€‹</mo><mi id="S3.E6.3.3.9" xref="S3.E6.3.3.9.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.4d" xref="S3.E6.3.3.4.cmml">â€‹</mo><mi id="S3.E6.3.3.10" xref="S3.E6.3.3.10.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.4e" xref="S3.E6.3.3.4.cmml">â€‹</mo><mi id="S3.E6.3.3.11" xref="S3.E6.3.3.11.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.4f" xref="S3.E6.3.3.4.cmml">â€‹</mo><msub id="S3.E6.3.3.12" xref="S3.E6.3.3.12.cmml"><mi id="S3.E6.3.3.12.2" xref="S3.E6.3.3.12.2.cmml">e</mi><mrow id="S3.E6.2.2.2.2.4" xref="S3.E6.2.2.2.2.3.cmml"><mi id="S3.E6.1.1.1.1.1" xref="S3.E6.1.1.1.1.1.cmml">i</mi><mo id="S3.E6.2.2.2.2.4.1" xref="S3.E6.2.2.2.2.3.cmml">,</mo><mi id="S3.E6.2.2.2.2.2" xref="S3.E6.2.2.2.2.2.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E6.3.3.4g" xref="S3.E6.3.3.4.cmml">â€‹</mo><mrow id="S3.E6.3.3.3.1" xref="S3.E6.3.3.3.1.1.cmml"><mo stretchy="false" id="S3.E6.3.3.3.1.2" xref="S3.E6.3.3.3.1.1.cmml">(</mo><mrow id="S3.E6.3.3.3.1.1" xref="S3.E6.3.3.3.1.1.cmml"><mi id="S3.E6.3.3.3.1.1.3" xref="S3.E6.3.3.3.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.3.1.1.2" xref="S3.E6.3.3.3.1.1.2.cmml">â€‹</mo><mi id="S3.E6.3.3.3.1.1.4" xref="S3.E6.3.3.3.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.3.1.1.2a" xref="S3.E6.3.3.3.1.1.2.cmml">â€‹</mo><mi id="S3.E6.3.3.3.1.1.5" xref="S3.E6.3.3.3.1.1.5.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E6.3.3.3.1.1.2b" xref="S3.E6.3.3.3.1.1.2.cmml">â€‹</mo><mrow id="S3.E6.3.3.3.1.1.1.1" xref="S3.E6.3.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.3.3.3.1.1.1.1.2" xref="S3.E6.3.3.3.1.1.1.1.1.cmml">(</mo><msub id="S3.E6.3.3.3.1.1.1.1.1" xref="S3.E6.3.3.3.1.1.1.1.1.cmml"><mi id="S3.E6.3.3.3.1.1.1.1.1.2" xref="S3.E6.3.3.3.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E6.3.3.3.1.1.1.1.1.3" xref="S3.E6.3.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E6.3.3.3.1.1.1.1.3" xref="S3.E6.3.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E6.3.3.3.1.3" xref="S3.E6.3.3.3.1.1.cmml">)</mo></mrow></mrow></mtd><mtd id="S3.E7.m1.3.3k" xref="S3.E7.m1.3.3.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E7.m1.3.3l" xref="S3.E7.m1.3.3.cmml"><mrow id="S3.E6.5.1" xref="S3.E6.5.1.cmml"><mi id="S3.E6.5.1.2" xref="S3.E6.5.1.2.cmml">i</mi><mo id="S3.E6.5.1.1" xref="S3.E6.5.1.1.cmml">&gt;</mo><mi id="S3.E6.5.1.3" xref="S3.E6.5.1.3.cmml">j</mi></mrow></mtd></mtr></mtable><mi id="S3.E7.m1.3.4.3.2.2" xref="S3.E7.m1.3.4.3.1.1.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.3b"><apply id="S3.E7.m1.3.4.cmml" xref="S3.E7.m1.3.4"><eq id="S3.E7.m1.3.4.1.cmml" xref="S3.E7.m1.3.4.1"></eq><apply id="S3.E7.m1.3.4.2.cmml" xref="S3.E7.m1.3.4.2"><csymbol cd="ambiguous" id="S3.E7.m1.3.4.2.1.cmml" xref="S3.E7.m1.3.4.2">subscript</csymbol><ci id="S3.E7.m1.3.4.2.2.cmml" xref="S3.E7.m1.3.4.2.2">ğ‘¥</ci><list id="S3.E7.m1.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.4"><ci id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1">ğ‘–</ci><ci id="S3.E7.m1.2.2.2.2.cmml" xref="S3.E7.m1.2.2.2.2">ğ‘—</ci></list></apply><apply id="S3.E7.m1.3.4.3.1.cmml" xref="S3.E7.m1.3.4.3.2"><csymbol cd="latexml" id="S3.E7.m1.3.4.3.1.1.cmml" xref="S3.E7.m1.3.4.3.2.1">cases</csymbol><matrix id="S3.E7.m1.3.3.cmml" xref="S3.E7.m1.3.3"><matrixrow id="S3.E7.m1.3.3a.cmml" xref="S3.E7.m1.3.3"><apply id="S3.E4.3.3.cmml" xref="S3.E4.3.3"><times id="S3.E4.3.3.4.cmml" xref="S3.E4.3.3.4"></times><ci id="S3.E4.3.3.5.cmml" xref="S3.E4.3.3.5">ğ‘‚</ci><ci id="S3.E4.3.3.6.cmml" xref="S3.E4.3.3.6">ğ‘£</ci><ci id="S3.E4.3.3.7.cmml" xref="S3.E4.3.3.7">ğ‘’</ci><ci id="S3.E4.3.3.8.cmml" xref="S3.E4.3.3.8">ğ‘Ÿ</ci><ci id="S3.E4.3.3.9.cmml" xref="S3.E4.3.3.9">ğ‘™</ci><ci id="S3.E4.3.3.10.cmml" xref="S3.E4.3.3.10">ğ‘</ci><ci id="S3.E4.3.3.11.cmml" xref="S3.E4.3.3.11">ğ‘</ci><ci id="S3.E4.3.3.12.cmml" xref="S3.E4.3.3.12">ğ‘</ci><ci id="S3.E4.3.3.13.cmml" xref="S3.E4.3.3.13">ğ‘’</ci><ci id="S3.E4.3.3.14.cmml" xref="S3.E4.3.3.14">ğ‘‘</ci><ci id="S3.E4.3.3.15.cmml" xref="S3.E4.3.3.15">ğ‘ƒ</ci><apply id="S3.E4.3.3.16.cmml" xref="S3.E4.3.3.16"><csymbol cd="ambiguous" id="S3.E4.3.3.16.1.cmml" xref="S3.E4.3.3.16">subscript</csymbol><ci id="S3.E4.3.3.16.2.cmml" xref="S3.E4.3.3.16.2">ğ¸</ci><list id="S3.E4.2.2.2.2.3.cmml" xref="S3.E4.2.2.2.2.4"><ci id="S3.E4.1.1.1.1.1.cmml" xref="S3.E4.1.1.1.1.1">ğ‘–</ci><ci id="S3.E4.2.2.2.2.2.cmml" xref="S3.E4.2.2.2.2.2">ğ‘—</ci></list></apply><apply id="S3.E4.3.3.3.1.1.cmml" xref="S3.E4.3.3.3.1"><times id="S3.E4.3.3.3.1.1.2.cmml" xref="S3.E4.3.3.3.1.1.2"></times><ci id="S3.E4.3.3.3.1.1.3.cmml" xref="S3.E4.3.3.3.1.1.3">ğ¹</ci><ci id="S3.E4.3.3.3.1.1.4.cmml" xref="S3.E4.3.3.3.1.1.4">ğ¹</ci><ci id="S3.E4.3.3.3.1.1.5.cmml" xref="S3.E4.3.3.3.1.1.5">ğ‘</ci><apply id="S3.E4.3.3.3.1.1.1.1.1.cmml" xref="S3.E4.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.3.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.3.3.3.1.1.1.1">subscript</csymbol><ci id="S3.E4.3.3.3.1.1.1.1.1.2.cmml" xref="S3.E4.3.3.3.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E4.3.3.3.1.1.1.1.1.3.cmml" xref="S3.E4.3.3.3.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply><cerror id="S3.E7.m1.3.3b.cmml" xref="S3.E7.m1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.3.3c.cmml" xref="S3.E7.m1.3.3">missing-subexpression</csymbol></cerror><apply id="S3.E4.5.1.cmml" xref="S3.E4.5.1"><lt id="S3.E4.5.1.1.cmml" xref="S3.E4.5.1.1"></lt><ci id="S3.E4.5.1.2.cmml" xref="S3.E4.5.1.2">ğ‘–</ci><ci id="S3.E4.5.1.3.cmml" xref="S3.E4.5.1.3">ğ‘—</ci></apply></matrixrow><matrixrow id="S3.E7.m1.3.3d.cmml" xref="S3.E7.m1.3.3"><apply id="S3.E5.1.1.cmml" xref="S3.E5.1.1"><csymbol cd="ambiguous" id="S3.E5.1.1.1.cmml" xref="S3.E5.1.1">subscript</csymbol><ci id="S3.E5.1.1.2.cmml" xref="S3.E5.1.1.2">ğ‘¥</ci><ci id="S3.E5.1.1.3.cmml" xref="S3.E5.1.1.3">ğ‘–</ci></apply><cerror id="S3.E7.m1.3.3e.cmml" xref="S3.E7.m1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.3.3f.cmml" xref="S3.E7.m1.3.3">missing-subexpression</csymbol></cerror><apply id="S3.E5.3.1.cmml" xref="S3.E5.3.1"><eq id="S3.E5.3.1.1.cmml" xref="S3.E5.3.1.1"></eq><ci id="S3.E5.3.1.2.cmml" xref="S3.E5.3.1.2">ğ‘–</ci><ci id="S3.E5.3.1.3.cmml" xref="S3.E5.3.1.3">ğ‘—</ci></apply></matrixrow><matrixrow id="S3.E7.m1.3.3g.cmml" xref="S3.E7.m1.3.3"><apply id="S3.E6.3.3.cmml" xref="S3.E6.3.3"><times id="S3.E6.3.3.4.cmml" xref="S3.E6.3.3.4"></times><ci id="S3.E6.3.3.5.cmml" xref="S3.E6.3.3.5">ğ‘ˆ</ci><ci id="S3.E6.3.3.6.cmml" xref="S3.E6.3.3.6">ğ‘</ci><ci id="S3.E6.3.3.7.cmml" xref="S3.E6.3.3.7">ğ‘ </ci><ci id="S3.E6.3.3.8.cmml" xref="S3.E6.3.3.8">ğ‘</ci><ci id="S3.E6.3.3.9.cmml" xref="S3.E6.3.3.9">ğ‘š</ci><ci id="S3.E6.3.3.10.cmml" xref="S3.E6.3.3.10">ğ‘</ci><ci id="S3.E6.3.3.11.cmml" xref="S3.E6.3.3.11">ğ‘™</ci><apply id="S3.E6.3.3.12.cmml" xref="S3.E6.3.3.12"><csymbol cd="ambiguous" id="S3.E6.3.3.12.1.cmml" xref="S3.E6.3.3.12">subscript</csymbol><ci id="S3.E6.3.3.12.2.cmml" xref="S3.E6.3.3.12.2">ğ‘’</ci><list id="S3.E6.2.2.2.2.3.cmml" xref="S3.E6.2.2.2.2.4"><ci id="S3.E6.1.1.1.1.1.cmml" xref="S3.E6.1.1.1.1.1">ğ‘–</ci><ci id="S3.E6.2.2.2.2.2.cmml" xref="S3.E6.2.2.2.2.2">ğ‘—</ci></list></apply><apply id="S3.E6.3.3.3.1.1.cmml" xref="S3.E6.3.3.3.1"><times id="S3.E6.3.3.3.1.1.2.cmml" xref="S3.E6.3.3.3.1.1.2"></times><ci id="S3.E6.3.3.3.1.1.3.cmml" xref="S3.E6.3.3.3.1.1.3">ğ¹</ci><ci id="S3.E6.3.3.3.1.1.4.cmml" xref="S3.E6.3.3.3.1.1.4">ğ¹</ci><ci id="S3.E6.3.3.3.1.1.5.cmml" xref="S3.E6.3.3.3.1.1.5">ğ‘</ci><apply id="S3.E6.3.3.3.1.1.1.1.1.cmml" xref="S3.E6.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.3.3.3.1.1.1.1.1.1.cmml" xref="S3.E6.3.3.3.1.1.1.1">subscript</csymbol><ci id="S3.E6.3.3.3.1.1.1.1.1.2.cmml" xref="S3.E6.3.3.3.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E6.3.3.3.1.1.1.1.1.3.cmml" xref="S3.E6.3.3.3.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply><cerror id="S3.E7.m1.3.3h.cmml" xref="S3.E7.m1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.3.3i.cmml" xref="S3.E7.m1.3.3">missing-subexpression</csymbol></cerror><apply id="S3.E6.5.1.cmml" xref="S3.E6.5.1"><gt id="S3.E6.5.1.1.cmml" xref="S3.E6.5.1.1"></gt><ci id="S3.E6.5.1.2.cmml" xref="S3.E6.5.1.2">ğ‘–</ci><ci id="S3.E6.5.1.3.cmml" xref="S3.E6.5.1.3">ğ‘—</ci></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.3c">\displaystyle x_{i,j}=\left\{\begin{array}[]{rcl}OverlappedPE_{i,j}(FFN(x_{i}))&amp;&amp;i&lt;j\\
x_{i}&amp;&amp;i=j\\
Upsample_{i,j}(FFN(x_{i}))&amp;&amp;i&gt;j\end{array}\right.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS3.p6" class="ltx_para">
<p id="S3.SS2.SSS3.p6.2" class="ltx_p">where <math id="S3.SS2.SSS3.p6.1.m1.2" class="ltx_Math" alttext="x_{i,j}" display="inline"><semantics id="S3.SS2.SSS3.p6.1.m1.2a"><msub id="S3.SS2.SSS3.p6.1.m1.2.3" xref="S3.SS2.SSS3.p6.1.m1.2.3.cmml"><mi id="S3.SS2.SSS3.p6.1.m1.2.3.2" xref="S3.SS2.SSS3.p6.1.m1.2.3.2.cmml">x</mi><mrow id="S3.SS2.SSS3.p6.1.m1.2.2.2.4" xref="S3.SS2.SSS3.p6.1.m1.2.2.2.3.cmml"><mi id="S3.SS2.SSS3.p6.1.m1.1.1.1.1" xref="S3.SS2.SSS3.p6.1.m1.1.1.1.1.cmml">i</mi><mo id="S3.SS2.SSS3.p6.1.m1.2.2.2.4.1" xref="S3.SS2.SSS3.p6.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.SSS3.p6.1.m1.2.2.2.2" xref="S3.SS2.SSS3.p6.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p6.1.m1.2b"><apply id="S3.SS2.SSS3.p6.1.m1.2.3.cmml" xref="S3.SS2.SSS3.p6.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p6.1.m1.2.3.1.cmml" xref="S3.SS2.SSS3.p6.1.m1.2.3">subscript</csymbol><ci id="S3.SS2.SSS3.p6.1.m1.2.3.2.cmml" xref="S3.SS2.SSS3.p6.1.m1.2.3.2">ğ‘¥</ci><list id="S3.SS2.SSS3.p6.1.m1.2.2.2.3.cmml" xref="S3.SS2.SSS3.p6.1.m1.2.2.2.4"><ci id="S3.SS2.SSS3.p6.1.m1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p6.1.m1.1.1.1.1">ğ‘–</ci><ci id="S3.SS2.SSS3.p6.1.m1.2.2.2.2.cmml" xref="S3.SS2.SSS3.p6.1.m1.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p6.1.m1.2c">x_{i,j}</annotation></semantics></math> is the input of aggregation MLP layer. <math id="S3.SS2.SSS3.p6.2.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.SS2.SSS3.p6.2.m2.1a"><msub id="S3.SS2.SSS3.p6.2.m2.1.1" xref="S3.SS2.SSS3.p6.2.m2.1.1.cmml"><mi id="S3.SS2.SSS3.p6.2.m2.1.1.2" xref="S3.SS2.SSS3.p6.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS2.SSS3.p6.2.m2.1.1.3" xref="S3.SS2.SSS3.p6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p6.2.m2.1b"><apply id="S3.SS2.SSS3.p6.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p6.2.m2.1.1.1.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p6.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1.2">ğ‘¥</ci><ci id="S3.SS2.SSS3.p6.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p6.2.m2.1c">x_{i}</annotation></semantics></math> denotes the feature map from adjacent resolution. The cross-layer aggregation module is defined as</p>
</div>
<div id="S3.SS2.SSS3.p7" class="ltx_para">
<table id="Sx1.EGx4" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E8.m1.1" class="ltx_Math" alttext="\displaystyle x_{j}=MixFFN(Concat(x_{j-1},x_{j},x_{j+1}))+x_{j}" display="inline"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1" xref="S3.E8.m1.1.1.cmml"><msub id="S3.E8.m1.1.1.3" xref="S3.E8.m1.1.1.3.cmml"><mi id="S3.E8.m1.1.1.3.2" xref="S3.E8.m1.1.1.3.2.cmml">x</mi><mi id="S3.E8.m1.1.1.3.3" xref="S3.E8.m1.1.1.3.3.cmml">j</mi></msub><mo id="S3.E8.m1.1.1.2" xref="S3.E8.m1.1.1.2.cmml">=</mo><mrow id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.4" xref="S3.E8.m1.1.1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.2a" xref="S3.E8.m1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.5" xref="S3.E8.m1.1.1.1.1.5.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.2b" xref="S3.E8.m1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.6" xref="S3.E8.m1.1.1.1.1.6.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.2c" xref="S3.E8.m1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.7" xref="S3.E8.m1.1.1.1.1.7.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.2d" xref="S3.E8.m1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.8" xref="S3.E8.m1.1.1.1.1.8.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.2e" xref="S3.E8.m1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E8.m1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E8.m1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.5" xref="S3.E8.m1.1.1.1.1.1.1.1.5.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.4" xref="S3.E8.m1.1.1.1.1.1.1.1.4.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.6" xref="S3.E8.m1.1.1.1.1.1.1.1.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.4a" xref="S3.E8.m1.1.1.1.1.1.1.1.4.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.7" xref="S3.E8.m1.1.1.1.1.1.1.1.7.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.4b" xref="S3.E8.m1.1.1.1.1.1.1.1.4.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.8" xref="S3.E8.m1.1.1.1.1.1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.4c" xref="S3.E8.m1.1.1.1.1.1.1.1.4.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.9" xref="S3.E8.m1.1.1.1.1.1.1.1.9.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.4d" xref="S3.E8.m1.1.1.1.1.1.1.1.4.cmml">â€‹</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.10" xref="S3.E8.m1.1.1.1.1.1.1.1.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.4e" xref="S3.E8.m1.1.1.1.1.1.1.1.4.cmml">â€‹</mo><mrow id="S3.E8.m1.1.1.1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.3.4.cmml"><mo stretchy="false" id="S3.E8.m1.1.1.1.1.1.1.1.3.3.4" xref="S3.E8.m1.1.1.1.1.1.1.1.3.4.cmml">(</mo><msub id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">j</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">âˆ’</mo><mn id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.E8.m1.1.1.1.1.1.1.1.3.3.5" xref="S3.E8.m1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S3.E8.m1.1.1.1.1.1.1.1.2.2.2" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.2.cmml">x</mi><mi id="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.3.cmml">j</mi></msub><mo id="S3.E8.m1.1.1.1.1.1.1.1.3.3.6" xref="S3.E8.m1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.2.cmml">x</mi><mrow id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.2.cmml">j</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.1" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.1.cmml">+</mo><mn id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="S3.E8.m1.1.1.1.1.1.1.1.3.3.7" xref="S3.E8.m1.1.1.1.1.1.1.1.3.4.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E8.m1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.1.1.1.2" xref="S3.E8.m1.1.1.1.2.cmml">+</mo><msub id="S3.E8.m1.1.1.1.3" xref="S3.E8.m1.1.1.1.3.cmml"><mi id="S3.E8.m1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.3.2.cmml">x</mi><mi id="S3.E8.m1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.3.3.cmml">j</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.cmml" xref="S3.E8.m1.1.1"><eq id="S3.E8.m1.1.1.2.cmml" xref="S3.E8.m1.1.1.2"></eq><apply id="S3.E8.m1.1.1.3.cmml" xref="S3.E8.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.3.2">ğ‘¥</ci><ci id="S3.E8.m1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.3.3">ğ‘—</ci></apply><apply id="S3.E8.m1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"><plus id="S3.E8.m1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.2"></plus><apply id="S3.E8.m1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1"><times id="S3.E8.m1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.2"></times><ci id="S3.E8.m1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.3">ğ‘€</ci><ci id="S3.E8.m1.1.1.1.1.4.cmml" xref="S3.E8.m1.1.1.1.1.4">ğ‘–</ci><ci id="S3.E8.m1.1.1.1.1.5.cmml" xref="S3.E8.m1.1.1.1.1.5">ğ‘¥</ci><ci id="S3.E8.m1.1.1.1.1.6.cmml" xref="S3.E8.m1.1.1.1.1.6">ğ¹</ci><ci id="S3.E8.m1.1.1.1.1.7.cmml" xref="S3.E8.m1.1.1.1.1.7">ğ¹</ci><ci id="S3.E8.m1.1.1.1.1.8.cmml" xref="S3.E8.m1.1.1.1.1.8">ğ‘</ci><apply id="S3.E8.m1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1"><times id="S3.E8.m1.1.1.1.1.1.1.1.4.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.4"></times><ci id="S3.E8.m1.1.1.1.1.1.1.1.5.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.5">ğ¶</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.6.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.6">ğ‘œ</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.7.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.7">ğ‘›</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.8.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.8">ğ‘</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.9.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.9">ğ‘</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.10.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.10">ğ‘¡</ci><vector id="S3.E8.m1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3"><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3"><minus id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.1"></minus><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘—</ci><cn type="integer" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.2">ğ‘¥</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.3">ğ‘—</ci></apply><apply id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.2">ğ‘¥</ci><apply id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3"><plus id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.1"></plus><ci id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.2">ğ‘—</ci><cn type="integer" id="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3.3.3.3.3">1</cn></apply></apply></vector></apply></apply><apply id="S3.E8.m1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E8.m1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.3.3">ğ‘—</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">\displaystyle x_{j}=MixFFN(Concat(x_{j-1},x_{j},x_{j+1}))+x_{j}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS3.p8" class="ltx_para">
<p id="S3.SS2.SSS3.p8.1" class="ltx_p">where <math id="S3.SS2.SSS3.p8.1.m1.1" class="ltx_Math" alttext="MixFFN" display="inline"><semantics id="S3.SS2.SSS3.p8.1.m1.1a"><mrow id="S3.SS2.SSS3.p8.1.m1.1.1" xref="S3.SS2.SSS3.p8.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p8.1.m1.1.1.2" xref="S3.SS2.SSS3.p8.1.m1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p8.1.m1.1.1.1" xref="S3.SS2.SSS3.p8.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p8.1.m1.1.1.3" xref="S3.SS2.SSS3.p8.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p8.1.m1.1.1.1a" xref="S3.SS2.SSS3.p8.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p8.1.m1.1.1.4" xref="S3.SS2.SSS3.p8.1.m1.1.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p8.1.m1.1.1.1b" xref="S3.SS2.SSS3.p8.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p8.1.m1.1.1.5" xref="S3.SS2.SSS3.p8.1.m1.1.1.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p8.1.m1.1.1.1c" xref="S3.SS2.SSS3.p8.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p8.1.m1.1.1.6" xref="S3.SS2.SSS3.p8.1.m1.1.1.6.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p8.1.m1.1.1.1d" xref="S3.SS2.SSS3.p8.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS2.SSS3.p8.1.m1.1.1.7" xref="S3.SS2.SSS3.p8.1.m1.1.1.7.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p8.1.m1.1b"><apply id="S3.SS2.SSS3.p8.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p8.1.m1.1.1"><times id="S3.SS2.SSS3.p8.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p8.1.m1.1.1.1"></times><ci id="S3.SS2.SSS3.p8.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p8.1.m1.1.1.2">ğ‘€</ci><ci id="S3.SS2.SSS3.p8.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p8.1.m1.1.1.3">ğ‘–</ci><ci id="S3.SS2.SSS3.p8.1.m1.1.1.4.cmml" xref="S3.SS2.SSS3.p8.1.m1.1.1.4">ğ‘¥</ci><ci id="S3.SS2.SSS3.p8.1.m1.1.1.5.cmml" xref="S3.SS2.SSS3.p8.1.m1.1.1.5">ğ¹</ci><ci id="S3.SS2.SSS3.p8.1.m1.1.1.6.cmml" xref="S3.SS2.SSS3.p8.1.m1.1.1.6">ğ¹</ci><ci id="S3.SS2.SSS3.p8.1.m1.1.1.7.cmml" xref="S3.SS2.SSS3.p8.1.m1.1.1.7">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p8.1.m1.1c">MixFFN</annotation></semantics></math> represents the Mix feed forward block in formula (3).</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Analysis</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">There are two main benefits of AggPose and our large-scale infant pose dataset over other CNN or hybrid CNN Transformer methods like HRFormer and TokenPose and other small dataset for infant pose estimation, which are concluded as follows.</p>
</div>
<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">(1) Potential of using self-supervised learning.</h5>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.1" class="ltx_p">Recently, Vision Transformers pre-trained with self-supervised learning have attracted much attention. MAEÂ <cite class="ltx_cite ltx_citemacro_cite">He <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite> construct an inpainting masked autoencoder task to learn representation from unlabeled data and fine-tuning the model on any supervised tasks. Their results prove that full transformers can learn reasonable semantic from large-scale unlabeled dataset. As Table 1 shows, we have plenty of unlabeled infant movement frames from 5,187 videos. All these data would be helpful for pre-training transformer-based autoencoder via self-supervised learning.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">(2) Faster convergence.</h5>

<div id="S3.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px2.p1.1" class="ltx_p">In HRFormer, the feature passing is achieved via cross-layer convolution operation, which, is difficult to convergence. In our AggPose framework, messages are propagated by MLP across different layers. It can be viewed as a kind of modification to the deep layer aggregation model. As our experiments will show, such message pass scheme achieves better results than hybrid CNN-Transformer based methods.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.14" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.6.6" class="ltx_tr">
<th id="S3.T3.6.6.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Method</th>
<th id="S3.T3.6.6.8" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Input size</th>
<th id="S3.T3.6.6.9" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Backbone</th>
<th id="S3.T3.6.6.10" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">GFLOPs</th>
<th id="S3.T3.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><math id="S3.T3.1.1.1.m1.1" class="ltx_Math" alttext="AP" display="inline"><semantics id="S3.T3.1.1.1.m1.1a"><mrow id="S3.T3.1.1.1.m1.1.1" xref="S3.T3.1.1.1.m1.1.1.cmml"><mi id="S3.T3.1.1.1.m1.1.1.2" xref="S3.T3.1.1.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.T3.1.1.1.m1.1.1.1" xref="S3.T3.1.1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T3.1.1.1.m1.1.1.3" xref="S3.T3.1.1.1.m1.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.m1.1b"><apply id="S3.T3.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.m1.1.1"><times id="S3.T3.1.1.1.m1.1.1.1.cmml" xref="S3.T3.1.1.1.m1.1.1.1"></times><ci id="S3.T3.1.1.1.m1.1.1.2.cmml" xref="S3.T3.1.1.1.m1.1.1.2">ğ´</ci><ci id="S3.T3.1.1.1.m1.1.1.3.cmml" xref="S3.T3.1.1.1.m1.1.1.3">ğ‘ƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.m1.1c">AP</annotation></semantics></math></th>
<th id="S3.T3.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><math id="S3.T3.2.2.2.m1.1" class="ltx_Math" alttext="AP^{50}" display="inline"><semantics id="S3.T3.2.2.2.m1.1a"><mrow id="S3.T3.2.2.2.m1.1.1" xref="S3.T3.2.2.2.m1.1.1.cmml"><mi id="S3.T3.2.2.2.m1.1.1.2" xref="S3.T3.2.2.2.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.T3.2.2.2.m1.1.1.1" xref="S3.T3.2.2.2.m1.1.1.1.cmml">â€‹</mo><msup id="S3.T3.2.2.2.m1.1.1.3" xref="S3.T3.2.2.2.m1.1.1.3.cmml"><mi id="S3.T3.2.2.2.m1.1.1.3.2" xref="S3.T3.2.2.2.m1.1.1.3.2.cmml">P</mi><mn id="S3.T3.2.2.2.m1.1.1.3.3" xref="S3.T3.2.2.2.m1.1.1.3.3.cmml">50</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.m1.1b"><apply id="S3.T3.2.2.2.m1.1.1.cmml" xref="S3.T3.2.2.2.m1.1.1"><times id="S3.T3.2.2.2.m1.1.1.1.cmml" xref="S3.T3.2.2.2.m1.1.1.1"></times><ci id="S3.T3.2.2.2.m1.1.1.2.cmml" xref="S3.T3.2.2.2.m1.1.1.2">ğ´</ci><apply id="S3.T3.2.2.2.m1.1.1.3.cmml" xref="S3.T3.2.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S3.T3.2.2.2.m1.1.1.3.1.cmml" xref="S3.T3.2.2.2.m1.1.1.3">superscript</csymbol><ci id="S3.T3.2.2.2.m1.1.1.3.2.cmml" xref="S3.T3.2.2.2.m1.1.1.3.2">ğ‘ƒ</ci><cn type="integer" id="S3.T3.2.2.2.m1.1.1.3.3.cmml" xref="S3.T3.2.2.2.m1.1.1.3.3">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.m1.1c">AP^{50}</annotation></semantics></math></th>
<th id="S3.T3.3.3.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><math id="S3.T3.3.3.3.m1.1" class="ltx_Math" alttext="AP^{75}" display="inline"><semantics id="S3.T3.3.3.3.m1.1a"><mrow id="S3.T3.3.3.3.m1.1.1" xref="S3.T3.3.3.3.m1.1.1.cmml"><mi id="S3.T3.3.3.3.m1.1.1.2" xref="S3.T3.3.3.3.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.T3.3.3.3.m1.1.1.1" xref="S3.T3.3.3.3.m1.1.1.1.cmml">â€‹</mo><msup id="S3.T3.3.3.3.m1.1.1.3" xref="S3.T3.3.3.3.m1.1.1.3.cmml"><mi id="S3.T3.3.3.3.m1.1.1.3.2" xref="S3.T3.3.3.3.m1.1.1.3.2.cmml">P</mi><mn id="S3.T3.3.3.3.m1.1.1.3.3" xref="S3.T3.3.3.3.m1.1.1.3.3.cmml">75</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.m1.1b"><apply id="S3.T3.3.3.3.m1.1.1.cmml" xref="S3.T3.3.3.3.m1.1.1"><times id="S3.T3.3.3.3.m1.1.1.1.cmml" xref="S3.T3.3.3.3.m1.1.1.1"></times><ci id="S3.T3.3.3.3.m1.1.1.2.cmml" xref="S3.T3.3.3.3.m1.1.1.2">ğ´</ci><apply id="S3.T3.3.3.3.m1.1.1.3.cmml" xref="S3.T3.3.3.3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.T3.3.3.3.m1.1.1.3.1.cmml" xref="S3.T3.3.3.3.m1.1.1.3">superscript</csymbol><ci id="S3.T3.3.3.3.m1.1.1.3.2.cmml" xref="S3.T3.3.3.3.m1.1.1.3.2">ğ‘ƒ</ci><cn type="integer" id="S3.T3.3.3.3.m1.1.1.3.3.cmml" xref="S3.T3.3.3.3.m1.1.1.3.3">75</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.3.m1.1c">AP^{75}</annotation></semantics></math></th>
<th id="S3.T3.4.4.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><math id="S3.T3.4.4.4.m1.1" class="ltx_Math" alttext="AP^{M}" display="inline"><semantics id="S3.T3.4.4.4.m1.1a"><mrow id="S3.T3.4.4.4.m1.1.1" xref="S3.T3.4.4.4.m1.1.1.cmml"><mi id="S3.T3.4.4.4.m1.1.1.2" xref="S3.T3.4.4.4.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.T3.4.4.4.m1.1.1.1" xref="S3.T3.4.4.4.m1.1.1.1.cmml">â€‹</mo><msup id="S3.T3.4.4.4.m1.1.1.3" xref="S3.T3.4.4.4.m1.1.1.3.cmml"><mi id="S3.T3.4.4.4.m1.1.1.3.2" xref="S3.T3.4.4.4.m1.1.1.3.2.cmml">P</mi><mi id="S3.T3.4.4.4.m1.1.1.3.3" xref="S3.T3.4.4.4.m1.1.1.3.3.cmml">M</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.4.m1.1b"><apply id="S3.T3.4.4.4.m1.1.1.cmml" xref="S3.T3.4.4.4.m1.1.1"><times id="S3.T3.4.4.4.m1.1.1.1.cmml" xref="S3.T3.4.4.4.m1.1.1.1"></times><ci id="S3.T3.4.4.4.m1.1.1.2.cmml" xref="S3.T3.4.4.4.m1.1.1.2">ğ´</ci><apply id="S3.T3.4.4.4.m1.1.1.3.cmml" xref="S3.T3.4.4.4.m1.1.1.3"><csymbol cd="ambiguous" id="S3.T3.4.4.4.m1.1.1.3.1.cmml" xref="S3.T3.4.4.4.m1.1.1.3">superscript</csymbol><ci id="S3.T3.4.4.4.m1.1.1.3.2.cmml" xref="S3.T3.4.4.4.m1.1.1.3.2">ğ‘ƒ</ci><ci id="S3.T3.4.4.4.m1.1.1.3.3.cmml" xref="S3.T3.4.4.4.m1.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.4.m1.1c">AP^{M}</annotation></semantics></math></th>
<th id="S3.T3.5.5.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><math id="S3.T3.5.5.5.m1.1" class="ltx_Math" alttext="AP^{L}" display="inline"><semantics id="S3.T3.5.5.5.m1.1a"><mrow id="S3.T3.5.5.5.m1.1.1" xref="S3.T3.5.5.5.m1.1.1.cmml"><mi id="S3.T3.5.5.5.m1.1.1.2" xref="S3.T3.5.5.5.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.T3.5.5.5.m1.1.1.1" xref="S3.T3.5.5.5.m1.1.1.1.cmml">â€‹</mo><msup id="S3.T3.5.5.5.m1.1.1.3" xref="S3.T3.5.5.5.m1.1.1.3.cmml"><mi id="S3.T3.5.5.5.m1.1.1.3.2" xref="S3.T3.5.5.5.m1.1.1.3.2.cmml">P</mi><mi id="S3.T3.5.5.5.m1.1.1.3.3" xref="S3.T3.5.5.5.m1.1.1.3.3.cmml">L</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.5.m1.1b"><apply id="S3.T3.5.5.5.m1.1.1.cmml" xref="S3.T3.5.5.5.m1.1.1"><times id="S3.T3.5.5.5.m1.1.1.1.cmml" xref="S3.T3.5.5.5.m1.1.1.1"></times><ci id="S3.T3.5.5.5.m1.1.1.2.cmml" xref="S3.T3.5.5.5.m1.1.1.2">ğ´</ci><apply id="S3.T3.5.5.5.m1.1.1.3.cmml" xref="S3.T3.5.5.5.m1.1.1.3"><csymbol cd="ambiguous" id="S3.T3.5.5.5.m1.1.1.3.1.cmml" xref="S3.T3.5.5.5.m1.1.1.3">superscript</csymbol><ci id="S3.T3.5.5.5.m1.1.1.3.2.cmml" xref="S3.T3.5.5.5.m1.1.1.3.2">ğ‘ƒ</ci><ci id="S3.T3.5.5.5.m1.1.1.3.3.cmml" xref="S3.T3.5.5.5.m1.1.1.3.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.5.m1.1c">AP^{L}</annotation></semantics></math></th>
<th id="S3.T3.6.6.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><math id="S3.T3.6.6.6.m1.1" class="ltx_Math" alttext="AR" display="inline"><semantics id="S3.T3.6.6.6.m1.1a"><mrow id="S3.T3.6.6.6.m1.1.1" xref="S3.T3.6.6.6.m1.1.1.cmml"><mi id="S3.T3.6.6.6.m1.1.1.2" xref="S3.T3.6.6.6.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.T3.6.6.6.m1.1.1.1" xref="S3.T3.6.6.6.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T3.6.6.6.m1.1.1.3" xref="S3.T3.6.6.6.m1.1.1.3.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.6.m1.1b"><apply id="S3.T3.6.6.6.m1.1.1.cmml" xref="S3.T3.6.6.6.m1.1.1"><times id="S3.T3.6.6.6.m1.1.1.1.cmml" xref="S3.T3.6.6.6.m1.1.1.1"></times><ci id="S3.T3.6.6.6.m1.1.1.2.cmml" xref="S3.T3.6.6.6.m1.1.1.2">ğ´</ci><ci id="S3.T3.6.6.6.m1.1.1.3.cmml" xref="S3.T3.6.6.6.m1.1.1.3">ğ‘…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.6.m1.1c">AR</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.7.7" class="ltx_tr">
<th id="S3.T3.7.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">SimpleBaseline-Res152</th>
<td id="S3.T3.7.7.1" class="ltx_td ltx_align_right ltx_border_t">256<math id="S3.T3.7.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T3.7.7.1.m1.1a"><mo id="S3.T3.7.7.1.m1.1.1" xref="S3.T3.7.7.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.1.m1.1b"><times id="S3.T3.7.7.1.m1.1.1.cmml" xref="S3.T3.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S3.T3.7.7.3" class="ltx_td ltx_align_right ltx_border_t">-</td>
<td id="S3.T3.7.7.4" class="ltx_td ltx_align_right ltx_border_t">15.7</td>
<td id="S3.T3.7.7.5" class="ltx_td ltx_align_right ltx_border_t">72.0</td>
<td id="S3.T3.7.7.6" class="ltx_td ltx_align_right ltx_border_t">89.3</td>
<td id="S3.T3.7.7.7" class="ltx_td ltx_align_right ltx_border_t">79.8</td>
<td id="S3.T3.7.7.8" class="ltx_td ltx_align_right ltx_border_t">68.7</td>
<td id="S3.T3.7.7.9" class="ltx_td ltx_align_right ltx_border_t">78.9</td>
<td id="S3.T3.7.7.10" class="ltx_td ltx_align_right ltx_border_t">77.8</td>
</tr>
<tr id="S3.T3.8.8" class="ltx_tr">
<th id="S3.T3.8.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">HRNet-W32Â <cite class="ltx_cite ltx_citemacro_cite">Wang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S3.T3.8.8.1" class="ltx_td ltx_align_right">256<math id="S3.T3.8.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T3.8.8.1.m1.1a"><mo id="S3.T3.8.8.1.m1.1.1" xref="S3.T3.8.8.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.1.m1.1b"><times id="S3.T3.8.8.1.m1.1.1.cmml" xref="S3.T3.8.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S3.T3.8.8.3" class="ltx_td ltx_align_right">-</td>
<td id="S3.T3.8.8.4" class="ltx_td ltx_align_right">7.1</td>
<td id="S3.T3.8.8.5" class="ltx_td ltx_align_right">74.4</td>
<td id="S3.T3.8.8.6" class="ltx_td ltx_align_right">90.5</td>
<td id="S3.T3.8.8.7" class="ltx_td ltx_align_right">81.9</td>
<td id="S3.T3.8.8.8" class="ltx_td ltx_align_right">70.8</td>
<td id="S3.T3.8.8.9" class="ltx_td ltx_align_right">81.0</td>
<td id="S3.T3.8.8.10" class="ltx_td ltx_align_right">79.8</td>
</tr>
<tr id="S3.T3.9.9" class="ltx_tr">
<th id="S3.T3.9.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">HRNet-W48Â <cite class="ltx_cite ltx_citemacro_cite">Wang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S3.T3.9.9.1" class="ltx_td ltx_align_right">256<math id="S3.T3.9.9.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T3.9.9.1.m1.1a"><mo id="S3.T3.9.9.1.m1.1.1" xref="S3.T3.9.9.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T3.9.9.1.m1.1b"><times id="S3.T3.9.9.1.m1.1.1.cmml" xref="S3.T3.9.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.9.9.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S3.T3.9.9.3" class="ltx_td ltx_align_right">-</td>
<td id="S3.T3.9.9.4" class="ltx_td ltx_align_right">16.0</td>
<td id="S3.T3.9.9.5" class="ltx_td ltx_align_right">75.1</td>
<td id="S3.T3.9.9.6" class="ltx_td ltx_align_right">90.6</td>
<td id="S3.T3.9.9.7" class="ltx_td ltx_align_right">82.2</td>
<td id="S3.T3.9.9.8" class="ltx_td ltx_align_right">71.5</td>
<td id="S3.T3.9.9.9" class="ltx_td ltx_align_right">81.8</td>
<td id="S3.T3.9.9.10" class="ltx_td ltx_align_right">80.4</td>
</tr>
<tr id="S3.T3.10.10" class="ltx_tr">
<th id="S3.T3.10.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">TransPoseÂ <cite class="ltx_cite ltx_citemacro_cite">Yang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T3.10.10.1" class="ltx_td ltx_align_right">256<math id="S3.T3.10.10.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T3.10.10.1.m1.1a"><mo id="S3.T3.10.10.1.m1.1.1" xref="S3.T3.10.10.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T3.10.10.1.m1.1b"><times id="S3.T3.10.10.1.m1.1.1.cmml" xref="S3.T3.10.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.10.10.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S3.T3.10.10.3" class="ltx_td ltx_align_right">HRNet</td>
<td id="S3.T3.10.10.4" class="ltx_td ltx_align_right">21.8</td>
<td id="S3.T3.10.10.5" class="ltx_td ltx_align_right">75.8</td>
<td id="S3.T3.10.10.6" class="ltx_td ltx_align_right">90.1</td>
<td id="S3.T3.10.10.7" class="ltx_td ltx_align_right">82.1</td>
<td id="S3.T3.10.10.8" class="ltx_td ltx_align_right">71.9</td>
<td id="S3.T3.10.10.9" class="ltx_td ltx_align_right">82.8</td>
<td id="S3.T3.10.10.10" class="ltx_td ltx_align_right">80.8</td>
</tr>
<tr id="S3.T3.11.11" class="ltx_tr">
<th id="S3.T3.11.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">TokenPose-L/D24Â <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T3.11.11.1" class="ltx_td ltx_align_right">256<math id="S3.T3.11.11.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T3.11.11.1.m1.1a"><mo id="S3.T3.11.11.1.m1.1.1" xref="S3.T3.11.11.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T3.11.11.1.m1.1b"><times id="S3.T3.11.11.1.m1.1.1.cmml" xref="S3.T3.11.11.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.11.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S3.T3.11.11.3" class="ltx_td ltx_align_right">HRNet</td>
<td id="S3.T3.11.11.4" class="ltx_td ltx_align_right">11.0</td>
<td id="S3.T3.11.11.5" class="ltx_td ltx_align_right">75.8</td>
<td id="S3.T3.11.11.6" class="ltx_td ltx_align_right">90.3</td>
<td id="S3.T3.11.11.7" class="ltx_td ltx_align_right">82.5</td>
<td id="S3.T3.11.11.8" class="ltx_td ltx_align_right">72.3</td>
<td id="S3.T3.11.11.9" class="ltx_td ltx_align_right">82.7</td>
<td id="S3.T3.11.11.10" class="ltx_td ltx_align_right">80.9</td>
</tr>
<tr id="S3.T3.12.12" class="ltx_tr">
<th id="S3.T3.12.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">HRFormer-BÂ <cite class="ltx_cite ltx_citemacro_cite">Yuan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T3.12.12.1" class="ltx_td ltx_align_right">256<math id="S3.T3.12.12.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T3.12.12.1.m1.1a"><mo id="S3.T3.12.12.1.m1.1.1" xref="S3.T3.12.12.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T3.12.12.1.m1.1b"><times id="S3.T3.12.12.1.m1.1.1.cmml" xref="S3.T3.12.12.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.12.12.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S3.T3.12.12.3" class="ltx_td ltx_align_right">HRNet</td>
<td id="S3.T3.12.12.4" class="ltx_td ltx_align_right">12.2</td>
<td id="S3.T3.12.12.5" class="ltx_td ltx_align_right">75.6</td>
<td id="S3.T3.12.12.6" class="ltx_td ltx_align_right"><span id="S3.T3.12.12.6.1" class="ltx_text ltx_font_bold">90.8</span></td>
<td id="S3.T3.12.12.7" class="ltx_td ltx_align_right">82.8</td>
<td id="S3.T3.12.12.8" class="ltx_td ltx_align_right">71.7</td>
<td id="S3.T3.12.12.9" class="ltx_td ltx_align_right">82.6</td>
<td id="S3.T3.12.12.10" class="ltx_td ltx_align_right">80.8</td>
</tr>
<tr id="S3.T3.13.13" class="ltx_tr">
<th id="S3.T3.13.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">AggPose-S</th>
<td id="S3.T3.13.13.1" class="ltx_td ltx_align_right">256<math id="S3.T3.13.13.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T3.13.13.1.m1.1a"><mo id="S3.T3.13.13.1.m1.1.1" xref="S3.T3.13.13.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T3.13.13.1.m1.1b"><times id="S3.T3.13.13.1.m1.1.1.cmml" xref="S3.T3.13.13.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.13.13.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S3.T3.13.13.3" class="ltx_td ltx_align_right">MiT-B2</td>
<td id="S3.T3.13.13.4" class="ltx_td ltx_align_right">9.0</td>
<td id="S3.T3.13.13.5" class="ltx_td ltx_align_right">75.2</td>
<td id="S3.T3.13.13.6" class="ltx_td ltx_align_right">89.9</td>
<td id="S3.T3.13.13.7" class="ltx_td ltx_align_right">82.0</td>
<td id="S3.T3.13.13.8" class="ltx_td ltx_align_right">71.4</td>
<td id="S3.T3.13.13.9" class="ltx_td ltx_align_right">82.4</td>
<td id="S3.T3.13.13.10" class="ltx_td ltx_align_right">80.3</td>
</tr>
<tr id="S3.T3.14.14" class="ltx_tr">
<th id="S3.T3.14.14.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">AggPose-L</th>
<td id="S3.T3.14.14.1" class="ltx_td ltx_align_right ltx_border_bb">256<math id="S3.T3.14.14.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T3.14.14.1.m1.1a"><mo id="S3.T3.14.14.1.m1.1.1" xref="S3.T3.14.14.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T3.14.14.1.m1.1b"><times id="S3.T3.14.14.1.m1.1.1.cmml" xref="S3.T3.14.14.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.14.14.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S3.T3.14.14.3" class="ltx_td ltx_align_right ltx_border_bb">MiT-B5</td>
<td id="S3.T3.14.14.4" class="ltx_td ltx_align_right ltx_border_bb">15.0</td>
<td id="S3.T3.14.14.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T3.14.14.5.1" class="ltx_text ltx_font_bold">76.4</span></td>
<td id="S3.T3.14.14.6" class="ltx_td ltx_align_right ltx_border_bb">90.6</td>
<td id="S3.T3.14.14.7" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T3.14.14.7.1" class="ltx_text ltx_font_bold">82.9</span></td>
<td id="S3.T3.14.14.8" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T3.14.14.8.1" class="ltx_text ltx_font_bold">72.7</span></td>
<td id="S3.T3.14.14.9" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T3.14.14.9.1" class="ltx_text ltx_font_bold">83.4</span></td>
<td id="S3.T3.14.14.10" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T3.14.14.10.1" class="ltx_text ltx_font_bold">81.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparisons on the COCO validation set, provided with the same detected human boxes from HRNet.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Model Variants</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Considering that the training process of most Transformer-based pose estimation models is complicated, we provide an effective training policy in this paper. First, we load the Mix TransformerÂ <cite class="ltx_cite ltx_citemacro_cite">Xie <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> pre-trained on ImageNet, training Mix Transformer on the COCO keypoints training set. After the Mix Transformer converges, we load the parameter of Mix Transformer into each layer of AggPose. Then, we fixed the parameters of AggPose at different resolution levels layer by layer and fine-tuned the model on COCO and infant pose dataset.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">The configuration details for the size of overlapped patch embedding and the number of transformer layers are presented in TableÂ <a href="#S3.T2" title="Table 2 â€£ 3.2.2 Aggregation Vision Transformers (AViTs) Architecture â€£ 3.2 Deep Aggregation Vision Transformers â€£ 3 Proposed Method â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Note, TableÂ <a href="#S3.T2" title="Table 2 â€£ 3.2.2 Aggregation Vision Transformers (AViTs) Architecture â€£ 3.2 Deep Aggregation Vision Transformers â€£ 3 Proposed Method â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> only provide the configuration for AggPose-L, which uses MiT-B5 as the backbone. For AggPose-S, we used MiT-B2 as backbone, the number of transformer layers is [[3,3,3,3],[4,3,3],[6,3],[3]].</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Comparing with SOTA Methods</h3>

<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset.</h5>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">We study the performance of AggPose on the COCO human pose estimation datasetÂ <cite class="ltx_cite ltx_citemacro_cite">Lin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2014</a>)</cite>, which contains more than 250K person instances labeled with 17 keypoints, and the new infant pose estimation dataset, which contains 20k infant instances labeled with 21 keypoints. MPII dataset is not used in our experiment due to its size (25K) is much smaller than COCO and has different keypoints format.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Training setting.</h5>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.1" class="ltx_p">Following most of the default training and evaluation settings from HRNet and HRFormer, we trained the models using AdamW optimizer and an initial value of 0.001 as the learning rate. For the training batch size, we chose 32 due to limited GPU memory. The experiment takes 4 <math id="S4.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a"><mo id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b"><times id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">\times</annotation></semantics></math> 48G-RTX8000 GPUs. We follow the data augmentation in Â <cite class="ltx_cite ltx_citemacro_cite">Wang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite> mainly.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation metric.</h5>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p1.1" class="ltx_p">For COCO dataset, we adopt the default standard average precision (AP) as our evaluation metric. AP is calculated based on Object Keypoint Similarity (OKS):</p>
</div>
<div id="S4.SS2.SSS0.Px3.p2" class="ltx_para">
<table id="Sx1.EGx5" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S4.E9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E9.m1.3" class="ltx_Math" alttext="\displaystyle OKS=\frac{\sum_{i}exp(-\frac{\hat{d}_{i}^{2}}{2s^{2}k_{i}^{2}})\delta(v_{i}&gt;0)}{\sum_{i}\delta(v_{i}&gt;0)}" display="inline"><semantics id="S4.E9.m1.3a"><mrow id="S4.E9.m1.3.4" xref="S4.E9.m1.3.4.cmml"><mrow id="S4.E9.m1.3.4.2" xref="S4.E9.m1.3.4.2.cmml"><mi id="S4.E9.m1.3.4.2.2" xref="S4.E9.m1.3.4.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.E9.m1.3.4.2.1" xref="S4.E9.m1.3.4.2.1.cmml">â€‹</mo><mi id="S4.E9.m1.3.4.2.3" xref="S4.E9.m1.3.4.2.3.cmml">K</mi><mo lspace="0em" rspace="0em" id="S4.E9.m1.3.4.2.1a" xref="S4.E9.m1.3.4.2.1.cmml">â€‹</mo><mi id="S4.E9.m1.3.4.2.4" xref="S4.E9.m1.3.4.2.4.cmml">S</mi></mrow><mo id="S4.E9.m1.3.4.1" xref="S4.E9.m1.3.4.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E9.m1.3.3" xref="S4.E9.m1.3.3.cmml"><mfrac id="S4.E9.m1.3.3a" xref="S4.E9.m1.3.3.cmml"><mrow id="S4.E9.m1.2.2.2" xref="S4.E9.m1.2.2.2.cmml"><msub id="S4.E9.m1.2.2.2.3" xref="S4.E9.m1.2.2.2.3.cmml"><mo id="S4.E9.m1.2.2.2.3.2" xref="S4.E9.m1.2.2.2.3.2.cmml">âˆ‘</mo><mi id="S4.E9.m1.2.2.2.3.3" xref="S4.E9.m1.2.2.2.3.3.cmml">i</mi></msub><mrow id="S4.E9.m1.2.2.2.2" xref="S4.E9.m1.2.2.2.2.cmml"><mi id="S4.E9.m1.2.2.2.2.4" xref="S4.E9.m1.2.2.2.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E9.m1.2.2.2.2.3" xref="S4.E9.m1.2.2.2.2.3.cmml">â€‹</mo><mi id="S4.E9.m1.2.2.2.2.5" xref="S4.E9.m1.2.2.2.2.5.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.E9.m1.2.2.2.2.3a" xref="S4.E9.m1.2.2.2.2.3.cmml">â€‹</mo><mi id="S4.E9.m1.2.2.2.2.6" xref="S4.E9.m1.2.2.2.2.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.E9.m1.2.2.2.2.3b" xref="S4.E9.m1.2.2.2.2.3.cmml">â€‹</mo><mrow id="S4.E9.m1.1.1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E9.m1.1.1.1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E9.m1.1.1.1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.1.1.1.cmml"><mo id="S4.E9.m1.1.1.1.1.1.1.1a" xref="S4.E9.m1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mfrac id="S4.E9.m1.1.1.1.1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.1.1.1.2.cmml"><msubsup id="S4.E9.m1.1.1.1.1.1.1.1.2.2" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.cmml"><mover accent="true" id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.2.cmml">d</mi><mo id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.1" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.1.cmml">^</mo></mover><mi id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.3.cmml">i</mi><mn id="S4.E9.m1.1.1.1.1.1.1.1.2.2.3" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.3.cmml">2</mn></msubsup><mrow id="S4.E9.m1.1.1.1.1.1.1.1.2.3" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.cmml"><mn id="S4.E9.m1.1.1.1.1.1.1.1.2.3.2" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.E9.m1.1.1.1.1.1.1.1.2.3.1" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><msup id="S4.E9.m1.1.1.1.1.1.1.1.2.3.3" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.2" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.2.cmml">s</mi><mn id="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.3" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="S4.E9.m1.1.1.1.1.1.1.1.2.3.1a" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><msubsup id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.cmml"><mi id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.2" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.2.cmml">k</mi><mi id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.3" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.3.cmml">i</mi><mn id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.3" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.3.cmml">2</mn></msubsup></mrow></mfrac></mrow><mo stretchy="false" id="S4.E9.m1.1.1.1.1.1.1.3" xref="S4.E9.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E9.m1.2.2.2.2.3c" xref="S4.E9.m1.2.2.2.2.3.cmml">â€‹</mo><mi id="S4.E9.m1.2.2.2.2.7" xref="S4.E9.m1.2.2.2.2.7.cmml">Î´</mi><mo lspace="0em" rspace="0em" id="S4.E9.m1.2.2.2.2.3d" xref="S4.E9.m1.2.2.2.2.3.cmml">â€‹</mo><mrow id="S4.E9.m1.2.2.2.2.2.1" xref="S4.E9.m1.2.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S4.E9.m1.2.2.2.2.2.1.2" xref="S4.E9.m1.2.2.2.2.2.1.1.cmml">(</mo><mrow id="S4.E9.m1.2.2.2.2.2.1.1" xref="S4.E9.m1.2.2.2.2.2.1.1.cmml"><msub id="S4.E9.m1.2.2.2.2.2.1.1.2" xref="S4.E9.m1.2.2.2.2.2.1.1.2.cmml"><mi id="S4.E9.m1.2.2.2.2.2.1.1.2.2" xref="S4.E9.m1.2.2.2.2.2.1.1.2.2.cmml">v</mi><mi id="S4.E9.m1.2.2.2.2.2.1.1.2.3" xref="S4.E9.m1.2.2.2.2.2.1.1.2.3.cmml">i</mi></msub><mo id="S4.E9.m1.2.2.2.2.2.1.1.1" xref="S4.E9.m1.2.2.2.2.2.1.1.1.cmml">&gt;</mo><mn id="S4.E9.m1.2.2.2.2.2.1.1.3" xref="S4.E9.m1.2.2.2.2.2.1.1.3.cmml">0</mn></mrow><mo stretchy="false" id="S4.E9.m1.2.2.2.2.2.1.3" xref="S4.E9.m1.2.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S4.E9.m1.3.3.3" xref="S4.E9.m1.3.3.3.cmml"><msub id="S4.E9.m1.3.3.3.2" xref="S4.E9.m1.3.3.3.2.cmml"><mo id="S4.E9.m1.3.3.3.2.2" xref="S4.E9.m1.3.3.3.2.2.cmml">âˆ‘</mo><mi id="S4.E9.m1.3.3.3.2.3" xref="S4.E9.m1.3.3.3.2.3.cmml">i</mi></msub><mrow id="S4.E9.m1.3.3.3.1" xref="S4.E9.m1.3.3.3.1.cmml"><mi id="S4.E9.m1.3.3.3.1.3" xref="S4.E9.m1.3.3.3.1.3.cmml">Î´</mi><mo lspace="0em" rspace="0em" id="S4.E9.m1.3.3.3.1.2" xref="S4.E9.m1.3.3.3.1.2.cmml">â€‹</mo><mrow id="S4.E9.m1.3.3.3.1.1.1" xref="S4.E9.m1.3.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.E9.m1.3.3.3.1.1.1.2" xref="S4.E9.m1.3.3.3.1.1.1.1.cmml">(</mo><mrow id="S4.E9.m1.3.3.3.1.1.1.1" xref="S4.E9.m1.3.3.3.1.1.1.1.cmml"><msub id="S4.E9.m1.3.3.3.1.1.1.1.2" xref="S4.E9.m1.3.3.3.1.1.1.1.2.cmml"><mi id="S4.E9.m1.3.3.3.1.1.1.1.2.2" xref="S4.E9.m1.3.3.3.1.1.1.1.2.2.cmml">v</mi><mi id="S4.E9.m1.3.3.3.1.1.1.1.2.3" xref="S4.E9.m1.3.3.3.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.E9.m1.3.3.3.1.1.1.1.1" xref="S4.E9.m1.3.3.3.1.1.1.1.1.cmml">&gt;</mo><mn id="S4.E9.m1.3.3.3.1.1.1.1.3" xref="S4.E9.m1.3.3.3.1.1.1.1.3.cmml">0</mn></mrow><mo stretchy="false" id="S4.E9.m1.3.3.3.1.1.1.3" xref="S4.E9.m1.3.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.E9.m1.3b"><apply id="S4.E9.m1.3.4.cmml" xref="S4.E9.m1.3.4"><eq id="S4.E9.m1.3.4.1.cmml" xref="S4.E9.m1.3.4.1"></eq><apply id="S4.E9.m1.3.4.2.cmml" xref="S4.E9.m1.3.4.2"><times id="S4.E9.m1.3.4.2.1.cmml" xref="S4.E9.m1.3.4.2.1"></times><ci id="S4.E9.m1.3.4.2.2.cmml" xref="S4.E9.m1.3.4.2.2">ğ‘‚</ci><ci id="S4.E9.m1.3.4.2.3.cmml" xref="S4.E9.m1.3.4.2.3">ğ¾</ci><ci id="S4.E9.m1.3.4.2.4.cmml" xref="S4.E9.m1.3.4.2.4">ğ‘†</ci></apply><apply id="S4.E9.m1.3.3.cmml" xref="S4.E9.m1.3.3"><divide id="S4.E9.m1.3.3.4.cmml" xref="S4.E9.m1.3.3"></divide><apply id="S4.E9.m1.2.2.2.cmml" xref="S4.E9.m1.2.2.2"><apply id="S4.E9.m1.2.2.2.3.cmml" xref="S4.E9.m1.2.2.2.3"><csymbol cd="ambiguous" id="S4.E9.m1.2.2.2.3.1.cmml" xref="S4.E9.m1.2.2.2.3">subscript</csymbol><sum id="S4.E9.m1.2.2.2.3.2.cmml" xref="S4.E9.m1.2.2.2.3.2"></sum><ci id="S4.E9.m1.2.2.2.3.3.cmml" xref="S4.E9.m1.2.2.2.3.3">ğ‘–</ci></apply><apply id="S4.E9.m1.2.2.2.2.cmml" xref="S4.E9.m1.2.2.2.2"><times id="S4.E9.m1.2.2.2.2.3.cmml" xref="S4.E9.m1.2.2.2.2.3"></times><ci id="S4.E9.m1.2.2.2.2.4.cmml" xref="S4.E9.m1.2.2.2.2.4">ğ‘’</ci><ci id="S4.E9.m1.2.2.2.2.5.cmml" xref="S4.E9.m1.2.2.2.2.5">ğ‘¥</ci><ci id="S4.E9.m1.2.2.2.2.6.cmml" xref="S4.E9.m1.2.2.2.2.6">ğ‘</ci><apply id="S4.E9.m1.1.1.1.1.1.1.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1"><minus id="S4.E9.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1"></minus><apply id="S4.E9.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2"><divide id="S4.E9.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2"></divide><apply id="S4.E9.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2">superscript</csymbol><apply id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2">subscript</csymbol><apply id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2"><ci id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.1">^</ci><ci id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.2.2">ğ‘‘</ci></apply><ci id="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.2.3">ğ‘–</ci></apply><cn type="integer" id="S4.E9.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.2.3">2</cn></apply><apply id="S4.E9.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3"><times id="S4.E9.m1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.1"></times><cn type="integer" id="S4.E9.m1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.2">2</cn><apply id="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.3">superscript</csymbol><ci id="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.2">ğ‘ </ci><cn type="integer" id="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.3.3">2</cn></apply><apply id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4">superscript</csymbol><apply id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4">subscript</csymbol><ci id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.2">ğ‘˜</ci><ci id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.2.3">ğ‘–</ci></apply><cn type="integer" id="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2.3.4.3">2</cn></apply></apply></apply></apply><ci id="S4.E9.m1.2.2.2.2.7.cmml" xref="S4.E9.m1.2.2.2.2.7">ğ›¿</ci><apply id="S4.E9.m1.2.2.2.2.2.1.1.cmml" xref="S4.E9.m1.2.2.2.2.2.1"><gt id="S4.E9.m1.2.2.2.2.2.1.1.1.cmml" xref="S4.E9.m1.2.2.2.2.2.1.1.1"></gt><apply id="S4.E9.m1.2.2.2.2.2.1.1.2.cmml" xref="S4.E9.m1.2.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E9.m1.2.2.2.2.2.1.1.2.1.cmml" xref="S4.E9.m1.2.2.2.2.2.1.1.2">subscript</csymbol><ci id="S4.E9.m1.2.2.2.2.2.1.1.2.2.cmml" xref="S4.E9.m1.2.2.2.2.2.1.1.2.2">ğ‘£</ci><ci id="S4.E9.m1.2.2.2.2.2.1.1.2.3.cmml" xref="S4.E9.m1.2.2.2.2.2.1.1.2.3">ğ‘–</ci></apply><cn type="integer" id="S4.E9.m1.2.2.2.2.2.1.1.3.cmml" xref="S4.E9.m1.2.2.2.2.2.1.1.3">0</cn></apply></apply></apply><apply id="S4.E9.m1.3.3.3.cmml" xref="S4.E9.m1.3.3.3"><apply id="S4.E9.m1.3.3.3.2.cmml" xref="S4.E9.m1.3.3.3.2"><csymbol cd="ambiguous" id="S4.E9.m1.3.3.3.2.1.cmml" xref="S4.E9.m1.3.3.3.2">subscript</csymbol><sum id="S4.E9.m1.3.3.3.2.2.cmml" xref="S4.E9.m1.3.3.3.2.2"></sum><ci id="S4.E9.m1.3.3.3.2.3.cmml" xref="S4.E9.m1.3.3.3.2.3">ğ‘–</ci></apply><apply id="S4.E9.m1.3.3.3.1.cmml" xref="S4.E9.m1.3.3.3.1"><times id="S4.E9.m1.3.3.3.1.2.cmml" xref="S4.E9.m1.3.3.3.1.2"></times><ci id="S4.E9.m1.3.3.3.1.3.cmml" xref="S4.E9.m1.3.3.3.1.3">ğ›¿</ci><apply id="S4.E9.m1.3.3.3.1.1.1.1.cmml" xref="S4.E9.m1.3.3.3.1.1.1"><gt id="S4.E9.m1.3.3.3.1.1.1.1.1.cmml" xref="S4.E9.m1.3.3.3.1.1.1.1.1"></gt><apply id="S4.E9.m1.3.3.3.1.1.1.1.2.cmml" xref="S4.E9.m1.3.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E9.m1.3.3.3.1.1.1.1.2.1.cmml" xref="S4.E9.m1.3.3.3.1.1.1.1.2">subscript</csymbol><ci id="S4.E9.m1.3.3.3.1.1.1.1.2.2.cmml" xref="S4.E9.m1.3.3.3.1.1.1.1.2.2">ğ‘£</ci><ci id="S4.E9.m1.3.3.3.1.1.1.1.2.3.cmml" xref="S4.E9.m1.3.3.3.1.1.1.1.2.3">ğ‘–</ci></apply><cn type="integer" id="S4.E9.m1.3.3.3.1.1.1.1.3.cmml" xref="S4.E9.m1.3.3.3.1.1.1.1.3">0</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E9.m1.3c">\displaystyle OKS=\frac{\sum_{i}exp(-\frac{\hat{d}_{i}^{2}}{2s^{2}k_{i}^{2}})\delta(v_{i}&gt;0)}{\sum_{i}\delta(v_{i}&gt;0)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS2.SSS0.Px3.p3" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p3.4" class="ltx_p">where <math id="S4.SS2.SSS0.Px3.p3.1.m1.1" class="ltx_Math" alttext="\hat{d_{i}}" display="inline"><semantics id="S4.SS2.SSS0.Px3.p3.1.m1.1a"><mover accent="true" id="S4.SS2.SSS0.Px3.p3.1.m1.1.1" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.cmml"><msub id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.cmml"><mi id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.2" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.2.cmml">d</mi><mi id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.3" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.1" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p3.1.m1.1b"><apply id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1"><ci id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.1">^</ci><apply id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.1.cmml" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.2.cmml" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.2">ğ‘‘</ci><ci id="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.3.cmml" xref="S4.SS2.SSS0.Px3.p3.1.m1.1.1.2.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p3.1.m1.1c">\hat{d_{i}}</annotation></semantics></math> is the L2 distance between the i-th keypoint and the groundtruth. <math id="S4.SS2.SSS0.Px3.p3.2.m2.1" class="ltx_Math" alttext="v_{i}" display="inline"><semantics id="S4.SS2.SSS0.Px3.p3.2.m2.1a"><msub id="S4.SS2.SSS0.Px3.p3.2.m2.1.1" xref="S4.SS2.SSS0.Px3.p3.2.m2.1.1.cmml"><mi id="S4.SS2.SSS0.Px3.p3.2.m2.1.1.2" xref="S4.SS2.SSS0.Px3.p3.2.m2.1.1.2.cmml">v</mi><mi id="S4.SS2.SSS0.Px3.p3.2.m2.1.1.3" xref="S4.SS2.SSS0.Px3.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p3.2.m2.1b"><apply id="S4.SS2.SSS0.Px3.p3.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px3.p3.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px3.p3.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p3.2.m2.1.1.2">ğ‘£</ci><ci id="S4.SS2.SSS0.Px3.p3.2.m2.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p3.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p3.2.m2.1c">v_{i}</annotation></semantics></math> denotes the visibility of the keypoint. <math id="S4.SS2.SSS0.Px3.p3.3.m3.1" class="ltx_Math" alttext="k_{i}" display="inline"><semantics id="S4.SS2.SSS0.Px3.p3.3.m3.1a"><msub id="S4.SS2.SSS0.Px3.p3.3.m3.1.1" xref="S4.SS2.SSS0.Px3.p3.3.m3.1.1.cmml"><mi id="S4.SS2.SSS0.Px3.p3.3.m3.1.1.2" xref="S4.SS2.SSS0.Px3.p3.3.m3.1.1.2.cmml">k</mi><mi id="S4.SS2.SSS0.Px3.p3.3.m3.1.1.3" xref="S4.SS2.SSS0.Px3.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p3.3.m3.1b"><apply id="S4.SS2.SSS0.Px3.p3.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px3.p3.3.m3.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px3.p3.3.m3.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p3.3.m3.1.1.2">ğ‘˜</ci><ci id="S4.SS2.SSS0.Px3.p3.3.m3.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p3.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p3.3.m3.1c">k_{i}</annotation></semantics></math> is a keypoint-specific constant, which is different for different keypoint. We adopt the same evaluation metric to COCO for the infant pose dataset. As the new proposed infant pose has 21 keypoints, we set <math id="S4.SS2.SSS0.Px3.p3.4.m4.1" class="ltx_Math" alttext="k_{i}" display="inline"><semantics id="S4.SS2.SSS0.Px3.p3.4.m4.1a"><msub id="S4.SS2.SSS0.Px3.p3.4.m4.1.1" xref="S4.SS2.SSS0.Px3.p3.4.m4.1.1.cmml"><mi id="S4.SS2.SSS0.Px3.p3.4.m4.1.1.2" xref="S4.SS2.SSS0.Px3.p3.4.m4.1.1.2.cmml">k</mi><mi id="S4.SS2.SSS0.Px3.p3.4.m4.1.1.3" xref="S4.SS2.SSS0.Px3.p3.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p3.4.m4.1b"><apply id="S4.SS2.SSS0.Px3.p3.4.m4.1.1.cmml" xref="S4.SS2.SSS0.Px3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px3.p3.4.m4.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p3.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px3.p3.4.m4.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p3.4.m4.1.1.2">ğ‘˜</ci><ci id="S4.SS2.SSS0.Px3.p3.4.m4.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p3.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p3.4.m4.1c">k_{i}</annotation></semantics></math> of each keypoint to the same value.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Keypoints detection on COCO pose estimation.</h5>

<div id="S4.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px4.p1.2" class="ltx_p">TableÂ <a href="#S3.T3" title="Table 3 â€£ (2) Faster convergence. â€£ 3.3 Analysis â€£ 3 Proposed Method â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the comparisons on COCO val set. We compare AggPose with several state-of-art methods, including HRFormerÂ <cite class="ltx_cite ltx_citemacro_cite">Yuan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>, TokenPoseÂ <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>, TransPoseÂ <cite class="ltx_cite ltx_citemacro_cite">Yang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>, HRNetÂ <cite class="ltx_cite ltx_citemacro_cite">Wang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>. For input size of 256<math id="S4.SS2.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.1.m1.1a"><mo id="S4.SS2.SSS0.Px4.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.1.m1.1b"><times id="S4.SS2.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.1.m1.1c">\times</annotation></semantics></math>192, AggPose-L achieves 76.4 AP, which is best among all methods. We believe that AggPose-L can achieve better results after applying the newest distribution-aware coordinate representationÂ <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite> or UDPÂ <cite class="ltx_cite ltx_citemacro_cite">Huang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>. AggPose-L achieves 75.7 AP on the COCO test-dev set with 256 <math id="S4.SS2.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS2.SSS0.Px4.p1.2.m2.1a"><mo id="S4.SS2.SSS0.Px4.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px4.p1.2.m2.1b"><times id="S4.SS2.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px4.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px4.p1.2.m2.1c">\times</annotation></semantics></math> 192 input size.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Keypoints detection on infant pose estimation.</h5>

<div id="S4.SS2.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px5.p1.1" class="ltx_p">TableÂ <a href="#S4.T4" title="Table 4 â€£ Keypoints detection on infant pose estimation. â€£ 4.2 Comparing with SOTA Methods â€£ 4 Experiment â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> reports the comparisons on our infant pose test set. We compare AggPose to the most representative bottom-up method OpenPose, as it is used by almost all newest proposed infant pose estimation frameworksÂ <cite class="ltx_cite ltx_citemacro_cite">Silva <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>. We also compare AggPose to several recent CNN and hybrid Transformer models such as HRNet, TokenPose, and HRFormer. AggPose gains the highest 95.0 AP with an input size of 256<math id="S4.SS2.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS2.SSS0.Px5.p1.1.m1.1a"><mo id="S4.SS2.SSS0.Px5.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px5.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px5.p1.1.m1.1b"><times id="S4.SS2.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px5.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px5.p1.1.m1.1c">\times</annotation></semantics></math>192. During the training, we also find that both AggPose and HRNet perform better and converge faster than hybrid model such as TokenPose, and HRFormer. Though all of these models are pre-trained on COCO dataset, full CNN or full Transformer based methods are more robust after we fine-tune them on other domain like infant pose data.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.6.7.1" class="ltx_tr">
<th id="S4.T4.6.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Method</th>
<th id="S4.T4.6.7.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">image size</th>
<th id="S4.T4.6.7.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">AP</th>
<th id="S4.T4.6.7.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">AR</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1" class="ltx_tr">
<th id="S4.T4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">OpenPose</th>
<td id="S4.T4.1.1.1" class="ltx_td ltx_align_right ltx_border_t">256<math id="S4.T4.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.1.1.1.m1.1a"><mo id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><times id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S4.T4.1.1.3" class="ltx_td ltx_align_right ltx_border_t">90.2</td>
<td id="S4.T4.1.1.4" class="ltx_td ltx_align_right ltx_border_t">91.1</td>
</tr>
<tr id="S4.T4.2.2" class="ltx_tr">
<th id="S4.T4.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">SimpleBaseline-Res152</th>
<td id="S4.T4.2.2.1" class="ltx_td ltx_align_right">256<math id="S4.T4.2.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.2.2.1.m1.1a"><mo id="S4.T4.2.2.1.m1.1.1" xref="S4.T4.2.2.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.1.m1.1b"><times id="S4.T4.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S4.T4.2.2.3" class="ltx_td ltx_align_right">93.9</td>
<td id="S4.T4.2.2.4" class="ltx_td ltx_align_right">94.9</td>
</tr>
<tr id="S4.T4.3.3" class="ltx_tr">
<th id="S4.T4.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">HRNet-W48</th>
<td id="S4.T4.3.3.1" class="ltx_td ltx_align_right">256<math id="S4.T4.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.3.3.1.m1.1a"><mo id="S4.T4.3.3.1.m1.1.1" xref="S4.T4.3.3.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.1.m1.1b"><times id="S4.T4.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S4.T4.3.3.3" class="ltx_td ltx_align_right">94.5</td>
<td id="S4.T4.3.3.4" class="ltx_td ltx_align_right">95.6</td>
</tr>
<tr id="S4.T4.4.4" class="ltx_tr">
<th id="S4.T4.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">HRFormer-B</th>
<td id="S4.T4.4.4.1" class="ltx_td ltx_align_right">256<math id="S4.T4.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.4.4.1.m1.1a"><mo id="S4.T4.4.4.1.m1.1.1" xref="S4.T4.4.4.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.1.m1.1b"><times id="S4.T4.4.4.1.m1.1.1.cmml" xref="S4.T4.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S4.T4.4.4.3" class="ltx_td ltx_align_right">93.8</td>
<td id="S4.T4.4.4.4" class="ltx_td ltx_align_right">95.0</td>
</tr>
<tr id="S4.T4.5.5" class="ltx_tr">
<th id="S4.T4.5.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">TokenPose-L/D24</th>
<td id="S4.T4.5.5.1" class="ltx_td ltx_align_right">256<math id="S4.T4.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.5.5.1.m1.1a"><mo id="S4.T4.5.5.1.m1.1.1" xref="S4.T4.5.5.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.1.m1.1b"><times id="S4.T4.5.5.1.m1.1.1.cmml" xref="S4.T4.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S4.T4.5.5.3" class="ltx_td ltx_align_right">93.0</td>
<td id="S4.T4.5.5.4" class="ltx_td ltx_align_right">93.9</td>
</tr>
<tr id="S4.T4.6.6" class="ltx_tr">
<th id="S4.T4.6.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">AggPose-L</th>
<td id="S4.T4.6.6.1" class="ltx_td ltx_align_right ltx_border_bb">256<math id="S4.T4.6.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.6.6.1.m1.1a"><mo id="S4.T4.6.6.1.m1.1.1" xref="S4.T4.6.6.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.1.m1.1b"><times id="S4.T4.6.6.1.m1.1.1.cmml" xref="S4.T4.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S4.T4.6.6.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T4.6.6.3.1" class="ltx_text ltx_font_bold">95.0</span></td>
<td id="S4.T4.6.6.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T4.6.6.4.1" class="ltx_text ltx_font_bold">95.7</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Comparisons on the infant pose test set, provided with the same object detection boxes (OpenPose do not need object detection, as it is a bottom-up method. We select OpenPose for comparison is because most of newest proposed infant pose estimation frameworks are choose OpenPose as backbone.)</figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.3.4.1" class="ltx_tr">
<th id="S4.T5.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Method</th>
<th id="S4.T5.3.4.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">image size</th>
<th id="S4.T5.3.4.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">GFLOPs</th>
<th id="S4.T5.3.4.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">AP</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1" class="ltx_tr">
<th id="S4.T5.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Swin-B</th>
<td id="S4.T5.1.1.1" class="ltx_td ltx_align_right ltx_border_t">256<math id="S4.T5.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.1.1.1.m1.1a"><mo id="S4.T5.1.1.1.m1.1.1" xref="S4.T5.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.m1.1b"><times id="S4.T5.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S4.T5.1.1.3" class="ltx_td ltx_align_right ltx_border_t">17.6</td>
<td id="S4.T5.1.1.4" class="ltx_td ltx_align_right ltx_border_t">74.3</td>
</tr>
<tr id="S4.T5.2.2" class="ltx_tr">
<th id="S4.T5.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">SegFormer-B5</th>
<td id="S4.T5.2.2.1" class="ltx_td ltx_align_right">256<math id="S4.T5.2.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.2.2.1.m1.1a"><mo id="S4.T5.2.2.1.m1.1.1" xref="S4.T5.2.2.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.1.m1.1b"><times id="S4.T5.2.2.1.m1.1.1.cmml" xref="S4.T5.2.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S4.T5.2.2.3" class="ltx_td ltx_align_right">12.3</td>
<td id="S4.T5.2.2.4" class="ltx_td ltx_align_right">74.2</td>
</tr>
<tr id="S4.T5.3.3" class="ltx_tr">
<th id="S4.T5.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">AggPose-L</th>
<td id="S4.T5.3.3.1" class="ltx_td ltx_align_right ltx_border_bb">256<math id="S4.T5.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.3.3.1.m1.1a"><mo id="S4.T5.3.3.1.m1.1.1" xref="S4.T5.3.3.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.1.m1.1b"><times id="S4.T5.3.3.1.m1.1.1.cmml" xref="S4.T5.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.1.m1.1c">\times</annotation></semantics></math>192</td>
<td id="S4.T5.3.3.3" class="ltx_td ltx_align_right ltx_border_bb">15.0</td>
<td id="S4.T5.3.3.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T5.3.3.4.1" class="ltx_text ltx_font_bold">76.4</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Comparisons to Non-aggregation framework (Swin Transformer, SegFormer) on COCO pose estimation val</figcaption>
</figure>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2205.05277/assets/figures/heatmap_infant.jpg" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Visualization of the pose estimation heatmap results based on AggPose-L on infant pose test set.</figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2205.05277/assets/figures/coco_vis.jpg" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="268" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Visualization of the pose estimation results based on AggPose-L on COCO val.</figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2205.05277/assets/figures/infant_vis.jpg" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="161" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Visualization of the pose estimation results based on AggPose-L on infant pose test.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation Experiments</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In previous sections, we compare AggPose with several state-of-art human pose estimation methods. To verify the techniques used in our method, we make detailed ablation studies in this subsection.</p>
</div>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Influence of full Transformer backbone.</h5>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">Considering all of the other new proposed hybrid methods are using HRNetâ€™s CNN encoder as backbone, we compare our method (without using convolution layers in the first stage) with the CNN scheme of HRNet in TableÂ <a href="#S3.T3" title="Table 3 â€£ (2) Faster convergence. â€£ 3.3 Analysis â€£ 3 Proposed Method â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The Backbone column shows the difference of the first stage inside the model. Both AggPose-S and AggPose-L are using SegFormer, a Transformer-based method as the first stage layer. Although other authors claim Transformers in the early stage will lead to lack detailed localization information, we observe that the full Transformer-based early stage of AggPose can still achieve better performance.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Influence of Deep Aggregation Framework.</h5>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.1" class="ltx_p">We report the COCO pose estimation results based on two well-known full transformer models, Swin Transformer and SegFormer in TableÂ <a href="#S4.T5" title="Table 5 â€£ Keypoints detection on infant pose estimation. â€£ 4.2 Comparing with SOTA Methods â€£ 4 Experiment â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Both the Swin-B and SegFormer-B5 are pre-trained on ImageNet21K and fine-tuned on COCO with 300 epochs. In fact, AggPose-L can be considered as a deep layer aggregation structure of SegFormer-B5 with MLP skip-connection. According to the results in TableÂ <a href="#S4.T5" title="Table 5 â€£ Keypoints detection on infant pose estimation. â€£ 4.2 Comparing with SOTA Methods â€£ 4 Experiment â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, our proposed multi-resolution aggregation framework (AggPose) achieves better performance than both Swin Transformer and SegFormer.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Visualization Analysis</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We provide qualitative results on both COCO val set and infant pose test set, as shown in FigureÂ <a href="#S4.F3" title="Figure 3 â€£ Keypoints detection on infant pose estimation. â€£ 4.2 Comparing with SOTA Methods â€£ 4 Experiment â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, FigureÂ <a href="#S4.F4" title="Figure 4 â€£ Keypoints detection on infant pose estimation. â€£ 4.2 Comparing with SOTA Methods â€£ 4 Experiment â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and FigureÂ <a href="#S4.F5" title="Figure 5 â€£ Keypoints detection on infant pose estimation. â€£ 4.2 Comparing with SOTA Methods â€£ 4 Experiment â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. FigureÂ <a href="#S4.F3" title="Figure 3 â€£ Keypoints detection on infant pose estimation. â€£ 4.2 Comparing with SOTA Methods â€£ 4 Experiment â€£ AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows a group of predictions and dependency areas for infant pose heatmap. Although infant pose data formats use more keypoints than COCO. AggPose still learns good representations in capturing constraint relationships between human keypoints.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">By leveraging a new dataset with pose labels and clinical labels, we built a Transformer-based infant pose estimation framework which can accurately detect infant supine position pose from movement frames in video. The key insight of the AggPose model is the deep aggregation Transformer with cross-layer MLP connection. The pose sequence generated by our model has been used in neurodevelopmental disorder prediction for newborns and early evaluation for related diseases. Besides, our method can be packaged to mobile devices in the future and solve inequality in medical resources and privacy protection for patients. Although our results are promising, we acknowledge that there is still a long path to apply our model completely end-to-end with currently available hardware.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">In addition to testing the utility of AggPose in real-time infant pose extraction and evaluation, a clear next step would be predicting the cerebral palsy via pose sequence understanding models in the futureâ€“before it is even visible to a trained pediatrician eye. For countries with limited pediatricians, this will greatly reduce the risk of severe disability in children.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by Sanming Project of Medicine in Shenzhen, China (SZSM202011005).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abbruzzese <span id="bib.bib1.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
LaurelÂ Daniels Abbruzzese, Natasha Yamane, Deborah Fein, Letitia Naigles, and
Sylvie Goldman.

</span>
<span class="ltx_bibblock">Assessing child postural variability: Development, feasibility, and
reliability of a video coding system.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic">Physical &amp; Occupational Therapy In Pediatrics</span>, 41(3):314â€“325,
2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao and Lin [2021]</span>
<span class="ltx_bibblock">
XuÂ Cao and Yanghao Lin.

</span>
<span class="ltx_bibblock">Caggnet: Crossing aggregation network for medical image segmentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">2020 25th International Conference on Pattern Recognition
(ICPR)</span>, pages 1744â€“1750. IEEE, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao <span id="bib.bib3.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei, and Yaser Sheikh.

</span>
<span class="ltx_bibblock">Openpose: realtime multi-person 2d pose estimation using part
affinity fields.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</span>,
43(1):172â€“186, 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng <span id="bib.bib4.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Bowen Cheng, Bin Xiao, Jingdong Wang, Honghui Shi, ThomasÂ S Huang, and Lei
Zhang.

</span>
<span class="ltx_bibblock">Higherhrnet: Scale-aware representation learning for bottom-up human
pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.3.1" class="ltx_text ltx_font_italic">Proceedings of CVPR</span>, pages 5386â€“5395, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu <span id="bib.bib5.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Jiaqi Gu, Hyoukjun Kwon, Dilin Wang, Wei Ye, Meng Li, Yu-Hsin Chen, Liangzhen
Lai, Vikas Chandra, and DavidÂ Z Pan.

</span>
<span class="ltx_bibblock">Multi-scale high-resolution vision transformer for semantic
segmentation.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2111.01236</span>, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He <span id="bib.bib6.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÃ¡r, and Ross
Girshick.

</span>
<span class="ltx_bibblock">Masked autoencoders are scalable vision learners.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2111.06377</span>, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hesse <span id="bib.bib7.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018]</span>
<span class="ltx_bibblock">
Nikolas Hesse, Christoph Bodensteiner, Michael Arens, UlrichÂ G Hofmann, Raphael
Weinberger, and AÂ SebastianÂ Schroeder.

</span>
<span class="ltx_bibblock">Computer vision for medical infant motion analysis: State of the art
and rgb-d data set.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.3.1" class="ltx_text ltx_font_italic">Proceedings of ECCV Workshops</span>, pages 0â€“0, 2018.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang <span id="bib.bib8.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Junjie Huang, Zheng Zhu, Feng Guo, and Guan Huang.

</span>
<span class="ltx_bibblock">The devil is in the details: Delving into unbiased data processing
for human pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.3.1" class="ltx_text ltx_font_italic">Proceedings of CVPR</span>, pages 5700â€“5709, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang <span id="bib.bib9.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Xiaofei Huang, Nihang Fu, Shuangjun Liu, and Sarah Ostadabbas.

</span>
<span class="ltx_bibblock">Invariant representation learning for infant pose estimation with
small data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.3.1" class="ltx_text ltx_font_italic">2021 16th IEEE International Conference on Automatic Face and
Gesture Recognition (FG 2021)</span>, pages 1â€“8. IEEE, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib10.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Yanjie Li, Shoukui Zhang, Zhicheng Wang, Sen Yang, Wankou Yang, Shu-Tao Xia,
and Erjin Zhou.

</span>
<span class="ltx_bibblock">Tokenpose: Learning keypoint tokens for human pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.3.1" class="ltx_text ltx_font_italic">Proceedings of ICCV</span>, pages 11313â€“11322, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin <span id="bib.bib11.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2014]</span>
<span class="ltx_bibblock">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr DollÃ¡r, and CÂ Lawrence Zitnick.

</span>
<span class="ltx_bibblock">Microsoft coco: Common objects in context.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.3.1" class="ltx_text ltx_font_italic">ECCV</span>, pages 740â€“755. Springer, 2014.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu <span id="bib.bib12.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
ZeÂ Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
Baining Guo.

</span>
<span class="ltx_bibblock">Swin transformer: Hierarchical vision transformer using shifted
windows.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.14030</span>, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCay <span id="bib.bib13.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
KevinÂ D McCay, EdmondÂ SL Ho, Claire Marcroft, and NicholasÂ D Embleton.

</span>
<span class="ltx_bibblock">Establishing pose based features using histograms for the detection
of abnormal infant movements.

</span>
<span class="ltx_bibblock">In <span id="bib.bib13.3.1" class="ltx_text ltx_font_italic">EMBC</span>, pages 5469â€“5472. IEEE, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reich <span id="bib.bib14.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Simon Reich, Dajie Zhang, Tomas Kulvicius, Sven BÃ¶lte, Karin
Nielsen-Saines, FlorianÂ B Pokorny, Robert Peharz, Luise Poustka, Florentin
WÃ¶rgÃ¶tter, Christa Einspieler, etÂ al.

</span>
<span class="ltx_bibblock">Novel ai driven approach to classify infant motor functions.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic">Scientific Reports</span>, 11(1):1â€“13, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silva <span id="bib.bib15.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Nelson Silva, Dajie Zhang, Tomas Kulvicius, Alexander Gail, Carla Barreiros,
Stefanie Lindstaedt, Marc Kraft, Sven BÃ¶lte, Luise Poustka, Karin
Nielsen-Saines, etÂ al.

</span>
<span class="ltx_bibblock">The future of general movement assessment: The role of computer
vision and machine learningâ€“a scoping review.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic">Research in developmental disabilities</span>, 110:103854, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang <span id="bib.bib16.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Jingdong Wang, KeÂ Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao,
Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, etÂ al.

</span>
<span class="ltx_bibblock">Deep high-resolution representation learning for visual recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</span>,
2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang <span id="bib.bib17.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong
Lu, Ping Luo, and Ling Shao.

</span>
<span class="ltx_bibblock">Pyramid vision transformer: A versatile backbone for dense prediction
without convolutions.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.12122</span>, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie <span id="bib.bib18.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, JoseÂ M Alvarez, and Ping
Luo.

</span>
<span class="ltx_bibblock">Segformer: Simple and efficient design for semantic segmentation with
transformers.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2105.15203</span>, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang <span id="bib.bib19.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Sen Yang, Zhibin Quan, MuÂ Nie, and Wankou Yang.

</span>
<span class="ltx_bibblock">Transpose: Keypoint localization via transformer.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.3.1" class="ltx_text ltx_font_italic">Proceedings of ICCV</span>, pages 11802â€“11812, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan <span id="bib.bib20.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Yuhui Yuan, Rao Fu, Lang Huang, Weihong Lin, Chao Zhang, Xilin Chen, and
Jingdong Wang.

</span>
<span class="ltx_bibblock">Hrformer: High-resolution transformer for dense prediction.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2110.09408</span>, 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang <span id="bib.bib21.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Feng Zhang, Xiatian Zhu, Hanbin Dai, Mao Ye, and CeÂ Zhu.

</span>
<span class="ltx_bibblock">Distribution-aware coordinate representation for human pose
estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.3.1" class="ltx_text ltx_font_italic">Proceedings of CVPR</span>, pages 7093â€“7102, 2020.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2205.05276" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2205.05277" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2205.05277">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2205.05277" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2205.05278" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 13:26:11 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
