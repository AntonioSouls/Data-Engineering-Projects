<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2307.09662] Object-aware Gaze Target Detection</title><meta property="og:description" content="Gaze target detection aims to predict the image location where the person is looking and the probability that a gaze is out of the scene.
Several works have tackled this task by regressing a gaze heatmap centered on thâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Object-aware Gaze Target Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Object-aware Gaze Target Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2307.09662">

<!--Generated on Mon Feb 26 21:55:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Object-aware Gaze Target Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Francesco Tonini<sup id="id8.8.id1" class="ltx_sup"><span id="id8.8.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Nicola Dallâ€™Asen<sup id="id9.9.id2" class="ltx_sup"><span id="id9.9.id2.1" class="ltx_text ltx_font_italic">1,3</span></sup>, Cigdem Beyan<sup id="id10.10.id3" class="ltx_sup"><span id="id10.10.id3.1" class="ltx_text ltx_font_italic">1</span></sup>, Elisa Ricci<sup id="id11.11.id4" class="ltx_sup"><span id="id11.11.id4.1" class="ltx_text ltx_font_italic">1,2</span></sup>
<br class="ltx_break"><sup id="id12.12.id5" class="ltx_sup"><span id="id12.12.id5.1" class="ltx_text ltx_font_italic">1</span></sup> University of Trento, Trento, ItalyÂ 
<sup id="id13.13.id6" class="ltx_sup"><span id="id13.13.id6.1" class="ltx_text ltx_font_italic">2</span></sup> Fondazione Bruno Kessler, Trento, Italy
<br class="ltx_break"><sup id="id14.14.id7" class="ltx_sup"><span id="id14.14.id7.1" class="ltx_text ltx_font_italic">3</span></sup> University of Pisa, Pisa, Italy
<br class="ltx_break"><span id="id15.15.id8" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{francesco.tonini, nicola.dallasen, cigdem.beyan, e.ricci}@unitn.it</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id16.id1" class="ltx_p">Gaze target detection aims to predict the image location where the person is looking and the probability that a gaze is out of the scene.
Several works have tackled this task by regressing a gaze heatmap centered on the gaze location, however, they overlooked decoding the relationship between the people and the gazed objects. This paper proposes a Transformer-based architecture that automatically detects objects (including heads) in the scene to build associations between every head and the gazed-head/object, resulting in a comprehensive, explainable gaze analysis composed of: gaze target area, gaze pixel point, the class and the image location of the gazed-object. Upon evaluation of the in-the-wild benchmarks, our method achieves state-of-the-art results on all metrics (up to 2.91% gain in AUC, 50% reduction in gaze distance, and 9% gain in out-of-frame average precision) for gaze target detection and 11-13% improvement in average precision for the classification and the localization of the gazed-objects.
The code of the proposed method is publicly available<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/francescotonini/object-aware-gaze-target-detection" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/francescotonini/object-aware-gaze-target-detection</a></span></span></span>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Gazing is a powerful nonverbal signal, which indicates the visual attention of a person and allows one to understand the interest, intention, or (future) action of people <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. For this reason, gaze analysis has widely been used in several disciplines such as human-computer interaction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, neuroscience <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, social and organizational psychology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, and social robotics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> to name a few.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Even though human beings have a remarkable capability to decode the gaze behavior of others, realizing this task <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">automatically</em> remains a challenging problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. The computer vision community has tackled the automated gaze behavior analysis in terms of two tasks: (a) <em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">gaze estimation</em> and (b) <em id="S1.p2.1.3" class="ltx_emph ltx_font_italic">gaze target detection</em>. Gaze estimation stands for predicting the personâ€™s gaze direction (usually in 3D) when typically a <em id="S1.p2.1.4" class="ltx_emph ltx_font_italic">cropped human head image</em> is given as the input <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Instead, gaze target detection (also referred to as gaze-following) is to determine the specific (2D or 3D) location that a human is looking at in an <em id="S1.p2.1.5" class="ltx_emph ltx_font_italic">in-the-wild</em> sceneÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div id="S1.F1.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:365pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(3.7pt,-3.1pt) scale(1.01753873366777,1.01753873366777) ;">
<table id="S1.F1.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S1.F1.1.1.1" class="ltx_tr">
<th id="S1.F1.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_row"><span id="S1.F1.1.1.1.2.1" class="ltx_text" style="position:relative; bottom:0.2pt;">
<span id="S1.F1.1.1.1.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:48.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:48.6pt;transform:translate(-20.85pt,-20.85pt) rotate(-90deg) ;">
<span id="S1.F1.1.1.1.2.1.1.1" class="ltx_p">Traditional</span>
</span></span></span></th>
<td id="S1.F1.1.1.1.1" class="ltx_td ltx_align_left"><img src="/html/2307.09662/assets/images/teaser/traditional.png" id="S1.F1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="192" alt="Refer to caption"></td>
</tr>
<tr id="S1.F1.2.2.2" class="ltx_tr">
<th id="S1.F1.2.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_row"><span id="S1.F1.2.2.2.2.1" class="ltx_text" style="position:relative; bottom:-0.1pt;">
<span id="S1.F1.2.2.2.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:10.0pt;height:106.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:106.9pt;transform:translate(-48.47pt,-47.22pt) rotate(-90deg) ;">
<span id="S1.F1.2.2.2.2.1.1.1" class="ltx_p">Tu et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite></span>
</span></span></span></th>
<td id="S1.F1.2.2.2.1" class="ltx_td ltx_align_left"><img src="/html/2307.09662/assets/images/teaser/tu.png" id="S1.F1.2.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="128" alt="Refer to caption"></td>
</tr>
<tr id="S1.F1.3.3.3" class="ltx_tr">
<th id="S1.F1.3.3.3.2" class="ltx_td ltx_align_right ltx_th ltx_th_row"><span id="S1.F1.3.3.3.2.1" class="ltx_text" style="position:relative; bottom:0.6pt;">
<span id="S1.F1.3.3.3.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.8pt;height:21.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:21.2pt;transform:translate(-7.18pt,-7.18pt) rotate(-90deg) ;">
<span id="S1.F1.3.3.3.2.1.1.1" class="ltx_p">Ours</span>
</span></span></span></th>
<td id="S1.F1.3.3.3.1" class="ltx_td ltx_align_left"><img src="/html/2307.09662/assets/images/teaser/ours.png" id="S1.F1.3.3.3.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="134" alt="Refer to caption"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The overall methodology of the existing approaches and ours.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Several works utilize head pose features and the saliency maps of possible gaze targets to perform gaze target detection.
For instance,Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> followed a two-pathway learning scheme, where one path learns feature embeddings from the scene image, and the other path models the head crops belonging to the person whose gaze target is aimed to be predicted. Chong <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> extend the aforementioned two-pathway approach to perform spatio-temporal modeling to determine the gaze targets in videos. In the same vein, a few other methods exist: <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Among them, some consider a third path to model the depth map of the scene image, which is determined by a monocular depth estimator
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Differently, others <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> inject depth maps and 2D-human poses to improve the 3D understanding of the scenes, resulting in better gaze target detection.
The results achieved by these approaches (referred to as <em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">traditional methods</em> throughout the manuscript, see Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>-top) are highly remarkable since they demonstrated that gaze target estimation could be directly performed on images or videos in contrast to using low-intrusive wearable eye trackers, which notoriously have several issues in terms of cost, battery life, and calibration. On the other hand, traditional methods also have some major drawbacks. First, both training and inference require carefully human-annotated head crops. Therefore, to ensure that traditional methods work well in real-life practical applications, there is a need for additional and highly accurate head detectors. Indeed, Tu <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> showed notable performance drops of traditional methods when head detectors were involved instead of using manually annotated head locations. A second limitation concerns the fact that traditional methods can perform a single gaze target detection at a time; thus, for scenes containing multiple people, the models should be run repeatedly for each person. Besides the computational complexity such implementation brings in, post-processing is also needed to combine the detected gaze targets of different subjects in the same scene. Tu <span id="S1.p3.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> to some extent overcome the shortcomings mentioned above by introducing a Transformer-based architecture that explicitly learns how to detect and localize the head during gaze target detection (see Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>-middle).
However, the contribution of objects to decipher the human-human/object gazing is completely omitted in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Several studies show that people typically gaze at living or non-living <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">objects</em> in the scene during social and physical interactions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. Motivated by this, we pursue an object-aware gaze target detection, instead of using features extracted from holistic scene images and head crops as in traditional methods: Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> or learning how to detect and localize the head of the person-in-interest (the one whose gaze target to be detected) as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Our proposal is not only able to predict the <em id="S1.p4.1.2" class="ltx_emph ltx_font_italic">gaze area</em> (in terms of heatmaps) that people looking at and determine if the gaze target is inside or outside of the scene but also <em id="S1.p4.1.3" class="ltx_emph ltx_font_italic">localize the objects</em> and <em id="S1.p4.1.4" class="ltx_emph ltx_font_italic">predicts the objectsâ€™ classes</em> (including head) on which the gaze point is (see Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>-bottom). The further has significant practical usage since it brings in an <em id="S1.p4.1.5" class="ltx_emph ltx_font_italic">explainable</em> gaze analysis (see TableÂ <a href="#S1.T1" title="Table 1 â€£ 1 Introduction â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for details).</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The proposed method is an end-to-end Transformer-based architecture. Given a scene image, we first extract all objects, including the ones classified as heads, with an <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">Object Detector Transformer</em>. Then, for each head, a gaze vector is predicted. Using this gaze vector, we build a <em id="S1.p5.1.2" class="ltx_emph ltx_font_italic">gaze cone</em> for each person individually, allowing the model to filter out the objects that are not in a personâ€™s Field of View (FoV). Subsequently, a masked transformer (called <em id="S1.p5.1.3" class="ltx_emph ltx_font_italic">Gaze Object Transformer</em>) learns the interactions between the detected heads and objects, boosting the gaze target detection performance in terms of both heatmaps and gaze points (<em id="S1.p5.1.4" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.p5.1.5" class="ltx_text"></span> a single pixel in the scene). Furthermore, this architecture has a remarkable capability to predict whether a gaze target point is out of the frame. The extensive evaluations on two large-scale benchmark datasets show the superior performance of our method <span id="S1.p5.1.6" class="ltx_text ltx_font_italic">w.r.t.</span> state-of-the-art (SOTA) gaze target detectors. At the same time, our model has additional competence to accurately predict the gazed objectsâ€™ locations and the associated classes as empirically demonstrated. The ablation study highlights the importance of all components and specifically the needs for our main technical contributions, <em id="S1.p5.1.7" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.p5.1.8" class="ltx_text"></span> the Gaze Cone Predictor and the Gaze Object Transformer.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">To summarize: (1) We introduce a novel object-oriented gaze target detection method. (2) This end-to-end Transformer-based model automatically detects the heads and other objects in the scene to build associations between every head and the gazed-head/object, resulting in a comprehensive, explainable gaze analysis composed of: gaze target area, gaze pixel point, the class of gazed-object, the bounding box of the gazed-object as well as predicting whether the gazed point is out of the frame. (3) We demonstrate SOTA results on standard datasets regarding all evaluation metrics for gaze-target detection (up to 2.91% gain in AUC, 50% reduction in gaze distance, and 9% gain in out-of-frame AP), gazed-object classification and localization (11-13% gain in AP) and in case of low/high variance across gaze annotations. (4) The code of the proposed method is publicly available. We also release our implementation<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/francescotonini/human-gaze-target-detection-transformer" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/francescotonini/human-gaze-target-detection-transformer</a></span></span></span> for <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> since during our private communications with the authors, we are informed that their code at the moment cannot be shared by them due to their ongoing collaborations with a company.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<div id="S1.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:411.9pt;height:86.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-9.4pt,2.0pt) scale(0.956386632085699,0.956386632085699) ;">
<table id="S1.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.1.1.1.1" class="ltx_tr">
<th id="S1.T1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" rowspan="2"><span id="S1.T1.1.1.1.1.1.1" class="ltx_text">Method</span></th>
<th id="S1.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Wout/ Head</th>
<th id="S1.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Multiple</th>
<th id="S1.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Head</th>
<th id="S1.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Object</th>
<th id="S1.T1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Object</th>
</tr>
<tr id="S1.T1.1.1.2.2" class="ltx_tr">
<th id="S1.T1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Loc. Given</th>
<th id="S1.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">People</th>
<th id="S1.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Detection</th>
<th id="S1.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Localization</th>
<th id="S1.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">Classification</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.1.1.3.1" class="ltx_tr">
<th id="S1.T1.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Traditional</th>
<td id="S1.T1.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.1.2.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S1.T1.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.1.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S1.T1.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.1.4.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S1.T1.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.1.5.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S1.T1.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.1.6.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
</tr>
<tr id="S1.T1.1.1.4.2" class="ltx_tr">
<th id="S1.T1.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Tu <span id="S1.T1.1.1.4.2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</th>
<td id="S1.T1.1.1.4.2.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S1.T1.1.1.4.2.3" class="ltx_td ltx_align_center">âœ“</td>
<td id="S1.T1.1.1.4.2.4" class="ltx_td ltx_align_center">âœ“</td>
<td id="S1.T1.1.1.4.2.5" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.4.2.5.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S1.T1.1.1.4.2.6" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.4.2.6.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
</tr>
<tr id="S1.T1.1.1.5.3" class="ltx_tr">
<th id="S1.T1.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b">Ours</th>
<td id="S1.T1.1.1.5.3.2" class="ltx_td ltx_align_center ltx_border_b">âœ“</td>
<td id="S1.T1.1.1.5.3.3" class="ltx_td ltx_align_center ltx_border_b">âœ“</td>
<td id="S1.T1.1.1.5.3.4" class="ltx_td ltx_align_center ltx_border_b">âœ“</td>
<td id="S1.T1.1.1.5.3.5" class="ltx_td ltx_align_center ltx_border_b">âœ“</td>
<td id="S1.T1.1.1.5.3.6" class="ltx_td ltx_align_center ltx_border_b">âœ“</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Existing gaze target detection methods compared to ours. Ours is more explainable since, for every person in the scene, it can detect the object class and bounding box location on which the gaze is. It learns the scene objects (including the head) without using the head locations supplied by datasets.</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2307.09662/assets/images/method.png" id="S1.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="514" height="247" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S1.F2.16.1" class="ltx_text ltx_font_bold">Proposed method.</span> The encoder (<math id="S1.F2.7.m1.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S1.F2.7.m1.1b"><mi class="ltx_font_mathcaligraphic" id="S1.F2.7.m1.1.1" xref="S1.F2.7.m1.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S1.F2.7.m1.1c"><ci id="S1.F2.7.m1.1.1.cmml" xref="S1.F2.7.m1.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.7.m1.1d">\mathcal{E}</annotation></semantics></math>) and decoder (<math id="S1.F2.8.m2.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S1.F2.8.m2.1b"><mi class="ltx_font_mathcaligraphic" id="S1.F2.8.m2.1.1" xref="S1.F2.8.m2.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S1.F2.8.m2.1c"><ci id="S1.F2.8.m2.1.1.cmml" xref="S1.F2.8.m2.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.8.m2.1d">\mathcal{D}</annotation></semantics></math>) of the Object Detector Transformer operate on the features extracted by a backbone <math id="S1.F2.9.m3.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S1.F2.9.m3.1b"><mi class="ltx_font_mathcaligraphic" id="S1.F2.9.m3.1.1" xref="S1.F2.9.m3.1.1.cmml">â„¬</mi><annotation-xml encoding="MathML-Content" id="S1.F2.9.m3.1c"><ci id="S1.F2.9.m3.1.1.cmml" xref="S1.F2.9.m3.1.1">â„¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.9.m3.1d">\mathcal{B}</annotation></semantics></math> to learn rich object features used to detect and localize objects (including heads) in the scene. Head features are used to build the <span id="S1.F2.17.2" class="ltx_text ltx_font_bold">gaze cone</span>. Objects in the cone are extremely likely to be gaze-interesting. The <span id="S1.F2.18.3" class="ltx_text ltx_font_italic">object score</span> matrix <math id="S1.F2.10.m4.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S1.F2.10.m4.1b"><mi mathvariant="normal" id="S1.F2.10.m4.1.1" xref="S1.F2.10.m4.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S1.F2.10.m4.1c"><ci id="S1.F2.10.m4.1.1.cmml" xref="S1.F2.10.m4.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.10.m4.1d">\Sigma</annotation></semantics></math> boosts attention scores in the <span id="S1.F2.19.4" class="ltx_text ltx_font_italic">Gaze Object Transformer</span> (<math id="S1.F2.11.m5.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S1.F2.11.m5.1b"><mrow id="S1.F2.11.m5.1.1" xref="S1.F2.11.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F2.11.m5.1.1.2" xref="S1.F2.11.m5.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S1.F2.11.m5.1.1.1" xref="S1.F2.11.m5.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S1.F2.11.m5.1.1.3" xref="S1.F2.11.m5.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S1.F2.11.m5.1.1.1b" xref="S1.F2.11.m5.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S1.F2.11.m5.1.1.4" xref="S1.F2.11.m5.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.F2.11.m5.1c"><apply id="S1.F2.11.m5.1.1.cmml" xref="S1.F2.11.m5.1.1"><times id="S1.F2.11.m5.1.1.1.cmml" xref="S1.F2.11.m5.1.1.1"></times><ci id="S1.F2.11.m5.1.1.2.cmml" xref="S1.F2.11.m5.1.1.2">ğ’¢</ci><ci id="S1.F2.11.m5.1.1.3.cmml" xref="S1.F2.11.m5.1.1.3">ğ’ª</ci><ci id="S1.F2.11.m5.1.1.4.cmml" xref="S1.F2.11.m5.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.11.m5.1d">\mathcal{GOT}\,</annotation></semantics></math>), whose output features are used to build the gaze heatmap. If no object lies in the cone, a skip-connection lets the network predict the heatmap from head features only.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The main focus of this paper is to determine the location that a human is looking at in an in-the-wild scene captured from the third-person view.
To this end, Recasens <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> presented the first relevant dataset called GazeFollow, and proposed a two-branch Convolutional Neural Network (CNN) whose first branch estimates the saliency from scene images and the second branch processes manually annotated head crops together with their location information. Several subsequent worksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> adopted this two-branch structure and further introduced additional components. For instance, Chong <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> brought in detecting the gaze targets not-being in the scene (so-called <em id="S2.p1.1.3" class="ltx_emph ltx_font_italic">out-of-frame</em> detection). Later on, the same authorsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> integrated a CNN-LSTM into their pipeline, modeling the dynamics of gaze in <em id="S2.p1.1.4" class="ltx_emph ltx_font_italic">videos</em> and making frame-based inferences. They also introduced the VideoAttentionTarget dataset, made of videos.
A few studies incorporated the depth maps obtained from monocular depth estimators in addition to the embeddings learned from RGB scenes and head cropsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Fang <span id="S2.p1.1.5" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> integrated the precise detection of head pose and the location of eyes. Jin <span id="S2.p1.1.6" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> used two auxiliary networks, one to learn depth features and the other to compute 3D-gaze orientation features. However, detecting head pose, eye locations, etc., are already challenging tasks to perform in-the-wild, and their inaccurate results can affect gaze target detection negatively. A better solution could be leveraging the collaborative learning of scene, depth, and head features, as shown inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.
Bao <span id="S2.p1.1.7" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> proposed a method taking an RGB image and a head crop at a time and further using the depth map and a 2D human body pose detector to reconstruct the 3D scene with point clouds. Such a modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> requires several detectors to be fine-tuned and therefore increases the computational complexity. Furthermore, it underperforms compared to, e.g.,Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> on the VideoAttentionTarget dataset. Qiaomu <span id="S2.p1.1.8" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> used the same modalities asÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> but also included a temporal attention model and replaced the in/out prediction encoder ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> with a patch distribution prediction module, resulting in effective performance in case of large annotation variances. Unlike aforesaid approaches, aka <em id="S2.p1.1.9" class="ltx_emph ltx_font_italic">traditional methods</em>, using pretrained CNN backbones, Tu <span id="S2.p1.1.10" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> introduced the first Transformer-based approach, outperforming the others.
Drastic performance drops for traditional methods were also demonstrated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, when they were evaluated with the head locations predicted by automated head detectors.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">We stand out from the prior art as our method performs simultaneous gaze target detection of multiple persons in the scene by mutually learning localization and classification of the gazed-objects (including the head) and determining the head-head/object gaze interactions. Our end-to-end Transformer-based model explicitly aims to provide explainable gaze target detection, which has not been accomplished before (see Table <a href="#S1.T1" title="Table 1 â€£ 1 Introduction â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for comparisons).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.15" class="ltx_p">The proposed method is shown in FigÂ <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Given an image, we first predict the set of objects <math id="S3.p1.1.m1.4" class="ltx_Math" alttext="\mathbf{O}=\{\,(c_{x},c_{y},w,h,l)\}" display="inline"><semantics id="S3.p1.1.m1.4a"><mrow id="S3.p1.1.m1.4.4" xref="S3.p1.1.m1.4.4.cmml"><mi id="S3.p1.1.m1.4.4.3" xref="S3.p1.1.m1.4.4.3.cmml">ğ</mi><mo id="S3.p1.1.m1.4.4.2" xref="S3.p1.1.m1.4.4.2.cmml">=</mo><mrow id="S3.p1.1.m1.4.4.1.1" xref="S3.p1.1.m1.4.4.1.2.cmml"><mo rspace="0.170em" stretchy="false" id="S3.p1.1.m1.4.4.1.1.2" xref="S3.p1.1.m1.4.4.1.2.cmml">{</mo><mrow id="S3.p1.1.m1.4.4.1.1.1.2" xref="S3.p1.1.m1.4.4.1.1.1.3.cmml"><mo stretchy="false" id="S3.p1.1.m1.4.4.1.1.1.2.3" xref="S3.p1.1.m1.4.4.1.1.1.3.cmml">(</mo><msub id="S3.p1.1.m1.4.4.1.1.1.1.1" xref="S3.p1.1.m1.4.4.1.1.1.1.1.cmml"><mi id="S3.p1.1.m1.4.4.1.1.1.1.1.2" xref="S3.p1.1.m1.4.4.1.1.1.1.1.2.cmml">c</mi><mi id="S3.p1.1.m1.4.4.1.1.1.1.1.3" xref="S3.p1.1.m1.4.4.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S3.p1.1.m1.4.4.1.1.1.2.4" xref="S3.p1.1.m1.4.4.1.1.1.3.cmml">,</mo><msub id="S3.p1.1.m1.4.4.1.1.1.2.2" xref="S3.p1.1.m1.4.4.1.1.1.2.2.cmml"><mi id="S3.p1.1.m1.4.4.1.1.1.2.2.2" xref="S3.p1.1.m1.4.4.1.1.1.2.2.2.cmml">c</mi><mi id="S3.p1.1.m1.4.4.1.1.1.2.2.3" xref="S3.p1.1.m1.4.4.1.1.1.2.2.3.cmml">y</mi></msub><mo id="S3.p1.1.m1.4.4.1.1.1.2.5" xref="S3.p1.1.m1.4.4.1.1.1.3.cmml">,</mo><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">w</mi><mo id="S3.p1.1.m1.4.4.1.1.1.2.6" xref="S3.p1.1.m1.4.4.1.1.1.3.cmml">,</mo><mi id="S3.p1.1.m1.2.2" xref="S3.p1.1.m1.2.2.cmml">h</mi><mo id="S3.p1.1.m1.4.4.1.1.1.2.7" xref="S3.p1.1.m1.4.4.1.1.1.3.cmml">,</mo><mi id="S3.p1.1.m1.3.3" xref="S3.p1.1.m1.3.3.cmml">l</mi><mo stretchy="false" id="S3.p1.1.m1.4.4.1.1.1.2.8" xref="S3.p1.1.m1.4.4.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S3.p1.1.m1.4.4.1.1.3" xref="S3.p1.1.m1.4.4.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.4b"><apply id="S3.p1.1.m1.4.4.cmml" xref="S3.p1.1.m1.4.4"><eq id="S3.p1.1.m1.4.4.2.cmml" xref="S3.p1.1.m1.4.4.2"></eq><ci id="S3.p1.1.m1.4.4.3.cmml" xref="S3.p1.1.m1.4.4.3">ğ</ci><set id="S3.p1.1.m1.4.4.1.2.cmml" xref="S3.p1.1.m1.4.4.1.1"><vector id="S3.p1.1.m1.4.4.1.1.1.3.cmml" xref="S3.p1.1.m1.4.4.1.1.1.2"><apply id="S3.p1.1.m1.4.4.1.1.1.1.1.cmml" xref="S3.p1.1.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.p1.1.m1.4.4.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.1.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.p1.1.m1.4.4.1.1.1.1.1.2">ğ‘</ci><ci id="S3.p1.1.m1.4.4.1.1.1.1.1.3.cmml" xref="S3.p1.1.m1.4.4.1.1.1.1.1.3">ğ‘¥</ci></apply><apply id="S3.p1.1.m1.4.4.1.1.1.2.2.cmml" xref="S3.p1.1.m1.4.4.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p1.1.m1.4.4.1.1.1.2.2.1.cmml" xref="S3.p1.1.m1.4.4.1.1.1.2.2">subscript</csymbol><ci id="S3.p1.1.m1.4.4.1.1.1.2.2.2.cmml" xref="S3.p1.1.m1.4.4.1.1.1.2.2.2">ğ‘</ci><ci id="S3.p1.1.m1.4.4.1.1.1.2.2.3.cmml" xref="S3.p1.1.m1.4.4.1.1.1.2.2.3">ğ‘¦</ci></apply><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ğ‘¤</ci><ci id="S3.p1.1.m1.2.2.cmml" xref="S3.p1.1.m1.2.2">â„</ci><ci id="S3.p1.1.m1.3.3.cmml" xref="S3.p1.1.m1.3.3">ğ‘™</ci></vector></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.4c">\mathbf{O}=\{\,(c_{x},c_{y},w,h,l)\}</annotation></semantics></math> in it, where <math id="S3.p1.2.m2.4" class="ltx_Math" alttext="(c_{x},c_{y},w,h)" display="inline"><semantics id="S3.p1.2.m2.4a"><mrow id="S3.p1.2.m2.4.4.2" xref="S3.p1.2.m2.4.4.3.cmml"><mo stretchy="false" id="S3.p1.2.m2.4.4.2.3" xref="S3.p1.2.m2.4.4.3.cmml">(</mo><msub id="S3.p1.2.m2.3.3.1.1" xref="S3.p1.2.m2.3.3.1.1.cmml"><mi id="S3.p1.2.m2.3.3.1.1.2" xref="S3.p1.2.m2.3.3.1.1.2.cmml">c</mi><mi id="S3.p1.2.m2.3.3.1.1.3" xref="S3.p1.2.m2.3.3.1.1.3.cmml">x</mi></msub><mo id="S3.p1.2.m2.4.4.2.4" xref="S3.p1.2.m2.4.4.3.cmml">,</mo><msub id="S3.p1.2.m2.4.4.2.2" xref="S3.p1.2.m2.4.4.2.2.cmml"><mi id="S3.p1.2.m2.4.4.2.2.2" xref="S3.p1.2.m2.4.4.2.2.2.cmml">c</mi><mi id="S3.p1.2.m2.4.4.2.2.3" xref="S3.p1.2.m2.4.4.2.2.3.cmml">y</mi></msub><mo id="S3.p1.2.m2.4.4.2.5" xref="S3.p1.2.m2.4.4.3.cmml">,</mo><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">w</mi><mo id="S3.p1.2.m2.4.4.2.6" xref="S3.p1.2.m2.4.4.3.cmml">,</mo><mi id="S3.p1.2.m2.2.2" xref="S3.p1.2.m2.2.2.cmml">h</mi><mo stretchy="false" id="S3.p1.2.m2.4.4.2.7" xref="S3.p1.2.m2.4.4.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.4b"><vector id="S3.p1.2.m2.4.4.3.cmml" xref="S3.p1.2.m2.4.4.2"><apply id="S3.p1.2.m2.3.3.1.1.cmml" xref="S3.p1.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.3.3.1.1.1.cmml" xref="S3.p1.2.m2.3.3.1.1">subscript</csymbol><ci id="S3.p1.2.m2.3.3.1.1.2.cmml" xref="S3.p1.2.m2.3.3.1.1.2">ğ‘</ci><ci id="S3.p1.2.m2.3.3.1.1.3.cmml" xref="S3.p1.2.m2.3.3.1.1.3">ğ‘¥</ci></apply><apply id="S3.p1.2.m2.4.4.2.2.cmml" xref="S3.p1.2.m2.4.4.2.2"><csymbol cd="ambiguous" id="S3.p1.2.m2.4.4.2.2.1.cmml" xref="S3.p1.2.m2.4.4.2.2">subscript</csymbol><ci id="S3.p1.2.m2.4.4.2.2.2.cmml" xref="S3.p1.2.m2.4.4.2.2.2">ğ‘</ci><ci id="S3.p1.2.m2.4.4.2.2.3.cmml" xref="S3.p1.2.m2.4.4.2.2.3">ğ‘¦</ci></apply><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">ğ‘¤</ci><ci id="S3.p1.2.m2.2.2.cmml" xref="S3.p1.2.m2.2.2">â„</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.4c">(c_{x},c_{y},w,h)</annotation></semantics></math> represent the center coordinates of a single object and its width and height, respectively, <math id="S3.p1.3.m3.2" class="ltx_Math" alttext="l\in[0,CLS)" display="inline"><semantics id="S3.p1.3.m3.2a"><mrow id="S3.p1.3.m3.2.2" xref="S3.p1.3.m3.2.2.cmml"><mi id="S3.p1.3.m3.2.2.3" xref="S3.p1.3.m3.2.2.3.cmml">l</mi><mo id="S3.p1.3.m3.2.2.2" xref="S3.p1.3.m3.2.2.2.cmml">âˆˆ</mo><mrow id="S3.p1.3.m3.2.2.1.1" xref="S3.p1.3.m3.2.2.1.2.cmml"><mo stretchy="false" id="S3.p1.3.m3.2.2.1.1.2" xref="S3.p1.3.m3.2.2.1.2.cmml">[</mo><mn id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">0</mn><mo id="S3.p1.3.m3.2.2.1.1.3" xref="S3.p1.3.m3.2.2.1.2.cmml">,</mo><mrow id="S3.p1.3.m3.2.2.1.1.1" xref="S3.p1.3.m3.2.2.1.1.1.cmml"><mi id="S3.p1.3.m3.2.2.1.1.1.2" xref="S3.p1.3.m3.2.2.1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.p1.3.m3.2.2.1.1.1.1" xref="S3.p1.3.m3.2.2.1.1.1.1.cmml">â€‹</mo><mi id="S3.p1.3.m3.2.2.1.1.1.3" xref="S3.p1.3.m3.2.2.1.1.1.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.p1.3.m3.2.2.1.1.1.1a" xref="S3.p1.3.m3.2.2.1.1.1.1.cmml">â€‹</mo><mi id="S3.p1.3.m3.2.2.1.1.1.4" xref="S3.p1.3.m3.2.2.1.1.1.4.cmml">S</mi></mrow><mo stretchy="false" id="S3.p1.3.m3.2.2.1.1.4" xref="S3.p1.3.m3.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.2b"><apply id="S3.p1.3.m3.2.2.cmml" xref="S3.p1.3.m3.2.2"><in id="S3.p1.3.m3.2.2.2.cmml" xref="S3.p1.3.m3.2.2.2"></in><ci id="S3.p1.3.m3.2.2.3.cmml" xref="S3.p1.3.m3.2.2.3">ğ‘™</ci><interval closure="closed-open" id="S3.p1.3.m3.2.2.1.2.cmml" xref="S3.p1.3.m3.2.2.1.1"><cn type="integer" id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">0</cn><apply id="S3.p1.3.m3.2.2.1.1.1.cmml" xref="S3.p1.3.m3.2.2.1.1.1"><times id="S3.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1"></times><ci id="S3.p1.3.m3.2.2.1.1.1.2.cmml" xref="S3.p1.3.m3.2.2.1.1.1.2">ğ¶</ci><ci id="S3.p1.3.m3.2.2.1.1.1.3.cmml" xref="S3.p1.3.m3.2.2.1.1.1.3">ğ¿</ci><ci id="S3.p1.3.m3.2.2.1.1.1.4.cmml" xref="S3.p1.3.m3.2.2.1.1.1.4">ğ‘†</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.2c">l\in[0,CLS)</annotation></semantics></math> is an objectâ€™s label, and <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="CLS" display="inline"><semantics id="S3.p1.4.m4.1a"><mrow id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml"><mi id="S3.p1.4.m4.1.1.2" xref="S3.p1.4.m4.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.p1.4.m4.1.1.1" xref="S3.p1.4.m4.1.1.1.cmml">â€‹</mo><mi id="S3.p1.4.m4.1.1.3" xref="S3.p1.4.m4.1.1.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.p1.4.m4.1.1.1a" xref="S3.p1.4.m4.1.1.1.cmml">â€‹</mo><mi id="S3.p1.4.m4.1.1.4" xref="S3.p1.4.m4.1.1.4.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><apply id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1"><times id="S3.p1.4.m4.1.1.1.cmml" xref="S3.p1.4.m4.1.1.1"></times><ci id="S3.p1.4.m4.1.1.2.cmml" xref="S3.p1.4.m4.1.1.2">ğ¶</ci><ci id="S3.p1.4.m4.1.1.3.cmml" xref="S3.p1.4.m4.1.1.3">ğ¿</ci><ci id="S3.p1.4.m4.1.1.4.cmml" xref="S3.p1.4.m4.1.1.4">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">CLS</annotation></semantics></math> is the number of classes, including a special <span id="S3.p1.15.1" class="ltx_text ltx_font_italic">no object</span> (<math id="S3.p1.5.m5.1" class="ltx_Math" alttext="\emptyset" display="inline"><semantics id="S3.p1.5.m5.1a"><mi mathvariant="normal" id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">âˆ…</mi><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><emptyset id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">\emptyset</annotation></semantics></math>) class (described in Sec.Â <a href="#S4.SS2" title="4.2 Implementation details â€£ 4 Experiments â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>). To this end, after extracting the image features through a backbone <math id="S3.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S3.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml">â„¬</mi><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b"><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">â„¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">\mathcal{B}</annotation></semantics></math>, we use an <span id="S3.p1.15.2" class="ltx_text ltx_font_italic">Object Detector Transformer</span> that reasons on the scene features with the encoder <math id="S3.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.p1.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><ci id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">\mathcal{E}</annotation></semantics></math> and learns relevant object features with the decoder <math id="S3.p1.8.m8.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.p1.8.m8.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.8.m8.1.1" xref="S3.p1.8.m8.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.1b"><ci id="S3.p1.8.m8.1.1.cmml" xref="S3.p1.8.m8.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.1c">\mathcal{D}</annotation></semantics></math>. Such features are used to differentiate between heads <math id="S3.p1.9.m9.1" class="ltx_Math" alttext="\mathbf{O_{h}}" display="inline"><semantics id="S3.p1.9.m9.1a"><msub id="S3.p1.9.m9.1.1" xref="S3.p1.9.m9.1.1.cmml"><mi id="S3.p1.9.m9.1.1.2" xref="S3.p1.9.m9.1.1.2.cmml">ğ</mi><mi id="S3.p1.9.m9.1.1.3" xref="S3.p1.9.m9.1.1.3.cmml">ğ¡</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><apply id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.p1.9.m9.1.1.1.cmml" xref="S3.p1.9.m9.1.1">subscript</csymbol><ci id="S3.p1.9.m9.1.1.2.cmml" xref="S3.p1.9.m9.1.1.2">ğ</ci><ci id="S3.p1.9.m9.1.1.3.cmml" xref="S3.p1.9.m9.1.1.3">ğ¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">\mathbf{O_{h}}</annotation></semantics></math> and other objects in the scene. For each head <math id="S3.p1.10.m10.1" class="ltx_Math" alttext="\mathbf{O}_{h}^{i}" display="inline"><semantics id="S3.p1.10.m10.1a"><msubsup id="S3.p1.10.m10.1.1" xref="S3.p1.10.m10.1.1.cmml"><mi id="S3.p1.10.m10.1.1.2.2" xref="S3.p1.10.m10.1.1.2.2.cmml">ğ</mi><mi id="S3.p1.10.m10.1.1.2.3" xref="S3.p1.10.m10.1.1.2.3.cmml">h</mi><mi id="S3.p1.10.m10.1.1.3" xref="S3.p1.10.m10.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p1.10.m10.1b"><apply id="S3.p1.10.m10.1.1.cmml" xref="S3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.p1.10.m10.1.1.1.cmml" xref="S3.p1.10.m10.1.1">superscript</csymbol><apply id="S3.p1.10.m10.1.1.2.cmml" xref="S3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.p1.10.m10.1.1.2.1.cmml" xref="S3.p1.10.m10.1.1">subscript</csymbol><ci id="S3.p1.10.m10.1.1.2.2.cmml" xref="S3.p1.10.m10.1.1.2.2">ğ</ci><ci id="S3.p1.10.m10.1.1.2.3.cmml" xref="S3.p1.10.m10.1.1.2.3">â„</ci></apply><ci id="S3.p1.10.m10.1.1.3.cmml" xref="S3.p1.10.m10.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.10.m10.1c">\mathbf{O}_{h}^{i}</annotation></semantics></math>, we feed its features to the <span id="S3.p1.15.3" class="ltx_text ltx_font_italic">Gaze Cone Predictor</span> to determine a gaze vector <math id="S3.p1.11.m11.1" class="ltx_Math" alttext="\mathbf{v}_{g}^{i}" display="inline"><semantics id="S3.p1.11.m11.1a"><msubsup id="S3.p1.11.m11.1.1" xref="S3.p1.11.m11.1.1.cmml"><mi id="S3.p1.11.m11.1.1.2.2" xref="S3.p1.11.m11.1.1.2.2.cmml">ğ¯</mi><mi id="S3.p1.11.m11.1.1.2.3" xref="S3.p1.11.m11.1.1.2.3.cmml">g</mi><mi id="S3.p1.11.m11.1.1.3" xref="S3.p1.11.m11.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p1.11.m11.1b"><apply id="S3.p1.11.m11.1.1.cmml" xref="S3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.p1.11.m11.1.1.1.cmml" xref="S3.p1.11.m11.1.1">superscript</csymbol><apply id="S3.p1.11.m11.1.1.2.cmml" xref="S3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.p1.11.m11.1.1.2.1.cmml" xref="S3.p1.11.m11.1.1">subscript</csymbol><ci id="S3.p1.11.m11.1.1.2.2.cmml" xref="S3.p1.11.m11.1.1.2.2">ğ¯</ci><ci id="S3.p1.11.m11.1.1.2.3.cmml" xref="S3.p1.11.m11.1.1.2.3">ğ‘”</ci></apply><ci id="S3.p1.11.m11.1.1.3.cmml" xref="S3.p1.11.m11.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.11.m11.1c">\mathbf{v}_{g}^{i}</annotation></semantics></math> that represents the gaze direction of the person. This gaze vector is used to build a gaze cone with an angle of <math id="S3.p1.12.m12.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.p1.12.m12.1a"><mi id="S3.p1.12.m12.1.1" xref="S3.p1.12.m12.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.p1.12.m12.1b"><ci id="S3.p1.12.m12.1.1.cmml" xref="S3.p1.12.m12.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.12.m12.1c">\alpha</annotation></semantics></math> corresponding to the Field of View (FoV) and to selectively maintain the objects that are inside the cone for each head. The <span id="S3.p1.15.4" class="ltx_text ltx_font_italic">Gaze-Object Transformer</span> (<math id="S3.p1.13.m13.1" class="ltx_Math" alttext="\mathcal{GOT}" display="inline"><semantics id="S3.p1.13.m13.1a"><mrow id="S3.p1.13.m13.1.1" xref="S3.p1.13.m13.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.13.m13.1.1.2" xref="S3.p1.13.m13.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S3.p1.13.m13.1.1.1" xref="S3.p1.13.m13.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.13.m13.1.1.3" xref="S3.p1.13.m13.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S3.p1.13.m13.1.1.1a" xref="S3.p1.13.m13.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.13.m13.1.1.4" xref="S3.p1.13.m13.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.13.m13.1b"><apply id="S3.p1.13.m13.1.1.cmml" xref="S3.p1.13.m13.1.1"><times id="S3.p1.13.m13.1.1.1.cmml" xref="S3.p1.13.m13.1.1.1"></times><ci id="S3.p1.13.m13.1.1.2.cmml" xref="S3.p1.13.m13.1.1.2">ğ’¢</ci><ci id="S3.p1.13.m13.1.1.3.cmml" xref="S3.p1.13.m13.1.1.3">ğ’ª</ci><ci id="S3.p1.13.m13.1.1.4.cmml" xref="S3.p1.13.m13.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.13.m13.1c">\mathcal{GOT}</annotation></semantics></math>) models the relationships between the detected
objects and predicts the probability of them being the gaze target of any person, with a higher probability for the objects closer to the gaze vector. The gaze of each person is represented as a Gaussian heatmap <math id="S3.p1.14.m14.1" class="ltx_Math" alttext="\mathbf{H}^{i}" display="inline"><semantics id="S3.p1.14.m14.1a"><msup id="S3.p1.14.m14.1.1" xref="S3.p1.14.m14.1.1.cmml"><mi id="S3.p1.14.m14.1.1.2" xref="S3.p1.14.m14.1.1.2.cmml">ğ‡</mi><mi id="S3.p1.14.m14.1.1.3" xref="S3.p1.14.m14.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p1.14.m14.1b"><apply id="S3.p1.14.m14.1.1.cmml" xref="S3.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S3.p1.14.m14.1.1.1.cmml" xref="S3.p1.14.m14.1.1">superscript</csymbol><ci id="S3.p1.14.m14.1.1.2.cmml" xref="S3.p1.14.m14.1.1.2">ğ‡</ci><ci id="S3.p1.14.m14.1.1.3.cmml" xref="S3.p1.14.m14.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.14.m14.1c">\mathbf{H}^{i}</annotation></semantics></math> centered on the gaze point <math id="S3.p1.15.m15.1" class="ltx_Math" alttext="\mathbf{p}_{g}^{i}" display="inline"><semantics id="S3.p1.15.m15.1a"><msubsup id="S3.p1.15.m15.1.1" xref="S3.p1.15.m15.1.1.cmml"><mi id="S3.p1.15.m15.1.1.2.2" xref="S3.p1.15.m15.1.1.2.2.cmml">ğ©</mi><mi id="S3.p1.15.m15.1.1.2.3" xref="S3.p1.15.m15.1.1.2.3.cmml">g</mi><mi id="S3.p1.15.m15.1.1.3" xref="S3.p1.15.m15.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p1.15.m15.1b"><apply id="S3.p1.15.m15.1.1.cmml" xref="S3.p1.15.m15.1.1"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.1.cmml" xref="S3.p1.15.m15.1.1">superscript</csymbol><apply id="S3.p1.15.m15.1.1.2.cmml" xref="S3.p1.15.m15.1.1"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.2.1.cmml" xref="S3.p1.15.m15.1.1">subscript</csymbol><ci id="S3.p1.15.m15.1.1.2.2.cmml" xref="S3.p1.15.m15.1.1.2.2">ğ©</ci><ci id="S3.p1.15.m15.1.1.2.3.cmml" xref="S3.p1.15.m15.1.1.2.3">ğ‘”</ci></apply><ci id="S3.p1.15.m15.1.1.3.cmml" xref="S3.p1.15.m15.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.15.m15.1c">\mathbf{p}_{g}^{i}</annotation></semantics></math>, and when no object is present inside the gaze cone, we use a <span id="S3.p1.15.5" class="ltx_text ltx_font_italic">no cone-object skip</span> to compute the heatmap directly from the head features. We also use the head features to predict the probability of the gaze target being outside the frame.
To sum up, our model consists of three major components: (a) Object Detector Transformer, (b) Gaze Cone Predictor, and (c) Gaze Object Transformer, which are described thoroughly in the following sections.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Object Detector Transformer</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.7" class="ltx_p">Given an RGB image <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{x}\in\mathbb{R}^{C\times H\times W}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">ğ±</mi><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p1.1.m1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.3.2" xref="S3.SS1.p1.1.m1.1.1.3.3.2.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.1.m1.1.1.3.3.1" xref="S3.SS1.p1.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.1.m1.1.1.3.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.3.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.1.m1.1.1.3.3.1a" xref="S3.SS1.p1.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.1.m1.1.1.3.3.4" xref="S3.SS1.p1.1.m1.1.1.3.3.4.cmml">W</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><in id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></in><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ±</ci><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">â„</ci><apply id="S3.SS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3"><times id="S3.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.1"></times><ci id="S3.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.2">ğ¶</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.3">ğ»</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.4.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.4">ğ‘Š</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\mathbf{x}\in\mathbb{R}^{C\times H\times W}</annotation></semantics></math>, we aim to predict the bounding boxes and labels of objects. We start by extracting a feature map <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{f_{b}}\in\mathbb{R}^{C_{b}\times H_{b}\times W_{b}}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><msub id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2.2" xref="S3.SS1.p1.2.m2.1.1.2.2.cmml">ğŸ</mi><mi id="S3.SS1.p1.2.m2.1.1.2.3" xref="S3.SS1.p1.2.m2.1.1.2.3.cmml">ğ›</mi></msub><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml"><msub id="S3.SS1.p1.2.m2.1.1.3.3.2" xref="S3.SS1.p1.2.m2.1.1.3.3.2.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.3.2.2" xref="S3.SS1.p1.2.m2.1.1.3.3.2.2.cmml">C</mi><mi id="S3.SS1.p1.2.m2.1.1.3.3.2.3" xref="S3.SS1.p1.2.m2.1.1.3.3.2.3.cmml">b</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.2.m2.1.1.3.3.1" xref="S3.SS1.p1.2.m2.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS1.p1.2.m2.1.1.3.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.3.3.2" xref="S3.SS1.p1.2.m2.1.1.3.3.3.2.cmml">H</mi><mi id="S3.SS1.p1.2.m2.1.1.3.3.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.3.3.cmml">b</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.2.m2.1.1.3.3.1a" xref="S3.SS1.p1.2.m2.1.1.3.3.1.cmml">Ã—</mo><msub id="S3.SS1.p1.2.m2.1.1.3.3.4" xref="S3.SS1.p1.2.m2.1.1.3.3.4.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.3.4.2" xref="S3.SS1.p1.2.m2.1.1.3.3.4.2.cmml">W</mi><mi id="S3.SS1.p1.2.m2.1.1.3.3.4.3" xref="S3.SS1.p1.2.m2.1.1.3.3.4.3.cmml">b</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><in id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></in><apply id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2.2">ğŸ</ci><ci id="S3.SS1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.p1.2.m2.1.1.2.3">ğ›</ci></apply><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3"><times id="S3.SS1.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.1"></times><apply id="S3.SS1.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.3.2.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.3.2.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.2.2">ğ¶</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.2.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.2.3">ğ‘</ci></apply><apply id="S3.SS1.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.3.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.3.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.3.2">ğ»</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.3.3">ğ‘</ci></apply><apply id="S3.SS1.p1.2.m2.1.1.3.3.4.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.3.4.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.4">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.3.4.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.4.2">ğ‘Š</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.4.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.4.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathbf{f_{b}}\in\mathbb{R}^{C_{b}\times H_{b}\times W_{b}}</annotation></semantics></math> with a convolutional backbone <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">â„¬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">â„¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\mathcal{B}</annotation></semantics></math>, and we linearly project the channel dimension to a lower space <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="C^{b^{\prime}}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msup id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">C</mi><msup id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">b</mi><mo id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">â€²</mo></msup></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">ğ¶</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">ğ‘</ci><ci id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">â€²</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">C^{b^{\prime}}</annotation></semantics></math> due to the high channel dimensionality.
We flatten the spatial dimensions and obtain <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{f_{b}^{{}^{\prime}}}\in\mathbb{R}^{H_{b}W_{b}\times C_{b}^{{}^{\prime}}}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><msubsup id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2.2.2" xref="S3.SS1.p1.5.m5.1.1.2.2.2.cmml">ğŸ</mi><mi id="S3.SS1.p1.5.m5.1.1.2.2.3" xref="S3.SS1.p1.5.m5.1.1.2.2.3.cmml">ğ›</mi><msup id="S3.SS1.p1.5.m5.1.1.2.3" xref="S3.SS1.p1.5.m5.1.1.2.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2.3a" xref="S3.SS1.p1.5.m5.1.1.2.3.cmml"></mi><mo id="S3.SS1.p1.5.m5.1.1.2.3.1" xref="S3.SS1.p1.5.m5.1.1.2.3.1.cmml">â€²</mo></msup></msubsup><mo id="S3.SS1.p1.5.m5.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3.2" xref="S3.SS1.p1.5.m5.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p1.5.m5.1.1.3.3" xref="S3.SS1.p1.5.m5.1.1.3.3.cmml"><mrow id="S3.SS1.p1.5.m5.1.1.3.3.2" xref="S3.SS1.p1.5.m5.1.1.3.3.2.cmml"><msub id="S3.SS1.p1.5.m5.1.1.3.3.2.2" xref="S3.SS1.p1.5.m5.1.1.3.3.2.2.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3.3.2.2.2" xref="S3.SS1.p1.5.m5.1.1.3.3.2.2.2.cmml">H</mi><mi id="S3.SS1.p1.5.m5.1.1.3.3.2.2.3" xref="S3.SS1.p1.5.m5.1.1.3.3.2.2.3.cmml">b</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.1.1.3.3.2.1" xref="S3.SS1.p1.5.m5.1.1.3.3.2.1.cmml">â€‹</mo><msub id="S3.SS1.p1.5.m5.1.1.3.3.2.3" xref="S3.SS1.p1.5.m5.1.1.3.3.2.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3.3.2.3.2" xref="S3.SS1.p1.5.m5.1.1.3.3.2.3.2.cmml">W</mi><mi id="S3.SS1.p1.5.m5.1.1.3.3.2.3.3" xref="S3.SS1.p1.5.m5.1.1.3.3.2.3.3.cmml">b</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.5.m5.1.1.3.3.1" xref="S3.SS1.p1.5.m5.1.1.3.3.1.cmml">Ã—</mo><msubsup id="S3.SS1.p1.5.m5.1.1.3.3.3" xref="S3.SS1.p1.5.m5.1.1.3.3.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3.3.3.2.2" xref="S3.SS1.p1.5.m5.1.1.3.3.3.2.2.cmml">C</mi><mi id="S3.SS1.p1.5.m5.1.1.3.3.3.2.3" xref="S3.SS1.p1.5.m5.1.1.3.3.3.2.3.cmml">b</mi><msup id="S3.SS1.p1.5.m5.1.1.3.3.3.3" xref="S3.SS1.p1.5.m5.1.1.3.3.3.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3.3.3.3a" xref="S3.SS1.p1.5.m5.1.1.3.3.3.3.cmml"></mi><mo id="S3.SS1.p1.5.m5.1.1.3.3.3.3.1" xref="S3.SS1.p1.5.m5.1.1.3.3.3.3.1.cmml">â€²</mo></msup></msubsup></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><in id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1"></in><apply id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.2">superscript</csymbol><apply id="S3.SS1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.2.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2.2">ğŸ</ci><ci id="S3.SS1.p1.5.m5.1.1.2.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2.3">ğ›</ci></apply><apply id="S3.SS1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3"><ci id="S3.SS1.p1.5.m5.1.1.2.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3.1">â€²</ci></apply></apply><apply id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2">â„</ci><apply id="S3.SS1.p1.5.m5.1.1.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3"><times id="S3.SS1.p1.5.m5.1.1.3.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.1"></times><apply id="S3.SS1.p1.5.m5.1.1.3.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2"><times id="S3.SS1.p1.5.m5.1.1.3.3.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2.1"></times><apply id="S3.SS1.p1.5.m5.1.1.3.3.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.3.3.2.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.3.3.2.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2.2.2">ğ»</ci><ci id="S3.SS1.p1.5.m5.1.1.3.3.2.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2.2.3">ğ‘</ci></apply><apply id="S3.SS1.p1.5.m5.1.1.3.3.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.3.3.2.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2.3">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.3.3.2.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2.3.2">ğ‘Š</ci><ci id="S3.SS1.p1.5.m5.1.1.3.3.2.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.2.3.3">ğ‘</ci></apply></apply><apply id="S3.SS1.p1.5.m5.1.1.3.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.3.3.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.3">superscript</csymbol><apply id="S3.SS1.p1.5.m5.1.1.3.3.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.3.3.3.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.3.3.3.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.3.2.2">ğ¶</ci><ci id="S3.SS1.p1.5.m5.1.1.3.3.3.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.3.2.3">ğ‘</ci></apply><apply id="S3.SS1.p1.5.m5.1.1.3.3.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.3.3"><ci id="S3.SS1.p1.5.m5.1.1.3.3.3.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3.3.3.1">â€²</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\mathbf{f_{b}^{{}^{\prime}}}\in\mathbb{R}^{H_{b}W_{b}\times C_{b}^{{}^{\prime}}}</annotation></semantics></math>, which is fed to a transformer encoder <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\mathcal{E}</annotation></semantics></math> that enhances the coarse image features extracted by <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">â„¬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">â„¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">\mathcal{B}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.13" class="ltx_p"><math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{E}</annotation></semantics></math> is designed as a stack of multi-head self-attention (MHSA) and feed-forward (FFN) layers.
The projected output of <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">â„¬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">â„¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\mathcal{B}</annotation></semantics></math>, <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{f_{b}^{{}^{\prime}}}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><msubsup id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2.2" xref="S3.SS1.p2.3.m3.1.1.2.2.cmml">ğŸ</mi><mi id="S3.SS1.p2.3.m3.1.1.2.3" xref="S3.SS1.p2.3.m3.1.1.2.3.cmml">ğ›</mi><msup id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml"><mi id="S3.SS1.p2.3.m3.1.1.3a" xref="S3.SS1.p2.3.m3.1.1.3.cmml"></mi><mo id="S3.SS1.p2.3.m3.1.1.3.1" xref="S3.SS1.p2.3.m3.1.1.3.1.cmml">â€²</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">superscript</csymbol><apply id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.2.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2.2">ğŸ</ci><ci id="S3.SS1.p2.3.m3.1.1.2.3.cmml" xref="S3.SS1.p2.3.m3.1.1.2.3">ğ›</ci></apply><apply id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3"><ci id="S3.SS1.p2.3.m3.1.1.3.1.cmml" xref="S3.SS1.p2.3.m3.1.1.3.1">â€²</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathbf{f_{b}^{{}^{\prime}}}</annotation></semantics></math>, forms the input queries <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">Q</annotation></semantics></math>, keys <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">K</annotation></semantics></math>, and values <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">V</annotation></semantics></math> of <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><ci id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">\mathcal{E}</annotation></semantics></math>. To retain the spatial information of the feature map, we add positional encodings for <math id="S3.SS1.p2.8.m8.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS1.p2.8.m8.1a"><mi id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><ci id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">Q</annotation></semantics></math> and <math id="S3.SS1.p2.9.m9.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.p2.9.m9.1a"><mi id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><ci id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">K</annotation></semantics></math>.
The output of the encoder, <math id="S3.SS1.p2.10.m10.1" class="ltx_Math" alttext="\mathbf{f_{e}}" display="inline"><semantics id="S3.SS1.p2.10.m10.1a"><msub id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml"><mi id="S3.SS1.p2.10.m10.1.1.2" xref="S3.SS1.p2.10.m10.1.1.2.cmml">ğŸ</mi><mi id="S3.SS1.p2.10.m10.1.1.3" xref="S3.SS1.p2.10.m10.1.1.3.cmml">ğ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.1b"><apply id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.10.m10.1.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1">subscript</csymbol><ci id="S3.SS1.p2.10.m10.1.1.2.cmml" xref="S3.SS1.p2.10.m10.1.1.2">ğŸ</ci><ci id="S3.SS1.p2.10.m10.1.1.3.cmml" xref="S3.SS1.p2.10.m10.1.1.3">ğ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.1c">\mathbf{f_{e}}</annotation></semantics></math>, forms the input <math id="S3.SS1.p2.11.m11.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.p2.11.m11.1a"><mi id="S3.SS1.p2.11.m11.1.1" xref="S3.SS1.p2.11.m11.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m11.1b"><ci id="S3.SS1.p2.11.m11.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m11.1c">K</annotation></semantics></math> and <math id="S3.SS1.p2.12.m12.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS1.p2.12.m12.1a"><mi id="S3.SS1.p2.12.m12.1.1" xref="S3.SS1.p2.12.m12.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m12.1b"><ci id="S3.SS1.p2.12.m12.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m12.1c">V</annotation></semantics></math> of the cross-attention module of the transformer decoder <math id="S3.SS1.p2.13.m13.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS1.p2.13.m13.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.13.m13.1.1" xref="S3.SS1.p2.13.m13.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m13.1b"><ci id="S3.SS1.p2.13.m13.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.13.m13.1c">\mathcal{D}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.9" class="ltx_p"><math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathcal{D}</annotation></semantics></math> completes our Object Detector Transformer and introduces a multi-head cross-attention module to obtain object-relevant features.
First, the decoder performs self-attention on a set of learnable embeddings <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="\mathbf{e_{d}}\in\mathbb{R}^{N\times C_{b}^{{}^{\prime}}}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mrow id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><msub id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2.2" xref="S3.SS1.p3.2.m2.1.1.2.2.cmml">ğ</mi><mi id="S3.SS1.p3.2.m2.1.1.2.3" xref="S3.SS1.p3.2.m2.1.1.2.3.cmml">ğ</mi></msub><mo id="S3.SS1.p3.2.m2.1.1.1" xref="S3.SS1.p3.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml"><mi id="S3.SS1.p3.2.m2.1.1.3.2" xref="S3.SS1.p3.2.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p3.2.m2.1.1.3.3" xref="S3.SS1.p3.2.m2.1.1.3.3.cmml"><mi id="S3.SS1.p3.2.m2.1.1.3.3.2" xref="S3.SS1.p3.2.m2.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.2.m2.1.1.3.3.1" xref="S3.SS1.p3.2.m2.1.1.3.3.1.cmml">Ã—</mo><msubsup id="S3.SS1.p3.2.m2.1.1.3.3.3" xref="S3.SS1.p3.2.m2.1.1.3.3.3.cmml"><mi id="S3.SS1.p3.2.m2.1.1.3.3.3.2.2" xref="S3.SS1.p3.2.m2.1.1.3.3.3.2.2.cmml">C</mi><mi id="S3.SS1.p3.2.m2.1.1.3.3.3.2.3" xref="S3.SS1.p3.2.m2.1.1.3.3.3.2.3.cmml">b</mi><msup id="S3.SS1.p3.2.m2.1.1.3.3.3.3" xref="S3.SS1.p3.2.m2.1.1.3.3.3.3.cmml"><mi id="S3.SS1.p3.2.m2.1.1.3.3.3.3a" xref="S3.SS1.p3.2.m2.1.1.3.3.3.3.cmml"></mi><mo id="S3.SS1.p3.2.m2.1.1.3.3.3.3.1" xref="S3.SS1.p3.2.m2.1.1.3.3.3.3.1.cmml">â€²</mo></msup></msubsup></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><in id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1.1"></in><apply id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.2.1.cmml" xref="S3.SS1.p3.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2.2">ğ</ci><ci id="S3.SS1.p3.2.m2.1.1.2.3.cmml" xref="S3.SS1.p3.2.m2.1.1.2.3">ğ</ci></apply><apply id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.3.1.cmml" xref="S3.SS1.p3.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.3.2.cmml" xref="S3.SS1.p3.2.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p3.2.m2.1.1.3.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3"><times id="S3.SS1.p3.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.1"></times><ci id="S3.SS1.p3.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.2">ğ‘</ci><apply id="S3.SS1.p3.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.3.3.3.1.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.3">superscript</csymbol><apply id="S3.SS1.p3.2.m2.1.1.3.3.3.2.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.3.3.3.2.1.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.3.3.3.2.2.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.3.2.2">ğ¶</ci><ci id="S3.SS1.p3.2.m2.1.1.3.3.3.2.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.3.2.3">ğ‘</ci></apply><apply id="S3.SS1.p3.2.m2.1.1.3.3.3.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.3.3"><ci id="S3.SS1.p3.2.m2.1.1.3.3.3.3.1.cmml" xref="S3.SS1.p3.2.m2.1.1.3.3.3.3.1">â€²</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\mathbf{e_{d}}\in\mathbb{R}^{N\times C_{b}^{{}^{\prime}}}</annotation></semantics></math>, where <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mi id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">N</annotation></semantics></math> is the maximum number of objects to be predicted.
Similar to <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">\mathcal{E}</annotation></semantics></math>, we add the learnable embeddings <math id="S3.SS1.p3.5.m5.1" class="ltx_Math" alttext="\mathbf{e_{d}}" display="inline"><semantics id="S3.SS1.p3.5.m5.1a"><msub id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml">ğ</mi><mi id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml">ğ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2">ğ</ci><ci id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3">ğ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">\mathbf{e_{d}}</annotation></semantics></math> with a set of fixed positional embeddings.
The output of the self-attention on <math id="S3.SS1.p3.6.m6.1" class="ltx_Math" alttext="\mathbf{e_{d}}" display="inline"><semantics id="S3.SS1.p3.6.m6.1a"><msub id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml"><mi id="S3.SS1.p3.6.m6.1.1.2" xref="S3.SS1.p3.6.m6.1.1.2.cmml">ğ</mi><mi id="S3.SS1.p3.6.m6.1.1.3" xref="S3.SS1.p3.6.m6.1.1.3.cmml">ğ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><apply id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.6.m6.1.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p3.6.m6.1.1.2.cmml" xref="S3.SS1.p3.6.m6.1.1.2">ğ</ci><ci id="S3.SS1.p3.6.m6.1.1.3.cmml" xref="S3.SS1.p3.6.m6.1.1.3">ğ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">\mathbf{e_{d}}</annotation></semantics></math> is then fed to a multi-head cross-attention module, where <math id="S3.SS1.p3.7.m7.1" class="ltx_Math" alttext="\mathbf{e_{d}}" display="inline"><semantics id="S3.SS1.p3.7.m7.1a"><msub id="S3.SS1.p3.7.m7.1.1" xref="S3.SS1.p3.7.m7.1.1.cmml"><mi id="S3.SS1.p3.7.m7.1.1.2" xref="S3.SS1.p3.7.m7.1.1.2.cmml">ğ</mi><mi id="S3.SS1.p3.7.m7.1.1.3" xref="S3.SS1.p3.7.m7.1.1.3.cmml">ğ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m7.1b"><apply id="S3.SS1.p3.7.m7.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.1.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p3.7.m7.1.1.2.cmml" xref="S3.SS1.p3.7.m7.1.1.2">ğ</ci><ci id="S3.SS1.p3.7.m7.1.1.3.cmml" xref="S3.SS1.p3.7.m7.1.1.3">ğ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m7.1c">\mathbf{e_{d}}</annotation></semantics></math> are the queries, and <math id="S3.SS1.p3.8.m8.1" class="ltx_Math" alttext="\mathbf{f_{e}}" display="inline"><semantics id="S3.SS1.p3.8.m8.1a"><msub id="S3.SS1.p3.8.m8.1.1" xref="S3.SS1.p3.8.m8.1.1.cmml"><mi id="S3.SS1.p3.8.m8.1.1.2" xref="S3.SS1.p3.8.m8.1.1.2.cmml">ğŸ</mi><mi id="S3.SS1.p3.8.m8.1.1.3" xref="S3.SS1.p3.8.m8.1.1.3.cmml">ğ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m8.1b"><apply id="S3.SS1.p3.8.m8.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.1.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p3.8.m8.1.1.2.cmml" xref="S3.SS1.p3.8.m8.1.1.2">ğŸ</ci><ci id="S3.SS1.p3.8.m8.1.1.3.cmml" xref="S3.SS1.p3.8.m8.1.1.3">ğ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m8.1c">\mathbf{f_{e}}</annotation></semantics></math> are the keys and values.
The output features <math id="S3.SS1.p3.9.m9.1" class="ltx_Math" alttext="\mathbf{f}_{d}" display="inline"><semantics id="S3.SS1.p3.9.m9.1a"><msub id="S3.SS1.p3.9.m9.1.1" xref="S3.SS1.p3.9.m9.1.1.cmml"><mi id="S3.SS1.p3.9.m9.1.1.2" xref="S3.SS1.p3.9.m9.1.1.2.cmml">ğŸ</mi><mi id="S3.SS1.p3.9.m9.1.1.3" xref="S3.SS1.p3.9.m9.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.9.m9.1b"><apply id="S3.SS1.p3.9.m9.1.1.cmml" xref="S3.SS1.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.9.m9.1.1.1.cmml" xref="S3.SS1.p3.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.p3.9.m9.1.1.2.cmml" xref="S3.SS1.p3.9.m9.1.1.2">ğŸ</ci><ci id="S3.SS1.p3.9.m9.1.1.3.cmml" xref="S3.SS1.p3.9.m9.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.9.m9.1c">\mathbf{f}_{d}</annotation></semantics></math> of the transformer decoder are finally used by two multi-layer perceptrons (MLP) to predict the object bounding box (Bbox) and class, respectively.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2307.09662/assets/images/fig_3.png" id="S3.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="479" height="490" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>(a) Our 3D cone construction from the head center point; <math id="S3.F3.5.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.F3.5.m1.1b"><mi id="S3.F3.5.m1.1.1" xref="S3.F3.5.m1.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.F3.5.m1.1c"><ci id="S3.F3.5.m1.1.1.cmml" xref="S3.F3.5.m1.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.5.m1.1d">\theta</annotation></semantics></math> and <math id="S3.F3.6.m2.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.F3.6.m2.1b"><mi id="S3.F3.6.m2.1.1" xref="S3.F3.6.m2.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.F3.6.m2.1c"><ci id="S3.F3.6.m2.1.1.cmml" xref="S3.F3.6.m2.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.6.m2.1d">\phi</annotation></semantics></math> are the polar and azimuthal angle, respectively. Exploded view computed with the depth map. (b) 3D gaze cone considers the depth and, in this way, excludes the objects unrelated to the gaze vector, in this case, the couch and the bed on the right. Instead, in (c) 2D gaze cone, the couch is inside it, although common sense would tell that it should not be. (d) <span id="S3.F3.14.1" class="ltx_text ltx_font_italic">Object score</span> matrix <math id="S3.F3.7.m3.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.F3.7.m3.1b"><mi mathvariant="normal" id="S3.F3.7.m3.1.1" xref="S3.F3.7.m3.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.F3.7.m3.1c"><ci id="S3.F3.7.m3.1.1.cmml" xref="S3.F3.7.m3.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.7.m3.1d">\Sigma</annotation></semantics></math> of (c) when the detected objects are: <span id="S3.F3.15.2" class="ltx_text ltx_font_italic">head</span>, <span id="S3.F3.16.3" class="ltx_text ltx_font_italic">laptop</span>, <span id="S3.F3.17.4" class="ltx_text ltx_font_italic">couch</span>, <span id="S3.F3.18.5" class="ltx_text ltx_font_italic">bed</span>, and <span id="S3.F3.19.6" class="ltx_text ltx_font_italic">bottle</span> classes.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Gaze Cone Predictor</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">The objects predicted by the <span id="S3.SS2.p1.2.1" class="ltx_text ltx_font_italic">Object Detector Transformer</span> may appear in an area outside the FoV of a person but inside of another person(s).
Since our method performs <em id="S3.SS2.p1.2.2" class="ltx_emph ltx_font_italic">multi-person</em> gaze prediction, we must consider the mentioned scenario and selectively focus on objects in the FoV of each individual.
To this end, the <span id="S3.SS2.p1.2.3" class="ltx_text ltx_font_italic">Gaze Cone Predictor</span> produces a gaze cone for each head detected and allows the <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.1.1.1a" xref="S3.SS2.p1.1.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1.4" xref="S3.SS2.p1.1.m1.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><times id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></times><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ’¢</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ğ’ª</ci><ci id="S3.SS2.p1.1.m1.1.1.4.cmml" xref="S3.SS2.p1.1.m1.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathcal{GOT}\,</annotation></semantics></math>to focus on only the relevant objects on a person-by-person basis. For the objects detected as a head, the gaze cone, which can be either in 2D or 3D, is built based on the estimated gaze vector. The gaze cone allows us to build an <span id="S3.SS2.p1.2.4" class="ltx_text ltx_font_italic">object score</span> matrix (<math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi mathvariant="normal" id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\Sigma</annotation></semantics></math>) based on the relationship between head-head/objects.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.21" class="ltx_p">In detail, an MLP takes as input the features of objects detected as heads <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{O}_{h}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">ğ</mi><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">ğ</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathbf{O}_{h}</annotation></semantics></math> and estimates, for each of them, a 3D gaze vector <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{v}_{g}^{i}" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><msubsup id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2.2" xref="S3.SS2.p2.2.m2.1.1.2.2.cmml">ğ¯</mi><mi id="S3.SS2.p2.2.m2.1.1.2.3" xref="S3.SS2.p2.2.m2.1.1.2.3.cmml">g</mi><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.2.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2.2">ğ¯</ci><ci id="S3.SS2.p2.2.m2.1.1.2.3.cmml" xref="S3.SS2.p2.2.m2.1.1.2.3">ğ‘”</ci></apply><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\mathbf{v}_{g}^{i}</annotation></semantics></math> <math id="S3.SS2.p2.3.m3.3" class="ltx_Math" alttext="=(\theta^{i},\phi^{i},\,\rho^{i})" display="inline"><semantics id="S3.SS2.p2.3.m3.3a"><mrow id="S3.SS2.p2.3.m3.3.3" xref="S3.SS2.p2.3.m3.3.3.cmml"><mi id="S3.SS2.p2.3.m3.3.3.5" xref="S3.SS2.p2.3.m3.3.3.5.cmml"></mi><mo id="S3.SS2.p2.3.m3.3.3.4" xref="S3.SS2.p2.3.m3.3.3.4.cmml">=</mo><mrow id="S3.SS2.p2.3.m3.3.3.3.3" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml"><mo stretchy="false" id="S3.SS2.p2.3.m3.3.3.3.3.4" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml">(</mo><msup id="S3.SS2.p2.3.m3.1.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.1.2.cmml">Î¸</mi><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.1.3.cmml">i</mi></msup><mo id="S3.SS2.p2.3.m3.3.3.3.3.5" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml">,</mo><msup id="S3.SS2.p2.3.m3.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.3.m3.2.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2.cmml">Ï•</mi><mi id="S3.SS2.p2.3.m3.2.2.2.2.2.3" xref="S3.SS2.p2.3.m3.2.2.2.2.2.3.cmml">i</mi></msup><mo rspace="0.337em" id="S3.SS2.p2.3.m3.3.3.3.3.6" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml">,</mo><msup id="S3.SS2.p2.3.m3.3.3.3.3.3" xref="S3.SS2.p2.3.m3.3.3.3.3.3.cmml"><mi id="S3.SS2.p2.3.m3.3.3.3.3.3.2" xref="S3.SS2.p2.3.m3.3.3.3.3.3.2.cmml">Ï</mi><mi id="S3.SS2.p2.3.m3.3.3.3.3.3.3" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3.cmml">i</mi></msup><mo stretchy="false" id="S3.SS2.p2.3.m3.3.3.3.3.7" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.3b"><apply id="S3.SS2.p2.3.m3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3"><eq id="S3.SS2.p2.3.m3.3.3.4.cmml" xref="S3.SS2.p2.3.m3.3.3.4"></eq><csymbol cd="latexml" id="S3.SS2.p2.3.m3.3.3.5.cmml" xref="S3.SS2.p2.3.m3.3.3.5">absent</csymbol><vector id="S3.SS2.p2.3.m3.3.3.3.4.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3"><apply id="S3.SS2.p2.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.2">ğœƒ</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2">superscript</csymbol><ci id="S3.SS2.p2.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2">italic-Ï•</ci><ci id="S3.SS2.p2.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.3.m3.3.3.3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.3.3.3.3.3.1.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3">superscript</csymbol><ci id="S3.SS2.p2.3.m3.3.3.3.3.3.2.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3.2">ğœŒ</ci><ci id="S3.SS2.p2.3.m3.3.3.3.3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3">ğ‘–</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.3c">=(\theta^{i},\phi^{i},\,\rho^{i})</annotation></semantics></math>. Each gaze vector uniquely identifies the orientation of the personâ€™s gaze with <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\theta</annotation></semantics></math>, <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">\phi</annotation></semantics></math>, and <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">Ï</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">ğœŒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">\rho</annotation></semantics></math>, which are the polar angle, azimuthal angle, and magnitude of the vector, respectively.
For each gaze vector <math id="S3.SS2.p2.7.m7.1" class="ltx_Math" alttext="\mathbf{v}_{g}^{i}" display="inline"><semantics id="S3.SS2.p2.7.m7.1a"><msubsup id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml"><mi id="S3.SS2.p2.7.m7.1.1.2.2" xref="S3.SS2.p2.7.m7.1.1.2.2.cmml">ğ¯</mi><mi id="S3.SS2.p2.7.m7.1.1.2.3" xref="S3.SS2.p2.7.m7.1.1.2.3.cmml">g</mi><mi id="S3.SS2.p2.7.m7.1.1.3" xref="S3.SS2.p2.7.m7.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><apply id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">superscript</csymbol><apply id="S3.SS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.2.1.cmml" xref="S3.SS2.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.2.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2.2">ğ¯</ci><ci id="S3.SS2.p2.7.m7.1.1.2.3.cmml" xref="S3.SS2.p2.7.m7.1.1.2.3">ğ‘”</ci></apply><ci id="S3.SS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">\mathbf{v}_{g}^{i}</annotation></semantics></math>, we design a 3D cone of angle <math id="S3.SS2.p2.8.m8.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.p2.8.m8.1a"><mi id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><ci id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">\alpha</annotation></semantics></math> and apex (<math id="S3.SS2.p2.9.m9.3" class="ltx_Math" alttext="c_{x}^{i},\,c_{y}^{i},\,c_{z}^{i}" display="inline"><semantics id="S3.SS2.p2.9.m9.3a"><mrow id="S3.SS2.p2.9.m9.3.3.3" xref="S3.SS2.p2.9.m9.3.3.4.cmml"><msubsup id="S3.SS2.p2.9.m9.1.1.1.1" xref="S3.SS2.p2.9.m9.1.1.1.1.cmml"><mi id="S3.SS2.p2.9.m9.1.1.1.1.2.2" xref="S3.SS2.p2.9.m9.1.1.1.1.2.2.cmml">c</mi><mi id="S3.SS2.p2.9.m9.1.1.1.1.2.3" xref="S3.SS2.p2.9.m9.1.1.1.1.2.3.cmml">x</mi><mi id="S3.SS2.p2.9.m9.1.1.1.1.3" xref="S3.SS2.p2.9.m9.1.1.1.1.3.cmml">i</mi></msubsup><mo rspace="0.337em" id="S3.SS2.p2.9.m9.3.3.3.4" xref="S3.SS2.p2.9.m9.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p2.9.m9.2.2.2.2" xref="S3.SS2.p2.9.m9.2.2.2.2.cmml"><mi id="S3.SS2.p2.9.m9.2.2.2.2.2.2" xref="S3.SS2.p2.9.m9.2.2.2.2.2.2.cmml">c</mi><mi id="S3.SS2.p2.9.m9.2.2.2.2.2.3" xref="S3.SS2.p2.9.m9.2.2.2.2.2.3.cmml">y</mi><mi id="S3.SS2.p2.9.m9.2.2.2.2.3" xref="S3.SS2.p2.9.m9.2.2.2.2.3.cmml">i</mi></msubsup><mo rspace="0.337em" id="S3.SS2.p2.9.m9.3.3.3.5" xref="S3.SS2.p2.9.m9.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p2.9.m9.3.3.3.3" xref="S3.SS2.p2.9.m9.3.3.3.3.cmml"><mi id="S3.SS2.p2.9.m9.3.3.3.3.2.2" xref="S3.SS2.p2.9.m9.3.3.3.3.2.2.cmml">c</mi><mi id="S3.SS2.p2.9.m9.3.3.3.3.2.3" xref="S3.SS2.p2.9.m9.3.3.3.3.2.3.cmml">z</mi><mi id="S3.SS2.p2.9.m9.3.3.3.3.3" xref="S3.SS2.p2.9.m9.3.3.3.3.3.cmml">i</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.3b"><list id="S3.SS2.p2.9.m9.3.3.4.cmml" xref="S3.SS2.p2.9.m9.3.3.3"><apply id="S3.SS2.p2.9.m9.1.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p2.9.m9.1.1.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.9.m9.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p2.9.m9.1.1.1.1.2.3.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.2.3">ğ‘¥</ci></apply><ci id="S3.SS2.p2.9.m9.1.1.1.1.3.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.9.m9.2.2.2.2.cmml" xref="S3.SS2.p2.9.m9.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.2.2.2.2.1.cmml" xref="S3.SS2.p2.9.m9.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p2.9.m9.2.2.2.2.2.cmml" xref="S3.SS2.p2.9.m9.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.9.m9.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.9.m9.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.9.m9.2.2.2.2.2.2">ğ‘</ci><ci id="S3.SS2.p2.9.m9.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.9.m9.2.2.2.2.2.3">ğ‘¦</ci></apply><ci id="S3.SS2.p2.9.m9.2.2.2.2.3.cmml" xref="S3.SS2.p2.9.m9.2.2.2.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.9.m9.3.3.3.3.cmml" xref="S3.SS2.p2.9.m9.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.3.3.3.3.1.cmml" xref="S3.SS2.p2.9.m9.3.3.3.3">superscript</csymbol><apply id="S3.SS2.p2.9.m9.3.3.3.3.2.cmml" xref="S3.SS2.p2.9.m9.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.3.3.3.3.2.1.cmml" xref="S3.SS2.p2.9.m9.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.9.m9.3.3.3.3.2.2.cmml" xref="S3.SS2.p2.9.m9.3.3.3.3.2.2">ğ‘</ci><ci id="S3.SS2.p2.9.m9.3.3.3.3.2.3.cmml" xref="S3.SS2.p2.9.m9.3.3.3.3.2.3">ğ‘§</ci></apply><ci id="S3.SS2.p2.9.m9.3.3.3.3.3.cmml" xref="S3.SS2.p2.9.m9.3.3.3.3.3">ğ‘–</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.3c">c_{x}^{i},\,c_{y}^{i},\,c_{z}^{i}</annotation></semantics></math>) representing the FoV of a person, where <math id="S3.SS2.p2.10.m10.1" class="ltx_Math" alttext="c_{x}^{i}" display="inline"><semantics id="S3.SS2.p2.10.m10.1a"><msubsup id="S3.SS2.p2.10.m10.1.1" xref="S3.SS2.p2.10.m10.1.1.cmml"><mi id="S3.SS2.p2.10.m10.1.1.2.2" xref="S3.SS2.p2.10.m10.1.1.2.2.cmml">c</mi><mi id="S3.SS2.p2.10.m10.1.1.2.3" xref="S3.SS2.p2.10.m10.1.1.2.3.cmml">x</mi><mi id="S3.SS2.p2.10.m10.1.1.3" xref="S3.SS2.p2.10.m10.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.1b"><apply id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.1.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">superscript</csymbol><apply id="S3.SS2.p2.10.m10.1.1.2.cmml" xref="S3.SS2.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.1.1.2.1.cmml" xref="S3.SS2.p2.10.m10.1.1">subscript</csymbol><ci id="S3.SS2.p2.10.m10.1.1.2.2.cmml" xref="S3.SS2.p2.10.m10.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p2.10.m10.1.1.2.3.cmml" xref="S3.SS2.p2.10.m10.1.1.2.3">ğ‘¥</ci></apply><ci id="S3.SS2.p2.10.m10.1.1.3.cmml" xref="S3.SS2.p2.10.m10.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.1c">c_{x}^{i}</annotation></semantics></math>, <math id="S3.SS2.p2.11.m11.1" class="ltx_Math" alttext="c_{y}^{i}" display="inline"><semantics id="S3.SS2.p2.11.m11.1a"><msubsup id="S3.SS2.p2.11.m11.1.1" xref="S3.SS2.p2.11.m11.1.1.cmml"><mi id="S3.SS2.p2.11.m11.1.1.2.2" xref="S3.SS2.p2.11.m11.1.1.2.2.cmml">c</mi><mi id="S3.SS2.p2.11.m11.1.1.2.3" xref="S3.SS2.p2.11.m11.1.1.2.3.cmml">y</mi><mi id="S3.SS2.p2.11.m11.1.1.3" xref="S3.SS2.p2.11.m11.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m11.1b"><apply id="S3.SS2.p2.11.m11.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m11.1.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1">superscript</csymbol><apply id="S3.SS2.p2.11.m11.1.1.2.cmml" xref="S3.SS2.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m11.1.1.2.1.cmml" xref="S3.SS2.p2.11.m11.1.1">subscript</csymbol><ci id="S3.SS2.p2.11.m11.1.1.2.2.cmml" xref="S3.SS2.p2.11.m11.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p2.11.m11.1.1.2.3.cmml" xref="S3.SS2.p2.11.m11.1.1.2.3">ğ‘¦</ci></apply><ci id="S3.SS2.p2.11.m11.1.1.3.cmml" xref="S3.SS2.p2.11.m11.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m11.1c">c_{y}^{i}</annotation></semantics></math>, and <math id="S3.SS2.p2.12.m12.1" class="ltx_Math" alttext="c_{z}^{i}" display="inline"><semantics id="S3.SS2.p2.12.m12.1a"><msubsup id="S3.SS2.p2.12.m12.1.1" xref="S3.SS2.p2.12.m12.1.1.cmml"><mi id="S3.SS2.p2.12.m12.1.1.2.2" xref="S3.SS2.p2.12.m12.1.1.2.2.cmml">c</mi><mi id="S3.SS2.p2.12.m12.1.1.2.3" xref="S3.SS2.p2.12.m12.1.1.2.3.cmml">z</mi><mi id="S3.SS2.p2.12.m12.1.1.3" xref="S3.SS2.p2.12.m12.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.12.m12.1b"><apply id="S3.SS2.p2.12.m12.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.12.m12.1.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1">superscript</csymbol><apply id="S3.SS2.p2.12.m12.1.1.2.cmml" xref="S3.SS2.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.12.m12.1.1.2.1.cmml" xref="S3.SS2.p2.12.m12.1.1">subscript</csymbol><ci id="S3.SS2.p2.12.m12.1.1.2.2.cmml" xref="S3.SS2.p2.12.m12.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p2.12.m12.1.1.2.3.cmml" xref="S3.SS2.p2.12.m12.1.1.2.3">ğ‘§</ci></apply><ci id="S3.SS2.p2.12.m12.1.1.3.cmml" xref="S3.SS2.p2.12.m12.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.12.m12.1c">c_{z}^{i}</annotation></semantics></math> are the center coordinates of the head.
The cone axis has the same direction as the gaze vector, and the intensity of the cone, <em id="S3.SS2.p2.21.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS2.p2.21.2" class="ltx_text"></span>, the point saliency, is calculated as the cosine similarity between <math id="S3.SS2.p2.13.m13.1" class="ltx_Math" alttext="\mathbf{v}_{g}^{i}" display="inline"><semantics id="S3.SS2.p2.13.m13.1a"><msubsup id="S3.SS2.p2.13.m13.1.1" xref="S3.SS2.p2.13.m13.1.1.cmml"><mi id="S3.SS2.p2.13.m13.1.1.2.2" xref="S3.SS2.p2.13.m13.1.1.2.2.cmml">ğ¯</mi><mi id="S3.SS2.p2.13.m13.1.1.2.3" xref="S3.SS2.p2.13.m13.1.1.2.3.cmml">g</mi><mi id="S3.SS2.p2.13.m13.1.1.3" xref="S3.SS2.p2.13.m13.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.13.m13.1b"><apply id="S3.SS2.p2.13.m13.1.1.cmml" xref="S3.SS2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.13.m13.1.1.1.cmml" xref="S3.SS2.p2.13.m13.1.1">superscript</csymbol><apply id="S3.SS2.p2.13.m13.1.1.2.cmml" xref="S3.SS2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.13.m13.1.1.2.1.cmml" xref="S3.SS2.p2.13.m13.1.1">subscript</csymbol><ci id="S3.SS2.p2.13.m13.1.1.2.2.cmml" xref="S3.SS2.p2.13.m13.1.1.2.2">ğ¯</ci><ci id="S3.SS2.p2.13.m13.1.1.2.3.cmml" xref="S3.SS2.p2.13.m13.1.1.2.3">ğ‘”</ci></apply><ci id="S3.SS2.p2.13.m13.1.1.3.cmml" xref="S3.SS2.p2.13.m13.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.13.m13.1c">\mathbf{v}_{g}^{i}</annotation></semantics></math> and all vectors inside the cone starting from (<math id="S3.SS2.p2.14.m14.3" class="ltx_Math" alttext="c_{x}^{i},\,c_{y}^{i},\,c_{z}^{i}" display="inline"><semantics id="S3.SS2.p2.14.m14.3a"><mrow id="S3.SS2.p2.14.m14.3.3.3" xref="S3.SS2.p2.14.m14.3.3.4.cmml"><msubsup id="S3.SS2.p2.14.m14.1.1.1.1" xref="S3.SS2.p2.14.m14.1.1.1.1.cmml"><mi id="S3.SS2.p2.14.m14.1.1.1.1.2.2" xref="S3.SS2.p2.14.m14.1.1.1.1.2.2.cmml">c</mi><mi id="S3.SS2.p2.14.m14.1.1.1.1.2.3" xref="S3.SS2.p2.14.m14.1.1.1.1.2.3.cmml">x</mi><mi id="S3.SS2.p2.14.m14.1.1.1.1.3" xref="S3.SS2.p2.14.m14.1.1.1.1.3.cmml">i</mi></msubsup><mo rspace="0.337em" id="S3.SS2.p2.14.m14.3.3.3.4" xref="S3.SS2.p2.14.m14.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p2.14.m14.2.2.2.2" xref="S3.SS2.p2.14.m14.2.2.2.2.cmml"><mi id="S3.SS2.p2.14.m14.2.2.2.2.2.2" xref="S3.SS2.p2.14.m14.2.2.2.2.2.2.cmml">c</mi><mi id="S3.SS2.p2.14.m14.2.2.2.2.2.3" xref="S3.SS2.p2.14.m14.2.2.2.2.2.3.cmml">y</mi><mi id="S3.SS2.p2.14.m14.2.2.2.2.3" xref="S3.SS2.p2.14.m14.2.2.2.2.3.cmml">i</mi></msubsup><mo rspace="0.337em" id="S3.SS2.p2.14.m14.3.3.3.5" xref="S3.SS2.p2.14.m14.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p2.14.m14.3.3.3.3" xref="S3.SS2.p2.14.m14.3.3.3.3.cmml"><mi id="S3.SS2.p2.14.m14.3.3.3.3.2.2" xref="S3.SS2.p2.14.m14.3.3.3.3.2.2.cmml">c</mi><mi id="S3.SS2.p2.14.m14.3.3.3.3.2.3" xref="S3.SS2.p2.14.m14.3.3.3.3.2.3.cmml">z</mi><mi id="S3.SS2.p2.14.m14.3.3.3.3.3" xref="S3.SS2.p2.14.m14.3.3.3.3.3.cmml">i</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.14.m14.3b"><list id="S3.SS2.p2.14.m14.3.3.4.cmml" xref="S3.SS2.p2.14.m14.3.3.3"><apply id="S3.SS2.p2.14.m14.1.1.1.1.cmml" xref="S3.SS2.p2.14.m14.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.14.m14.1.1.1.1.1.cmml" xref="S3.SS2.p2.14.m14.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p2.14.m14.1.1.1.1.2.cmml" xref="S3.SS2.p2.14.m14.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.14.m14.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.14.m14.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.14.m14.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.14.m14.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p2.14.m14.1.1.1.1.2.3.cmml" xref="S3.SS2.p2.14.m14.1.1.1.1.2.3">ğ‘¥</ci></apply><ci id="S3.SS2.p2.14.m14.1.1.1.1.3.cmml" xref="S3.SS2.p2.14.m14.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.14.m14.2.2.2.2.cmml" xref="S3.SS2.p2.14.m14.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.14.m14.2.2.2.2.1.cmml" xref="S3.SS2.p2.14.m14.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p2.14.m14.2.2.2.2.2.cmml" xref="S3.SS2.p2.14.m14.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.14.m14.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.14.m14.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.14.m14.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.14.m14.2.2.2.2.2.2">ğ‘</ci><ci id="S3.SS2.p2.14.m14.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.14.m14.2.2.2.2.2.3">ğ‘¦</ci></apply><ci id="S3.SS2.p2.14.m14.2.2.2.2.3.cmml" xref="S3.SS2.p2.14.m14.2.2.2.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.14.m14.3.3.3.3.cmml" xref="S3.SS2.p2.14.m14.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.14.m14.3.3.3.3.1.cmml" xref="S3.SS2.p2.14.m14.3.3.3.3">superscript</csymbol><apply id="S3.SS2.p2.14.m14.3.3.3.3.2.cmml" xref="S3.SS2.p2.14.m14.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.14.m14.3.3.3.3.2.1.cmml" xref="S3.SS2.p2.14.m14.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.14.m14.3.3.3.3.2.2.cmml" xref="S3.SS2.p2.14.m14.3.3.3.3.2.2">ğ‘</ci><ci id="S3.SS2.p2.14.m14.3.3.3.3.2.3.cmml" xref="S3.SS2.p2.14.m14.3.3.3.3.2.3">ğ‘§</ci></apply><ci id="S3.SS2.p2.14.m14.3.3.3.3.3.cmml" xref="S3.SS2.p2.14.m14.3.3.3.3.3">ğ‘–</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.14.m14.3c">c_{x}^{i},\,c_{y}^{i},\,c_{z}^{i}</annotation></semantics></math>). In the 2D case, <math id="S3.SS2.p2.15.m15.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS2.p2.15.m15.1a"><mi id="S3.SS2.p2.15.m15.1.1" xref="S3.SS2.p2.15.m15.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.15.m15.1b"><ci id="S3.SS2.p2.15.m15.1.1.cmml" xref="S3.SS2.p2.15.m15.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.15.m15.1c">\theta</annotation></semantics></math> is not available, and we only have one angle <math id="S3.SS2.p2.16.m16.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.SS2.p2.16.m16.1a"><mi id="S3.SS2.p2.16.m16.1.1" xref="S3.SS2.p2.16.m16.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.16.m16.1b"><ci id="S3.SS2.p2.16.m16.1.1.cmml" xref="S3.SS2.p2.16.m16.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.16.m16.1c">\phi</annotation></semantics></math> and the magnitude <math id="S3.SS2.p2.17.m17.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S3.SS2.p2.17.m17.1a"><mi id="S3.SS2.p2.17.m17.1.1" xref="S3.SS2.p2.17.m17.1.1.cmml">Ï</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.17.m17.1b"><ci id="S3.SS2.p2.17.m17.1.1.cmml" xref="S3.SS2.p2.17.m17.1.1">ğœŒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.17.m17.1c">\rho</annotation></semantics></math> for the gaze vector, while the 2D cone is still in the center of the apex but spans only in 2D instead of 3D. We adopt the discretized space of the same dimensionality of the predicted heatmap presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, while we extend it to the 3D case, with <math id="S3.SS2.p2.18.m18.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.p2.18.m18.1a"><mi id="S3.SS2.p2.18.m18.1.1" xref="S3.SS2.p2.18.m18.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.18.m18.1b"><ci id="S3.SS2.p2.18.m18.1.1.cmml" xref="S3.SS2.p2.18.m18.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.18.m18.1c">x</annotation></semantics></math>, <math id="S3.SS2.p2.19.m19.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS2.p2.19.m19.1a"><mi id="S3.SS2.p2.19.m19.1.1" xref="S3.SS2.p2.19.m19.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.19.m19.1b"><ci id="S3.SS2.p2.19.m19.1.1.cmml" xref="S3.SS2.p2.19.m19.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.19.m19.1c">y</annotation></semantics></math>, and <math id="S3.SS2.p2.20.m20.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS2.p2.20.m20.1a"><mi id="S3.SS2.p2.20.m20.1.1" xref="S3.SS2.p2.20.m20.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.20.m20.1b"><ci id="S3.SS2.p2.20.m20.1.1.cmml" xref="S3.SS2.p2.20.m20.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.20.m20.1c">z</annotation></semantics></math> axis corresponding to the width, height, and depth of the image.
For the 2D cone building, we follow the approach of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, but we constrain the cone to be a fixed angle <math id="S3.SS2.p2.21.m21.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.p2.21.m21.1a"><mi id="S3.SS2.p2.21.m21.1.1" xref="S3.SS2.p2.21.m21.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.21.m21.1b"><ci id="S3.SS2.p2.21.m21.1.1.cmml" xref="S3.SS2.p2.21.m21.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.21.m21.1c">\alpha</annotation></semantics></math>, which is in line with the FoV of human boundaries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.5" class="ltx_p">Below, the derivations are given for the 3D gaze cone, but the corresponding 2D implementation of them is the same except for not having the depth coordinates as described above. Refer to the visual explanation of the 2D and 3D gaze cone in Fig.Â <a href="#S3.F3" title="Figure 3 â€£ 3.1 Object Detector Transformer â€£ 3 Method â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>a-c.
Formally, let <math id="S3.SS2.p3.1.m1.2" class="ltx_Math" alttext="angle(\textbf{v}_{a},\textbf{v}_{b})" display="inline"><semantics id="S3.SS2.p3.1.m1.2a"><mrow id="S3.SS2.p3.1.m1.2.2" xref="S3.SS2.p3.1.m1.2.2.cmml"><mi id="S3.SS2.p3.1.m1.2.2.4" xref="S3.SS2.p3.1.m1.2.2.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.2.2.3" xref="S3.SS2.p3.1.m1.2.2.3.cmml">â€‹</mo><mi id="S3.SS2.p3.1.m1.2.2.5" xref="S3.SS2.p3.1.m1.2.2.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.2.2.3a" xref="S3.SS2.p3.1.m1.2.2.3.cmml">â€‹</mo><mi id="S3.SS2.p3.1.m1.2.2.6" xref="S3.SS2.p3.1.m1.2.2.6.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.2.2.3b" xref="S3.SS2.p3.1.m1.2.2.3.cmml">â€‹</mo><mi id="S3.SS2.p3.1.m1.2.2.7" xref="S3.SS2.p3.1.m1.2.2.7.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.2.2.3c" xref="S3.SS2.p3.1.m1.2.2.3.cmml">â€‹</mo><mi id="S3.SS2.p3.1.m1.2.2.8" xref="S3.SS2.p3.1.m1.2.2.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.2.2.3d" xref="S3.SS2.p3.1.m1.2.2.3.cmml">â€‹</mo><mrow id="S3.SS2.p3.1.m1.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.p3.1.m1.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">(</mo><msub id="S3.SS2.p3.1.m1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.1.m1.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2a.cmml">v</mtext><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.SS2.p3.1.m1.2.2.2.2.4" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.1.m1.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.1.m1.2.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2a.cmml">v</mtext><mi id="S3.SS2.p3.1.m1.2.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.2.2.3.cmml">b</mi></msub><mo stretchy="false" id="S3.SS2.p3.1.m1.2.2.2.2.5" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.2b"><apply id="S3.SS2.p3.1.m1.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2"><times id="S3.SS2.p3.1.m1.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.3"></times><ci id="S3.SS2.p3.1.m1.2.2.4.cmml" xref="S3.SS2.p3.1.m1.2.2.4">ğ‘</ci><ci id="S3.SS2.p3.1.m1.2.2.5.cmml" xref="S3.SS2.p3.1.m1.2.2.5">ğ‘›</ci><ci id="S3.SS2.p3.1.m1.2.2.6.cmml" xref="S3.SS2.p3.1.m1.2.2.6">ğ‘”</ci><ci id="S3.SS2.p3.1.m1.2.2.7.cmml" xref="S3.SS2.p3.1.m1.2.2.7">ğ‘™</ci><ci id="S3.SS2.p3.1.m1.2.2.8.cmml" xref="S3.SS2.p3.1.m1.2.2.8">ğ‘’</ci><interval closure="open" id="S3.SS2.p3.1.m1.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2"><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.2a.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2">v</mtext></ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3">ğ‘</ci></apply><apply id="S3.SS2.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.2a.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2">v</mtext></ci><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.3">ğ‘</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.2c">angle(\textbf{v}_{a},\textbf{v}_{b})</annotation></semantics></math> be the absolute value of the angle between two vectors, and <math id="S3.SS2.p3.2.m2.2" class="ltx_Math" alttext="\sigma(\mathbf{v}_{a},\mathbf{v}_{b})" display="inline"><semantics id="S3.SS2.p3.2.m2.2a"><mrow id="S3.SS2.p3.2.m2.2.2" xref="S3.SS2.p3.2.m2.2.2.cmml"><mi id="S3.SS2.p3.2.m2.2.2.4" xref="S3.SS2.p3.2.m2.2.2.4.cmml">Ïƒ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.3.cmml">â€‹</mo><mrow id="S3.SS2.p3.2.m2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.p3.2.m2.2.2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml">(</mo><msub id="S3.SS2.p3.2.m2.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml">ğ¯</mi><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.SS2.p3.2.m2.2.2.2.2.4" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.2.m2.2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS2.p3.2.m2.2.2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.2.2.2.cmml">ğ¯</mi><mi id="S3.SS2.p3.2.m2.2.2.2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.2.2.2.3.cmml">b</mi></msub><mo stretchy="false" id="S3.SS2.p3.2.m2.2.2.2.2.5" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.2b"><apply id="S3.SS2.p3.2.m2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2"><times id="S3.SS2.p3.2.m2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.3"></times><ci id="S3.SS2.p3.2.m2.2.2.4.cmml" xref="S3.SS2.p3.2.m2.2.2.4">ğœ</ci><interval closure="open" id="S3.SS2.p3.2.m2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2"><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2">ğ¯</ci><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3">ğ‘</ci></apply><apply id="S3.SS2.p3.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2.2">ğ¯</ci><ci id="S3.SS2.p3.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2.3">ğ‘</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.2c">\sigma(\mathbf{v}_{a},\mathbf{v}_{b})</annotation></semantics></math> be the cosine similarity between two vectors <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{v}_{a}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">ğ¯</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">ğ¯</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathbf{v}_{a}</annotation></semantics></math> and <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="\mathbf{v}_{b}" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">ğ¯</mi><mi id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">ğ¯</ci><ci id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">\mathbf{v}_{b}</annotation></semantics></math> conditioned on the cone angle <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\alpha</annotation></semantics></math>:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.6" class="ltx_Math" alttext="\sigma(\mathbf{v}_{a},\mathbf{v}_{b})=\begin{cases}\cos{(\mathbf{v}_{a},\mathbf{v}_{b})}&amp;\text{if}\,\,angle(\mathbf{v}_{a},\mathbf{v}_{b})\leq\frac{\alpha}{2},\\
0&amp;\text{otherwise}\end{cases}\vspace{-0.2cm}" display="block"><semantics id="S3.E1.m1.6a"><mrow id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml"><mrow id="S3.E1.m1.6.6.2" xref="S3.E1.m1.6.6.2.cmml"><mi id="S3.E1.m1.6.6.2.4" xref="S3.E1.m1.6.6.2.4.cmml">Ïƒ</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.2.3" xref="S3.E1.m1.6.6.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.2.2.2" xref="S3.E1.m1.6.6.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.2.2.2.3" xref="S3.E1.m1.6.6.2.2.3.cmml">(</mo><msub id="S3.E1.m1.5.5.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.1.2.cmml">ğ¯</mi><mi id="S3.E1.m1.5.5.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.E1.m1.6.6.2.2.2.4" xref="S3.E1.m1.6.6.2.2.3.cmml">,</mo><msub id="S3.E1.m1.6.6.2.2.2.2" xref="S3.E1.m1.6.6.2.2.2.2.cmml"><mi id="S3.E1.m1.6.6.2.2.2.2.2" xref="S3.E1.m1.6.6.2.2.2.2.2.cmml">ğ¯</mi><mi id="S3.E1.m1.6.6.2.2.2.2.3" xref="S3.E1.m1.6.6.2.2.2.2.3.cmml">b</mi></msub><mo stretchy="false" id="S3.E1.m1.6.6.2.2.2.5" xref="S3.E1.m1.6.6.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.6.6.3" xref="S3.E1.m1.6.6.3.cmml">=</mo><mrow id="S3.E1.m1.4.4" xref="S3.E1.m1.6.6.4.1.cmml"><mo id="S3.E1.m1.4.4.5" xref="S3.E1.m1.6.6.4.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.E1.m1.4.4.4" xref="S3.E1.m1.6.6.4.1.cmml"><mtr id="S3.E1.m1.4.4.4a" xref="S3.E1.m1.6.6.4.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4.4b" xref="S3.E1.m1.6.6.4.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.4.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">cos</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3a" xref="S3.E1.m1.1.1.1.1.1.1.4.cmml">â¡</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.4.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.4.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.2.1.1" xref="S3.E1.m1.1.1.1.1.1.1.2.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.1.1.2.cmml">ğ¯</mi><mi id="S3.E1.m1.1.1.1.1.1.1.2.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.2.1.1.3.cmml">a</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.1.3.2.4" xref="S3.E1.m1.1.1.1.1.1.1.4.cmml">,</mo><msub id="S3.E1.m1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.2.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2.2.cmml">ğ¯</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.2.3" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2.3.cmml">b</mi></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.3.2.5" xref="S3.E1.m1.1.1.1.1.1.1.4.cmml">)</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4.4c" xref="S3.E1.m1.6.6.4.1.cmml"><mrow id="S3.E1.m1.2.2.2.2.2.1.1" xref="S3.E1.m1.2.2.2.2.2.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.2.2.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.2.2.2.1.1.1.2" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.cmml"><mtext id="S3.E1.m1.2.2.2.2.2.1.1.1.2.4" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.4a.cmml">if</mtext><mo lspace="0.330em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.3" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.3.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.2.5" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.3a" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.3.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.2.6" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.3b" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.3.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.2.7" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.7.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.3c" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.3.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.2.8" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.8.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.3d" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.3.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.2.9" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.3e" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.2.cmml">ğ¯</mi><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.2.cmml">ğ¯</mi><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.3.cmml">b</mi></msub><mo stretchy="false" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.5" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.2.2.2.1.1.1.3" xref="S3.E1.m1.2.2.2.2.2.1.1.1.3.cmml">â‰¤</mo><mstyle displaystyle="false" id="S3.E1.m1.2.2.2.2.2.1.1.1.4" xref="S3.E1.m1.2.2.2.2.2.1.1.1.4.cmml"><mfrac id="S3.E1.m1.2.2.2.2.2.1.1.1.4a" xref="S3.E1.m1.2.2.2.2.2.1.1.1.4.cmml"><mi id="S3.E1.m1.2.2.2.2.2.1.1.1.4.2" xref="S3.E1.m1.2.2.2.2.2.1.1.1.4.2.cmml">Î±</mi><mn id="S3.E1.m1.2.2.2.2.2.1.1.1.4.3" xref="S3.E1.m1.2.2.2.2.2.1.1.1.4.3.cmml">2</mn></mfrac></mstyle></mrow><mo id="S3.E1.m1.2.2.2.2.2.1.1.2" xref="S3.E1.m1.2.2.2.2.2.1.1.1.cmml">,</mo></mrow></mtd></mtr><mtr id="S3.E1.m1.4.4.4d" xref="S3.E1.m1.6.6.4.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4.4e" xref="S3.E1.m1.6.6.4.1.cmml"><mn id="S3.E1.m1.3.3.3.3.1.1" xref="S3.E1.m1.3.3.3.3.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4.4f" xref="S3.E1.m1.6.6.4.1.cmml"><mtext id="S3.E1.m1.4.4.4.4.2.1" xref="S3.E1.m1.4.4.4.4.2.1a.cmml">otherwise</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.6b"><apply id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6"><eq id="S3.E1.m1.6.6.3.cmml" xref="S3.E1.m1.6.6.3"></eq><apply id="S3.E1.m1.6.6.2.cmml" xref="S3.E1.m1.6.6.2"><times id="S3.E1.m1.6.6.2.3.cmml" xref="S3.E1.m1.6.6.2.3"></times><ci id="S3.E1.m1.6.6.2.4.cmml" xref="S3.E1.m1.6.6.2.4">ğœ</ci><interval closure="open" id="S3.E1.m1.6.6.2.2.3.cmml" xref="S3.E1.m1.6.6.2.2.2"><apply id="S3.E1.m1.5.5.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.2">ğ¯</ci><ci id="S3.E1.m1.5.5.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.3">ğ‘</ci></apply><apply id="S3.E1.m1.6.6.2.2.2.2.cmml" xref="S3.E1.m1.6.6.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.2.2.2.2.1.cmml" xref="S3.E1.m1.6.6.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.6.6.2.2.2.2.2.cmml" xref="S3.E1.m1.6.6.2.2.2.2.2">ğ¯</ci><ci id="S3.E1.m1.6.6.2.2.2.2.3.cmml" xref="S3.E1.m1.6.6.2.2.2.2.3">ğ‘</ci></apply></interval></apply><apply id="S3.E1.m1.6.6.4.1.cmml" xref="S3.E1.m1.4.4"><csymbol cd="latexml" id="S3.E1.m1.6.6.4.1.1.cmml" xref="S3.E1.m1.4.4.5">cases</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><cos id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"></cos><apply id="S3.E1.m1.1.1.1.1.1.1.2.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.1.1.2">ğ¯</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.1.1.3">ğ‘</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2.2">ğ¯</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2.3">ğ‘</ci></apply></apply><apply id="S3.E1.m1.2.2.2.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1"><leq id="S3.E1.m1.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.3"></leq><apply id="S3.E1.m1.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2"><times id="S3.E1.m1.2.2.2.2.2.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.3"></times><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.2.4a.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.4"><mtext id="S3.E1.m1.2.2.2.2.2.1.1.1.2.4.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.4">if</mtext></ci><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.2.5.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.5">ğ‘</ci><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.2.6.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.6">ğ‘›</ci><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.2.7.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.7">ğ‘”</ci><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.2.8.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.8">ğ‘™</ci><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.2.9.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.9">ğ‘’</ci><interval closure="open" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2"><apply id="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.2">ğ¯</ci><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.1.1.1.1.3">ğ‘</ci></apply><apply id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.2">ğ¯</ci><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.2.2.2.2.3">ğ‘</ci></apply></interval></apply><apply id="S3.E1.m1.2.2.2.2.2.1.1.1.4.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.4"><divide id="S3.E1.m1.2.2.2.2.2.1.1.1.4.1.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.4"></divide><ci id="S3.E1.m1.2.2.2.2.2.1.1.1.4.2.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.4.2">ğ›¼</ci><cn type="integer" id="S3.E1.m1.2.2.2.2.2.1.1.1.4.3.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1.1.4.3">2</cn></apply></apply><cn type="integer" id="S3.E1.m1.3.3.3.3.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1">0</cn><ci id="S3.E1.m1.4.4.4.4.2.1a.cmml" xref="S3.E1.m1.4.4.4.4.2.1"><mtext id="S3.E1.m1.4.4.4.4.2.1.cmml" xref="S3.E1.m1.4.4.4.4.2.1">otherwise</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.6c">\sigma(\mathbf{v}_{a},\mathbf{v}_{b})=\begin{cases}\cos{(\mathbf{v}_{a},\mathbf{v}_{b})}&amp;\text{if}\,\,angle(\mathbf{v}_{a},\mathbf{v}_{b})\leq\frac{\alpha}{2},\\
0&amp;\text{otherwise}\end{cases}\vspace{-0.2cm}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.9" class="ltx_p">The projected 3D gaze cone of a person <math id="S3.SS2.p3.6.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p3.6.m1.1a"><mi id="S3.SS2.p3.6.m1.1.1" xref="S3.SS2.p3.6.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m1.1b"><ci id="S3.SS2.p3.6.m1.1.1.cmml" xref="S3.SS2.p3.6.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m1.1c">i</annotation></semantics></math>, <math id="S3.SS2.p3.7.m2.1" class="ltx_Math" alttext="\mathbf{CD}_{3D}^{i}" display="inline"><semantics id="S3.SS2.p3.7.m2.1a"><msubsup id="S3.SS2.p3.7.m2.1.1" xref="S3.SS2.p3.7.m2.1.1.cmml"><mi id="S3.SS2.p3.7.m2.1.1.2.2" xref="S3.SS2.p3.7.m2.1.1.2.2.cmml">ğ‚ğƒ</mi><mrow id="S3.SS2.p3.7.m2.1.1.2.3" xref="S3.SS2.p3.7.m2.1.1.2.3.cmml"><mn id="S3.SS2.p3.7.m2.1.1.2.3.2" xref="S3.SS2.p3.7.m2.1.1.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m2.1.1.2.3.1" xref="S3.SS2.p3.7.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.7.m2.1.1.2.3.3" xref="S3.SS2.p3.7.m2.1.1.2.3.3.cmml">D</mi></mrow><mi id="S3.SS2.p3.7.m2.1.1.3" xref="S3.SS2.p3.7.m2.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m2.1b"><apply id="S3.SS2.p3.7.m2.1.1.cmml" xref="S3.SS2.p3.7.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m2.1.1.1.cmml" xref="S3.SS2.p3.7.m2.1.1">superscript</csymbol><apply id="S3.SS2.p3.7.m2.1.1.2.cmml" xref="S3.SS2.p3.7.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m2.1.1.2.1.cmml" xref="S3.SS2.p3.7.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m2.1.1.2.2.cmml" xref="S3.SS2.p3.7.m2.1.1.2.2">ğ‚ğƒ</ci><apply id="S3.SS2.p3.7.m2.1.1.2.3.cmml" xref="S3.SS2.p3.7.m2.1.1.2.3"><times id="S3.SS2.p3.7.m2.1.1.2.3.1.cmml" xref="S3.SS2.p3.7.m2.1.1.2.3.1"></times><cn type="integer" id="S3.SS2.p3.7.m2.1.1.2.3.2.cmml" xref="S3.SS2.p3.7.m2.1.1.2.3.2">3</cn><ci id="S3.SS2.p3.7.m2.1.1.2.3.3.cmml" xref="S3.SS2.p3.7.m2.1.1.2.3.3">ğ·</ci></apply></apply><ci id="S3.SS2.p3.7.m2.1.1.3.cmml" xref="S3.SS2.p3.7.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m2.1c">\mathbf{CD}_{3D}^{i}</annotation></semantics></math>, whose head center coordinates are <math id="S3.SS2.p3.8.m3.3" class="ltx_Math" alttext="c_{x}^{i},c_{y}^{i},c_{z}^{i}" display="inline"><semantics id="S3.SS2.p3.8.m3.3a"><mrow id="S3.SS2.p3.8.m3.3.3.3" xref="S3.SS2.p3.8.m3.3.3.4.cmml"><msubsup id="S3.SS2.p3.8.m3.1.1.1.1" xref="S3.SS2.p3.8.m3.1.1.1.1.cmml"><mi id="S3.SS2.p3.8.m3.1.1.1.1.2.2" xref="S3.SS2.p3.8.m3.1.1.1.1.2.2.cmml">c</mi><mi id="S3.SS2.p3.8.m3.1.1.1.1.2.3" xref="S3.SS2.p3.8.m3.1.1.1.1.2.3.cmml">x</mi><mi id="S3.SS2.p3.8.m3.1.1.1.1.3" xref="S3.SS2.p3.8.m3.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.SS2.p3.8.m3.3.3.3.4" xref="S3.SS2.p3.8.m3.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p3.8.m3.2.2.2.2" xref="S3.SS2.p3.8.m3.2.2.2.2.cmml"><mi id="S3.SS2.p3.8.m3.2.2.2.2.2.2" xref="S3.SS2.p3.8.m3.2.2.2.2.2.2.cmml">c</mi><mi id="S3.SS2.p3.8.m3.2.2.2.2.2.3" xref="S3.SS2.p3.8.m3.2.2.2.2.2.3.cmml">y</mi><mi id="S3.SS2.p3.8.m3.2.2.2.2.3" xref="S3.SS2.p3.8.m3.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S3.SS2.p3.8.m3.3.3.3.5" xref="S3.SS2.p3.8.m3.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p3.8.m3.3.3.3.3" xref="S3.SS2.p3.8.m3.3.3.3.3.cmml"><mi id="S3.SS2.p3.8.m3.3.3.3.3.2.2" xref="S3.SS2.p3.8.m3.3.3.3.3.2.2.cmml">c</mi><mi id="S3.SS2.p3.8.m3.3.3.3.3.2.3" xref="S3.SS2.p3.8.m3.3.3.3.3.2.3.cmml">z</mi><mi id="S3.SS2.p3.8.m3.3.3.3.3.3" xref="S3.SS2.p3.8.m3.3.3.3.3.3.cmml">i</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m3.3b"><list id="S3.SS2.p3.8.m3.3.3.4.cmml" xref="S3.SS2.p3.8.m3.3.3.3"><apply id="S3.SS2.p3.8.m3.1.1.1.1.cmml" xref="S3.SS2.p3.8.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m3.1.1.1.1.1.cmml" xref="S3.SS2.p3.8.m3.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p3.8.m3.1.1.1.1.2.cmml" xref="S3.SS2.p3.8.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m3.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.8.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.8.m3.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.8.m3.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p3.8.m3.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.8.m3.1.1.1.1.2.3">ğ‘¥</ci></apply><ci id="S3.SS2.p3.8.m3.1.1.1.1.3.cmml" xref="S3.SS2.p3.8.m3.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p3.8.m3.2.2.2.2.cmml" xref="S3.SS2.p3.8.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m3.2.2.2.2.1.cmml" xref="S3.SS2.p3.8.m3.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p3.8.m3.2.2.2.2.2.cmml" xref="S3.SS2.p3.8.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m3.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.8.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.8.m3.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.8.m3.2.2.2.2.2.2">ğ‘</ci><ci id="S3.SS2.p3.8.m3.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.8.m3.2.2.2.2.2.3">ğ‘¦</ci></apply><ci id="S3.SS2.p3.8.m3.2.2.2.2.3.cmml" xref="S3.SS2.p3.8.m3.2.2.2.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p3.8.m3.3.3.3.3.cmml" xref="S3.SS2.p3.8.m3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m3.3.3.3.3.1.cmml" xref="S3.SS2.p3.8.m3.3.3.3.3">superscript</csymbol><apply id="S3.SS2.p3.8.m3.3.3.3.3.2.cmml" xref="S3.SS2.p3.8.m3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m3.3.3.3.3.2.1.cmml" xref="S3.SS2.p3.8.m3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p3.8.m3.3.3.3.3.2.2.cmml" xref="S3.SS2.p3.8.m3.3.3.3.3.2.2">ğ‘</ci><ci id="S3.SS2.p3.8.m3.3.3.3.3.2.3.cmml" xref="S3.SS2.p3.8.m3.3.3.3.3.2.3">ğ‘§</ci></apply><ci id="S3.SS2.p3.8.m3.3.3.3.3.3.cmml" xref="S3.SS2.p3.8.m3.3.3.3.3.3">ğ‘–</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m3.3c">c_{x}^{i},c_{y}^{i},c_{z}^{i}</annotation></semantics></math>, and predicted gaze vector <math id="S3.SS2.p3.9.m4.1" class="ltx_Math" alttext="\mathbf{v}_{g}^{i}" display="inline"><semantics id="S3.SS2.p3.9.m4.1a"><msubsup id="S3.SS2.p3.9.m4.1.1" xref="S3.SS2.p3.9.m4.1.1.cmml"><mi id="S3.SS2.p3.9.m4.1.1.2.2" xref="S3.SS2.p3.9.m4.1.1.2.2.cmml">ğ¯</mi><mi id="S3.SS2.p3.9.m4.1.1.2.3" xref="S3.SS2.p3.9.m4.1.1.2.3.cmml">g</mi><mi id="S3.SS2.p3.9.m4.1.1.3" xref="S3.SS2.p3.9.m4.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m4.1b"><apply id="S3.SS2.p3.9.m4.1.1.cmml" xref="S3.SS2.p3.9.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m4.1.1.1.cmml" xref="S3.SS2.p3.9.m4.1.1">superscript</csymbol><apply id="S3.SS2.p3.9.m4.1.1.2.cmml" xref="S3.SS2.p3.9.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m4.1.1.2.1.cmml" xref="S3.SS2.p3.9.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.9.m4.1.1.2.2.cmml" xref="S3.SS2.p3.9.m4.1.1.2.2">ğ¯</ci><ci id="S3.SS2.p3.9.m4.1.1.2.3.cmml" xref="S3.SS2.p3.9.m4.1.1.2.3">ğ‘”</ci></apply><ci id="S3.SS2.p3.9.m4.1.1.3.cmml" xref="S3.SS2.p3.9.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m4.1c">\mathbf{v}_{g}^{i}</annotation></semantics></math>, is defined as:</p>
<table id="S3.E2" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E2X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\small{\mathbf{CD}_{3D}^{i}=\{\sigma(\mathbf{v}_{g}^{i},\mathbf{v}_{H}^{ijkl})\}}" display="inline"><semantics id="S3.E2X.2.1.1.m1.1a"><mrow id="S3.E2X.2.1.1.m1.1.1" xref="S3.E2X.2.1.1.m1.1.1.cmml"><msubsup id="S3.E2X.2.1.1.m1.1.1.3" xref="S3.E2X.2.1.1.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.3.2.2" xref="S3.E2X.2.1.1.m1.1.1.3.2.2.cmml">ğ‚ğƒ</mi><mrow id="S3.E2X.2.1.1.m1.1.1.3.2.3" xref="S3.E2X.2.1.1.m1.1.1.3.2.3.cmml"><mn mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.3.2.3.2" xref="S3.E2X.2.1.1.m1.1.1.3.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.3.2.3.1" xref="S3.E2X.2.1.1.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.3.2.3.3" xref="S3.E2X.2.1.1.m1.1.1.3.2.3.3.cmml">D</mi></mrow><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.3.3" xref="S3.E2X.2.1.1.m1.1.1.3.3.cmml">i</mi></msubsup><mo mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.2" xref="S3.E2X.2.1.1.m1.1.1.2.cmml">=</mo><mrow id="S3.E2X.2.1.1.m1.1.1.1.1" xref="S3.E2X.2.1.1.m1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.2" xref="S3.E2X.2.1.1.m1.1.1.1.2.cmml">{</mo><mrow id="S3.E2X.2.1.1.m1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.4" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.4.cmml">Ïƒ</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.3.cmml">â€‹</mo><mrow id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.3.cmml">(</mo><msubsup id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml">ğ¯</mi><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml">g</mi><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.4" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.3.cmml">,</mo><msubsup id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.cmml"><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.2.cmml">ğ¯</mi><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.cmml">H</mi><mrow id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.cmml"><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.1" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.3.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.1a" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.4" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.4.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.1b" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.5" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.5.cmml">l</mi></mrow></msubsup><mo maxsize="90%" minsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.5" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo maxsize="90%" minsize="90%" id="S3.E2X.2.1.1.m1.1.1.1.1.3" xref="S3.E2X.2.1.1.m1.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2X.2.1.1.m1.1b"><apply id="S3.E2X.2.1.1.m1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1"><eq id="S3.E2X.2.1.1.m1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.2"></eq><apply id="S3.E2X.2.1.1.m1.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.1.1.3.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.3">superscript</csymbol><apply id="S3.E2X.2.1.1.m1.1.1.3.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.1.1.3.2.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.3">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.1.1.3.2.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.3.2.2">ğ‚ğƒ</ci><apply id="S3.E2X.2.1.1.m1.1.1.3.2.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.3.2.3"><times id="S3.E2X.2.1.1.m1.1.1.3.2.3.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.3.2.3.1"></times><cn type="integer" id="S3.E2X.2.1.1.m1.1.1.3.2.3.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.3.2.3.2">3</cn><ci id="S3.E2X.2.1.1.m1.1.1.3.2.3.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.3.2.3.3">ğ·</ci></apply></apply><ci id="S3.E2X.2.1.1.m1.1.1.3.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.3.3">ğ‘–</ci></apply><set id="S3.E2X.2.1.1.m1.1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1"><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1"><times id="S3.E2X.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.3"></times><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.4.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.4">ğœ</ci><interval closure="open" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2"><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2">ğ¯</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3">ğ‘”</ci></apply><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2">superscript</csymbol><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.2">ğ¯</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.2.3">ğ»</ci></apply><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3"><times id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.1"></times><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.2">ğ‘–</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.3">ğ‘—</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.4.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.4">ğ‘˜</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.5.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.3.5">ğ‘™</ci></apply></apply></interval></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2X.2.1.1.m1.1c">\displaystyle\small{\mathbf{CD}_{3D}^{i}=\{\sigma(\mathbf{v}_{g}^{i},\mathbf{v}_{H}^{ijkl})\}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(2)</span></td>
</tr>
<tr id="S3.E2Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2Xa.2.1.1.m1.9" class="ltx_Math" alttext="\displaystyle\,\small{\forall j,k,l\in[0,w)\times[0,h)\times[0,d)}" display="inline"><semantics id="S3.E2Xa.2.1.1.m1.9a"><mrow id="S3.E2Xa.2.1.1.m1.9.9" xref="S3.E2Xa.2.1.1.m1.9.9.cmml"><mrow id="S3.E2Xa.2.1.1.m1.9.9.1.1" xref="S3.E2Xa.2.1.1.m1.9.9.1.2.cmml"><mrow id="S3.E2Xa.2.1.1.m1.9.9.1.1.1" xref="S3.E2Xa.2.1.1.m1.9.9.1.1.1.cmml"><mo mathsize="90%" rspace="0.167em" id="S3.E2Xa.2.1.1.m1.9.9.1.1.1.1" xref="S3.E2Xa.2.1.1.m1.9.9.1.1.1.1.cmml">âˆ€</mo><mi mathsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.1.1.1.2" xref="S3.E2Xa.2.1.1.m1.9.9.1.1.1.2.cmml">j</mi></mrow><mo mathsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.1.1.2" xref="S3.E2Xa.2.1.1.m1.9.9.1.2.cmml">,</mo><mi mathsize="90%" id="S3.E2Xa.2.1.1.m1.7.7" xref="S3.E2Xa.2.1.1.m1.7.7.cmml">k</mi><mo mathsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.1.1.3" xref="S3.E2Xa.2.1.1.m1.9.9.1.2.cmml">,</mo><mi mathsize="90%" id="S3.E2Xa.2.1.1.m1.8.8" xref="S3.E2Xa.2.1.1.m1.8.8.cmml">l</mi></mrow><mo mathsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.2" xref="S3.E2Xa.2.1.1.m1.9.9.2.cmml">âˆˆ</mo><mrow id="S3.E2Xa.2.1.1.m1.9.9.3" xref="S3.E2Xa.2.1.1.m1.9.9.3.cmml"><mrow id="S3.E2Xa.2.1.1.m1.9.9.3.2.2" xref="S3.E2Xa.2.1.1.m1.9.9.3.2.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.3.2.2.1" xref="S3.E2Xa.2.1.1.m1.9.9.3.2.1.cmml">[</mo><mn mathsize="90%" id="S3.E2Xa.2.1.1.m1.1.1" xref="S3.E2Xa.2.1.1.m1.1.1.cmml">0</mn><mo mathsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.3.2.2.2" xref="S3.E2Xa.2.1.1.m1.9.9.3.2.1.cmml">,</mo><mi mathsize="90%" id="S3.E2Xa.2.1.1.m1.2.2" xref="S3.E2Xa.2.1.1.m1.2.2.cmml">w</mi><mo maxsize="90%" minsize="90%" rspace="0.055em" id="S3.E2Xa.2.1.1.m1.9.9.3.2.2.3" xref="S3.E2Xa.2.1.1.m1.9.9.3.2.1.cmml">)</mo></mrow><mo mathsize="90%" rspace="0.222em" id="S3.E2Xa.2.1.1.m1.9.9.3.1" xref="S3.E2Xa.2.1.1.m1.9.9.3.1.cmml">Ã—</mo><mrow id="S3.E2Xa.2.1.1.m1.9.9.3.3.2" xref="S3.E2Xa.2.1.1.m1.9.9.3.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.3.3.2.1" xref="S3.E2Xa.2.1.1.m1.9.9.3.3.1.cmml">[</mo><mn mathsize="90%" id="S3.E2Xa.2.1.1.m1.3.3" xref="S3.E2Xa.2.1.1.m1.3.3.cmml">0</mn><mo mathsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.3.3.2.2" xref="S3.E2Xa.2.1.1.m1.9.9.3.3.1.cmml">,</mo><mi mathsize="90%" id="S3.E2Xa.2.1.1.m1.4.4" xref="S3.E2Xa.2.1.1.m1.4.4.cmml">h</mi><mo maxsize="90%" minsize="90%" rspace="0.055em" id="S3.E2Xa.2.1.1.m1.9.9.3.3.2.3" xref="S3.E2Xa.2.1.1.m1.9.9.3.3.1.cmml">)</mo></mrow><mo mathsize="90%" rspace="0.222em" id="S3.E2Xa.2.1.1.m1.9.9.3.1a" xref="S3.E2Xa.2.1.1.m1.9.9.3.1.cmml">Ã—</mo><mrow id="S3.E2Xa.2.1.1.m1.9.9.3.4.2" xref="S3.E2Xa.2.1.1.m1.9.9.3.4.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.3.4.2.1" xref="S3.E2Xa.2.1.1.m1.9.9.3.4.1.cmml">[</mo><mn mathsize="90%" id="S3.E2Xa.2.1.1.m1.5.5" xref="S3.E2Xa.2.1.1.m1.5.5.cmml">0</mn><mo mathsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.3.4.2.2" xref="S3.E2Xa.2.1.1.m1.9.9.3.4.1.cmml">,</mo><mi mathsize="90%" id="S3.E2Xa.2.1.1.m1.6.6" xref="S3.E2Xa.2.1.1.m1.6.6.cmml">d</mi><mo maxsize="90%" minsize="90%" id="S3.E2Xa.2.1.1.m1.9.9.3.4.2.3" xref="S3.E2Xa.2.1.1.m1.9.9.3.4.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2Xa.2.1.1.m1.9b"><apply id="S3.E2Xa.2.1.1.m1.9.9.cmml" xref="S3.E2Xa.2.1.1.m1.9.9"><in id="S3.E2Xa.2.1.1.m1.9.9.2.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.2"></in><list id="S3.E2Xa.2.1.1.m1.9.9.1.2.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.1.1"><apply id="S3.E2Xa.2.1.1.m1.9.9.1.1.1.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.1.1.1"><csymbol cd="latexml" id="S3.E2Xa.2.1.1.m1.9.9.1.1.1.1.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.1.1.1.1">for-all</csymbol><ci id="S3.E2Xa.2.1.1.m1.9.9.1.1.1.2.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.1.1.1.2">ğ‘—</ci></apply><ci id="S3.E2Xa.2.1.1.m1.7.7.cmml" xref="S3.E2Xa.2.1.1.m1.7.7">ğ‘˜</ci><ci id="S3.E2Xa.2.1.1.m1.8.8.cmml" xref="S3.E2Xa.2.1.1.m1.8.8">ğ‘™</ci></list><apply id="S3.E2Xa.2.1.1.m1.9.9.3.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.3"><times id="S3.E2Xa.2.1.1.m1.9.9.3.1.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.3.1"></times><interval closure="closed-open" id="S3.E2Xa.2.1.1.m1.9.9.3.2.1.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.3.2.2"><cn type="integer" id="S3.E2Xa.2.1.1.m1.1.1.cmml" xref="S3.E2Xa.2.1.1.m1.1.1">0</cn><ci id="S3.E2Xa.2.1.1.m1.2.2.cmml" xref="S3.E2Xa.2.1.1.m1.2.2">ğ‘¤</ci></interval><interval closure="closed-open" id="S3.E2Xa.2.1.1.m1.9.9.3.3.1.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.3.3.2"><cn type="integer" id="S3.E2Xa.2.1.1.m1.3.3.cmml" xref="S3.E2Xa.2.1.1.m1.3.3">0</cn><ci id="S3.E2Xa.2.1.1.m1.4.4.cmml" xref="S3.E2Xa.2.1.1.m1.4.4">â„</ci></interval><interval closure="closed-open" id="S3.E2Xa.2.1.1.m1.9.9.3.4.1.cmml" xref="S3.E2Xa.2.1.1.m1.9.9.3.4.2"><cn type="integer" id="S3.E2Xa.2.1.1.m1.5.5.cmml" xref="S3.E2Xa.2.1.1.m1.5.5">0</cn><ci id="S3.E2Xa.2.1.1.m1.6.6.cmml" xref="S3.E2Xa.2.1.1.m1.6.6">ğ‘‘</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2Xa.2.1.1.m1.9c">\displaystyle\,\small{\forall j,k,l\in[0,w)\times[0,h)\times[0,d)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S3.SS2.p3.14" class="ltx_p">where <math id="S3.SS2.p3.10.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.SS2.p3.10.m1.1a"><mi id="S3.SS2.p3.10.m1.1.1" xref="S3.SS2.p3.10.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m1.1b"><ci id="S3.SS2.p3.10.m1.1.1.cmml" xref="S3.SS2.p3.10.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m1.1c">w</annotation></semantics></math>, <math id="S3.SS2.p3.11.m2.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S3.SS2.p3.11.m2.1a"><mi id="S3.SS2.p3.11.m2.1.1" xref="S3.SS2.p3.11.m2.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m2.1b"><ci id="S3.SS2.p3.11.m2.1.1.cmml" xref="S3.SS2.p3.11.m2.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m2.1c">h</annotation></semantics></math>, and <math id="S3.SS2.p3.12.m3.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.p3.12.m3.1a"><mi id="S3.SS2.p3.12.m3.1.1" xref="S3.SS2.p3.12.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m3.1b"><ci id="S3.SS2.p3.12.m3.1.1.cmml" xref="S3.SS2.p3.12.m3.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m3.1c">d</annotation></semantics></math> are the width, height, and depth of the space on which the 3D cone is computed, and <math id="S3.SS2.p3.13.m4.1" class="ltx_Math" alttext="\mathbf{v}^{i}_{H}" display="inline"><semantics id="S3.SS2.p3.13.m4.1a"><msubsup id="S3.SS2.p3.13.m4.1.1" xref="S3.SS2.p3.13.m4.1.1.cmml"><mi id="S3.SS2.p3.13.m4.1.1.2.2" xref="S3.SS2.p3.13.m4.1.1.2.2.cmml">ğ¯</mi><mi id="S3.SS2.p3.13.m4.1.1.3" xref="S3.SS2.p3.13.m4.1.1.3.cmml">H</mi><mi id="S3.SS2.p3.13.m4.1.1.2.3" xref="S3.SS2.p3.13.m4.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.13.m4.1b"><apply id="S3.SS2.p3.13.m4.1.1.cmml" xref="S3.SS2.p3.13.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.13.m4.1.1.1.cmml" xref="S3.SS2.p3.13.m4.1.1">subscript</csymbol><apply id="S3.SS2.p3.13.m4.1.1.2.cmml" xref="S3.SS2.p3.13.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.13.m4.1.1.2.1.cmml" xref="S3.SS2.p3.13.m4.1.1">superscript</csymbol><ci id="S3.SS2.p3.13.m4.1.1.2.2.cmml" xref="S3.SS2.p3.13.m4.1.1.2.2">ğ¯</ci><ci id="S3.SS2.p3.13.m4.1.1.2.3.cmml" xref="S3.SS2.p3.13.m4.1.1.2.3">ğ‘–</ci></apply><ci id="S3.SS2.p3.13.m4.1.1.3.cmml" xref="S3.SS2.p3.13.m4.1.1.3">ğ»</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.13.m4.1c">\mathbf{v}^{i}_{H}</annotation></semantics></math> indicates the vectors in the discretized space starting from <math id="S3.SS2.p3.14.m5.3" class="ltx_Math" alttext="(c_{x}^{i},c_{y}^{i},c_{z}^{i})" display="inline"><semantics id="S3.SS2.p3.14.m5.3a"><mrow id="S3.SS2.p3.14.m5.3.3.3" xref="S3.SS2.p3.14.m5.3.3.4.cmml"><mo stretchy="false" id="S3.SS2.p3.14.m5.3.3.3.4" xref="S3.SS2.p3.14.m5.3.3.4.cmml">(</mo><msubsup id="S3.SS2.p3.14.m5.1.1.1.1" xref="S3.SS2.p3.14.m5.1.1.1.1.cmml"><mi id="S3.SS2.p3.14.m5.1.1.1.1.2.2" xref="S3.SS2.p3.14.m5.1.1.1.1.2.2.cmml">c</mi><mi id="S3.SS2.p3.14.m5.1.1.1.1.2.3" xref="S3.SS2.p3.14.m5.1.1.1.1.2.3.cmml">x</mi><mi id="S3.SS2.p3.14.m5.1.1.1.1.3" xref="S3.SS2.p3.14.m5.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.SS2.p3.14.m5.3.3.3.5" xref="S3.SS2.p3.14.m5.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p3.14.m5.2.2.2.2" xref="S3.SS2.p3.14.m5.2.2.2.2.cmml"><mi id="S3.SS2.p3.14.m5.2.2.2.2.2.2" xref="S3.SS2.p3.14.m5.2.2.2.2.2.2.cmml">c</mi><mi id="S3.SS2.p3.14.m5.2.2.2.2.2.3" xref="S3.SS2.p3.14.m5.2.2.2.2.2.3.cmml">y</mi><mi id="S3.SS2.p3.14.m5.2.2.2.2.3" xref="S3.SS2.p3.14.m5.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S3.SS2.p3.14.m5.3.3.3.6" xref="S3.SS2.p3.14.m5.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p3.14.m5.3.3.3.3" xref="S3.SS2.p3.14.m5.3.3.3.3.cmml"><mi id="S3.SS2.p3.14.m5.3.3.3.3.2.2" xref="S3.SS2.p3.14.m5.3.3.3.3.2.2.cmml">c</mi><mi id="S3.SS2.p3.14.m5.3.3.3.3.2.3" xref="S3.SS2.p3.14.m5.3.3.3.3.2.3.cmml">z</mi><mi id="S3.SS2.p3.14.m5.3.3.3.3.3" xref="S3.SS2.p3.14.m5.3.3.3.3.3.cmml">i</mi></msubsup><mo stretchy="false" id="S3.SS2.p3.14.m5.3.3.3.7" xref="S3.SS2.p3.14.m5.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.14.m5.3b"><vector id="S3.SS2.p3.14.m5.3.3.4.cmml" xref="S3.SS2.p3.14.m5.3.3.3"><apply id="S3.SS2.p3.14.m5.1.1.1.1.cmml" xref="S3.SS2.p3.14.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.14.m5.1.1.1.1.1.cmml" xref="S3.SS2.p3.14.m5.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p3.14.m5.1.1.1.1.2.cmml" xref="S3.SS2.p3.14.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.14.m5.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.14.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.14.m5.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.14.m5.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p3.14.m5.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.14.m5.1.1.1.1.2.3">ğ‘¥</ci></apply><ci id="S3.SS2.p3.14.m5.1.1.1.1.3.cmml" xref="S3.SS2.p3.14.m5.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p3.14.m5.2.2.2.2.cmml" xref="S3.SS2.p3.14.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.14.m5.2.2.2.2.1.cmml" xref="S3.SS2.p3.14.m5.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p3.14.m5.2.2.2.2.2.cmml" xref="S3.SS2.p3.14.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.14.m5.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.14.m5.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.14.m5.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.14.m5.2.2.2.2.2.2">ğ‘</ci><ci id="S3.SS2.p3.14.m5.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.14.m5.2.2.2.2.2.3">ğ‘¦</ci></apply><ci id="S3.SS2.p3.14.m5.2.2.2.2.3.cmml" xref="S3.SS2.p3.14.m5.2.2.2.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p3.14.m5.3.3.3.3.cmml" xref="S3.SS2.p3.14.m5.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.14.m5.3.3.3.3.1.cmml" xref="S3.SS2.p3.14.m5.3.3.3.3">superscript</csymbol><apply id="S3.SS2.p3.14.m5.3.3.3.3.2.cmml" xref="S3.SS2.p3.14.m5.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.14.m5.3.3.3.3.2.1.cmml" xref="S3.SS2.p3.14.m5.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p3.14.m5.3.3.3.3.2.2.cmml" xref="S3.SS2.p3.14.m5.3.3.3.3.2.2">ğ‘</ci><ci id="S3.SS2.p3.14.m5.3.3.3.3.2.3.cmml" xref="S3.SS2.p3.14.m5.3.3.3.3.2.3">ğ‘§</ci></apply><ci id="S3.SS2.p3.14.m5.3.3.3.3.3.cmml" xref="S3.SS2.p3.14.m5.3.3.3.3.3">ğ‘–</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.14.m5.3c">(c_{x}^{i},c_{y}^{i},c_{z}^{i})</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.7" class="ltx_p">The set of 3D cones <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\mathbf{CD}_{3D}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><msub id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">ğ‚ğƒ</mi><mrow id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml"><mn id="S3.SS2.p4.1.m1.1.1.3.2" xref="S3.SS2.p4.1.m1.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.3.1" xref="S3.SS2.p4.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.1.m1.1.1.3.3" xref="S3.SS2.p4.1.m1.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">ğ‚ğƒ</ci><apply id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3"><times id="S3.SS2.p4.1.m1.1.1.3.1.cmml" xref="S3.SS2.p4.1.m1.1.1.3.1"></times><cn type="integer" id="S3.SS2.p4.1.m1.1.1.3.2.cmml" xref="S3.SS2.p4.1.m1.1.1.3.2">3</cn><ci id="S3.SS2.p4.1.m1.1.1.3.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\mathbf{CD}_{3D}</annotation></semantics></math> allows us to define the <span id="S3.SS2.p4.7.1" class="ltx_text ltx_font_italic">object score</span> as a square matrix <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><mi mathvariant="normal" id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">\Sigma</annotation></semantics></math> of size <math id="S3.SS2.p4.3.m3.1" class="ltx_Math" alttext="N\times N" display="inline"><semantics id="S3.SS2.p4.3.m3.1a"><mrow id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.p4.3.m3.1.1.2" xref="S3.SS2.p4.3.m3.1.1.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p4.3.m3.1.1.1" xref="S3.SS2.p4.3.m3.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.p4.3.m3.1.1.3" xref="S3.SS2.p4.3.m3.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><apply id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1"><times id="S3.SS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1.1"></times><ci id="S3.SS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.p4.3.m3.1.1.2">ğ‘</ci><ci id="S3.SS2.p4.3.m3.1.1.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">N\times N</annotation></semantics></math>, where <math id="S3.SS2.p4.4.m4.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p4.4.m4.1a"><mi id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><ci id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">N</annotation></semantics></math> is the number of objects detected by the Object Detector Transformer.
The object score matrix represents whether an object is in the visual cone of each person and how close it is to their predicted gaze vector (see Fig.Â <a href="#S3.F3" title="Figure 3 â€£ 3.1 Object Detector Transformer â€£ 3 Method â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>d).
Each row represents an object where the rows of objects not classified as heads are zero.
For rows of <span id="S3.SS2.p4.7.2" class="ltx_text ltx_font_italic">head</span> objects, the score for each other object is equivalent to the value of the gaze cone picked at the center coordinates of the object.
When no object is in the gaze cone, the corresponding row becomes zero, and then we exploit the <span id="S3.SS2.p4.7.3" class="ltx_text ltx_font_italic">no cone-object</span> skip to compute the gaze heatmap. The <span id="S3.SS2.p4.7.4" class="ltx_text ltx_font_italic">object score</span> matrix <math id="S3.SS2.p4.5.m5.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS2.p4.5.m5.1a"><mi mathvariant="normal" id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><ci id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">\Sigma</annotation></semantics></math> is used by <math id="S3.SS2.p4.6.m6.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S3.SS2.p4.6.m6.1a"><mrow id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.6.m6.1.1.2" xref="S3.SS2.p4.6.m6.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.6.m6.1.1.1" xref="S3.SS2.p4.6.m6.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.6.m6.1.1.3" xref="S3.SS2.p4.6.m6.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.6.m6.1.1.1a" xref="S3.SS2.p4.6.m6.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.6.m6.1.1.4" xref="S3.SS2.p4.6.m6.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><apply id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1"><times id="S3.SS2.p4.6.m6.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1"></times><ci id="S3.SS2.p4.6.m6.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.2">ğ’¢</ci><ci id="S3.SS2.p4.6.m6.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.3">ğ’ª</ci><ci id="S3.SS2.p4.6.m6.1.1.4.cmml" xref="S3.SS2.p4.6.m6.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">\mathcal{GOT}\,</annotation></semantics></math>as an additive bias in the attention module. The rationale behind the score matrix <math id="S3.SS2.p4.7.m7.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS2.p4.7.m7.1a"><mi mathvariant="normal" id="S3.SS2.p4.7.m7.1.1" xref="S3.SS2.p4.7.m7.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m7.1b"><ci id="S3.SS2.p4.7.m7.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m7.1c">\Sigma</annotation></semantics></math> is to exploit the strong prior coming from the gaze vector and constrain the network to focus on relevant objects in the scene.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<div id="S3.T2.12.12" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:411.9pt;height:223.7pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-148.0pt,80.1pt) scale(0.581962239335459,0.581962239335459) ;">
<table id="S3.T2.12.12.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.12.12.12.13.1" class="ltx_tr">
<th id="S3.T2.12.12.12.13.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S3.T2.12.12.12.13.1.1.1" class="ltx_text">Method</span></th>
<td id="S3.T2.12.12.12.13.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T2.12.12.12.13.1.2.1" class="ltx_text">Modalities</span></td>
<td id="S3.T2.12.12.12.13.1.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T2.12.12.12.13.1.3.1" class="ltx_text">
<span id="S3.T2.12.12.12.13.1.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.12.12.12.13.1.3.1.1.1" class="ltx_tr">
<span id="S3.T2.12.12.12.13.1.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Multiperson</span></span>
<span id="S3.T2.12.12.12.13.1.3.1.1.2" class="ltx_tr">
<span id="S3.T2.12.12.12.13.1.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Gaze</span></span>
</span></span></td>
<td id="S3.T2.12.12.12.13.1.4" class="ltx_td ltx_align_center ltx_border_t" colspan="3">
<table id="S3.T2.12.12.12.13.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.12.12.12.13.1.4.1.1" class="ltx_tr">
<td id="S3.T2.12.12.12.13.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
</td>
</tr>
</table>
</td>
<td id="S3.T2.12.12.12.13.1.5" class="ltx_td ltx_align_center ltx_border_t" colspan="3">
<table id="S3.T2.12.12.12.13.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.12.12.12.13.1.5.1.1" class="ltx_tr">
<td id="S3.T2.12.12.12.13.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">VideoAttentionTarget <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T2.1.1.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1.2" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" colspan="2">Distance <math id="S3.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T2.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T2.1.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S3.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S3.T2.1.1.1.1.3.1" class="ltx_text ltx_font_italic">In frame</span></td>
<td id="S3.T2.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.1.1.1.1.4.1" class="ltx_text ltx_font_italic">Out of frame</span></td>
</tr>
<tr id="S3.T2.5.5.5.5" class="ltx_tr">
<td id="S3.T2.2.2.2.2.1" class="ltx_td ltx_align_center">AUC <math id="S3.T2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S3.T2.2.2.2.2.1.m1.1.1" xref="S3.T2.2.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.2.1.m1.1b"><ci id="S3.T2.2.2.2.2.1.m1.1.1.cmml" xref="S3.T2.2.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S3.T2.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">Avg.</td>
<td id="S3.T2.5.5.5.5.6" class="ltx_td ltx_align_center ltx_border_t">Min.</td>
<td id="S3.T2.3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t">AUC <math id="S3.T2.3.3.3.3.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.3.3.3.3.2.m1.1a"><mo stretchy="false" id="S3.T2.3.3.3.3.2.m1.1.1" xref="S3.T2.3.3.3.3.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.3.2.m1.1b"><ci id="S3.T2.3.3.3.3.2.m1.1.1.cmml" xref="S3.T2.3.3.3.3.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.3.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S3.T2.4.4.4.4.3" class="ltx_td ltx_align_center ltx_border_t">Dist. <math id="S3.T2.4.4.4.4.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T2.4.4.4.4.3.m1.1a"><mo stretchy="false" id="S3.T2.4.4.4.4.3.m1.1.1" xref="S3.T2.4.4.4.4.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.4.3.m1.1b"><ci id="S3.T2.4.4.4.4.3.m1.1.1.cmml" xref="S3.T2.4.4.4.4.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.4.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S3.T2.5.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t">AP <math id="S3.T2.5.5.5.5.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.5.5.5.5.4.m1.1a"><mo stretchy="false" id="S3.T2.5.5.5.5.4.m1.1.1" xref="S3.T2.5.5.5.5.4.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.5.4.m1.1b"><ci id="S3.T2.5.5.5.5.4.m1.1.1.cmml" xref="S3.T2.5.5.5.5.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.5.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T2.11.11.11.11" class="ltx_tr">
<th id="S3.T2.11.11.11.11.7" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S3.T2.11.11.11.11.8" class="ltx_td"></td>
<td id="S3.T2.11.11.11.11.9" class="ltx_td"></td>
<td id="S3.T2.6.6.6.6.1" class="ltx_td ltx_align_center">
<span id="S3.T2.6.6.6.6.1.2" class="ltx_text ltx_font_italic">Head</span> <span id="S3.T2.6.6.6.6.1.1" class="ltx_text ltx_font_italic">Real<sup id="S3.T2.6.6.6.6.1.1.1" class="ltx_sup"><span id="S3.T2.6.6.6.6.1.1.1.1" class="ltx_text ltx_font_upright">â€ </span></sup></span>
</td>
<td id="S3.T2.7.7.7.7.2" class="ltx_td ltx_align_center">
<span id="S3.T2.7.7.7.7.2.2" class="ltx_text ltx_font_italic">Head</span> <span id="S3.T2.7.7.7.7.2.1" class="ltx_text ltx_font_italic">Real<sup id="S3.T2.7.7.7.7.2.1.1" class="ltx_sup"><span id="S3.T2.7.7.7.7.2.1.1.1" class="ltx_text ltx_font_upright">â€ </span></sup></span>
</td>
<td id="S3.T2.8.8.8.8.3" class="ltx_td ltx_align_center">
<span id="S3.T2.8.8.8.8.3.2" class="ltx_text ltx_font_italic">Head</span> <span id="S3.T2.8.8.8.8.3.1" class="ltx_text ltx_font_italic">Real<sup id="S3.T2.8.8.8.8.3.1.1" class="ltx_sup"><span id="S3.T2.8.8.8.8.3.1.1.1" class="ltx_text ltx_font_upright">â€ </span></sup></span>
</td>
<td id="S3.T2.9.9.9.9.4" class="ltx_td ltx_align_center">
<span id="S3.T2.9.9.9.9.4.2" class="ltx_text ltx_font_italic">Head</span> <span id="S3.T2.9.9.9.9.4.1" class="ltx_text ltx_font_italic">Real<sup id="S3.T2.9.9.9.9.4.1.1" class="ltx_sup"><span id="S3.T2.9.9.9.9.4.1.1.1" class="ltx_text ltx_font_upright">â€ </span></sup></span>
</td>
<td id="S3.T2.10.10.10.10.5" class="ltx_td ltx_align_center">
<span id="S3.T2.10.10.10.10.5.2" class="ltx_text ltx_font_italic">Head</span> <span id="S3.T2.10.10.10.10.5.1" class="ltx_text ltx_font_italic">Real<sup id="S3.T2.10.10.10.10.5.1.1" class="ltx_sup"><span id="S3.T2.10.10.10.10.5.1.1.1" class="ltx_text ltx_font_upright">â€ </span></sup></span>
</td>
<td id="S3.T2.11.11.11.11.6" class="ltx_td ltx_align_center">
<span id="S3.T2.11.11.11.11.6.2" class="ltx_text ltx_font_italic">Head</span> <span id="S3.T2.11.11.11.11.6.1" class="ltx_text ltx_font_italic">Real<sup id="S3.T2.11.11.11.11.6.1.1" class="ltx_sup"><span id="S3.T2.11.11.11.11.6.1.1.1" class="ltx_text ltx_font_upright">â€ </span></sup></span>
</td>
</tr>
<tr id="S3.T2.12.12.12.14.2" class="ltx_tr">
<th id="S3.T2.12.12.12.14.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S3.T2.12.12.12.14.2.2" class="ltx_td"></td>
<td id="S3.T2.12.12.12.14.2.3" class="ltx_td"></td>
<td id="S3.T2.12.12.12.14.2.4" class="ltx_td ltx_align_center">Â Â <span id="S3.T2.12.12.12.14.2.4.1" class="ltx_text ltx_font_italic">GT</span>
</td>
<td id="S3.T2.12.12.12.14.2.5" class="ltx_td ltx_align_center">Â Â <span id="S3.T2.12.12.12.14.2.5.1" class="ltx_text ltx_font_italic">GT</span>
</td>
<td id="S3.T2.12.12.12.14.2.6" class="ltx_td ltx_align_center">Â Â <span id="S3.T2.12.12.12.14.2.6.1" class="ltx_text ltx_font_italic">GT</span>
</td>
<td id="S3.T2.12.12.12.14.2.7" class="ltx_td ltx_align_center">Â Â <span id="S3.T2.12.12.12.14.2.7.1" class="ltx_text ltx_font_italic">GT</span>
</td>
<td id="S3.T2.12.12.12.14.2.8" class="ltx_td ltx_align_center">Â Â <span id="S3.T2.12.12.12.14.2.8.1" class="ltx_text ltx_font_italic">GT</span>
</td>
<td id="S3.T2.12.12.12.14.2.9" class="ltx_td ltx_align_center">Â Â <span id="S3.T2.12.12.12.14.2.9.1" class="ltx_text ltx_font_italic">GT</span>
</td>
</tr>
<tr id="S3.T2.12.12.12.15.3" class="ltx_tr">
<th id="S3.T2.12.12.12.15.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Random</th>
<td id="S3.T2.12.12.12.15.3.2" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.12.12.12.15.3.3" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.12.12.12.15.3.4" class="ltx_td ltx_align_center ltx_border_t">0.504Â Â 0.391</td>
<td id="S3.T2.12.12.12.15.3.5" class="ltx_td ltx_align_center ltx_border_t">0.484Â Â 0.533</td>
<td id="S3.T2.12.12.12.15.3.6" class="ltx_td ltx_align_center ltx_border_t">0.391Â Â 0.487</td>
<td id="S3.T2.12.12.12.15.3.7" class="ltx_td ltx_align_center ltx_border_t">0.505Â Â 0.247</td>
<td id="S3.T2.12.12.12.15.3.8" class="ltx_td ltx_align_center ltx_border_t">0.458Â Â 0.592</td>
<td id="S3.T2.12.12.12.15.3.9" class="ltx_td ltx_align_center ltx_border_t">0.621Â Â 0.349</td>
</tr>
<tr id="S3.T2.12.12.12.16.4" class="ltx_tr">
<th id="S3.T2.12.12.12.16.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Center</th>
<td id="S3.T2.12.12.12.16.4.2" class="ltx_td"></td>
<td id="S3.T2.12.12.12.16.4.3" class="ltx_td"></td>
<td id="S3.T2.12.12.12.16.4.4" class="ltx_td ltx_align_center">0.633Â Â 0.446</td>
<td id="S3.T2.12.12.12.16.4.5" class="ltx_td ltx_align_center">0.313Â Â 0.495</td>
<td id="S3.T2.12.12.12.16.4.6" class="ltx_td ltx_align_center">0.230Â Â 0.371</td>
<td id="S3.T2.12.12.12.16.4.7" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
<td id="S3.T2.12.12.12.16.4.8" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
<td id="S3.T2.12.12.12.16.4.9" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
</tr>
<tr id="S3.T2.12.12.12.17.5" class="ltx_tr">
<th id="S3.T2.12.12.12.17.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Fixed bias</th>
<td id="S3.T2.12.12.12.17.5.2" class="ltx_td"></td>
<td id="S3.T2.12.12.12.17.5.3" class="ltx_td"></td>
<td id="S3.T2.12.12.12.17.5.4" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
<td id="S3.T2.12.12.12.17.5.5" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
<td id="S3.T2.12.12.12.17.5.6" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
<td id="S3.T2.12.12.12.17.5.7" class="ltx_td ltx_align_center">0.728Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.17.5.8" class="ltx_td ltx_align_center">0.326Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.17.5.9" class="ltx_td ltx_align_center">0.624Â Â Â Â Â -</td>
</tr>
<tr id="S3.T2.12.12.12.18.6" class="ltx_tr">
<th id="S3.T2.12.12.12.18.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Recasens et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
</th>
<td id="S3.T2.12.12.12.18.6.2" class="ltx_td ltx_align_center">R</td>
<td id="S3.T2.12.12.12.18.6.3" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.18.6.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S3.T2.12.12.12.18.6.4" class="ltx_td ltx_align_center">0.878Â Â 0.804</td>
<td id="S3.T2.12.12.12.18.6.5" class="ltx_td ltx_align_center">0.190Â Â 0.233</td>
<td id="S3.T2.12.12.12.18.6.6" class="ltx_td ltx_align_center">0.113Â Â 0.124</td>
<td id="S3.T2.12.12.12.18.6.7" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
<td id="S3.T2.12.12.12.18.6.8" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
<td id="S3.T2.12.12.12.18.6.9" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
</tr>
<tr id="S3.T2.12.12.12.19.7" class="ltx_tr">
<th id="S3.T2.12.12.12.19.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Chong et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</th>
<td id="S3.T2.12.12.12.19.7.2" class="ltx_td ltx_align_center">R</td>
<td id="S3.T2.12.12.12.19.7.3" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.19.7.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S3.T2.12.12.12.19.7.4" class="ltx_td ltx_align_center">0.896Â Â 0.807</td>
<td id="S3.T2.12.12.12.19.7.5" class="ltx_td ltx_align_center">0.187Â Â 0.207</td>
<td id="S3.T2.12.12.12.19.7.6" class="ltx_td ltx_align_center">0.112Â Â 0.120</td>
<td id="S3.T2.12.12.12.19.7.7" class="ltx_td ltx_align_center">0.830Â Â 0.791</td>
<td id="S3.T2.12.12.12.19.7.8" class="ltx_td ltx_align_center">0.193Â Â 0.214</td>
<td id="S3.T2.12.12.12.19.7.9" class="ltx_td ltx_align_center">0.705Â Â 0.651</td>
</tr>
<tr id="S3.T2.12.12.12.20.8" class="ltx_tr">
<th id="S3.T2.12.12.12.20.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Lian et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</th>
<td id="S3.T2.12.12.12.20.8.2" class="ltx_td ltx_align_center">R</td>
<td id="S3.T2.12.12.12.20.8.3" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.20.8.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S3.T2.12.12.12.20.8.4" class="ltx_td ltx_align_center">0.906Â Â 0.881</td>
<td id="S3.T2.12.12.12.20.8.5" class="ltx_td ltx_align_center">0.145Â Â 0.153</td>
<td id="S3.T2.12.12.12.20.8.6" class="ltx_td ltx_align_center">0.081Â Â 0.087</td>
<td id="S3.T2.12.12.12.20.8.7" class="ltx_td ltx_align_center">0.837Â Â 0.784</td>
<td id="S3.T2.12.12.12.20.8.8" class="ltx_td ltx_align_center">0.165Â Â 0.172</td>
<td id="S3.T2.12.12.12.20.8.9" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
</tr>
<tr id="S3.T2.12.12.12.21.9" class="ltx_tr">
<th id="S3.T2.12.12.12.21.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Chong et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</th>
<td id="S3.T2.12.12.12.21.9.2" class="ltx_td ltx_align_center">R + T</td>
<td id="S3.T2.12.12.12.21.9.3" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.21.9.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S3.T2.12.12.12.21.9.4" class="ltx_td ltx_align_center">0.921Â Â 0.902</td>
<td id="S3.T2.12.12.12.21.9.5" class="ltx_td ltx_align_center">0.137Â Â 0.142</td>
<td id="S3.T2.12.12.12.21.9.6" class="ltx_td ltx_align_center">0.077Â Â 0.082</td>
<td id="S3.T2.12.12.12.21.9.7" class="ltx_td ltx_align_center">0.860Â Â 0.812</td>
<td id="S3.T2.12.12.12.21.9.8" class="ltx_td ltx_align_center">0.134Â Â 0.146</td>
<td id="S3.T2.12.12.12.21.9.9" class="ltx_td ltx_align_center">0.853Â Â 0.849</td>
</tr>
<tr id="S3.T2.12.12.12.22.10" class="ltx_tr">
<th id="S3.T2.12.12.12.22.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Fang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</th>
<td id="S3.T2.12.12.12.22.10.2" class="ltx_td ltx_align_center">R + D</td>
<td id="S3.T2.12.12.12.22.10.3" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.22.10.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S3.T2.12.12.12.22.10.4" class="ltx_td ltx_align_center">0.922Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.22.10.5" class="ltx_td ltx_align_center">0,124Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.22.10.6" class="ltx_td ltx_align_center">0.067Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.22.10.7" class="ltx_td ltx_align_center">0.905Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.22.10.8" class="ltx_td ltx_align_center">0.108Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.22.10.9" class="ltx_td ltx_align_center">0.896Â Â Â Â Â -</td>
</tr>
<tr id="S3.T2.12.12.12.23.11" class="ltx_tr">
<th id="S3.T2.12.12.12.23.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Bao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</th>
<td id="S3.T2.12.12.12.23.11.2" class="ltx_td ltx_align_center">R + D + P</td>
<td id="S3.T2.12.12.12.23.11.3" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.23.11.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S3.T2.12.12.12.23.11.4" class="ltx_td ltx_align_center">0.928Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.23.11.5" class="ltx_td ltx_align_center">0.122Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.23.11.6" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
<td id="S3.T2.12.12.12.23.11.7" class="ltx_td ltx_align_center">0.885Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.23.11.8" class="ltx_td ltx_align_center">0.120Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.23.11.9" class="ltx_td ltx_align_center">0.869Â Â Â Â Â -</td>
</tr>
<tr id="S3.T2.12.12.12.24.12" class="ltx_tr">
<th id="S3.T2.12.12.12.24.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Jin et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>
</th>
<td id="S3.T2.12.12.12.24.12.2" class="ltx_td ltx_align_center">R + D</td>
<td id="S3.T2.12.12.12.24.12.3" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.24.12.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S3.T2.12.12.12.24.12.4" class="ltx_td ltx_align_center">0.920Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.24.12.5" class="ltx_td ltx_align_center">0.118Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.24.12.6" class="ltx_td ltx_align_center">0.063Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.24.12.7" class="ltx_td ltx_align_center">0.900Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.24.12.8" class="ltx_td ltx_align_center">0.104Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.24.12.9" class="ltx_td ltx_align_center">0.895Â Â Â Â Â -</td>
</tr>
<tr id="S3.T2.12.12.12.25.13" class="ltx_tr">
<th id="S3.T2.12.12.12.25.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Tonini et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>
</th>
<td id="S3.T2.12.12.12.25.13.2" class="ltx_td ltx_align_center">R + D</td>
<td id="S3.T2.12.12.12.25.13.3" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.25.13.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S3.T2.12.12.12.25.13.4" class="ltx_td ltx_align_center">0.927Â Â 0.894</td>
<td id="S3.T2.12.12.12.25.13.5" class="ltx_td ltx_align_center">0.141Â Â 0.165</td>
<td id="S3.T2.12.12.12.25.13.6" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
<td id="S3.T2.12.12.12.25.13.7" class="ltx_td ltx_align_center">0.940Â Â 0.894</td>
<td id="S3.T2.12.12.12.25.13.8" class="ltx_td ltx_align_center">0.129Â Â 0.182</td>
<td id="S3.T2.12.12.12.25.13.9" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  -</td>
</tr>
<tr id="S3.T2.12.12.12.26.14" class="ltx_tr">
<th id="S3.T2.12.12.12.26.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Qiaomu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</th>
<td id="S3.T2.12.12.12.26.14.2" class="ltx_td ltx_align_center">R + D + T</td>
<td id="S3.T2.12.12.12.26.14.3" class="ltx_td ltx_align_center"><span id="S3.T2.12.12.12.26.14.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S3.T2.12.12.12.26.14.4" class="ltx_td ltx_align_center">0.934Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.26.14.5" class="ltx_td ltx_align_center">0.123Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.26.14.6" class="ltx_td ltx_align_center">0.065Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.26.14.7" class="ltx_td ltx_align_center">0.917Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.26.14.8" class="ltx_td ltx_align_center">0.109Â Â Â Â Â -</td>
<td id="S3.T2.12.12.12.26.14.9" class="ltx_td ltx_align_center">0.908Â Â Â Â Â -</td>
</tr>
<tr id="S3.T2.12.12.12.27.15" class="ltx_tr">
<th id="S3.T2.12.12.12.27.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</th>
<td id="S3.T2.12.12.12.27.15.2" class="ltx_td ltx_align_center">R</td>
<td id="S3.T2.12.12.12.27.15.3" class="ltx_td ltx_align_center">âœ“</td>
<td id="S3.T2.12.12.12.27.15.4" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.917</td>
<td id="S3.T2.12.12.12.27.15.5" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.133</td>
<td id="S3.T2.12.12.12.27.15.6" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.069</td>
<td id="S3.T2.12.12.12.27.15.7" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.904</td>
<td id="S3.T2.12.12.12.27.15.8" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.126</td>
<td id="S3.T2.12.12.12.27.15.9" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.854</td>
</tr>
<tr id="S3.T2.12.12.12.12" class="ltx_tr">
<th id="S3.T2.12.12.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite><sup id="S3.T2.12.12.12.12.1.1" class="ltx_sup">â‹†</sup>
</th>
<td id="S3.T2.12.12.12.12.2" class="ltx_td ltx_align_center">R</td>
<td id="S3.T2.12.12.12.12.3" class="ltx_td ltx_align_center">âœ“</td>
<td id="S3.T2.12.12.12.12.4" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.915</td>
<td id="S3.T2.12.12.12.12.5" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.104</td>
<td id="S3.T2.12.12.12.12.6" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.055</td>
<td id="S3.T2.12.12.12.12.7" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.891</td>
<td id="S3.T2.12.12.12.12.8" class="ltx_td ltx_align_center">Â Â Â -Â Â Â Â Â 0.229</td>
<td id="S3.T2.12.12.12.12.9" class="ltx_td ltx_align_center">-Â Â Â Â Â Â  0.809</td>
</tr>
<tr id="S3.T2.12.12.12.28.16" class="ltx_tr" style="background-color:#CAF0F8;">
<th id="S3.T2.12.12.12.28.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S3.T2.12.12.12.28.16.1.1" class="ltx_text" style="background-color:#CAF0F8;">Our method</span></th>
<td id="S3.T2.12.12.12.28.16.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.12.12.12.28.16.2.1" class="ltx_text" style="background-color:#CAF0F8;">R</span></td>
<td id="S3.T2.12.12.12.28.16.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.12.12.12.28.16.3.1" class="ltx_text" style="background-color:#CAF0F8;">âœ“</span></td>
<td id="S3.T2.12.12.12.28.16.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.12.12.12.28.16.4.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â <span id="S3.T2.12.12.12.28.16.4.1.1" class="ltx_text ltx_font_bold">0.922</span></span></td>
<td id="S3.T2.12.12.12.28.16.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.12.12.12.28.16.5.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â 0.072</span></td>
<td id="S3.T2.12.12.12.28.16.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.12.12.12.28.16.6.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â 0.033</span></td>
<td id="S3.T2.12.12.12.28.16.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.12.12.12.28.16.7.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â 0.923</span></td>
<td id="S3.T2.12.12.12.28.16.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.12.12.12.28.16.8.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â <span id="S3.T2.12.12.12.28.16.8.1.1" class="ltx_text ltx_font_bold">0.102</span></span></td>
<td id="S3.T2.12.12.12.28.16.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.12.12.12.28.16.9.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â <span id="S3.T2.12.12.12.28.16.9.1.1" class="ltx_text ltx_font_bold">0.944</span></span></td>
</tr>
<tr id="S3.T2.12.12.12.29.17" class="ltx_tr" style="background-color:#CAF0F8;">
<th id="S3.T2.12.12.12.29.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b"><span id="S3.T2.12.12.12.29.17.1.1" class="ltx_text" style="background-color:#CAF0F8;">Our method</span></th>
<td id="S3.T2.12.12.12.29.17.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T2.12.12.12.29.17.2.1" class="ltx_text" style="background-color:#CAF0F8;">R + D</span></td>
<td id="S3.T2.12.12.12.29.17.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T2.12.12.12.29.17.3.1" class="ltx_text" style="background-color:#CAF0F8;">âœ“</span></td>
<td id="S3.T2.12.12.12.29.17.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T2.12.12.12.29.17.4.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â <span id="S3.T2.12.12.12.29.17.4.1.1" class="ltx_text ltx_font_bold">0.922</span></span></td>
<td id="S3.T2.12.12.12.29.17.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T2.12.12.12.29.17.5.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â <span id="S3.T2.12.12.12.29.17.5.1.1" class="ltx_text ltx_font_bold">0.069</span></span></td>
<td id="S3.T2.12.12.12.29.17.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T2.12.12.12.29.17.6.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â <span id="S3.T2.12.12.12.29.17.6.1.1" class="ltx_text ltx_font_bold">0.029</span></span></td>
<td id="S3.T2.12.12.12.29.17.7" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T2.12.12.12.29.17.7.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â <span id="S3.T2.12.12.12.29.17.7.1.1" class="ltx_text ltx_font_bold">0.933</span></span></td>
<td id="S3.T2.12.12.12.29.17.8" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T2.12.12.12.29.17.8.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â 0.104</span></td>
<td id="S3.T2.12.12.12.29.17.9" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T2.12.12.12.29.17.9.1" class="ltx_text" style="background-color:#CAF0F8;">Â Â Â -Â Â Â Â Â 0.934</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Evaluation on the GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and VideoAttentionTarget <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> datasets. <span id="S3.T2.30.1" class="ltx_text ltx_font_italic">Head GT</span> refers to using carefully labeled ground-truth head crops and head locations in training and testing. <span id="S3.T2.31.2" class="ltx_text ltx_font_italic">Real</span> indicated with <sup id="S3.T2.32.3" class="ltx_sup">â€ </sup> is the implementation of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, which applies an additional SOTA head detection network to predict the head location for real-world applications. We produce only <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>â€™s <span id="S3.T2.33.4" class="ltx_text ltx_font_italic">Real</span> results (see text for details).
<sup id="S3.T2.34.5" class="ltx_sup">â‹†</sup> indicates our implementation. <math id="S3.T2.21.21.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.T2.21.21.m3.1b"><mi id="S3.T2.21.21.m3.1.1" xref="S3.T2.21.21.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.T2.21.21.m3.1c"><ci id="S3.T2.21.21.m3.1.1.cmml" xref="S3.T2.21.21.m3.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.21.21.m3.1d">R</annotation></semantics></math>, <math id="S3.T2.22.22.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.T2.22.22.m4.1b"><mi id="S3.T2.22.22.m4.1.1" xref="S3.T2.22.22.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.T2.22.22.m4.1c"><ci id="S3.T2.22.22.m4.1.1.cmml" xref="S3.T2.22.22.m4.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.22.22.m4.1d">D</annotation></semantics></math>, <math id="S3.T2.23.23.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.T2.23.23.m5.1b"><mi id="S3.T2.23.23.m5.1.1" xref="S3.T2.23.23.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.T2.23.23.m5.1c"><ci id="S3.T2.23.23.m5.1.1.cmml" xref="S3.T2.23.23.m5.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.23.23.m5.1d">T</annotation></semantics></math>, and <math id="S3.T2.24.24.m6.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.T2.24.24.m6.1b"><mi id="S3.T2.24.24.m6.1.1" xref="S3.T2.24.24.m6.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.T2.24.24.m6.1c"><ci id="S3.T2.24.24.m6.1.1.cmml" xref="S3.T2.24.24.m6.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.24.24.m6.1d">P</annotation></semantics></math> stand for RGB, depth, temporal processing, and 2D-pose, respectively. Refer to Supp. Mat. for Angular Error results.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Gaze Object Transformer</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.5" class="ltx_p">Although the information from the predicted gaze vector, cone, and <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi mathvariant="normal" id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\Sigma</annotation></semantics></math> provides important knowledge for the task at hand, accurately predicting the gaze direction is fundamentally a hard problem since the precise angle and magnitude of the vector are highly sensitive and might even introduce noise for the training procedure (see Sec.Â <a href="#S4.SS4" title="4.4 Ablation Study â€£ 4 Experiments â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a> for empirical justification). Eventually, an accurate vector estimation requires considering eye position and sight. However, such elements potentially introduce the need to use auxiliary networks, increasing the computational complexity of the overall architecture. Instead, our proposal is much simpler but effective as it does not use the gaze vector to predict the final heatmap, but we further process the output of <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\mathcal{D}</annotation></semantics></math> with the aid of the <span id="S3.SS3.p1.5.1" class="ltx_text ltx_font_italic">object score</span> matrix <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi mathvariant="normal" id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">\Sigma</annotation></semantics></math> in <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mrow id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1a" xref="S3.SS3.p1.4.m4.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.4.m4.1.1.4" xref="S3.SS3.p1.4.m4.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><times id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1"></times><ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">ğ’¢</ci><ci id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3">ğ’ª</ci><ci id="S3.SS3.p1.4.m4.1.1.4.cmml" xref="S3.SS3.p1.4.m4.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">\mathcal{GOT}\,</annotation></semantics></math>, which follows the same design principle as the decoder <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><ci id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">\mathcal{D}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.3" class="ltx_p">First, a stack of MHSA and FFN layers encodes a set of learnable embeddings <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{e}_{g}\in\mathbb{R}^{N\times C_{b}^{{}^{\prime}}}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mrow id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><msub id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2.2" xref="S3.SS3.p2.1.m1.1.1.2.2.cmml">ğ</mi><mi id="S3.SS3.p2.1.m1.1.1.2.3" xref="S3.SS3.p2.1.m1.1.1.2.3.cmml">g</mi></msub><mo id="S3.SS3.p2.1.m1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.3.2" xref="S3.SS3.p2.1.m1.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.1.m1.1.1.3.3.1" xref="S3.SS3.p2.1.m1.1.1.3.3.1.cmml">Ã—</mo><msubsup id="S3.SS3.p2.1.m1.1.1.3.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.3.3.2.2" xref="S3.SS3.p2.1.m1.1.1.3.3.3.2.2.cmml">C</mi><mi id="S3.SS3.p2.1.m1.1.1.3.3.3.2.3" xref="S3.SS3.p2.1.m1.1.1.3.3.3.2.3.cmml">b</mi><msup id="S3.SS3.p2.1.m1.1.1.3.3.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.3.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.3.3.3a" xref="S3.SS3.p2.1.m1.1.1.3.3.3.3.cmml"></mi><mo id="S3.SS3.p2.1.m1.1.1.3.3.3.3.1" xref="S3.SS3.p2.1.m1.1.1.3.3.3.3.1.cmml">â€²</mo></msup></msubsup></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><in id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1"></in><apply id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.2.1.cmml" xref="S3.SS3.p2.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2.2">ğ</ci><ci id="S3.SS3.p2.1.m1.1.1.2.3.cmml" xref="S3.SS3.p2.1.m1.1.1.2.3">ğ‘”</ci></apply><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.2">â„</ci><apply id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3"><times id="S3.SS3.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.1"></times><ci id="S3.SS3.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.2">ğ‘</ci><apply id="S3.SS3.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.3.3.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.3">superscript</csymbol><apply id="S3.SS3.p2.1.m1.1.1.3.3.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.3.3.3.2.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.3.3.3.2.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.3.2.2">ğ¶</ci><ci id="S3.SS3.p2.1.m1.1.1.3.3.3.2.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.3.2.3">ğ‘</ci></apply><apply id="S3.SS3.p2.1.m1.1.1.3.3.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.3.3"><ci id="S3.SS3.p2.1.m1.1.1.3.3.3.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.3.3.1">â€²</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\mathbf{e}_{g}\in\mathbb{R}^{N\times C_{b}^{{}^{\prime}}}</annotation></semantics></math>, where <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">N</annotation></semantics></math> is the number of predicted objects. Unlike the object detector transformerâ€™s encoder, the multi-head self-attention includes an additive bias, <em id="S3.SS3.p2.3.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p2.3.2" class="ltx_text"></span> our <span id="S3.SS3.p2.3.3" class="ltx_text ltx_font_italic">object score</span> matrix <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mi mathvariant="normal" id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">\Sigma</annotation></semantics></math>. Therefore, the new attention is defined as:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.4" class="ltx_Math" alttext="\small{\text{BiasedAttention}(Q,K,V)=\text{softmax}\Big{(}\frac{QK^{T}+\Sigma}{\sqrt{d_{k}}}\Big{)}V}\vspace{-0.1cm}" display="block"><semantics id="S3.E3.m1.4a"><mrow id="S3.E3.m1.4.5" xref="S3.E3.m1.4.5.cmml"><mrow id="S3.E3.m1.4.5.2" xref="S3.E3.m1.4.5.2.cmml"><mtext mathsize="90%" id="S3.E3.m1.4.5.2.2" xref="S3.E3.m1.4.5.2.2a.cmml">BiasedAttention</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.2.1" xref="S3.E3.m1.4.5.2.1.cmml">â€‹</mo><mrow id="S3.E3.m1.4.5.2.3.2" xref="S3.E3.m1.4.5.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E3.m1.4.5.2.3.2.1" xref="S3.E3.m1.4.5.2.3.1.cmml">(</mo><mi mathsize="90%" id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">Q</mi><mo mathsize="90%" id="S3.E3.m1.4.5.2.3.2.2" xref="S3.E3.m1.4.5.2.3.1.cmml">,</mo><mi mathsize="90%" id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">K</mi><mo mathsize="90%" id="S3.E3.m1.4.5.2.3.2.3" xref="S3.E3.m1.4.5.2.3.1.cmml">,</mo><mi mathsize="90%" id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">V</mi><mo maxsize="90%" minsize="90%" id="S3.E3.m1.4.5.2.3.2.4" xref="S3.E3.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S3.E3.m1.4.5.1" xref="S3.E3.m1.4.5.1.cmml">=</mo><mrow id="S3.E3.m1.4.5.3" xref="S3.E3.m1.4.5.3.cmml"><mtext mathsize="90%" id="S3.E3.m1.4.5.3.2" xref="S3.E3.m1.4.5.3.2a.cmml">softmax</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.3.1" xref="S3.E3.m1.4.5.3.1.cmml">â€‹</mo><mrow id="S3.E3.m1.4.5.3.3.2" xref="S3.E3.m1.4.4.cmml"><mo maxsize="160%" minsize="160%" id="S3.E3.m1.4.5.3.3.2.1" xref="S3.E3.m1.4.4.cmml">(</mo><mfrac id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml"><mrow id="S3.E3.m1.4.4.2" xref="S3.E3.m1.4.4.2.cmml"><mrow id="S3.E3.m1.4.4.2.2" xref="S3.E3.m1.4.4.2.2.cmml"><mi mathsize="90%" id="S3.E3.m1.4.4.2.2.2" xref="S3.E3.m1.4.4.2.2.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.2.2.1" xref="S3.E3.m1.4.4.2.2.1.cmml">â€‹</mo><msup id="S3.E3.m1.4.4.2.2.3" xref="S3.E3.m1.4.4.2.2.3.cmml"><mi mathsize="90%" id="S3.E3.m1.4.4.2.2.3.2" xref="S3.E3.m1.4.4.2.2.3.2.cmml">K</mi><mi mathsize="90%" id="S3.E3.m1.4.4.2.2.3.3" xref="S3.E3.m1.4.4.2.2.3.3.cmml">T</mi></msup></mrow><mo mathsize="90%" id="S3.E3.m1.4.4.2.1" xref="S3.E3.m1.4.4.2.1.cmml">+</mo><mi mathsize="90%" mathvariant="normal" id="S3.E3.m1.4.4.2.3" xref="S3.E3.m1.4.4.2.3.cmml">Î£</mi></mrow><msqrt id="S3.E3.m1.4.4.3" xref="S3.E3.m1.4.4.3.cmml"><msub id="S3.E3.m1.4.4.3.2" xref="S3.E3.m1.4.4.3.2.cmml"><mi mathsize="90%" id="S3.E3.m1.4.4.3.2.2" xref="S3.E3.m1.4.4.3.2.2.cmml">d</mi><mi mathsize="90%" id="S3.E3.m1.4.4.3.2.3" xref="S3.E3.m1.4.4.3.2.3.cmml">k</mi></msub></msqrt></mfrac><mo maxsize="160%" minsize="160%" id="S3.E3.m1.4.5.3.3.2.2" xref="S3.E3.m1.4.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.5.3.1a" xref="S3.E3.m1.4.5.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.E3.m1.4.5.3.4" xref="S3.E3.m1.4.5.3.4.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.4b"><apply id="S3.E3.m1.4.5.cmml" xref="S3.E3.m1.4.5"><eq id="S3.E3.m1.4.5.1.cmml" xref="S3.E3.m1.4.5.1"></eq><apply id="S3.E3.m1.4.5.2.cmml" xref="S3.E3.m1.4.5.2"><times id="S3.E3.m1.4.5.2.1.cmml" xref="S3.E3.m1.4.5.2.1"></times><ci id="S3.E3.m1.4.5.2.2a.cmml" xref="S3.E3.m1.4.5.2.2"><mtext mathsize="90%" id="S3.E3.m1.4.5.2.2.cmml" xref="S3.E3.m1.4.5.2.2">BiasedAttention</mtext></ci><vector id="S3.E3.m1.4.5.2.3.1.cmml" xref="S3.E3.m1.4.5.2.3.2"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘„</ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">ğ¾</ci><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">ğ‘‰</ci></vector></apply><apply id="S3.E3.m1.4.5.3.cmml" xref="S3.E3.m1.4.5.3"><times id="S3.E3.m1.4.5.3.1.cmml" xref="S3.E3.m1.4.5.3.1"></times><ci id="S3.E3.m1.4.5.3.2a.cmml" xref="S3.E3.m1.4.5.3.2"><mtext mathsize="90%" id="S3.E3.m1.4.5.3.2.cmml" xref="S3.E3.m1.4.5.3.2">softmax</mtext></ci><apply id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.5.3.3.2"><divide id="S3.E3.m1.4.4.1.cmml" xref="S3.E3.m1.4.5.3.3.2"></divide><apply id="S3.E3.m1.4.4.2.cmml" xref="S3.E3.m1.4.4.2"><plus id="S3.E3.m1.4.4.2.1.cmml" xref="S3.E3.m1.4.4.2.1"></plus><apply id="S3.E3.m1.4.4.2.2.cmml" xref="S3.E3.m1.4.4.2.2"><times id="S3.E3.m1.4.4.2.2.1.cmml" xref="S3.E3.m1.4.4.2.2.1"></times><ci id="S3.E3.m1.4.4.2.2.2.cmml" xref="S3.E3.m1.4.4.2.2.2">ğ‘„</ci><apply id="S3.E3.m1.4.4.2.2.3.cmml" xref="S3.E3.m1.4.4.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.2.2.3.1.cmml" xref="S3.E3.m1.4.4.2.2.3">superscript</csymbol><ci id="S3.E3.m1.4.4.2.2.3.2.cmml" xref="S3.E3.m1.4.4.2.2.3.2">ğ¾</ci><ci id="S3.E3.m1.4.4.2.2.3.3.cmml" xref="S3.E3.m1.4.4.2.2.3.3">ğ‘‡</ci></apply></apply><ci id="S3.E3.m1.4.4.2.3.cmml" xref="S3.E3.m1.4.4.2.3">Î£</ci></apply><apply id="S3.E3.m1.4.4.3.cmml" xref="S3.E3.m1.4.4.3"><root id="S3.E3.m1.4.4.3a.cmml" xref="S3.E3.m1.4.4.3"></root><apply id="S3.E3.m1.4.4.3.2.cmml" xref="S3.E3.m1.4.4.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.3.2.1.cmml" xref="S3.E3.m1.4.4.3.2">subscript</csymbol><ci id="S3.E3.m1.4.4.3.2.2.cmml" xref="S3.E3.m1.4.4.3.2.2">ğ‘‘</ci><ci id="S3.E3.m1.4.4.3.2.3.cmml" xref="S3.E3.m1.4.4.3.2.3">ğ‘˜</ci></apply></apply></apply><ci id="S3.E3.m1.4.5.3.4.cmml" xref="S3.E3.m1.4.5.3.4">ğ‘‰</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.4c">\small{\text{BiasedAttention}(Q,K,V)=\text{softmax}\Big{(}\frac{QK^{T}+\Sigma}{\sqrt{d_{k}}}\Big{)}V}\vspace{-0.1cm}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.8" class="ltx_p">Additionally, we mask the learnable embeddings corresponding to objects not classified as heads.
The masked features of the self-attention of <math id="S3.SS3.p2.4.m1.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S3.SS3.p2.4.m1.1a"><mrow id="S3.SS3.p2.4.m1.1.1" xref="S3.SS3.p2.4.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.4.m1.1.1.2" xref="S3.SS3.p2.4.m1.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m1.1.1.1" xref="S3.SS3.p2.4.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.4.m1.1.1.3" xref="S3.SS3.p2.4.m1.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m1.1.1.1a" xref="S3.SS3.p2.4.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.4.m1.1.1.4" xref="S3.SS3.p2.4.m1.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m1.1b"><apply id="S3.SS3.p2.4.m1.1.1.cmml" xref="S3.SS3.p2.4.m1.1.1"><times id="S3.SS3.p2.4.m1.1.1.1.cmml" xref="S3.SS3.p2.4.m1.1.1.1"></times><ci id="S3.SS3.p2.4.m1.1.1.2.cmml" xref="S3.SS3.p2.4.m1.1.1.2">ğ’¢</ci><ci id="S3.SS3.p2.4.m1.1.1.3.cmml" xref="S3.SS3.p2.4.m1.1.1.3">ğ’ª</ci><ci id="S3.SS3.p2.4.m1.1.1.4.cmml" xref="S3.SS3.p2.4.m1.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m1.1c">\mathcal{GOT}\,</annotation></semantics></math>are the inputs to the cross-attention module.
Likewise self-attention, the cross-attention module exploits the <span id="S3.SS3.p2.8.1" class="ltx_text ltx_font_italic">object score</span> matrix as additive bias and performs binary masking on heads for <math id="S3.SS3.p2.5.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS3.p2.5.m2.1a"><mi id="S3.SS3.p2.5.m2.1.1" xref="S3.SS3.p2.5.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m2.1b"><ci id="S3.SS3.p2.5.m2.1.1.cmml" xref="S3.SS3.p2.5.m2.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m2.1c">Q</annotation></semantics></math> and other objects for <math id="S3.SS3.p2.6.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p2.6.m3.1a"><mi id="S3.SS3.p2.6.m3.1.1" xref="S3.SS3.p2.6.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m3.1b"><ci id="S3.SS3.p2.6.m3.1.1.cmml" xref="S3.SS3.p2.6.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m3.1c">K</annotation></semantics></math> and <math id="S3.SS3.p2.7.m4.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS3.p2.7.m4.1a"><mi id="S3.SS3.p2.7.m4.1.1" xref="S3.SS3.p2.7.m4.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m4.1b"><ci id="S3.SS3.p2.7.m4.1.1.cmml" xref="S3.SS3.p2.7.m4.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m4.1c">V</annotation></semantics></math>. We also exclude the objects with low confidence prediction or that are classified as <span id="S3.SS3.p2.8.2" class="ltx_text ltx_font_italic">no-object</span> (<math id="S3.SS3.p2.8.m5.1" class="ltx_Math" alttext="\emptyset" display="inline"><semantics id="S3.SS3.p2.8.m5.1a"><mi mathvariant="normal" id="S3.SS3.p2.8.m5.1.1" xref="S3.SS3.p2.8.m5.1.1.cmml">âˆ…</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m5.1b"><emptyset id="S3.SS3.p2.8.m5.1.1.cmml" xref="S3.SS3.p2.8.m5.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m5.1c">\emptyset</annotation></semantics></math>) (see Sec.Â <a href="#S4.SS2" title="4.2 Implementation details â€£ 4 Experiments â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> for details).</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">The output features of the cross-attention form the input to the <span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_italic">heatmap</span> MLP to predict the gaze heatmap for each head.
However, since we cannot assume that an object is always present, a second MLP (<span id="S3.SS3.p3.1.2" class="ltx_text ltx_font_italic">heatmap no-object</span> in Fig.Â <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) predicts the heatmap from head features only when no object is inside the visual cone.
The outputs of <span id="S3.SS3.p3.1.3" class="ltx_text ltx_font_italic">heatmap</span> MLP and <span id="S3.SS3.p3.1.4" class="ltx_text ltx_font_italic">heatmap no-object</span> MLP are fed to <span id="S3.SS3.p3.1.5" class="ltx_text ltx_font_italic">a gated operator</span> that selects the heatmap based on the presence (or absence) of objects in the cone of each person. Finally, an additional <span id="S3.SS3.p3.1.6" class="ltx_text ltx_font_italic">watch outside</span> MLP, only for head objects, predicts <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{p}_{out}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">ğ©</mi><mrow id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml"><mi id="S3.SS3.p3.1.m1.1.1.3.2" xref="S3.SS3.p3.1.m1.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.1.1.3.1" xref="S3.SS3.p3.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p3.1.m1.1.1.3.3" xref="S3.SS3.p3.1.m1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.1.1.3.1a" xref="S3.SS3.p3.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p3.1.m1.1.1.3.4" xref="S3.SS3.p3.1.m1.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">ğ©</ci><apply id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3"><times id="S3.SS3.p3.1.m1.1.1.3.1.cmml" xref="S3.SS3.p3.1.m1.1.1.3.1"></times><ci id="S3.SS3.p3.1.m1.1.1.3.2.cmml" xref="S3.SS3.p3.1.m1.1.1.3.2">ğ‘œ</ci><ci id="S3.SS3.p3.1.m1.1.1.3.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3.3">ğ‘¢</ci><ci id="S3.SS3.p3.1.m1.1.1.3.4.cmml" xref="S3.SS3.p3.1.m1.1.1.3.4">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\mathbf{p}_{out}</annotation></semantics></math>, the probability that the given head gaze lies outside the frame.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Training objective</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">As we perform multiple tasks simultaneously (e.g., object localization and classification, gaze vector regression, and gaze heatmap regression), our training objective is defined as a <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">weighted sum</span> of all tasks.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.5" class="ltx_p">We supervise the object localization with the weighted difference of <math id="S3.SS4.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{1}" display="inline"><semantics id="S3.SS4.p2.1.m1.1a"><msub id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">â„’</mi><mn id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">â„’</ci><cn type="integer" id="S3.SS4.p2.1.m1.1.1.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">\mathcal{L}_{1}</annotation></semantics></math> distance and Generalized Intersection over Union (GIoU) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> of the target box <math id="S3.SS4.p2.2.m2.1" class="ltx_Math" alttext="box" display="inline"><semantics id="S3.SS4.p2.2.m2.1a"><mrow id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml"><mi id="S3.SS4.p2.2.m2.1.1.2" xref="S3.SS4.p2.2.m2.1.1.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.2.m2.1.1.1" xref="S3.SS4.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p2.2.m2.1.1.3" xref="S3.SS4.p2.2.m2.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.2.m2.1.1.1a" xref="S3.SS4.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p2.2.m2.1.1.4" xref="S3.SS4.p2.2.m2.1.1.4.cmml">x</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><apply id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1"><times id="S3.SS4.p2.2.m2.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1.1"></times><ci id="S3.SS4.p2.2.m2.1.1.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2">ğ‘</ci><ci id="S3.SS4.p2.2.m2.1.1.3.cmml" xref="S3.SS4.p2.2.m2.1.1.3">ğ‘œ</ci><ci id="S3.SS4.p2.2.m2.1.1.4.cmml" xref="S3.SS4.p2.2.m2.1.1.4">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">box</annotation></semantics></math> and predicted box <math id="S3.SS4.p2.3.m3.1" class="ltx_Math" alttext="box_{p}" display="inline"><semantics id="S3.SS4.p2.3.m3.1a"><mrow id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml"><mi id="S3.SS4.p2.3.m3.1.1.2" xref="S3.SS4.p2.3.m3.1.1.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.3.m3.1.1.1" xref="S3.SS4.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p2.3.m3.1.1.3" xref="S3.SS4.p2.3.m3.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.3.m3.1.1.1a" xref="S3.SS4.p2.3.m3.1.1.1.cmml">â€‹</mo><msub id="S3.SS4.p2.3.m3.1.1.4" xref="S3.SS4.p2.3.m3.1.1.4.cmml"><mi id="S3.SS4.p2.3.m3.1.1.4.2" xref="S3.SS4.p2.3.m3.1.1.4.2.cmml">x</mi><mi id="S3.SS4.p2.3.m3.1.1.4.3" xref="S3.SS4.p2.3.m3.1.1.4.3.cmml">p</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><apply id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1"><times id="S3.SS4.p2.3.m3.1.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1.1"></times><ci id="S3.SS4.p2.3.m3.1.1.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2">ğ‘</ci><ci id="S3.SS4.p2.3.m3.1.1.3.cmml" xref="S3.SS4.p2.3.m3.1.1.3">ğ‘œ</ci><apply id="S3.SS4.p2.3.m3.1.1.4.cmml" xref="S3.SS4.p2.3.m3.1.1.4"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.1.1.4.1.cmml" xref="S3.SS4.p2.3.m3.1.1.4">subscript</csymbol><ci id="S3.SS4.p2.3.m3.1.1.4.2.cmml" xref="S3.SS4.p2.3.m3.1.1.4.2">ğ‘¥</ci><ci id="S3.SS4.p2.3.m3.1.1.4.3.cmml" xref="S3.SS4.p2.3.m3.1.1.4.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">box_{p}</annotation></semantics></math>, respectively, formalized as <math id="S3.SS4.p2.4.m4.3" class="ltx_Math" alttext="\mathcal{L}_{box}=\lambda_{l1}\|box-box_{p}\|-\lambda_{giou}GIoU(box,box_{p})" display="inline"><semantics id="S3.SS4.p2.4.m4.3a"><mrow id="S3.SS4.p2.4.m4.3.3" xref="S3.SS4.p2.4.m4.3.3.cmml"><msub id="S3.SS4.p2.4.m4.3.3.5" xref="S3.SS4.p2.4.m4.3.3.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.4.m4.3.3.5.2" xref="S3.SS4.p2.4.m4.3.3.5.2.cmml">â„’</mi><mrow id="S3.SS4.p2.4.m4.3.3.5.3" xref="S3.SS4.p2.4.m4.3.3.5.3.cmml"><mi id="S3.SS4.p2.4.m4.3.3.5.3.2" xref="S3.SS4.p2.4.m4.3.3.5.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.5.3.1" xref="S3.SS4.p2.4.m4.3.3.5.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.5.3.3" xref="S3.SS4.p2.4.m4.3.3.5.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.5.3.1a" xref="S3.SS4.p2.4.m4.3.3.5.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.5.3.4" xref="S3.SS4.p2.4.m4.3.3.5.3.4.cmml">x</mi></mrow></msub><mo id="S3.SS4.p2.4.m4.3.3.4" xref="S3.SS4.p2.4.m4.3.3.4.cmml">=</mo><mrow id="S3.SS4.p2.4.m4.3.3.3" xref="S3.SS4.p2.4.m4.3.3.3.cmml"><mrow id="S3.SS4.p2.4.m4.1.1.1.1" xref="S3.SS4.p2.4.m4.1.1.1.1.cmml"><msub id="S3.SS4.p2.4.m4.1.1.1.1.3" xref="S3.SS4.p2.4.m4.1.1.1.1.3.cmml"><mi id="S3.SS4.p2.4.m4.1.1.1.1.3.2" xref="S3.SS4.p2.4.m4.1.1.1.1.3.2.cmml">Î»</mi><mrow id="S3.SS4.p2.4.m4.1.1.1.1.3.3" xref="S3.SS4.p2.4.m4.1.1.1.1.3.3.cmml"><mi id="S3.SS4.p2.4.m4.1.1.1.1.3.3.2" xref="S3.SS4.p2.4.m4.1.1.1.1.3.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.1.1.1.1.3.3.1" xref="S3.SS4.p2.4.m4.1.1.1.1.3.3.1.cmml">â€‹</mo><mn id="S3.SS4.p2.4.m4.1.1.1.1.3.3.3" xref="S3.SS4.p2.4.m4.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.1.1.1.1.2" xref="S3.SS4.p2.4.m4.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS4.p2.4.m4.1.1.1.1.1.1" xref="S3.SS4.p2.4.m4.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS4.p2.4.m4.1.1.1.1.1.1.2" xref="S3.SS4.p2.4.m4.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.cmml"><mrow id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.cmml"><mi id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.2" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.1" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.3" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.1a" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.4" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.4.cmml">x</mi></mrow><mo id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.1" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mrow id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.2" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.1" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.3" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.1a" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><msub id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.cmml"><mi id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.2" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.2.cmml">x</mi><mi id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.3" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.3.cmml">p</mi></msub></mrow></mrow><mo stretchy="false" id="S3.SS4.p2.4.m4.1.1.1.1.1.1.3" xref="S3.SS4.p2.4.m4.1.1.1.1.1.2.1.cmml">â€–</mo></mrow></mrow><mo id="S3.SS4.p2.4.m4.3.3.3.4" xref="S3.SS4.p2.4.m4.3.3.3.4.cmml">âˆ’</mo><mrow id="S3.SS4.p2.4.m4.3.3.3.3" xref="S3.SS4.p2.4.m4.3.3.3.3.cmml"><msub id="S3.SS4.p2.4.m4.3.3.3.3.4" xref="S3.SS4.p2.4.m4.3.3.3.3.4.cmml"><mi id="S3.SS4.p2.4.m4.3.3.3.3.4.2" xref="S3.SS4.p2.4.m4.3.3.3.3.4.2.cmml">Î»</mi><mrow id="S3.SS4.p2.4.m4.3.3.3.3.4.3" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.cmml"><mi id="S3.SS4.p2.4.m4.3.3.3.3.4.3.2" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.4.3.1" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.3.3.4.3.3" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.4.3.1a" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.3.3.4.3.4" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.4.3.1b" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.3.3.4.3.5" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.5.cmml">u</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.3" xref="S3.SS4.p2.4.m4.3.3.3.3.3.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.3.3.5" xref="S3.SS4.p2.4.m4.3.3.3.3.5.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.3a" xref="S3.SS4.p2.4.m4.3.3.3.3.3.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.3.3.6" xref="S3.SS4.p2.4.m4.3.3.3.3.6.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.3b" xref="S3.SS4.p2.4.m4.3.3.3.3.3.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.3.3.7" xref="S3.SS4.p2.4.m4.3.3.3.3.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.3c" xref="S3.SS4.p2.4.m4.3.3.3.3.3.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.3.3.8" xref="S3.SS4.p2.4.m4.3.3.3.3.8.cmml">U</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.3d" xref="S3.SS4.p2.4.m4.3.3.3.3.3.cmml">â€‹</mo><mrow id="S3.SS4.p2.4.m4.3.3.3.3.2.2" xref="S3.SS4.p2.4.m4.3.3.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS4.p2.4.m4.3.3.3.3.2.2.3" xref="S3.SS4.p2.4.m4.3.3.3.3.2.3.cmml">(</mo><mrow id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.cmml"><mi id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.2" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.1" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.3" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.1a" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.4" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.4.cmml">x</mi></mrow><mo id="S3.SS4.p2.4.m4.3.3.3.3.2.2.4" xref="S3.SS4.p2.4.m4.3.3.3.3.2.3.cmml">,</mo><mrow id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.cmml"><mi id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.2" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.1" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.3" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.1a" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.1.cmml">â€‹</mo><msub id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.cmml"><mi id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.2" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.2.cmml">x</mi><mi id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.3" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.3.cmml">p</mi></msub></mrow><mo stretchy="false" id="S3.SS4.p2.4.m4.3.3.3.3.2.2.5" xref="S3.SS4.p2.4.m4.3.3.3.3.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.3b"><apply id="S3.SS4.p2.4.m4.3.3.cmml" xref="S3.SS4.p2.4.m4.3.3"><eq id="S3.SS4.p2.4.m4.3.3.4.cmml" xref="S3.SS4.p2.4.m4.3.3.4"></eq><apply id="S3.SS4.p2.4.m4.3.3.5.cmml" xref="S3.SS4.p2.4.m4.3.3.5"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.3.3.5.1.cmml" xref="S3.SS4.p2.4.m4.3.3.5">subscript</csymbol><ci id="S3.SS4.p2.4.m4.3.3.5.2.cmml" xref="S3.SS4.p2.4.m4.3.3.5.2">â„’</ci><apply id="S3.SS4.p2.4.m4.3.3.5.3.cmml" xref="S3.SS4.p2.4.m4.3.3.5.3"><times id="S3.SS4.p2.4.m4.3.3.5.3.1.cmml" xref="S3.SS4.p2.4.m4.3.3.5.3.1"></times><ci id="S3.SS4.p2.4.m4.3.3.5.3.2.cmml" xref="S3.SS4.p2.4.m4.3.3.5.3.2">ğ‘</ci><ci id="S3.SS4.p2.4.m4.3.3.5.3.3.cmml" xref="S3.SS4.p2.4.m4.3.3.5.3.3">ğ‘œ</ci><ci id="S3.SS4.p2.4.m4.3.3.5.3.4.cmml" xref="S3.SS4.p2.4.m4.3.3.5.3.4">ğ‘¥</ci></apply></apply><apply id="S3.SS4.p2.4.m4.3.3.3.cmml" xref="S3.SS4.p2.4.m4.3.3.3"><minus id="S3.SS4.p2.4.m4.3.3.3.4.cmml" xref="S3.SS4.p2.4.m4.3.3.3.4"></minus><apply id="S3.SS4.p2.4.m4.1.1.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1"><times id="S3.SS4.p2.4.m4.1.1.1.1.2.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.2"></times><apply id="S3.SS4.p2.4.m4.1.1.1.1.3.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.1.1.1.1.3.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.3">subscript</csymbol><ci id="S3.SS4.p2.4.m4.1.1.1.1.3.2.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.3.2">ğœ†</ci><apply id="S3.SS4.p2.4.m4.1.1.1.1.3.3.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.3.3"><times id="S3.SS4.p2.4.m4.1.1.1.1.3.3.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.3.3.1"></times><ci id="S3.SS4.p2.4.m4.1.1.1.1.3.3.2.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.3.3.2">ğ‘™</ci><cn type="integer" id="S3.SS4.p2.4.m4.1.1.1.1.3.3.3.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.3.3.3">1</cn></apply></apply><apply id="S3.SS4.p2.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS4.p2.4.m4.1.1.1.1.1.2.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1"><minus id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.1"></minus><apply id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2"><times id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.1"></times><ci id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.3">ğ‘œ</ci><ci id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.4.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.2.4">ğ‘¥</ci></apply><apply id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3"><times id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.1"></times><ci id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.3">ğ‘œ</ci><apply id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4">subscript</csymbol><ci id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.2.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.2">ğ‘¥</ci><ci id="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.3.cmml" xref="S3.SS4.p2.4.m4.1.1.1.1.1.1.1.3.4.3">ğ‘</ci></apply></apply></apply></apply></apply><apply id="S3.SS4.p2.4.m4.3.3.3.3.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3"><times id="S3.SS4.p2.4.m4.3.3.3.3.3.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.3"></times><apply id="S3.SS4.p2.4.m4.3.3.3.3.4.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.4"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.3.3.3.3.4.1.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.4">subscript</csymbol><ci id="S3.SS4.p2.4.m4.3.3.3.3.4.2.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.4.2">ğœ†</ci><apply id="S3.SS4.p2.4.m4.3.3.3.3.4.3.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3"><times id="S3.SS4.p2.4.m4.3.3.3.3.4.3.1.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.1"></times><ci id="S3.SS4.p2.4.m4.3.3.3.3.4.3.2.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.2">ğ‘”</ci><ci id="S3.SS4.p2.4.m4.3.3.3.3.4.3.3.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.3">ğ‘–</ci><ci id="S3.SS4.p2.4.m4.3.3.3.3.4.3.4.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.4">ğ‘œ</ci><ci id="S3.SS4.p2.4.m4.3.3.3.3.4.3.5.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.4.3.5">ğ‘¢</ci></apply></apply><ci id="S3.SS4.p2.4.m4.3.3.3.3.5.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.5">ğº</ci><ci id="S3.SS4.p2.4.m4.3.3.3.3.6.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.6">ğ¼</ci><ci id="S3.SS4.p2.4.m4.3.3.3.3.7.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.7">ğ‘œ</ci><ci id="S3.SS4.p2.4.m4.3.3.3.3.8.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.8">ğ‘ˆ</ci><interval closure="open" id="S3.SS4.p2.4.m4.3.3.3.3.2.3.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2"><apply id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.cmml" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1"><times id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.1.cmml" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.1"></times><ci id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.2.cmml" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.2">ğ‘</ci><ci id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.3.cmml" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.3">ğ‘œ</ci><ci id="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.4.cmml" xref="S3.SS4.p2.4.m4.2.2.2.2.1.1.1.4">ğ‘¥</ci></apply><apply id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2"><times id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.1.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.1"></times><ci id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.2.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.2">ğ‘</ci><ci id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.3.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.3">ğ‘œ</ci><apply id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.1.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4">subscript</csymbol><ci id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.2.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.2">ğ‘¥</ci><ci id="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.3.cmml" xref="S3.SS4.p2.4.m4.3.3.3.3.2.2.2.4.3">ğ‘</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.3c">\mathcal{L}_{box}=\lambda_{l1}\|box-box_{p}\|-\lambda_{giou}GIoU(box,box_{p})</annotation></semantics></math>.
Object classification loss <math id="S3.SS4.p2.5.m5.1" class="ltx_Math" alttext="\mathcal{L}_{cls}" display="inline"><semantics id="S3.SS4.p2.5.m5.1a"><msub id="S3.SS4.p2.5.m5.1.1" xref="S3.SS4.p2.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.5.m5.1.1.2" xref="S3.SS4.p2.5.m5.1.1.2.cmml">â„’</mi><mrow id="S3.SS4.p2.5.m5.1.1.3" xref="S3.SS4.p2.5.m5.1.1.3.cmml"><mi id="S3.SS4.p2.5.m5.1.1.3.2" xref="S3.SS4.p2.5.m5.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.5.m5.1.1.3.1" xref="S3.SS4.p2.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.5.m5.1.1.3.3" xref="S3.SS4.p2.5.m5.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.5.m5.1.1.3.1a" xref="S3.SS4.p2.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.5.m5.1.1.3.4" xref="S3.SS4.p2.5.m5.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m5.1b"><apply id="S3.SS4.p2.5.m5.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.5.m5.1.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS4.p2.5.m5.1.1.2.cmml" xref="S3.SS4.p2.5.m5.1.1.2">â„’</ci><apply id="S3.SS4.p2.5.m5.1.1.3.cmml" xref="S3.SS4.p2.5.m5.1.1.3"><times id="S3.SS4.p2.5.m5.1.1.3.1.cmml" xref="S3.SS4.p2.5.m5.1.1.3.1"></times><ci id="S3.SS4.p2.5.m5.1.1.3.2.cmml" xref="S3.SS4.p2.5.m5.1.1.3.2">ğ‘</ci><ci id="S3.SS4.p2.5.m5.1.1.3.3.cmml" xref="S3.SS4.p2.5.m5.1.1.3.3">ğ‘™</ci><ci id="S3.SS4.p2.5.m5.1.1.3.4.cmml" xref="S3.SS4.p2.5.m5.1.1.3.4">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.5.m5.1c">\mathcal{L}_{cls}</annotation></semantics></math> is the cross-entropy between the ground truth label and the post-softmax distribution of the predicted class.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.9" class="ltx_p">The gaze-related tasks involve the use of three losses: (a) gaze vector loss, (b) gaze heatmap loss, and (c) gaze watch-outside loss.
The gaze vector loss is formulated as the <math id="S3.SS4.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{2}" display="inline"><semantics id="S3.SS4.p3.1.m1.1a"><msub id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p3.1.m1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.2.cmml">â„’</mi><mn id="S3.SS4.p3.1.m1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><apply id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.1.m1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p3.1.m1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.2">â„’</ci><cn type="integer" id="S3.SS4.p3.1.m1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">\mathcal{L}_{2}</annotation></semantics></math> loss between elements of the predicted and target vector such that <math id="S3.SS4.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{vec}=\|\mathbf{v}_{g}-\mathbf{v}_{p}\|_{2}" display="inline"><semantics id="S3.SS4.p3.2.m2.1a"><mrow id="S3.SS4.p3.2.m2.1.1" xref="S3.SS4.p3.2.m2.1.1.cmml"><msub id="S3.SS4.p3.2.m2.1.1.3" xref="S3.SS4.p3.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p3.2.m2.1.1.3.2" xref="S3.SS4.p3.2.m2.1.1.3.2.cmml">â„’</mi><mrow id="S3.SS4.p3.2.m2.1.1.3.3" xref="S3.SS4.p3.2.m2.1.1.3.3.cmml"><mi id="S3.SS4.p3.2.m2.1.1.3.3.2" xref="S3.SS4.p3.2.m2.1.1.3.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.2.m2.1.1.3.3.1" xref="S3.SS4.p3.2.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.2.m2.1.1.3.3.3" xref="S3.SS4.p3.2.m2.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.2.m2.1.1.3.3.1a" xref="S3.SS4.p3.2.m2.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.2.m2.1.1.3.3.4" xref="S3.SS4.p3.2.m2.1.1.3.3.4.cmml">c</mi></mrow></msub><mo id="S3.SS4.p3.2.m2.1.1.2" xref="S3.SS4.p3.2.m2.1.1.2.cmml">=</mo><msub id="S3.SS4.p3.2.m2.1.1.1" xref="S3.SS4.p3.2.m2.1.1.1.cmml"><mrow id="S3.SS4.p3.2.m2.1.1.1.1.1" xref="S3.SS4.p3.2.m2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS4.p3.2.m2.1.1.1.1.1.2" xref="S3.SS4.p3.2.m2.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.SS4.p3.2.m2.1.1.1.1.1.1" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.cmml"><msub id="S3.SS4.p3.2.m2.1.1.1.1.1.1.2" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.cmml"><mi id="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.2" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.2.cmml">ğ¯</mi><mi id="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.3" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.3.cmml">g</mi></msub><mo id="S3.SS4.p3.2.m2.1.1.1.1.1.1.1" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.SS4.p3.2.m2.1.1.1.1.1.1.3" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.2" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.2.cmml">ğ¯</mi><mi id="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.3" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.3.cmml">p</mi></msub></mrow><mo stretchy="false" id="S3.SS4.p3.2.m2.1.1.1.1.1.3" xref="S3.SS4.p3.2.m2.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.SS4.p3.2.m2.1.1.1.3" xref="S3.SS4.p3.2.m2.1.1.1.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m2.1b"><apply id="S3.SS4.p3.2.m2.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1"><eq id="S3.SS4.p3.2.m2.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.2"></eq><apply id="S3.SS4.p3.2.m2.1.1.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m2.1.1.3.1.cmml" xref="S3.SS4.p3.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS4.p3.2.m2.1.1.3.2.cmml" xref="S3.SS4.p3.2.m2.1.1.3.2">â„’</ci><apply id="S3.SS4.p3.2.m2.1.1.3.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3.3"><times id="S3.SS4.p3.2.m2.1.1.3.3.1.cmml" xref="S3.SS4.p3.2.m2.1.1.3.3.1"></times><ci id="S3.SS4.p3.2.m2.1.1.3.3.2.cmml" xref="S3.SS4.p3.2.m2.1.1.3.3.2">ğ‘£</ci><ci id="S3.SS4.p3.2.m2.1.1.3.3.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3.3.3">ğ‘’</ci><ci id="S3.SS4.p3.2.m2.1.1.3.3.4.cmml" xref="S3.SS4.p3.2.m2.1.1.3.3.4">ğ‘</ci></apply></apply><apply id="S3.SS4.p3.2.m2.1.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m2.1.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.1">subscript</csymbol><apply id="S3.SS4.p3.2.m2.1.1.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS4.p3.2.m2.1.1.1.1.2.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.2">norm</csymbol><apply id="S3.SS4.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1"><minus id="S3.SS4.p3.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.1"></minus><apply id="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.2">ğ¯</ci><ci id="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.3.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.2.3">ğ‘”</ci></apply><apply id="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.2">ğ¯</ci><ci id="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p3.2.m2.1.1.1.1.1.1.3.3">ğ‘</ci></apply></apply></apply><cn type="integer" id="S3.SS4.p3.2.m2.1.1.1.3.cmml" xref="S3.SS4.p3.2.m2.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m2.1c">\mathcal{L}_{vec}=\|\mathbf{v}_{g}-\mathbf{v}_{p}\|_{2}</annotation></semantics></math>, with <math id="S3.SS4.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{v}_{g}\," display="inline"><semantics id="S3.SS4.p3.3.m3.1a"><msub id="S3.SS4.p3.3.m3.1.1" xref="S3.SS4.p3.3.m3.1.1.cmml"><mi id="S3.SS4.p3.3.m3.1.1.2" xref="S3.SS4.p3.3.m3.1.1.2.cmml">ğ¯</mi><mi id="S3.SS4.p3.3.m3.1.1.3" xref="S3.SS4.p3.3.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m3.1b"><apply id="S3.SS4.p3.3.m3.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.3.m3.1.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p3.3.m3.1.1.2.cmml" xref="S3.SS4.p3.3.m3.1.1.2">ğ¯</ci><ci id="S3.SS4.p3.3.m3.1.1.3.cmml" xref="S3.SS4.p3.3.m3.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m3.1c">\mathbf{v}_{g}\,</annotation></semantics></math>being the ground truth gaze vector and <math id="S3.SS4.p3.4.m4.1" class="ltx_Math" alttext="\mathbf{v}_{p}" display="inline"><semantics id="S3.SS4.p3.4.m4.1a"><msub id="S3.SS4.p3.4.m4.1.1" xref="S3.SS4.p3.4.m4.1.1.cmml"><mi id="S3.SS4.p3.4.m4.1.1.2" xref="S3.SS4.p3.4.m4.1.1.2.cmml">ğ¯</mi><mi id="S3.SS4.p3.4.m4.1.1.3" xref="S3.SS4.p3.4.m4.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.4.m4.1b"><apply id="S3.SS4.p3.4.m4.1.1.cmml" xref="S3.SS4.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.4.m4.1.1.1.cmml" xref="S3.SS4.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.p3.4.m4.1.1.2.cmml" xref="S3.SS4.p3.4.m4.1.1.2">ğ¯</ci><ci id="S3.SS4.p3.4.m4.1.1.3.cmml" xref="S3.SS4.p3.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.4.m4.1c">\mathbf{v}_{p}</annotation></semantics></math> the one predicted by our method.
The watch-outside loss is a binary cross-entropy loss <math id="S3.SS4.p3.5.m5.3" class="ltx_Math" alttext="\mathcal{L}_{out}=-\big{[}out\log(\mathbf{p}_{out})+(1-out)\log(1-\mathbf{p}_{out})\big{]}" display="inline"><semantics id="S3.SS4.p3.5.m5.3a"><mrow id="S3.SS4.p3.5.m5.3.3" xref="S3.SS4.p3.5.m5.3.3.cmml"><msub id="S3.SS4.p3.5.m5.3.3.3" xref="S3.SS4.p3.5.m5.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p3.5.m5.3.3.3.2" xref="S3.SS4.p3.5.m5.3.3.3.2.cmml">â„’</mi><mrow id="S3.SS4.p3.5.m5.3.3.3.3" xref="S3.SS4.p3.5.m5.3.3.3.3.cmml"><mi id="S3.SS4.p3.5.m5.3.3.3.3.2" xref="S3.SS4.p3.5.m5.3.3.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.3.3.1" xref="S3.SS4.p3.5.m5.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.3.3.3" xref="S3.SS4.p3.5.m5.3.3.3.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.3.3.1a" xref="S3.SS4.p3.5.m5.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.3.3.4" xref="S3.SS4.p3.5.m5.3.3.3.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS4.p3.5.m5.3.3.2" xref="S3.SS4.p3.5.m5.3.3.2.cmml">=</mo><mrow id="S3.SS4.p3.5.m5.3.3.1" xref="S3.SS4.p3.5.m5.3.3.1.cmml"><mo id="S3.SS4.p3.5.m5.3.3.1a" xref="S3.SS4.p3.5.m5.3.3.1.cmml">âˆ’</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.2.cmml"><mo maxsize="120%" minsize="120%" id="S3.SS4.p3.5.m5.3.3.1.1.1.2" xref="S3.SS4.p3.5.m5.3.3.1.1.2.1.cmml">[</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.cmml"><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.cmml"><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.4" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.2a" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.5" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.5.cmml">t</mi><mo lspace="0.167em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.2b" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml"><mi id="S3.SS4.p3.5.m5.1.1" xref="S3.SS4.p3.5.m5.1.1.cmml">log</mi><mo id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1a" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml">â¡</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml">(</mo><msub id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.2.cmml">ğ©</mi><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.1a" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.4" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.4.cmml">t</mi></mrow></msub><mo stretchy="false" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.SS4.p3.5.m5.3.3.1.1.1.1.4" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.4.cmml">+</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.cmml"><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.cmml">(</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.cmml"><mn id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.2.cmml">1</mn><mo id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.1.cmml">âˆ’</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.cmml"><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.1a" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.4" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.4.cmml">t</mi></mrow></mrow><mo stretchy="false" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.cmml">)</mo></mrow><mo lspace="0.167em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.3.cmml">â€‹</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.2.cmml"><mi id="S3.SS4.p3.5.m5.2.2" xref="S3.SS4.p3.5.m5.2.2.cmml">log</mi><mo id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1a" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.2.cmml">â¡</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.2.cmml"><mo stretchy="false" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.2.cmml">(</mo><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.cmml"><mn id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.2.cmml">1</mn><mo id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.1.cmml">âˆ’</mo><msub id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.cmml"><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.2.cmml">ğ©</mi><mrow id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.cmml"><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.2" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.1" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.1a" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.4" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.4.cmml">t</mi></mrow></msub></mrow><mo stretchy="false" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.3" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo maxsize="120%" minsize="120%" id="S3.SS4.p3.5.m5.3.3.1.1.1.3" xref="S3.SS4.p3.5.m5.3.3.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.5.m5.3b"><apply id="S3.SS4.p3.5.m5.3.3.cmml" xref="S3.SS4.p3.5.m5.3.3"><eq id="S3.SS4.p3.5.m5.3.3.2.cmml" xref="S3.SS4.p3.5.m5.3.3.2"></eq><apply id="S3.SS4.p3.5.m5.3.3.3.cmml" xref="S3.SS4.p3.5.m5.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.p3.5.m5.3.3.3.1.cmml" xref="S3.SS4.p3.5.m5.3.3.3">subscript</csymbol><ci id="S3.SS4.p3.5.m5.3.3.3.2.cmml" xref="S3.SS4.p3.5.m5.3.3.3.2">â„’</ci><apply id="S3.SS4.p3.5.m5.3.3.3.3.cmml" xref="S3.SS4.p3.5.m5.3.3.3.3"><times id="S3.SS4.p3.5.m5.3.3.3.3.1.cmml" xref="S3.SS4.p3.5.m5.3.3.3.3.1"></times><ci id="S3.SS4.p3.5.m5.3.3.3.3.2.cmml" xref="S3.SS4.p3.5.m5.3.3.3.3.2">ğ‘œ</ci><ci id="S3.SS4.p3.5.m5.3.3.3.3.3.cmml" xref="S3.SS4.p3.5.m5.3.3.3.3.3">ğ‘¢</ci><ci id="S3.SS4.p3.5.m5.3.3.3.3.4.cmml" xref="S3.SS4.p3.5.m5.3.3.3.3.4">ğ‘¡</ci></apply></apply><apply id="S3.SS4.p3.5.m5.3.3.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1"><minus id="S3.SS4.p3.5.m5.3.3.1.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1"></minus><apply id="S3.SS4.p3.5.m5.3.3.1.1.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1"><csymbol cd="latexml" id="S3.SS4.p3.5.m5.3.3.1.1.2.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1"><plus id="S3.SS4.p3.5.m5.3.3.1.1.1.1.4.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.4"></plus><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1"><times id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.2"></times><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.3">ğ‘œ</ci><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.4.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.4">ğ‘¢</ci><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.5.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.5">ğ‘¡</ci><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1"><log id="S3.SS4.p3.5.m5.1.1.cmml" xref="S3.SS4.p3.5.m5.1.1"></log><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.2">ğ©</ci><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3"><times id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.2">ğ‘œ</ci><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.3">ğ‘¢</ci><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.1.1.1.1.1.3.4">ğ‘¡</ci></apply></apply></apply></apply><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3"><times id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.3"></times><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1"><minus id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.1"></minus><cn type="integer" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.2">1</cn><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3"><times id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.1"></times><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.2">ğ‘œ</ci><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.3">ğ‘¢</ci><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.4.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.2.1.1.1.3.4">ğ‘¡</ci></apply></apply><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1"><log id="S3.SS4.p3.5.m5.2.2.cmml" xref="S3.SS4.p3.5.m5.2.2"></log><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1"><minus id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.1"></minus><cn type="integer" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.2">1</cn><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3">subscript</csymbol><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.2">ğ©</ci><apply id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3"><times id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.1.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.1"></times><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.2.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.2">ğ‘œ</ci><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.3.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.3">ğ‘¢</ci><ci id="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.4.cmml" xref="S3.SS4.p3.5.m5.3.3.1.1.1.1.3.2.1.1.1.3.3.4">ğ‘¡</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.5.m5.3c">\mathcal{L}_{out}=-\big{[}out\log(\mathbf{p}_{out})+(1-out)\log(1-\mathbf{p}_{out})\big{]}</annotation></semantics></math>, where <math id="S3.SS4.p3.6.m6.1" class="ltx_Math" alttext="out" display="inline"><semantics id="S3.SS4.p3.6.m6.1a"><mrow id="S3.SS4.p3.6.m6.1.1" xref="S3.SS4.p3.6.m6.1.1.cmml"><mi id="S3.SS4.p3.6.m6.1.1.2" xref="S3.SS4.p3.6.m6.1.1.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.6.m6.1.1.1" xref="S3.SS4.p3.6.m6.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p3.6.m6.1.1.3" xref="S3.SS4.p3.6.m6.1.1.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.6.m6.1.1.1a" xref="S3.SS4.p3.6.m6.1.1.1.cmml">â€‹</mo><mi id="S3.SS4.p3.6.m6.1.1.4" xref="S3.SS4.p3.6.m6.1.1.4.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.6.m6.1b"><apply id="S3.SS4.p3.6.m6.1.1.cmml" xref="S3.SS4.p3.6.m6.1.1"><times id="S3.SS4.p3.6.m6.1.1.1.cmml" xref="S3.SS4.p3.6.m6.1.1.1"></times><ci id="S3.SS4.p3.6.m6.1.1.2.cmml" xref="S3.SS4.p3.6.m6.1.1.2">ğ‘œ</ci><ci id="S3.SS4.p3.6.m6.1.1.3.cmml" xref="S3.SS4.p3.6.m6.1.1.3">ğ‘¢</ci><ci id="S3.SS4.p3.6.m6.1.1.4.cmml" xref="S3.SS4.p3.6.m6.1.1.4">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.6.m6.1c">out</annotation></semantics></math> is the ground truth binary annotation of whether the person is watching outside and <math id="S3.SS4.p3.7.m7.1" class="ltx_Math" alttext="\mathbf{p}_{out}" display="inline"><semantics id="S3.SS4.p3.7.m7.1a"><msub id="S3.SS4.p3.7.m7.1.1" xref="S3.SS4.p3.7.m7.1.1.cmml"><mi id="S3.SS4.p3.7.m7.1.1.2" xref="S3.SS4.p3.7.m7.1.1.2.cmml">ğ©</mi><mrow id="S3.SS4.p3.7.m7.1.1.3" xref="S3.SS4.p3.7.m7.1.1.3.cmml"><mi id="S3.SS4.p3.7.m7.1.1.3.2" xref="S3.SS4.p3.7.m7.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.7.m7.1.1.3.1" xref="S3.SS4.p3.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.7.m7.1.1.3.3" xref="S3.SS4.p3.7.m7.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.7.m7.1.1.3.1a" xref="S3.SS4.p3.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.7.m7.1.1.3.4" xref="S3.SS4.p3.7.m7.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.7.m7.1b"><apply id="S3.SS4.p3.7.m7.1.1.cmml" xref="S3.SS4.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.7.m7.1.1.1.cmml" xref="S3.SS4.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS4.p3.7.m7.1.1.2.cmml" xref="S3.SS4.p3.7.m7.1.1.2">ğ©</ci><apply id="S3.SS4.p3.7.m7.1.1.3.cmml" xref="S3.SS4.p3.7.m7.1.1.3"><times id="S3.SS4.p3.7.m7.1.1.3.1.cmml" xref="S3.SS4.p3.7.m7.1.1.3.1"></times><ci id="S3.SS4.p3.7.m7.1.1.3.2.cmml" xref="S3.SS4.p3.7.m7.1.1.3.2">ğ‘œ</ci><ci id="S3.SS4.p3.7.m7.1.1.3.3.cmml" xref="S3.SS4.p3.7.m7.1.1.3.3">ğ‘¢</ci><ci id="S3.SS4.p3.7.m7.1.1.3.4.cmml" xref="S3.SS4.p3.7.m7.1.1.3.4">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.7.m7.1c">\mathbf{p}_{out}</annotation></semantics></math> is the predicted value.
Lastly, the gaze heatmap loss is an <math id="S3.SS4.p3.8.m8.1" class="ltx_Math" alttext="\mathcal{L}_{2}" display="inline"><semantics id="S3.SS4.p3.8.m8.1a"><msub id="S3.SS4.p3.8.m8.1.1" xref="S3.SS4.p3.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p3.8.m8.1.1.2" xref="S3.SS4.p3.8.m8.1.1.2.cmml">â„’</mi><mn id="S3.SS4.p3.8.m8.1.1.3" xref="S3.SS4.p3.8.m8.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.8.m8.1b"><apply id="S3.SS4.p3.8.m8.1.1.cmml" xref="S3.SS4.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.8.m8.1.1.1.cmml" xref="S3.SS4.p3.8.m8.1.1">subscript</csymbol><ci id="S3.SS4.p3.8.m8.1.1.2.cmml" xref="S3.SS4.p3.8.m8.1.1.2">â„’</ci><cn type="integer" id="S3.SS4.p3.8.m8.1.1.3.cmml" xref="S3.SS4.p3.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.8.m8.1c">\mathcal{L}_{2}</annotation></semantics></math> loss between target and predicted heatmap: <math id="S3.SS4.p3.9.m9.1" class="ltx_Math" alttext="\mathcal{L}_{heat}=\lambda_{heat}\|\mathbf{H}-\mathbf{H}_{p}\|_{2}" display="inline"><semantics id="S3.SS4.p3.9.m9.1a"><mrow id="S3.SS4.p3.9.m9.1.1" xref="S3.SS4.p3.9.m9.1.1.cmml"><msub id="S3.SS4.p3.9.m9.1.1.3" xref="S3.SS4.p3.9.m9.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p3.9.m9.1.1.3.2" xref="S3.SS4.p3.9.m9.1.1.3.2.cmml">â„’</mi><mrow id="S3.SS4.p3.9.m9.1.1.3.3" xref="S3.SS4.p3.9.m9.1.1.3.3.cmml"><mi id="S3.SS4.p3.9.m9.1.1.3.3.2" xref="S3.SS4.p3.9.m9.1.1.3.3.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.9.m9.1.1.3.3.1" xref="S3.SS4.p3.9.m9.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.9.m9.1.1.3.3.3" xref="S3.SS4.p3.9.m9.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.9.m9.1.1.3.3.1a" xref="S3.SS4.p3.9.m9.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.9.m9.1.1.3.3.4" xref="S3.SS4.p3.9.m9.1.1.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.9.m9.1.1.3.3.1b" xref="S3.SS4.p3.9.m9.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.9.m9.1.1.3.3.5" xref="S3.SS4.p3.9.m9.1.1.3.3.5.cmml">t</mi></mrow></msub><mo id="S3.SS4.p3.9.m9.1.1.2" xref="S3.SS4.p3.9.m9.1.1.2.cmml">=</mo><mrow id="S3.SS4.p3.9.m9.1.1.1" xref="S3.SS4.p3.9.m9.1.1.1.cmml"><msub id="S3.SS4.p3.9.m9.1.1.1.3" xref="S3.SS4.p3.9.m9.1.1.1.3.cmml"><mi id="S3.SS4.p3.9.m9.1.1.1.3.2" xref="S3.SS4.p3.9.m9.1.1.1.3.2.cmml">Î»</mi><mrow id="S3.SS4.p3.9.m9.1.1.1.3.3" xref="S3.SS4.p3.9.m9.1.1.1.3.3.cmml"><mi id="S3.SS4.p3.9.m9.1.1.1.3.3.2" xref="S3.SS4.p3.9.m9.1.1.1.3.3.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.9.m9.1.1.1.3.3.1" xref="S3.SS4.p3.9.m9.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.9.m9.1.1.1.3.3.3" xref="S3.SS4.p3.9.m9.1.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.9.m9.1.1.1.3.3.1a" xref="S3.SS4.p3.9.m9.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.9.m9.1.1.1.3.3.4" xref="S3.SS4.p3.9.m9.1.1.1.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.9.m9.1.1.1.3.3.1b" xref="S3.SS4.p3.9.m9.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.9.m9.1.1.1.3.3.5" xref="S3.SS4.p3.9.m9.1.1.1.3.3.5.cmml">t</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p3.9.m9.1.1.1.2" xref="S3.SS4.p3.9.m9.1.1.1.2.cmml">â€‹</mo><msub id="S3.SS4.p3.9.m9.1.1.1.1" xref="S3.SS4.p3.9.m9.1.1.1.1.cmml"><mrow id="S3.SS4.p3.9.m9.1.1.1.1.1.1" xref="S3.SS4.p3.9.m9.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS4.p3.9.m9.1.1.1.1.1.1.2" xref="S3.SS4.p3.9.m9.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.cmml"><mi id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.2" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.2.cmml">ğ‡</mi><mo id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.1" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.2" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.2.cmml">ğ‡</mi><mi id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.3" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.3.cmml">p</mi></msub></mrow><mo stretchy="false" id="S3.SS4.p3.9.m9.1.1.1.1.1.1.3" xref="S3.SS4.p3.9.m9.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.SS4.p3.9.m9.1.1.1.1.3" xref="S3.SS4.p3.9.m9.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.9.m9.1b"><apply id="S3.SS4.p3.9.m9.1.1.cmml" xref="S3.SS4.p3.9.m9.1.1"><eq id="S3.SS4.p3.9.m9.1.1.2.cmml" xref="S3.SS4.p3.9.m9.1.1.2"></eq><apply id="S3.SS4.p3.9.m9.1.1.3.cmml" xref="S3.SS4.p3.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.9.m9.1.1.3.1.cmml" xref="S3.SS4.p3.9.m9.1.1.3">subscript</csymbol><ci id="S3.SS4.p3.9.m9.1.1.3.2.cmml" xref="S3.SS4.p3.9.m9.1.1.3.2">â„’</ci><apply id="S3.SS4.p3.9.m9.1.1.3.3.cmml" xref="S3.SS4.p3.9.m9.1.1.3.3"><times id="S3.SS4.p3.9.m9.1.1.3.3.1.cmml" xref="S3.SS4.p3.9.m9.1.1.3.3.1"></times><ci id="S3.SS4.p3.9.m9.1.1.3.3.2.cmml" xref="S3.SS4.p3.9.m9.1.1.3.3.2">â„</ci><ci id="S3.SS4.p3.9.m9.1.1.3.3.3.cmml" xref="S3.SS4.p3.9.m9.1.1.3.3.3">ğ‘’</ci><ci id="S3.SS4.p3.9.m9.1.1.3.3.4.cmml" xref="S3.SS4.p3.9.m9.1.1.3.3.4">ğ‘</ci><ci id="S3.SS4.p3.9.m9.1.1.3.3.5.cmml" xref="S3.SS4.p3.9.m9.1.1.3.3.5">ğ‘¡</ci></apply></apply><apply id="S3.SS4.p3.9.m9.1.1.1.cmml" xref="S3.SS4.p3.9.m9.1.1.1"><times id="S3.SS4.p3.9.m9.1.1.1.2.cmml" xref="S3.SS4.p3.9.m9.1.1.1.2"></times><apply id="S3.SS4.p3.9.m9.1.1.1.3.cmml" xref="S3.SS4.p3.9.m9.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.9.m9.1.1.1.3.1.cmml" xref="S3.SS4.p3.9.m9.1.1.1.3">subscript</csymbol><ci id="S3.SS4.p3.9.m9.1.1.1.3.2.cmml" xref="S3.SS4.p3.9.m9.1.1.1.3.2">ğœ†</ci><apply id="S3.SS4.p3.9.m9.1.1.1.3.3.cmml" xref="S3.SS4.p3.9.m9.1.1.1.3.3"><times id="S3.SS4.p3.9.m9.1.1.1.3.3.1.cmml" xref="S3.SS4.p3.9.m9.1.1.1.3.3.1"></times><ci id="S3.SS4.p3.9.m9.1.1.1.3.3.2.cmml" xref="S3.SS4.p3.9.m9.1.1.1.3.3.2">â„</ci><ci id="S3.SS4.p3.9.m9.1.1.1.3.3.3.cmml" xref="S3.SS4.p3.9.m9.1.1.1.3.3.3">ğ‘’</ci><ci id="S3.SS4.p3.9.m9.1.1.1.3.3.4.cmml" xref="S3.SS4.p3.9.m9.1.1.1.3.3.4">ğ‘</ci><ci id="S3.SS4.p3.9.m9.1.1.1.3.3.5.cmml" xref="S3.SS4.p3.9.m9.1.1.1.3.3.5">ğ‘¡</ci></apply></apply><apply id="S3.SS4.p3.9.m9.1.1.1.1.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.9.m9.1.1.1.1.2.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1">subscript</csymbol><apply id="S3.SS4.p3.9.m9.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS4.p3.9.m9.1.1.1.1.1.2.1.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1"><minus id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.1"></minus><ci id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.2.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.2">ğ‡</ci><apply id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.2">ğ‡</ci><ci id="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.1.1.1.3.3">ğ‘</ci></apply></apply></apply><cn type="integer" id="S3.SS4.p3.9.m9.1.1.1.1.3.cmml" xref="S3.SS4.p3.9.m9.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.9.m9.1c">\mathcal{L}_{heat}=\lambda_{heat}\|\mathbf{H}-\mathbf{H}_{p}\|_{2}</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets and Evaluation metrics</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Datasets.</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">Our model is trained and tested on both GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and VideoAttentionTarget <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> datasets. <span id="S4.SS1.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_bold">GazeFollow</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> is a large-scale <em id="S4.SS1.SSS0.Px1.p1.1.2" class="ltx_emph ltx_font_italic">image</em> dataset containing over 122K images in total with more than 130K people. The test images include gaze and head location annotations performed by up to 10 people for a single person in the scene while the training set contains only one annotatorâ€™s judgment indicating gaze and head locations. <span id="S4.SS1.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_bold">VideoAttentionTarget</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> is composed of YouTube <em id="S4.SS1.SSS0.Px1.p1.1.4" class="ltx_emph ltx_font_italic">video</em> clips, each has a length of up to 80 seconds. It includes 109574 in-frame and 54967 out-of-frame gaze annotations together with the head locations. Both the training and test sets contain one gaze annotation per person. Given that we do not use the <em id="S4.SS1.SSS0.Px1.p1.1.5" class="ltx_emph ltx_font_italic">temporal</em> information in our model, we randomly select one image for every 5 consecutive frames, allowing us to avoid overfitting. This setup is the same with SOTAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. 
<br class="ltx_break"></p>
</div>
<div id="S4.SS1.SSS0.Px1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.SSS0.Px1.p2.3" class="ltx_p"><span id="S4.SS1.SSS0.Px1.p2.3.1" class="ltx_text ltx_font_bold">Evaluation Metrics.</span> We evaluate the performance of the proposed method in terms of <span id="S4.SS1.SSS0.Px1.p2.3.2" class="ltx_text ltx_font_bold">gaze target detection</span> and <span id="S4.SS1.SSS0.Px1.p2.3.3" class="ltx_text ltx_font_bold">object class detection and localization</span>. For the former task, we use all standard metricsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> described as follows. <span id="S4.SS1.SSS0.Px1.p2.3.4" class="ltx_text ltx_font_bold">AUC</span> assesses the confidence of the predicted gaze heatmap <span id="S4.SS1.SSS0.Px1.p2.3.5" class="ltx_text ltx_font_italic">w.r.t.</span> the gaze ground-truth. <span id="S4.SS1.SSS0.Px1.p2.3.6" class="ltx_text ltx_font_bold">Distance</span> (Dist.) is the <math id="S4.SS1.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{2}" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.1.m1.1a"><msub id="S4.SS1.SSS0.Px1.p2.1.m1.1.1" xref="S4.SS1.SSS0.Px1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px1.p2.1.m1.1.1.2" xref="S4.SS1.SSS0.Px1.p2.1.m1.1.1.2.cmml">â„’</mi><mn id="S4.SS1.SSS0.Px1.p2.1.m1.1.1.3" xref="S4.SS1.SSS0.Px1.p2.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.1.m1.1b"><apply id="S4.SS1.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p2.1.m1.1.1.2">â„’</ci><cn type="integer" id="S4.SS1.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.1.m1.1c">\mathcal{L}_{2}</annotation></semantics></math> between the ground-truth gaze point and the predicted gaze location, which is the point with the maximum confidence on the gaze heatmap. <span id="S4.SS1.SSS0.Px1.p2.3.7" class="ltx_text ltx_font_bold">Angular Error</span> (Ang. Err.) is the angle between predicted and ground-truth gaze vector. In GazeFollow, it is a standard to declare both the minimum and average distances. <span id="S4.SS1.SSS0.Px1.p2.3.8" class="ltx_text ltx_font_bold">I/O gaze AP</span> is the average precision used to evaluate the <em id="S4.SS1.SSS0.Px1.p2.3.9" class="ltx_emph ltx_font_italic">out-of-frame</em> probability of the gaze in VideoAttentionTarget. We use the standard metric <span id="S4.SS1.SSS0.Px1.p2.3.10" class="ltx_text ltx_font_bold">Mean Average Precision (mAP)</span> for object class detection and localization. In that case, a prediction is correct if the class label of the predicted bounding box and the ground truth bounding box are the same and the Intersection over Union (<math id="S4.SS1.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="IoU" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.2.m2.1a"><mrow id="S4.SS1.SSS0.Px1.p2.2.m2.1.1" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.2" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.1" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.3" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.1a" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.4" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.4.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.2.m2.1b"><apply id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1"><times id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.1"></times><ci id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.2">ğ¼</ci><ci id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.3">ğ‘œ</ci><ci id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.4.cmml" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.4">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.2.m2.1c">IoU</annotation></semantics></math>) between them is greater than a <math id="S4.SS1.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="threshold" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.3.m3.1a"><mrow id="S4.SS1.SSS0.Px1.p2.3.m3.1.1" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.2" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.3" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1a" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.4" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1b" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.5" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1c" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.6" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1d" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.7" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.7.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1e" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.8" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.8.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1f" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.9" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.9.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1g" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.10" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.10.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.3.m3.1b"><apply id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1"><times id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.1"></times><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.2">ğ‘¡</ci><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.3">â„</ci><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.4.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.4">ğ‘Ÿ</ci><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.5.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.5">ğ‘’</ci><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.6.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.6">ğ‘ </ci><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.7.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.7">â„</ci><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.8.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.8">ğ‘œ</ci><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.9.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.9">ğ‘™</ci><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.10.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.10">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.3.m3.1c">threshold</annotation></semantics></math> value.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation details</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.11" class="ltx_p"><math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">â„¬</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">â„¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\mathcal{B}</annotation></semantics></math> is a ResNet-50 pretrained on ImageNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> and the Object Detector Transformer follows the DETRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> architecture. We train all our components (Object Detector Transformer, <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.1a" xref="S4.SS2.p1.2.m2.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.2.m2.1.1.4" xref="S4.SS2.p1.2.m2.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><times id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></times><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">ğ’¢</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">ğ’ª</ci><ci id="S4.SS2.p1.2.m2.1.1.4.cmml" xref="S4.SS2.p1.2.m2.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\mathcal{GOT}\,</annotation></semantics></math>, <span id="S4.SS2.p1.11.1" class="ltx_text ltx_font_italic">Gaze Cone Predictor</span>, and MLPs) with Adam optimizer and a learning rate of <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mn id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.3.m3.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.cmml">Ã—</mo><msup id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml"><mn id="S4.SS2.p1.3.m3.1.1.3.2" xref="S4.SS2.p1.3.m3.1.1.3.2.cmml">10</mn><mrow id="S4.SS2.p1.3.m3.1.1.3.3" xref="S4.SS2.p1.3.m3.1.1.3.3.cmml"><mo id="S4.SS2.p1.3.m3.1.1.3.3a" xref="S4.SS2.p1.3.m3.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p1.3.m3.1.1.3.3.2" xref="S4.SS2.p1.3.m3.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><times id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1"></times><cn type="integer" id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">1</cn><apply id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.3.1.cmml" xref="S4.SS2.p1.3.m3.1.1.3">superscript</csymbol><cn type="integer" id="S4.SS2.p1.3.m3.1.1.3.2.cmml" xref="S4.SS2.p1.3.m3.1.1.3.2">10</cn><apply id="S4.SS2.p1.3.m3.1.1.3.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3.3"><minus id="S4.SS2.p1.3.m3.1.1.3.3.1.cmml" xref="S4.SS2.p1.3.m3.1.1.3.3"></minus><cn type="integer" id="S4.SS2.p1.3.m3.1.1.3.3.2.cmml" xref="S4.SS2.p1.3.m3.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">1\times 10^{-4}</annotation></semantics></math> for 80 epochs, then we drop the learning rate by 10 times and train for 20 epochs. Differently, <math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">â„¬</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><ci id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">â„¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">\mathcal{B}</annotation></semantics></math> has a learning rate 10 times smaller, i.e. <math id="S4.SS2.p1.5.m5.1" class="ltx_Math" alttext="1\times 10^{-5}" display="inline"><semantics id="S4.SS2.p1.5.m5.1a"><mrow id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml"><mn id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.5.m5.1.1.1" xref="S4.SS2.p1.5.m5.1.1.1.cmml">Ã—</mo><msup id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3.cmml"><mn id="S4.SS2.p1.5.m5.1.1.3.2" xref="S4.SS2.p1.5.m5.1.1.3.2.cmml">10</mn><mrow id="S4.SS2.p1.5.m5.1.1.3.3" xref="S4.SS2.p1.5.m5.1.1.3.3.cmml"><mo id="S4.SS2.p1.5.m5.1.1.3.3a" xref="S4.SS2.p1.5.m5.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p1.5.m5.1.1.3.3.2" xref="S4.SS2.p1.5.m5.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1"><times id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1.1"></times><cn type="integer" id="S4.SS2.p1.5.m5.1.1.2.cmml" xref="S4.SS2.p1.5.m5.1.1.2">1</cn><apply id="S4.SS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.5.m5.1.1.3.1.cmml" xref="S4.SS2.p1.5.m5.1.1.3">superscript</csymbol><cn type="integer" id="S4.SS2.p1.5.m5.1.1.3.2.cmml" xref="S4.SS2.p1.5.m5.1.1.3.2">10</cn><apply id="S4.SS2.p1.5.m5.1.1.3.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3.3"><minus id="S4.SS2.p1.5.m5.1.1.3.3.1.cmml" xref="S4.SS2.p1.5.m5.1.1.3.3"></minus><cn type="integer" id="S4.SS2.p1.5.m5.1.1.3.3.2.cmml" xref="S4.SS2.p1.5.m5.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">1\times 10^{-5}</annotation></semantics></math>.
Furthermore, we perform matching between predictions and ground-truth samples as described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.
The FoV angle of the cone predictor is set to <math id="S4.SS2.p1.6.m6.1" class="ltx_Math" alttext="120\degree" display="inline"><semantics id="S4.SS2.p1.6.m6.1a"><mrow id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml"><mn id="S4.SS2.p1.6.m6.1.1.2" xref="S4.SS2.p1.6.m6.1.1.2.cmml">120</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p1.6.m6.1.1.1" xref="S4.SS2.p1.6.m6.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S4.SS2.p1.6.m6.1.1.3" xref="S4.SS2.p1.6.m6.1.1.3.cmml">Â°</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><apply id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1"><times id="S4.SS2.p1.6.m6.1.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1.1"></times><cn type="integer" id="S4.SS2.p1.6.m6.1.1.2.cmml" xref="S4.SS2.p1.6.m6.1.1.2">120</cn><ci id="S4.SS2.p1.6.m6.1.1.3.cmml" xref="S4.SS2.p1.6.m6.1.1.3">Â°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">120\degree</annotation></semantics></math>, corresponding to the binocular FoV of humansÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
<math id="S4.SS2.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S4.SS2.p1.7.m7.1a"><mrow id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.7.m7.1.1.2" xref="S4.SS2.p1.7.m7.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.7.m7.1.1.1" xref="S4.SS2.p1.7.m7.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.7.m7.1.1.3" xref="S4.SS2.p1.7.m7.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.7.m7.1.1.1a" xref="S4.SS2.p1.7.m7.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.7.m7.1.1.4" xref="S4.SS2.p1.7.m7.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><apply id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1"><times id="S4.SS2.p1.7.m7.1.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1.1"></times><ci id="S4.SS2.p1.7.m7.1.1.2.cmml" xref="S4.SS2.p1.7.m7.1.1.2">ğ’¢</ci><ci id="S4.SS2.p1.7.m7.1.1.3.cmml" xref="S4.SS2.p1.7.m7.1.1.3">ğ’ª</ci><ci id="S4.SS2.p1.7.m7.1.1.4.cmml" xref="S4.SS2.p1.7.m7.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">\mathcal{GOT}\,</annotation></semantics></math>keeps only queries of objects classified as heads and with confidence above <math id="S4.SS2.p1.8.m8.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.SS2.p1.8.m8.1a"><mn id="S4.SS2.p1.8.m8.1.1" xref="S4.SS2.p1.8.m8.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m8.1b"><cn type="float" id="S4.SS2.p1.8.m8.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m8.1c">0.5</annotation></semantics></math>. Conversely, the keys and values are those of objects (heads included) with the confidence above <math id="S4.SS2.p1.9.m9.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.SS2.p1.9.m9.1a"><mn id="S4.SS2.p1.9.m9.1.1" xref="S4.SS2.p1.9.m9.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m9.1b"><cn type="float" id="S4.SS2.p1.9.m9.1.1.cmml" xref="S4.SS2.p1.9.m9.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m9.1c">0.5</annotation></semantics></math>, which are not classified as <span id="S4.SS2.p1.11.2" class="ltx_text ltx_font_italic">no-object</span>.
The final loss is the weighted sum of the defined objectives. We set <math id="S4.SS2.p1.10.m10.1" class="ltx_Math" alttext="\lambda_{gious}=2.5" display="inline"><semantics id="S4.SS2.p1.10.m10.1a"><mrow id="S4.SS2.p1.10.m10.1.1" xref="S4.SS2.p1.10.m10.1.1.cmml"><msub id="S4.SS2.p1.10.m10.1.1.2" xref="S4.SS2.p1.10.m10.1.1.2.cmml"><mi id="S4.SS2.p1.10.m10.1.1.2.2" xref="S4.SS2.p1.10.m10.1.1.2.2.cmml">Î»</mi><mrow id="S4.SS2.p1.10.m10.1.1.2.3" xref="S4.SS2.p1.10.m10.1.1.2.3.cmml"><mi id="S4.SS2.p1.10.m10.1.1.2.3.2" xref="S4.SS2.p1.10.m10.1.1.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.10.m10.1.1.2.3.1" xref="S4.SS2.p1.10.m10.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p1.10.m10.1.1.2.3.3" xref="S4.SS2.p1.10.m10.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.10.m10.1.1.2.3.1a" xref="S4.SS2.p1.10.m10.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p1.10.m10.1.1.2.3.4" xref="S4.SS2.p1.10.m10.1.1.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.10.m10.1.1.2.3.1b" xref="S4.SS2.p1.10.m10.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p1.10.m10.1.1.2.3.5" xref="S4.SS2.p1.10.m10.1.1.2.3.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.10.m10.1.1.2.3.1c" xref="S4.SS2.p1.10.m10.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p1.10.m10.1.1.2.3.6" xref="S4.SS2.p1.10.m10.1.1.2.3.6.cmml">s</mi></mrow></msub><mo id="S4.SS2.p1.10.m10.1.1.1" xref="S4.SS2.p1.10.m10.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.10.m10.1.1.3" xref="S4.SS2.p1.10.m10.1.1.3.cmml">2.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.10.m10.1b"><apply id="S4.SS2.p1.10.m10.1.1.cmml" xref="S4.SS2.p1.10.m10.1.1"><eq id="S4.SS2.p1.10.m10.1.1.1.cmml" xref="S4.SS2.p1.10.m10.1.1.1"></eq><apply id="S4.SS2.p1.10.m10.1.1.2.cmml" xref="S4.SS2.p1.10.m10.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.10.m10.1.1.2.1.cmml" xref="S4.SS2.p1.10.m10.1.1.2">subscript</csymbol><ci id="S4.SS2.p1.10.m10.1.1.2.2.cmml" xref="S4.SS2.p1.10.m10.1.1.2.2">ğœ†</ci><apply id="S4.SS2.p1.10.m10.1.1.2.3.cmml" xref="S4.SS2.p1.10.m10.1.1.2.3"><times id="S4.SS2.p1.10.m10.1.1.2.3.1.cmml" xref="S4.SS2.p1.10.m10.1.1.2.3.1"></times><ci id="S4.SS2.p1.10.m10.1.1.2.3.2.cmml" xref="S4.SS2.p1.10.m10.1.1.2.3.2">ğ‘”</ci><ci id="S4.SS2.p1.10.m10.1.1.2.3.3.cmml" xref="S4.SS2.p1.10.m10.1.1.2.3.3">ğ‘–</ci><ci id="S4.SS2.p1.10.m10.1.1.2.3.4.cmml" xref="S4.SS2.p1.10.m10.1.1.2.3.4">ğ‘œ</ci><ci id="S4.SS2.p1.10.m10.1.1.2.3.5.cmml" xref="S4.SS2.p1.10.m10.1.1.2.3.5">ğ‘¢</ci><ci id="S4.SS2.p1.10.m10.1.1.2.3.6.cmml" xref="S4.SS2.p1.10.m10.1.1.2.3.6">ğ‘ </ci></apply></apply><cn type="float" id="S4.SS2.p1.10.m10.1.1.3.cmml" xref="S4.SS2.p1.10.m10.1.1.3">2.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.10.m10.1c">\lambda_{gious}=2.5</annotation></semantics></math> and <math id="S4.SS2.p1.11.m11.1" class="ltx_Math" alttext="\lambda_{heat}=2" display="inline"><semantics id="S4.SS2.p1.11.m11.1a"><mrow id="S4.SS2.p1.11.m11.1.1" xref="S4.SS2.p1.11.m11.1.1.cmml"><msub id="S4.SS2.p1.11.m11.1.1.2" xref="S4.SS2.p1.11.m11.1.1.2.cmml"><mi id="S4.SS2.p1.11.m11.1.1.2.2" xref="S4.SS2.p1.11.m11.1.1.2.2.cmml">Î»</mi><mrow id="S4.SS2.p1.11.m11.1.1.2.3" xref="S4.SS2.p1.11.m11.1.1.2.3.cmml"><mi id="S4.SS2.p1.11.m11.1.1.2.3.2" xref="S4.SS2.p1.11.m11.1.1.2.3.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.11.m11.1.1.2.3.1" xref="S4.SS2.p1.11.m11.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p1.11.m11.1.1.2.3.3" xref="S4.SS2.p1.11.m11.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.11.m11.1.1.2.3.1a" xref="S4.SS2.p1.11.m11.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p1.11.m11.1.1.2.3.4" xref="S4.SS2.p1.11.m11.1.1.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.11.m11.1.1.2.3.1b" xref="S4.SS2.p1.11.m11.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS2.p1.11.m11.1.1.2.3.5" xref="S4.SS2.p1.11.m11.1.1.2.3.5.cmml">t</mi></mrow></msub><mo id="S4.SS2.p1.11.m11.1.1.1" xref="S4.SS2.p1.11.m11.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.11.m11.1.1.3" xref="S4.SS2.p1.11.m11.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.11.m11.1b"><apply id="S4.SS2.p1.11.m11.1.1.cmml" xref="S4.SS2.p1.11.m11.1.1"><eq id="S4.SS2.p1.11.m11.1.1.1.cmml" xref="S4.SS2.p1.11.m11.1.1.1"></eq><apply id="S4.SS2.p1.11.m11.1.1.2.cmml" xref="S4.SS2.p1.11.m11.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.11.m11.1.1.2.1.cmml" xref="S4.SS2.p1.11.m11.1.1.2">subscript</csymbol><ci id="S4.SS2.p1.11.m11.1.1.2.2.cmml" xref="S4.SS2.p1.11.m11.1.1.2.2">ğœ†</ci><apply id="S4.SS2.p1.11.m11.1.1.2.3.cmml" xref="S4.SS2.p1.11.m11.1.1.2.3"><times id="S4.SS2.p1.11.m11.1.1.2.3.1.cmml" xref="S4.SS2.p1.11.m11.1.1.2.3.1"></times><ci id="S4.SS2.p1.11.m11.1.1.2.3.2.cmml" xref="S4.SS2.p1.11.m11.1.1.2.3.2">â„</ci><ci id="S4.SS2.p1.11.m11.1.1.2.3.3.cmml" xref="S4.SS2.p1.11.m11.1.1.2.3.3">ğ‘’</ci><ci id="S4.SS2.p1.11.m11.1.1.2.3.4.cmml" xref="S4.SS2.p1.11.m11.1.1.2.3.4">ğ‘</ci><ci id="S4.SS2.p1.11.m11.1.1.2.3.5.cmml" xref="S4.SS2.p1.11.m11.1.1.2.3.5">ğ‘¡</ci></apply></apply><cn type="integer" id="S4.SS2.p1.11.m11.1.1.3.cmml" xref="S4.SS2.p1.11.m11.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.11.m11.1c">\lambda_{heat}=2</annotation></semantics></math>. The other losses are summed up without any weighting.
We use a SoTA monocular depth estimator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> to obtain depth maps corresponding to each scene image.
Note that we use depth information only for gaze cone building without learning additional depth features.
More details are available in Supp. Mat.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Comparison with State-of-the-Art</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The gaze target detection performance of our method is compared with the SOTA in TableÂ <a href="#S3.T2" title="Table 2 â€£ 3.2 Gaze Cone Predictor â€£ 3 Method â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Recalling that the cropped head images and the head locations are required for traditional methods (i.e., SOTA exceptÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>) and these methods are evaluated when the ground-truth head locations are granted (referred to as â€œHead GTâ€), we proceed with the evaluation procedure ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, summarized as follows. Tu et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> employ additional head detectors to automatically obtain the heads position, which is given to the traditional models, providing their real-world application performance. We inherit the corresponding results fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> and refer to them as â€œRealâ€. For the methods whose â€œRealâ€ results are not provided byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, we obtain the results using RetinaFaceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> to detect heads position. However, we are able to perform this only for the method whose code is publicly available:Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">As we can see from the results, our method only with RGB data outperforms existing SOTA on all datasets for all metrics. Such a performance is important to emphasize since several SOTA perform relatively poorly even though they use multi-modalities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> or temporal data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Particularly, for VideoAttentionTarget <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> dataset, our method achieves better scores compared to many complex methods relying on several pretrained task-specific backbones (e.g., 2D-pose estimation) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> or leveraging the temporal dimensionality of the data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> while both utilize RGB and depth maps.
Our better performance <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">w.r.t.</span> Transformer-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> is also conspicuous.
Furthermore, when both RGB and depth are taken into account, our method performance slightly improves on average. Recalling that we use depth information only during gaze cone production without requiring additional (pretrained) CNN to learn depth features as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> or needing to detect the eyes as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, the corresponding results are momentous. Particularly, our minimum and average distance and mAP results are always the best whether or not others were evaluated within â€œHead GTâ€ or â€œRealâ€ settings. This shows that the proposed method is notably good at predicting if the gaze is located inside or outside the frame, the gaze heatmaps, and eventually, a single pixel gaze point that our model predicts per person is much closer to the ground truth-gaze point.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Study</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.7" class="ltx_p">The ablation study is performed on both GazeFollowÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and VideoAttentionTargetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> datasets, whose results can be found in TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.4 Ablation Study â€£ 4 Experiments â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. 
<br class="ltx_break"><span id="S4.SS4.p1.7.1" class="ltx_text ltx_font_bold">Gaze Object Transformer.</span>
If we do not use <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mrow id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.1" xref="S4.SS4.p1.1.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.1.m1.1.1.3" xref="S4.SS4.p1.1.m1.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.1a" xref="S4.SS4.p1.1.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.1.m1.1.1.4" xref="S4.SS4.p1.1.m1.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><times id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1.1"></times><ci id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">ğ’¢</ci><ci id="S4.SS4.p1.1.m1.1.1.3.cmml" xref="S4.SS4.p1.1.m1.1.1.3">ğ’ª</ci><ci id="S4.SS4.p1.1.m1.1.1.4.cmml" xref="S4.SS4.p1.1.m1.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\mathcal{GOT}\,</annotation></semantics></math>, it is still possible to predict the
gaze heatmap using the features of <math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">\mathcal{D}</annotation></semantics></math>. As seen from the results (first row of the ablations for each dataset), <math id="S4.SS4.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S4.SS4.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><ci id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">\mathcal{D}</annotation></semantics></math> features alone are insufficient to reach SOTA results for gaze target detection. Whereas including <math id="S4.SS4.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S4.SS4.p1.4.m4.1a"><mrow id="S4.SS4.p1.4.m4.1.1" xref="S4.SS4.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.4.m4.1.1.2" xref="S4.SS4.p1.4.m4.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.4.m4.1.1.1" xref="S4.SS4.p1.4.m4.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.4.m4.1.1.3" xref="S4.SS4.p1.4.m4.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.4.m4.1.1.1a" xref="S4.SS4.p1.4.m4.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.4.m4.1.1.4" xref="S4.SS4.p1.4.m4.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.4.m4.1b"><apply id="S4.SS4.p1.4.m4.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1"><times id="S4.SS4.p1.4.m4.1.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1.1"></times><ci id="S4.SS4.p1.4.m4.1.1.2.cmml" xref="S4.SS4.p1.4.m4.1.1.2">ğ’¢</ci><ci id="S4.SS4.p1.4.m4.1.1.3.cmml" xref="S4.SS4.p1.4.m4.1.1.3">ğ’ª</ci><ci id="S4.SS4.p1.4.m4.1.1.4.cmml" xref="S4.SS4.p1.4.m4.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.4.m4.1c">\mathcal{GOT}\,</annotation></semantics></math>boosts the results for all metrics and datasets (second row of the ablations for each dataset). 
<br class="ltx_break"><span id="S4.SS4.p1.7.2" class="ltx_text ltx_font_bold">Object Masking.</span> By definition, Transformer attention attends to every token in a sequence and tries to learn relationships between all elements. In our case, this refers to computing the interaction between every object.
Instead, our design retains only the <span id="S4.SS4.p1.7.3" class="ltx_text ltx_font_italic">queries</span> to be of those elements recognized as heads and <span id="S4.SS4.p1.7.4" class="ltx_text ltx_font_italic">keys</span> and <span id="S4.SS4.p1.7.5" class="ltx_text ltx_font_italic">values</span> to be those of any other object/head. In this way, we obtain an improvement across both datasets for all the metrics (third row of the ablations). Furthermore, we obtain an interpretable attention matrix of interaction between heads and objects. 
<br class="ltx_break"><span id="S4.SS4.p1.7.6" class="ltx_text ltx_font_bold">Gaze Cone and No cone-object Skip.</span>
Gaze cone building assigns a score into <math id="S4.SS4.p1.5.m5.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S4.SS4.p1.5.m5.1a"><mi mathvariant="normal" id="S4.SS4.p1.5.m5.1.1" xref="S4.SS4.p1.5.m5.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.5.m5.1b"><ci id="S4.SS4.p1.5.m5.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.5.m5.1c">\Sigma</annotation></semantics></math> inversely proportional to the distance from the gaze vector for the objects inside the cone. This acts similarly to a temperature to skew the softmax operation inside the attention towards the objects more probable to be looked at. As seen, the gaze cone alone might not be sufficient to improve the performance of the method (fourth row of the table). We attribute this to the cases where we cannot find a meaningful object inside the gaze cone, meaning that the <math id="S4.SS4.p1.6.m6.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S4.SS4.p1.6.m6.1a"><mi mathvariant="normal" id="S4.SS4.p1.6.m6.1.1" xref="S4.SS4.p1.6.m6.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.6.m6.1b"><ci id="S4.SS4.p1.6.m6.1.1.cmml" xref="S4.SS4.p1.6.m6.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.6.m6.1c">\Sigma</annotation></semantics></math> row corresponding to the face is empty, and attention does not operate on any feature, hindering the performance of the <span id="S4.SS4.p1.7.7" class="ltx_text ltx_font_italic">heatmap</span> MLP. To solve this, we design a <span id="S4.SS4.p1.7.8" class="ltx_text ltx_font_italic">no cone-object</span> skip, which allows building a heatmap starting from <math id="S4.SS4.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S4.SS4.p1.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.7.m7.1.1" xref="S4.SS4.p1.7.m7.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.7.m7.1b"><ci id="S4.SS4.p1.7.m7.1.1.cmml" xref="S4.SS4.p1.7.m7.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.7.m7.1c">\mathcal{D}</annotation></semantics></math> features. In such cases, a gating mechanism allows selecting which heatmap to use depending on the presence of objects in the cone. When we use this mechanism in conjunction with cone building (fifth row of the table, aka <span id="S4.SS4.p1.7.9" class="ltx_text ltx_font_italic">full proposed method</span>), we obtain the best results consistently across the datasets, proving the effectiveness of focusing on relevant objects in the scene.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:362pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(65.9pt,-55.0pt) scale(1.43648667625008,1.43648667625008) ;">
<table id="S4.T3.8.8" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" rowspan="2"><span id="S4.T3.1.1.1.1.1" class="ltx_text"><math id="S4.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mrow id="S4.T3.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T3.1.1.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.1.1.m1.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S4.T3.1.1.1.1.1.m1.1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.T3.1.1.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.1.1.m1.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S4.T3.1.1.1.1.1.m1.1.1.1a" xref="S4.T3.1.1.1.1.1.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.T3.1.1.1.1.1.m1.1.1.4" xref="S4.T3.1.1.1.1.1.m1.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1"><times id="S4.T3.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.1"></times><ci id="S4.T3.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.2">ğ’¢</ci><ci id="S4.T3.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.3">ğ’ª</ci><ci id="S4.T3.1.1.1.1.1.m1.1.1.4.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\mathcal{GOT}\,</annotation></semantics></math></span></th>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.1.1.1.2.1" class="ltx_text">OM</span></td>
<td id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.1.1.1.3.1" class="ltx_text">GC</span></td>
<td id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.1.1.1.4.1" class="ltx_text">NOCS</span></td>
<td id="S4.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
</td>
</tr>
<tr id="S4.T3.4.4.4" class="ltx_tr">
<td id="S4.T3.2.2.2.1" class="ltx_td ltx_align_center ltx_border_t">AUC <math id="S4.T3.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T3.2.2.2.1.m1.1.1" xref="S4.T3.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.1.m1.1b"><ci id="S4.T3.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t">Avg. dist. <math id="S4.T3.3.3.3.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.3.3.3.2.m1.1a"><mo stretchy="false" id="S4.T3.3.3.3.2.m1.1.1" xref="S4.T3.3.3.3.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.2.m1.1b"><ci id="S4.T3.3.3.3.2.m1.1.1.cmml" xref="S4.T3.3.3.3.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T3.4.4.4.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">Min. dist. <math id="S4.T3.4.4.4.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.4.4.4.3.m1.1a"><mo stretchy="false" id="S4.T3.4.4.4.3.m1.1.1" xref="S4.T3.4.4.4.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.3.m1.1b"><ci id="S4.T3.4.4.4.3.m1.1.1.cmml" xref="S4.T3.4.4.4.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T3.8.8.9.1" class="ltx_tr">
<th id="S4.T3.8.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T3.8.8.9.1.1.1" class="ltx_text" style="color:#FF0000;">âœ—</span></th>
<td id="S4.T3.8.8.9.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.9.1.2.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.9.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.9.1.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.9.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.9.1.4.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.9.1.5" class="ltx_td ltx_align_center ltx_border_t">0.864</td>
<td id="S4.T3.8.8.9.1.6" class="ltx_td ltx_align_center ltx_border_t">0.110</td>
<td id="S4.T3.8.8.9.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.061</td>
</tr>
<tr id="S4.T3.8.8.10.2" class="ltx_tr">
<th id="S4.T3.8.8.10.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">âœ“</th>
<td id="S4.T3.8.8.10.2.2" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.10.2.2.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.10.2.3" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.10.2.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.10.2.4" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.10.2.4.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.10.2.5" class="ltx_td ltx_align_center">0.918</td>
<td id="S4.T3.8.8.10.2.6" class="ltx_td ltx_align_center">0.075</td>
<td id="S4.T3.8.8.10.2.7" class="ltx_td ltx_nopad_r ltx_align_center">0.038</td>
</tr>
<tr id="S4.T3.8.8.11.3" class="ltx_tr">
<th id="S4.T3.8.8.11.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">âœ“</th>
<td id="S4.T3.8.8.11.3.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T3.8.8.11.3.3" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.11.3.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.11.3.4" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.11.3.4.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.11.3.5" class="ltx_td ltx_align_center">0.919</td>
<td id="S4.T3.8.8.11.3.6" class="ltx_td ltx_align_center">0.073</td>
<td id="S4.T3.8.8.11.3.7" class="ltx_td ltx_nopad_r ltx_align_center">0.033</td>
</tr>
<tr id="S4.T3.8.8.12.4" class="ltx_tr">
<th id="S4.T3.8.8.12.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">âœ“</th>
<td id="S4.T3.8.8.12.4.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T3.8.8.12.4.3" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T3.8.8.12.4.4" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.12.4.4.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.12.4.5" class="ltx_td ltx_align_center">0.905</td>
<td id="S4.T3.8.8.12.4.6" class="ltx_td ltx_align_center">0.090</td>
<td id="S4.T3.8.8.12.4.7" class="ltx_td ltx_nopad_r ltx_align_center">0.051</td>
</tr>
<tr id="S4.T3.8.8.13.5" class="ltx_tr">
<th id="S4.T3.8.8.13.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">âœ“</th>
<td id="S4.T3.8.8.13.5.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T3.8.8.13.5.3" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T3.8.8.13.5.4" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T3.8.8.13.5.5" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.13.5.5.1" class="ltx_text ltx_font_bold">0.922</span></td>
<td id="S4.T3.8.8.13.5.6" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.13.5.6.1" class="ltx_text ltx_font_bold">0.072</span></td>
<td id="S4.T3.8.8.13.5.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.8.8.13.5.7.1" class="ltx_text ltx_font_bold">0.033</span></td>
</tr>
<tr id="S4.T3.5.5.5" class="ltx_tr">
<th id="S4.T3.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" rowspan="2"><span id="S4.T3.5.5.5.1.1" class="ltx_text"><math id="S4.T3.5.5.5.1.1.m1.1" class="ltx_Math" alttext="\mathcal{GOT}\," display="inline"><semantics id="S4.T3.5.5.5.1.1.m1.1a"><mrow id="S4.T3.5.5.5.1.1.m1.1.1" xref="S4.T3.5.5.5.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T3.5.5.5.1.1.m1.1.1.2" xref="S4.T3.5.5.5.1.1.m1.1.1.2.cmml">ğ’¢</mi><mo lspace="0em" rspace="0em" id="S4.T3.5.5.5.1.1.m1.1.1.1" xref="S4.T3.5.5.5.1.1.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.T3.5.5.5.1.1.m1.1.1.3" xref="S4.T3.5.5.5.1.1.m1.1.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S4.T3.5.5.5.1.1.m1.1.1.1a" xref="S4.T3.5.5.5.1.1.m1.1.1.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S4.T3.5.5.5.1.1.m1.1.1.4" xref="S4.T3.5.5.5.1.1.m1.1.1.4.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.1.1.m1.1b"><apply id="S4.T3.5.5.5.1.1.m1.1.1.cmml" xref="S4.T3.5.5.5.1.1.m1.1.1"><times id="S4.T3.5.5.5.1.1.m1.1.1.1.cmml" xref="S4.T3.5.5.5.1.1.m1.1.1.1"></times><ci id="S4.T3.5.5.5.1.1.m1.1.1.2.cmml" xref="S4.T3.5.5.5.1.1.m1.1.1.2">ğ’¢</ci><ci id="S4.T3.5.5.5.1.1.m1.1.1.3.cmml" xref="S4.T3.5.5.5.1.1.m1.1.1.3">ğ’ª</ci><ci id="S4.T3.5.5.5.1.1.m1.1.1.4.cmml" xref="S4.T3.5.5.5.1.1.m1.1.1.4">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.1.1.m1.1c">\mathcal{GOT}\,</annotation></semantics></math></span></th>
<td id="S4.T3.5.5.5.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.5.5.5.2.1" class="ltx_text">OM</span></td>
<td id="S4.T3.5.5.5.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.5.5.5.3.1" class="ltx_text">GC</span></td>
<td id="S4.T3.5.5.5.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.5.5.5.4.1" class="ltx_text">NOCS</span></td>
<td id="S4.T3.5.5.5.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">VideoAttentionTarget <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
</tr>
<tr id="S4.T3.8.8.8" class="ltx_tr">
<td id="S4.T3.6.6.6.1" class="ltx_td ltx_align_center ltx_border_t">AUCÂ <math id="S4.T3.6.6.6.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.6.6.6.1.m1.1a"><mo stretchy="false" id="S4.T3.6.6.6.1.m1.1.1" xref="S4.T3.6.6.6.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.1.m1.1b"><ci id="S4.T3.6.6.6.1.m1.1.1.cmml" xref="S4.T3.6.6.6.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T3.7.7.7.2" class="ltx_td ltx_align_center ltx_border_t">Dist.Â <math id="S4.T3.7.7.7.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.7.7.7.2.m1.1a"><mo stretchy="false" id="S4.T3.7.7.7.2.m1.1.1" xref="S4.T3.7.7.7.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.2.m1.1b"><ci id="S4.T3.7.7.7.2.m1.1.1.cmml" xref="S4.T3.7.7.7.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T3.8.8.8.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">APÂ <math id="S4.T3.8.8.8.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.8.8.8.3.m1.1a"><mo stretchy="false" id="S4.T3.8.8.8.3.m1.1.1" xref="S4.T3.8.8.8.3.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.3.m1.1b"><ci id="S4.T3.8.8.8.3.m1.1.1.cmml" xref="S4.T3.8.8.8.3.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T3.8.8.14.6" class="ltx_tr">
<th id="S4.T3.8.8.14.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T3.8.8.14.6.1.1" class="ltx_text" style="color:#FF0000;">âœ—</span></th>
<td id="S4.T3.8.8.14.6.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.14.6.2.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.14.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.14.6.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.14.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.14.6.4.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.14.6.5" class="ltx_td ltx_align_center ltx_border_t">0.811</td>
<td id="S4.T3.8.8.14.6.6" class="ltx_td ltx_align_center ltx_border_t">0.271</td>
<td id="S4.T3.8.8.14.6.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.77</td>
</tr>
<tr id="S4.T3.8.8.15.7" class="ltx_tr">
<th id="S4.T3.8.8.15.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">âœ“</th>
<td id="S4.T3.8.8.15.7.2" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.15.7.2.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.15.7.3" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.15.7.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.15.7.4" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.15.7.4.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.15.7.5" class="ltx_td ltx_align_center">0.902</td>
<td id="S4.T3.8.8.15.7.6" class="ltx_td ltx_align_center">0.125</td>
<td id="S4.T3.8.8.15.7.7" class="ltx_td ltx_nopad_r ltx_align_center">0.92</td>
</tr>
<tr id="S4.T3.8.8.16.8" class="ltx_tr">
<th id="S4.T3.8.8.16.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">âœ“</th>
<td id="S4.T3.8.8.16.8.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T3.8.8.16.8.3" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.16.8.3.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.16.8.4" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.16.8.4.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.16.8.5" class="ltx_td ltx_align_center">0.907</td>
<td id="S4.T3.8.8.16.8.6" class="ltx_td ltx_align_center">0.112</td>
<td id="S4.T3.8.8.16.8.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.8.8.16.8.7.1" class="ltx_text ltx_font_bold">0.94</span></td>
</tr>
<tr id="S4.T3.8.8.17.9" class="ltx_tr">
<th id="S4.T3.8.8.17.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">âœ“</th>
<td id="S4.T3.8.8.17.9.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T3.8.8.17.9.3" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T3.8.8.17.9.4" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.17.9.4.1" class="ltx_text" style="color:#FF0000;">âœ—</span></td>
<td id="S4.T3.8.8.17.9.5" class="ltx_td ltx_align_center">0.909</td>
<td id="S4.T3.8.8.17.9.6" class="ltx_td ltx_align_center">0.154</td>
<td id="S4.T3.8.8.17.9.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.8.8.17.9.7.1" class="ltx_text ltx_font_bold">0.94</span></td>
</tr>
<tr id="S4.T3.8.8.18.10" class="ltx_tr">
<th id="S4.T3.8.8.18.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">âœ“</th>
<td id="S4.T3.8.8.18.10.2" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S4.T3.8.8.18.10.3" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S4.T3.8.8.18.10.4" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S4.T3.8.8.18.10.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.8.8.18.10.5.1" class="ltx_text ltx_font_bold">0.923</span></td>
<td id="S4.T3.8.8.18.10.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.8.8.18.10.6.1" class="ltx_text ltx_font_bold">0.101</span></td>
<td id="S4.T3.8.8.18.10.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S4.T3.8.8.18.10.7.1" class="ltx_text ltx_font_bold">0.94</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation study on GazeFollowÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and VideoAttentionTargetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. <math id="S4.T3.12.m1.1" class="ltx_Math" alttext="OM" display="inline"><semantics id="S4.T3.12.m1.1b"><mrow id="S4.T3.12.m1.1.1" xref="S4.T3.12.m1.1.1.cmml"><mi id="S4.T3.12.m1.1.1.2" xref="S4.T3.12.m1.1.1.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.T3.12.m1.1.1.1" xref="S4.T3.12.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T3.12.m1.1.1.3" xref="S4.T3.12.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.12.m1.1c"><apply id="S4.T3.12.m1.1.1.cmml" xref="S4.T3.12.m1.1.1"><times id="S4.T3.12.m1.1.1.1.cmml" xref="S4.T3.12.m1.1.1.1"></times><ci id="S4.T3.12.m1.1.1.2.cmml" xref="S4.T3.12.m1.1.1.2">ğ‘‚</ci><ci id="S4.T3.12.m1.1.1.3.cmml" xref="S4.T3.12.m1.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.m1.1d">OM</annotation></semantics></math>, <math id="S4.T3.13.m2.1" class="ltx_Math" alttext="GC" display="inline"><semantics id="S4.T3.13.m2.1b"><mrow id="S4.T3.13.m2.1.1" xref="S4.T3.13.m2.1.1.cmml"><mi id="S4.T3.13.m2.1.1.2" xref="S4.T3.13.m2.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.T3.13.m2.1.1.1" xref="S4.T3.13.m2.1.1.1.cmml">â€‹</mo><mi id="S4.T3.13.m2.1.1.3" xref="S4.T3.13.m2.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.13.m2.1c"><apply id="S4.T3.13.m2.1.1.cmml" xref="S4.T3.13.m2.1.1"><times id="S4.T3.13.m2.1.1.1.cmml" xref="S4.T3.13.m2.1.1.1"></times><ci id="S4.T3.13.m2.1.1.2.cmml" xref="S4.T3.13.m2.1.1.2">ğº</ci><ci id="S4.T3.13.m2.1.1.3.cmml" xref="S4.T3.13.m2.1.1.3">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.m2.1d">GC</annotation></semantics></math>, <math id="S4.T3.14.m3.1" class="ltx_Math" alttext="NCOS" display="inline"><semantics id="S4.T3.14.m3.1b"><mrow id="S4.T3.14.m3.1.1" xref="S4.T3.14.m3.1.1.cmml"><mi id="S4.T3.14.m3.1.1.2" xref="S4.T3.14.m3.1.1.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S4.T3.14.m3.1.1.1" xref="S4.T3.14.m3.1.1.1.cmml">â€‹</mo><mi id="S4.T3.14.m3.1.1.3" xref="S4.T3.14.m3.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.T3.14.m3.1.1.1b" xref="S4.T3.14.m3.1.1.1.cmml">â€‹</mo><mi id="S4.T3.14.m3.1.1.4" xref="S4.T3.14.m3.1.1.4.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.T3.14.m3.1.1.1c" xref="S4.T3.14.m3.1.1.1.cmml">â€‹</mo><mi id="S4.T3.14.m3.1.1.5" xref="S4.T3.14.m3.1.1.5.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.14.m3.1c"><apply id="S4.T3.14.m3.1.1.cmml" xref="S4.T3.14.m3.1.1"><times id="S4.T3.14.m3.1.1.1.cmml" xref="S4.T3.14.m3.1.1.1"></times><ci id="S4.T3.14.m3.1.1.2.cmml" xref="S4.T3.14.m3.1.1.2">ğ‘</ci><ci id="S4.T3.14.m3.1.1.3.cmml" xref="S4.T3.14.m3.1.1.3">ğ¶</ci><ci id="S4.T3.14.m3.1.1.4.cmml" xref="S4.T3.14.m3.1.1.4">ğ‘‚</ci><ci id="S4.T3.14.m3.1.1.5.cmml" xref="S4.T3.14.m3.1.1.5">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.m3.1d">NCOS</annotation></semantics></math> stand for object masking, gaze cone, and <span id="S4.T3.16.1" class="ltx_text ltx_font_italic">no cone-obj</span> skip, respectively.</figcaption>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Gazed-object class detection and localization</h3>

<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:95.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(13.0pt,-2.9pt) scale(1.06404519611885,1.06404519611885) ;">
<table id="S4.T4.6.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.6.6.6" class="ltx_tr">
<th id="S4.T4.6.6.6.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Method</th>
<th id="S4.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"># params.Â <math id="S4.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T4.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T4.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">APÂ <math id="S4.T4.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T4.2.2.2.2.m1.1.1" xref="S4.T4.2.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.m1.1b"><ci id="S4.T4.2.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S4.T4.4.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">AP<sub id="S4.T4.4.4.4.4.1" class="ltx_sub"><span id="S4.T4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">50</span></sub><math id="S4.T4.4.4.4.4.m2.1" class="ltx_Math" alttext="~{}\uparrow" display="inline"><semantics id="S4.T4.4.4.4.4.m2.1a"><mo stretchy="false" id="S4.T4.4.4.4.4.m2.1.1" xref="S4.T4.4.4.4.4.m2.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.4.m2.1b"><ci id="S4.T4.4.4.4.4.m2.1.1.cmml" xref="S4.T4.4.4.4.4.m2.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.4.m2.1c">~{}\uparrow</annotation></semantics></math>
</th>
<th id="S4.T4.6.6.6.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">AP<sub id="S4.T4.6.6.6.6.1" class="ltx_sub"><span id="S4.T4.6.6.6.6.1.1" class="ltx_text ltx_font_italic">75</span></sub>Â <math id="S4.T4.6.6.6.6.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.6.6.6.6.m2.1a"><mo stretchy="false" id="S4.T4.6.6.6.6.m2.1.1" xref="S4.T4.6.6.6.6.m2.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.6.m2.1b"><ci id="S4.T4.6.6.6.6.m2.1.1.cmml" xref="S4.T4.6.6.6.6.m2.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.6.m2.1c">\uparrow</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.6.6.7.1" class="ltx_tr">
<th id="S4.T4.6.6.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</th>
<th id="S4.T4.6.6.7.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">43M</th>
<td id="S4.T4.6.6.7.1.3" class="ltx_td ltx_align_right ltx_border_t">0.01</td>
<td id="S4.T4.6.6.7.1.4" class="ltx_td ltx_align_right ltx_border_t">0.03</td>
<td id="S4.T4.6.6.7.1.5" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t">0.01</td>
</tr>
<tr id="S4.T4.6.6.8.2" class="ltx_tr">
<th id="S4.T4.6.6.8.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> + DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</th>
<th id="S4.T4.6.6.8.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">84M</th>
<td id="S4.T4.6.6.8.2.3" class="ltx_td ltx_align_right">0.04</td>
<td id="S4.T4.6.6.8.2.4" class="ltx_td ltx_align_right">0.12</td>
<td id="S4.T4.6.6.8.2.5" class="ltx_td ltx_nopad_r ltx_align_right">0.02</td>
</tr>
<tr id="S4.T4.6.6.9.3" class="ltx_tr">
<th id="S4.T4.6.6.9.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</th>
<th id="S4.T4.6.6.9.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">97M</th>
<td id="S4.T4.6.6.9.3.3" class="ltx_td ltx_align_right">0.03</td>
<td id="S4.T4.6.6.9.3.4" class="ltx_td ltx_align_right">0.10</td>
<td id="S4.T4.6.6.9.3.5" class="ltx_td ltx_nopad_r ltx_align_right">0.01</td>
</tr>
<tr id="S4.T4.6.6.10.4" class="ltx_tr">
<th id="S4.T4.6.6.10.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Ours</th>
<th id="S4.T4.6.6.10.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T4.6.6.10.4.2.1" class="ltx_text ltx_font_bold">54M</span></th>
<td id="S4.T4.6.6.10.4.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T4.6.6.10.4.3.1" class="ltx_text ltx_font_bold">0.14</span></td>
<td id="S4.T4.6.6.10.4.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T4.6.6.10.4.4.1" class="ltx_text ltx_font_bold">0.22</span></td>
<td id="S4.T4.6.6.10.4.5" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb"><span id="S4.T4.6.6.10.4.5.1" class="ltx_text ltx_font_bold">0.15</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Gazed-object classification and localization performance. The computational complexity is reported in terms of parameters.</figcaption>
</figure>
<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">This section reports the evaluations regarding gazed-object class detection and localization performance.
Our method is notably different from using an auxiliary object detector accompanying a gaze target detection model. Still, in order to empirically highlight the difference, we combine the model of Tu et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
with DETRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> pretrained on COCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. To this end, given a produced gaze heatmap ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, we use the bounding box proposal of DETR which contains the highest value of the heatmap (notice that this is in line with ground-truth gaze heatmap construction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>).
Similarly, we also combined the results of DETR with our modelâ€™s gaze heatmap predictions.
Moreover, we include <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> in the comparisons by determining a bounding box that surrounds the gaze heatmaps of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. In that case, <math id="S4.SS5.p1.1.m1.1" class="ltx_Math" alttext="AP" display="inline"><semantics id="S4.SS5.p1.1.m1.1a"><mrow id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml"><mi id="S4.SS5.p1.1.m1.1.1.2" xref="S4.SS5.p1.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS5.p1.1.m1.1.1.1" xref="S4.SS5.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS5.p1.1.m1.1.1.3" xref="S4.SS5.p1.1.m1.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><apply id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1"><times id="S4.SS5.p1.1.m1.1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1.1"></times><ci id="S4.SS5.p1.1.m1.1.1.2.cmml" xref="S4.SS5.p1.1.m1.1.1.2">ğ´</ci><ci id="S4.SS5.p1.1.m1.1.1.3.cmml" xref="S4.SS5.p1.1.m1.1.1.3">ğ‘ƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">AP</annotation></semantics></math> was calculated only for object locations, discarding the object class prediction.
The corresponding results given in TableÂ <a href="#S4.T4" title="Table 4 â€£ 4.5 Gazed-object class detection and localization â€£ 4 Experiments â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> were performed using the COCO-subset of the GazeFollow dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> providing the ground-truth object class and location information. Notice that our model was not particularly trained on COCO ground-truth object classes and locations but was trained on the full set of the GazeFollow and its <em id="S4.SS5.p1.1.1" class="ltx_emph ltx_font_italic">gaze</em> annotations. Instead, DETR was trained on the full COCO dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. That setting should rather be advantageous for DETR since it is aware of all object classes. Overall, the results show the relative effectiveness of our model for gazed-object prediction while it is also the most efficient in terms of the number of parameters.</p>
</div>
<figure id="S4.T5" class="ltx_table ltx_figure_panel ltx_align_center">
<div id="S4.T5.1" class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" style="width:433.6pt;height:74.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(6.6pt,-1.1pt) scale(1.03133510580906,1.03133510580906) ;">
<table id="S4.T5.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T5.1.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">10%</th>
<th id="S4.T5.1.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">20%</th>
<th id="S4.T5.1.1.1.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">30%</th>
<th id="S4.T5.1.1.1.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">40%</th>
<th id="S4.T5.1.1.1.1.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">50%</th>
<th id="S4.T5.1.1.1.1.7" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">60%</th>
<th id="S4.T5.1.1.1.1.8" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">70%</th>
<th id="S4.T5.1.1.1.1.9" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">80%</th>
<th id="S4.T5.1.1.1.1.10" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">90%</th>
<th id="S4.T5.1.1.1.1.11" class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt">100%</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.2.1" class="ltx_tr">
<th id="S4.T5.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Ours 2D</th>
<td id="S4.T5.1.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">0.980</td>
<td id="S4.T5.1.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">0.977</td>
<td id="S4.T5.1.1.2.1.4" class="ltx_td ltx_align_right ltx_border_t">0.973</td>
<td id="S4.T5.1.1.2.1.5" class="ltx_td ltx_align_right ltx_border_t">0.970</td>
<td id="S4.T5.1.1.2.1.6" class="ltx_td ltx_align_right ltx_border_t">0.964</td>
<td id="S4.T5.1.1.2.1.7" class="ltx_td ltx_align_right ltx_border_t">0.961</td>
<td id="S4.T5.1.1.2.1.8" class="ltx_td ltx_align_right ltx_border_t">0.958</td>
<td id="S4.T5.1.1.2.1.9" class="ltx_td ltx_align_right ltx_border_t">0.954</td>
<td id="S4.T5.1.1.2.1.10" class="ltx_td ltx_align_right ltx_border_t">0.943</td>
<td id="S4.T5.1.1.2.1.11" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t">0.922</td>
</tr>
<tr id="S4.T5.1.1.3.2" class="ltx_tr">
<th id="S4.T5.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours 3D</th>
<td id="S4.T5.1.1.3.2.2" class="ltx_td ltx_align_right">0.980</td>
<td id="S4.T5.1.1.3.2.3" class="ltx_td ltx_align_right">0.977</td>
<td id="S4.T5.1.1.3.2.4" class="ltx_td ltx_align_right">0.972</td>
<td id="S4.T5.1.1.3.2.5" class="ltx_td ltx_align_right">0.967</td>
<td id="S4.T5.1.1.3.2.6" class="ltx_td ltx_align_right">0.961</td>
<td id="S4.T5.1.1.3.2.7" class="ltx_td ltx_align_right">0.957</td>
<td id="S4.T5.1.1.3.2.8" class="ltx_td ltx_align_right">0.953</td>
<td id="S4.T5.1.1.3.2.9" class="ltx_td ltx_align_right">0.950</td>
<td id="S4.T5.1.1.3.2.10" class="ltx_td ltx_align_right">0.944</td>
<td id="S4.T5.1.1.3.2.11" class="ltx_td ltx_nopad_r ltx_align_right">0.922</td>
</tr>
<tr id="S4.T5.1.1.4.3" class="ltx_tr">
<th id="S4.T5.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite></th>
<td id="S4.T5.1.1.4.3.2" class="ltx_td ltx_align_right ltx_border_bb">0.973</td>
<td id="S4.T5.1.1.4.3.3" class="ltx_td ltx_align_right ltx_border_bb">0.967</td>
<td id="S4.T5.1.1.4.3.4" class="ltx_td ltx_align_right ltx_border_bb">0.964</td>
<td id="S4.T5.1.1.4.3.5" class="ltx_td ltx_align_right ltx_border_bb">0.957</td>
<td id="S4.T5.1.1.4.3.6" class="ltx_td ltx_align_right ltx_border_bb">0.953</td>
<td id="S4.T5.1.1.4.3.7" class="ltx_td ltx_align_right ltx_border_bb">0.948</td>
<td id="S4.T5.1.1.4.3.8" class="ltx_td ltx_align_right ltx_border_bb">0.945</td>
<td id="S4.T5.1.1.4.3.9" class="ltx_td ltx_align_right ltx_border_bb">0.940</td>
<td id="S4.T5.1.1.4.3.10" class="ltx_td ltx_align_right ltx_border_bb">0.932</td>
<td id="S4.T5.1.1.4.3.11" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb">0.915</td>
</tr>
</tbody>
</table>
</span></div>
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>AUC between our 2D and 3D method and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> w.r.t. increasing variance levels.</figcaption>
</figure>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>The effect of variance in gaze annotations</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">We compare the AUC of the proposed method with <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> considering the multiple annotations that the GazeFollow datasetâ€™s test split provides. In some cases, the annotatorsâ€™ consensus is low, as highlighted in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, which motivated us to evaluate the methods under different levels of variance across the individual gaze annotations. The calculation of the annotation variance and extensive discussions are given in Supp. Mat. The results presented in TableÂ <a href="#S4.T5" title="Table 5 â€£ 4.5 Gazed-object class detection and localization â€£ 4 Experiments â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> show the permanent better performance of our model both in 2D and 3D <span id="S4.SS6.p1.1.1" class="ltx_text ltx_font_italic">w.r.t.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> while, as expected, with lower variance all methods perform better. We speculate that the lower performance of Ours-3D <span id="S4.SS6.p1.1.2" class="ltx_text ltx_font_italic">w.r.t.</span> Ours-2D can be since the human annotations were collected on 2D images.</p>
</div>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>Qualitative Results</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">We visualize gaze heatmaps of our method and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> in Fig.Â <a href="#S4.F4" title="Figure 4 â€£ 4.7 Qualitative Results â€£ 4 Experiments â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> on the GazeFollow dataset. Our predictions are more accurate compared to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> in line with the quantitative results. Refer to Supp. Mat. for more qualitative results, including some less accurate performance of the proposed method <span id="S4.SS7.p1.1.1" class="ltx_text ltx_font_italic">w.r.t.</span> the ground-truth.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2307.09662/assets/images/qualitatives.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="391" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Qualitative results of our method (bottom) and Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> (middle) <span id="S4.F4.2.1" class="ltx_text ltx_font_italic">w.r.t.</span>Â the ground-truth (top). For simplicity, we show only one personâ€™s gaze.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion &amp; Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We have presented a new end-to-end Transformer-based gaze target detector simultaneously predicting the <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">object class</em> and the <em id="S5.p1.1.2" class="ltx_emph ltx_font_italic">location</em> of the gazed-object. The latter is advantageous <span id="S5.p1.1.3" class="ltx_text ltx_font_italic">w.r.t.</span> prior art as it improves explainability.
Extensive experiments validate our approachâ€™s better performance for gaze behavior understanding, promising its usefulness in real-world human interaction analysis. 
<br class="ltx_break"><span id="S5.p1.1.4" class="ltx_text ltx_font_bold">Broader Impacts.</span>
We target a human-centric task and consequently, our model, in some cases, might need to process human faces. This might result in issues regarding privacy protection, therefore policy review should be considered when using this model in real-world applications. 
<br class="ltx_break"><span id="S5.p1.1.5" class="ltx_text ltx_font_bold">Limitations &amp; Future Work.</span> As expected from a Transformer-based model, our network also has slow convergence, requiring long training epochs. Future work will investigate gaze-target detection within the open-set object detection paradigms.


<br class="ltx_break">
<br class="ltx_break"><span id="S5.p1.1.6" class="ltx_text ltx_font_bold">Acknowledgments.</span> This work was supported by the EU H2020 SPRING (No. 871245) and AI4Media (No. 951911) projects, and the MUR PNRR project FAIR - Future AI Research (PE00000013) funded by the NextGenerationEU. It was carried out in the Vision and Learning joint laboratory of FBK and UNITN.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Henny Admoni and Brian Scassellati.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Social eye gaze in human-robot interaction: a review.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Human-Robot Interaction</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, 6(1):25â€“63, 2017.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Jun Bao, Buyu Liu, and Jun Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Escnet: Gaze target detection with the understanding of 3d scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 14126â€“14135, 2022.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Francesca Capozzi, Cigdem Beyan, Antonio Pierro, Atesh Koul, Vittorio Murino, Stefano Livi, AndrewÂ P Bayliss, Jelena Ristic, and Cristina Becchio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Tracking the leader: Gaze behavior in group interactions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Iscience</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 16:242â€“249, 2019.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Yihua Cheng, Feng Lu, and Xucong Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Appearance-based gaze estimation via evaluation-guided asymmetric regression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. of ECCV</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, September 2018.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Dae-Yong Cho and Min-Koo Kang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Human gaze-aware attentive object detection for ambient intelligence.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Engineering Applications of Artificial Intelligence</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 106:104471, 2021.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Eunji Chong, Nataniel Ruiz, Yongxin Wang, Yun Zhang, Agata Rozga, and JamesÂ M. Rehg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Connecting gaze, scene, and attention: Generalized attention estimation via joint modeling of gaze and scene saliency.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The European Conference on Computer Vision (ECCV)</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, September 2018.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Eunji Chong, Yongxin Wang, Nataniel Ruiz, and JamesÂ M Rehg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Detecting attended visual targets in video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 5396â€“5406, 2020.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
KimÂ M Dalton, BrendonÂ M Nacewicz, Tom Johnstone, HillaryÂ S Schaefer, MortonÂ Ann Gernsbacher, HillÂ H Goldsmith, AndrewÂ L Alexander, and RichardÂ J Davidson.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Gaze fixation and the neural circuitry of face processing in autism.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Nature neuroscience</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 8(4):519â€“526, 2005.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">ImageNet: A Large-Scale Hierarchical Image Database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR09</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, 2009.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Jiankang Deng, Jia Guo, Evangelos Ververas, Irene Kotsia, and Stefanos Zafeiriou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Retinaface: Single-shot multi-level face localisation in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, June 2020.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
SÂ Gareth Edwards, LisaÂ J Stephenson, Mario Dalmaso, and AndrewÂ P Bayliss.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Social orienting in gaze leading: a mechanism for shared attention.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Royal Society B: Biological Sciences</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 282(1812):20151141, 2015.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
NathanÂ J Emery.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">The eyes have it: the neuroethology, function and evolution of social gaze.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Neuroscience &amp; biobehavioral reviews</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, 24(6):581â€“604, 2000.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Yi Fang, Jiapeng Tang, Wang Shen, Wei Shen, Xiao Gu, Li Song, and Guangtao Zhai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Dual attention guided gaze target detection in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 11390â€“11399, 2021.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
KennethÂ Alberto FunesÂ Mora, Florent Monay, and Jean-Marc Odobez.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Eyediap: A database for the development and evaluation of gaze estimation algorithms from rgb and rgb-d cameras.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the symposium on eye tracking research and applications</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 255â€“258, 2014.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Zidong Guo, Zejian Yuan, Chong Zhang, Wanchao Chi, Yonggen Ling, and Shenghao Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Domain adaptation gaze estimation by embedding with prediction consistency.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Asian Conference on Computer Vision</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Anshul Gupta, Samy Tafasca, and Jean-Marc Odobez.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">A modular multimodal architecture for gaze target prediction: Application to privacy-sensitive settings.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 5041â€“5050, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
IanÂ P Howard, BrianÂ J Rogers, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Binocular vision and stereopsis</span><span id="bib.bib17.3.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.4.1" class="ltx_text" style="font-size:90%;">Oxford University Press, USA, 1995.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Zhengxi Hu, Dingye Yang, Shilei Cheng, Lei Zhou, Shichao Wu, and Jingtai Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">We know where they are looking at from the rgb-d camera: Gaze following in 3d.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Instrumentation and Measurement</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 71:1â€“14, 2022.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Tianlei Jin, Qizhi Yu, Shiqiang Zhu, Zheyuan Lin, Jie Ren, Yuanhai Zhou, and Wei Song.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Depth-aware gaze-following via auxiliary networks for robotics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Engineering Applications of Artificial Intelligence</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, 113:104924, 2022.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Glenn Jocher, Ayush Chaurasia, and Jing Qiu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">YOLO by Ultralytics, 2023.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Petr Kellnhofer, Adria Recasens, Simon Stent, Wojciech Matusik, and Antonio Torralba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Gaze360: Physically unconstrained gaze estimation in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 6912â€“6921, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Yin Li, Miao Liu, and Jame Rehg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">In the eye of the beholder: Gaze and actions in first person video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Dongze Lian, Zehao Yu, and Shenghua Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Believe it or not, we know what you are looking at!
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Asian Conference on Computer Vision</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 35â€“50. Springer, 2018.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr DollÃ¡r, and CÂ Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Visionâ€“ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, pages 740â€“755. Springer, 2014.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Michele Mazzamuto, Francesco Ragusa, Antonino Furnari, Giovanni Signorello, and GiovanniÂ Maria Farinella.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Weakly supervised attended object detection using gaze data as annotations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Image Analysis and Processingâ€“ICIAP 2022: 21st International Conference, Lecce, Italy, May 23â€“27, 2022, Proceedings, Part II</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 263â€“274. Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Qiaomu Miao, Minh Hoai, and Dimitris Samaras.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Patch-level gaze distribution prediction for gaze following.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 880â€“889, 2023.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Borna Noureddin, PeterÂ D Lawrence, and CF Man.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">A non-contact device for tracking gaze in a human computer interface.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision and Image Understanding</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:90%;">, 98(1):52â€“82, 2005.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
RenÃ© Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen Koltun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine intelligence</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, 44(3):1623â€“1637, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Keith Rayner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Eye movements in reading and information processing: 20 years of research.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Psychological bulletin</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">, 124(3):372, 1998.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Adria Recasens, Aditya Khosla, Carl Vondrick, and Antonio Torralba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Where are they looking?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, volumeÂ 28. Curran Associates, Inc., 2015.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
AdriÃ  Recasens, Carl Vondrick, Aditya Khosla, and Antonio Torralba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Following gaze in video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, pages 1444â€“1452, 2017.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian Reid, and Silvio Savarese.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Generalized intersection over union.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Boris Schauerte and Rainer Stiefelhagen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">â€œlook at this!â€ learning to guide visual saliency in human-robot interaction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2014 IEEE/RSJ International Conference on Intelligent Robots and Systems</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, pages 995â€“1002, 2014.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Francesco Tonini, Cigdem Beyan, and Elisa Ricci.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Multimodal across domains gaze target detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2022 International Conference on Multimodal Interaction</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 420â€“431, 2022.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Danyang Tu, Xiongkuo Min, Huiyu Duan, Guodong Guo, Guangtao Zhai, and Wei Shen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">End-to-end human-gaze-target detection with transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 2192â€“2200. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Daniel Weber, Wolfgang Fuhl, Andreas Zell, and Enkelejda Kasneci.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Gaze-based object detection in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 Sixth IEEE International Conference on Robotic Computing (IRC)</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, pages 62â€“66, 2022.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Lijun Yin and Michael Reale.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Real time eye tracking for human computer interaction, Nov.Â 11 2014.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">US Patent 8,885,882.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Akishige Yuguchi, Tomoaki Inoue, Gustavo AlfonsoÂ Garcia Ricardez, Ming Ding, Jun Takamatsu, and Tsukasa Ogasawara.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Real-time gazed object identification with a variable point of view using a mobile service robot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, pages 1â€“6. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Kiwon Yun, Yifan Peng, Dimitris Samaras, GregoryÂ J Zelinsky, and TamaraÂ L Berg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Exploring the role of gaze behavior and object detection in scene understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Frontiers in psychology</span><span id="bib.bib39.4.2" class="ltx_text" style="font-size:90%;">, 4:917, 2013.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Deformable DETR: deformable transformers for end-to-end object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">9th International Conference on Learning Representations, ICLR 2021</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>The effect of variance in gaze annotations</h2>

<figure id="A1.F5" class="ltx_figure"><img src="/html/2307.09662/assets/images/fig_variance.png" id="A1.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="896" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>An image from the GazeFollow datasetâ€™s <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> test split which has several annotations for the gaze point with high annotation variance.</figcaption>
</figure>
<figure id="A1.F6" class="ltx_figure"><img src="/html/2307.09662/assets/x1.png" id="A1.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="302" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Performance of Our model (2D and 3D) and Tu et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> <span id="A1.F6.3.1" class="ltx_text ltx_font_italic">w.r.t.</span> the variance in the ground-truth annotations of the GazeFollow dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.</figcaption>
</figure>
<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">As mentioned in the paper, the GazeFollow datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> contains a single gaze point annotation for a single person in a scene in its training split. However, its test splits include several numbers of annotations with respect to a single personâ€™s gaze. The number of annotations can be varying up to 10 different gaze points for each person. Such an annotation procedure would not present an issue if all the annotators reached a consensus regarding the gaze point, however, as also shown in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> the test split annotations of that dataset per person can vary remarkably. An example image and the corresponding gaze points demonstrating the variety across the annotations are given in Fig.Â <a href="#A1.F5" title="Figure 5 â€£ Appendix A The effect of variance in gaze annotations â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p">On the other hand, the standard metric used to make evaluations on this dataset, aka AUC does not consider the (possible) varieties across the annotations.
For this reason, herein as well as in the main paper, we present an additional evaluation procedure, which considers the multiple annotations that GazeFollow test split provides (see Fig.Â <a href="#A1.F6" title="Figure 6 â€£ Appendix A The effect of variance in gaze annotations â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>). That evaluation procedure can be described as follows. For each gaze point annotation corresponding to a single person, we compute its distance to the corresponding average gaze annotation point. We record all the distances for the whole test split and compose a distribution from them. Then, given this distribution, we keep the gaze points falling inside a certain threshold (shown as variance retained in the figure), and we opt for the deciles for easiness of computation. For each decile, we compute the AUC and report it in Fig.Â <a href="#A1.F6" title="Figure 6 â€£ Appendix A The effect of variance in gaze annotations â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. As seen, our method is extremely effective when there is high annotation consensus, <em id="A1.p2.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A1.p2.1.2" class="ltx_text"></span> the distance from the average point falls in the first decile (<em id="A1.p2.1.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A1.p2.1.4" class="ltx_text"></span>, 0-10% variance retained in the figure); the performance slightly decreases until the eighth decile (<em id="A1.p2.1.5" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A1.p2.1.6" class="ltx_text"></span>, 70-80% variance retained in the figure), with the last <math id="A1.p2.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="A1.p2.1.m1.1a"><mrow id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml"><mn id="A1.p2.1.m1.1.1.2" xref="A1.p2.1.m1.1.1.2.cmml">20</mn><mo id="A1.p2.1.m1.1.1.1" xref="A1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><apply id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1"><csymbol cd="latexml" id="A1.p2.1.m1.1.1.1.cmml" xref="A1.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A1.p2.1.m1.1.1.2.cmml" xref="A1.p2.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">20\%</annotation></semantics></math> representing high noise annotations (<em id="A1.p2.1.7" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A1.p2.1.8" class="ltx_text"></span>, 80-100% variance retained in the figure) where the performance lowers at a faster rate. When we compare our performance against the state-of-the-art method ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, one can observe a consistently higher performance for all cases both in 2D and 3D versions of our method. We speculate that the lower performance of Ours-3D <span id="A1.p2.1.9" class="ltx_text ltx_font_italic">w.r.t.</span> Ours-2D can be since the human annotations were collected on 2D images.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Additional evaluation on GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and VideoAttentionTarget <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">TableÂ <a href="#A2.T6" title="Table 6 â€£ Appendix B Additional evaluation on GazeFollow [30] and VideoAttentionTarget [7] â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> reports the <span id="A2.p1.1.1" class="ltx_text ltx_font_italic">Angular Error</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> (i.e. the angle between predicted and ground-truth gaze vector) results and compare it with SOTA. Our method produces the best results out of all, while Ours (3D) is better than Ours (2D).</p>
</div>
<figure id="A2.T6" class="ltx_table">
<div id="A2.T6.9.9" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:30.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-288.1pt,20.5pt) scale(0.429403920349246,0.429403920349246) ;">
<table id="A2.T6.9.9.9" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A2.T6.3.3.3.3" class="ltx_tr">
<th id="A2.T6.3.3.3.3.4" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt"></th>
<th id="A2.T6.3.3.3.3.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Ours (2D)</th>
<th id="A2.T6.3.3.3.3.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Ours (3D)</th>
<th id="A2.T6.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite><sup id="A2.T6.1.1.1.1.1.1" class="ltx_sup"><span id="A2.T6.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">â‹†</span></sup>
</th>
<th id="A2.T6.2.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite><sup id="A2.T6.2.2.2.2.2.1" class="ltx_sup"><span id="A2.T6.2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">â‹†</span></sup>
</th>
<th id="A2.T6.3.3.3.3.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></th>
<th id="A2.T6.3.3.3.3.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite></th>
<th id="A2.T6.3.3.3.3.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite></th>
<th id="A2.T6.3.3.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite><sup id="A2.T6.3.3.3.3.3.1" class="ltx_sup"><span id="A2.T6.3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">â‹†</span></sup>
</th>
<th id="A2.T6.3.3.3.3.10" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite></th>
<th id="A2.T6.3.3.3.3.11" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A2.T6.5.5.5.5" class="ltx_tr">
<th id="A2.T6.4.4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Min. <math id="A2.T6.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A2.T6.4.4.4.4.1.m1.1a"><mo stretchy="false" id="A2.T6.4.4.4.4.1.m1.1.1" xref="A2.T6.4.4.4.4.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A2.T6.4.4.4.4.1.m1.1b"><ci id="A2.T6.4.4.4.4.1.m1.1.1.cmml" xref="A2.T6.4.4.4.4.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.4.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="A2.T6.5.5.5.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">4.0Â°</th>
<th id="A2.T6.5.5.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="A2.T6.5.5.5.5.2.1" class="ltx_text ltx_font_bold">3.5Â°</span> (<math id="A2.T6.5.5.5.5.2.m1.1" class="ltx_Math" alttext="-12.5\%" display="inline"><semantics id="A2.T6.5.5.5.5.2.m1.1a"><mrow id="A2.T6.5.5.5.5.2.m1.1.1" xref="A2.T6.5.5.5.5.2.m1.1.1.cmml"><mo id="A2.T6.5.5.5.5.2.m1.1.1a" xref="A2.T6.5.5.5.5.2.m1.1.1.cmml">âˆ’</mo><mrow id="A2.T6.5.5.5.5.2.m1.1.1.2" xref="A2.T6.5.5.5.5.2.m1.1.1.2.cmml"><mn id="A2.T6.5.5.5.5.2.m1.1.1.2.2" xref="A2.T6.5.5.5.5.2.m1.1.1.2.2.cmml">12.5</mn><mo id="A2.T6.5.5.5.5.2.m1.1.1.2.1" xref="A2.T6.5.5.5.5.2.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T6.5.5.5.5.2.m1.1b"><apply id="A2.T6.5.5.5.5.2.m1.1.1.cmml" xref="A2.T6.5.5.5.5.2.m1.1.1"><minus id="A2.T6.5.5.5.5.2.m1.1.1.1.cmml" xref="A2.T6.5.5.5.5.2.m1.1.1"></minus><apply id="A2.T6.5.5.5.5.2.m1.1.1.2.cmml" xref="A2.T6.5.5.5.5.2.m1.1.1.2"><csymbol cd="latexml" id="A2.T6.5.5.5.5.2.m1.1.1.2.1.cmml" xref="A2.T6.5.5.5.5.2.m1.1.1.2.1">percent</csymbol><cn type="float" id="A2.T6.5.5.5.5.2.m1.1.1.2.2.cmml" xref="A2.T6.5.5.5.5.2.m1.1.1.2.2">12.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.5.5.5.5.2.m1.1c">-12.5\%</annotation></semantics></math>)</th>
<td id="A2.T6.5.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t">6.6Â°</td>
<td id="A2.T6.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">8.1Â°</td>
<td id="A2.T6.5.5.5.5.6" class="ltx_td ltx_align_center ltx_border_t">â€”</td>
<td id="A2.T6.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">â€”</td>
<td id="A2.T6.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">â€”</td>
<td id="A2.T6.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t">9.1Â°</td>
<td id="A2.T6.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_t">8.8Â°</td>
<td id="A2.T6.5.5.5.5.11" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">â€”</td>
</tr>
<tr id="A2.T6.7.7.7.7" class="ltx_tr">
<th id="A2.T6.6.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Avg. <math id="A2.T6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A2.T6.6.6.6.6.1.m1.1a"><mo stretchy="false" id="A2.T6.6.6.6.6.1.m1.1.1" xref="A2.T6.6.6.6.6.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A2.T6.6.6.6.6.1.m1.1b"><ci id="A2.T6.6.6.6.6.1.m1.1.1.cmml" xref="A2.T6.6.6.6.6.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.6.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="A2.T6.7.7.7.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">7.7Â°</th>
<th id="A2.T6.7.7.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="A2.T6.7.7.7.7.2.1" class="ltx_text ltx_font_bold">7.2Â°</span> (<math id="A2.T6.7.7.7.7.2.m1.1" class="ltx_Math" alttext="-6.2\%" display="inline"><semantics id="A2.T6.7.7.7.7.2.m1.1a"><mrow id="A2.T6.7.7.7.7.2.m1.1.1" xref="A2.T6.7.7.7.7.2.m1.1.1.cmml"><mo id="A2.T6.7.7.7.7.2.m1.1.1a" xref="A2.T6.7.7.7.7.2.m1.1.1.cmml">âˆ’</mo><mrow id="A2.T6.7.7.7.7.2.m1.1.1.2" xref="A2.T6.7.7.7.7.2.m1.1.1.2.cmml"><mn id="A2.T6.7.7.7.7.2.m1.1.1.2.2" xref="A2.T6.7.7.7.7.2.m1.1.1.2.2.cmml">6.2</mn><mo id="A2.T6.7.7.7.7.2.m1.1.1.2.1" xref="A2.T6.7.7.7.7.2.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T6.7.7.7.7.2.m1.1b"><apply id="A2.T6.7.7.7.7.2.m1.1.1.cmml" xref="A2.T6.7.7.7.7.2.m1.1.1"><minus id="A2.T6.7.7.7.7.2.m1.1.1.1.cmml" xref="A2.T6.7.7.7.7.2.m1.1.1"></minus><apply id="A2.T6.7.7.7.7.2.m1.1.1.2.cmml" xref="A2.T6.7.7.7.7.2.m1.1.1.2"><csymbol cd="latexml" id="A2.T6.7.7.7.7.2.m1.1.1.2.1.cmml" xref="A2.T6.7.7.7.7.2.m1.1.1.2.1">percent</csymbol><cn type="float" id="A2.T6.7.7.7.7.2.m1.1.1.2.2.cmml" xref="A2.T6.7.7.7.7.2.m1.1.1.2.2">6.2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.7.7.7.7.2.m1.1c">-6.2\%</annotation></semantics></math>)</th>
<td id="A2.T6.7.7.7.7.4" class="ltx_td ltx_align_center">11.0Â°</td>
<td id="A2.T6.7.7.7.7.5" class="ltx_td ltx_align_center">19.5Â°</td>
<td id="A2.T6.7.7.7.7.6" class="ltx_td ltx_align_center">14.8Â°</td>
<td id="A2.T6.7.7.7.7.7" class="ltx_td ltx_align_center">14.6Â°</td>
<td id="A2.T6.7.7.7.7.8" class="ltx_td ltx_align_center">14.9Â°</td>
<td id="A2.T6.7.7.7.7.9" class="ltx_td ltx_align_center">20.5Â°</td>
<td id="A2.T6.7.7.7.7.10" class="ltx_td ltx_align_center">17.6Â°</td>
<td id="A2.T6.7.7.7.7.11" class="ltx_td ltx_nopad_r ltx_align_center">24.0Â°</td>
</tr>
<tr id="A2.T6.9.9.9.9" class="ltx_tr">
<th id="A2.T6.8.8.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">Max. <math id="A2.T6.8.8.8.8.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A2.T6.8.8.8.8.1.m1.1a"><mo stretchy="false" id="A2.T6.8.8.8.8.1.m1.1.1" xref="A2.T6.8.8.8.8.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A2.T6.8.8.8.8.1.m1.1b"><ci id="A2.T6.8.8.8.8.1.m1.1.1.cmml" xref="A2.T6.8.8.8.8.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.8.8.8.8.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="A2.T6.9.9.9.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">20.1Â°</th>
<th id="A2.T6.9.9.9.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="A2.T6.9.9.9.9.2.1" class="ltx_text ltx_font_bold">19.3Â°</span> (<math id="A2.T6.9.9.9.9.2.m1.1" class="ltx_Math" alttext="-3.9\%" display="inline"><semantics id="A2.T6.9.9.9.9.2.m1.1a"><mrow id="A2.T6.9.9.9.9.2.m1.1.1" xref="A2.T6.9.9.9.9.2.m1.1.1.cmml"><mo id="A2.T6.9.9.9.9.2.m1.1.1a" xref="A2.T6.9.9.9.9.2.m1.1.1.cmml">âˆ’</mo><mrow id="A2.T6.9.9.9.9.2.m1.1.1.2" xref="A2.T6.9.9.9.9.2.m1.1.1.2.cmml"><mn id="A2.T6.9.9.9.9.2.m1.1.1.2.2" xref="A2.T6.9.9.9.9.2.m1.1.1.2.2.cmml">3.9</mn><mo id="A2.T6.9.9.9.9.2.m1.1.1.2.1" xref="A2.T6.9.9.9.9.2.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T6.9.9.9.9.2.m1.1b"><apply id="A2.T6.9.9.9.9.2.m1.1.1.cmml" xref="A2.T6.9.9.9.9.2.m1.1.1"><minus id="A2.T6.9.9.9.9.2.m1.1.1.1.cmml" xref="A2.T6.9.9.9.9.2.m1.1.1"></minus><apply id="A2.T6.9.9.9.9.2.m1.1.1.2.cmml" xref="A2.T6.9.9.9.9.2.m1.1.1.2"><csymbol cd="latexml" id="A2.T6.9.9.9.9.2.m1.1.1.2.1.cmml" xref="A2.T6.9.9.9.9.2.m1.1.1.2.1">percent</csymbol><cn type="float" id="A2.T6.9.9.9.9.2.m1.1.1.2.2.cmml" xref="A2.T6.9.9.9.9.2.m1.1.1.2.2">3.9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.9.9.9.9.2.m1.1c">-3.9\%</annotation></semantics></math>)</th>
<td id="A2.T6.9.9.9.9.4" class="ltx_td ltx_align_center ltx_border_bb">22.5Â°</td>
<td id="A2.T6.9.9.9.9.5" class="ltx_td ltx_align_center ltx_border_bb">37.0Â°</td>
<td id="A2.T6.9.9.9.9.6" class="ltx_td ltx_align_center ltx_border_bb">â€”</td>
<td id="A2.T6.9.9.9.9.7" class="ltx_td ltx_align_center ltx_border_bb">â€”</td>
<td id="A2.T6.9.9.9.9.8" class="ltx_td ltx_align_center ltx_border_bb">â€”</td>
<td id="A2.T6.9.9.9.9.9" class="ltx_td ltx_align_center ltx_border_bb">37.9Â°</td>
<td id="A2.T6.9.9.9.9.10" class="ltx_td ltx_align_center ltx_border_bb">â€”</td>
<td id="A2.T6.9.9.9.9.11" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">â€”</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Angular error on GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> <math id="A2.T6.11.11.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="A2.T6.11.11.m1.1b"><mo id="A2.T6.11.11.m1.1.1" xref="A2.T6.11.11.m1.1.1.cmml">â‹†</mo><annotation-xml encoding="MathML-Content" id="A2.T6.11.11.m1.1c"><ci id="A2.T6.11.11.m1.1.1.cmml" xref="A2.T6.11.11.m1.1.1">â‹†</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.11.11.m1.1d">\star</annotation></semantics></math> means our implementation. Improvements are w.r.t. â€œOurs (2D)â€.</figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Implementation Details</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">We implemented our method in PyTorch and relied on the official code of DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> as the backbone.
The heads of DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, <em id="A3.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A3.p1.1.2" class="ltx_text"></span> the two MLPs for object classification and detection, were replaced by two larger MLPs that allow us to predict the location and classification of objects in the scene including the <span id="A3.p1.1.3" class="ltx_text ltx_font_italic">heads</span>. Therefore, the number of classes of objects is adapted to accommodate the <span id="A3.p1.1.4" class="ltx_text ltx_font_italic">head</span> class. We used a SOTA object detector, YOLOv8 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, to pseudo-annotate objects in images that lack object annotations. This has been needed since the used datasets (except the COCO subset of the GazeFollow dataset) do not provide object annotations.
We finetuned the <em id="A3.p1.1.5" class="ltx_emph ltx_font_italic">Object Detector Transformer</em> using head locations given in the used datasets as well as automatically obtained using an additional head detector, RetinaFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, and for other objects extracted from YOLOv8. RetinaFace was necessary (but other head detectors can be also adapted as shown in Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>) as we observed that both Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, and our method could not converge without head annotations of all heads in the image.
The depth images were obtained by processing both datasets with a SOTA monocular depth estimation method called MIDAS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Qualitative Results</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">In this section, we provide additional qualitative results of the gaze heatmaps and the head bounding box of the gaze source (<em id="A4.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A4.p1.1.2" class="ltx_text"></span>, a personâ€™s head) and demonstrate the improved performance of our method <span id="A4.p1.1.3" class="ltx_text ltx_font_italic">w.r.t.</span> the current state-of-the-art (SOTA) for both GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and VideoAttentionTarget <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> datasets. Furthermore, we discuss some example cases in which our method has relatively lower performance (<math id="A4.p1.1.m1.1" class="ltx_Math" alttext="AUC&lt;70\%" display="inline"><semantics id="A4.p1.1.m1.1a"><mrow id="A4.p1.1.m1.1.1" xref="A4.p1.1.m1.1.1.cmml"><mrow id="A4.p1.1.m1.1.1.2" xref="A4.p1.1.m1.1.1.2.cmml"><mi id="A4.p1.1.m1.1.1.2.2" xref="A4.p1.1.m1.1.1.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="A4.p1.1.m1.1.1.2.1" xref="A4.p1.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="A4.p1.1.m1.1.1.2.3" xref="A4.p1.1.m1.1.1.2.3.cmml">U</mi><mo lspace="0em" rspace="0em" id="A4.p1.1.m1.1.1.2.1a" xref="A4.p1.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="A4.p1.1.m1.1.1.2.4" xref="A4.p1.1.m1.1.1.2.4.cmml">C</mi></mrow><mo id="A4.p1.1.m1.1.1.1" xref="A4.p1.1.m1.1.1.1.cmml">&lt;</mo><mrow id="A4.p1.1.m1.1.1.3" xref="A4.p1.1.m1.1.1.3.cmml"><mn id="A4.p1.1.m1.1.1.3.2" xref="A4.p1.1.m1.1.1.3.2.cmml">70</mn><mo id="A4.p1.1.m1.1.1.3.1" xref="A4.p1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.1.m1.1b"><apply id="A4.p1.1.m1.1.1.cmml" xref="A4.p1.1.m1.1.1"><lt id="A4.p1.1.m1.1.1.1.cmml" xref="A4.p1.1.m1.1.1.1"></lt><apply id="A4.p1.1.m1.1.1.2.cmml" xref="A4.p1.1.m1.1.1.2"><times id="A4.p1.1.m1.1.1.2.1.cmml" xref="A4.p1.1.m1.1.1.2.1"></times><ci id="A4.p1.1.m1.1.1.2.2.cmml" xref="A4.p1.1.m1.1.1.2.2">ğ´</ci><ci id="A4.p1.1.m1.1.1.2.3.cmml" xref="A4.p1.1.m1.1.1.2.3">ğ‘ˆ</ci><ci id="A4.p1.1.m1.1.1.2.4.cmml" xref="A4.p1.1.m1.1.1.2.4">ğ¶</ci></apply><apply id="A4.p1.1.m1.1.1.3.cmml" xref="A4.p1.1.m1.1.1.3"><csymbol cd="latexml" id="A4.p1.1.m1.1.1.3.1.cmml" xref="A4.p1.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="A4.p1.1.m1.1.1.3.2.cmml" xref="A4.p1.1.m1.1.1.3.2">70</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.1.m1.1c">AUC&lt;70\%</annotation></semantics></math>) <span id="A4.p1.1.4" class="ltx_text ltx_font_italic">w.r.t.</span> ground-truth as well as Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Lastly, we compare our methodsâ€™ versions in 2D and 3D and demonstrate the latterâ€™s effectiveness in challenging scenarios.</p>
</div>
<section id="A4.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Comparison with SOTA and ground-truth.</h4>

<div id="A4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A4.SS0.SSS0.Px1.p1.1" class="ltx_p">Fig.Â <a href="#A4.F7" title="Figure 7 â€£ Comparison with SOTA and ground-truth. â€£ Appendix D Qualitative Results â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and Fig.Â <a href="#A4.F8" title="Figure 8 â€£ Comparison with SOTA and ground-truth. â€£ Appendix D Qualitative Results â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> compare our predictions with respect to the ground truth and the predictions of Tu et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> on both datasets, GazeFollowÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and VideoAttentionTargetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
As we can see, our model precisely predicts the gaze in many scenes where <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> is not able to.
More importantly, we can see that predictions of both our method and Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> are in the field of view of the person whose gaze is to be predicted. However, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> favors image regions closer to the gaze source (<em id="A4.SS0.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A4.SS0.SSS0.Px1.p1.1.2" class="ltx_text"></span> personâ€™s head).</p>
</div>
<figure id="A4.F7" class="ltx_figure"><img src="/html/2307.09662/assets/images/ours_gazefollow_better.jpg" id="A4.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="534" height="823" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Qualitative results of our method (center) and Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> (left) <span id="A4.F7.3.1" class="ltx_text ltx_font_italic">w.r.t.</span> the ground-truth annotations of the GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> dataset (right). Please note that we only show gaze predictions for the person whose gaze is included in the ground truth. The green boxes show the person-in-interest for the ground truth while they are the detected head for Our and Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Even though our method can detect the gaze of multiple persons in the scene simultaneously, for better visualization, we plot the predicted heatmaps and head locations per person.</figcaption>
</figure>
<figure id="A4.F8" class="ltx_figure"><img src="/html/2307.09662/assets/images/ours_videoattention_better.jpg" id="A4.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="436" height="823" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Qualitative results of our method (center) and Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> (left) <span id="A4.F8.3.1" class="ltx_text ltx_font_italic">w.r.t.</span> the ground-truth annotations of the VideoAttentionTarget <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> dataset (right). Please note that we only show gaze predictions for the person whose gaze is included in the ground truth. The green boxes show the person-in-interest for the ground truth while they are the detected head for Our and Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Even though our method can detect the gaze of multiple persons in the scene simultaneously, for better visualization, we plot a single personâ€™s predicted heatmaps and head location.</figcaption>
</figure>
</section>
<section id="A4.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Relatively low-performing predictions.</h4>

<div id="A4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A4.SS0.SSS0.Px2.p1.1" class="ltx_p">Fig.Â <a href="#A4.F9" title="Figure 9 â€£ Relatively low-performing predictions. â€£ Appendix D Qualitative Results â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> presents example images in which our method relatively performs worse. Notice that such images are highly challenging and most of the time also SOTA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> underperform, <span id="A4.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span> in the second row of Fig.Â <a href="#A4.F9" title="Figure 9 â€£ Relatively low-performing predictions. â€£ Appendix D Qualitative Results â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, where the head-pose makes it difficult to accurately predict the gaze.
Conversely, when the face is not fully visible, e.g., in the third and fifth row of Fig.Â <a href="#A4.F9" title="Figure 9 â€£ Relatively low-performing predictions. â€£ Appendix D Qualitative Results â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, we predict scattered heatmaps that cover the gaze point.</p>
</div>
<figure id="A4.F9" class="ltx_figure"><img src="/html/2307.09662/assets/images/ours_2d_failures.jpg" id="A4.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="550" height="823" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Qualitative results in which Our method performs relatively lower since the images are highly challenging due to several reasons (see text for details). Our method (center) and Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> (left) <span id="A4.F9.3.1" class="ltx_text ltx_font_italic">w.r.t.</span> the ground-truth annotations of the GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> dataset (right). The green boxes show the person-in-interest for the ground truth while they are the detected head for Our and Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Even though our method can detect the gaze of multiple persons in the scene simultaneously, for better visualization, we plot a single personâ€™s predicted heatmaps and head location.</figcaption>
</figure>
</section>
<section id="A4.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">The contribution of 3D gaze cone.</h4>

<div id="A4.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="A4.SS0.SSS0.Px3.p1.1" class="ltx_p">Fig.Â <a href="#A4.F10" title="Figure 10 â€£ The contribution of 3D gaze cone. â€£ Appendix D Qualitative Results â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> demonstrates the results of our method with the 2D or 3D gaze cone (see main paper for additional details). This comparison aims to highlight the importance of the 3D cone particularly in challenging scenes.
As the quantitative results in the main paper showed, the advantage of the 3D cone is especially visible in terms of the average and minimum distance between the ground-truth gaze point and the point of maximum confidence of the gaze heatmap. The example images in Fig.Â <a href="#A4.F10" title="Figure 10 â€£ The contribution of 3D gaze cone. â€£ Appendix D Qualitative Results â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> demonstrate that in complex scenes, the 3D gaze vector and the corresponding 3D gaze cone help to decipher which object the person is looking at. Moreover, when the predictions with 2D cone are already high (<span id="A4.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span> the first row of Fig.Â <a href="#A4.F10" title="Figure 10 â€£ The contribution of 3D gaze cone. â€£ Appendix D Qualitative Results â€£ Object-aware Gaze Target Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>), the 3D cone counterpart further consolidates the center of the heatmap towards the object, resulting in better performance.</p>
</div>
<figure id="A4.F10" class="ltx_figure"><img src="/html/2307.09662/assets/images/ours_3d_better.jpg" id="A4.F10.1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="430" height="840" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Qualitative results of our 2D (left) and 3D (center) method <span id="A4.F10.3.1" class="ltx_text ltx_font_italic">w.r.t.</span> the ground-truth annotations of the GazeFollow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> dataset (right), showing the importance of 3D-gaze cone building. Even though our method can detect the gaze of multiple persons in the scene simultaneously, for better visualization, we plot a single personâ€™s predicted heatmaps and head location.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2307.09661" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2307.09662" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2307.09662">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2307.09662" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2307.09663" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Feb 26 21:55:04 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
