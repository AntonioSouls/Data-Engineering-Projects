<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.09810] Semi-Supervised Object Detection for Sorghum Panicles in UAV Imagery</title><meta property="og:description" content="The sorghum panicle is an important trait related to grain yield and plant development.
Detecting and counting sorghum panicles can provide significant information for plant phenotyping.
Current deep-learning-based objâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Semi-Supervised Object Detection for Sorghum Panicles in UAV Imagery">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Semi-Supervised Object Detection for Sorghum Panicles in UAV Imagery">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.09810">

<!--Generated on Thu Feb 29 07:15:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Semi-Supervised Object Detection for Sorghum Panicles in UAV Imagery</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The sorghum panicle is an important trait related to grain yield and plant development.
Detecting and counting sorghum panicles can provide significant information for plant phenotyping.
Current deep-learning-based object detection methods for panicles require a large amount of training data.
The data labeling is time-consuming and not feasible for real application.
In this paper, we present an approach to reduce the amount of training data for sorghum panicle detection via semi-supervised learning.
Results show we can achieve similar performance as supervised methods for sorghum panicle detection by only using 10% of original training data.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">â€”â€‰</span></span>
semi-supervised learning, plant phenotyping, panicle detection, sorghum</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Plant phenotyping is used to find the connection between a plantâ€™s physical properties and the genetic information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
Modern high-throughput plant phenotyping uses Unmanned Aerial Vehicles (UAVs) equipped with multiple sensors to collect imagery <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
The images collected by UAVs can be analyzed to estimate plant traits <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
Sorghum (<span id="S1.p1.1.1" class="ltx_text ltx_font_italic">Sorghum bi-color</span> (L.) Moench) is an important crop for food and biofuel production <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
The Sorghum panicle is a cluster of grains at the top of the plants that is critical to plant growth and management <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
Detecting sorghum panicles can help plant breeders estimate plant properties such as flowering time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
The deep neural network has shown successful results in general object detection tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Recently, deep neural networks have also demonstrated the capability for detection tasks related to plant phenotyping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
However, a large amount images are needed for training the neural network.
Ground truthing a large amount of RGB images captured by UAVs is a major bottleneck relative to the performance of the detection tasks.
Semi-supervised classification approaches train the network with a small amount of labeled data and a large amount of unlabeled data to reduce the manual data labeling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
The use of pseudo-labels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> is the key idea for semi-supervised approaches.
The pseudo-labels are the data labels generated by the model pretrained on the small dataset.
The pseudo-labels are combined with the real labels to expand the training dataset.
A semi-supervised loss is also introduced for training on labeled and unlabeled data.
Recent work focuses on regulating the loss function to maintain consistency during training.
MixMatch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> is an example of consistency regulation.
It uses data augmentation, label guessing, and MixUp on both labeled and unlabeled images.
FixMatch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> is another consistency-based method for semi-supervised classification.
It combines consistency regularization and pseudo-labeling to improve the performance of semi-supervised learning.
Similar to semi-supervised classification, pseudo-label-based approaches are used for semi-supervised object detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
The approach consists of a teacher model and a student model.
The teacher model is trained with a small amount of data at first.
The teacher network will then generate the annotation from the unlabeled dataset to produce pseudo-labels.
The pseudo-labeled data and labeled data are combined to train the student model.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, Sohn <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">et al.</span>Â introduce a framework, STAC, to generate highly confident pseudo labels and update the models by enforcing consistency.
STAC generates pseudo-labels from unlabeled data using non-maximum suppression (NMS).
The confidence-based method is used to filter pseudo-labels.
Unbiased Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> is another framework to jointly train the student and teacher networks in a mutually-beneficial manner.
In this paper, we present a method to train a sorghum panicle detection deep neural network on RGB UAV images with a small amount of training data using semi-supervised learning.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We investigate semi-supervised learning for two-stage and one-stage
object detection methods.
For two-stage object detection, we use the Soft Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> framework with Faster-RCNN.
For one-stage object detection, we choose the Efficient Teacher <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> framework with YOLOv5.
The selection of the detection network is based on the performance of general detection datasets such as COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
Theoretically, both semi-supervised methods are interchangeable with the other object detection method.
However, the performance is degraded if we simply apply one method to another due to the structure difference between one-stage networks and two-stage networks.
In this case, we choose semi-supervised methods that have the best fit for each type of detection network as a fair comparison.
The block diagram of our semi-supervised framework is shown in Figure <a href="#S2.F1" title="Figure 1 â€£ 2 Methods â€£ Semi-Supervised Object Detection for Sorghum Panicles in UAV Imagery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2305.09810/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="242" height="202" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text ltx_font_bold">Fig.Â 1</span>: </span>Block diagram of our semi-supervised learning framework.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Soft Teacher Framework</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">The Soft Teacher framework consists of a teacher model and a student model.
The teacher model is trained using a small batch of labeled data and performs pseudo-labeling on the unlabeled images.
The student model is trained on both labeled and pseudo-labeled images.
During the training process, the teacher model is continuously updated by the student model through an exponential moving average (EMA) strategy.
The loss function of the Soft Teacher is a combined loss function from the supervised and unsupervised loss:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\mathcal{L}=\mathcal{L}_{s}+\alpha\mathcal{L}_{u}" display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml">â„’</mi><mo id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><msub id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.3.2.2" xref="S2.E1.m1.1.1.3.2.2.cmml">â„’</mi><mi id="S2.E1.m1.1.1.3.2.3" xref="S2.E1.m1.1.1.3.2.3.cmml">s</mi></msub><mo id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml">+</mo><mrow id="S2.E1.m1.1.1.3.3" xref="S2.E1.m1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.3.3.2" xref="S2.E1.m1.1.1.3.3.2.cmml">Î±</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.3.1" xref="S2.E1.m1.1.1.3.3.1.cmml">â€‹</mo><msub id="S2.E1.m1.1.1.3.3.3" xref="S2.E1.m1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.3.3.3.2" xref="S2.E1.m1.1.1.3.3.3.2.cmml">â„’</mi><mi id="S2.E1.m1.1.1.3.3.3.3" xref="S2.E1.m1.1.1.3.3.3.3.cmml">u</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"></eq><ci id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2">â„’</ci><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><plus id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"></plus><apply id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2">â„’</ci><ci id="S2.E1.m1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3">ğ‘ </ci></apply><apply id="S2.E1.m1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.3.3"><times id="S2.E1.m1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.3.3.1"></times><ci id="S2.E1.m1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.3.3.2">ğ›¼</ci><apply id="S2.E1.m1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.3.3.1.cmml" xref="S2.E1.m1.1.1.3.3.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.3.3.2.cmml" xref="S2.E1.m1.1.1.3.3.3.2">â„’</ci><ci id="S2.E1.m1.1.1.3.3.3.3.cmml" xref="S2.E1.m1.1.1.3.3.3.3">ğ‘¢</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\mathcal{L}=\mathcal{L}_{s}+\alpha\mathcal{L}_{u}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="\mathcal{L}_{s}=\frac{1}{N_{l}}(\mathcal{L}_{cls}(I_{l}^{i})+\mathcal{L}_{reg}(I_{l}^{i}))" display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><msub id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.3.2" xref="S2.E2.m1.1.1.3.2.cmml">â„’</mi><mi id="S2.E2.m1.1.1.3.3" xref="S2.E2.m1.1.1.3.3.cmml">s</mi></msub><mo id="S2.E2.m1.1.1.2" xref="S2.E2.m1.1.1.2.cmml">=</mo><mrow id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.cmml"><mfrac id="S2.E2.m1.1.1.1.3" xref="S2.E2.m1.1.1.1.3.cmml"><mn id="S2.E2.m1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.3.2.cmml">1</mn><msub id="S2.E2.m1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.3.3.2.cmml">N</mi><mi id="S2.E2.m1.1.1.1.3.3.3" xref="S2.E2.m1.1.1.1.3.3.3.cmml">l</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.2" xref="S2.E2.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.cmml"><msub id="S2.E2.m1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.1.1.1.3.2.cmml">â„’</mi><mrow id="S2.E2.m1.1.1.1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.1.3.3.1" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.1.1.1.1.1.1.1.3.3.3" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.1.3.3.1a" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.1.1.1.1.1.1.1.3.3.4" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.4.cmml">s</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">I</mi><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">l</mi><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.3.cmml">+</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.2.cmml"><msub id="S2.E2.m1.1.1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.1.1.1.1.2.3.2" xref="S2.E2.m1.1.1.1.1.1.1.2.3.2.cmml">â„’</mi><mrow id="S2.E2.m1.1.1.1.1.1.1.2.3.3" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.2.3.3.2" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.2.3.3.1" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.1.1.1.1.1.1.2.3.3.3" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.2.3.3.1a" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.1.1.1.1.1.1.2.3.3.4" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.4.cmml">g</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.2.2" xref="S2.E2.m1.1.1.1.1.1.1.2.2.cmml">â€‹</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.2.1.1" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.2.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><msubsup id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.2" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.2.cmml">I</mi><mi id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.3.cmml">l</mi><mi id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.2.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><eq id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1.2"></eq><apply id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.3.2">â„’</ci><ci id="S2.E2.m1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.3.3">ğ‘ </ci></apply><apply id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"><times id="S2.E2.m1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.2"></times><apply id="S2.E2.m1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.3"><divide id="S2.E2.m1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.3"></divide><cn type="integer" id="S2.E2.m1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.3.2">1</cn><apply id="S2.E2.m1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.3.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.3.3.2">ğ‘</ci><ci id="S2.E2.m1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.1.1.1.3.3.3">ğ‘™</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"><plus id="S2.E2.m1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3"></plus><apply id="S2.E2.m1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1"><times id="S2.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.2"></times><apply id="S2.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.3.2">â„’</ci><apply id="S2.E2.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3"><times id="S2.E2.m1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S2.E2.m1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.2">ğ‘</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.3">ğ‘™</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.3.3.4">ğ‘ </ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.2">ğ¼</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2.3">ğ‘™</ci></apply><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2"><times id="S2.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.2"></times><apply id="S2.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3.2">â„’</ci><apply id="S2.E2.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3"><times id="S2.E2.m1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.1"></times><ci id="S2.E2.m1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.2">ğ‘Ÿ</ci><ci id="S2.E2.m1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.3">ğ‘’</ci><ci id="S2.E2.m1.1.1.1.1.1.1.2.3.3.4.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.3.3.4">ğ‘”</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.2">ğ¼</ci><ci id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.2.3">ğ‘™</ci></apply><ci id="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">\mathcal{L}_{s}=\frac{1}{N_{l}}(\mathcal{L}_{cls}(I_{l}^{i})+\mathcal{L}_{reg}(I_{l}^{i}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.1" class="ltx_Math" alttext="\mathcal{L}_{u}=\frac{1}{N_{u}}(\mathcal{L}_{cls}(I_{u}^{i})+\mathcal{L}_{reg}(I_{u}^{i}))" display="block"><semantics id="S2.E3.m1.1a"><mrow id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml"><msub id="S2.E3.m1.1.1.3" xref="S2.E3.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.1.1.3.2" xref="S2.E3.m1.1.1.3.2.cmml">â„’</mi><mi id="S2.E3.m1.1.1.3.3" xref="S2.E3.m1.1.1.3.3.cmml">u</mi></msub><mo id="S2.E3.m1.1.1.2" xref="S2.E3.m1.1.1.2.cmml">=</mo><mrow id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.cmml"><mfrac id="S2.E3.m1.1.1.1.3" xref="S2.E3.m1.1.1.1.3.cmml"><mn id="S2.E3.m1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.3.2.cmml">1</mn><msub id="S2.E3.m1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.3.3.cmml"><mi id="S2.E3.m1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.3.3.2.cmml">N</mi><mi id="S2.E3.m1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.3.3.3.cmml">u</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.2" xref="S2.E3.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E3.m1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.cmml"><msub id="S2.E3.m1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.3.2.cmml">â„’</mi><mrow id="S2.E3.m1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.1.3.3.1" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.1.3.3.1a" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.1.1.3.3.4" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.4.cmml">s</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">I</mi><mi id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">u</mi><mi id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.3.cmml">+</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.2.cmml"><msub id="S2.E3.m1.1.1.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.1.1.1.1.1.1.2.3.2" xref="S2.E3.m1.1.1.1.1.1.1.2.3.2.cmml">â„’</mi><mrow id="S2.E3.m1.1.1.1.1.1.1.2.3.3" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.2.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.2.3.3.1" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.1.2.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.2.3.3.1a" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.1.1.1.1.1.1.2.3.3.4" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.4.cmml">g</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.1.1.2.2.cmml">â€‹</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.2.1.1" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.1.2.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><msubsup id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.2.cmml">I</mi><mi id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.3.cmml">u</mi><mi id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.1.2.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.1b"><apply id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1"><eq id="S2.E3.m1.1.1.2.cmml" xref="S2.E3.m1.1.1.2"></eq><apply id="S2.E3.m1.1.1.3.cmml" xref="S2.E3.m1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.3.2">â„’</ci><ci id="S2.E3.m1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.3.3">ğ‘¢</ci></apply><apply id="S2.E3.m1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"><times id="S2.E3.m1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.2"></times><apply id="S2.E3.m1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.3"><divide id="S2.E3.m1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.3"></divide><cn type="integer" id="S2.E3.m1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.3.2">1</cn><apply id="S2.E3.m1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.3.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.3.3.2">ğ‘</ci><ci id="S2.E3.m1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.3.3.3">ğ‘¢</ci></apply></apply><apply id="S2.E3.m1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1"><plus id="S2.E3.m1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3"></plus><apply id="S2.E3.m1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1"><times id="S2.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.2"></times><apply id="S2.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.2">â„’</ci><apply id="S2.E3.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3"><times id="S2.E3.m1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S2.E3.m1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.2">ğ‘</ci><ci id="S2.E3.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.3">ğ‘™</ci><ci id="S2.E3.m1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.4">ğ‘ </ci></apply></apply><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.2">ğ¼</ci><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.3">ğ‘¢</ci></apply><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="S2.E3.m1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2"><times id="S2.E3.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.2"></times><apply id="S2.E3.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.2">â„’</ci><apply id="S2.E3.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3"><times id="S2.E3.m1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.1"></times><ci id="S2.E3.m1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.2">ğ‘Ÿ</ci><ci id="S2.E3.m1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.3">ğ‘’</ci><ci id="S2.E3.m1.1.1.1.1.1.1.2.3.3.4.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.4">ğ‘”</ci></apply></apply><apply id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1">superscript</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.2">ğ¼</ci><ci id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.2.3">ğ‘¢</ci></apply><ci id="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.1c">\mathcal{L}_{u}=\frac{1}{N_{u}}(\mathcal{L}_{cls}(I_{u}^{i})+\mathcal{L}_{reg}(I_{u}^{i}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p3.12" class="ltx_p">where <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">â„’</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">â„’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">\mathcal{L}</annotation></semantics></math> is the weighted sum of supervised loss <math id="S2.SS1.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{s}" display="inline"><semantics id="S2.SS1.p3.2.m2.1a"><msub id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.2.m2.1.1.2" xref="S2.SS1.p3.2.m2.1.1.2.cmml">â„’</mi><mi id="S2.SS1.p3.2.m2.1.1.3" xref="S2.SS1.p3.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><apply id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.2.m2.1.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p3.2.m2.1.1.2.cmml" xref="S2.SS1.p3.2.m2.1.1.2">â„’</ci><ci id="S2.SS1.p3.2.m2.1.1.3.cmml" xref="S2.SS1.p3.2.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">\mathcal{L}_{s}</annotation></semantics></math> and unsupervised loss <math id="S2.SS1.p3.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{s}" display="inline"><semantics id="S2.SS1.p3.3.m3.1a"><msub id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.3.m3.1.1.2" xref="S2.SS1.p3.3.m3.1.1.2.cmml">â„’</mi><mi id="S2.SS1.p3.3.m3.1.1.3" xref="S2.SS1.p3.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><apply id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.3.m3.1.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p3.3.m3.1.1.2.cmml" xref="S2.SS1.p3.3.m3.1.1.2">â„’</ci><ci id="S2.SS1.p3.3.m3.1.1.3.cmml" xref="S2.SS1.p3.3.m3.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">\mathcal{L}_{s}</annotation></semantics></math>, <math id="S2.SS1.p3.4.m4.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS1.p3.4.m4.1a"><mi id="S2.SS1.p3.4.m4.1.1" xref="S2.SS1.p3.4.m4.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m4.1b"><ci id="S2.SS1.p3.4.m4.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m4.1c">\alpha</annotation></semantics></math> is the weight for unsupervised loss, <math id="S2.SS1.p3.5.m5.1" class="ltx_Math" alttext="\mathcal{L}_{cls}" display="inline"><semantics id="S2.SS1.p3.5.m5.1a"><msub id="S2.SS1.p3.5.m5.1.1" xref="S2.SS1.p3.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.5.m5.1.1.2" xref="S2.SS1.p3.5.m5.1.1.2.cmml">â„’</mi><mrow id="S2.SS1.p3.5.m5.1.1.3" xref="S2.SS1.p3.5.m5.1.1.3.cmml"><mi id="S2.SS1.p3.5.m5.1.1.3.2" xref="S2.SS1.p3.5.m5.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.5.m5.1.1.3.1" xref="S2.SS1.p3.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS1.p3.5.m5.1.1.3.3" xref="S2.SS1.p3.5.m5.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.5.m5.1.1.3.1a" xref="S2.SS1.p3.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS1.p3.5.m5.1.1.3.4" xref="S2.SS1.p3.5.m5.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m5.1b"><apply id="S2.SS1.p3.5.m5.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m5.1.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p3.5.m5.1.1.2.cmml" xref="S2.SS1.p3.5.m5.1.1.2">â„’</ci><apply id="S2.SS1.p3.5.m5.1.1.3.cmml" xref="S2.SS1.p3.5.m5.1.1.3"><times id="S2.SS1.p3.5.m5.1.1.3.1.cmml" xref="S2.SS1.p3.5.m5.1.1.3.1"></times><ci id="S2.SS1.p3.5.m5.1.1.3.2.cmml" xref="S2.SS1.p3.5.m5.1.1.3.2">ğ‘</ci><ci id="S2.SS1.p3.5.m5.1.1.3.3.cmml" xref="S2.SS1.p3.5.m5.1.1.3.3">ğ‘™</ci><ci id="S2.SS1.p3.5.m5.1.1.3.4.cmml" xref="S2.SS1.p3.5.m5.1.1.3.4">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m5.1c">\mathcal{L}_{cls}</annotation></semantics></math> is the classification loss, <math id="S2.SS1.p3.6.m6.1" class="ltx_Math" alttext="\mathcal{L}_{reg}" display="inline"><semantics id="S2.SS1.p3.6.m6.1a"><msub id="S2.SS1.p3.6.m6.1.1" xref="S2.SS1.p3.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p3.6.m6.1.1.2" xref="S2.SS1.p3.6.m6.1.1.2.cmml">â„’</mi><mrow id="S2.SS1.p3.6.m6.1.1.3" xref="S2.SS1.p3.6.m6.1.1.3.cmml"><mi id="S2.SS1.p3.6.m6.1.1.3.2" xref="S2.SS1.p3.6.m6.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.6.m6.1.1.3.1" xref="S2.SS1.p3.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS1.p3.6.m6.1.1.3.3" xref="S2.SS1.p3.6.m6.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.6.m6.1.1.3.1a" xref="S2.SS1.p3.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS1.p3.6.m6.1.1.3.4" xref="S2.SS1.p3.6.m6.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.6.m6.1b"><apply id="S2.SS1.p3.6.m6.1.1.cmml" xref="S2.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.6.m6.1.1.1.cmml" xref="S2.SS1.p3.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.p3.6.m6.1.1.2.cmml" xref="S2.SS1.p3.6.m6.1.1.2">â„’</ci><apply id="S2.SS1.p3.6.m6.1.1.3.cmml" xref="S2.SS1.p3.6.m6.1.1.3"><times id="S2.SS1.p3.6.m6.1.1.3.1.cmml" xref="S2.SS1.p3.6.m6.1.1.3.1"></times><ci id="S2.SS1.p3.6.m6.1.1.3.2.cmml" xref="S2.SS1.p3.6.m6.1.1.3.2">ğ‘Ÿ</ci><ci id="S2.SS1.p3.6.m6.1.1.3.3.cmml" xref="S2.SS1.p3.6.m6.1.1.3.3">ğ‘’</ci><ci id="S2.SS1.p3.6.m6.1.1.3.4.cmml" xref="S2.SS1.p3.6.m6.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.6.m6.1c">\mathcal{L}_{reg}</annotation></semantics></math> is box classification loss, <math id="S2.SS1.p3.7.m7.1" class="ltx_Math" alttext="I_{u}^{i}" display="inline"><semantics id="S2.SS1.p3.7.m7.1a"><msubsup id="S2.SS1.p3.7.m7.1.1" xref="S2.SS1.p3.7.m7.1.1.cmml"><mi id="S2.SS1.p3.7.m7.1.1.2.2" xref="S2.SS1.p3.7.m7.1.1.2.2.cmml">I</mi><mi id="S2.SS1.p3.7.m7.1.1.2.3" xref="S2.SS1.p3.7.m7.1.1.2.3.cmml">u</mi><mi id="S2.SS1.p3.7.m7.1.1.3" xref="S2.SS1.p3.7.m7.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.7.m7.1b"><apply id="S2.SS1.p3.7.m7.1.1.cmml" xref="S2.SS1.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.7.m7.1.1.1.cmml" xref="S2.SS1.p3.7.m7.1.1">superscript</csymbol><apply id="S2.SS1.p3.7.m7.1.1.2.cmml" xref="S2.SS1.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.7.m7.1.1.2.1.cmml" xref="S2.SS1.p3.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p3.7.m7.1.1.2.2.cmml" xref="S2.SS1.p3.7.m7.1.1.2.2">ğ¼</ci><ci id="S2.SS1.p3.7.m7.1.1.2.3.cmml" xref="S2.SS1.p3.7.m7.1.1.2.3">ğ‘¢</ci></apply><ci id="S2.SS1.p3.7.m7.1.1.3.cmml" xref="S2.SS1.p3.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.7.m7.1c">I_{u}^{i}</annotation></semantics></math> is the <math id="S2.SS1.p3.8.m8.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p3.8.m8.1a"><mi id="S2.SS1.p3.8.m8.1.1" xref="S2.SS1.p3.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.8.m8.1b"><ci id="S2.SS1.p3.8.m8.1.1.cmml" xref="S2.SS1.p3.8.m8.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.8.m8.1c">i</annotation></semantics></math>-th unlabeled image, <math id="S2.SS1.p3.9.m9.1" class="ltx_Math" alttext="I_{l}^{i}" display="inline"><semantics id="S2.SS1.p3.9.m9.1a"><msubsup id="S2.SS1.p3.9.m9.1.1" xref="S2.SS1.p3.9.m9.1.1.cmml"><mi id="S2.SS1.p3.9.m9.1.1.2.2" xref="S2.SS1.p3.9.m9.1.1.2.2.cmml">I</mi><mi id="S2.SS1.p3.9.m9.1.1.2.3" xref="S2.SS1.p3.9.m9.1.1.2.3.cmml">l</mi><mi id="S2.SS1.p3.9.m9.1.1.3" xref="S2.SS1.p3.9.m9.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.9.m9.1b"><apply id="S2.SS1.p3.9.m9.1.1.cmml" xref="S2.SS1.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.9.m9.1.1.1.cmml" xref="S2.SS1.p3.9.m9.1.1">superscript</csymbol><apply id="S2.SS1.p3.9.m9.1.1.2.cmml" xref="S2.SS1.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.9.m9.1.1.2.1.cmml" xref="S2.SS1.p3.9.m9.1.1">subscript</csymbol><ci id="S2.SS1.p3.9.m9.1.1.2.2.cmml" xref="S2.SS1.p3.9.m9.1.1.2.2">ğ¼</ci><ci id="S2.SS1.p3.9.m9.1.1.2.3.cmml" xref="S2.SS1.p3.9.m9.1.1.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p3.9.m9.1.1.3.cmml" xref="S2.SS1.p3.9.m9.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.9.m9.1c">I_{l}^{i}</annotation></semantics></math> is the <math id="S2.SS1.p3.10.m10.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p3.10.m10.1a"><mi id="S2.SS1.p3.10.m10.1.1" xref="S2.SS1.p3.10.m10.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.10.m10.1b"><ci id="S2.SS1.p3.10.m10.1.1.cmml" xref="S2.SS1.p3.10.m10.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.10.m10.1c">i</annotation></semantics></math>-th labeled image, <math id="S2.SS1.p3.11.m11.1" class="ltx_Math" alttext="N_{u}" display="inline"><semantics id="S2.SS1.p3.11.m11.1a"><msub id="S2.SS1.p3.11.m11.1.1" xref="S2.SS1.p3.11.m11.1.1.cmml"><mi id="S2.SS1.p3.11.m11.1.1.2" xref="S2.SS1.p3.11.m11.1.1.2.cmml">N</mi><mi id="S2.SS1.p3.11.m11.1.1.3" xref="S2.SS1.p3.11.m11.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.11.m11.1b"><apply id="S2.SS1.p3.11.m11.1.1.cmml" xref="S2.SS1.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.11.m11.1.1.1.cmml" xref="S2.SS1.p3.11.m11.1.1">subscript</csymbol><ci id="S2.SS1.p3.11.m11.1.1.2.cmml" xref="S2.SS1.p3.11.m11.1.1.2">ğ‘</ci><ci id="S2.SS1.p3.11.m11.1.1.3.cmml" xref="S2.SS1.p3.11.m11.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.11.m11.1c">N_{u}</annotation></semantics></math> is the number of unlabeled image and <math id="S2.SS1.p3.12.m12.1" class="ltx_Math" alttext="N_{l}" display="inline"><semantics id="S2.SS1.p3.12.m12.1a"><msub id="S2.SS1.p3.12.m12.1.1" xref="S2.SS1.p3.12.m12.1.1.cmml"><mi id="S2.SS1.p3.12.m12.1.1.2" xref="S2.SS1.p3.12.m12.1.1.2.cmml">N</mi><mi id="S2.SS1.p3.12.m12.1.1.3" xref="S2.SS1.p3.12.m12.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.12.m12.1b"><apply id="S2.SS1.p3.12.m12.1.1.cmml" xref="S2.SS1.p3.12.m12.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.12.m12.1.1.1.cmml" xref="S2.SS1.p3.12.m12.1.1">subscript</csymbol><ci id="S2.SS1.p3.12.m12.1.1.2.cmml" xref="S2.SS1.p3.12.m12.1.1.2">ğ‘</ci><ci id="S2.SS1.p3.12.m12.1.1.3.cmml" xref="S2.SS1.p3.12.m12.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.12.m12.1c">N_{l}</annotation></semantics></math> is the number of labeled image.
During pseudo-label generation, the NMS and FixMatch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> strategy is used to remove duplicate bounding box candidates.
The high threshold value is also used for pseudo-label generation to improve the quality of pseudo-labels.
The process of pseudo-label generation will introduce error since some foreground box candidates will be assigned as negative.
To compensate for this problem, the Soft Teacher introduces a loss function that uses more information from the teacher model.
The Soft Teacher framework also uses a jittering box refinement technique to filter out duplicate boxes.
The original method from Soft Teacher is training the teacher model and student model at the same time with random weights at the beginning.
In practice, we found the training is not stable due to the limited amount of images in our dataset.
We introduce another warm-up stage for the teacher model.
During the warm-up stage, the teacher model will be trained only with labeled data.
The trained weight will then be loaded into the co-training stage with the student model.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Efficient Teacher Framework</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.6" class="ltx_p">One-stage object detection networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> generally have higher recall and faster training speed compared to two-stage object detection networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
However, the semi-supervised learning approach from two-stage detection networks is facing challenges when directly applied to a one-stage detection network.
The multi-anchor strategy used in the one-stage network magnifies the label imbalance problem from semi-supervised learning in the two-stage network, resulting in low-quality pseudo-labels and poor training results.
Efficient Teacher is a semi-supervised learning approach optimized for single-stage object detection networks.
To leverage the label inconsistency problem, Efficient Teacher introduces a novel pseudo-label assigner to prevent interference from low-quality pseudo-labels.
During training, each pseudo-label is assigned a pseudo-label score that represents the uncertainty of the label.
Two threshold value of the score <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="\tau_{1}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><msub id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">Ï„</mi><mn id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">ğœ</ci><cn type="integer" id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">\tau_{1}</annotation></semantics></math> and <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="\tau_{2}" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><msub id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mi id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml">Ï„</mi><mn id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">ğœ</ci><cn type="integer" id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">\tau_{2}</annotation></semantics></math> is used.
If a pseudo-label has a score between <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="\tau_{1}" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><msub id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">Ï„</mi><mn id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">ğœ</ci><cn type="integer" id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">\tau_{1}</annotation></semantics></math> and <math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="\tau_{2}" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><msub id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">Ï„</mi><mn id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">ğœ</ci><cn type="integer" id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">\tau_{2}</annotation></semantics></math>, the pseudo-label is categorized as an uncertain label.
The loss of uncertain labels is filtered out to improve the performance.
The Efficient Teacher framework also introduces epoch adaptor mechanism to stabilize and accelerate the training process.
Epoch adaptor combines domain adaptation and distribution adaptation techniques.
Domain adaptation enables training on both unlabeled data and labeled data during the first Burn-In phase to prevent overfitting on labeled data.
The distribution adaptation technique dynamically updates the thresholds <math id="S2.SS2.p1.5.m5.1" class="ltx_Math" alttext="\tau_{1}" display="inline"><semantics id="S2.SS2.p1.5.m5.1a"><msub id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml"><mi id="S2.SS2.p1.5.m5.1.1.2" xref="S2.SS2.p1.5.m5.1.1.2.cmml">Ï„</mi><mn id="S2.SS2.p1.5.m5.1.1.3" xref="S2.SS2.p1.5.m5.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><apply id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m5.1.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.p1.5.m5.1.1.2.cmml" xref="S2.SS2.p1.5.m5.1.1.2">ğœ</ci><cn type="integer" id="S2.SS2.p1.5.m5.1.1.3.cmml" xref="S2.SS2.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">\tau_{1}</annotation></semantics></math> and <math id="S2.SS2.p1.6.m6.1" class="ltx_Math" alttext="\tau_{2}" display="inline"><semantics id="S2.SS2.p1.6.m6.1a"><msub id="S2.SS2.p1.6.m6.1.1" xref="S2.SS2.p1.6.m6.1.1.cmml"><mi id="S2.SS2.p1.6.m6.1.1.2" xref="S2.SS2.p1.6.m6.1.1.2.cmml">Ï„</mi><mn id="S2.SS2.p1.6.m6.1.1.3" xref="S2.SS2.p1.6.m6.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m6.1b"><apply id="S2.SS2.p1.6.m6.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.p1.6.m6.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.2">ğœ</ci><cn type="integer" id="S2.SS2.p1.6.m6.1.1.3.cmml" xref="S2.SS2.p1.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m6.1c">\tau_{2}</annotation></semantics></math> at each epoch to reduce overfitting.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Results</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The sorghum panicle dataset is from an RGB orthomosaic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> captured by UAVs in a sorghum field.
We select a small region of the orthomosaic and crop it into small images for data labeling and training purposes as shown in Figure <a href="#S3.F2" title="Figure 2 â€£ 3 Experimental Results â€£ Semi-Supervised Object Detection for Sorghum Panicles in UAV Imagery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
We select the early sorghum growing stage for the experiments.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2305.09810/assets/figures/semi_train_2.jpg" id="S3.F2.g1" class="ltx_graphics ltx_figure_panel ltx_img_portrait" width="240" height="300" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2305.09810/assets/figures/semi_train_3.jpg" id="S3.F2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="240" height="300" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text ltx_font_bold">Fig.Â 2</span>: </span>Sample images from the training dataset.</figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Compared to the later stage, the early-stage sorghum panicles have more variation in shapes and sizes which brings more challenge to the methods.
Moreover, the fewer panicles in each image can further reduce the number of available labels for training.
In total, we have 364 images for training, 90 images for validation, and 60 images for testing.
Each image is resized to 640 <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.p2.1.m1.1a"><mo id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><times id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\times</annotation></semantics></math> 640 resolution during training.
These RGB images are used to form a supervised baseline to compare with semi-supervised learning.
For semi-supervised learning, we randomly select 1%, 5%, and 10% within the training dataset to form a semi-supervised learning dataset.
The labels of the rest of the training data are removed correspondingly to represent the unlabeled data.
We have 3 labeled images for the 1% dataset, 18 labeled images for the 5% dataset, and 36 labeled images for the 10% dataset.
Setting the appropriate training parameters is very important for semi-supervised learning on the limited dataset.
From the empirical experiment, we found the learning rate and NMS threshold for pseudo-labels have the most impact on training performance.
In the supervised learning stage, the learning rate can have a greater learning rate for fast convergence.
In the semi-supervised learning stage, the learning rate needed to be decreased for a very small amount of labeled data.
In practice, we found setting the learning rate of 0.001 for the supervised stage is appropriate for the warm-up of the teacher model.
The default semi-supervised learning rate from both methods is too large, resulting in unstable training.
We found to set the learning rate to 0.00005 is suitable for the semi-supervised stage in both methods.
For the NMS threshold in Efficient Teacher, we set the confidence threshold to 0.5 to reduce the false positive and the IoU threshold to 0.1 to reduce the duplicated bounding box.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">We evaluate the semi-supervised learning approach by using three different settings of the original training dataset: 1%, 5%, and 10% training data.
In the warm-up stage, we first trained the network with only 1%, 5%, and 10% labeled data in a supervised manner to form a baseline.
In the semi-supervised stage, the weights of the baseline model are loaded into the teacher model.
The teacher model with pre-loaded weight is trained with the student model together.
For the Soft Teacher framework, we use Faster-RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> with ResNet-50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> backbone.
For the Efficient Teacher framework, we use the YOLOv5l <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> model.
The result of the Soft Teacher method is shown in Table <a href="#S3.T1" title="Table 1 â€£ 3 Experimental Results â€£ Semi-Supervised Object Detection for Sorghum Panicles in UAV Imagery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the semi-supervised learning increases the mAP by 5.6% in 1% labeled data, 2.5% in 5% labeled data, and 3.7% in 10% labeled data.
The result of the Efficient Teacher method is shown in Table <a href="#S3.T2" title="Table 2 â€£ 3 Experimental Results â€£ Semi-Supervised Object Detection for Sorghum Panicles in UAV Imagery" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the semi-supervised learning increases the mAP by 3.1% in 1% labeled data, 1.7% in 5% labeled data and 1.7% in 10% labeled data.
The Efficient Teacher method achieves the highest mAP due to the better YOLOv5 model in the baseline.
However, the Soft Teacher framework has the highest mAP increases in three scenarios.
The training is done on a single NVIDIA RTX A40 GPU.
The Soft Teacher took 7 hours to finish training while the Efficient Teacher only took one hour to finish.
Compare to supervised learning using fully labeled data (364 images), we can achieve comparable results with only 10% of the original amount (36 images).</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.2.1.1" class="ltx_tr">
<th id="S3.T1.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T1.2.1.1.1.1" class="ltx_text ltx_font_bold">mAP@[.5:.95]</span></th>
<th id="S3.T1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T1.2.1.1.2.1" class="ltx_text ltx_font_bold">Baseline</span></th>
<th id="S3.T1.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T1.2.1.1.3.1" class="ltx_text ltx_font_bold">Soft Teacher</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.2.2.1" class="ltx_tr">
<td id="S3.T1.2.2.1.1" class="ltx_td ltx_align_center ltx_border_t">1%</td>
<td id="S3.T1.2.2.1.2" class="ltx_td ltx_align_center ltx_border_t">38.2</td>
<td id="S3.T1.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.2.1.3.1" class="ltx_text ltx_font_bold">43.8</span></td>
</tr>
<tr id="S3.T1.2.3.2" class="ltx_tr">
<td id="S3.T1.2.3.2.1" class="ltx_td ltx_align_center">5%</td>
<td id="S3.T1.2.3.2.2" class="ltx_td ltx_align_center">42.8</td>
<td id="S3.T1.2.3.2.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.3.2.3.1" class="ltx_text ltx_font_bold">45.3</span></td>
</tr>
<tr id="S3.T1.2.4.3" class="ltx_tr">
<td id="S3.T1.2.4.3.1" class="ltx_td ltx_align_center">10%</td>
<td id="S3.T1.2.4.3.2" class="ltx_td ltx_align_center">43.4</td>
<td id="S3.T1.2.4.3.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.4.3.3.1" class="ltx_text ltx_font_bold">47.1</span></td>
</tr>
<tr id="S3.T1.2.5.4" class="ltx_tr">
<td id="S3.T1.2.5.4.1" class="ltx_td ltx_align_center ltx_border_bb">100%</td>
<td id="S3.T1.2.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">50.2</td>
<td id="S3.T1.2.5.4.3" class="ltx_td ltx_border_bb"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.3.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>Results from Soft Teacher Framework with Faster-RCNN. The baseline is supervised learning only with 1%, 5%, and 10% data accordingly.</figcaption>
</figure>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.2.1.1" class="ltx_tr">
<th id="S3.T2.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T2.2.1.1.1.1" class="ltx_text ltx_font_bold">mAP@[.5:.95]</span></th>
<th id="S3.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T2.2.1.1.2.1" class="ltx_text ltx_font_bold">Baseline</span></th>
<th id="S3.T2.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T2.2.1.1.3.1" class="ltx_text ltx_font_bold">Efficient Teacher</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.2.2.1" class="ltx_tr">
<td id="S3.T2.2.2.1.1" class="ltx_td ltx_align_center ltx_border_t">1%</td>
<td id="S3.T2.2.2.1.2" class="ltx_td ltx_align_center ltx_border_t">38.1</td>
<td id="S3.T2.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.2.2.1.3.1" class="ltx_text ltx_font_bold">41.2</span></td>
</tr>
<tr id="S3.T2.2.3.2" class="ltx_tr">
<td id="S3.T2.2.3.2.1" class="ltx_td ltx_align_center">5%</td>
<td id="S3.T2.2.3.2.2" class="ltx_td ltx_align_center">45.9</td>
<td id="S3.T2.2.3.2.3" class="ltx_td ltx_align_center"><span id="S3.T2.2.3.2.3.1" class="ltx_text ltx_font_bold">47.6</span></td>
</tr>
<tr id="S3.T2.2.4.3" class="ltx_tr">
<td id="S3.T2.2.4.3.1" class="ltx_td ltx_align_center">10%</td>
<td id="S3.T2.2.4.3.2" class="ltx_td ltx_align_center">47.4</td>
<td id="S3.T2.2.4.3.3" class="ltx_td ltx_align_center"><span id="S3.T2.2.4.3.3.1" class="ltx_text ltx_font_bold">49.1</span></td>
</tr>
<tr id="S3.T2.2.5.4" class="ltx_tr">
<td id="S3.T2.2.5.4.1" class="ltx_td ltx_align_center ltx_border_bb">100%</td>
<td id="S3.T2.2.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">51.2</td>
<td id="S3.T2.2.5.4.3" class="ltx_td ltx_border_bb"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.3.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>Results from Efficient Teacher Framework with YOLOv5. The baseline is supervised learning only with 1%, 5%, and 10% data accordingly.</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion and Discussion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this paper, we propose a method for reducing training data in sorghum panicle detection.
We examine two different types of semi-supervised learning approaches for sorghum panicle detection.
We demonstrate the capability of semi-supervised learning methods for achieving similar performance by only using 10% of training data compared to the supervised approach.
Future work includes developing auto-tuning methods for the hyper-parameters and extending the methods to other plant traits.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Acknowledgments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We thank Professor Ayman Habib and the Digital Photogrammetry Research Group (DPRG) from the School of Civil Engineering at Purdue University for providing the images used in this paper. The work presented herein was funded in part by the Advanced Research Projects Agency-Energy (ARPA-E), U.S. Department of Energy, under Award Number DE-AR0001135.
The views and opinions of the authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof.
Address all correspondence to Edward J. Delp, ace@ecn.purdue.edu</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A.Â Walter, F.Â Liebisch, and A.Â Hund,

</span>
<span class="ltx_bibblock">â€œPlant phenotyping: from bean weighing to image analysis,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Plant Methods</span>, vol. 11, no. 1, pp. 1â€“11, March 2015.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
S.Â C. Chapman, T.Â Merz, A.Â Chan, P.Â Jackway, S.Â Hrabar, M.Â F. Dreccer,
E.Â Holland, B.Â Zheng, T.Â J. Ling, and J.Â Jimenez-Berni,

</span>
<span class="ltx_bibblock">â€œPheno-copter: A low-altitude, autonomous remote-sensing robotic
helicopter for high-throughput field-based phenotyping,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Agronomy</span>, vol. 4, no. 2, pp. 279â€“301, June 2014.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A.Â Habib, W.Â Xiong, F.Â He, H.Â L. Yang, and M.Â Crawford,

</span>
<span class="ltx_bibblock">â€œImproving orthorectification of uav-based push-broom scanner
imagery using derived orthophotos from frame cameras,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">IEEE Journal of Selected Topics in Applied Earth Observations
and Remote Sensing</span>, vol. 10, no. 1, pp. 262â€“276, January 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S.Â Mathur, A.Â V. Umakanth, V.Â A. Tonapi, R.Â Sharma, and M.Â K. Sharma,

</span>
<span class="ltx_bibblock">â€œSweet sorghum as biofuel feedstock: recent advances and available
resources,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Biotechnology for Biofuels</span>, vol. 10, June 2017.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
E.Â Cai, S.Â Baireddy, C.Â Yang, E.Â J. Delp, and M.Â Crawford,

</span>
<span class="ltx_bibblock">â€œPanicle counting in uav images for estimating flowering time in
sorghum,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Proceedings of IEEE International Symposium on Geoscience and
Remote Sensing</span>, pp. 6280â€“6283, July 2021,

</span>
<span class="ltx_bibblock">Brussels, Belgium.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S.Â Ren, K.Â He, R.Â Girshick, and J.Â Sun,

</span>
<span class="ltx_bibblock">â€œFaster R-CNN: Towards real-time object detection with region
proposal networks,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>,
vol. 36, no. 6, pp. 1137â€“1149, June 2016.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Z.Â Lin and W.Â Guo,

</span>
<span class="ltx_bibblock">â€œSorghum panicle detection and counting using unmanned aerial system
images and deep learning,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Frontiers in Plant Science</span>, vol. 11, pp. 1346, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y.Â Grandvalet and Y.Â Bengio,

</span>
<span class="ltx_bibblock">â€œSemi-supervised learning by entropy minimization,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proceedings of the Advances in Neural Information Processing
Systems</span>, vol. 17, 2004.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
D.Â Lee,

</span>
<span class="ltx_bibblock">â€œPseudo-label : The simple and efficient semi-supervised learning
method for deep neural networks,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of The International Conference on Machine Learning
Workshop : Challenges in Representation Learning</span>, 07 2013.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
D.Â Berthelot, N.Â Carlini, I.Â Goodfellow, A.Â Oliver, N.Â Papernot, and C.Â Raffel,

</span>
<span class="ltx_bibblock">â€œMixmatch: A holistic approach to semi-supervised learning,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Conference on Neural
Information Processing Systems</span>, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
K.Â Sohn, D.Â Berthelot, C.Â Li, Z.Â Zhang, N.Â Carlini, E.Â D. Cubuk, A.Â Kurakin,
H.Â Zhang, and C.Â Raffel,

</span>
<span class="ltx_bibblock">â€œFixmatch: Simplifying semi-supervised learning with consistency and
confidence,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Conference on Neural
Information Processing Systems</span>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
K.Â Sohn, Z.Â Zhang, C.Â Li, H.Â Zhang, C.Â Lee, and T.Â Pfister,

</span>
<span class="ltx_bibblock">â€œA simple semi-supervised learning framework for object detection,â€

</span>
<span class="ltx_bibblock">2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M.Â Xu, Z.Â Zhang, H.Â Hu, J.Â Wang, L.Â Wang, F.Â Wei, X.Â Bai, and Z.Â Liu,

</span>
<span class="ltx_bibblock">â€œEnd-to-end semi-supervised object detection with soft teacher,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer
Vision</span>, pp. 3040â€“3049, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Y.Â Liu, C.Â Ma, Z.Â He, C.Â Kuo, K.Â Chen, P.Â Zhang, B.Â Wu, Z.Â Kira, and P.Â Vajda,

</span>
<span class="ltx_bibblock">â€œUnbiased teacher for semi-supervised object detection,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Conference on Learning
Representations</span>, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Bowen Xu, Mingtao Chen, Wenlong Guan, and Lulu Hu,

</span>
<span class="ltx_bibblock">â€œEfficient teacher: Semi-supervised object detection for yolov5,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.07577</span>, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
T.Â Lin, M.Â Maire, S.Â Belongie, J.Â Hays, P.Â Perona, D.Â Ramanan, P.Â DollÃ¡r, and
C.Â L. Zitnick,

</span>
<span class="ltx_bibblock">â€œMicrosoft coco: Common objects in context,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Lecture Notes in Computer Science</span>, p. 740â€“755, 2014.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
G.Â Jocher etÂ al.,

</span>
<span class="ltx_bibblock">â€œultralytics/yolov5: v7.0 - YOLOv5 SOTA Realtime Instance
Segmentation,â€ 11 2022,

</span>
<span class="ltx_bibblock">doi: 10.5281/zenodo.7347926.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
K.Â He, X.Â Zhang, S.Â Ren, and J.Â Sun,

</span>
<span class="ltx_bibblock">â€œDeep residual learning for image recognition,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Proceedings of IEEE Conference on Computer Vision and Pattern
Recognition</span>, pp. 770â€“778, June 2016,

</span>
<span class="ltx_bibblock">Las Vegas, NV.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.09809" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.09810" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.09810">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.09810" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.09811" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 07:15:44 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
