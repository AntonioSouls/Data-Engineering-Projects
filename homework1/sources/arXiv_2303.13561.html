<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.13561] MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation</title><meta property="og:description" content="Monocular 3D object detection (Mono3D) in mobile settings (e.g., on a vehicle, a drone, or a robot) is an important yet challenging task. Due to the near-far disparity phenomenon of monocular vision and the ever-changi…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.13561">

<!--Generated on Thu Feb 29 18:29:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yunsong Zhou <sup id="id1.1.id1" class="ltx_sup">1</sup>  
Quan Liu <sup id="id2.2.id2" class="ltx_sup">1</sup>  
Hongzi Zhu <sup id="id3.3.id3" class="ltx_sup">1</sup>   
Yunzhe Li <sup id="id4.4.id4" class="ltx_sup">1</sup>  
Shan Chang <sup id="id5.5.id5" class="ltx_sup">2</sup>  
Minyi Guo <sup id="id6.6.id6" class="ltx_sup">1</sup>   
<br class="ltx_break"><sup id="id7.7.id7" class="ltx_sup">1</sup>Shanghai Jiao Tong University  
<sup id="id8.8.id8" class="ltx_sup">2</sup>Donghua University

<br class="ltx_break"><span id="id9.9.id9" class="ltx_text">{zhouyunsong,liuquan2017,hongzi,yunzhe.li,guo-my}@sjtu.edu.cn</span>  
<span id="id10.10.id10" class="ltx_text">changshan@dhu.edu.cn</span>
</span><span class="ltx_author_notes">Corresponding author.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p">Monocular 3D object detection (Mono3D) in mobile settings (<em id="id11.id1.1" class="ltx_emph ltx_font_italic">e.g.</em>, on a vehicle, a drone, or a robot) is an important yet challenging task. Due to the <em id="id11.id1.2" class="ltx_emph ltx_font_italic">near-far disparity</em> phenomenon of monocular vision and the ever-changing camera pose, it is hard to acquire high detection accuracy, especially for far objects.
Inspired by the insight that the depth of an object can be well determined according to the depth of the ground where it stands, in this paper, we propose a novel Mono3D framework, called <em id="id11.id1.3" class="ltx_emph ltx_font_italic">MoGDE</em>, which constantly estimates the corresponding ground depth of an image and then utilizes the estimated ground depth information to guide Mono3D.
To this end, we utilize a pose detection network to estimate the pose of the camera and then construct a feature map portraying pixel-level ground depth according to the 3D-to-2D perspective geometry.
Moreover, to improve Mono3D with the estimated ground depth, we design an RGB-D feature fusion network based on the transformer structure, where the long-range self-attention mechanism is utilized to effectively identify ground-contacting points and pin the corresponding ground depth to the image feature map.
We conduct extensive experiments on the real-world KITTI dataset. The results demonstrate that MoGDE can effectively improve the Mono3D accuracy and robustness for both near and far objects.
MoGDE yields the best performance compared with the state-of-the-art methods by a large margin and is ranked number one on the KITTI 3D benchmark.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Building on the promising progress achieved in 2D object detection in recent years <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite>, 3D object detection, particularly on moving agents, has received increasing attention from both industry and academia as an important component in many applications, ranging from autonomous vehicles <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> and drones, to robotic manipulation and augmented reality applications.
Compared to LiDAR-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>, <a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a>, <a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">42</span></a>, <a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">43</span></a>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>, <a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">63</span></a>]</cite> and stereo-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>, <a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>, <a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>, <a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite> methods, a much cheaper, more energy-efficient, and easier-to-deploy alternative, <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, monocular 3D object detection (Mono3D), remains an open and challenging research field.
A practical Mono3D detector for moving agents should meet the following two requirements:
1) the 3D bounding box produced by the Mono3D detector should be accurate enough, not only for near objects but also for very distant objects, to secure, for instance, high-priority driving safety applications;
2) the Mono3D detector should remain robust in mobile scenarios, where the camera pose inevitably changes along with the movement of a mobile agent.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.3" class="ltx_p">In the literature, recent Mono3D methods with complex network structures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>, <a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>, <a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite> have achieved considerably high accuracy for near objects, but the predicted 3D bounding boxes for far objects are often <em id="S1.p2.3.1" class="ltx_emph ltx_font_italic">ill-posed</em> due to the lack of depth cues. This huge disparity between near and far objects lies in the nature of monocular vision. Specifically, as depicted in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (a), equal distances of different depth from the camera (<em id="S1.p2.3.2" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S1.p2.1.m1.1" class="ltx_Math" alttext="\Delta z_{1}=\Delta z_{2}" display="inline"><semantics id="S1.p2.1.m1.1a"><mrow id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml"><mrow id="S1.p2.1.m1.1.1.2" xref="S1.p2.1.m1.1.1.2.cmml"><mi mathvariant="normal" id="S1.p2.1.m1.1.1.2.2" xref="S1.p2.1.m1.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.p2.1.m1.1.1.2.1" xref="S1.p2.1.m1.1.1.2.1.cmml">​</mo><msub id="S1.p2.1.m1.1.1.2.3" xref="S1.p2.1.m1.1.1.2.3.cmml"><mi id="S1.p2.1.m1.1.1.2.3.2" xref="S1.p2.1.m1.1.1.2.3.2.cmml">z</mi><mn id="S1.p2.1.m1.1.1.2.3.3" xref="S1.p2.1.m1.1.1.2.3.3.cmml">1</mn></msub></mrow><mo id="S1.p2.1.m1.1.1.1" xref="S1.p2.1.m1.1.1.1.cmml">=</mo><mrow id="S1.p2.1.m1.1.1.3" xref="S1.p2.1.m1.1.1.3.cmml"><mi mathvariant="normal" id="S1.p2.1.m1.1.1.3.2" xref="S1.p2.1.m1.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.p2.1.m1.1.1.3.1" xref="S1.p2.1.m1.1.1.3.1.cmml">​</mo><msub id="S1.p2.1.m1.1.1.3.3" xref="S1.p2.1.m1.1.1.3.3.cmml"><mi id="S1.p2.1.m1.1.1.3.3.2" xref="S1.p2.1.m1.1.1.3.3.2.cmml">z</mi><mn id="S1.p2.1.m1.1.1.3.3.3" xref="S1.p2.1.m1.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><apply id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1"><eq id="S1.p2.1.m1.1.1.1.cmml" xref="S1.p2.1.m1.1.1.1"></eq><apply id="S1.p2.1.m1.1.1.2.cmml" xref="S1.p2.1.m1.1.1.2"><times id="S1.p2.1.m1.1.1.2.1.cmml" xref="S1.p2.1.m1.1.1.2.1"></times><ci id="S1.p2.1.m1.1.1.2.2.cmml" xref="S1.p2.1.m1.1.1.2.2">Δ</ci><apply id="S1.p2.1.m1.1.1.2.3.cmml" xref="S1.p2.1.m1.1.1.2.3"><csymbol cd="ambiguous" id="S1.p2.1.m1.1.1.2.3.1.cmml" xref="S1.p2.1.m1.1.1.2.3">subscript</csymbol><ci id="S1.p2.1.m1.1.1.2.3.2.cmml" xref="S1.p2.1.m1.1.1.2.3.2">𝑧</ci><cn type="integer" id="S1.p2.1.m1.1.1.2.3.3.cmml" xref="S1.p2.1.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S1.p2.1.m1.1.1.3.cmml" xref="S1.p2.1.m1.1.1.3"><times id="S1.p2.1.m1.1.1.3.1.cmml" xref="S1.p2.1.m1.1.1.3.1"></times><ci id="S1.p2.1.m1.1.1.3.2.cmml" xref="S1.p2.1.m1.1.1.3.2">Δ</ci><apply id="S1.p2.1.m1.1.1.3.3.cmml" xref="S1.p2.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S1.p2.1.m1.1.1.3.3.1.cmml" xref="S1.p2.1.m1.1.1.3.3">subscript</csymbol><ci id="S1.p2.1.m1.1.1.3.3.2.cmml" xref="S1.p2.1.m1.1.1.3.3.2">𝑧</ci><cn type="integer" id="S1.p2.1.m1.1.1.3.3.3.cmml" xref="S1.p2.1.m1.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">\Delta z_{1}=\Delta z_{2}</annotation></semantics></math>) have a distinct number of pixels in the image (<em id="S1.p2.3.3" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S1.p2.2.m2.1" class="ltx_Math" alttext="\Delta u_{1}&gt;\Delta u_{2}" display="inline"><semantics id="S1.p2.2.m2.1a"><mrow id="S1.p2.2.m2.1.1" xref="S1.p2.2.m2.1.1.cmml"><mrow id="S1.p2.2.m2.1.1.2" xref="S1.p2.2.m2.1.1.2.cmml"><mi mathvariant="normal" id="S1.p2.2.m2.1.1.2.2" xref="S1.p2.2.m2.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.p2.2.m2.1.1.2.1" xref="S1.p2.2.m2.1.1.2.1.cmml">​</mo><msub id="S1.p2.2.m2.1.1.2.3" xref="S1.p2.2.m2.1.1.2.3.cmml"><mi id="S1.p2.2.m2.1.1.2.3.2" xref="S1.p2.2.m2.1.1.2.3.2.cmml">u</mi><mn id="S1.p2.2.m2.1.1.2.3.3" xref="S1.p2.2.m2.1.1.2.3.3.cmml">1</mn></msub></mrow><mo id="S1.p2.2.m2.1.1.1" xref="S1.p2.2.m2.1.1.1.cmml">&gt;</mo><mrow id="S1.p2.2.m2.1.1.3" xref="S1.p2.2.m2.1.1.3.cmml"><mi mathvariant="normal" id="S1.p2.2.m2.1.1.3.2" xref="S1.p2.2.m2.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.p2.2.m2.1.1.3.1" xref="S1.p2.2.m2.1.1.3.1.cmml">​</mo><msub id="S1.p2.2.m2.1.1.3.3" xref="S1.p2.2.m2.1.1.3.3.cmml"><mi id="S1.p2.2.m2.1.1.3.3.2" xref="S1.p2.2.m2.1.1.3.3.2.cmml">u</mi><mn id="S1.p2.2.m2.1.1.3.3.3" xref="S1.p2.2.m2.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><apply id="S1.p2.2.m2.1.1.cmml" xref="S1.p2.2.m2.1.1"><gt id="S1.p2.2.m2.1.1.1.cmml" xref="S1.p2.2.m2.1.1.1"></gt><apply id="S1.p2.2.m2.1.1.2.cmml" xref="S1.p2.2.m2.1.1.2"><times id="S1.p2.2.m2.1.1.2.1.cmml" xref="S1.p2.2.m2.1.1.2.1"></times><ci id="S1.p2.2.m2.1.1.2.2.cmml" xref="S1.p2.2.m2.1.1.2.2">Δ</ci><apply id="S1.p2.2.m2.1.1.2.3.cmml" xref="S1.p2.2.m2.1.1.2.3"><csymbol cd="ambiguous" id="S1.p2.2.m2.1.1.2.3.1.cmml" xref="S1.p2.2.m2.1.1.2.3">subscript</csymbol><ci id="S1.p2.2.m2.1.1.2.3.2.cmml" xref="S1.p2.2.m2.1.1.2.3.2">𝑢</ci><cn type="integer" id="S1.p2.2.m2.1.1.2.3.3.cmml" xref="S1.p2.2.m2.1.1.2.3.3">1</cn></apply></apply><apply id="S1.p2.2.m2.1.1.3.cmml" xref="S1.p2.2.m2.1.1.3"><times id="S1.p2.2.m2.1.1.3.1.cmml" xref="S1.p2.2.m2.1.1.3.1"></times><ci id="S1.p2.2.m2.1.1.3.2.cmml" xref="S1.p2.2.m2.1.1.3.2">Δ</ci><apply id="S1.p2.2.m2.1.1.3.3.cmml" xref="S1.p2.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S1.p2.2.m2.1.1.3.3.1.cmml" xref="S1.p2.2.m2.1.1.3.3">subscript</csymbol><ci id="S1.p2.2.m2.1.1.3.3.2.cmml" xref="S1.p2.2.m2.1.1.3.3.2">𝑢</ci><cn type="integer" id="S1.p2.2.m2.1.1.3.3.3.cmml" xref="S1.p2.2.m2.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">\Delta u_{1}&gt;\Delta u_{2}</annotation></semantics></math> and <math id="S1.p2.3.m3.1" class="ltx_Math" alttext="\Delta v_{1}&gt;\Delta v_{2}" display="inline"><semantics id="S1.p2.3.m3.1a"><mrow id="S1.p2.3.m3.1.1" xref="S1.p2.3.m3.1.1.cmml"><mrow id="S1.p2.3.m3.1.1.2" xref="S1.p2.3.m3.1.1.2.cmml"><mi mathvariant="normal" id="S1.p2.3.m3.1.1.2.2" xref="S1.p2.3.m3.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.p2.3.m3.1.1.2.1" xref="S1.p2.3.m3.1.1.2.1.cmml">​</mo><msub id="S1.p2.3.m3.1.1.2.3" xref="S1.p2.3.m3.1.1.2.3.cmml"><mi id="S1.p2.3.m3.1.1.2.3.2" xref="S1.p2.3.m3.1.1.2.3.2.cmml">v</mi><mn id="S1.p2.3.m3.1.1.2.3.3" xref="S1.p2.3.m3.1.1.2.3.3.cmml">1</mn></msub></mrow><mo id="S1.p2.3.m3.1.1.1" xref="S1.p2.3.m3.1.1.1.cmml">&gt;</mo><mrow id="S1.p2.3.m3.1.1.3" xref="S1.p2.3.m3.1.1.3.cmml"><mi mathvariant="normal" id="S1.p2.3.m3.1.1.3.2" xref="S1.p2.3.m3.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.p2.3.m3.1.1.3.1" xref="S1.p2.3.m3.1.1.3.1.cmml">​</mo><msub id="S1.p2.3.m3.1.1.3.3" xref="S1.p2.3.m3.1.1.3.3.cmml"><mi id="S1.p2.3.m3.1.1.3.3.2" xref="S1.p2.3.m3.1.1.3.3.2.cmml">v</mi><mn id="S1.p2.3.m3.1.1.3.3.3" xref="S1.p2.3.m3.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.3.m3.1b"><apply id="S1.p2.3.m3.1.1.cmml" xref="S1.p2.3.m3.1.1"><gt id="S1.p2.3.m3.1.1.1.cmml" xref="S1.p2.3.m3.1.1.1"></gt><apply id="S1.p2.3.m3.1.1.2.cmml" xref="S1.p2.3.m3.1.1.2"><times id="S1.p2.3.m3.1.1.2.1.cmml" xref="S1.p2.3.m3.1.1.2.1"></times><ci id="S1.p2.3.m3.1.1.2.2.cmml" xref="S1.p2.3.m3.1.1.2.2">Δ</ci><apply id="S1.p2.3.m3.1.1.2.3.cmml" xref="S1.p2.3.m3.1.1.2.3"><csymbol cd="ambiguous" id="S1.p2.3.m3.1.1.2.3.1.cmml" xref="S1.p2.3.m3.1.1.2.3">subscript</csymbol><ci id="S1.p2.3.m3.1.1.2.3.2.cmml" xref="S1.p2.3.m3.1.1.2.3.2">𝑣</ci><cn type="integer" id="S1.p2.3.m3.1.1.2.3.3.cmml" xref="S1.p2.3.m3.1.1.2.3.3">1</cn></apply></apply><apply id="S1.p2.3.m3.1.1.3.cmml" xref="S1.p2.3.m3.1.1.3"><times id="S1.p2.3.m3.1.1.3.1.cmml" xref="S1.p2.3.m3.1.1.3.1"></times><ci id="S1.p2.3.m3.1.1.3.2.cmml" xref="S1.p2.3.m3.1.1.3.2">Δ</ci><apply id="S1.p2.3.m3.1.1.3.3.cmml" xref="S1.p2.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S1.p2.3.m3.1.1.3.3.1.cmml" xref="S1.p2.3.m3.1.1.3.3">subscript</csymbol><ci id="S1.p2.3.m3.1.1.3.3.2.cmml" xref="S1.p2.3.m3.1.1.3.3.2">𝑣</ci><cn type="integer" id="S1.p2.3.m3.1.1.3.3.3.cmml" xref="S1.p2.3.m3.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.3.m3.1c">\Delta v_{1}&gt;\Delta v_{2}</annotation></semantics></math>), which makes the pixel rounding errors have a non-negligible impact for detecting far objects.
Furthermore, as illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b), the camera pose variance can eventually result in a large offset both in form of 3D boxes and in the bird’s eye view <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>. To the best of our knowledge, existing Mono3D methods such as geometric constraint based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">53</span></a>]</cite>, pseudo-LiDAR based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>, <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>, <a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite>, and pure image based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>, <a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>, <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>, <a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>, <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>, <a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>, <a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>, <a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite>, have not taken into account the issue of inevitable camera pose changes in mobile scenarios.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we propose a novel Mono3D method, called <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">MoGDE</em>, which fixates on improving detection accuracy and robustness in mobile settings. We have one key insight that <em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">the depth of an object in 3D space can be well determined according to the depth of the ground where it stands</em>. Given the pinhole model and the pose of a camera, the depth of each pixel corresponding to the ground can be accurately derived. Based on this insight, the core idea of MoGDE is first to constantly estimate the ground depth while moving and then to utilize the estimated ground depth information to guide a Mono3D detector.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2303.13561/assets/figures/intro1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="137" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>(a) Equal distances of different depths from the camera (<em id="S1.F1.9.1" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S1.F1.4.m1.1" class="ltx_Math" alttext="\Delta z_{1}=\Delta z_{2}" display="inline"><semantics id="S1.F1.4.m1.1b"><mrow id="S1.F1.4.m1.1.1" xref="S1.F1.4.m1.1.1.cmml"><mrow id="S1.F1.4.m1.1.1.2" xref="S1.F1.4.m1.1.1.2.cmml"><mi mathvariant="normal" id="S1.F1.4.m1.1.1.2.2" xref="S1.F1.4.m1.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.F1.4.m1.1.1.2.1" xref="S1.F1.4.m1.1.1.2.1.cmml">​</mo><msub id="S1.F1.4.m1.1.1.2.3" xref="S1.F1.4.m1.1.1.2.3.cmml"><mi id="S1.F1.4.m1.1.1.2.3.2" xref="S1.F1.4.m1.1.1.2.3.2.cmml">z</mi><mn id="S1.F1.4.m1.1.1.2.3.3" xref="S1.F1.4.m1.1.1.2.3.3.cmml">1</mn></msub></mrow><mo id="S1.F1.4.m1.1.1.1" xref="S1.F1.4.m1.1.1.1.cmml">=</mo><mrow id="S1.F1.4.m1.1.1.3" xref="S1.F1.4.m1.1.1.3.cmml"><mi mathvariant="normal" id="S1.F1.4.m1.1.1.3.2" xref="S1.F1.4.m1.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.F1.4.m1.1.1.3.1" xref="S1.F1.4.m1.1.1.3.1.cmml">​</mo><msub id="S1.F1.4.m1.1.1.3.3" xref="S1.F1.4.m1.1.1.3.3.cmml"><mi id="S1.F1.4.m1.1.1.3.3.2" xref="S1.F1.4.m1.1.1.3.3.2.cmml">z</mi><mn id="S1.F1.4.m1.1.1.3.3.3" xref="S1.F1.4.m1.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.4.m1.1c"><apply id="S1.F1.4.m1.1.1.cmml" xref="S1.F1.4.m1.1.1"><eq id="S1.F1.4.m1.1.1.1.cmml" xref="S1.F1.4.m1.1.1.1"></eq><apply id="S1.F1.4.m1.1.1.2.cmml" xref="S1.F1.4.m1.1.1.2"><times id="S1.F1.4.m1.1.1.2.1.cmml" xref="S1.F1.4.m1.1.1.2.1"></times><ci id="S1.F1.4.m1.1.1.2.2.cmml" xref="S1.F1.4.m1.1.1.2.2">Δ</ci><apply id="S1.F1.4.m1.1.1.2.3.cmml" xref="S1.F1.4.m1.1.1.2.3"><csymbol cd="ambiguous" id="S1.F1.4.m1.1.1.2.3.1.cmml" xref="S1.F1.4.m1.1.1.2.3">subscript</csymbol><ci id="S1.F1.4.m1.1.1.2.3.2.cmml" xref="S1.F1.4.m1.1.1.2.3.2">𝑧</ci><cn type="integer" id="S1.F1.4.m1.1.1.2.3.3.cmml" xref="S1.F1.4.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S1.F1.4.m1.1.1.3.cmml" xref="S1.F1.4.m1.1.1.3"><times id="S1.F1.4.m1.1.1.3.1.cmml" xref="S1.F1.4.m1.1.1.3.1"></times><ci id="S1.F1.4.m1.1.1.3.2.cmml" xref="S1.F1.4.m1.1.1.3.2">Δ</ci><apply id="S1.F1.4.m1.1.1.3.3.cmml" xref="S1.F1.4.m1.1.1.3.3"><csymbol cd="ambiguous" id="S1.F1.4.m1.1.1.3.3.1.cmml" xref="S1.F1.4.m1.1.1.3.3">subscript</csymbol><ci id="S1.F1.4.m1.1.1.3.3.2.cmml" xref="S1.F1.4.m1.1.1.3.3.2">𝑧</ci><cn type="integer" id="S1.F1.4.m1.1.1.3.3.3.cmml" xref="S1.F1.4.m1.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.4.m1.1d">\Delta z_{1}=\Delta z_{2}</annotation></semantics></math>) have a distinct number of pixels in the image (<em id="S1.F1.10.2" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S1.F1.5.m2.1" class="ltx_Math" alttext="\Delta u_{1}&gt;\Delta u_{2}" display="inline"><semantics id="S1.F1.5.m2.1b"><mrow id="S1.F1.5.m2.1.1" xref="S1.F1.5.m2.1.1.cmml"><mrow id="S1.F1.5.m2.1.1.2" xref="S1.F1.5.m2.1.1.2.cmml"><mi mathvariant="normal" id="S1.F1.5.m2.1.1.2.2" xref="S1.F1.5.m2.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.F1.5.m2.1.1.2.1" xref="S1.F1.5.m2.1.1.2.1.cmml">​</mo><msub id="S1.F1.5.m2.1.1.2.3" xref="S1.F1.5.m2.1.1.2.3.cmml"><mi id="S1.F1.5.m2.1.1.2.3.2" xref="S1.F1.5.m2.1.1.2.3.2.cmml">u</mi><mn id="S1.F1.5.m2.1.1.2.3.3" xref="S1.F1.5.m2.1.1.2.3.3.cmml">1</mn></msub></mrow><mo id="S1.F1.5.m2.1.1.1" xref="S1.F1.5.m2.1.1.1.cmml">&gt;</mo><mrow id="S1.F1.5.m2.1.1.3" xref="S1.F1.5.m2.1.1.3.cmml"><mi mathvariant="normal" id="S1.F1.5.m2.1.1.3.2" xref="S1.F1.5.m2.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.F1.5.m2.1.1.3.1" xref="S1.F1.5.m2.1.1.3.1.cmml">​</mo><msub id="S1.F1.5.m2.1.1.3.3" xref="S1.F1.5.m2.1.1.3.3.cmml"><mi id="S1.F1.5.m2.1.1.3.3.2" xref="S1.F1.5.m2.1.1.3.3.2.cmml">u</mi><mn id="S1.F1.5.m2.1.1.3.3.3" xref="S1.F1.5.m2.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.5.m2.1c"><apply id="S1.F1.5.m2.1.1.cmml" xref="S1.F1.5.m2.1.1"><gt id="S1.F1.5.m2.1.1.1.cmml" xref="S1.F1.5.m2.1.1.1"></gt><apply id="S1.F1.5.m2.1.1.2.cmml" xref="S1.F1.5.m2.1.1.2"><times id="S1.F1.5.m2.1.1.2.1.cmml" xref="S1.F1.5.m2.1.1.2.1"></times><ci id="S1.F1.5.m2.1.1.2.2.cmml" xref="S1.F1.5.m2.1.1.2.2">Δ</ci><apply id="S1.F1.5.m2.1.1.2.3.cmml" xref="S1.F1.5.m2.1.1.2.3"><csymbol cd="ambiguous" id="S1.F1.5.m2.1.1.2.3.1.cmml" xref="S1.F1.5.m2.1.1.2.3">subscript</csymbol><ci id="S1.F1.5.m2.1.1.2.3.2.cmml" xref="S1.F1.5.m2.1.1.2.3.2">𝑢</ci><cn type="integer" id="S1.F1.5.m2.1.1.2.3.3.cmml" xref="S1.F1.5.m2.1.1.2.3.3">1</cn></apply></apply><apply id="S1.F1.5.m2.1.1.3.cmml" xref="S1.F1.5.m2.1.1.3"><times id="S1.F1.5.m2.1.1.3.1.cmml" xref="S1.F1.5.m2.1.1.3.1"></times><ci id="S1.F1.5.m2.1.1.3.2.cmml" xref="S1.F1.5.m2.1.1.3.2">Δ</ci><apply id="S1.F1.5.m2.1.1.3.3.cmml" xref="S1.F1.5.m2.1.1.3.3"><csymbol cd="ambiguous" id="S1.F1.5.m2.1.1.3.3.1.cmml" xref="S1.F1.5.m2.1.1.3.3">subscript</csymbol><ci id="S1.F1.5.m2.1.1.3.3.2.cmml" xref="S1.F1.5.m2.1.1.3.3.2">𝑢</ci><cn type="integer" id="S1.F1.5.m2.1.1.3.3.3.cmml" xref="S1.F1.5.m2.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.5.m2.1d">\Delta u_{1}&gt;\Delta u_{2}</annotation></semantics></math> and <math id="S1.F1.6.m3.1" class="ltx_Math" alttext="\Delta v_{1}&gt;\Delta v_{2}" display="inline"><semantics id="S1.F1.6.m3.1b"><mrow id="S1.F1.6.m3.1.1" xref="S1.F1.6.m3.1.1.cmml"><mrow id="S1.F1.6.m3.1.1.2" xref="S1.F1.6.m3.1.1.2.cmml"><mi mathvariant="normal" id="S1.F1.6.m3.1.1.2.2" xref="S1.F1.6.m3.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.F1.6.m3.1.1.2.1" xref="S1.F1.6.m3.1.1.2.1.cmml">​</mo><msub id="S1.F1.6.m3.1.1.2.3" xref="S1.F1.6.m3.1.1.2.3.cmml"><mi id="S1.F1.6.m3.1.1.2.3.2" xref="S1.F1.6.m3.1.1.2.3.2.cmml">v</mi><mn id="S1.F1.6.m3.1.1.2.3.3" xref="S1.F1.6.m3.1.1.2.3.3.cmml">1</mn></msub></mrow><mo id="S1.F1.6.m3.1.1.1" xref="S1.F1.6.m3.1.1.1.cmml">&gt;</mo><mrow id="S1.F1.6.m3.1.1.3" xref="S1.F1.6.m3.1.1.3.cmml"><mi mathvariant="normal" id="S1.F1.6.m3.1.1.3.2" xref="S1.F1.6.m3.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S1.F1.6.m3.1.1.3.1" xref="S1.F1.6.m3.1.1.3.1.cmml">​</mo><msub id="S1.F1.6.m3.1.1.3.3" xref="S1.F1.6.m3.1.1.3.3.cmml"><mi id="S1.F1.6.m3.1.1.3.3.2" xref="S1.F1.6.m3.1.1.3.3.2.cmml">v</mi><mn id="S1.F1.6.m3.1.1.3.3.3" xref="S1.F1.6.m3.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.6.m3.1c"><apply id="S1.F1.6.m3.1.1.cmml" xref="S1.F1.6.m3.1.1"><gt id="S1.F1.6.m3.1.1.1.cmml" xref="S1.F1.6.m3.1.1.1"></gt><apply id="S1.F1.6.m3.1.1.2.cmml" xref="S1.F1.6.m3.1.1.2"><times id="S1.F1.6.m3.1.1.2.1.cmml" xref="S1.F1.6.m3.1.1.2.1"></times><ci id="S1.F1.6.m3.1.1.2.2.cmml" xref="S1.F1.6.m3.1.1.2.2">Δ</ci><apply id="S1.F1.6.m3.1.1.2.3.cmml" xref="S1.F1.6.m3.1.1.2.3"><csymbol cd="ambiguous" id="S1.F1.6.m3.1.1.2.3.1.cmml" xref="S1.F1.6.m3.1.1.2.3">subscript</csymbol><ci id="S1.F1.6.m3.1.1.2.3.2.cmml" xref="S1.F1.6.m3.1.1.2.3.2">𝑣</ci><cn type="integer" id="S1.F1.6.m3.1.1.2.3.3.cmml" xref="S1.F1.6.m3.1.1.2.3.3">1</cn></apply></apply><apply id="S1.F1.6.m3.1.1.3.cmml" xref="S1.F1.6.m3.1.1.3"><times id="S1.F1.6.m3.1.1.3.1.cmml" xref="S1.F1.6.m3.1.1.3.1"></times><ci id="S1.F1.6.m3.1.1.3.2.cmml" xref="S1.F1.6.m3.1.1.3.2">Δ</ci><apply id="S1.F1.6.m3.1.1.3.3.cmml" xref="S1.F1.6.m3.1.1.3.3"><csymbol cd="ambiguous" id="S1.F1.6.m3.1.1.3.3.1.cmml" xref="S1.F1.6.m3.1.1.3.3">subscript</csymbol><ci id="S1.F1.6.m3.1.1.3.3.2.cmml" xref="S1.F1.6.m3.1.1.3.3.2">𝑣</ci><cn type="integer" id="S1.F1.6.m3.1.1.3.3.3.cmml" xref="S1.F1.6.m3.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.6.m3.1d">\Delta v_{1}&gt;\Delta v_{2}</annotation></semantics></math>), which is referred to as the near-far disparity phenomenon of monocular vision, making the detection of far object susceptible to pixel rounding errors.
(b) The camera pose variance, caused by the movement of a mobile agent, can eventually result in a large offset both in form of 3D boxes and in the bird’s eye view.
(c) Each color block represents its attention value with the centroid of the vehicle. The attention mechanism of the transformer network can be well leveraged for this long-range relationship modeling. </figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">There are two main challenges in designing MoGDE.
First, how to detect varying camera pose (<em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, the pitch and roll angles) from an image, which is dynamically changing in mobile scenes, and how to ultimately obtain accurate ground depth information are non-trivial. It is clear that different camera poses correspond to distinct ground depth estimates.
To tackle this challenge, we introduce a pose detection network to extract the vanishing point and horizon information in an image to estimate the instant camera pose corresponding to this image.
After the view direction of the camera is decided, we then construct a feature map portraying pixel-level depth clues.
Specifically, we envision a virtual 3D scene containing only the sky and the ground and project this virtual scene to an image where each pixel is associated with a depth uniquely derived according to the 3D-to-2D perspective geometry.
Therefore, MoGDE can obtain the dynamic ground depth information as prior knowledge for guiding Mono3D.
</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Second, how to incorporate the estimated ground depth into the image features to enhance the detection accuracy is challenging. Based on our aforementioned insight, it is essential for the Mono3D detector to identify those <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">ground-contacting points</em> of an object on the image. For example in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (a), these blue dots denote the ground-contacting points of a vehicle. To this end, we design an RGB-D feature fusion network based on the transformer structure to tie the ground depth feature to the image feature.
Specifically, as illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(c), the feature fusion network captures the feature of pixels close to the centroid of an object and identifies those ground-contacting points using the attention mechanism. It then attaches depth values with weights to compute a new feature map containing object location information. As a result, accurate 3D detection results can be obtained via a conventional Mono3D detector using the fused feature map.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Experiments on KITTI dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> demonstrate that our method outperforms the SOTA methods by a large margin. Such a framework can be applied to existing detectors and is practical for industrial applications.
The proposed MoGDE is ranked <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">number one</em> on the KITTI 3D benchmark by submission. The whole suite of the code base will be released and the experimental results will be posted to the public leaderboard.
We highlight the main contributions made in this paper as follows:
1) A novel Mono3D detector in a mobile setting is introduced, leveraging the dynamically estimated ground depth as prior knowledge to improve the detection accuracy and robustness for both near and far objects.
2) A transformer-based feature fusion network is designed, which utilizes the long-range attention mechanism to effectively identify ground-contacting points and pin the corresponding ground depth to the image feature map.
3) Extensive experiments on the real-world KITTI dataset are conducted and the results demonstrate the efficacy of MoGDE.
</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Monocular 3D Object Detection.</span>
The monocular 3D object detection aims to predict 3D bounding boxes from a single given image.
Existing Mono3D methods can be roughly divided into the following three categories.
<em id="S2.p1.1.2" class="ltx_emph ltx_font_italic">1) Geometric constraint based methods:</em> Extra information of prior 3D vehicle shapes is widely used, such as vehicle computer aided design (CAD) models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">53</span></a>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite> or key points <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite>.
By this means, extra labeling cost is inevitably required.
<em id="S2.p1.1.3" class="ltx_emph ltx_font_italic">2) Depth assist methods:</em> A stand-alone depth map of the monocular image is predicted at the first stage.
Such prior knowledge can be derived in various ways, such as a depth map generated by LiDAR point cloud (or Pseudo-LiDAR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>, <a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite>, monocular depth predictors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>, or disparity map generated by stereo cameras <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite>.
However, such external data is not easily available in all scenarios.
In addition, the inference time increases significantly due to the prediction of these dense heatmaps.
<em id="S2.p1.1.4" class="ltx_emph ltx_font_italic">3) Pure image-based methods:</em>
Without requiring extra side-channel information, such methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>, <a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> take only a single image as input and adopt center-based pipelines following conventional 2D detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>, <a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite>.
M3D-RPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite> reformulates the monocular 3D detection problem as a standalone 3D region proposal network.
With very few handcrafted modules, SMOKE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite> and FCOS3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite> predict a 3D bounding box by combining a concise one-stage keypoint estimation with regressed 3D variables based on CenterNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>]</cite> and FCOS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite>, respectively.
To further strengthen monocular detectors, current SOTA methods have introduced more effective but complicated geometric priors.
MonoPair <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite> improves the modeling of occluded objects by considering the relationship of paired samples and parses their spatial relations with uncertainty.
Kinematic3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite> proposes a novel method for monocular video-based 3D object detection, which uses kinematic motion to improve the accuracy of 3D localization.
MonoEF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> first proposes a novel method to capture the camera pose in order to formulate detectors that are not subject to camera extrinsic perturbations.
MonoFlex <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>]</cite> conducts an uncertainty-guided depth ensemble and categorizes different objects for distinctive processing.
GUPNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite> solves the error amplification problem by geometry-guided depth uncertainty and collocates a hierarchical learning strategy to reduce the training instability.
MonoDETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite> introduces a simple monocular object detection framework that makes the vanilla transformer to be depth-aware and enforces the whole detection process guided by depth.
The above geometrically dependent designs largely promote the overall performance of center-based methods, but the underlying problem still exists, namely, the detection accuracy for distant objects is still not satisfactory.
</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Object Detection with Transformer.</span>
2D object detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite> have achieved excellent performance in recent years but are equipped with cumbersome post-processing, e.g. non-maximum suppression (NMS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite>.
To circumvent it, the pioneering work DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> constructs a novel and simple framework by adapting the powerful transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite> to the field of vision detection.
DETR detects objects on images by encoding-decoding paradigm, which improves the detection performance by using the long-range attention mechanism.
DETR is further enhanced by designing deformable attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">64</span></a>]</cite>, placing anchors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite>, setting conditional attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>]</cite>, embedding dense prior <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>]</cite>, and so on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite>.
Some recent works have tried to apply transformer to some other tasks related to monocular scene reconstruction, depth prediction, <span id="S2.p2.1.2" class="ltx_text ltx_font_italic">etc.</span>
Transformerfusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> leverages the transformer architecture so that the network learns to focus on the most relevant image frames for each 3D location in the scene, supervised only by the scene reconstruction task.
MT-SfMLearner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite> first demonstrates how to adapt vision transformers for self-supervised monocular depth estimation focusing on improving the robustness of natural corruptions.
While these methods have made a demonstration of how to apply a transformer to a monocular camera model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>, <a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">55</span></a>, <a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>]</cite>, they all rely on other branches (either the environment reconstruction or the depth map), which will not be available in a typical Mono3D task based on RGB images.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Our MoGDE inherits DETR’s superiority for non-local encoding and long-range attention.
Specifically, we endow the transformer to be <span id="S2.p3.1.1" class="ltx_text ltx_font_italic">ground-aware</span> by pinning ground depth to image features leveraging the encoder-decoder architecture to improve the detection accuracy for far objects.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2303.13561/assets/x1.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="166" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>MoGDE consists of three main components, <em id="S2.F2.5.1" class="ltx_emph ltx_font_italic">i.e.</em>, <em id="S2.F2.6.2" class="ltx_emph ltx_font_italic">ground depth estimation</em> (GDE), <em id="S2.F2.7.3" class="ltx_emph ltx_font_italic">ground depth fusion</em> (GDF) and <em id="S2.F2.8.4" class="ltx_emph ltx_font_italic">monocular 3D detection</em> (M3D). In GDE, the pose network predicts the ground plane as well as the vanishing point. The derived pose information is then used to construct a virtual scene and obtain a pose-specific ground depth feature map. In GDF, a transformer network is leveraged to fuse the image features with the ground depth feature map, resulting a ground-aware fused feature map. M3D employs a standard Mono3D detector as the underlying detection core.</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Design of MoGDE</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Overview</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.3" class="ltx_p">The core idea of MoGDE is to utilize dynamically estimated ground depth information to improve Mono3D so that two goals can be achieved: 1) superior ground-aware image features are obtained to increase Mono3D accuracy for both near and far objects; 2) the impact of camera pose variation is diminished to enhance Mono3D robustness in mobile settings.
Figure <a href="#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> depicts the architecture of our framework. Specifically, MoGDE first adopts the DLA-34 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>]</cite> as its backbone, which takes a monocular image of size (<math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="W\times H\times 3" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">×</mo><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.1.m1.1.1.1a" xref="S3.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS1.p1.1.m1.1.1.4" xref="S3.SS1.p1.1.m1.1.1.4.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><times id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></times><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝑊</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">𝐻</ci><cn type="integer" id="S3.SS1.p1.1.m1.1.1.4.cmml" xref="S3.SS1.p1.1.m1.1.1.4">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">W\times H\times 3</annotation></semantics></math>) as input and outputs a feature map of size (<math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="W_{s}\times H_{s}\times C" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><msub id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2.2" xref="S3.SS1.p1.2.m2.1.1.2.2.cmml">W</mi><mi id="S3.SS1.p1.2.m2.1.1.2.3" xref="S3.SS1.p1.2.m2.1.1.2.3.cmml">s</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">×</mo><msub id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">H</mi><mi id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml">s</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.2.m2.1.1.1a" xref="S3.SS1.p1.2.m2.1.1.1.cmml">×</mo><mi id="S3.SS1.p1.2.m2.1.1.4" xref="S3.SS1.p1.2.m2.1.1.4.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><times id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></times><apply id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2.2">𝑊</ci><ci id="S3.SS1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.p1.2.m2.1.1.2.3">𝑠</ci></apply><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">𝐻</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">𝑠</ci></apply><ci id="S3.SS1.p1.2.m2.1.1.4.cmml" xref="S3.SS1.p1.2.m2.1.1.4">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">W_{s}\times H_{s}\times C</annotation></semantics></math>) after down-sampling with an <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">s</annotation></semantics></math>-factor. Then, the feature map is fed into three components as follows:</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Ground Depth Estimation (GDE).</span>
GDF mainly integrates two functions, <em id="S3.SS1.p2.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, <em id="S3.SS1.p2.1.3" class="ltx_emph ltx_font_italic">camera pose detection</em> (CPD), and <em id="S3.SS1.p2.1.4" class="ltx_emph ltx_font_italic">virtual scene construction</em> (VSC). Specifically, CPD estimates the camera pose (<em id="S3.SS1.p2.1.5" class="ltx_emph ltx_font_italic">i.e.</em>, the pitch and roll angles) based on the predicted vanishing point and ground plane extracted by a pose detection network. VSC establishes a 2D ground depth feature map based on a pose-specific virtual 3D scene containing only the sky and the ground.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Ground Depth Fusion (GDF).</span>
GDF leverages the attention mechanism of a transformer network to fuse the image features with the ground depth feature map, resulting a superior ground-aware fused feature map.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Monocular 3D Detection (M3D).</span>
MoGDE employs GUPNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite>, a SOTA CenterNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>]</cite> based SOTA monocular 3D object detector as its underlying detection core.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Ground Depth Estimation</h3>

<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Camera Pose Detection</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">In order to generate a ground depth estimate, it is key to detect the camera pose given an image feature map. We have the following proposition:</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.8" class="ltx_p"><span id="S3.SS2.SSS1.p2.8.9" class="ltx_text ltx_font_bold">Proposition 1:</span> <span id="S3.SS2.SSS1.p2.8.8" class="ltx_text ltx_font_italic">Given a benchmark camera coordinate system <math id="S3.SS2.SSS1.p2.1.1.m1.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS1.p2.1.1.m1.1a"><msup id="S3.SS2.SSS1.p2.1.1.m1.1.1" xref="S3.SS2.SSS1.p2.1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p2.1.1.m1.1.1.2" xref="S3.SS2.SSS1.p2.1.1.m1.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS1.p2.1.1.m1.1.1.3" xref="S3.SS2.SSS1.p2.1.1.m1.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.1.1.m1.1b"><apply id="S3.SS2.SSS1.p2.1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p2.1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p2.1.1.m1.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS1.p2.1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p2.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.1.1.m1.1c">\mathbf{P}^{0}</annotation></semantics></math>, which is aligned with the ground plane coordinate systems, and the current camera coordinate system <math id="S3.SS2.SSS1.p2.2.2.m2.1" class="ltx_Math" alttext="\mathbf{P}^{i}" display="inline"><semantics id="S3.SS2.SSS1.p2.2.2.m2.1a"><msup id="S3.SS2.SSS1.p2.2.2.m2.1.1" xref="S3.SS2.SSS1.p2.2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p2.2.2.m2.1.1.2" xref="S3.SS2.SSS1.p2.2.2.m2.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.SSS1.p2.2.2.m2.1.1.3" xref="S3.SS2.SSS1.p2.2.2.m2.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.2.2.m2.1b"><apply id="S3.SS2.SSS1.p2.2.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p2.2.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p2.2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p2.2.2.m2.1.1.2">𝐏</ci><ci id="S3.SS2.SSS1.p2.2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p2.2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.2.2.m2.1c">\mathbf{P}^{i}</annotation></semantics></math>, which is not aligned with <math id="S3.SS2.SSS1.p2.3.3.m3.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS1.p2.3.3.m3.1a"><msup id="S3.SS2.SSS1.p2.3.3.m3.1.1" xref="S3.SS2.SSS1.p2.3.3.m3.1.1.cmml"><mi id="S3.SS2.SSS1.p2.3.3.m3.1.1.2" xref="S3.SS2.SSS1.p2.3.3.m3.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS1.p2.3.3.m3.1.1.3" xref="S3.SS2.SSS1.p2.3.3.m3.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.3.3.m3.1b"><apply id="S3.SS2.SSS1.p2.3.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p2.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS1.p2.3.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p2.3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p2.3.3.m3.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS1.p2.3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p2.3.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.3.3.m3.1c">\mathbf{P}^{0}</annotation></semantics></math> due to camera movement, there exists a transformation matrix <math id="S3.SS2.SSS1.p2.4.4.m4.1" class="ltx_Math" alttext="\mathbf{A}" display="inline"><semantics id="S3.SS2.SSS1.p2.4.4.m4.1a"><mi id="S3.SS2.SSS1.p2.4.4.m4.1.1" xref="S3.SS2.SSS1.p2.4.4.m4.1.1.cmml">𝐀</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.4.4.m4.1b"><ci id="S3.SS2.SSS1.p2.4.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p2.4.4.m4.1.1">𝐀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.4.4.m4.1c">\mathbf{A}</annotation></semantics></math> between <math id="S3.SS2.SSS1.p2.5.5.m5.1" class="ltx_Math" alttext="\mathbf{P}^{i}" display="inline"><semantics id="S3.SS2.SSS1.p2.5.5.m5.1a"><msup id="S3.SS2.SSS1.p2.5.5.m5.1.1" xref="S3.SS2.SSS1.p2.5.5.m5.1.1.cmml"><mi id="S3.SS2.SSS1.p2.5.5.m5.1.1.2" xref="S3.SS2.SSS1.p2.5.5.m5.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.SSS1.p2.5.5.m5.1.1.3" xref="S3.SS2.SSS1.p2.5.5.m5.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.5.5.m5.1b"><apply id="S3.SS2.SSS1.p2.5.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p2.5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.5.5.m5.1.1.1.cmml" xref="S3.SS2.SSS1.p2.5.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p2.5.5.m5.1.1.2.cmml" xref="S3.SS2.SSS1.p2.5.5.m5.1.1.2">𝐏</ci><ci id="S3.SS2.SSS1.p2.5.5.m5.1.1.3.cmml" xref="S3.SS2.SSS1.p2.5.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.5.5.m5.1c">\mathbf{P}^{i}</annotation></semantics></math> and <math id="S3.SS2.SSS1.p2.6.6.m6.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS1.p2.6.6.m6.1a"><msup id="S3.SS2.SSS1.p2.6.6.m6.1.1" xref="S3.SS2.SSS1.p2.6.6.m6.1.1.cmml"><mi id="S3.SS2.SSS1.p2.6.6.m6.1.1.2" xref="S3.SS2.SSS1.p2.6.6.m6.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS1.p2.6.6.m6.1.1.3" xref="S3.SS2.SSS1.p2.6.6.m6.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.6.6.m6.1b"><apply id="S3.SS2.SSS1.p2.6.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p2.6.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.6.6.m6.1.1.1.cmml" xref="S3.SS2.SSS1.p2.6.6.m6.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p2.6.6.m6.1.1.2.cmml" xref="S3.SS2.SSS1.p2.6.6.m6.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS1.p2.6.6.m6.1.1.3.cmml" xref="S3.SS2.SSS1.p2.6.6.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.6.6.m6.1c">\mathbf{P}^{0}</annotation></semantics></math> that can be uniquely determined by pitch <math id="S3.SS2.SSS1.p2.7.7.m7.1" class="ltx_Math" alttext="\theta_{p}" display="inline"><semantics id="S3.SS2.SSS1.p2.7.7.m7.1a"><msub id="S3.SS2.SSS1.p2.7.7.m7.1.1" xref="S3.SS2.SSS1.p2.7.7.m7.1.1.cmml"><mi id="S3.SS2.SSS1.p2.7.7.m7.1.1.2" xref="S3.SS2.SSS1.p2.7.7.m7.1.1.2.cmml">θ</mi><mi id="S3.SS2.SSS1.p2.7.7.m7.1.1.3" xref="S3.SS2.SSS1.p2.7.7.m7.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.7.7.m7.1b"><apply id="S3.SS2.SSS1.p2.7.7.m7.1.1.cmml" xref="S3.SS2.SSS1.p2.7.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.7.7.m7.1.1.1.cmml" xref="S3.SS2.SSS1.p2.7.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.7.7.m7.1.1.2.cmml" xref="S3.SS2.SSS1.p2.7.7.m7.1.1.2">𝜃</ci><ci id="S3.SS2.SSS1.p2.7.7.m7.1.1.3.cmml" xref="S3.SS2.SSS1.p2.7.7.m7.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.7.7.m7.1c">\theta_{p}</annotation></semantics></math> and roll <math id="S3.SS2.SSS1.p2.8.8.m8.1" class="ltx_Math" alttext="\theta_{p}" display="inline"><semantics id="S3.SS2.SSS1.p2.8.8.m8.1a"><msub id="S3.SS2.SSS1.p2.8.8.m8.1.1" xref="S3.SS2.SSS1.p2.8.8.m8.1.1.cmml"><mi id="S3.SS2.SSS1.p2.8.8.m8.1.1.2" xref="S3.SS2.SSS1.p2.8.8.m8.1.1.2.cmml">θ</mi><mi id="S3.SS2.SSS1.p2.8.8.m8.1.1.3" xref="S3.SS2.SSS1.p2.8.8.m8.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.8.8.m8.1b"><apply id="S3.SS2.SSS1.p2.8.8.m8.1.1.cmml" xref="S3.SS2.SSS1.p2.8.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.8.8.m8.1.1.1.cmml" xref="S3.SS2.SSS1.p2.8.8.m8.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.8.8.m8.1.1.2.cmml" xref="S3.SS2.SSS1.p2.8.8.m8.1.1.2">𝜃</ci><ci id="S3.SS2.SSS1.p2.8.8.m8.1.1.3.cmml" xref="S3.SS2.SSS1.p2.8.8.m8.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.8.8.m8.1c">\theta_{p}</annotation></semantics></math> angle changes of the camera.</span>)</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.4" class="ltx_p">Therefore, we introduce the subsequent neural network to learn the pitch <math id="S3.SS2.SSS1.p3.1.m1.1" class="ltx_Math" alttext="\theta_{p}" display="inline"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><msub id="S3.SS2.SSS1.p3.1.m1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml">θ</mi><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><apply id="S3.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.2">𝜃</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">\theta_{p}</annotation></semantics></math> and roll <math id="S3.SS2.SSS1.p3.2.m2.1" class="ltx_Math" alttext="\theta_{p}" display="inline"><semantics id="S3.SS2.SSS1.p3.2.m2.1a"><msub id="S3.SS2.SSS1.p3.2.m2.1.1" xref="S3.SS2.SSS1.p3.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p3.2.m2.1.1.2" xref="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml">θ</mi><mi id="S3.SS2.SSS1.p3.2.m2.1.1.3" xref="S3.SS2.SSS1.p3.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.2.m2.1b"><apply id="S3.SS2.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.2">𝜃</ci><ci id="S3.SS2.SSS1.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.2.m2.1c">\theta_{p}</annotation></semantics></math> angle changes of the camera when the camera coordinate system changes from <math id="S3.SS2.SSS1.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS1.p3.3.m3.1a"><msup id="S3.SS2.SSS1.p3.3.m3.1.1" xref="S3.SS2.SSS1.p3.3.m3.1.1.cmml"><mi id="S3.SS2.SSS1.p3.3.m3.1.1.2" xref="S3.SS2.SSS1.p3.3.m3.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS1.p3.3.m3.1.1.3" xref="S3.SS2.SSS1.p3.3.m3.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.3.m3.1b"><apply id="S3.SS2.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS1.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.3.m3.1c">\mathbf{P}^{0}</annotation></semantics></math> to <math id="S3.SS2.SSS1.p3.4.m4.1" class="ltx_Math" alttext="\mathbf{P}^{i}" display="inline"><semantics id="S3.SS2.SSS1.p3.4.m4.1a"><msup id="S3.SS2.SSS1.p3.4.m4.1.1" xref="S3.SS2.SSS1.p3.4.m4.1.1.cmml"><mi id="S3.SS2.SSS1.p3.4.m4.1.1.2" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.SSS1.p3.4.m4.1.1.3" xref="S3.SS2.SSS1.p3.4.m4.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.4.m4.1b"><apply id="S3.SS2.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p3.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2">𝐏</ci><ci id="S3.SS2.SSS1.p3.4.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.4.m4.1c">\mathbf{P}^{i}</annotation></semantics></math>.
Specifically, in addition to the regular regression tasks in CenterNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>]</cite> based network, we introduce a regression branch for pose detection following MonoEF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite>.
Since the camera pose is a feature that is implicit for images, we chose two physical quantities with a clear meaning for detection: the ground plane (associated with roll angle) and the vanishing point (associated with pitch angle).
Following the state-of-the-art odometer framework in DeepVP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>]</cite>, we represent a regression task with L1 loss as:</p>
<table id="S3.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle{\left[\hat{\mathbf{y}}_{\mathrm{gp}},\hat{\mathbf{y}}_{\mathrm{vp}}\right]}" display="inline"><semantics id="S3.E1X.2.1.1.m1.2a"><mrow id="S3.E1X.2.1.1.m1.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.3.cmml"><mo id="S3.E1X.2.1.1.m1.2.2.2.3" xref="S3.E1X.2.1.1.m1.2.2.3.cmml">[</mo><msub id="S3.E1X.2.1.1.m1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.cmml"><mover accent="true" id="S3.E1X.2.1.1.m1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.2.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.cmml">𝐲</mi><mo id="S3.E1X.2.1.1.m1.1.1.1.1.2.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S3.E1X.2.1.1.m1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.cmml">gp</mi></msub><mo id="S3.E1X.2.1.1.m1.2.2.2.4" xref="S3.E1X.2.1.1.m1.2.2.3.cmml">,</mo><msub id="S3.E1X.2.1.1.m1.2.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.cmml"><mover accent="true" id="S3.E1X.2.1.1.m1.2.2.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.cmml"><mi id="S3.E1X.2.1.1.m1.2.2.2.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.cmml">𝐲</mi><mo id="S3.E1X.2.1.1.m1.2.2.2.2.2.1" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.E1X.2.1.1.m1.2.2.2.2.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.cmml">vp</mi></msub><mo id="S3.E1X.2.1.1.m1.2.2.2.5" xref="S3.E1X.2.1.1.m1.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1X.2.1.1.m1.2b"><interval closure="closed" id="S3.E1X.2.1.1.m1.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2"><apply id="S3.E1X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1">subscript</csymbol><apply id="S3.E1X.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2"><ci id="S3.E1X.2.1.1.m1.1.1.1.1.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.1">^</ci><ci id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2">𝐲</ci></apply><ci id="S3.E1X.2.1.1.m1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.3">gp</ci></apply><apply id="S3.E1X.2.1.1.m1.2.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.2.2.2.2.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2">subscript</csymbol><apply id="S3.E1X.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2"><ci id="S3.E1X.2.1.1.m1.2.2.2.2.2.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.1">^</ci><ci id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2">𝐲</ci></apply><ci id="S3.E1X.2.1.1.m1.2.2.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3">vp</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.E1X.2.1.1.m1.2c">\displaystyle{\left[\hat{\mathbf{y}}_{\mathrm{gp}},\hat{\mathbf{y}}_{\mathrm{vp}}\right]}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1X.3.2.2.m1.2" class="ltx_Math" alttext="\displaystyle=f^{\mathrm{pose}}\left(\mathbf{H}\right)," display="inline"><semantics id="S3.E1X.3.2.2.m1.2a"><mrow id="S3.E1X.3.2.2.m1.2.2.1" xref="S3.E1X.3.2.2.m1.2.2.1.1.cmml"><mrow id="S3.E1X.3.2.2.m1.2.2.1.1" xref="S3.E1X.3.2.2.m1.2.2.1.1.cmml"><mi id="S3.E1X.3.2.2.m1.2.2.1.1.2" xref="S3.E1X.3.2.2.m1.2.2.1.1.2.cmml"></mi><mo id="S3.E1X.3.2.2.m1.2.2.1.1.1" xref="S3.E1X.3.2.2.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E1X.3.2.2.m1.2.2.1.1.3" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.cmml"><msup id="S3.E1X.3.2.2.m1.2.2.1.1.3.2" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.2.cmml"><mi id="S3.E1X.3.2.2.m1.2.2.1.1.3.2.2" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.2.2.cmml">f</mi><mi id="S3.E1X.3.2.2.m1.2.2.1.1.3.2.3" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.2.3.cmml">pose</mi></msup><mo lspace="0em" rspace="0em" id="S3.E1X.3.2.2.m1.2.2.1.1.3.1" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S3.E1X.3.2.2.m1.2.2.1.1.3.3.2" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.cmml"><mo id="S3.E1X.3.2.2.m1.2.2.1.1.3.3.2.1" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.cmml">(</mo><mi id="S3.E1X.3.2.2.m1.1.1" xref="S3.E1X.3.2.2.m1.1.1.cmml">𝐇</mi><mo id="S3.E1X.3.2.2.m1.2.2.1.1.3.3.2.2" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1X.3.2.2.m1.2.2.1.2" xref="S3.E1X.3.2.2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1X.3.2.2.m1.2b"><apply id="S3.E1X.3.2.2.m1.2.2.1.1.cmml" xref="S3.E1X.3.2.2.m1.2.2.1"><eq id="S3.E1X.3.2.2.m1.2.2.1.1.1.cmml" xref="S3.E1X.3.2.2.m1.2.2.1.1.1"></eq><csymbol cd="latexml" id="S3.E1X.3.2.2.m1.2.2.1.1.2.cmml" xref="S3.E1X.3.2.2.m1.2.2.1.1.2">absent</csymbol><apply id="S3.E1X.3.2.2.m1.2.2.1.1.3.cmml" xref="S3.E1X.3.2.2.m1.2.2.1.1.3"><times id="S3.E1X.3.2.2.m1.2.2.1.1.3.1.cmml" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.1"></times><apply id="S3.E1X.3.2.2.m1.2.2.1.1.3.2.cmml" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1X.3.2.2.m1.2.2.1.1.3.2.1.cmml" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.2">superscript</csymbol><ci id="S3.E1X.3.2.2.m1.2.2.1.1.3.2.2.cmml" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.2.2">𝑓</ci><ci id="S3.E1X.3.2.2.m1.2.2.1.1.3.2.3.cmml" xref="S3.E1X.3.2.2.m1.2.2.1.1.3.2.3">pose</ci></apply><ci id="S3.E1X.3.2.2.m1.1.1.cmml" xref="S3.E1X.3.2.2.m1.1.1">𝐇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1X.3.2.2.m1.2c">\displaystyle=f^{\mathrm{pose}}\left(\mathbf{H}\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
<tr id="S3.E1Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1Xa.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\mathcal{L}_{\mathrm{pose}}" display="inline"><semantics id="S3.E1Xa.2.1.1.m1.1a"><msub id="S3.E1Xa.2.1.1.m1.1.1" xref="S3.E1Xa.2.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1Xa.2.1.1.m1.1.1.2" xref="S3.E1Xa.2.1.1.m1.1.1.2.cmml">ℒ</mi><mi id="S3.E1Xa.2.1.1.m1.1.1.3" xref="S3.E1Xa.2.1.1.m1.1.1.3.cmml">pose</mi></msub><annotation-xml encoding="MathML-Content" id="S3.E1Xa.2.1.1.m1.1b"><apply id="S3.E1Xa.2.1.1.m1.1.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.1.1.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.2">ℒ</ci><ci id="S3.E1Xa.2.1.1.m1.1.1.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.3">pose</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1Xa.2.1.1.m1.1c">\displaystyle\mathcal{L}_{\mathrm{pose}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1Xa.3.2.2.m1.1" class="ltx_Math" alttext="\displaystyle=\left\|\mathbf{A}-\mathbf{g}\left(\hat{\mathbf{y}}_{\mathrm{gp}},\hat{\mathbf{y}}_{\mathrm{vp}}\right)\right\|," display="inline"><semantics id="S3.E1Xa.3.2.2.m1.1a"><mrow id="S3.E1Xa.3.2.2.m1.1.1.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.cmml"><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.3.cmml"></mi><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.2.cmml"><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.4" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.4.cmml">𝐀</mi><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.4" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.4.cmml">𝐠</mi><mo lspace="0em" rspace="0em" id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.3.cmml">​</mo><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.3.cmml"><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">𝐲</mi><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">gp</mi></msub><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.4" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.cmml"><mover accent="true" id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.2.cmml">𝐲</mi><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.3.cmml">vp</mi></msub><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.5" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow><mo id="S3.E1Xa.3.2.2.m1.1.1.1.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1Xa.3.2.2.m1.1b"><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1"><eq id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2"></eq><csymbol cd="latexml" id="S3.E1Xa.3.2.2.m1.1.1.1.1.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.3">absent</csymbol><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.2.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1"><minus id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.3"></minus><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.4.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.4">𝐀</ci><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2"><times id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.3"></times><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.4.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.4">𝐠</ci><interval closure="open" id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2"><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2"><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.1">^</ci><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝐲</ci></apply><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.3">gp</ci></apply><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2"><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.1">^</ci><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.2.2">𝐲</ci></apply><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.2.2.2.2.3">vp</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1Xa.3.2.2.m1.1c">\displaystyle=\left\|\mathbf{A}-\mathbf{g}\left(\hat{\mathbf{y}}_{\mathrm{gp}},\hat{\mathbf{y}}_{\mathrm{vp}}\right)\right\|,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S3.SS2.SSS1.p3.12" class="ltx_p">where <math id="S3.SS2.SSS1.p3.5.m1.1" class="ltx_Math" alttext="\mathbf{H}" display="inline"><semantics id="S3.SS2.SSS1.p3.5.m1.1a"><mi id="S3.SS2.SSS1.p3.5.m1.1.1" xref="S3.SS2.SSS1.p3.5.m1.1.1.cmml">𝐇</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.5.m1.1b"><ci id="S3.SS2.SSS1.p3.5.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.5.m1.1.1">𝐇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.5.m1.1c">\mathbf{H}</annotation></semantics></math> is the input image feature; <math id="S3.SS2.SSS1.p3.6.m2.1" class="ltx_Math" alttext="f^{pose}" display="inline"><semantics id="S3.SS2.SSS1.p3.6.m2.1a"><msup id="S3.SS2.SSS1.p3.6.m2.1.1" xref="S3.SS2.SSS1.p3.6.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p3.6.m2.1.1.2" xref="S3.SS2.SSS1.p3.6.m2.1.1.2.cmml">f</mi><mrow id="S3.SS2.SSS1.p3.6.m2.1.1.3" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.cmml"><mi id="S3.SS2.SSS1.p3.6.m2.1.1.3.2" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p3.6.m2.1.1.3.1" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS1.p3.6.m2.1.1.3.3" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p3.6.m2.1.1.3.1a" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS1.p3.6.m2.1.1.3.4" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p3.6.m2.1.1.3.1b" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS1.p3.6.m2.1.1.3.5" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.5.cmml">e</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.6.m2.1b"><apply id="S3.SS2.SSS1.p3.6.m2.1.1.cmml" xref="S3.SS2.SSS1.p3.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.6.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p3.6.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p3.6.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p3.6.m2.1.1.2">𝑓</ci><apply id="S3.SS2.SSS1.p3.6.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p3.6.m2.1.1.3"><times id="S3.SS2.SSS1.p3.6.m2.1.1.3.1.cmml" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.1"></times><ci id="S3.SS2.SSS1.p3.6.m2.1.1.3.2.cmml" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.2">𝑝</ci><ci id="S3.SS2.SSS1.p3.6.m2.1.1.3.3.cmml" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.3">𝑜</ci><ci id="S3.SS2.SSS1.p3.6.m2.1.1.3.4.cmml" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.4">𝑠</ci><ci id="S3.SS2.SSS1.p3.6.m2.1.1.3.5.cmml" xref="S3.SS2.SSS1.p3.6.m2.1.1.3.5">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.6.m2.1c">f^{pose}</annotation></semantics></math> is the CNN architecture used for horizon and vanishing point detection in the work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>; <math id="S3.SS2.SSS1.p3.7.m3.1" class="ltx_Math" alttext="\hat{\mathbf{y}}_{\mathrm{gp}}" display="inline"><semantics id="S3.SS2.SSS1.p3.7.m3.1a"><msub id="S3.SS2.SSS1.p3.7.m3.1.1" xref="S3.SS2.SSS1.p3.7.m3.1.1.cmml"><mover accent="true" id="S3.SS2.SSS1.p3.7.m3.1.1.2" xref="S3.SS2.SSS1.p3.7.m3.1.1.2.cmml"><mi id="S3.SS2.SSS1.p3.7.m3.1.1.2.2" xref="S3.SS2.SSS1.p3.7.m3.1.1.2.2.cmml">𝐲</mi><mo id="S3.SS2.SSS1.p3.7.m3.1.1.2.1" xref="S3.SS2.SSS1.p3.7.m3.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.SSS1.p3.7.m3.1.1.3" xref="S3.SS2.SSS1.p3.7.m3.1.1.3.cmml">gp</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.7.m3.1b"><apply id="S3.SS2.SSS1.p3.7.m3.1.1.cmml" xref="S3.SS2.SSS1.p3.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.7.m3.1.1.1.cmml" xref="S3.SS2.SSS1.p3.7.m3.1.1">subscript</csymbol><apply id="S3.SS2.SSS1.p3.7.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p3.7.m3.1.1.2"><ci id="S3.SS2.SSS1.p3.7.m3.1.1.2.1.cmml" xref="S3.SS2.SSS1.p3.7.m3.1.1.2.1">^</ci><ci id="S3.SS2.SSS1.p3.7.m3.1.1.2.2.cmml" xref="S3.SS2.SSS1.p3.7.m3.1.1.2.2">𝐲</ci></apply><ci id="S3.SS2.SSS1.p3.7.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p3.7.m3.1.1.3">gp</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.7.m3.1c">\hat{\mathbf{y}}_{\mathrm{gp}}</annotation></semantics></math> and <math id="S3.SS2.SSS1.p3.8.m4.1" class="ltx_Math" alttext="\hat{\mathbf{y}}_{\mathrm{vp}}" display="inline"><semantics id="S3.SS2.SSS1.p3.8.m4.1a"><msub id="S3.SS2.SSS1.p3.8.m4.1.1" xref="S3.SS2.SSS1.p3.8.m4.1.1.cmml"><mover accent="true" id="S3.SS2.SSS1.p3.8.m4.1.1.2" xref="S3.SS2.SSS1.p3.8.m4.1.1.2.cmml"><mi id="S3.SS2.SSS1.p3.8.m4.1.1.2.2" xref="S3.SS2.SSS1.p3.8.m4.1.1.2.2.cmml">𝐲</mi><mo id="S3.SS2.SSS1.p3.8.m4.1.1.2.1" xref="S3.SS2.SSS1.p3.8.m4.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.SSS1.p3.8.m4.1.1.3" xref="S3.SS2.SSS1.p3.8.m4.1.1.3.cmml">vp</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.8.m4.1b"><apply id="S3.SS2.SSS1.p3.8.m4.1.1.cmml" xref="S3.SS2.SSS1.p3.8.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.8.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p3.8.m4.1.1">subscript</csymbol><apply id="S3.SS2.SSS1.p3.8.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p3.8.m4.1.1.2"><ci id="S3.SS2.SSS1.p3.8.m4.1.1.2.1.cmml" xref="S3.SS2.SSS1.p3.8.m4.1.1.2.1">^</ci><ci id="S3.SS2.SSS1.p3.8.m4.1.1.2.2.cmml" xref="S3.SS2.SSS1.p3.8.m4.1.1.2.2">𝐲</ci></apply><ci id="S3.SS2.SSS1.p3.8.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p3.8.m4.1.1.3">vp</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.8.m4.1c">\hat{\mathbf{y}}_{\mathrm{vp}}</annotation></semantics></math> are the predicted ground plane and vanishing point; <math id="S3.SS2.SSS1.p3.9.m5.1" class="ltx_Math" alttext="\mathbf{g}" display="inline"><semantics id="S3.SS2.SSS1.p3.9.m5.1a"><mi id="S3.SS2.SSS1.p3.9.m5.1.1" xref="S3.SS2.SSS1.p3.9.m5.1.1.cmml">𝐠</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.9.m5.1b"><ci id="S3.SS2.SSS1.p3.9.m5.1.1.cmml" xref="S3.SS2.SSS1.p3.9.m5.1.1">𝐠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.9.m5.1c">\mathbf{g}</annotation></semantics></math> is a mapping function <math id="S3.SS2.SSS1.p3.10.m6.2" class="ltx_Math" alttext="\mathbf{g}:\left(\mathbb{R}^{2},\mathbb{R}^{2}\right)\mapsto\mathbf{A}_{3\times 3}" display="inline"><semantics id="S3.SS2.SSS1.p3.10.m6.2a"><mrow id="S3.SS2.SSS1.p3.10.m6.2.2" xref="S3.SS2.SSS1.p3.10.m6.2.2.cmml"><mi id="S3.SS2.SSS1.p3.10.m6.2.2.4" xref="S3.SS2.SSS1.p3.10.m6.2.2.4.cmml">𝐠</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS2.SSS1.p3.10.m6.2.2.3" xref="S3.SS2.SSS1.p3.10.m6.2.2.3.cmml">:</mo><mrow id="S3.SS2.SSS1.p3.10.m6.2.2.2" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.cmml"><mrow id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.3.cmml"><mo id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.3" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.3.cmml">(</mo><msup id="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1" xref="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.2" xref="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.2.cmml">ℝ</mi><mn id="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.3" xref="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.4" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.3.cmml">,</mo><msup id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.cmml"><mi id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.2" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.2.cmml">ℝ</mi><mn id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.3" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.3.cmml">2</mn></msup><mo id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.5" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.3.cmml">)</mo></mrow><mo stretchy="false" id="S3.SS2.SSS1.p3.10.m6.2.2.2.3" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.3.cmml">↦</mo><msub id="S3.SS2.SSS1.p3.10.m6.2.2.2.4" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.cmml"><mi id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.2" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.2.cmml">𝐀</mi><mrow id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.cmml"><mn id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.2" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.1" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.1.cmml">×</mo><mn id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.3" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.3.cmml">3</mn></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.10.m6.2b"><apply id="S3.SS2.SSS1.p3.10.m6.2.2.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2"><ci id="S3.SS2.SSS1.p3.10.m6.2.2.3.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.3">:</ci><ci id="S3.SS2.SSS1.p3.10.m6.2.2.4.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.4">𝐠</ci><apply id="S3.SS2.SSS1.p3.10.m6.2.2.2.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p3.10.m6.2.2.2.3.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.3">maps-to</csymbol><interval closure="open" id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.3.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2"><apply id="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.2">ℝ</ci><cn type="integer" id="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.10.m6.1.1.1.1.1.1.3">2</cn></apply><apply id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2">superscript</csymbol><ci id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.2">ℝ</ci><cn type="integer" id="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.3.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.2.2.2.3">2</cn></apply></interval><apply id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.1.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4">subscript</csymbol><ci id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.2.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.2">𝐀</ci><apply id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3"><times id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.1.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.1"></times><cn type="integer" id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.2.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.2">3</cn><cn type="integer" id="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.3.cmml" xref="S3.SS2.SSS1.p3.10.m6.2.2.2.4.3.3">3</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.10.m6.2c">\mathbf{g}:\left(\mathbb{R}^{2},\mathbb{R}^{2}\right)\mapsto\mathbf{A}_{3\times 3}</annotation></semantics></math> which turns pitch and roll angles into a matrix <math id="S3.SS2.SSS1.p3.11.m7.1" class="ltx_Math" alttext="\mathbf{A}" display="inline"><semantics id="S3.SS2.SSS1.p3.11.m7.1a"><mi id="S3.SS2.SSS1.p3.11.m7.1.1" xref="S3.SS2.SSS1.p3.11.m7.1.1.cmml">𝐀</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.11.m7.1b"><ci id="S3.SS2.SSS1.p3.11.m7.1.1.cmml" xref="S3.SS2.SSS1.p3.11.m7.1.1">𝐀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.11.m7.1c">\mathbf{A}</annotation></semantics></math>.
The regression network is supervised by <math id="S3.SS2.SSS1.p3.12.m8.1" class="ltx_Math" alttext="\mathcal{L}_{\mathrm{pose}}" display="inline"><semantics id="S3.SS2.SSS1.p3.12.m8.1a"><msub id="S3.SS2.SSS1.p3.12.m8.1.1" xref="S3.SS2.SSS1.p3.12.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS1.p3.12.m8.1.1.2" xref="S3.SS2.SSS1.p3.12.m8.1.1.2.cmml">ℒ</mi><mi id="S3.SS2.SSS1.p3.12.m8.1.1.3" xref="S3.SS2.SSS1.p3.12.m8.1.1.3.cmml">pose</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.12.m8.1b"><apply id="S3.SS2.SSS1.p3.12.m8.1.1.cmml" xref="S3.SS2.SSS1.p3.12.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.12.m8.1.1.1.cmml" xref="S3.SS2.SSS1.p3.12.m8.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p3.12.m8.1.1.2.cmml" xref="S3.SS2.SSS1.p3.12.m8.1.1.2">ℒ</ci><ci id="S3.SS2.SSS1.p3.12.m8.1.1.3.cmml" xref="S3.SS2.SSS1.p3.12.m8.1.1.3">pose</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.12.m8.1c">\mathcal{L}_{\mathrm{pose}}</annotation></semantics></math> and can be trained jointly with other Mono3D branches.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Virtual Scene Construction</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">We envision such a virtual scene, where there is a vast and infinite horizontal plane in the camera coordinate system <math id="S3.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><msup id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p1.1.m1.1.1.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS2.p1.1.m1.1.1.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><apply id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">\mathbf{P}^{0}</annotation></semantics></math>, and have the following proposition:</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.5" class="ltx_p"><span id="S3.SS2.SSS2.p2.5.6" class="ltx_text ltx_font_bold">Proposistion 2:</span> <span id="S3.SS2.SSS2.p2.5.5" class="ltx_text ltx_font_italic">Given the camera coordinate system <math id="S3.SS2.SSS2.p2.1.1.m1.1" class="ltx_Math" alttext="\mathbf{P}^{i}" display="inline"><semantics id="S3.SS2.SSS2.p2.1.1.m1.1a"><msup id="S3.SS2.SSS2.p2.1.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p2.1.1.m1.1.1.2" xref="S3.SS2.SSS2.p2.1.1.m1.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.SSS2.p2.1.1.m1.1.1.3" xref="S3.SS2.SSS2.p2.1.1.m1.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.1.m1.1b"><apply id="S3.SS2.SSS2.p2.1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p2.1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.1.1.m1.1.1.2">𝐏</ci><ci id="S3.SS2.SSS2.p2.1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p2.1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.1.m1.1c">\mathbf{P}^{i}</annotation></semantics></math>, the virtual horizontal plane can be projected on the image plane of the camera according to the ideal pinhole camera model and the depth corresponding to each pixel on the image is determined by the camera intrinsic parameter <math id="S3.SS2.SSS2.p2.2.2.m2.1" class="ltx_Math" alttext="\mathbf{K}" display="inline"><semantics id="S3.SS2.SSS2.p2.2.2.m2.1a"><mi id="S3.SS2.SSS2.p2.2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.2.m2.1.1.cmml">𝐊</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.2.m2.1b"><ci id="S3.SS2.SSS2.p2.2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.2.m2.1.1">𝐊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.2.m2.1c">\mathbf{K}</annotation></semantics></math> and pose matrix <math id="S3.SS2.SSS2.p2.3.3.m3.1" class="ltx_Math" alttext="\mathbf{A}" display="inline"><semantics id="S3.SS2.SSS2.p2.3.3.m3.1a"><mi id="S3.SS2.SSS2.p2.3.3.m3.1.1" xref="S3.SS2.SSS2.p2.3.3.m3.1.1.cmml">𝐀</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.3.3.m3.1b"><ci id="S3.SS2.SSS2.p2.3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p2.3.3.m3.1.1">𝐀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.3.3.m3.1c">\mathbf{A}</annotation></semantics></math> from <math id="S3.SS2.SSS2.p2.4.4.m4.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS2.p2.4.4.m4.1a"><msup id="S3.SS2.SSS2.p2.4.4.m4.1.1" xref="S3.SS2.SSS2.p2.4.4.m4.1.1.cmml"><mi id="S3.SS2.SSS2.p2.4.4.m4.1.1.2" xref="S3.SS2.SSS2.p2.4.4.m4.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS2.p2.4.4.m4.1.1.3" xref="S3.SS2.SSS2.p2.4.4.m4.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.4.4.m4.1b"><apply id="S3.SS2.SSS2.p2.4.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p2.4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.4.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p2.4.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p2.4.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p2.4.4.m4.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS2.p2.4.4.m4.1.1.3.cmml" xref="S3.SS2.SSS2.p2.4.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.4.4.m4.1c">\mathbf{P}^{0}</annotation></semantics></math> to <math id="S3.SS2.SSS2.p2.5.5.m5.1" class="ltx_Math" alttext="\mathbf{P}^{i}" display="inline"><semantics id="S3.SS2.SSS2.p2.5.5.m5.1a"><msup id="S3.SS2.SSS2.p2.5.5.m5.1.1" xref="S3.SS2.SSS2.p2.5.5.m5.1.1.cmml"><mi id="S3.SS2.SSS2.p2.5.5.m5.1.1.2" xref="S3.SS2.SSS2.p2.5.5.m5.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.SSS2.p2.5.5.m5.1.1.3" xref="S3.SS2.SSS2.p2.5.5.m5.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.5.5.m5.1b"><apply id="S3.SS2.SSS2.p2.5.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p2.5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.5.5.m5.1.1.1.cmml" xref="S3.SS2.SSS2.p2.5.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p2.5.5.m5.1.1.2.cmml" xref="S3.SS2.SSS2.p2.5.5.m5.1.1.2">𝐏</ci><ci id="S3.SS2.SSS2.p2.5.5.m5.1.1.3.cmml" xref="S3.SS2.SSS2.p2.5.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.5.5.m5.1c">\mathbf{P}^{i}</annotation></semantics></math>.</span></p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.4" class="ltx_p">We first construct the ground depth feature map in the camera coordinate system <math id="S3.SS2.SSS2.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS2.p3.1.m1.1a"><msup id="S3.SS2.SSS2.p3.1.m1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p3.1.m1.1.1.2" xref="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS2.p3.1.m1.1.1.3" xref="S3.SS2.SSS2.p3.1.m1.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.1b"><apply id="S3.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.1c">\mathbf{P}^{0}</annotation></semantics></math>.
Specifically, as illustrated in Figure <a href="#S3.SS2.SSS2" title="3.2.2 Virtual Scene Construction ‣ 3.2 Ground Depth Estimation ‣ 3 Design of MoGDE ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>, for each pixel on the depth image locating at <math id="S3.SS2.SSS2.p3.2.m2.2" class="ltx_Math" alttext="(u^{0},v^{0})" display="inline"><semantics id="S3.SS2.SSS2.p3.2.m2.2a"><mrow id="S3.SS2.SSS2.p3.2.m2.2.2.2" xref="S3.SS2.SSS2.p3.2.m2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS2.p3.2.m2.2.2.2.3" xref="S3.SS2.SSS2.p3.2.m2.2.2.3.cmml">(</mo><msup id="S3.SS2.SSS2.p3.2.m2.1.1.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.2" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.2.cmml">u</mi><mn id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.3" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.3.cmml">0</mn></msup><mo id="S3.SS2.SSS2.p3.2.m2.2.2.2.4" xref="S3.SS2.SSS2.p3.2.m2.2.2.3.cmml">,</mo><msup id="S3.SS2.SSS2.p3.2.m2.2.2.2.2" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.cmml"><mi id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.2" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.2.cmml">v</mi><mn id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.3" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.3.cmml">0</mn></msup><mo stretchy="false" id="S3.SS2.SSS2.p3.2.m2.2.2.2.5" xref="S3.SS2.SSS2.p3.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.2b"><interval closure="open" id="S3.SS2.SSS2.p3.2.m2.2.2.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2"><apply id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.2">𝑢</ci><cn type="integer" id="S3.SS2.SSS2.p3.2.m2.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.1.3">0</cn></apply><apply id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2">superscript</csymbol><ci id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.2">𝑣</ci><cn type="integer" id="S3.SS2.SSS2.p3.2.m2.2.2.2.2.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.2.2.2.2.3">0</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.2c">(u^{0},v^{0})</annotation></semantics></math> with an estimated depth <math id="S3.SS2.SSS2.p3.3.m3.1" class="ltx_Math" alttext="\hat{z}^{0}" display="inline"><semantics id="S3.SS2.SSS2.p3.3.m3.1a"><msup id="S3.SS2.SSS2.p3.3.m3.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.cmml"><mover accent="true" id="S3.SS2.SSS2.p3.3.m3.1.1.2" xref="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml"><mi id="S3.SS2.SSS2.p3.3.m3.1.1.2.2" xref="S3.SS2.SSS2.p3.3.m3.1.1.2.2.cmml">z</mi><mo id="S3.SS2.SSS2.p3.3.m3.1.1.2.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.2.1.cmml">^</mo></mover><mn id="S3.SS2.SSS2.p3.3.m3.1.1.3" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.3.m3.1b"><apply id="S3.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1">superscript</csymbol><apply id="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.2"><ci id="S3.SS2.SSS2.p3.3.m3.1.1.2.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.2.1">^</ci><ci id="S3.SS2.SSS2.p3.3.m3.1.1.2.2.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.2.2">𝑧</ci></apply><cn type="integer" id="S3.SS2.SSS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.3.m3.1c">\hat{z}^{0}</annotation></semantics></math>, it can be back-projected to a point (<math id="S3.SS2.SSS2.p3.4.m4.3" class="ltx_Math" alttext="x_{3d}^{0},y_{3d}^{0},\hat{z}^{0}" display="inline"><semantics id="S3.SS2.SSS2.p3.4.m4.3a"><mrow id="S3.SS2.SSS2.p3.4.m4.3.3.3" xref="S3.SS2.SSS2.p3.4.m4.3.3.4.cmml"><msubsup id="S3.SS2.SSS2.p3.4.m4.1.1.1.1" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.2" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.2.cmml">x</mi><mrow id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.cmml"><mn id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.2" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.1" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.3" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.3.cmml">d</mi></mrow><mn id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.3" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.3.cmml">0</mn></msubsup><mo id="S3.SS2.SSS2.p3.4.m4.3.3.3.4" xref="S3.SS2.SSS2.p3.4.m4.3.3.4.cmml">,</mo><msubsup id="S3.SS2.SSS2.p3.4.m4.2.2.2.2" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.cmml"><mi id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.2" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.2.cmml">y</mi><mrow id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.cmml"><mn id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.2" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.1" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.1.cmml">​</mo><mi id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.3" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.3.cmml">d</mi></mrow><mn id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.3" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.3.cmml">0</mn></msubsup><mo id="S3.SS2.SSS2.p3.4.m4.3.3.3.5" xref="S3.SS2.SSS2.p3.4.m4.3.3.4.cmml">,</mo><msup id="S3.SS2.SSS2.p3.4.m4.3.3.3.3" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3.cmml"><mover accent="true" id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.cmml"><mi id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.2" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.2.cmml">z</mi><mo id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.1" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.1.cmml">^</mo></mover><mn id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.3" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3.3.cmml">0</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.4.m4.3b"><list id="S3.SS2.SSS2.p3.4.m4.3.3.4.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.3"><apply id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1">superscript</csymbol><apply id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.2">𝑥</ci><apply id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3"><times id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.1"></times><cn type="integer" id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.2">3</cn><ci id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.2.3.3">𝑑</ci></apply></apply><cn type="integer" id="S3.SS2.SSS2.p3.4.m4.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.1.3">0</cn></apply><apply id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2">superscript</csymbol><apply id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.2">𝑦</ci><apply id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3"><times id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.1"></times><cn type="integer" id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.2">3</cn><ci id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.2.3.3">𝑑</ci></apply></apply><cn type="integer" id="S3.SS2.SSS2.p3.4.m4.2.2.2.2.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.2.2.3">0</cn></apply><apply id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3">superscript</csymbol><apply id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2"><ci id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.1">^</ci><ci id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3.2.2">𝑧</ci></apply><cn type="integer" id="S3.SS2.SSS2.p3.4.m4.3.3.3.3.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.3.3">0</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.4.m4.3c">x_{3d}^{0},y_{3d}^{0},\hat{z}^{0}</annotation></semantics></math>) in the 3D scene:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="x_{3d}^{0}=\frac{u^{0}-c_{x}}{f_{x}}\hat{z}^{0}\quad y_{3d}^{0}=\frac{v^{0}-c_{y}}{f_{y}}\hat{z}^{0}," display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1"><mrow id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><msubsup id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.cmml">x</mi><mrow id="S3.E2.m1.1.1.1.1.1.1.2.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3.cmml"><mn id="S3.E2.m1.1.1.1.1.1.1.2.2.3.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.2.2.3.1" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.1.1.2.2.3.3" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3.3.cmml">d</mi></mrow><mn id="S3.E2.m1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.cmml">0</mn></msubsup><mo id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml"><mfrac id="S3.E2.m1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.cmml"><msup id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.2.cmml">u</mi><mn id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.3.cmml">0</mn></msup><mo id="S3.E2.m1.1.1.1.1.1.1.3.2.2.1" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml">−</mo><msub id="S3.E2.m1.1.1.1.1.1.1.3.2.2.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.2.cmml">c</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.3.cmml">x</mi></msub></mrow><msub id="S3.E2.m1.1.1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.2.cmml">f</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.cmml">x</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.1.1.3.1.cmml">​</mo><msup id="S3.E2.m1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.cmml"><mover accent="true" id="S3.E2.m1.1.1.1.1.1.1.3.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.3.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.3.2.2.cmml">z</mi><mo id="S3.E2.m1.1.1.1.1.1.1.3.3.2.1" xref="S3.E2.m1.1.1.1.1.1.1.3.3.2.1.cmml">^</mo></mover><mn id="S3.E2.m1.1.1.1.1.1.1.3.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.cmml">0</mn></msup></mrow></mrow><mspace width="1em" id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.3a.cmml"></mspace><mrow id="S3.E2.m1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.2.2.cmml"><msubsup id="S3.E2.m1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml">y</mi><mrow id="S3.E2.m1.1.1.1.1.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml"><mn id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.2.2.2.3.1" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.cmml">d</mi></mrow><mn id="S3.E2.m1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.3.cmml">0</mn></msubsup><mo id="S3.E2.m1.1.1.1.1.2.2.1" xref="S3.E2.m1.1.1.1.1.2.2.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml"><mfrac id="S3.E2.m1.1.1.1.1.2.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.3.2.cmml"><mrow id="S3.E2.m1.1.1.1.1.2.2.3.2.2" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.cmml"><msup id="S3.E2.m1.1.1.1.1.2.2.3.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.2.cmml">v</mi><mn id="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.3.cmml">0</mn></msup><mo id="S3.E2.m1.1.1.1.1.2.2.3.2.2.1" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.1.cmml">−</mo><msub id="S3.E2.m1.1.1.1.1.2.2.3.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.2.cmml">c</mi><mi id="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.3.cmml">y</mi></msub></mrow><msub id="S3.E2.m1.1.1.1.1.2.2.3.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.3.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.3.2.3.2.cmml">f</mi><mi id="S3.E2.m1.1.1.1.1.2.2.3.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.3.2.3.3.cmml">y</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.2.3.1" xref="S3.E2.m1.1.1.1.1.2.2.3.1.cmml">​</mo><msup id="S3.E2.m1.1.1.1.1.2.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.3.3.cmml"><mover accent="true" id="S3.E2.m1.1.1.1.1.2.2.3.3.2" xref="S3.E2.m1.1.1.1.1.2.2.3.3.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.3.3.2.2" xref="S3.E2.m1.1.1.1.1.2.2.3.3.2.2.cmml">z</mi><mo id="S3.E2.m1.1.1.1.1.2.2.3.3.2.1" xref="S3.E2.m1.1.1.1.1.2.2.3.3.2.1.cmml">^</mo></mover><mn id="S3.E2.m1.1.1.1.1.2.2.3.3.3" xref="S3.E2.m1.1.1.1.1.2.2.3.3.3.cmml">0</mn></msup></mrow></mrow></mrow><mo id="S3.E2.m1.1.1.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3a.cmml" xref="S3.E2.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"></eq><apply id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2">𝑥</ci><apply id="S3.E2.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3"><times id="S3.E2.m1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3.1"></times><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3.2">3</cn><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3.3">𝑑</ci></apply></apply><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3">0</cn></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><times id="S3.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.1"></times><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2"><divide id="S3.E2.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2"></divide><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2"><minus id="S3.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.1"></minus><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.2">𝑢</ci><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.3">0</cn></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.2">𝑐</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.3">𝑥</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.2">𝑓</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.3">𝑥</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.2"><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.2.1">^</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.2.2">𝑧</ci></apply><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3">0</cn></apply></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2"><eq id="S3.E2.m1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1"></eq><apply id="S3.E2.m1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2">𝑦</ci><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3"><times id="S3.E2.m1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.1"></times><cn type="integer" id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2">3</cn><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3">𝑑</ci></apply></apply><cn type="integer" id="S3.E2.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.3">0</cn></apply><apply id="S3.E2.m1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3"><times id="S3.E2.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.1"></times><apply id="S3.E2.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2"><divide id="S3.E2.m1.1.1.1.1.2.2.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2"></divide><apply id="S3.E2.m1.1.1.1.1.2.2.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2"><minus id="S3.E2.m1.1.1.1.1.2.2.3.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.1"></minus><apply id="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.2">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.2">𝑣</ci><cn type="integer" id="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.2.3">0</cn></apply><apply id="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.2">𝑐</ci><ci id="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.2.3.3">𝑦</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.3.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.3.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.3.2">𝑓</ci><ci id="S3.E2.m1.1.1.1.1.2.2.3.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2.3.3">𝑦</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.3">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.2.2.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.3.2"><ci id="S3.E2.m1.1.1.1.1.2.2.3.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.3.2.1">^</ci><ci id="S3.E2.m1.1.1.1.1.2.2.3.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.3.2.2">𝑧</ci></apply><cn type="integer" id="S3.E2.m1.1.1.1.1.2.2.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.3.3">0</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">x_{3d}^{0}=\frac{u^{0}-c_{x}}{f_{x}}\hat{z}^{0}\quad y_{3d}^{0}=\frac{v^{0}-c_{y}}{f_{y}}\hat{z}^{0},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS2.p3.14" class="ltx_p">where <math id="S3.SS2.SSS2.p3.5.m1.1" class="ltx_Math" alttext="f_{x}" display="inline"><semantics id="S3.SS2.SSS2.p3.5.m1.1a"><msub id="S3.SS2.SSS2.p3.5.m1.1.1" xref="S3.SS2.SSS2.p3.5.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p3.5.m1.1.1.2" xref="S3.SS2.SSS2.p3.5.m1.1.1.2.cmml">f</mi><mi id="S3.SS2.SSS2.p3.5.m1.1.1.3" xref="S3.SS2.SSS2.p3.5.m1.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.5.m1.1b"><apply id="S3.SS2.SSS2.p3.5.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.5.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.5.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.5.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.5.m1.1.1.2">𝑓</ci><ci id="S3.SS2.SSS2.p3.5.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.5.m1.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.5.m1.1c">f_{x}</annotation></semantics></math> and <math id="S3.SS2.SSS2.p3.6.m2.1" class="ltx_Math" alttext="f_{y}" display="inline"><semantics id="S3.SS2.SSS2.p3.6.m2.1a"><msub id="S3.SS2.SSS2.p3.6.m2.1.1" xref="S3.SS2.SSS2.p3.6.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p3.6.m2.1.1.2" xref="S3.SS2.SSS2.p3.6.m2.1.1.2.cmml">f</mi><mi id="S3.SS2.SSS2.p3.6.m2.1.1.3" xref="S3.SS2.SSS2.p3.6.m2.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.6.m2.1b"><apply id="S3.SS2.SSS2.p3.6.m2.1.1.cmml" xref="S3.SS2.SSS2.p3.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.6.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p3.6.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.6.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p3.6.m2.1.1.2">𝑓</ci><ci id="S3.SS2.SSS2.p3.6.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p3.6.m2.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.6.m2.1c">f_{y}</annotation></semantics></math> are the focal lengths represented in the units of pixels along the <math id="S3.SS2.SSS2.p3.7.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.SSS2.p3.7.m3.1a"><mi id="S3.SS2.SSS2.p3.7.m3.1.1" xref="S3.SS2.SSS2.p3.7.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.7.m3.1b"><ci id="S3.SS2.SSS2.p3.7.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.7.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.7.m3.1c">x</annotation></semantics></math>- and <math id="S3.SS2.SSS2.p3.8.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS2.SSS2.p3.8.m4.1a"><mi id="S3.SS2.SSS2.p3.8.m4.1.1" xref="S3.SS2.SSS2.p3.8.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.8.m4.1b"><ci id="S3.SS2.SSS2.p3.8.m4.1.1.cmml" xref="S3.SS2.SSS2.p3.8.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.8.m4.1c">y</annotation></semantics></math>-axis of the image plane and <math id="S3.SS2.SSS2.p3.9.m5.1" class="ltx_Math" alttext="c_{x}" display="inline"><semantics id="S3.SS2.SSS2.p3.9.m5.1a"><msub id="S3.SS2.SSS2.p3.9.m5.1.1" xref="S3.SS2.SSS2.p3.9.m5.1.1.cmml"><mi id="S3.SS2.SSS2.p3.9.m5.1.1.2" xref="S3.SS2.SSS2.p3.9.m5.1.1.2.cmml">c</mi><mi id="S3.SS2.SSS2.p3.9.m5.1.1.3" xref="S3.SS2.SSS2.p3.9.m5.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.9.m5.1b"><apply id="S3.SS2.SSS2.p3.9.m5.1.1.cmml" xref="S3.SS2.SSS2.p3.9.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.9.m5.1.1.1.cmml" xref="S3.SS2.SSS2.p3.9.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.9.m5.1.1.2.cmml" xref="S3.SS2.SSS2.p3.9.m5.1.1.2">𝑐</ci><ci id="S3.SS2.SSS2.p3.9.m5.1.1.3.cmml" xref="S3.SS2.SSS2.p3.9.m5.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.9.m5.1c">c_{x}</annotation></semantics></math> and <math id="S3.SS2.SSS2.p3.10.m6.1" class="ltx_Math" alttext="c_{y}" display="inline"><semantics id="S3.SS2.SSS2.p3.10.m6.1a"><msub id="S3.SS2.SSS2.p3.10.m6.1.1" xref="S3.SS2.SSS2.p3.10.m6.1.1.cmml"><mi id="S3.SS2.SSS2.p3.10.m6.1.1.2" xref="S3.SS2.SSS2.p3.10.m6.1.1.2.cmml">c</mi><mi id="S3.SS2.SSS2.p3.10.m6.1.1.3" xref="S3.SS2.SSS2.p3.10.m6.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.10.m6.1b"><apply id="S3.SS2.SSS2.p3.10.m6.1.1.cmml" xref="S3.SS2.SSS2.p3.10.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.10.m6.1.1.1.cmml" xref="S3.SS2.SSS2.p3.10.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.10.m6.1.1.2.cmml" xref="S3.SS2.SSS2.p3.10.m6.1.1.2">𝑐</ci><ci id="S3.SS2.SSS2.p3.10.m6.1.1.3.cmml" xref="S3.SS2.SSS2.p3.10.m6.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.10.m6.1c">c_{y}</annotation></semantics></math> are the possible displacement between the image center and the foot point. These are referred to as the camera intrinsic parameters <math id="S3.SS2.SSS2.p3.11.m7.1" class="ltx_Math" alttext="\mathbf{K}" display="inline"><semantics id="S3.SS2.SSS2.p3.11.m7.1a"><mi id="S3.SS2.SSS2.p3.11.m7.1.1" xref="S3.SS2.SSS2.p3.11.m7.1.1.cmml">𝐊</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.11.m7.1b"><ci id="S3.SS2.SSS2.p3.11.m7.1.1.cmml" xref="S3.SS2.SSS2.p3.11.m7.1.1">𝐊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.11.m7.1c">\mathbf{K}</annotation></semantics></math>.
We omit the camera extrinsic <math id="S3.SS2.SSS2.p3.12.m8.1" class="ltx_Math" alttext="\mathbf{T}" display="inline"><semantics id="S3.SS2.SSS2.p3.12.m8.1a"><mi id="S3.SS2.SSS2.p3.12.m8.1.1" xref="S3.SS2.SSS2.p3.12.m8.1.1.cmml">𝐓</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.12.m8.1b"><ci id="S3.SS2.SSS2.p3.12.m8.1.1.cmml" xref="S3.SS2.SSS2.p3.12.m8.1.1">𝐓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.12.m8.1c">\mathbf{T}</annotation></semantics></math> for the sake of simplicity, and the depth corresponding to each pixel on the image is solely determined by the camera intrinsic parameter <math id="S3.SS2.SSS2.p3.13.m9.1" class="ltx_Math" alttext="\mathbf{K}" display="inline"><semantics id="S3.SS2.SSS2.p3.13.m9.1a"><mi id="S3.SS2.SSS2.p3.13.m9.1.1" xref="S3.SS2.SSS2.p3.13.m9.1.1.cmml">𝐊</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.13.m9.1b"><ci id="S3.SS2.SSS2.p3.13.m9.1.1.cmml" xref="S3.SS2.SSS2.p3.13.m9.1.1">𝐊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.13.m9.1c">\mathbf{K}</annotation></semantics></math> under <math id="S3.SS2.SSS2.p3.14.m10.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS2.p3.14.m10.1a"><msup id="S3.SS2.SSS2.p3.14.m10.1.1" xref="S3.SS2.SSS2.p3.14.m10.1.1.cmml"><mi id="S3.SS2.SSS2.p3.14.m10.1.1.2" xref="S3.SS2.SSS2.p3.14.m10.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS2.p3.14.m10.1.1.3" xref="S3.SS2.SSS2.p3.14.m10.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.14.m10.1b"><apply id="S3.SS2.SSS2.p3.14.m10.1.1.cmml" xref="S3.SS2.SSS2.p3.14.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.14.m10.1.1.1.cmml" xref="S3.SS2.SSS2.p3.14.m10.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p3.14.m10.1.1.2.cmml" xref="S3.SS2.SSS2.p3.14.m10.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS2.p3.14.m10.1.1.3.cmml" xref="S3.SS2.SSS2.p3.14.m10.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.14.m10.1c">\mathbf{P}^{0}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<p id="S3.SS2.SSS2.p4.2" class="ltx_p">Assume that the elevation of the camera from the ground, denoted as <math id="S3.SS2.SSS2.p4.1.m1.1" class="ltx_Math" alttext="EL" display="inline"><semantics id="S3.SS2.SSS2.p4.1.m1.1a"><mrow id="S3.SS2.SSS2.p4.1.m1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p4.1.m1.1.1.2" xref="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p4.1.m1.1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS2.p4.1.m1.1.1.3" xref="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.1.m1.1b"><apply id="S3.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1"><times id="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.1"></times><ci id="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.2">𝐸</ci><ci id="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.1.m1.1c">EL</annotation></semantics></math>, is known (for instance, the mean height of all vehicles in the KITTI dataset, including ego vehicles, is 1.65m <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>), the depth of a point on the depth feature map <math id="S3.SS2.SSS2.p4.2.m2.2" class="ltx_Math" alttext="(u^{0},v^{0})" display="inline"><semantics id="S3.SS2.SSS2.p4.2.m2.2a"><mrow id="S3.SS2.SSS2.p4.2.m2.2.2.2" xref="S3.SS2.SSS2.p4.2.m2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS2.p4.2.m2.2.2.2.3" xref="S3.SS2.SSS2.p4.2.m2.2.2.3.cmml">(</mo><msup id="S3.SS2.SSS2.p4.2.m2.1.1.1.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p4.2.m2.1.1.1.1.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.1.1.2.cmml">u</mi><mn id="S3.SS2.SSS2.p4.2.m2.1.1.1.1.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.1.1.3.cmml">0</mn></msup><mo id="S3.SS2.SSS2.p4.2.m2.2.2.2.4" xref="S3.SS2.SSS2.p4.2.m2.2.2.3.cmml">,</mo><msup id="S3.SS2.SSS2.p4.2.m2.2.2.2.2" xref="S3.SS2.SSS2.p4.2.m2.2.2.2.2.cmml"><mi id="S3.SS2.SSS2.p4.2.m2.2.2.2.2.2" xref="S3.SS2.SSS2.p4.2.m2.2.2.2.2.2.cmml">v</mi><mn id="S3.SS2.SSS2.p4.2.m2.2.2.2.2.3" xref="S3.SS2.SSS2.p4.2.m2.2.2.2.2.3.cmml">0</mn></msup><mo stretchy="false" id="S3.SS2.SSS2.p4.2.m2.2.2.2.5" xref="S3.SS2.SSS2.p4.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.2.m2.2b"><interval closure="open" id="S3.SS2.SSS2.p4.2.m2.2.2.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.2.2.2"><apply id="S3.SS2.SSS2.p4.2.m2.1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p4.2.m2.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.1.1.2">𝑢</ci><cn type="integer" id="S3.SS2.SSS2.p4.2.m2.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.1.1.3">0</cn></apply><apply id="S3.SS2.SSS2.p4.2.m2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.2.m2.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.2.2.2.2">superscript</csymbol><ci id="S3.SS2.SSS2.p4.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.2.2.2.2.2">𝑣</ci><cn type="integer" id="S3.SS2.SSS2.p4.2.m2.2.2.2.2.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.2.2.2.2.3">0</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.2.m2.2c">(u^{0},v^{0})</annotation></semantics></math> can be calculated as:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="z^{0}=\frac{f_{y}\cdot EL}{v^{0}-c_{y}}." display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><msup id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.2.2.cmml">z</mi><mn id="S3.E3.m1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.2.3.cmml">0</mn></msup><mo id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml">=</mo><mfrac id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mrow id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml"><mrow id="S3.E3.m1.1.1.1.1.3.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.cmml"><msub id="S3.E3.m1.1.1.1.1.3.2.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.2.cmml"><mi id="S3.E3.m1.1.1.1.1.3.2.2.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2.cmml">f</mi><mi id="S3.E3.m1.1.1.1.1.3.2.2.2.3" xref="S3.E3.m1.1.1.1.1.3.2.2.2.3.cmml">y</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.1.1.1.1.3.2.2.1" xref="S3.E3.m1.1.1.1.1.3.2.2.1.cmml">⋅</mo><mi id="S3.E3.m1.1.1.1.1.3.2.2.3" xref="S3.E3.m1.1.1.1.1.3.2.2.3.cmml">E</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.2.1" xref="S3.E3.m1.1.1.1.1.3.2.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.2.3" xref="S3.E3.m1.1.1.1.1.3.2.3.cmml">L</mi></mrow><mrow id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3.cmml"><msup id="S3.E3.m1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.3.3.2.cmml"><mi id="S3.E3.m1.1.1.1.1.3.3.2.2" xref="S3.E3.m1.1.1.1.1.3.3.2.2.cmml">v</mi><mn id="S3.E3.m1.1.1.1.1.3.3.2.3" xref="S3.E3.m1.1.1.1.1.3.3.2.3.cmml">0</mn></msup><mo id="S3.E3.m1.1.1.1.1.3.3.1" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">−</mo><msub id="S3.E3.m1.1.1.1.1.3.3.3" xref="S3.E3.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.3.3.2" xref="S3.E3.m1.1.1.1.1.3.3.3.2.cmml">c</mi><mi id="S3.E3.m1.1.1.1.1.3.3.3.3" xref="S3.E3.m1.1.1.1.1.3.3.3.3.cmml">y</mi></msub></mrow></mfrac></mrow><mo lspace="0em" id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"></eq><apply id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2">𝑧</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3">0</cn></apply><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><divide id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3"></divide><apply id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2"><times id="S3.E3.m1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2.1"></times><apply id="S3.E3.m1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2"><ci id="S3.E3.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.1">⋅</ci><apply id="S3.E3.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.2.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.2">𝑓</ci><ci id="S3.E3.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.2.3">𝑦</ci></apply><ci id="S3.E3.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2.3">𝐸</ci></apply><ci id="S3.E3.m1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.3">𝐿</ci></apply><apply id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3"><minus id="S3.E3.m1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1"></minus><apply id="S3.E3.m1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.2">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.2.2">𝑣</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.2.3">0</cn></apply><apply id="S3.E3.m1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.2">𝑐</ci><ci id="S3.E3.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3.3">𝑦</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">z^{0}=\frac{f_{y}\cdot EL}{v^{0}-c_{y}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS2.p5" class="ltx_para">
<p id="S3.SS2.SSS2.p5.4" class="ltx_p">Note that (<a href="#S3.E3" title="In 3.2.2 Virtual Scene Construction ‣ 3.2 Ground Depth Estimation ‣ 3 Design of MoGDE ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) is not continuous when the point is near the vanishing point, <em id="S3.SS2.SSS2.p5.4.1" class="ltx_emph ltx_font_italic">i.e.</em>, <math id="S3.SS2.SSS2.p5.1.m1.1" class="ltx_Math" alttext="v^{0}=c_{y}" display="inline"><semantics id="S3.SS2.SSS2.p5.1.m1.1a"><mrow id="S3.SS2.SSS2.p5.1.m1.1.1" xref="S3.SS2.SSS2.p5.1.m1.1.1.cmml"><msup id="S3.SS2.SSS2.p5.1.m1.1.1.2" xref="S3.SS2.SSS2.p5.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS2.p5.1.m1.1.1.2.2" xref="S3.SS2.SSS2.p5.1.m1.1.1.2.2.cmml">v</mi><mn id="S3.SS2.SSS2.p5.1.m1.1.1.2.3" xref="S3.SS2.SSS2.p5.1.m1.1.1.2.3.cmml">0</mn></msup><mo id="S3.SS2.SSS2.p5.1.m1.1.1.1" xref="S3.SS2.SSS2.p5.1.m1.1.1.1.cmml">=</mo><msub id="S3.SS2.SSS2.p5.1.m1.1.1.3" xref="S3.SS2.SSS2.p5.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS2.p5.1.m1.1.1.3.2" xref="S3.SS2.SSS2.p5.1.m1.1.1.3.2.cmml">c</mi><mi id="S3.SS2.SSS2.p5.1.m1.1.1.3.3" xref="S3.SS2.SSS2.p5.1.m1.1.1.3.3.cmml">y</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.1.m1.1b"><apply id="S3.SS2.SSS2.p5.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1"><eq id="S3.SS2.SSS2.p5.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1.1"></eq><apply id="S3.SS2.SSS2.p5.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1.2">superscript</csymbol><ci id="S3.SS2.SSS2.p5.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1.2.2">𝑣</ci><cn type="integer" id="S3.SS2.SSS2.p5.1.m1.1.1.2.3.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1.2.3">0</cn></apply><apply id="S3.SS2.SSS2.p5.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS2.p5.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1.3.2">𝑐</ci><ci id="S3.SS2.SSS2.p5.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1.3.3">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.1.m1.1c">v^{0}=c_{y}</annotation></semantics></math>, and does not physically hold when <math id="S3.SS2.SSS2.p5.2.m2.1" class="ltx_Math" alttext="v^{0}\leq c_{y}" display="inline"><semantics id="S3.SS2.SSS2.p5.2.m2.1a"><mrow id="S3.SS2.SSS2.p5.2.m2.1.1" xref="S3.SS2.SSS2.p5.2.m2.1.1.cmml"><msup id="S3.SS2.SSS2.p5.2.m2.1.1.2" xref="S3.SS2.SSS2.p5.2.m2.1.1.2.cmml"><mi id="S3.SS2.SSS2.p5.2.m2.1.1.2.2" xref="S3.SS2.SSS2.p5.2.m2.1.1.2.2.cmml">v</mi><mn id="S3.SS2.SSS2.p5.2.m2.1.1.2.3" xref="S3.SS2.SSS2.p5.2.m2.1.1.2.3.cmml">0</mn></msup><mo id="S3.SS2.SSS2.p5.2.m2.1.1.1" xref="S3.SS2.SSS2.p5.2.m2.1.1.1.cmml">≤</mo><msub id="S3.SS2.SSS2.p5.2.m2.1.1.3" xref="S3.SS2.SSS2.p5.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS2.p5.2.m2.1.1.3.2" xref="S3.SS2.SSS2.p5.2.m2.1.1.3.2.cmml">c</mi><mi id="S3.SS2.SSS2.p5.2.m2.1.1.3.3" xref="S3.SS2.SSS2.p5.2.m2.1.1.3.3.cmml">y</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.2.m2.1b"><apply id="S3.SS2.SSS2.p5.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1"><leq id="S3.SS2.SSS2.p5.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.1"></leq><apply id="S3.SS2.SSS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.2">superscript</csymbol><ci id="S3.SS2.SSS2.p5.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.2.2">𝑣</ci><cn type="integer" id="S3.SS2.SSS2.p5.2.m2.1.1.2.3.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.2.3">0</cn></apply><apply id="S3.SS2.SSS2.p5.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS2.p5.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.3.2">𝑐</ci><ci id="S3.SS2.SSS2.p5.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.3.3">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.2.m2.1c">v^{0}\leq c_{y}</annotation></semantics></math>.
To address this problem, similar to the KITTI stereo setup, we encode the depth gradient value as an associated feature map using a virtual stereo setup with baseline <math id="S3.SS2.SSS2.p5.3.m3.1" class="ltx_Math" alttext="B=0.54" display="inline"><semantics id="S3.SS2.SSS2.p5.3.m3.1a"><mrow id="S3.SS2.SSS2.p5.3.m3.1.1" xref="S3.SS2.SSS2.p5.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p5.3.m3.1.1.2" xref="S3.SS2.SSS2.p5.3.m3.1.1.2.cmml">B</mi><mo id="S3.SS2.SSS2.p5.3.m3.1.1.1" xref="S3.SS2.SSS2.p5.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS2.p5.3.m3.1.1.3" xref="S3.SS2.SSS2.p5.3.m3.1.1.3.cmml">0.54</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.3.m3.1b"><apply id="S3.SS2.SSS2.p5.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p5.3.m3.1.1"><eq id="S3.SS2.SSS2.p5.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p5.3.m3.1.1.1"></eq><ci id="S3.SS2.SSS2.p5.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p5.3.m3.1.1.2">𝐵</ci><cn type="float" id="S3.SS2.SSS2.p5.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p5.3.m3.1.1.3">0.54</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.3.m3.1c">B=0.54</annotation></semantics></math>m. We represent the ground depth <math id="S3.SS2.SSS2.p5.4.m4.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.SSS2.p5.4.m4.1a"><mi id="S3.SS2.SSS2.p5.4.m4.1.1" xref="S3.SS2.SSS2.p5.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.4.m4.1b"><ci id="S3.SS2.SSS2.p5.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.4.m4.1c">d</annotation></semantics></math> in the following form:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.2" class="ltx_Math" alttext="d=\operatorname{ReLU}(f_{y}\cdot B\frac{v^{0}-c_{y}}{f_{y}\cdot EL+b})" display="block"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml"><mi id="S3.E4.m1.2.2.3" xref="S3.E4.m1.2.2.3.cmml">d</mi><mo id="S3.E4.m1.2.2.2" xref="S3.E4.m1.2.2.2.cmml">=</mo><mrow id="S3.E4.m1.2.2.1.1" xref="S3.E4.m1.2.2.1.2.cmml"><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">ReLU</mi><mo id="S3.E4.m1.2.2.1.1a" xref="S3.E4.m1.2.2.1.2.cmml">⁡</mo><mrow id="S3.E4.m1.2.2.1.1.1" xref="S3.E4.m1.2.2.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.1.1.1.2" xref="S3.E4.m1.2.2.1.2.cmml">(</mo><mrow id="S3.E4.m1.2.2.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E4.m1.2.2.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.2.cmml"><msub id="S3.E4.m1.2.2.1.1.1.1.2.2" xref="S3.E4.m1.2.2.1.1.1.1.2.2.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.2.2.2.cmml">f</mi><mi id="S3.E4.m1.2.2.1.1.1.1.2.2.3" xref="S3.E4.m1.2.2.1.1.1.1.2.2.3.cmml">y</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.2.2.1.1.1.1.2.1" xref="S3.E4.m1.2.2.1.1.1.1.2.1.cmml">⋅</mo><mi id="S3.E4.m1.2.2.1.1.1.1.2.3" xref="S3.E4.m1.2.2.1.1.1.1.2.3.cmml">B</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.cmml">​</mo><mfrac id="S3.E4.m1.2.2.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.3.cmml"><mrow id="S3.E4.m1.2.2.1.1.1.1.3.2" xref="S3.E4.m1.2.2.1.1.1.1.3.2.cmml"><msup id="S3.E4.m1.2.2.1.1.1.1.3.2.2" xref="S3.E4.m1.2.2.1.1.1.1.3.2.2.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.3.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.3.2.2.2.cmml">v</mi><mn id="S3.E4.m1.2.2.1.1.1.1.3.2.2.3" xref="S3.E4.m1.2.2.1.1.1.1.3.2.2.3.cmml">0</mn></msup><mo id="S3.E4.m1.2.2.1.1.1.1.3.2.1" xref="S3.E4.m1.2.2.1.1.1.1.3.2.1.cmml">−</mo><msub id="S3.E4.m1.2.2.1.1.1.1.3.2.3" xref="S3.E4.m1.2.2.1.1.1.1.3.2.3.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.3.2.3.2" xref="S3.E4.m1.2.2.1.1.1.1.3.2.3.2.cmml">c</mi><mi id="S3.E4.m1.2.2.1.1.1.1.3.2.3.3" xref="S3.E4.m1.2.2.1.1.1.1.3.2.3.3.cmml">y</mi></msub></mrow><mrow id="S3.E4.m1.2.2.1.1.1.1.3.3" xref="S3.E4.m1.2.2.1.1.1.1.3.3.cmml"><mrow id="S3.E4.m1.2.2.1.1.1.1.3.3.2" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.cmml"><mrow id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.cmml"><msub id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.2.cmml">f</mi><mi id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.3" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.3.cmml">y</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.1" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.1.cmml">⋅</mo><mi id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.3" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.3.cmml">E</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.1.1.1.1.3.3.2.1" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.1.cmml">​</mo><mi id="S3.E4.m1.2.2.1.1.1.1.3.3.2.3" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.3.cmml">L</mi></mrow><mo id="S3.E4.m1.2.2.1.1.1.1.3.3.1" xref="S3.E4.m1.2.2.1.1.1.1.3.3.1.cmml">+</mo><mi id="S3.E4.m1.2.2.1.1.1.1.3.3.3" xref="S3.E4.m1.2.2.1.1.1.1.3.3.3.cmml">b</mi></mrow></mfrac></mrow><mo stretchy="false" id="S3.E4.m1.2.2.1.1.1.3" xref="S3.E4.m1.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"><eq id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.2"></eq><ci id="S3.E4.m1.2.2.3.cmml" xref="S3.E4.m1.2.2.3">𝑑</ci><apply id="S3.E4.m1.2.2.1.2.cmml" xref="S3.E4.m1.2.2.1.1"><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">ReLU</ci><apply id="S3.E4.m1.2.2.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1"><times id="S3.E4.m1.2.2.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1"></times><apply id="S3.E4.m1.2.2.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.2"><ci id="S3.E4.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.2.1">⋅</ci><apply id="S3.E4.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.2.2.2">𝑓</ci><ci id="S3.E4.m1.2.2.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.2.2.3">𝑦</ci></apply><ci id="S3.E4.m1.2.2.1.1.1.1.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.2.3">𝐵</ci></apply><apply id="S3.E4.m1.2.2.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3"><divide id="S3.E4.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3"></divide><apply id="S3.E4.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2"><minus id="S3.E4.m1.2.2.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2.1"></minus><apply id="S3.E4.m1.2.2.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.3.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2.2">superscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.3.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2.2.2">𝑣</ci><cn type="integer" id="S3.E4.m1.2.2.1.1.1.1.3.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2.2.3">0</cn></apply><apply id="S3.E4.m1.2.2.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.3.2.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.3.2.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2.3.2">𝑐</ci><ci id="S3.E4.m1.2.2.1.1.1.1.3.2.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.2.3.3">𝑦</ci></apply></apply><apply id="S3.E4.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3"><plus id="S3.E4.m1.2.2.1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.1"></plus><apply id="S3.E4.m1.2.2.1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2"><times id="S3.E4.m1.2.2.1.1.1.1.3.3.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.1"></times><apply id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2"><ci id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.1">⋅</ci><apply id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.2">𝑓</ci><ci id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.2.3">𝑦</ci></apply><ci id="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.2.3">𝐸</ci></apply><ci id="S3.E4.m1.2.2.1.1.1.1.3.3.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.2.3">𝐿</ci></apply><ci id="S3.E4.m1.2.2.1.1.1.1.3.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.3.3.3">𝑏</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">d=\operatorname{ReLU}(f_{y}\cdot B\frac{v^{0}-c_{y}}{f_{y}\cdot EL+b})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS2.p5.6" class="ltx_p">where <math id="S3.SS2.SSS2.p5.5.m1.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S3.SS2.SSS2.p5.5.m1.1a"><mi id="S3.SS2.SSS2.p5.5.m1.1.1" xref="S3.SS2.SSS2.p5.5.m1.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.5.m1.1b"><ci id="S3.SS2.SSS2.p5.5.m1.1.1.cmml" xref="S3.SS2.SSS2.p5.5.m1.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.5.m1.1c">b</annotation></semantics></math> is a constant to prevent the value of <math id="S3.SS2.SSS2.p5.6.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.SSS2.p5.6.m2.1a"><mi id="S3.SS2.SSS2.p5.6.m2.1.1" xref="S3.SS2.SSS2.p5.6.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.6.m2.1b"><ci id="S3.SS2.SSS2.p5.6.m2.1.1.cmml" xref="S3.SS2.SSS2.p5.6.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.6.m2.1c">d</annotation></semantics></math> from being too large. The ReLU activation is applied to suppress ground depth values smaller than zero, which is not physically feasible for monocular cameras.
As a result, the ground depth feature map becomes spatially continuous and consistent.</p>
</div>
<div id="S3.SS2.SSS2.p6" class="ltx_para">
<p id="S3.SS2.SSS2.p6.1" class="ltx_p">Finally, to obtain the ground depth feature map in <math id="S3.SS2.SSS2.p6.1.m1.1" class="ltx_Math" alttext="\mathbf{P}^{i}" display="inline"><semantics id="S3.SS2.SSS2.p6.1.m1.1a"><msup id="S3.SS2.SSS2.p6.1.m1.1.1" xref="S3.SS2.SSS2.p6.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p6.1.m1.1.1.2" xref="S3.SS2.SSS2.p6.1.m1.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.SSS2.p6.1.m1.1.1.3" xref="S3.SS2.SSS2.p6.1.m1.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p6.1.m1.1b"><apply id="S3.SS2.SSS2.p6.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p6.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p6.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p6.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p6.1.m1.1.1.2">𝐏</ci><ci id="S3.SS2.SSS2.p6.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p6.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p6.1.m1.1c">\mathbf{P}^{i}</annotation></semantics></math>, the model needs to convert the 3D coordinate system first, and then just apply (<a href="#S3.E4" title="In 3.2.2 Virtual Scene Construction ‣ 3.2 Ground Depth Estimation ‣ 3 Design of MoGDE ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). We omit the formula derivation due to page limitation.</p>
</div>
<figure id="S3.SS2.SSS2.19" class="ltx_figure ltx_minipage ltx_align_middle" style="width:195.1pt;"><img src="/html/2303.13561/assets/x2.png" id="S3.SS2.SSS2.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="327" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Perspective geometry for ground depth estimation.
In the camera coordinate system <math id="S3.SS2.SSS2.11.10.m1.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS2.11.10.m1.1b"><msup id="S3.SS2.SSS2.11.10.m1.1.1" xref="S3.SS2.SSS2.11.10.m1.1.1.cmml"><mi id="S3.SS2.SSS2.11.10.m1.1.1.2" xref="S3.SS2.SSS2.11.10.m1.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS2.11.10.m1.1.1.3" xref="S3.SS2.SSS2.11.10.m1.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.11.10.m1.1c"><apply id="S3.SS2.SSS2.11.10.m1.1.1.cmml" xref="S3.SS2.SSS2.11.10.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.11.10.m1.1.1.1.cmml" xref="S3.SS2.SSS2.11.10.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.11.10.m1.1.1.2.cmml" xref="S3.SS2.SSS2.11.10.m1.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS2.11.10.m1.1.1.3.cmml" xref="S3.SS2.SSS2.11.10.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.11.10.m1.1d">\mathbf{P}^{0}</annotation></semantics></math>, given the camera intrinsic parameters <math id="S3.SS2.SSS2.12.11.m2.1" class="ltx_Math" alttext="\mathbf{K}" display="inline"><semantics id="S3.SS2.SSS2.12.11.m2.1b"><mi id="S3.SS2.SSS2.12.11.m2.1.1" xref="S3.SS2.SSS2.12.11.m2.1.1.cmml">𝐊</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.12.11.m2.1c"><ci id="S3.SS2.SSS2.12.11.m2.1.1.cmml" xref="S3.SS2.SSS2.12.11.m2.1.1">𝐊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.12.11.m2.1d">\mathbf{K}</annotation></semantics></math> and the elevation of the camera from the ground <math id="S3.SS2.SSS2.13.12.m3.1" class="ltx_Math" alttext="EL" display="inline"><semantics id="S3.SS2.SSS2.13.12.m3.1b"><mrow id="S3.SS2.SSS2.13.12.m3.1.1" xref="S3.SS2.SSS2.13.12.m3.1.1.cmml"><mi id="S3.SS2.SSS2.13.12.m3.1.1.2" xref="S3.SS2.SSS2.13.12.m3.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.13.12.m3.1.1.1" xref="S3.SS2.SSS2.13.12.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS2.13.12.m3.1.1.3" xref="S3.SS2.SSS2.13.12.m3.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.13.12.m3.1c"><apply id="S3.SS2.SSS2.13.12.m3.1.1.cmml" xref="S3.SS2.SSS2.13.12.m3.1.1"><times id="S3.SS2.SSS2.13.12.m3.1.1.1.cmml" xref="S3.SS2.SSS2.13.12.m3.1.1.1"></times><ci id="S3.SS2.SSS2.13.12.m3.1.1.2.cmml" xref="S3.SS2.SSS2.13.12.m3.1.1.2">𝐸</ci><ci id="S3.SS2.SSS2.13.12.m3.1.1.3.cmml" xref="S3.SS2.SSS2.13.12.m3.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.13.12.m3.1d">EL</annotation></semantics></math>, the depth of a point on the ground depth feature map can be calculated. Moreover, by estimating the transformation matrix <math id="S3.SS2.SSS2.14.13.m4.1" class="ltx_Math" alttext="\mathbf{A}" display="inline"><semantics id="S3.SS2.SSS2.14.13.m4.1b"><mi id="S3.SS2.SSS2.14.13.m4.1.1" xref="S3.SS2.SSS2.14.13.m4.1.1.cmml">𝐀</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.14.13.m4.1c"><ci id="S3.SS2.SSS2.14.13.m4.1.1.cmml" xref="S3.SS2.SSS2.14.13.m4.1.1">𝐀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.14.13.m4.1d">\mathbf{A}</annotation></semantics></math> between <math id="S3.SS2.SSS2.15.14.m5.1" class="ltx_Math" alttext="\mathbf{P}^{0}" display="inline"><semantics id="S3.SS2.SSS2.15.14.m5.1b"><msup id="S3.SS2.SSS2.15.14.m5.1.1" xref="S3.SS2.SSS2.15.14.m5.1.1.cmml"><mi id="S3.SS2.SSS2.15.14.m5.1.1.2" xref="S3.SS2.SSS2.15.14.m5.1.1.2.cmml">𝐏</mi><mn id="S3.SS2.SSS2.15.14.m5.1.1.3" xref="S3.SS2.SSS2.15.14.m5.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.15.14.m5.1c"><apply id="S3.SS2.SSS2.15.14.m5.1.1.cmml" xref="S3.SS2.SSS2.15.14.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.15.14.m5.1.1.1.cmml" xref="S3.SS2.SSS2.15.14.m5.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.15.14.m5.1.1.2.cmml" xref="S3.SS2.SSS2.15.14.m5.1.1.2">𝐏</ci><cn type="integer" id="S3.SS2.SSS2.15.14.m5.1.1.3.cmml" xref="S3.SS2.SSS2.15.14.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.15.14.m5.1d">\mathbf{P}^{0}</annotation></semantics></math> and an arbitrary <math id="S3.SS2.SSS2.16.15.m6.1" class="ltx_Math" alttext="\mathbf{P}^{i}" display="inline"><semantics id="S3.SS2.SSS2.16.15.m6.1b"><msup id="S3.SS2.SSS2.16.15.m6.1.1" xref="S3.SS2.SSS2.16.15.m6.1.1.cmml"><mi id="S3.SS2.SSS2.16.15.m6.1.1.2" xref="S3.SS2.SSS2.16.15.m6.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.SSS2.16.15.m6.1.1.3" xref="S3.SS2.SSS2.16.15.m6.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.16.15.m6.1c"><apply id="S3.SS2.SSS2.16.15.m6.1.1.cmml" xref="S3.SS2.SSS2.16.15.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.16.15.m6.1.1.1.cmml" xref="S3.SS2.SSS2.16.15.m6.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.16.15.m6.1.1.2.cmml" xref="S3.SS2.SSS2.16.15.m6.1.1.2">𝐏</ci><ci id="S3.SS2.SSS2.16.15.m6.1.1.3.cmml" xref="S3.SS2.SSS2.16.15.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.16.15.m6.1d">\mathbf{P}^{i}</annotation></semantics></math>, the ground depth feature map in <math id="S3.SS2.SSS2.17.16.m7.1" class="ltx_Math" alttext="\mathbf{P}^{i}" display="inline"><semantics id="S3.SS2.SSS2.17.16.m7.1b"><msup id="S3.SS2.SSS2.17.16.m7.1.1" xref="S3.SS2.SSS2.17.16.m7.1.1.cmml"><mi id="S3.SS2.SSS2.17.16.m7.1.1.2" xref="S3.SS2.SSS2.17.16.m7.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.SSS2.17.16.m7.1.1.3" xref="S3.SS2.SSS2.17.16.m7.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.17.16.m7.1c"><apply id="S3.SS2.SSS2.17.16.m7.1.1.cmml" xref="S3.SS2.SSS2.17.16.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.17.16.m7.1.1.1.cmml" xref="S3.SS2.SSS2.17.16.m7.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.17.16.m7.1.1.2.cmml" xref="S3.SS2.SSS2.17.16.m7.1.1.2">𝐏</ci><ci id="S3.SS2.SSS2.17.16.m7.1.1.3.cmml" xref="S3.SS2.SSS2.17.16.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.17.16.m7.1d">\mathbf{P}^{i}</annotation></semantics></math> can be obtained. To utilize the ground depth feature, it is key to locate <em id="S3.SS2.SSS2.19.24.1" class="ltx_emph ltx_font_italic">ground-contacting</em> points of an object (<em id="S3.SS2.SSS2.19.25.2" class="ltx_emph ltx_font_italic">e.g.</em>, the dark point) to get an accurate depth (<em id="S3.SS2.SSS2.19.26.3" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S3.SS2.SSS2.18.17.m8.1" class="ltx_Math" alttext="z_{r}^{0}" display="inline"><semantics id="S3.SS2.SSS2.18.17.m8.1b"><msubsup id="S3.SS2.SSS2.18.17.m8.1.1" xref="S3.SS2.SSS2.18.17.m8.1.1.cmml"><mi id="S3.SS2.SSS2.18.17.m8.1.1.2.2" xref="S3.SS2.SSS2.18.17.m8.1.1.2.2.cmml">z</mi><mi id="S3.SS2.SSS2.18.17.m8.1.1.2.3" xref="S3.SS2.SSS2.18.17.m8.1.1.2.3.cmml">r</mi><mn id="S3.SS2.SSS2.18.17.m8.1.1.3" xref="S3.SS2.SSS2.18.17.m8.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.18.17.m8.1c"><apply id="S3.SS2.SSS2.18.17.m8.1.1.cmml" xref="S3.SS2.SSS2.18.17.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.18.17.m8.1.1.1.cmml" xref="S3.SS2.SSS2.18.17.m8.1.1">superscript</csymbol><apply id="S3.SS2.SSS2.18.17.m8.1.1.2.cmml" xref="S3.SS2.SSS2.18.17.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.18.17.m8.1.1.2.1.cmml" xref="S3.SS2.SSS2.18.17.m8.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.18.17.m8.1.1.2.2.cmml" xref="S3.SS2.SSS2.18.17.m8.1.1.2.2">𝑧</ci><ci id="S3.SS2.SSS2.18.17.m8.1.1.2.3.cmml" xref="S3.SS2.SSS2.18.17.m8.1.1.2.3">𝑟</ci></apply><cn type="integer" id="S3.SS2.SSS2.18.17.m8.1.1.3.cmml" xref="S3.SS2.SSS2.18.17.m8.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.18.17.m8.1d">z_{r}^{0}</annotation></semantics></math>). On the contrary, misuse of the depth in the ground depth feature corresponding to other points on the object (<em id="S3.SS2.SSS2.19.27.4" class="ltx_emph ltx_font_italic">e.g.</em>, the bright point) leads to obvious depth estimation error (<em id="S3.SS2.SSS2.19.28.5" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S3.SS2.SSS2.19.18.m9.1" class="ltx_Math" alttext="z^{0}" display="inline"><semantics id="S3.SS2.SSS2.19.18.m9.1b"><msup id="S3.SS2.SSS2.19.18.m9.1.1" xref="S3.SS2.SSS2.19.18.m9.1.1.cmml"><mi id="S3.SS2.SSS2.19.18.m9.1.1.2" xref="S3.SS2.SSS2.19.18.m9.1.1.2.cmml">z</mi><mn id="S3.SS2.SSS2.19.18.m9.1.1.3" xref="S3.SS2.SSS2.19.18.m9.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.19.18.m9.1c"><apply id="S3.SS2.SSS2.19.18.m9.1.1.cmml" xref="S3.SS2.SSS2.19.18.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.19.18.m9.1.1.1.cmml" xref="S3.SS2.SSS2.19.18.m9.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.19.18.m9.1.1.2.cmml" xref="S3.SS2.SSS2.19.18.m9.1.1.2">𝑧</ci><cn type="integer" id="S3.SS2.SSS2.19.18.m9.1.1.3.cmml" xref="S3.SS2.SSS2.19.18.m9.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.19.18.m9.1d">z^{0}</annotation></semantics></math>). </figcaption>
</figure>
<figure id="S3.SS2.SSS2.20" class="ltx_figure ltx_minipage ltx_align_middle" style="width:229.8pt;"><img src="/html/2303.13561/assets/x3.png" id="S3.SS2.SSS2.20.g1" class="ltx_graphics ltx_centering ltx_img_square" width="415" height="452" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The architecture of <span id="S3.SS2.SSS2.20.3.1" class="ltx_text ltx_font_italic">ground-aware</span> transformer.
The encoder uses self-attention to encode the non-local mutual correlation of image pixels (<span id="S3.SS2.SSS2.20.4.2" class="ltx_text ltx_font_italic">i.e.</span>, object centers and ground points). The ground depth estimate is used to generate location queries which are thereby fed to the decoder along with the location encoding. The cross-attention in the decoder prompts each query to consider the image and depth features of its associated points.</figcaption>
</figure>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Ground Depth Fusion</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.4" class="ltx_p">In real-world scenarios, as depicted in Figure <a href="#S3.SS2.SSS2" title="3.2.2 Virtual Scene Construction ‣ 3.2 Ground Depth Estimation ‣ 3 Design of MoGDE ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>, objects have height. To fuse the image feature and the ground depth feature, it is key to locate <em id="S3.SS3.p1.4.1" class="ltx_emph ltx_font_italic">ground-contacting</em> points of an object (<em id="S3.SS3.p1.4.2" class="ltx_emph ltx_font_italic">e.g.</em>, the dark point) to get an accurate depth (<em id="S3.SS3.p1.4.3" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="z_{r}^{0}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msubsup id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.2.2.cmml">z</mi><mi id="S3.SS3.p1.1.m1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.2.3.cmml">r</mi><mn id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">superscript</csymbol><apply id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2.2">𝑧</ci><ci id="S3.SS3.p1.1.m1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3">𝑟</ci></apply><cn type="integer" id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">z_{r}^{0}</annotation></semantics></math>). On the contrary, misuse of the depth in the ground depth feature corresponding to other points on the object (<em id="S3.SS3.p1.4.4" class="ltx_emph ltx_font_italic">e.g.</em>, the bright point) leads to obvious depth estimation error (<em id="S3.SS3.p1.4.5" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="z^{0}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msup id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">z</mi><mn id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝑧</ci><cn type="integer" id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">z^{0}</annotation></semantics></math>).
Specifically, the relation between the estimated depth of an object <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="\hat{z}^{0}" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><msup id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mover accent="true" id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2.2" xref="S3.SS3.p1.3.m3.1.1.2.2.cmml">z</mi><mo id="S3.SS3.p1.3.m3.1.1.2.1" xref="S3.SS3.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mn id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">superscript</csymbol><apply id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2"><ci id="S3.SS3.p1.3.m3.1.1.2.1.cmml" xref="S3.SS3.p1.3.m3.1.1.2.1">^</ci><ci id="S3.SS3.p1.3.m3.1.1.2.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2.2">𝑧</ci></apply><cn type="integer" id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">\hat{z}^{0}</annotation></semantics></math> and the pixel displacement in locating ground-contacting points, denoted as <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="T_{y}" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><msub id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">T</mi><mi id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">𝑇</ci><ci id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">T_{y}</annotation></semantics></math>, can be calculated as,</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="\hat{z}^{0}=\frac{EL\cdot f_{y}\cdot z_{r}^{0}}{EL\cdot f_{y}-z_{r}^{0}\cdot T_{y}}." display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><msup id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml"><mover accent="true" id="S3.E5.m1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.2.2.cmml"><mi id="S3.E5.m1.1.1.1.1.2.2.2" xref="S3.E5.m1.1.1.1.1.2.2.2.cmml">z</mi><mo id="S3.E5.m1.1.1.1.1.2.2.1" xref="S3.E5.m1.1.1.1.1.2.2.1.cmml">^</mo></mover><mn id="S3.E5.m1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.2.3.cmml">0</mn></msup><mo id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml">=</mo><mfrac id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml"><mrow id="S3.E5.m1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.3.2.cmml"><mrow id="S3.E5.m1.1.1.1.1.3.2.2" xref="S3.E5.m1.1.1.1.1.3.2.2.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2.2.2" xref="S3.E5.m1.1.1.1.1.3.2.2.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.1.3.2.2.1" xref="S3.E5.m1.1.1.1.1.3.2.2.1.cmml">​</mo><mi id="S3.E5.m1.1.1.1.1.3.2.2.3" xref="S3.E5.m1.1.1.1.1.3.2.2.3.cmml">L</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.3.2.1" xref="S3.E5.m1.1.1.1.1.3.2.1.cmml">⋅</mo><msub id="S3.E5.m1.1.1.1.1.3.2.3" xref="S3.E5.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2.3.2" xref="S3.E5.m1.1.1.1.1.3.2.3.2.cmml">f</mi><mi id="S3.E5.m1.1.1.1.1.3.2.3.3" xref="S3.E5.m1.1.1.1.1.3.2.3.3.cmml">y</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.3.2.1a" xref="S3.E5.m1.1.1.1.1.3.2.1.cmml">⋅</mo><msubsup id="S3.E5.m1.1.1.1.1.3.2.4" xref="S3.E5.m1.1.1.1.1.3.2.4.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2.4.2.2" xref="S3.E5.m1.1.1.1.1.3.2.4.2.2.cmml">z</mi><mi id="S3.E5.m1.1.1.1.1.3.2.4.2.3" xref="S3.E5.m1.1.1.1.1.3.2.4.2.3.cmml">r</mi><mn id="S3.E5.m1.1.1.1.1.3.2.4.3" xref="S3.E5.m1.1.1.1.1.3.2.4.3.cmml">0</mn></msubsup></mrow><mrow id="S3.E5.m1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.3.3.cmml"><mrow id="S3.E5.m1.1.1.1.1.3.3.2" xref="S3.E5.m1.1.1.1.1.3.3.2.cmml"><mrow id="S3.E5.m1.1.1.1.1.3.3.2.2" xref="S3.E5.m1.1.1.1.1.3.3.2.2.cmml"><mi id="S3.E5.m1.1.1.1.1.3.3.2.2.2" xref="S3.E5.m1.1.1.1.1.3.3.2.2.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.1.3.3.2.2.1" xref="S3.E5.m1.1.1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S3.E5.m1.1.1.1.1.3.3.2.2.3" xref="S3.E5.m1.1.1.1.1.3.3.2.2.3.cmml">L</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.3.3.2.1" xref="S3.E5.m1.1.1.1.1.3.3.2.1.cmml">⋅</mo><msub id="S3.E5.m1.1.1.1.1.3.3.2.3" xref="S3.E5.m1.1.1.1.1.3.3.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1.3.3.2.3.2" xref="S3.E5.m1.1.1.1.1.3.3.2.3.2.cmml">f</mi><mi id="S3.E5.m1.1.1.1.1.3.3.2.3.3" xref="S3.E5.m1.1.1.1.1.3.3.2.3.3.cmml">y</mi></msub></mrow><mo id="S3.E5.m1.1.1.1.1.3.3.1" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">−</mo><mrow id="S3.E5.m1.1.1.1.1.3.3.3" xref="S3.E5.m1.1.1.1.1.3.3.3.cmml"><msubsup id="S3.E5.m1.1.1.1.1.3.3.3.2" xref="S3.E5.m1.1.1.1.1.3.3.3.2.cmml"><mi id="S3.E5.m1.1.1.1.1.3.3.3.2.2.2" xref="S3.E5.m1.1.1.1.1.3.3.3.2.2.2.cmml">z</mi><mi id="S3.E5.m1.1.1.1.1.3.3.3.2.2.3" xref="S3.E5.m1.1.1.1.1.3.3.3.2.2.3.cmml">r</mi><mn id="S3.E5.m1.1.1.1.1.3.3.3.2.3" xref="S3.E5.m1.1.1.1.1.3.3.3.2.3.cmml">0</mn></msubsup><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.3.3.3.1" xref="S3.E5.m1.1.1.1.1.3.3.3.1.cmml">⋅</mo><msub id="S3.E5.m1.1.1.1.1.3.3.3.3" xref="S3.E5.m1.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.3.3.3.3.2" xref="S3.E5.m1.1.1.1.1.3.3.3.3.2.cmml">T</mi><mi id="S3.E5.m1.1.1.1.1.3.3.3.3.3" xref="S3.E5.m1.1.1.1.1.3.3.3.3.3.cmml">y</mi></msub></mrow></mrow></mfrac></mrow><mo lspace="0em" id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"></eq><apply id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2"><ci id="S3.E5.m1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2.2.1">^</ci><ci id="S3.E5.m1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2.2">𝑧</ci></apply><cn type="integer" id="S3.E5.m1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.3">0</cn></apply><apply id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"><divide id="S3.E5.m1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3"></divide><apply id="S3.E5.m1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2"><ci id="S3.E5.m1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.1">⋅</ci><apply id="S3.E5.m1.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2"><times id="S3.E5.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.1"></times><ci id="S3.E5.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.2">𝐸</ci><ci id="S3.E5.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2.3">𝐿</ci></apply><apply id="S3.E5.m1.1.1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.3.2">𝑓</ci><ci id="S3.E5.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2.3.3">𝑦</ci></apply><apply id="S3.E5.m1.1.1.1.1.3.2.4.cmml" xref="S3.E5.m1.1.1.1.1.3.2.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.2.4.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.4">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.3.2.4.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.2.4.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2.4">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.4.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.4.2.2">𝑧</ci><ci id="S3.E5.m1.1.1.1.1.3.2.4.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2.4.2.3">𝑟</ci></apply><cn type="integer" id="S3.E5.m1.1.1.1.1.3.2.4.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2.4.3">0</cn></apply></apply><apply id="S3.E5.m1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3"><minus id="S3.E5.m1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.1"></minus><apply id="S3.E5.m1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2"><ci id="S3.E5.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.1">⋅</ci><apply id="S3.E5.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.2"><times id="S3.E5.m1.1.1.1.1.3.3.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.2.1"></times><ci id="S3.E5.m1.1.1.1.1.3.3.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.2.2">𝐸</ci><ci id="S3.E5.m1.1.1.1.1.3.3.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.2.3">𝐿</ci></apply><apply id="S3.E5.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.3.2">𝑓</ci><ci id="S3.E5.m1.1.1.1.1.3.3.2.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.3.3">𝑦</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3"><ci id="S3.E5.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.1">⋅</ci><apply id="S3.E5.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.3.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.2">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.3.3.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.3.3.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.3.3.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.2.2.2">𝑧</ci><ci id="S3.E5.m1.1.1.1.1.3.3.3.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.2.2.3">𝑟</ci></apply><cn type="integer" id="S3.E5.m1.1.1.1.1.3.3.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.2.3">0</cn></apply><apply id="S3.E5.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.3.2">𝑇</ci><ci id="S3.E5.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.3.3">𝑦</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">\hat{z}^{0}=\frac{EL\cdot f_{y}\cdot z_{r}^{0}}{EL\cdot f_{y}-z_{r}^{0}\cdot T_{y}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.7" class="ltx_p">It can be seen from (<a href="#S3.E5" title="In 3.3 Ground Depth Fusion ‣ 3 Design of MoGDE ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) that <math id="S3.SS3.p1.5.m1.1" class="ltx_Math" alttext="T_{y}" display="inline"><semantics id="S3.SS3.p1.5.m1.1a"><msub id="S3.SS3.p1.5.m1.1.1" xref="S3.SS3.p1.5.m1.1.1.cmml"><mi id="S3.SS3.p1.5.m1.1.1.2" xref="S3.SS3.p1.5.m1.1.1.2.cmml">T</mi><mi id="S3.SS3.p1.5.m1.1.1.3" xref="S3.SS3.p1.5.m1.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m1.1b"><apply id="S3.SS3.p1.5.m1.1.1.cmml" xref="S3.SS3.p1.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m1.1.1.1.cmml" xref="S3.SS3.p1.5.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.5.m1.1.1.2.cmml" xref="S3.SS3.p1.5.m1.1.1.2">𝑇</ci><ci id="S3.SS3.p1.5.m1.1.1.3.cmml" xref="S3.SS3.p1.5.m1.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m1.1c">T_{y}</annotation></semantics></math> can cause inaccurate <math id="S3.SS3.p1.6.m2.1" class="ltx_Math" alttext="\hat{z}^{0}" display="inline"><semantics id="S3.SS3.p1.6.m2.1a"><msup id="S3.SS3.p1.6.m2.1.1" xref="S3.SS3.p1.6.m2.1.1.cmml"><mover accent="true" id="S3.SS3.p1.6.m2.1.1.2" xref="S3.SS3.p1.6.m2.1.1.2.cmml"><mi id="S3.SS3.p1.6.m2.1.1.2.2" xref="S3.SS3.p1.6.m2.1.1.2.2.cmml">z</mi><mo id="S3.SS3.p1.6.m2.1.1.2.1" xref="S3.SS3.p1.6.m2.1.1.2.1.cmml">^</mo></mover><mn id="S3.SS3.p1.6.m2.1.1.3" xref="S3.SS3.p1.6.m2.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m2.1b"><apply id="S3.SS3.p1.6.m2.1.1.cmml" xref="S3.SS3.p1.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m2.1.1.1.cmml" xref="S3.SS3.p1.6.m2.1.1">superscript</csymbol><apply id="S3.SS3.p1.6.m2.1.1.2.cmml" xref="S3.SS3.p1.6.m2.1.1.2"><ci id="S3.SS3.p1.6.m2.1.1.2.1.cmml" xref="S3.SS3.p1.6.m2.1.1.2.1">^</ci><ci id="S3.SS3.p1.6.m2.1.1.2.2.cmml" xref="S3.SS3.p1.6.m2.1.1.2.2">𝑧</ci></apply><cn type="integer" id="S3.SS3.p1.6.m2.1.1.3.cmml" xref="S3.SS3.p1.6.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m2.1c">\hat{z}^{0}</annotation></semantics></math>.
However, how to acquire <math id="S3.SS3.p1.7.m3.1" class="ltx_Math" alttext="T_{y}" display="inline"><semantics id="S3.SS3.p1.7.m3.1a"><msub id="S3.SS3.p1.7.m3.1.1" xref="S3.SS3.p1.7.m3.1.1.cmml"><mi id="S3.SS3.p1.7.m3.1.1.2" xref="S3.SS3.p1.7.m3.1.1.2.cmml">T</mi><mi id="S3.SS3.p1.7.m3.1.1.3" xref="S3.SS3.p1.7.m3.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m3.1b"><apply id="S3.SS3.p1.7.m3.1.1.cmml" xref="S3.SS3.p1.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m3.1.1.1.cmml" xref="S3.SS3.p1.7.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.7.m3.1.1.2.cmml" xref="S3.SS3.p1.7.m3.1.1.2">𝑇</ci><ci id="S3.SS3.p1.7.m3.1.1.3.cmml" xref="S3.SS3.p1.7.m3.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m3.1c">T_{y}</annotation></semantics></math> is non-trivial. Inspired by the great success of transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">64</span></a>, <a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>, <a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite> in adaptive long-range relational modeling, we propose a <span id="S3.SS3.p1.7.1" class="ltx_text ltx_font_italic">ground-aware</span> feature fusion method based on a transformer structure as depicted in Figure <a href="#S3.SS2.SSS2" title="3.2.2 Virtual Scene Construction ‣ 3.2 Ground Depth Estimation ‣ 3 Design of MoGDE ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>, leveraging its attention mechanism to automatically locate ground-contacting points of an object and fuse the corresponding depth feature with the image feature of that object.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.7" class="ltx_p"><span id="S3.SS3.p2.7.1" class="ltx_text ltx_font_bold">Encoder.</span>
Our transformer encoder aims to encode the correlation between image features using a self-attention mechanism.
The input of the transformer encoder is the flattened image features <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{H}_{\mathrm{img}}\in\mathbb{R}^{N\times C}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mrow id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><msub id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2.2" xref="S3.SS3.p2.1.m1.1.1.2.2.cmml">𝐇</mi><mi id="S3.SS3.p2.1.m1.1.1.2.3" xref="S3.SS3.p2.1.m1.1.1.2.3.cmml">img</mi></msub><mo id="S3.SS3.p2.1.m1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.3.2" xref="S3.SS3.p2.1.m1.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.1.m1.1.1.3.3.1" xref="S3.SS3.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p2.1.m1.1.1.3.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><in id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1"></in><apply id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.2.1.cmml" xref="S3.SS3.p2.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2.2">𝐇</ci><ci id="S3.SS3.p2.1.m1.1.1.2.3.cmml" xref="S3.SS3.p2.1.m1.1.1.2.3">img</ci></apply><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3"><times id="S3.SS3.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.1"></times><ci id="S3.SS3.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\mathbf{H}_{\mathrm{img}}\in\mathbb{R}^{N\times C}</annotation></semantics></math> with position encoding and the output is the embedding vectors <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{H}_{e}\in\mathbb{R}^{N\times C}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mrow id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><msub id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2.2" xref="S3.SS3.p2.2.m2.1.1.2.2.cmml">𝐇</mi><mi id="S3.SS3.p2.2.m2.1.1.2.3" xref="S3.SS3.p2.2.m2.1.1.2.3.cmml">e</mi></msub><mo id="S3.SS3.p2.2.m2.1.1.1" xref="S3.SS3.p2.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml"><mi id="S3.SS3.p2.2.m2.1.1.3.2" xref="S3.SS3.p2.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p2.2.m2.1.1.3.3" xref="S3.SS3.p2.2.m2.1.1.3.3.cmml"><mi id="S3.SS3.p2.2.m2.1.1.3.3.2" xref="S3.SS3.p2.2.m2.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.2.m2.1.1.3.3.1" xref="S3.SS3.p2.2.m2.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p2.2.m2.1.1.3.3.3" xref="S3.SS3.p2.2.m2.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><in id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1.1"></in><apply id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.2.1.cmml" xref="S3.SS3.p2.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2.2">𝐇</ci><ci id="S3.SS3.p2.2.m2.1.1.2.3.cmml" xref="S3.SS3.p2.2.m2.1.1.2.3">𝑒</ci></apply><apply id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.3.1.cmml" xref="S3.SS3.p2.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.3.2.cmml" xref="S3.SS3.p2.2.m2.1.1.3.2">ℝ</ci><apply id="S3.SS3.p2.2.m2.1.1.3.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3.3"><times id="S3.SS3.p2.2.m2.1.1.3.3.1.cmml" xref="S3.SS3.p2.2.m2.1.1.3.3.1"></times><ci id="S3.SS3.p2.2.m2.1.1.3.3.2.cmml" xref="S3.SS3.p2.2.m2.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p2.2.m2.1.1.3.3.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">\mathbf{H}_{e}\in\mathbb{R}^{N\times C}</annotation></semantics></math> to be sent to the decoder.
Following the self-attention pipeline, given the input matrix calculated from the image features: query <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{Q}\in\mathbb{R}^{N\times C}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mrow id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">𝐐</mi><mo id="S3.SS3.p2.3.m3.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.3.2" xref="S3.SS3.p2.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p2.3.m3.1.1.3.3" xref="S3.SS3.p2.3.m3.1.1.3.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.3.3.2" xref="S3.SS3.p2.3.m3.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.3.m3.1.1.3.3.1" xref="S3.SS3.p2.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p2.3.m3.1.1.3.3.3" xref="S3.SS3.p2.3.m3.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><in id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1"></in><ci id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">𝐐</ci><apply id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS3.p2.3.m3.1.1.3.2">ℝ</ci><apply id="S3.SS3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3"><times id="S3.SS3.p2.3.m3.1.1.3.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3.1"></times><ci id="S3.SS3.p2.3.m3.1.1.3.3.2.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p2.3.m3.1.1.3.3.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">\mathbf{Q}\in\mathbb{R}^{N\times C}</annotation></semantics></math>, key <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{K}\in\mathbb{R}^{N\times C}" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mrow id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">𝐊</mi><mo id="S3.SS3.p2.4.m4.1.1.1" xref="S3.SS3.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml"><mi id="S3.SS3.p2.4.m4.1.1.3.2" xref="S3.SS3.p2.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p2.4.m4.1.1.3.3" xref="S3.SS3.p2.4.m4.1.1.3.3.cmml"><mi id="S3.SS3.p2.4.m4.1.1.3.3.2" xref="S3.SS3.p2.4.m4.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.4.m4.1.1.3.3.1" xref="S3.SS3.p2.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p2.4.m4.1.1.3.3.3" xref="S3.SS3.p2.4.m4.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><in id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1.1"></in><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">𝐊</ci><apply id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.3.1.cmml" xref="S3.SS3.p2.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.4.m4.1.1.3.2.cmml" xref="S3.SS3.p2.4.m4.1.1.3.2">ℝ</ci><apply id="S3.SS3.p2.4.m4.1.1.3.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3.3"><times id="S3.SS3.p2.4.m4.1.1.3.3.1.cmml" xref="S3.SS3.p2.4.m4.1.1.3.3.1"></times><ci id="S3.SS3.p2.4.m4.1.1.3.3.2.cmml" xref="S3.SS3.p2.4.m4.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p2.4.m4.1.1.3.3.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\mathbf{K}\in\mathbb{R}^{N\times C}</annotation></semantics></math>, and value <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{V}\in\mathbb{R}^{N\times C}" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mrow id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">𝐕</mi><mo id="S3.SS3.p2.5.m5.1.1.1" xref="S3.SS3.p2.5.m5.1.1.1.cmml">∈</mo><msup id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml"><mi id="S3.SS3.p2.5.m5.1.1.3.2" xref="S3.SS3.p2.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p2.5.m5.1.1.3.3" xref="S3.SS3.p2.5.m5.1.1.3.3.cmml"><mi id="S3.SS3.p2.5.m5.1.1.3.3.2" xref="S3.SS3.p2.5.m5.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.5.m5.1.1.3.3.1" xref="S3.SS3.p2.5.m5.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p2.5.m5.1.1.3.3.3" xref="S3.SS3.p2.5.m5.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><in id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1.1"></in><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">𝐕</ci><apply id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.3.1.cmml" xref="S3.SS3.p2.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.5.m5.1.1.3.2.cmml" xref="S3.SS3.p2.5.m5.1.1.3.2">ℝ</ci><apply id="S3.SS3.p2.5.m5.1.1.3.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3.3"><times id="S3.SS3.p2.5.m5.1.1.3.3.1.cmml" xref="S3.SS3.p2.5.m5.1.1.3.3.1"></times><ci id="S3.SS3.p2.5.m5.1.1.3.3.2.cmml" xref="S3.SS3.p2.5.m5.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p2.5.m5.1.1.3.3.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">\mathbf{V}\in\mathbb{R}^{N\times C}</annotation></semantics></math> with sequence length <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="N=W\times H" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><mrow id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml"><mi id="S3.SS3.p2.6.m6.1.1.2" xref="S3.SS3.p2.6.m6.1.1.2.cmml">N</mi><mo id="S3.SS3.p2.6.m6.1.1.1" xref="S3.SS3.p2.6.m6.1.1.1.cmml">=</mo><mrow id="S3.SS3.p2.6.m6.1.1.3" xref="S3.SS3.p2.6.m6.1.1.3.cmml"><mi id="S3.SS3.p2.6.m6.1.1.3.2" xref="S3.SS3.p2.6.m6.1.1.3.2.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.6.m6.1.1.3.1" xref="S3.SS3.p2.6.m6.1.1.3.1.cmml">×</mo><mi id="S3.SS3.p2.6.m6.1.1.3.3" xref="S3.SS3.p2.6.m6.1.1.3.3.cmml">H</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><apply id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1"><eq id="S3.SS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1.1"></eq><ci id="S3.SS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.2">𝑁</ci><apply id="S3.SS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3"><times id="S3.SS3.p2.6.m6.1.1.3.1.cmml" xref="S3.SS3.p2.6.m6.1.1.3.1"></times><ci id="S3.SS3.p2.6.m6.1.1.3.2.cmml" xref="S3.SS3.p2.6.m6.1.1.3.2">𝑊</ci><ci id="S3.SS3.p2.6.m6.1.1.3.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3.3">𝐻</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">N=W\times H</annotation></semantics></math>, the output of <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="l+1" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><mrow id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml"><mi id="S3.SS3.p2.7.m7.1.1.2" xref="S3.SS3.p2.7.m7.1.1.2.cmml">l</mi><mo id="S3.SS3.p2.7.m7.1.1.1" xref="S3.SS3.p2.7.m7.1.1.1.cmml">+</mo><mn id="S3.SS3.p2.7.m7.1.1.3" xref="S3.SS3.p2.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><apply id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1"><plus id="S3.SS3.p2.7.m7.1.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1.1"></plus><ci id="S3.SS3.p2.7.m7.1.1.2.cmml" xref="S3.SS3.p2.7.m7.1.1.2">𝑙</ci><cn type="integer" id="S3.SS3.p2.7.m7.1.1.3.cmml" xref="S3.SS3.p2.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">l+1</annotation></semantics></math>-th layer of self-attention can be briefly formulated as:</p>
<table id="S3.E6" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E6X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E6X.2.1.1.m1.3" class="ltx_Math" alttext="\displaystyle\mathbf{Q}^{l},\mathbf{K}^{l},\mathbf{V}^{l}" display="inline"><semantics id="S3.E6X.2.1.1.m1.3a"><mrow id="S3.E6X.2.1.1.m1.3.3.3" xref="S3.E6X.2.1.1.m1.3.3.4.cmml"><msup id="S3.E6X.2.1.1.m1.1.1.1.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.cmml"><mi id="S3.E6X.2.1.1.m1.1.1.1.1.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.2.cmml">𝐐</mi><mi id="S3.E6X.2.1.1.m1.1.1.1.1.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.3.cmml">l</mi></msup><mo id="S3.E6X.2.1.1.m1.3.3.3.4" xref="S3.E6X.2.1.1.m1.3.3.4.cmml">,</mo><msup id="S3.E6X.2.1.1.m1.2.2.2.2" xref="S3.E6X.2.1.1.m1.2.2.2.2.cmml"><mi id="S3.E6X.2.1.1.m1.2.2.2.2.2" xref="S3.E6X.2.1.1.m1.2.2.2.2.2.cmml">𝐊</mi><mi id="S3.E6X.2.1.1.m1.2.2.2.2.3" xref="S3.E6X.2.1.1.m1.2.2.2.2.3.cmml">l</mi></msup><mo id="S3.E6X.2.1.1.m1.3.3.3.5" xref="S3.E6X.2.1.1.m1.3.3.4.cmml">,</mo><msup id="S3.E6X.2.1.1.m1.3.3.3.3" xref="S3.E6X.2.1.1.m1.3.3.3.3.cmml"><mi id="S3.E6X.2.1.1.m1.3.3.3.3.2" xref="S3.E6X.2.1.1.m1.3.3.3.3.2.cmml">𝐕</mi><mi id="S3.E6X.2.1.1.m1.3.3.3.3.3" xref="S3.E6X.2.1.1.m1.3.3.3.3.3.cmml">l</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.E6X.2.1.1.m1.3b"><list id="S3.E6X.2.1.1.m1.3.3.4.cmml" xref="S3.E6X.2.1.1.m1.3.3.3"><apply id="S3.E6X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1">superscript</csymbol><ci id="S3.E6X.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.2">𝐐</ci><ci id="S3.E6X.2.1.1.m1.1.1.1.1.3.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.3">𝑙</ci></apply><apply id="S3.E6X.2.1.1.m1.2.2.2.2.cmml" xref="S3.E6X.2.1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.2.2.2.2.1.cmml" xref="S3.E6X.2.1.1.m1.2.2.2.2">superscript</csymbol><ci id="S3.E6X.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E6X.2.1.1.m1.2.2.2.2.2">𝐊</ci><ci id="S3.E6X.2.1.1.m1.2.2.2.2.3.cmml" xref="S3.E6X.2.1.1.m1.2.2.2.2.3">𝑙</ci></apply><apply id="S3.E6X.2.1.1.m1.3.3.3.3.cmml" xref="S3.E6X.2.1.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.3.3.3.3.1.cmml" xref="S3.E6X.2.1.1.m1.3.3.3.3">superscript</csymbol><ci id="S3.E6X.2.1.1.m1.3.3.3.3.2.cmml" xref="S3.E6X.2.1.1.m1.3.3.3.3.2">𝐕</ci><ci id="S3.E6X.2.1.1.m1.3.3.3.3.3.cmml" xref="S3.E6X.2.1.1.m1.3.3.3.3.3">𝑙</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.E6X.2.1.1.m1.3c">\displaystyle\mathbf{Q}^{l},\mathbf{K}^{l},\mathbf{V}^{l}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E6X.3.2.2.m1.2" class="ltx_Math" alttext="\displaystyle=\operatorname{Embedding}(\mathbf{H}_{\mathrm{img}}^{l},\mathbf{W}_{q}^{l},\mathbf{W}_{k}^{l},\mathbf{W}_{v}^{l})," display="inline"><semantics id="S3.E6X.3.2.2.m1.2a"><mrow id="S3.E6X.3.2.2.m1.2.2.1" xref="S3.E6X.3.2.2.m1.2.2.1.1.cmml"><mrow id="S3.E6X.3.2.2.m1.2.2.1.1" xref="S3.E6X.3.2.2.m1.2.2.1.1.cmml"><mi id="S3.E6X.3.2.2.m1.2.2.1.1.6" xref="S3.E6X.3.2.2.m1.2.2.1.1.6.cmml"></mi><mo id="S3.E6X.3.2.2.m1.2.2.1.1.5" xref="S3.E6X.3.2.2.m1.2.2.1.1.5.cmml">=</mo><mrow id="S3.E6X.3.2.2.m1.2.2.1.1.4.4" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.5.cmml"><mi id="S3.E6X.3.2.2.m1.1.1" xref="S3.E6X.3.2.2.m1.1.1.cmml">Embedding</mi><mo id="S3.E6X.3.2.2.m1.2.2.1.1.4.4a" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.5.cmml">⁡</mo><mrow id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.5.cmml"><mo stretchy="false" id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.5" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.5.cmml">(</mo><msubsup id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.2.cmml">𝐇</mi><mi id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.3" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.3.cmml">img</mi><mi id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.3.cmml">l</mi></msubsup><mo id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.6" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.5.cmml">,</mo><msubsup id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.cmml"><mi id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.2.cmml">𝐖</mi><mi id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.3" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.3.cmml">q</mi><mi id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.3" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.3.cmml">l</mi></msubsup><mo id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.7" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.5.cmml">,</mo><msubsup id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.cmml"><mi id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.2" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.2.cmml">𝐖</mi><mi id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.3" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.3.cmml">k</mi><mi id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.3" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.3.cmml">l</mi></msubsup><mo id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.8" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.5.cmml">,</mo><msubsup id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.cmml"><mi id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.2" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.2.cmml">𝐖</mi><mi id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.3" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.3.cmml">v</mi><mi id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.3" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.3.cmml">l</mi></msubsup><mo stretchy="false" id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.9" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.5.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E6X.3.2.2.m1.2.2.1.2" xref="S3.E6X.3.2.2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6X.3.2.2.m1.2b"><apply id="S3.E6X.3.2.2.m1.2.2.1.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1"><eq id="S3.E6X.3.2.2.m1.2.2.1.1.5.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.5"></eq><csymbol cd="latexml" id="S3.E6X.3.2.2.m1.2.2.1.1.6.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.6">absent</csymbol><apply id="S3.E6X.3.2.2.m1.2.2.1.1.4.5.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4"><ci id="S3.E6X.3.2.2.m1.1.1.cmml" xref="S3.E6X.3.2.2.m1.1.1">Embedding</ci><apply id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.2">𝐇</ci><ci id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.2.3">img</ci></apply><ci id="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.1.1.1.1.3">𝑙</ci></apply><apply id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2">superscript</csymbol><apply id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.2.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.2">𝐖</ci><ci id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.2.3">𝑞</ci></apply><ci id="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.2.2.2.2.3">𝑙</ci></apply><apply id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3">superscript</csymbol><apply id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3">subscript</csymbol><ci id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.2.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.2">𝐖</ci><ci id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.3.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.2.3">𝑘</ci></apply><ci id="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.3.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.3.3.3.3.3">𝑙</ci></apply><apply id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4"><csymbol cd="ambiguous" id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4">superscript</csymbol><apply id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4"><csymbol cd="ambiguous" id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.1.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4">subscript</csymbol><ci id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.2.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.2">𝐖</ci><ci id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.3.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.2.3">𝑣</ci></apply><ci id="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.3.cmml" xref="S3.E6X.3.2.2.m1.2.2.1.1.4.4.4.4.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6X.3.2.2.m1.2c">\displaystyle=\operatorname{Embedding}(\mathbf{H}_{\mathrm{img}}^{l},\mathbf{W}_{q}^{l},\mathbf{W}_{k}^{l},\mathbf{W}_{v}^{l}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(6)</span></td>
</tr>
<tr id="S3.E6Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E6Xa.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{H}_{\mathrm{img}}^{l+1}" display="inline"><semantics id="S3.E6Xa.2.1.1.m1.1a"><msubsup id="S3.E6Xa.2.1.1.m1.1.1" xref="S3.E6Xa.2.1.1.m1.1.1.cmml"><mi id="S3.E6Xa.2.1.1.m1.1.1.2.2" xref="S3.E6Xa.2.1.1.m1.1.1.2.2.cmml">𝐇</mi><mi id="S3.E6Xa.2.1.1.m1.1.1.2.3" xref="S3.E6Xa.2.1.1.m1.1.1.2.3.cmml">img</mi><mrow id="S3.E6Xa.2.1.1.m1.1.1.3" xref="S3.E6Xa.2.1.1.m1.1.1.3.cmml"><mi id="S3.E6Xa.2.1.1.m1.1.1.3.2" xref="S3.E6Xa.2.1.1.m1.1.1.3.2.cmml">l</mi><mo id="S3.E6Xa.2.1.1.m1.1.1.3.1" xref="S3.E6Xa.2.1.1.m1.1.1.3.1.cmml">+</mo><mn id="S3.E6Xa.2.1.1.m1.1.1.3.3" xref="S3.E6Xa.2.1.1.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.E6Xa.2.1.1.m1.1b"><apply id="S3.E6Xa.2.1.1.m1.1.1.cmml" xref="S3.E6Xa.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.E6Xa.2.1.1.m1.1.1.1.cmml" xref="S3.E6Xa.2.1.1.m1.1.1">superscript</csymbol><apply id="S3.E6Xa.2.1.1.m1.1.1.2.cmml" xref="S3.E6Xa.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.E6Xa.2.1.1.m1.1.1.2.1.cmml" xref="S3.E6Xa.2.1.1.m1.1.1">subscript</csymbol><ci id="S3.E6Xa.2.1.1.m1.1.1.2.2.cmml" xref="S3.E6Xa.2.1.1.m1.1.1.2.2">𝐇</ci><ci id="S3.E6Xa.2.1.1.m1.1.1.2.3.cmml" xref="S3.E6Xa.2.1.1.m1.1.1.2.3">img</ci></apply><apply id="S3.E6Xa.2.1.1.m1.1.1.3.cmml" xref="S3.E6Xa.2.1.1.m1.1.1.3"><plus id="S3.E6Xa.2.1.1.m1.1.1.3.1.cmml" xref="S3.E6Xa.2.1.1.m1.1.1.3.1"></plus><ci id="S3.E6Xa.2.1.1.m1.1.1.3.2.cmml" xref="S3.E6Xa.2.1.1.m1.1.1.3.2">𝑙</ci><cn type="integer" id="S3.E6Xa.2.1.1.m1.1.1.3.3.cmml" xref="S3.E6Xa.2.1.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6Xa.2.1.1.m1.1c">\displaystyle\mathbf{H}_{\mathrm{img}}^{l+1}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E6Xa.3.2.2.m1.3" class="ltx_Math" alttext="\displaystyle=\operatorname{Attention}(\mathbf{Q}^{l},\mathbf{K}^{l},\mathbf{V}^{l})=\operatorname{softmax}\left({\mathbf{Q}^{l}{\mathbf{K}^{l}}^{\top}}/{\sqrt{C}}\right)\mathbf{M}^{l}\mathbf{V}^{l}." display="inline"><semantics id="S3.E6Xa.3.2.2.m1.3a"><mrow id="S3.E6Xa.3.2.2.m1.3.3.1" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.cmml"><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.cmml"><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.6" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.6.cmml"></mi><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.7" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.7.cmml">=</mo><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.4.cmml"><mi id="S3.E6Xa.3.2.2.m1.1.1" xref="S3.E6Xa.3.2.2.m1.1.1.cmml">Attention</mi><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3a" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.4.cmml">⁡</mo><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.4.cmml"><mo stretchy="false" id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.4" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.4.cmml">(</mo><msup id="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.2.cmml">𝐐</mi><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.3.cmml">l</mi></msup><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.5" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.4.cmml">,</mo><msup id="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.cmml"><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.2.cmml">𝐊</mi><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.3.cmml">l</mi></msup><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.6" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.4.cmml">,</mo><msup id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.cmml"><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.2.cmml">𝐕</mi><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.3.cmml">l</mi></msup><mo stretchy="false" id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.7" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.8" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.8.cmml">=</mo><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1.4" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.cmml"><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.2.cmml"><mi id="S3.E6Xa.3.2.2.m1.2.2" xref="S3.E6Xa.3.2.2.m1.2.2.cmml">softmax</mi><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1a" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.2.cmml">⁡</mo><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.2.cmml"><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.2.cmml">(</mo><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.cmml"><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.cmml"><msup id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.cmml"><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.2.cmml">𝐐</mi><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.3.cmml">l</mi></msup><mo lspace="0em" rspace="0em" id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.1" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.1.cmml">​</mo><mmultiscripts id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.cmml"><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.2.cmml">𝐊</mi><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3a" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.cmml"></mrow><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.3.cmml">l</mi><mrow id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3b" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.cmml"></mrow><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.3.cmml">⊤</mo></mmultiscripts></mrow><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.1" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.1.cmml">/</mo><msqrt id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3.cmml"><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3.2.cmml">C</mi></msqrt></mrow><mo id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.2.cmml">)</mo></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.2.cmml">​</mo><msup id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.cmml"><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.2.cmml">𝐌</mi><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.3.cmml">l</mi></msup><mo lspace="0em" rspace="0em" id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.2a" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.2.cmml">​</mo><msup id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.cmml"><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.2.cmml">𝐕</mi><mi id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.3" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.3.cmml">l</mi></msup></mrow></mrow><mo lspace="0em" id="S3.E6Xa.3.2.2.m1.3.3.1.2" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6Xa.3.2.2.m1.3b"><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1"><and id="S3.E6Xa.3.2.2.m1.3.3.1.1a.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1"></and><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1b.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1"><eq id="S3.E6Xa.3.2.2.m1.3.3.1.1.7.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.7"></eq><csymbol cd="latexml" id="S3.E6Xa.3.2.2.m1.3.3.1.1.6.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.6">absent</csymbol><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.4.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3"><ci id="S3.E6Xa.3.2.2.m1.1.1.cmml" xref="S3.E6Xa.3.2.2.m1.1.1">Attention</ci><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.2">𝐐</ci><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.1.1.1.1.3">𝑙</ci></apply><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2">superscript</csymbol><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.2">𝐊</ci><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.2.2.2.2.3">𝑙</ci></apply><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3">superscript</csymbol><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.2">𝐕</ci><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.3.3.3.3.3">𝑙</ci></apply></apply></apply><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1c.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1"><eq id="S3.E6Xa.3.2.2.m1.3.3.1.1.8.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.8"></eq><share href="#S3.E6Xa.3.2.2.m1.3.3.1.1.3.cmml" id="S3.E6Xa.3.2.2.m1.3.3.1.1d.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1"></share><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4"><times id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.2"></times><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1"><ci id="S3.E6Xa.3.2.2.m1.2.2.cmml" xref="S3.E6Xa.3.2.2.m1.2.2">softmax</ci><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1"><divide id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.1"></divide><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2"><times id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.1"></times><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2">superscript</csymbol><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.2">𝐐</ci><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.2.3">𝑙</ci></apply><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3">superscript</csymbol><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3">superscript</csymbol><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.2">𝐊</ci><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.2.3">𝑙</ci></apply><csymbol cd="latexml" id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.2.3.3">top</csymbol></apply></apply><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3"><root id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3a.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3"></root><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.1.1.1.1.3.2">𝐶</ci></apply></apply></apply><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3"><csymbol cd="ambiguous" id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3">superscript</csymbol><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.2">𝐌</ci><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.3.3">𝑙</ci></apply><apply id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4"><csymbol cd="ambiguous" id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.1.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4">superscript</csymbol><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.2.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.2">𝐕</ci><ci id="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.3.cmml" xref="S3.E6Xa.3.2.2.m1.3.3.1.1.4.4.3">𝑙</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6Xa.3.2.2.m1.3c">\displaystyle=\operatorname{Attention}(\mathbf{Q}^{l},\mathbf{K}^{l},\mathbf{V}^{l})=\operatorname{softmax}\left({\mathbf{Q}^{l}{\mathbf{K}^{l}}^{\top}}/{\sqrt{C}}\right)\mathbf{M}^{l}\mathbf{V}^{l}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S3.SS3.p2.9" class="ltx_p">Here, <math id="S3.SS3.p2.8.m1.1" class="ltx_Math" alttext="\mathbf{M}^{l}" display="inline"><semantics id="S3.SS3.p2.8.m1.1a"><msup id="S3.SS3.p2.8.m1.1.1" xref="S3.SS3.p2.8.m1.1.1.cmml"><mi id="S3.SS3.p2.8.m1.1.1.2" xref="S3.SS3.p2.8.m1.1.1.2.cmml">𝐌</mi><mi id="S3.SS3.p2.8.m1.1.1.3" xref="S3.SS3.p2.8.m1.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m1.1b"><apply id="S3.SS3.p2.8.m1.1.1.cmml" xref="S3.SS3.p2.8.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m1.1.1.1.cmml" xref="S3.SS3.p2.8.m1.1.1">superscript</csymbol><ci id="S3.SS3.p2.8.m1.1.1.2.cmml" xref="S3.SS3.p2.8.m1.1.1.2">𝐌</ci><ci id="S3.SS3.p2.8.m1.1.1.3.cmml" xref="S3.SS3.p2.8.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m1.1c">\mathbf{M}^{l}</annotation></semantics></math> is the mask used to constrain the visible range of attention.
The introduction of <math id="S3.SS3.p2.9.m2.1" class="ltx_Math" alttext="\mathbf{M}^{l}" display="inline"><semantics id="S3.SS3.p2.9.m2.1a"><msup id="S3.SS3.p2.9.m2.1.1" xref="S3.SS3.p2.9.m2.1.1.cmml"><mi id="S3.SS3.p2.9.m2.1.1.2" xref="S3.SS3.p2.9.m2.1.1.2.cmml">𝐌</mi><mi id="S3.SS3.p2.9.m2.1.1.3" xref="S3.SS3.p2.9.m2.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m2.1b"><apply id="S3.SS3.p2.9.m2.1.1.cmml" xref="S3.SS3.p2.9.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m2.1.1.1.cmml" xref="S3.SS3.p2.9.m2.1.1">superscript</csymbol><ci id="S3.SS3.p2.9.m2.1.1.2.cmml" xref="S3.SS3.p2.9.m2.1.1.2">𝐌</ci><ci id="S3.SS3.p2.9.m2.1.1.3.cmml" xref="S3.SS3.p2.9.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m2.1c">\mathbf{M}^{l}</annotation></semantics></math> is to take advantage of the <span id="S3.SS3.p2.9.1" class="ltx_text ltx_font_italic">ground-aware</span> property (<span id="S3.SS3.p2.9.2" class="ltx_text ltx_font_italic">i.e.</span>, the depth of each object should be related to the depth of the object’s location) so that each pixel will only consider information within a window around that location.
The encoded feature obtained through multi-head self-attention operation is then re-transformed into a 2D feature map format and fed into a convolution-based feed-forward network (FFN).
The 2D reshape as well as convolution-based FFN are necessary because image data is two-dimensional, unlike one-dimensional serialized data.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_bold">Decoder.</span>
The proposed transformer decoder aims to determine for each location its depth information, using the cross-correlation between the ground depth and the image features.
We propose utilizing the ground depth as the location query of the decoder instead of learnable embedding (object query), which is different from the common usage in previous encoder-decoder vision transformer works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">64</span></a>]</cite>.
The main reason is that the simple learnable embedding is hard to fully represent the object’s property and handle complex depth variant situations in the Mono3D task.
In contrast, plentiful distance-aware cues are hidden in the ground depth features, which will give the transformer a baseline estimate of the expected depth at each location.
To this end, the decoder can leverage the power of cross-attention in the transformer to efficiently model the correlation between the target pixel point and the point of interest (<span id="S3.SS3.p3.1.2" class="ltx_text ltx_font_italic">i.e.</span>, the grounded point), thus achieving the <span id="S3.SS3.p3.1.3" class="ltx_text ltx_font_italic">ground-awareness</span> for higher performance.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.6" class="ltx_p">Specifically, the input of the decoder is the flattened ground depth <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="\mathbf{H}_{\mathrm{dep}}\in\mathbb{R}^{N\times 1}" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><mrow id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><msub id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2.2" xref="S3.SS3.p4.1.m1.1.1.2.2.cmml">𝐇</mi><mi id="S3.SS3.p4.1.m1.1.1.2.3" xref="S3.SS3.p4.1.m1.1.1.2.3.cmml">dep</mi></msub><mo id="S3.SS3.p4.1.m1.1.1.1" xref="S3.SS3.p4.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml"><mi id="S3.SS3.p4.1.m1.1.1.3.2" xref="S3.SS3.p4.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p4.1.m1.1.1.3.3" xref="S3.SS3.p4.1.m1.1.1.3.3.cmml"><mi id="S3.SS3.p4.1.m1.1.1.3.3.2" xref="S3.SS3.p4.1.m1.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p4.1.m1.1.1.3.3.1" xref="S3.SS3.p4.1.m1.1.1.3.3.1.cmml">×</mo><mn id="S3.SS3.p4.1.m1.1.1.3.3.3" xref="S3.SS3.p4.1.m1.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><in id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1.1"></in><apply id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.2.1.cmml" xref="S3.SS3.p4.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2.2">𝐇</ci><ci id="S3.SS3.p4.1.m1.1.1.2.3.cmml" xref="S3.SS3.p4.1.m1.1.1.2.3">dep</ci></apply><apply id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.3.1.cmml" xref="S3.SS3.p4.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.3.2.cmml" xref="S3.SS3.p4.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS3.p4.1.m1.1.1.3.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3.3"><times id="S3.SS3.p4.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p4.1.m1.1.1.3.3.1"></times><ci id="S3.SS3.p4.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p4.1.m1.1.1.3.3.2">𝑁</ci><cn type="integer" id="S3.SS3.p4.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">\mathbf{H}_{\mathrm{dep}}\in\mathbb{R}^{N\times 1}</annotation></semantics></math> with position encoding and embedding vectors <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="\mathbf{H}_{e}\in\mathbb{R}^{N\times C}" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><mrow id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><msub id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml"><mi id="S3.SS3.p4.2.m2.1.1.2.2" xref="S3.SS3.p4.2.m2.1.1.2.2.cmml">𝐇</mi><mi id="S3.SS3.p4.2.m2.1.1.2.3" xref="S3.SS3.p4.2.m2.1.1.2.3.cmml">e</mi></msub><mo id="S3.SS3.p4.2.m2.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml"><mi id="S3.SS3.p4.2.m2.1.1.3.2" xref="S3.SS3.p4.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p4.2.m2.1.1.3.3" xref="S3.SS3.p4.2.m2.1.1.3.3.cmml"><mi id="S3.SS3.p4.2.m2.1.1.3.3.2" xref="S3.SS3.p4.2.m2.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p4.2.m2.1.1.3.3.1" xref="S3.SS3.p4.2.m2.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p4.2.m2.1.1.3.3.3" xref="S3.SS3.p4.2.m2.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><in id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1"></in><apply id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.2.1.cmml" xref="S3.SS3.p4.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.2.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2.2">𝐇</ci><ci id="S3.SS3.p4.2.m2.1.1.2.3.cmml" xref="S3.SS3.p4.2.m2.1.1.2.3">𝑒</ci></apply><apply id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.3.2.cmml" xref="S3.SS3.p4.2.m2.1.1.3.2">ℝ</ci><apply id="S3.SS3.p4.2.m2.1.1.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3.3"><times id="S3.SS3.p4.2.m2.1.1.3.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.3.3.1"></times><ci id="S3.SS3.p4.2.m2.1.1.3.3.2.cmml" xref="S3.SS3.p4.2.m2.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p4.2.m2.1.1.3.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">\mathbf{H}_{e}\in\mathbb{R}^{N\times C}</annotation></semantics></math> obtained from the encoder.
In addition, the output is the aggregated feature map <math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="\mathbf{H}_{d}\in\mathbb{R}^{N\times C}" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><mrow id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml"><msub id="S3.SS3.p4.3.m3.1.1.2" xref="S3.SS3.p4.3.m3.1.1.2.cmml"><mi id="S3.SS3.p4.3.m3.1.1.2.2" xref="S3.SS3.p4.3.m3.1.1.2.2.cmml">𝐇</mi><mi id="S3.SS3.p4.3.m3.1.1.2.3" xref="S3.SS3.p4.3.m3.1.1.2.3.cmml">d</mi></msub><mo id="S3.SS3.p4.3.m3.1.1.1" xref="S3.SS3.p4.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS3.p4.3.m3.1.1.3" xref="S3.SS3.p4.3.m3.1.1.3.cmml"><mi id="S3.SS3.p4.3.m3.1.1.3.2" xref="S3.SS3.p4.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p4.3.m3.1.1.3.3" xref="S3.SS3.p4.3.m3.1.1.3.3.cmml"><mi id="S3.SS3.p4.3.m3.1.1.3.3.2" xref="S3.SS3.p4.3.m3.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p4.3.m3.1.1.3.3.1" xref="S3.SS3.p4.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p4.3.m3.1.1.3.3.3" xref="S3.SS3.p4.3.m3.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><apply id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1"><in id="S3.SS3.p4.3.m3.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1"></in><apply id="S3.SS3.p4.3.m3.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.2.1.cmml" xref="S3.SS3.p4.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.2.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2.2">𝐇</ci><ci id="S3.SS3.p4.3.m3.1.1.2.3.cmml" xref="S3.SS3.p4.3.m3.1.1.2.3">𝑑</ci></apply><apply id="S3.SS3.p4.3.m3.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.3.1.cmml" xref="S3.SS3.p4.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.3.2.cmml" xref="S3.SS3.p4.3.m3.1.1.3.2">ℝ</ci><apply id="S3.SS3.p4.3.m3.1.1.3.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3"><times id="S3.SS3.p4.3.m3.1.1.3.3.1.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3.1"></times><ci id="S3.SS3.p4.3.m3.1.1.3.3.2.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p4.3.m3.1.1.3.3.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">\mathbf{H}_{d}\in\mathbb{R}^{N\times C}</annotation></semantics></math>.
The ground depth is first embedded upon the standard self-attention architecture following (<a href="#S3.E6" title="In 3.3 Ground Depth Fusion ‣ 3 Design of MoGDE ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>).
For the cross-attention module, its input <math id="S3.SS3.p4.4.m4.1" class="ltx_Math" alttext="\mathbf{Q}" display="inline"><semantics id="S3.SS3.p4.4.m4.1a"><mi id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml">𝐐</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><ci id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">𝐐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">\mathbf{Q}</annotation></semantics></math> is derived from the self-attention part upstream in the decoder, and its <math id="S3.SS3.p4.5.m5.1" class="ltx_Math" alttext="\mathbf{K}" display="inline"><semantics id="S3.SS3.p4.5.m5.1a"><mi id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml">𝐊</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><ci id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">𝐊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">\mathbf{K}</annotation></semantics></math> is derived from the encoder.
The input <math id="S3.SS3.p4.6.m6.1" class="ltx_Math" alttext="\mathbf{V}" display="inline"><semantics id="S3.SS3.p4.6.m6.1a"><mi id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml">𝐕</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.1b"><ci id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1">𝐕</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.1c">\mathbf{V}</annotation></semantics></math> is a concatenation of two sources from both the encoder and decoder.
The purpose of this concatenation is to make the decoder take into account both the information from the image and the depth during decoding.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Performance Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We conduct experiments on the widely-adopted KITTI3D dataset and KITTI Odometry dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>.
We report the detection results with three-level difficulties, <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span> easy, moderate, and hard, in which the moderate scores are normally for ranking and the hard category is generally distant objects that is difficult to distinguish.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Quantitative and Qualitative Results</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We first show the performance of our proposed MoGDE on KITTI 3D object detection benchmark <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>http://www.cvlibs.net/datasets/kitti/eval object.php?obj benchmark=3d</span></span></span> for car.
Comparison results with other state-of-the-art (SOTA) monocular 3D detectors are shown in Table <a href="#S4.SS1" title="4.1 Quantitative and Qualitative Results ‣ 4 Performance Evaluation ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
For the official <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">test</span> set, we achieve the highest score for all kinds of samples and are ranked</p>
</div>
<div id="S4.SS1.2" class="ltx_para ltx_minipage ltx_align_middle" style="width:346.9pt;">
<div id="S4.SS1.2.2" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:208.7pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-46.0pt,22.0pt) scale(0.825117092841512,0.825117092841512) ;">
<table id="S4.SS1.2.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.SS1.2.2.2.2" class="ltx_tr">
<td id="S4.SS1.2.2.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.SS1.2.2.2.2.3.1" class="ltx_text">Method</span></td>
<td id="S4.SS1.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.SS1.2.2.2.2.4.1" class="ltx_text">Extra data</span></td>
<td id="S4.SS1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Test, <math id="S4.SS1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S4.SS1.1.1.1.1.1.m1.1a"><mrow id="S4.SS1.1.1.1.1.1.m1.1.1" xref="S4.SS1.1.1.1.1.1.m1.1.1.cmml"><mi id="S4.SS1.1.1.1.1.1.m1.1.1.2" xref="S4.SS1.1.1.1.1.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.1.1.1.1.1.m1.1.1.1" xref="S4.SS1.1.1.1.1.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.1.1.1.1.1.m1.1.1.3" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.cmml"><mi id="S4.SS1.1.1.1.1.1.m1.1.1.3.2" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.1.1.1.1.1.m1.1.1.3.3" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.3.cmml"><mn id="S4.SS1.1.1.1.1.1.m1.1.1.3.3.2" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS1.1.1.1.1.1.m1.1.1.3.3.1" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.1.1.1.1.1.m1.1.1.3.3.3" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.1.1.1.1.1.m1.1b"><apply id="S4.SS1.1.1.1.1.1.m1.1.1.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1"><times id="S4.SS1.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1.1"></times><ci id="S4.SS1.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1.2">𝐴</ci><apply id="S4.SS1.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.1.1.1.1.1.m1.1.1.3.1.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.1.1.1.1.1.m1.1.1.3.2.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.2">𝑃</ci><apply id="S4.SS1.1.1.1.1.1.m1.1.1.3.3.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.3"><times id="S4.SS1.1.1.1.1.1.m1.1.1.3.3.1.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.3.1"></times><cn type="integer" id="S4.SS1.1.1.1.1.1.m1.1.1.3.3.2.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.3.2">3</cn><ci id="S4.SS1.1.1.1.1.1.m1.1.1.3.3.3.cmml" xref="S4.SS1.1.1.1.1.1.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.1.1.1.1.1.m1.1c">AP_{3D}</annotation></semantics></math>
</td>
<td id="S4.SS1.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Test, <math id="S4.SS1.2.2.2.2.2.m1.1" class="ltx_Math" alttext="AP_{BEV}" display="inline"><semantics id="S4.SS1.2.2.2.2.2.m1.1a"><mrow id="S4.SS1.2.2.2.2.2.m1.1.1" xref="S4.SS1.2.2.2.2.2.m1.1.1.cmml"><mi id="S4.SS1.2.2.2.2.2.m1.1.1.2" xref="S4.SS1.2.2.2.2.2.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.2.2.2.2.2.m1.1.1.1" xref="S4.SS1.2.2.2.2.2.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.2.2.2.2.2.m1.1.1.3" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.cmml"><mi id="S4.SS1.2.2.2.2.2.m1.1.1.3.2" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.2.2.2.2.2.m1.1.1.3.3" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.cmml"><mi id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.2" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.1" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.3" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.1a" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.4" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.4.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.2.2.2.2.2.m1.1b"><apply id="S4.SS1.2.2.2.2.2.m1.1.1.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1"><times id="S4.SS1.2.2.2.2.2.m1.1.1.1.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.1"></times><ci id="S4.SS1.2.2.2.2.2.m1.1.1.2.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.2">𝐴</ci><apply id="S4.SS1.2.2.2.2.2.m1.1.1.3.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.2.2.2.2.2.m1.1.1.3.1.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.2.2.2.2.2.m1.1.1.3.2.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.2">𝑃</ci><apply id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3"><times id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.1.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.1"></times><ci id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.2.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.2">𝐵</ci><ci id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.3.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.3">𝐸</ci><ci id="S4.SS1.2.2.2.2.2.m1.1.1.3.3.4.cmml" xref="S4.SS1.2.2.2.2.2.m1.1.1.3.3.4">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.2.2.2.2.2.m1.1c">AP_{BEV}</annotation></semantics></math>
</td>
</tr>
<tr id="S4.SS1.2.2.2.3" class="ltx_tr">
<td id="S4.SS1.2.2.2.3.1" class="ltx_td ltx_align_center">Easy</td>
<td id="S4.SS1.2.2.2.3.2" class="ltx_td ltx_align_center">Mod.</td>
<td id="S4.SS1.2.2.2.3.3" class="ltx_td ltx_align_center ltx_border_r">Hard</td>
<td id="S4.SS1.2.2.2.3.4" class="ltx_td ltx_align_center">Easy</td>
<td id="S4.SS1.2.2.2.3.5" class="ltx_td ltx_align_center">Mod.</td>
<td id="S4.SS1.2.2.2.3.6" class="ltx_td ltx_align_center">Hard</td>
</tr>
<tr id="S4.SS1.2.2.2.4" class="ltx_tr">
<td id="S4.SS1.2.2.2.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">PatchNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.SS1.2.2.2.4.2.1" class="ltx_text">Depth</span></td>
<td id="S4.SS1.2.2.2.4.3" class="ltx_td ltx_align_center ltx_border_tt">15.68</td>
<td id="S4.SS1.2.2.2.4.4" class="ltx_td ltx_align_center ltx_border_tt">11.12</td>
<td id="S4.SS1.2.2.2.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">10.17</td>
<td id="S4.SS1.2.2.2.4.6" class="ltx_td ltx_align_center ltx_border_tt">22.97</td>
<td id="S4.SS1.2.2.2.4.7" class="ltx_td ltx_align_center ltx_border_tt">16.86</td>
<td id="S4.SS1.2.2.2.4.8" class="ltx_td ltx_align_center ltx_border_tt">14.97</td>
</tr>
<tr id="S4.SS1.2.2.2.5" class="ltx_tr">
<td id="S4.SS1.2.2.2.5.1" class="ltx_td ltx_align_left ltx_border_r">D4LCN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.5.2" class="ltx_td ltx_align_center">16.65</td>
<td id="S4.SS1.2.2.2.5.3" class="ltx_td ltx_align_center">11.72</td>
<td id="S4.SS1.2.2.2.5.4" class="ltx_td ltx_align_center ltx_border_r">9.51</td>
<td id="S4.SS1.2.2.2.5.5" class="ltx_td ltx_align_center">22.51</td>
<td id="S4.SS1.2.2.2.5.6" class="ltx_td ltx_align_center">16.02</td>
<td id="S4.SS1.2.2.2.5.7" class="ltx_td ltx_align_center">12.55</td>
</tr>
<tr id="S4.SS1.2.2.2.6" class="ltx_tr">
<td id="S4.SS1.2.2.2.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Kinematic3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Multi-frames</td>
<td id="S4.SS1.2.2.2.6.3" class="ltx_td ltx_align_center ltx_border_t">19.07</td>
<td id="S4.SS1.2.2.2.6.4" class="ltx_td ltx_align_center ltx_border_t">12.72</td>
<td id="S4.SS1.2.2.2.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">9.17</td>
<td id="S4.SS1.2.2.2.6.6" class="ltx_td ltx_align_center ltx_border_t">26.69</td>
<td id="S4.SS1.2.2.2.6.7" class="ltx_td ltx_align_center ltx_border_t">17.52</td>
<td id="S4.SS1.2.2.2.6.8" class="ltx_td ltx_align_center ltx_border_t">13.10</td>
</tr>
<tr id="S4.SS1.2.2.2.7" class="ltx_tr">
<td id="S4.SS1.2.2.2.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">MonoRUn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.SS1.2.2.2.7.2.1" class="ltx_text">Lidar</span></td>
<td id="S4.SS1.2.2.2.7.3" class="ltx_td ltx_align_center ltx_border_t">19.65</td>
<td id="S4.SS1.2.2.2.7.4" class="ltx_td ltx_align_center ltx_border_t">12.30</td>
<td id="S4.SS1.2.2.2.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.58</td>
<td id="S4.SS1.2.2.2.7.6" class="ltx_td ltx_align_center ltx_border_t">27.94</td>
<td id="S4.SS1.2.2.2.7.7" class="ltx_td ltx_align_center ltx_border_t">17.34</td>
<td id="S4.SS1.2.2.2.7.8" class="ltx_td ltx_align_center ltx_border_t">15.24</td>
</tr>
<tr id="S4.SS1.2.2.2.8" class="ltx_tr">
<td id="S4.SS1.2.2.2.8.1" class="ltx_td ltx_align_left ltx_border_r">CaDDN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.8.2" class="ltx_td ltx_align_center">19.17</td>
<td id="S4.SS1.2.2.2.8.3" class="ltx_td ltx_align_center">13.41</td>
<td id="S4.SS1.2.2.2.8.4" class="ltx_td ltx_align_center ltx_border_r">11.46</td>
<td id="S4.SS1.2.2.2.8.5" class="ltx_td ltx_align_center">27.94</td>
<td id="S4.SS1.2.2.2.8.6" class="ltx_td ltx_align_center">18.91</td>
<td id="S4.SS1.2.2.2.8.7" class="ltx_td ltx_align_center">17.19</td>
</tr>
<tr id="S4.SS1.2.2.2.9" class="ltx_tr">
<td id="S4.SS1.2.2.2.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AutoShape <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CAD</td>
<td id="S4.SS1.2.2.2.9.3" class="ltx_td ltx_align_center ltx_border_t">22.47</td>
<td id="S4.SS1.2.2.2.9.4" class="ltx_td ltx_align_center ltx_border_t">14.17</td>
<td id="S4.SS1.2.2.2.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.36</td>
<td id="S4.SS1.2.2.2.9.6" class="ltx_td ltx_align_center ltx_border_t">30.66</td>
<td id="S4.SS1.2.2.2.9.7" class="ltx_td ltx_align_center ltx_border_t">20.08</td>
<td id="S4.SS1.2.2.2.9.8" class="ltx_td ltx_align_center ltx_border_t">15.59</td>
</tr>
<tr id="S4.SS1.2.2.2.10" class="ltx_tr">
<td id="S4.SS1.2.2.2.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">SMOKE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="4"><span id="S4.SS1.2.2.2.10.2.1" class="ltx_text">None</span></td>
<td id="S4.SS1.2.2.2.10.3" class="ltx_td ltx_align_center ltx_border_t">14.03</td>
<td id="S4.SS1.2.2.2.10.4" class="ltx_td ltx_align_center ltx_border_t">9.76</td>
<td id="S4.SS1.2.2.2.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">7.84</td>
<td id="S4.SS1.2.2.2.10.6" class="ltx_td ltx_align_center ltx_border_t">20.83</td>
<td id="S4.SS1.2.2.2.10.7" class="ltx_td ltx_align_center ltx_border_t">14.49</td>
<td id="S4.SS1.2.2.2.10.8" class="ltx_td ltx_align_center ltx_border_t">12.75</td>
</tr>
<tr id="S4.SS1.2.2.2.11" class="ltx_tr">
<td id="S4.SS1.2.2.2.11.1" class="ltx_td ltx_align_left ltx_border_r">MonoFlex <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.11.2" class="ltx_td ltx_align_center">19.94</td>
<td id="S4.SS1.2.2.2.11.3" class="ltx_td ltx_align_center">13.89</td>
<td id="S4.SS1.2.2.2.11.4" class="ltx_td ltx_align_center ltx_border_r">12.07</td>
<td id="S4.SS1.2.2.2.11.5" class="ltx_td ltx_align_center">28.23</td>
<td id="S4.SS1.2.2.2.11.6" class="ltx_td ltx_align_center">19.75</td>
<td id="S4.SS1.2.2.2.11.7" class="ltx_td ltx_align_center">16.89</td>
</tr>
<tr id="S4.SS1.2.2.2.12" class="ltx_tr">
<td id="S4.SS1.2.2.2.12.1" class="ltx_td ltx_align_left ltx_border_r">GUPNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.12.2" class="ltx_td ltx_align_center">20.11</td>
<td id="S4.SS1.2.2.2.12.3" class="ltx_td ltx_align_center">14.20</td>
<td id="S4.SS1.2.2.2.12.4" class="ltx_td ltx_align_center ltx_border_r">11.77</td>
<td id="S4.SS1.2.2.2.12.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.SS1.2.2.2.12.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.SS1.2.2.2.12.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.SS1.2.2.2.13" class="ltx_tr">
<td id="S4.SS1.2.2.2.13.1" class="ltx_td ltx_align_left ltx_border_r">MonoDETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite>
</td>
<td id="S4.SS1.2.2.2.13.2" class="ltx_td ltx_align_center"><span id="S4.SS1.2.2.2.13.2.1" class="ltx_text" style="color:#BF0040;">23.65</span></td>
<td id="S4.SS1.2.2.2.13.3" class="ltx_td ltx_align_center"><span id="S4.SS1.2.2.2.13.3.1" class="ltx_text" style="color:#BF0040;">15.92</span></td>
<td id="S4.SS1.2.2.2.13.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.2.2.2.13.4.1" class="ltx_text" style="color:#BF0040;">12.99</span></td>
<td id="S4.SS1.2.2.2.13.5" class="ltx_td ltx_align_center"><span id="S4.SS1.2.2.2.13.5.1" class="ltx_text" style="color:#BF0040;">32.08</span></td>
<td id="S4.SS1.2.2.2.13.6" class="ltx_td ltx_align_center"><span id="S4.SS1.2.2.2.13.6.1" class="ltx_text" style="color:#BF0040;">21.44</span></td>
<td id="S4.SS1.2.2.2.13.7" class="ltx_td ltx_align_center"><span id="S4.SS1.2.2.2.13.7.1" class="ltx_text" style="color:#BF0040;">17.85</span></td>
</tr>
<tr id="S4.SS1.2.2.2.14" class="ltx_tr">
<td id="S4.SS1.2.2.2.14.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.SS1.2.2.2.14.1.1" class="ltx_text ltx_font_bold">MoGDE (Ours)</span></td>
<td id="S4.SS1.2.2.2.14.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.SS1.2.2.2.14.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.SS1.2.2.2.14.3.1" class="ltx_text ltx_font_bold">27.07</span></td>
<td id="S4.SS1.2.2.2.14.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.SS1.2.2.2.14.4.1" class="ltx_text ltx_font_bold">17.88</span></td>
<td id="S4.SS1.2.2.2.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.SS1.2.2.2.14.5.1" class="ltx_text ltx_font_bold">15.66</span></td>
<td id="S4.SS1.2.2.2.14.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.SS1.2.2.2.14.6.1" class="ltx_text ltx_font_bold">38.38</span></td>
<td id="S4.SS1.2.2.2.14.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.SS1.2.2.2.14.7.1" class="ltx_text ltx_font_bold">25.60</span></td>
<td id="S4.SS1.2.2.2.14.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.SS1.2.2.2.14.8.1" class="ltx_text ltx_font_bold">22.91</span></td>
</tr>
<tr id="S4.SS1.2.2.2.15" class="ltx_tr">
<td id="S4.SS1.2.2.2.15.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.SS1.2.2.2.15.1.1" class="ltx_text ltx_font_italic">Improvement</span></td>
<td id="S4.SS1.2.2.2.15.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.SS1.2.2.2.15.2.1" class="ltx_text ltx_font_italic">v.s. second-best</span></td>
<td id="S4.SS1.2.2.2.15.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.2.2.2.15.3.1" class="ltx_text" style="color:#0000FF;">+3.42</span></td>
<td id="S4.SS1.2.2.2.15.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.2.2.2.15.4.1" class="ltx_text" style="color:#0000FF;">+1.96</span></td>
<td id="S4.SS1.2.2.2.15.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.SS1.2.2.2.15.5.1" class="ltx_text" style="color:#0000FF;">+2.67</span></td>
<td id="S4.SS1.2.2.2.15.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.2.2.2.15.6.1" class="ltx_text" style="color:#0000FF;">+6.30</span></td>
<td id="S4.SS1.2.2.2.15.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.2.2.2.15.7.1" class="ltx_text" style="color:#0000FF;">+4.16</span></td>
<td id="S4.SS1.2.2.2.15.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.2.2.2.15.8.1" class="ltx_text" style="color:#0000FF;">+5.06</span></td>
</tr>
</table>
</span></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_subsection">Table 1: </span><math id="S4.SS1.4.m1.1" class="ltx_Math" alttext="AP_{40}" display="inline"><semantics id="S4.SS1.4.m1.1a"><mrow id="S4.SS1.4.m1.1.1" xref="S4.SS1.4.m1.1.1.cmml"><mi id="S4.SS1.4.m1.1.1.2" xref="S4.SS1.4.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.4.m1.1.1.1" xref="S4.SS1.4.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.4.m1.1.1.3" xref="S4.SS1.4.m1.1.1.3.cmml"><mi id="S4.SS1.4.m1.1.1.3.2" xref="S4.SS1.4.m1.1.1.3.2.cmml">P</mi><mn id="S4.SS1.4.m1.1.1.3.3" xref="S4.SS1.4.m1.1.1.3.3.cmml">40</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.4.m1.1b"><apply id="S4.SS1.4.m1.1.1.cmml" xref="S4.SS1.4.m1.1.1"><times id="S4.SS1.4.m1.1.1.1.cmml" xref="S4.SS1.4.m1.1.1.1"></times><ci id="S4.SS1.4.m1.1.1.2.cmml" xref="S4.SS1.4.m1.1.1.2">𝐴</ci><apply id="S4.SS1.4.m1.1.1.3.cmml" xref="S4.SS1.4.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.4.m1.1.1.3.1.cmml" xref="S4.SS1.4.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.4.m1.1.1.3.2.cmml" xref="S4.SS1.4.m1.1.1.3.2">𝑃</ci><cn type="integer" id="S4.SS1.4.m1.1.1.3.3.cmml" xref="S4.SS1.4.m1.1.1.3.3">40</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.4.m1.1c">AP_{40}</annotation></semantics></math> scores(%) of the car category on KITTI <span id="S4.SS1.12.1" class="ltx_text ltx_font_italic">test</span> set at 0.7 IoU threshold referred from the KITTI benchmark website. We utilize bold to highlight the best results, and color the second-best ones and our performance gain over them in blue. Our model is ranked NO. 1 on the benchmark.</figcaption>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">No.1 among all existing methods with different additional data inputs on all metrics.
Compared to the second-best models, MoGDE surpasses them under easy, moderate, and hard levels respectively by +3.42, +1.96, and +2.67 in <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml"><mi id="S4.SS1.p2.1.m1.1.1.3.2" xref="S4.SS1.p2.1.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.p2.1.m1.1.1.3.3" xref="S4.SS1.p2.1.m1.1.1.3.3.cmml"><mn id="S4.SS1.p2.1.m1.1.1.3.3.2" xref="S4.SS1.p2.1.m1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.3.3.1" xref="S4.SS1.p2.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.p2.1.m1.1.1.3.3.3" xref="S4.SS1.p2.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><times id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"></times><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">𝐴</ci><apply id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2">𝑃</ci><apply id="S4.SS1.p2.1.m1.1.1.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3"><times id="S4.SS1.p2.1.m1.1.1.3.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.1"></times><cn type="integer" id="S4.SS1.p2.1.m1.1.1.3.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.2">3</cn><ci id="S4.SS1.p2.1.m1.1.1.3.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">AP_{3D}</annotation></semantics></math>, especially achieving a significant increase (17%) in the hard level.
The comparison fully proves the effectiveness of the proposed oracle fusion for images with prior depth knowledge.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Figure <a href="#S4.F5" title="Figure 5 ‣ 4.1 Quantitative and Qualitative Results ‣ 4 Performance Evaluation ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the qualitative results on the KITTI Odometry dataset.
Compared with the baseline model without the aid of ground depth, the predictions from MoGDE are much closer to the ground truth, especially for distinct objects.
It shows that the consideration of sight-based supporting depth clues can help to locate the object precisely.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2303.13561/assets/x4.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="186" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Qualitative results on KITTI Odometry dataset. The predicted 3D bounding boxes of our proposed MoGDE are shown in the first row.
The second row shows the detection results in the bird’s eye view (<math id="S4.F5.2.m1.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S4.F5.2.m1.1b"><mi id="S4.F5.2.m1.1.1" xref="S4.F5.2.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S4.F5.2.m1.1c"><ci id="S4.F5.2.m1.1.1.cmml" xref="S4.F5.2.m1.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.2.m1.1d">z</annotation></semantics></math>-direction from right to left).
The green dashed boxes are the ground truth, and the blue and red solid boxes are the prediction results of our MoGDE and the comparison baseline (GUPNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite>), respectively.
The third row visualizes the results of the attention map in the transformer’s encoder, where the purple point is the location of the query point; the yellow dashed box is the range of the encoder’s mask; the brightness of the image represents the attention value between the query point and that pixel.
</figcaption>
</figure>
<div id="S4.SS1.13" class="ltx_sectional-block ltx_minipage">
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Ablation Study</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">Effectiveness of each proposed component.</span>
In Table <a href="#S4.SS1" title="4.1 Quantitative and Qualitative Results ‣ 4 Performance Evaluation ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we conduct an ablation study to analyze the effectiveness of the proposed components: (a) Baseline: only using image features for 3D object detection, <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">i.e.</span>, without concerning posed variance and proposed ground-aware modules.
(b) Considering the camera pose variations implied in the images, we use the method described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> to apply a "projection transform" to the input image to remove the perturbations.
(c) Considering the use of ground plane clues, we generate a depth oracle about the scene (assuming constant pose) using a convolutional neural network. (d) With</p>
</div>
</section>
</div>
<figure id="S4.SS1.fig1" class="ltx_figure ltx_minipage ltx_align_middle" style="width:208.1pt;">
<div id="S4.SS1.fig1.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:210.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(81.0pt,-39.4pt) scale(1.59647116733877,1.59647116733877) ;">
<table id="S4.SS1.fig1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.SS1.fig1.1.1.1" class="ltx_tr">
<td id="S4.SS1.fig1.1.1.1.1" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S4.SS1.fig1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.SS1.fig1.1.1.1.2.1" class="ltx_text">
<span id="S4.SS1.fig1.1.1.1.2.1.1" class="ltx_inline-block">
<span id="S4.SS1.fig1.1.1.1.2.1.1.1" class="ltx_p">Pose</span>
<span id="S4.SS1.fig1.1.1.1.2.1.1.2" class="ltx_p">-guided</span>
</span></span></td>
<td id="S4.SS1.fig1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.SS1.fig1.1.1.1.3.1" class="ltx_text">
<span id="S4.SS1.fig1.1.1.1.3.1.1" class="ltx_inline-block">
<span id="S4.SS1.fig1.1.1.1.3.1.1.1" class="ltx_p">Conv.</span>
<span id="S4.SS1.fig1.1.1.1.3.1.1.2" class="ltx_p">Fusion</span>
</span></span></td>
<td id="S4.SS1.fig1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.SS1.fig1.1.1.1.4.1" class="ltx_text">
<span id="S4.SS1.fig1.1.1.1.4.1.1" class="ltx_inline-block">
<span id="S4.SS1.fig1.1.1.1.4.1.1.1" class="ltx_p">Tran.</span>
<span id="S4.SS1.fig1.1.1.1.4.1.1.2" class="ltx_p">Fusion</span>
</span></span></td>
<td id="S4.SS1.fig1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.SS1.fig1.1.1.1.5.1" class="ltx_text">Easy</span></td>
<td id="S4.SS1.fig1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.SS1.fig1.1.1.1.6.1" class="ltx_text">Mod.</span></td>
<td id="S4.SS1.fig1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.SS1.fig1.1.1.1.7.1" class="ltx_text">Hard</span></td>
</tr>
<tr id="S4.SS1.fig1.1.1.2" class="ltx_tr">
<td id="S4.SS1.fig1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">(a)</td>
<td id="S4.SS1.fig1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_tt">-</td>
<td id="S4.SS1.fig1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">-</td>
<td id="S4.SS1.fig1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S4.SS1.fig1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_tt">22.76</td>
<td id="S4.SS1.fig1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_tt">16.46</td>
<td id="S4.SS1.fig1.1.1.2.7" class="ltx_td ltx_align_center ltx_border_tt">13.72</td>
</tr>
<tr id="S4.SS1.fig1.1.1.3" class="ltx_tr">
<td id="S4.SS1.fig1.1.1.3.1" class="ltx_td ltx_align_left ltx_border_r">(b)</td>
<td id="S4.SS1.fig1.1.1.3.2" class="ltx_td ltx_align_center">✓</td>
<td id="S4.SS1.fig1.1.1.3.3" class="ltx_td ltx_align_center">-</td>
<td id="S4.SS1.fig1.1.1.3.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.SS1.fig1.1.1.3.5" class="ltx_td ltx_align_center">22.78</td>
<td id="S4.SS1.fig1.1.1.3.6" class="ltx_td ltx_align_center">16.93</td>
<td id="S4.SS1.fig1.1.1.3.7" class="ltx_td ltx_align_center">14.04</td>
</tr>
<tr id="S4.SS1.fig1.1.1.4" class="ltx_tr">
<td id="S4.SS1.fig1.1.1.4.1" class="ltx_td ltx_align_left ltx_border_r">(c)</td>
<td id="S4.SS1.fig1.1.1.4.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.SS1.fig1.1.1.4.3" class="ltx_td ltx_align_center">✓</td>
<td id="S4.SS1.fig1.1.1.4.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.SS1.fig1.1.1.4.5" class="ltx_td ltx_align_center">22.82</td>
<td id="S4.SS1.fig1.1.1.4.6" class="ltx_td ltx_align_center">17.22</td>
<td id="S4.SS1.fig1.1.1.4.7" class="ltx_td ltx_align_center">14.51</td>
</tr>
<tr id="S4.SS1.fig1.1.1.5" class="ltx_tr">
<td id="S4.SS1.fig1.1.1.5.1" class="ltx_td ltx_align_left ltx_border_r">(d)</td>
<td id="S4.SS1.fig1.1.1.5.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.SS1.fig1.1.1.5.3" class="ltx_td ltx_align_center">-</td>
<td id="S4.SS1.fig1.1.1.5.4" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S4.SS1.fig1.1.1.5.5" class="ltx_td ltx_align_center">22.93</td>
<td id="S4.SS1.fig1.1.1.5.6" class="ltx_td ltx_align_center">18.42</td>
<td id="S4.SS1.fig1.1.1.5.7" class="ltx_td ltx_align_center">15.46</td>
</tr>
<tr id="S4.SS1.fig1.1.1.6" class="ltx_tr">
<td id="S4.SS1.fig1.1.1.6.1" class="ltx_td ltx_align_left ltx_border_r">(e)</td>
<td id="S4.SS1.fig1.1.1.6.2" class="ltx_td ltx_align_center">✓</td>
<td id="S4.SS1.fig1.1.1.6.3" class="ltx_td ltx_align_center">✓</td>
<td id="S4.SS1.fig1.1.1.6.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.SS1.fig1.1.1.6.5" class="ltx_td ltx_align_center">23.07</td>
<td id="S4.SS1.fig1.1.1.6.6" class="ltx_td ltx_align_center">18.66</td>
<td id="S4.SS1.fig1.1.1.6.7" class="ltx_td ltx_align_center">15.73</td>
</tr>
<tr id="S4.SS1.fig1.1.1.7" class="ltx_tr">
<td id="S4.SS1.fig1.1.1.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">(f)</td>
<td id="S4.SS1.fig1.1.1.7.2" class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td id="S4.SS1.fig1.1.1.7.3" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.SS1.fig1.1.1.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">✓</td>
<td id="S4.SS1.fig1.1.1.7.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.fig1.1.1.7.5.1" class="ltx_text ltx_font_bold">23.35</span></td>
<td id="S4.SS1.fig1.1.1.7.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.fig1.1.1.7.6.1" class="ltx_text ltx_font_bold">20.35</span></td>
<td id="S4.SS1.fig1.1.1.7.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.fig1.1.1.7.7.1" class="ltx_text ltx_font_bold">17.71</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 2: </span>Effectiveness of different components of our approach on the KITTI <span id="S4.SS1.fig1.3.1" class="ltx_text ltx_font_italic">val</span> set for car category. The first column is whether the model takes into account the pose variance. The second and third columns show which way the model chooses to fuse the ground depth information.</figcaption>
</figure>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">the proposed <span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_italic">ground-aware</span> transformer, this model has the ability to model long-range relationships of pixels.
(e) Full model except that we use a convolutional neural network for oracle fusion.
(f) Full model (MoGDE).</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.4" class="ltx_p">First, we can observe from (a <math id="S4.SS1.p5.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS1.p5.1.m1.1a"><mo stretchy="false" id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><ci id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">\rightarrow</annotation></semantics></math> b, c <math id="S4.SS1.p5.2.m2.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS1.p5.2.m2.1a"><mo stretchy="false" id="S4.SS1.p5.2.m2.1.1" xref="S4.SS1.p5.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.2.m2.1b"><ci id="S4.SS1.p5.2.m2.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.2.m2.1c">\rightarrow</annotation></semantics></math> e, and d <math id="S4.SS1.p5.3.m3.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS1.p5.3.m3.1a"><mo stretchy="false" id="S4.SS1.p5.3.m3.1.1" xref="S4.SS1.p5.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.3.m3.1b"><ci id="S4.SS1.p5.3.m3.1.1.cmml" xref="S4.SS1.p5.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.3.m3.1c">\rightarrow</annotation></semantics></math> f) that there is an implicit uncalibrated pose variation in the KITTI dataset, and considering it is necessary to improve the detection accuracy.
Besides, by observing (b <math id="S4.SS1.p5.4.m4.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS1.p5.4.m4.1a"><mo stretchy="false" id="S4.SS1.p5.4.m4.1.1" xref="S4.SS1.p5.4.m4.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.4.m4.1b"><ci id="S4.SS1.p5.4.m4.1.1.cmml" xref="S4.SS1.p5.4.m4.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.4.m4.1c">\rightarrow</annotation></semantics></math> e), we illustrate that leveraging ground depth brings an improvement in accuracy in hard level, but the improvement is limited because fusion by convolution is clumsy.</p>
</div>
<figure id="S4.SS1.6" class="ltx_figure ltx_minipage ltx_align_middle" style="width:212.5pt;">
<div id="S4.SS1.6.2" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:251.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(46.1pt,-26.7pt) scale(1.26974875768439,1.26974875768439) ;">
<table id="S4.SS1.6.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.SS1.6.2.2.2" class="ltx_tr">
<td id="S4.SS1.6.2.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.SS1.6.2.2.2.3.1" class="ltx_text">Pose Var.</span></td>
<td id="S4.SS1.6.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.SS1.6.2.2.2.4.1" class="ltx_text">Method</span></td>
<td id="S4.SS1.5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Val, <math id="S4.SS1.5.1.1.1.1.m1.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S4.SS1.5.1.1.1.1.m1.1a"><mrow id="S4.SS1.5.1.1.1.1.m1.1.1" xref="S4.SS1.5.1.1.1.1.m1.1.1.cmml"><mi id="S4.SS1.5.1.1.1.1.m1.1.1.2" xref="S4.SS1.5.1.1.1.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.5.1.1.1.1.m1.1.1.1" xref="S4.SS1.5.1.1.1.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.5.1.1.1.1.m1.1.1.3" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.cmml"><mi id="S4.SS1.5.1.1.1.1.m1.1.1.3.2" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.5.1.1.1.1.m1.1.1.3.3" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.3.cmml"><mn id="S4.SS1.5.1.1.1.1.m1.1.1.3.3.2" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS1.5.1.1.1.1.m1.1.1.3.3.1" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.5.1.1.1.1.m1.1.1.3.3.3" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.5.1.1.1.1.m1.1b"><apply id="S4.SS1.5.1.1.1.1.m1.1.1.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1"><times id="S4.SS1.5.1.1.1.1.m1.1.1.1.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1.1"></times><ci id="S4.SS1.5.1.1.1.1.m1.1.1.2.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1.2">𝐴</ci><apply id="S4.SS1.5.1.1.1.1.m1.1.1.3.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.5.1.1.1.1.m1.1.1.3.1.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.5.1.1.1.1.m1.1.1.3.2.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.2">𝑃</ci><apply id="S4.SS1.5.1.1.1.1.m1.1.1.3.3.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.3"><times id="S4.SS1.5.1.1.1.1.m1.1.1.3.3.1.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.3.1"></times><cn type="integer" id="S4.SS1.5.1.1.1.1.m1.1.1.3.3.2.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.3.2">3</cn><ci id="S4.SS1.5.1.1.1.1.m1.1.1.3.3.3.cmml" xref="S4.SS1.5.1.1.1.1.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.5.1.1.1.1.m1.1c">AP_{3D}</annotation></semantics></math>
</td>
<td id="S4.SS1.6.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Val, <math id="S4.SS1.6.2.2.2.2.m1.1" class="ltx_Math" alttext="AP_{BEV}" display="inline"><semantics id="S4.SS1.6.2.2.2.2.m1.1a"><mrow id="S4.SS1.6.2.2.2.2.m1.1.1" xref="S4.SS1.6.2.2.2.2.m1.1.1.cmml"><mi id="S4.SS1.6.2.2.2.2.m1.1.1.2" xref="S4.SS1.6.2.2.2.2.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.6.2.2.2.2.m1.1.1.1" xref="S4.SS1.6.2.2.2.2.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.6.2.2.2.2.m1.1.1.3" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.cmml"><mi id="S4.SS1.6.2.2.2.2.m1.1.1.3.2" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.6.2.2.2.2.m1.1.1.3.3" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.cmml"><mi id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.2" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.1" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.3" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.1a" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.4" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.4.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.6.2.2.2.2.m1.1b"><apply id="S4.SS1.6.2.2.2.2.m1.1.1.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1"><times id="S4.SS1.6.2.2.2.2.m1.1.1.1.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.1"></times><ci id="S4.SS1.6.2.2.2.2.m1.1.1.2.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.2">𝐴</ci><apply id="S4.SS1.6.2.2.2.2.m1.1.1.3.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.6.2.2.2.2.m1.1.1.3.1.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.6.2.2.2.2.m1.1.1.3.2.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.2">𝑃</ci><apply id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3"><times id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.1.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.1"></times><ci id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.2.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.2">𝐵</ci><ci id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.3.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.3">𝐸</ci><ci id="S4.SS1.6.2.2.2.2.m1.1.1.3.3.4.cmml" xref="S4.SS1.6.2.2.2.2.m1.1.1.3.3.4">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.6.2.2.2.2.m1.1c">AP_{BEV}</annotation></semantics></math>
</td>
</tr>
<tr id="S4.SS1.6.2.2.3" class="ltx_tr">
<td id="S4.SS1.6.2.2.3.1" class="ltx_td ltx_align_center">Easy</td>
<td id="S4.SS1.6.2.2.3.2" class="ltx_td ltx_align_center">Mod.</td>
<td id="S4.SS1.6.2.2.3.3" class="ltx_td ltx_align_center ltx_border_r">Hard</td>
<td id="S4.SS1.6.2.2.3.4" class="ltx_td ltx_align_center">Easy</td>
<td id="S4.SS1.6.2.2.3.5" class="ltx_td ltx_align_center">Mod.</td>
<td id="S4.SS1.6.2.2.3.6" class="ltx_td ltx_align_center">Hard</td>
</tr>
<tr id="S4.SS1.6.2.2.4" class="ltx_tr">
<td id="S4.SS1.6.2.2.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="3"><span id="S4.SS1.6.2.2.4.1.1" class="ltx_text">Tiny</span></td>
<td id="S4.SS1.6.2.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">w/o</td>
<td id="S4.SS1.6.2.2.4.3" class="ltx_td ltx_align_center ltx_border_tt">20.64</td>
<td id="S4.SS1.6.2.2.4.4" class="ltx_td ltx_align_center ltx_border_tt">14.87</td>
<td id="S4.SS1.6.2.2.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">12.47</td>
<td id="S4.SS1.6.2.2.4.6" class="ltx_td ltx_align_center ltx_border_tt">27.97</td>
<td id="S4.SS1.6.2.2.4.7" class="ltx_td ltx_align_center ltx_border_tt">20.78</td>
<td id="S4.SS1.6.2.2.4.8" class="ltx_td ltx_align_center ltx_border_tt">17.79</td>
</tr>
<tr id="S4.SS1.6.2.2.5" class="ltx_tr">
<td id="S4.SS1.6.2.2.5.1" class="ltx_td ltx_align_center ltx_border_r">w/</td>
<td id="S4.SS1.6.2.2.5.2" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.5.2.1" class="ltx_text ltx_font_bold">22.30</span></td>
<td id="S4.SS1.6.2.2.5.3" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.5.3.1" class="ltx_text ltx_font_bold">19.42</span></td>
<td id="S4.SS1.6.2.2.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.6.2.2.5.4.1" class="ltx_text ltx_font_bold">16.84</span></td>
<td id="S4.SS1.6.2.2.5.5" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.5.5.1" class="ltx_text ltx_font_bold">29.86</span></td>
<td id="S4.SS1.6.2.2.5.6" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.5.6.1" class="ltx_text ltx_font_bold">24.28</span></td>
<td id="S4.SS1.6.2.2.5.7" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.5.7.1" class="ltx_text ltx_font_bold">23.15</span></td>
</tr>
<tr id="S4.SS1.6.2.2.6" class="ltx_tr">
<td id="S4.SS1.6.2.2.6.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.6.2.2.6.1.1" class="ltx_text ltx_font_italic">Imp.</span></td>
<td id="S4.SS1.6.2.2.6.2" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.6.2.1" class="ltx_text" style="color:#0000FF;">+1.66</span></td>
<td id="S4.SS1.6.2.2.6.3" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.6.3.1" class="ltx_text" style="color:#0000FF;">+4.55</span></td>
<td id="S4.SS1.6.2.2.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.6.2.2.6.4.1" class="ltx_text" style="color:#0000FF;">+4.37</span></td>
<td id="S4.SS1.6.2.2.6.5" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.6.5.1" class="ltx_text" style="color:#0000FF;">+1.89</span></td>
<td id="S4.SS1.6.2.2.6.6" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.6.6.1" class="ltx_text" style="color:#0000FF;">+3.50</span></td>
<td id="S4.SS1.6.2.2.6.7" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.6.7.1" class="ltx_text" style="color:#0000FF;">+5.35</span></td>
</tr>
<tr id="S4.SS1.6.2.2.7" class="ltx_tr">
<td id="S4.SS1.6.2.2.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="3"><span id="S4.SS1.6.2.2.7.1.1" class="ltx_text">Medium</span></td>
<td id="S4.SS1.6.2.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">w/o</td>
<td id="S4.SS1.6.2.2.7.3" class="ltx_td ltx_align_center ltx_border_t">17.76</td>
<td id="S4.SS1.6.2.2.7.4" class="ltx_td ltx_align_center ltx_border_t">12.98</td>
<td id="S4.SS1.6.2.2.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.78</td>
<td id="S4.SS1.6.2.2.7.6" class="ltx_td ltx_align_center ltx_border_t">24.43</td>
<td id="S4.SS1.6.2.2.7.7" class="ltx_td ltx_align_center ltx_border_t">18.06</td>
<td id="S4.SS1.6.2.2.7.8" class="ltx_td ltx_align_center ltx_border_t">15.46</td>
</tr>
<tr id="S4.SS1.6.2.2.8" class="ltx_tr">
<td id="S4.SS1.6.2.2.8.1" class="ltx_td ltx_align_center ltx_border_r">w/</td>
<td id="S4.SS1.6.2.2.8.2" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.8.2.1" class="ltx_text ltx_font_bold">21.86</span></td>
<td id="S4.SS1.6.2.2.8.3" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.8.3.1" class="ltx_text ltx_font_bold">19.08</span></td>
<td id="S4.SS1.6.2.2.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.6.2.2.8.4.1" class="ltx_text ltx_font_bold">16.61</span></td>
<td id="S4.SS1.6.2.2.8.5" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.8.5.1" class="ltx_text ltx_font_bold">29.23</span></td>
<td id="S4.SS1.6.2.2.8.6" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.8.6.1" class="ltx_text ltx_font_bold">23.70</span></td>
<td id="S4.SS1.6.2.2.8.7" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.8.7.1" class="ltx_text ltx_font_bold">22.84</span></td>
</tr>
<tr id="S4.SS1.6.2.2.9" class="ltx_tr">
<td id="S4.SS1.6.2.2.9.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.6.2.2.9.1.1" class="ltx_text ltx_font_italic">Imp.</span></td>
<td id="S4.SS1.6.2.2.9.2" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.9.2.1" class="ltx_text" style="color:#0000FF;">+4.10</span></td>
<td id="S4.SS1.6.2.2.9.3" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.9.3.1" class="ltx_text" style="color:#0000FF;">+6.10</span></td>
<td id="S4.SS1.6.2.2.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.6.2.2.9.4.1" class="ltx_text" style="color:#0000FF;">+5.83</span></td>
<td id="S4.SS1.6.2.2.9.5" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.9.5.1" class="ltx_text" style="color:#0000FF;">+4.81</span></td>
<td id="S4.SS1.6.2.2.9.6" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.9.6.1" class="ltx_text" style="color:#0000FF;">+5.64</span></td>
<td id="S4.SS1.6.2.2.9.7" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.9.7.1" class="ltx_text" style="color:#0000FF;">+7.38</span></td>
</tr>
<tr id="S4.SS1.6.2.2.10" class="ltx_tr">
<td id="S4.SS1.6.2.2.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" rowspan="3"><span id="S4.SS1.6.2.2.10.1.1" class="ltx_text">Large</span></td>
<td id="S4.SS1.6.2.2.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">w/o</td>
<td id="S4.SS1.6.2.2.10.3" class="ltx_td ltx_align_center ltx_border_t">13.29</td>
<td id="S4.SS1.6.2.2.10.4" class="ltx_td ltx_align_center ltx_border_t">9.60</td>
<td id="S4.SS1.6.2.2.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8.05</td>
<td id="S4.SS1.6.2.2.10.6" class="ltx_td ltx_align_center ltx_border_t">18.05</td>
<td id="S4.SS1.6.2.2.10.7" class="ltx_td ltx_align_center ltx_border_t">13.34</td>
<td id="S4.SS1.6.2.2.10.8" class="ltx_td ltx_align_center ltx_border_t">11.57</td>
</tr>
<tr id="S4.SS1.6.2.2.11" class="ltx_tr">
<td id="S4.SS1.6.2.2.11.1" class="ltx_td ltx_align_center ltx_border_r">w/</td>
<td id="S4.SS1.6.2.2.11.2" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.11.2.1" class="ltx_text ltx_font_bold">21.10</span></td>
<td id="S4.SS1.6.2.2.11.3" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.11.3.1" class="ltx_text ltx_font_bold">18.35</span></td>
<td id="S4.SS1.6.2.2.11.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.6.2.2.11.4.1" class="ltx_text ltx_font_bold">16.10</span></td>
<td id="S4.SS1.6.2.2.11.5" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.11.5.1" class="ltx_text ltx_font_bold">28.33</span></td>
<td id="S4.SS1.6.2.2.11.6" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.11.6.1" class="ltx_text ltx_font_bold">22.98</span></td>
<td id="S4.SS1.6.2.2.11.7" class="ltx_td ltx_align_center"><span id="S4.SS1.6.2.2.11.7.1" class="ltx_text ltx_font_bold">22.06</span></td>
</tr>
<tr id="S4.SS1.6.2.2.12" class="ltx_tr">
<td id="S4.SS1.6.2.2.12.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.SS1.6.2.2.12.1.1" class="ltx_text ltx_font_italic">Imp.</span></td>
<td id="S4.SS1.6.2.2.12.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.6.2.2.12.2.1" class="ltx_text" style="color:#0000FF;">+7.81</span></td>
<td id="S4.SS1.6.2.2.12.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.6.2.2.12.3.1" class="ltx_text" style="color:#0000FF;">+8.75</span></td>
<td id="S4.SS1.6.2.2.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.SS1.6.2.2.12.4.1" class="ltx_text" style="color:#0000FF;">+8.05</span></td>
<td id="S4.SS1.6.2.2.12.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.6.2.2.12.5.1" class="ltx_text" style="color:#0000FF;">+10.28</span></td>
<td id="S4.SS1.6.2.2.12.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.6.2.2.12.6.1" class="ltx_text" style="color:#0000FF;">+9.64</span></td>
<td id="S4.SS1.6.2.2.12.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.6.2.2.12.7.1" class="ltx_text" style="color:#0000FF;">+10.48</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 3: </span>Robustness test of our approach on the KITTI <span id="S4.SS1.6.5.1" class="ltx_text ltx_font_italic">val</span> set for car category. Tiny, medium, and large correspond to three different degrees of posture change, <span id="S4.SS1.6.6.2" class="ltx_text ltx_font_italic">i.e.</span>, the camera pitch and roll angles vary with a Gaussian distribution with mean 0 and standard deviation 1, 2, and 3, respectively.</figcaption>
</figure>
<figure id="S4.SS1.10" class="ltx_figure ltx_minipage ltx_align_middle" style="width:212.5pt;">
<div id="S4.SS1.8.2" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:192.6pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.2pt,3.2pt) scale(0.967659926804716,0.967659926804716) ;">
<table id="S4.SS1.8.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.SS1.8.2.2.2" class="ltx_tr">
<td id="S4.SS1.8.2.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.SS1.8.2.2.2.3.1" class="ltx_text">Method</span></td>
<td id="S4.SS1.7.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Val, <math id="S4.SS1.7.1.1.1.1.m1.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S4.SS1.7.1.1.1.1.m1.1a"><mrow id="S4.SS1.7.1.1.1.1.m1.1.1" xref="S4.SS1.7.1.1.1.1.m1.1.1.cmml"><mi id="S4.SS1.7.1.1.1.1.m1.1.1.2" xref="S4.SS1.7.1.1.1.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.7.1.1.1.1.m1.1.1.1" xref="S4.SS1.7.1.1.1.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.7.1.1.1.1.m1.1.1.3" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.cmml"><mi id="S4.SS1.7.1.1.1.1.m1.1.1.3.2" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.7.1.1.1.1.m1.1.1.3.3" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.3.cmml"><mn id="S4.SS1.7.1.1.1.1.m1.1.1.3.3.2" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS1.7.1.1.1.1.m1.1.1.3.3.1" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.7.1.1.1.1.m1.1.1.3.3.3" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.7.1.1.1.1.m1.1b"><apply id="S4.SS1.7.1.1.1.1.m1.1.1.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1"><times id="S4.SS1.7.1.1.1.1.m1.1.1.1.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1.1"></times><ci id="S4.SS1.7.1.1.1.1.m1.1.1.2.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1.2">𝐴</ci><apply id="S4.SS1.7.1.1.1.1.m1.1.1.3.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.7.1.1.1.1.m1.1.1.3.1.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.7.1.1.1.1.m1.1.1.3.2.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.2">𝑃</ci><apply id="S4.SS1.7.1.1.1.1.m1.1.1.3.3.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.3"><times id="S4.SS1.7.1.1.1.1.m1.1.1.3.3.1.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.3.1"></times><cn type="integer" id="S4.SS1.7.1.1.1.1.m1.1.1.3.3.2.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.3.2">3</cn><ci id="S4.SS1.7.1.1.1.1.m1.1.1.3.3.3.cmml" xref="S4.SS1.7.1.1.1.1.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.7.1.1.1.1.m1.1c">AP_{3D}</annotation></semantics></math>
</td>
<td id="S4.SS1.8.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Val, <math id="S4.SS1.8.2.2.2.2.m1.1" class="ltx_Math" alttext="AP_{BEV}" display="inline"><semantics id="S4.SS1.8.2.2.2.2.m1.1a"><mrow id="S4.SS1.8.2.2.2.2.m1.1.1" xref="S4.SS1.8.2.2.2.2.m1.1.1.cmml"><mi id="S4.SS1.8.2.2.2.2.m1.1.1.2" xref="S4.SS1.8.2.2.2.2.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.8.2.2.2.2.m1.1.1.1" xref="S4.SS1.8.2.2.2.2.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.8.2.2.2.2.m1.1.1.3" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.cmml"><mi id="S4.SS1.8.2.2.2.2.m1.1.1.3.2" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.8.2.2.2.2.m1.1.1.3.3" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.cmml"><mi id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.2" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.1" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.3" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.1a" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.4" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.4.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.8.2.2.2.2.m1.1b"><apply id="S4.SS1.8.2.2.2.2.m1.1.1.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1"><times id="S4.SS1.8.2.2.2.2.m1.1.1.1.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.1"></times><ci id="S4.SS1.8.2.2.2.2.m1.1.1.2.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.2">𝐴</ci><apply id="S4.SS1.8.2.2.2.2.m1.1.1.3.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.8.2.2.2.2.m1.1.1.3.1.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.8.2.2.2.2.m1.1.1.3.2.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.2">𝑃</ci><apply id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3"><times id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.1.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.1"></times><ci id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.2.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.2">𝐵</ci><ci id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.3.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.3">𝐸</ci><ci id="S4.SS1.8.2.2.2.2.m1.1.1.3.3.4.cmml" xref="S4.SS1.8.2.2.2.2.m1.1.1.3.3.4">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.8.2.2.2.2.m1.1c">AP_{BEV}</annotation></semantics></math>
</td>
</tr>
<tr id="S4.SS1.8.2.2.3" class="ltx_tr">
<td id="S4.SS1.8.2.2.3.1" class="ltx_td ltx_align_center">Easy</td>
<td id="S4.SS1.8.2.2.3.2" class="ltx_td ltx_align_center">Mod.</td>
<td id="S4.SS1.8.2.2.3.3" class="ltx_td ltx_align_center ltx_border_r">Hard</td>
<td id="S4.SS1.8.2.2.3.4" class="ltx_td ltx_align_center">Easy</td>
<td id="S4.SS1.8.2.2.3.5" class="ltx_td ltx_align_center">Mod.</td>
<td id="S4.SS1.8.2.2.3.6" class="ltx_td ltx_align_center">Hard</td>
</tr>
<tr id="S4.SS1.8.2.2.4" class="ltx_tr">
<td id="S4.SS1.8.2.2.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">M3D-RPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite>
</td>
<td id="S4.SS1.8.2.2.4.2" class="ltx_td ltx_align_center ltx_border_tt">14.53</td>
<td id="S4.SS1.8.2.2.4.3" class="ltx_td ltx_align_center ltx_border_tt">11.07</td>
<td id="S4.SS1.8.2.2.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">8.65</td>
<td id="S4.SS1.8.2.2.4.5" class="ltx_td ltx_align_center ltx_border_tt">20.85</td>
<td id="S4.SS1.8.2.2.4.6" class="ltx_td ltx_align_center ltx_border_tt">15.62</td>
<td id="S4.SS1.8.2.2.4.7" class="ltx_td ltx_align_center ltx_border_tt">11.88</td>
</tr>
<tr id="S4.SS1.8.2.2.5" class="ltx_tr">
<td id="S4.SS1.8.2.2.5.1" class="ltx_td ltx_align_left ltx_border_r">M3D-RPN + <span id="S4.SS1.8.2.2.5.1.1" class="ltx_text ltx_font_bold">Ours</span>
</td>
<td id="S4.SS1.8.2.2.5.2" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.5.2.1" class="ltx_text ltx_font_bold">19.85</span></td>
<td id="S4.SS1.8.2.2.5.3" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.5.3.1" class="ltx_text ltx_font_bold">16.84</span></td>
<td id="S4.SS1.8.2.2.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.8.2.2.5.4.1" class="ltx_text ltx_font_bold">14.62</span></td>
<td id="S4.SS1.8.2.2.5.5" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.5.5.1" class="ltx_text ltx_font_bold">25.16</span></td>
<td id="S4.SS1.8.2.2.5.6" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.5.6.1" class="ltx_text ltx_font_bold">20.65</span></td>
<td id="S4.SS1.8.2.2.5.7" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.5.7.1" class="ltx_text ltx_font_bold">17.39</span></td>
</tr>
<tr id="S4.SS1.8.2.2.6" class="ltx_tr">
<td id="S4.SS1.8.2.2.6.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.SS1.8.2.2.6.1.1" class="ltx_text ltx_font_italic">Imp.</span></td>
<td id="S4.SS1.8.2.2.6.2" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.6.2.1" class="ltx_text" style="color:#0000FF;">+5.32</span></td>
<td id="S4.SS1.8.2.2.6.3" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.6.3.1" class="ltx_text" style="color:#0000FF;">+5.77</span></td>
<td id="S4.SS1.8.2.2.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.8.2.2.6.4.1" class="ltx_text" style="color:#0000FF;">+5.97</span></td>
<td id="S4.SS1.8.2.2.6.5" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.6.5.1" class="ltx_text" style="color:#0000FF;">+4.31</span></td>
<td id="S4.SS1.8.2.2.6.6" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.6.6.1" class="ltx_text" style="color:#0000FF;">+5.03</span></td>
<td id="S4.SS1.8.2.2.6.7" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.6.7.1" class="ltx_text" style="color:#0000FF;">+5.51</span></td>
</tr>
<tr id="S4.SS1.8.2.2.7" class="ltx_tr">
<td id="S4.SS1.8.2.2.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">MonoPair <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite>
</td>
<td id="S4.SS1.8.2.2.7.2" class="ltx_td ltx_align_center ltx_border_t">16.28</td>
<td id="S4.SS1.8.2.2.7.3" class="ltx_td ltx_align_center ltx_border_t">12.30</td>
<td id="S4.SS1.8.2.2.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.42</td>
<td id="S4.SS1.8.2.2.7.5" class="ltx_td ltx_align_center ltx_border_t">24.12</td>
<td id="S4.SS1.8.2.2.7.6" class="ltx_td ltx_align_center ltx_border_t">18.17</td>
<td id="S4.SS1.8.2.2.7.7" class="ltx_td ltx_align_center ltx_border_t">15.76</td>
</tr>
<tr id="S4.SS1.8.2.2.8" class="ltx_tr">
<td id="S4.SS1.8.2.2.8.1" class="ltx_td ltx_align_left ltx_border_r">MonoPair + <span id="S4.SS1.8.2.2.8.1.1" class="ltx_text ltx_font_bold">Ours</span>
</td>
<td id="S4.SS1.8.2.2.8.2" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.8.2.1" class="ltx_text ltx_font_bold">19.20</span></td>
<td id="S4.SS1.8.2.2.8.3" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.8.3.1" class="ltx_text ltx_font_bold">15.42</span></td>
<td id="S4.SS1.8.2.2.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.8.2.2.8.4.1" class="ltx_text ltx_font_bold">13.16</span></td>
<td id="S4.SS1.8.2.2.8.5" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.8.5.1" class="ltx_text ltx_font_bold">27.33</span></td>
<td id="S4.SS1.8.2.2.8.6" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.8.6.1" class="ltx_text ltx_font_bold">21.71</span></td>
<td id="S4.SS1.8.2.2.8.7" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.8.7.1" class="ltx_text ltx_font_bold">18.68</span></td>
</tr>
<tr id="S4.SS1.8.2.2.9" class="ltx_tr">
<td id="S4.SS1.8.2.2.9.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.SS1.8.2.2.9.1.1" class="ltx_text ltx_font_italic">Imp.</span></td>
<td id="S4.SS1.8.2.2.9.2" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.9.2.1" class="ltx_text" style="color:#0000FF;">+2.92</span></td>
<td id="S4.SS1.8.2.2.9.3" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.9.3.1" class="ltx_text" style="color:#0000FF;">+3.12</span></td>
<td id="S4.SS1.8.2.2.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.8.2.2.9.4.1" class="ltx_text" style="color:#0000FF;">+2.74</span></td>
<td id="S4.SS1.8.2.2.9.5" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.9.5.1" class="ltx_text" style="color:#0000FF;">+3.21</span></td>
<td id="S4.SS1.8.2.2.9.6" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.9.6.1" class="ltx_text" style="color:#0000FF;">+3.54</span></td>
<td id="S4.SS1.8.2.2.9.7" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.9.7.1" class="ltx_text" style="color:#0000FF;">+2.92</span></td>
</tr>
<tr id="S4.SS1.8.2.2.10" class="ltx_tr">
<td id="S4.SS1.8.2.2.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Kinematic3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite>
</td>
<td id="S4.SS1.8.2.2.10.2" class="ltx_td ltx_align_center ltx_border_t">19.76</td>
<td id="S4.SS1.8.2.2.10.3" class="ltx_td ltx_align_center ltx_border_t">14.10</td>
<td id="S4.SS1.8.2.2.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.47</td>
<td id="S4.SS1.8.2.2.10.5" class="ltx_td ltx_align_center ltx_border_t">27.83</td>
<td id="S4.SS1.8.2.2.10.6" class="ltx_td ltx_align_center ltx_border_t">19.72</td>
<td id="S4.SS1.8.2.2.10.7" class="ltx_td ltx_align_center ltx_border_t">15.10</td>
</tr>
<tr id="S4.SS1.8.2.2.11" class="ltx_tr">
<td id="S4.SS1.8.2.2.11.1" class="ltx_td ltx_align_left ltx_border_r">Kinematic3D + <span id="S4.SS1.8.2.2.11.1.1" class="ltx_text ltx_font_bold">Ours</span>
</td>
<td id="S4.SS1.8.2.2.11.2" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.11.2.1" class="ltx_text ltx_font_bold">21.59</span></td>
<td id="S4.SS1.8.2.2.11.3" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.11.3.1" class="ltx_text ltx_font_bold">16.54</span></td>
<td id="S4.SS1.8.2.2.11.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.SS1.8.2.2.11.4.1" class="ltx_text ltx_font_bold">12.77</span></td>
<td id="S4.SS1.8.2.2.11.5" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.11.5.1" class="ltx_text ltx_font_bold">29.80</span></td>
<td id="S4.SS1.8.2.2.11.6" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.11.6.1" class="ltx_text ltx_font_bold">22.80</span></td>
<td id="S4.SS1.8.2.2.11.7" class="ltx_td ltx_align_center"><span id="S4.SS1.8.2.2.11.7.1" class="ltx_text ltx_font_bold">17.96</span></td>
</tr>
<tr id="S4.SS1.8.2.2.12" class="ltx_tr">
<td id="S4.SS1.8.2.2.12.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.SS1.8.2.2.12.1.1" class="ltx_text ltx_font_italic">Imp.</span></td>
<td id="S4.SS1.8.2.2.12.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.8.2.2.12.2.1" class="ltx_text" style="color:#0000FF;">+1.83</span></td>
<td id="S4.SS1.8.2.2.12.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.8.2.2.12.3.1" class="ltx_text" style="color:#0000FF;">+2.44</span></td>
<td id="S4.SS1.8.2.2.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.SS1.8.2.2.12.4.1" class="ltx_text" style="color:#0000FF;">+2.30</span></td>
<td id="S4.SS1.8.2.2.12.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.8.2.2.12.5.1" class="ltx_text" style="color:#0000FF;">+1.97</span></td>
<td id="S4.SS1.8.2.2.12.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.8.2.2.12.6.1" class="ltx_text" style="color:#0000FF;">+3.08</span></td>
<td id="S4.SS1.8.2.2.12.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS1.8.2.2.12.7.1" class="ltx_text" style="color:#0000FF;">+2.86</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 4: </span>Extension of MoGDE to existing image-only monocular 3D object detectors. We show the <math id="S4.SS1.10.4.m1.1" class="ltx_Math" alttext="AP_{40}" display="inline"><semantics id="S4.SS1.10.4.m1.1b"><mrow id="S4.SS1.10.4.m1.1.1" xref="S4.SS1.10.4.m1.1.1.cmml"><mi id="S4.SS1.10.4.m1.1.1.2" xref="S4.SS1.10.4.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.10.4.m1.1.1.1" xref="S4.SS1.10.4.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.10.4.m1.1.1.3" xref="S4.SS1.10.4.m1.1.1.3.cmml"><mi id="S4.SS1.10.4.m1.1.1.3.2" xref="S4.SS1.10.4.m1.1.1.3.2.cmml">P</mi><mn id="S4.SS1.10.4.m1.1.1.3.3" xref="S4.SS1.10.4.m1.1.1.3.3.cmml">40</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.10.4.m1.1c"><apply id="S4.SS1.10.4.m1.1.1.cmml" xref="S4.SS1.10.4.m1.1.1"><times id="S4.SS1.10.4.m1.1.1.1.cmml" xref="S4.SS1.10.4.m1.1.1.1"></times><ci id="S4.SS1.10.4.m1.1.1.2.cmml" xref="S4.SS1.10.4.m1.1.1.2">𝐴</ci><apply id="S4.SS1.10.4.m1.1.1.3.cmml" xref="S4.SS1.10.4.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.10.4.m1.1.1.3.1.cmml" xref="S4.SS1.10.4.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.10.4.m1.1.1.3.2.cmml" xref="S4.SS1.10.4.m1.1.1.3.2">𝑃</ci><cn type="integer" id="S4.SS1.10.4.m1.1.1.3.3.cmml" xref="S4.SS1.10.4.m1.1.1.3.3">40</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.10.4.m1.1d">AP_{40}</annotation></semantics></math> scores(%) evaluated on KITTI3D <span id="S4.SS1.10.7.1" class="ltx_text ltx_font_italic">val</span> set.
<span id="S4.SS1.10.8.2" class="ltx_text ltx_font_bold">+Ours</span> indicates that we apply the GDE and GDF modules to the original methods. All models benefit from the MoGDE design.
</figcaption>
</figure>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">In contrast, (e <math id="S4.SS1.p6.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS1.p6.1.m1.1a"><mo stretchy="false" id="S4.SS1.p6.1.m1.1.1" xref="S4.SS1.p6.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p6.1.m1.1b"><ci id="S4.SS1.p6.1.m1.1.1.cmml" xref="S4.SS1.p6.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p6.1.m1.1c">\rightarrow</annotation></semantics></math> f) indicates the effectiveness of the transformer, which helps the model to understand the long-range attention relationship between pixel points and the ground plane.</p>
</div>
<div id="S4.SS1.p7" class="ltx_para">
<p id="S4.SS1.p7.1" class="ltx_p"><span id="S4.SS1.p7.1.1" class="ltx_text ltx_font_bold">Visualization of attention.</span>
To facilitate the understanding of our <span id="S4.SS1.p7.1.2" class="ltx_text ltx_font_italic">ground-aware</span> transformer, we visualize the depth self-attention map in the encoder and paint the query points red and mask region yellow in the third row of Figure <a href="#S4.F5" title="Figure 5 ‣ 4.1 Quantitative and Qualitative Results ‣ 4 Performance Evaluation ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
As shown in the figure, it can be seen that, within the relevant region of each query, areas that are interfacing the object and the ground have the highest attention scores. In contrast, for non-ground pixels of the object, the lower attention values indicate that the query is not relevant to them, even if they have similar image features and are geographically adjacent.
This implies that under the transformer’s attention mechanism guidance, the query is able to borrow depth information from regions of interest (<span id="S4.SS1.p7.1.3" class="ltx_text ltx_font_italic">i.e.</span>, the ground plane), which helps the fused feature map produce more accurate prediction results.</p>
</div>
<div id="S4.SS1.p8" class="ltx_para">
<p id="S4.SS1.p8.1" class="ltx_p"><span id="S4.SS1.p8.1.1" class="ltx_text ltx_font_bold">Simulation experiments on robustness.</span>
In order to verify the robustness of our proposed MoGDE against camera pose variance, we set three cases of variances (tiny, medium, and large) to compare the accuracy degradation of MoGDE with that of the baseline.
In Table <a href="#S4.SS1" title="4.1 Quantitative and Qualitative Results ‣ 4 Performance Evaluation ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, it can be noticed that the baseline is quite sensitive to pose variance, with very severe performance degradation, while our model only has a slight performance drop. Moreover, our model performs more robustly especially in the hard case, gaining higher performance improvement.
This demonstrates the effectiveness of our proposed pose-specific ground depth in handling camera pose variance for mobile scenes.</p>
</div>
<div id="S4.SS1.p9" class="ltx_para">
<p id="S4.SS1.p9.2" class="ltx_p"><span id="S4.SS1.p9.2.1" class="ltx_text ltx_font_bold">Plugging into existing methods.</span>
Our proposed approach is flexible to extend to existing image-only Mono3D detectors.
We respectively plug the Ground Depth Estimation and the Ground Depth Fusion components to three popular Mono3D detectors, which is shown in Table <a href="#S4.SS1" title="4.1 Quantitative and Qualitative Results ‣ 4 Performance Evaluation ‣ MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
It can be seen that, with the aid of our proposed ground depth fusion, these detectors can achieve further improvements on KITTI3D <span id="S4.SS1.p9.2.2" class="ltx_text ltx_font_italic">val</span> set, demonstrating the effectiveness and flexibility of our approach. Particularly, MoGDE-enabled models tend to achieve more performance gains on the hard category. For example, for Kinematic3D, the <math id="S4.SS1.p9.1.m1.1" class="ltx_Math" alttext="AP_{3D}" display="inline"><semantics id="S4.SS1.p9.1.m1.1a"><mrow id="S4.SS1.p9.1.m1.1.1" xref="S4.SS1.p9.1.m1.1.1.cmml"><mi id="S4.SS1.p9.1.m1.1.1.2" xref="S4.SS1.p9.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p9.1.m1.1.1.1" xref="S4.SS1.p9.1.m1.1.1.1.cmml">​</mo><msub id="S4.SS1.p9.1.m1.1.1.3" xref="S4.SS1.p9.1.m1.1.1.3.cmml"><mi id="S4.SS1.p9.1.m1.1.1.3.2" xref="S4.SS1.p9.1.m1.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.p9.1.m1.1.1.3.3" xref="S4.SS1.p9.1.m1.1.1.3.3.cmml"><mn id="S4.SS1.p9.1.m1.1.1.3.3.2" xref="S4.SS1.p9.1.m1.1.1.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p9.1.m1.1.1.3.3.1" xref="S4.SS1.p9.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.p9.1.m1.1.1.3.3.3" xref="S4.SS1.p9.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.1.m1.1b"><apply id="S4.SS1.p9.1.m1.1.1.cmml" xref="S4.SS1.p9.1.m1.1.1"><times id="S4.SS1.p9.1.m1.1.1.1.cmml" xref="S4.SS1.p9.1.m1.1.1.1"></times><ci id="S4.SS1.p9.1.m1.1.1.2.cmml" xref="S4.SS1.p9.1.m1.1.1.2">𝐴</ci><apply id="S4.SS1.p9.1.m1.1.1.3.cmml" xref="S4.SS1.p9.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p9.1.m1.1.1.3.1.cmml" xref="S4.SS1.p9.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.p9.1.m1.1.1.3.2.cmml" xref="S4.SS1.p9.1.m1.1.1.3.2">𝑃</ci><apply id="S4.SS1.p9.1.m1.1.1.3.3.cmml" xref="S4.SS1.p9.1.m1.1.1.3.3"><times id="S4.SS1.p9.1.m1.1.1.3.3.1.cmml" xref="S4.SS1.p9.1.m1.1.1.3.3.1"></times><cn type="integer" id="S4.SS1.p9.1.m1.1.1.3.3.2.cmml" xref="S4.SS1.p9.1.m1.1.1.3.3.2">3</cn><ci id="S4.SS1.p9.1.m1.1.1.3.3.3.cmml" xref="S4.SS1.p9.1.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.1.m1.1c">AP_{3D}</annotation></semantics></math>/<math id="S4.SS1.p9.2.m2.1" class="ltx_Math" alttext="AP_{BEV}" display="inline"><semantics id="S4.SS1.p9.2.m2.1a"><mrow id="S4.SS1.p9.2.m2.1.1" xref="S4.SS1.p9.2.m2.1.1.cmml"><mi id="S4.SS1.p9.2.m2.1.1.2" xref="S4.SS1.p9.2.m2.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p9.2.m2.1.1.1" xref="S4.SS1.p9.2.m2.1.1.1.cmml">​</mo><msub id="S4.SS1.p9.2.m2.1.1.3" xref="S4.SS1.p9.2.m2.1.1.3.cmml"><mi id="S4.SS1.p9.2.m2.1.1.3.2" xref="S4.SS1.p9.2.m2.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.p9.2.m2.1.1.3.3" xref="S4.SS1.p9.2.m2.1.1.3.3.cmml"><mi id="S4.SS1.p9.2.m2.1.1.3.3.2" xref="S4.SS1.p9.2.m2.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p9.2.m2.1.1.3.3.1" xref="S4.SS1.p9.2.m2.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.p9.2.m2.1.1.3.3.3" xref="S4.SS1.p9.2.m2.1.1.3.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p9.2.m2.1.1.3.3.1a" xref="S4.SS1.p9.2.m2.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.p9.2.m2.1.1.3.3.4" xref="S4.SS1.p9.2.m2.1.1.3.3.4.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.2.m2.1b"><apply id="S4.SS1.p9.2.m2.1.1.cmml" xref="S4.SS1.p9.2.m2.1.1"><times id="S4.SS1.p9.2.m2.1.1.1.cmml" xref="S4.SS1.p9.2.m2.1.1.1"></times><ci id="S4.SS1.p9.2.m2.1.1.2.cmml" xref="S4.SS1.p9.2.m2.1.1.2">𝐴</ci><apply id="S4.SS1.p9.2.m2.1.1.3.cmml" xref="S4.SS1.p9.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p9.2.m2.1.1.3.1.cmml" xref="S4.SS1.p9.2.m2.1.1.3">subscript</csymbol><ci id="S4.SS1.p9.2.m2.1.1.3.2.cmml" xref="S4.SS1.p9.2.m2.1.1.3.2">𝑃</ci><apply id="S4.SS1.p9.2.m2.1.1.3.3.cmml" xref="S4.SS1.p9.2.m2.1.1.3.3"><times id="S4.SS1.p9.2.m2.1.1.3.3.1.cmml" xref="S4.SS1.p9.2.m2.1.1.3.3.1"></times><ci id="S4.SS1.p9.2.m2.1.1.3.3.2.cmml" xref="S4.SS1.p9.2.m2.1.1.3.3.2">𝐵</ci><ci id="S4.SS1.p9.2.m2.1.1.3.3.3.cmml" xref="S4.SS1.p9.2.m2.1.1.3.3.3">𝐸</ci><ci id="S4.SS1.p9.2.m2.1.1.3.3.4.cmml" xref="S4.SS1.p9.2.m2.1.1.3.3.4">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.2.m2.1c">AP_{BEV}</annotation></semantics></math> gain is +1.83/+1.97 on the easy category and +2.30/+2.86 on the hard category.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we have proposed a Mono3D framework, called <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">MoGDE</em>, which can effectively utilize the estimated ground depth as prior knowledge to improve Mono3D in mobile settings. The advantages of MoGDE are two-fold: 1) it can significantly improve the Mono3D accuracy, especially for far objects, which is an open issue for Mono3D; 2) it can improve the robustness of Mono3D detectors when applied in more appealing mobile applications. Nevertheless, MoGDE still has two main limitations as follows: 1) it heavily relies on pose detection, which directly affects the accuracy of the ground depth estimation; 2) it also counts on the detection of ground-contacting points. In cases when such points are uncertain or ambiguous due to occlusion and truncation, it is hard for the proposed ground-aware feature fusion method to obtain accurate results. These limitations also direct our future work. We have implemented Mono3D and conducted extensive experiments on the real-world KITTI dataset. MoGDE yields the best performance compared with the state-of-the-art methods by a large margin and is ranked number one on the KITTI 3D benchmark.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This research was supported in part by National Key RD Program of China (Grants No. 2018YFC1900700), National Natural Science Foundation of China (Grants No. 61872240 and 61972081), and the Natural Science Foundation of Shanghai (Grant No. 22ZR1400200).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.2.2.1" class="ltx_text" style="font-size:90%;">[1]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.4.1" class="ltx_text" style="font-size:90%;">
Ivan Barabanau, Alexey Artemov, Evgeny Burnaev, and Vyacheslav Murashkin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.5.1" class="ltx_text" style="font-size:90%;">Monocular 3D Object Detection via Geometric Reasoning on
Keypoints.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv:1905.05618 [cs]</span><span id="bib.bib1.7.2" class="ltx_text" style="font-size:90%;">, May 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.8.1" class="ltx_text" style="font-size:90%;">arXiv: 1905.05618.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.2.2.1" class="ltx_text" style="font-size:90%;">[2]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.4.1" class="ltx_text" style="font-size:90%;">
Aljaz Bozic, Pablo Palafox, Justus Thies, Angela Dai, and Matthias Nießner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.5.1" class="ltx_text" style="font-size:90%;">TransformerFusion: Monocular RGB Scene Reconstruction using
Transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib2.7.2" class="ltx_text" style="font-size:90%;">, 34, 2021.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.2.2.1" class="ltx_text" style="font-size:90%;">[3]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.4.1" class="ltx_text" style="font-size:90%;">
Garrick Brazil and Xiaoming Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.5.1" class="ltx_text" style="font-size:90%;">M3D-RPN: Monocular 3D Region Proposal Network for Object Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib3.8.3" class="ltx_text" style="font-size:90%;">,
October 2019.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.2.2.1" class="ltx_text" style="font-size:90%;">[4]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.4.1" class="ltx_text" style="font-size:90%;">
Garrick Brazil, Gerard Pons-Moll, Xiaoming Liu, and Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.5.1" class="ltx_text" style="font-size:90%;">Kinematic 3D Object Detection in Monocular Video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2007.09548</span><span id="bib.bib4.7.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.2.2.1" class="ltx_text" style="font-size:90%;">[5]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.4.1" class="ltx_text" style="font-size:90%;">
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
Kirillov, and Sergey Zagoruyko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.5.1" class="ltx_text" style="font-size:90%;">End-to-End Object Detection with Transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European conference on computer vision</span><span id="bib.bib5.8.3" class="ltx_text" style="font-size:90%;">, pages 213–229.
Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.2.2.1" class="ltx_text" style="font-size:90%;">[6]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.4.1" class="ltx_text" style="font-size:90%;">
Florian Chabot, Mohamed Chaouch, Jaonary Rabarisoa, Céline Teulière,
and Thierry Chateau.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.5.1" class="ltx_text" style="font-size:90%;">Deep MANTA: A Coarse-to-Fine Many-Task Network for Joint 2D and 3D
Vehicle Analysis from Monocular Image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib6.8.3" class="ltx_text" style="font-size:90%;">, pages 2040–2049, 2017.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.2.2.1" class="ltx_text" style="font-size:90%;">[7]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.4.1" class="ltx_text" style="font-size:90%;">
Chin-Kai Chang, Jiaping Zhao, and Laurent Itti.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.5.1" class="ltx_text" style="font-size:90%;">DeepVP: Deep Learning for Vanishing Point Detection on 1 Million
Street View Images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE International Conference on Robotics and Automation
(ICRA)</span><span id="bib.bib7.8.3" class="ltx_text" style="font-size:90%;">, pages 1–8. IEEE, 2018.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.2.2.1" class="ltx_text" style="font-size:90%;">[8]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.4.1" class="ltx_text" style="font-size:90%;">
Hansheng Chen, Yuyao Huang, Wei Tian, Zhong Gao, and Lu Xiong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.5.1" class="ltx_text" style="font-size:90%;">MonoRUn: Monocular 3D Object Detection by Reconstruction and
Uncertainty Propagation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib8.8.3" class="ltx_text" style="font-size:90%;">, pages 10379–10388, 2021.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.2.2.1" class="ltx_text" style="font-size:90%;">[9]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.4.1" class="ltx_text" style="font-size:90%;">
Xiaozhi Chen, Kaustav Kundu, Ziyu Zhang, Huimin Ma, Sanja Fidler, and Raquel
Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.5.1" class="ltx_text" style="font-size:90%;">Monocular 3D Object Detection for Autonomous Driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib9.8.3" class="ltx_text" style="font-size:90%;">, pages 2147–2156, Las Vegas, NV, USA, June 2016.
IEEE.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.2.2.1" class="ltx_text" style="font-size:90%;">[10]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.4.1" class="ltx_text" style="font-size:90%;">
Xiaozhi Chen, Kaustav Kundu, Yukun Zhu, Andrew G Berneshawi, Huimin Ma, Sanja
Fidler, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.5.1" class="ltx_text" style="font-size:90%;">3D Object Proposals for Accurate Object Class Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib10.8.3" class="ltx_text" style="font-size:90%;">, pages
424–432, 2015.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.2.2.1" class="ltx_text" style="font-size:90%;">[11]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.4.1" class="ltx_text" style="font-size:90%;">
Xiaozhi Chen, Kaustav Kundu, Yukun Zhu, Huimin Ma, Sanja Fidler, and Raquel
Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.5.1" class="ltx_text" style="font-size:90%;">3D Object Proposals Using Stereo Imagery for Accurate
Object Class Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib11.7.2" class="ltx_text" style="font-size:90%;">,
40(5):1259–1272, May 2018.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.2.2.1" class="ltx_text" style="font-size:90%;">[12]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.4.1" class="ltx_text" style="font-size:90%;">
Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.5.1" class="ltx_text" style="font-size:90%;">Multi-View 3D Object Detection Network for Autonomous Driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib12.8.3" class="ltx_text" style="font-size:90%;">, pages 1907–1915, 2017.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.2.2.1" class="ltx_text" style="font-size:90%;">[13]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.4.1" class="ltx_text" style="font-size:90%;">
Yongjian Chen, Lei Tai, Kai Sun, and Mingyang Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.5.1" class="ltx_text" style="font-size:90%;">MonoPair: Monocular 3D Object Detection Using Pairwise Spatial
Relationships.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib13.8.3" class="ltx_text" style="font-size:90%;">, pages 12093–12102, 2020.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.2.2.1" class="ltx_text" style="font-size:90%;">[14]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.4.1" class="ltx_text" style="font-size:90%;">
Zeyu Cheng, Yi Zhang, and Chengkai Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.5.1" class="ltx_text" style="font-size:90%;">Swin-Depth: Using Transformers and Multi-Scale Fusion for
Monocular-Based Depth Estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Sensors Journal</span><span id="bib.bib14.7.2" class="ltx_text" style="font-size:90%;">, 21(23):26912–26920, 2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.2.2.1" class="ltx_text" style="font-size:90%;">[15]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.4.1" class="ltx_text" style="font-size:90%;">
Tom van Dijk and Guido de Croon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.5.1" class="ltx_text" style="font-size:90%;">How Do Neural Networks See Depth in Single Images?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib15.8.3" class="ltx_text" style="font-size:90%;">, pages 2183–2191, 2019.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.2.2.1" class="ltx_text" style="font-size:90%;">[16]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.4.1" class="ltx_text" style="font-size:90%;">
Mingyu Ding, Yuqi Huo, Hongwei Yi, Zhe Wang, Jianping Shi, Zhiwu Lu, and Ping
Luo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.5.1" class="ltx_text" style="font-size:90%;">Learning Depth-Guided Convolutions for Monocular 3D Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition Workshops</span><span id="bib.bib16.8.3" class="ltx_text" style="font-size:90%;">, pages 1000–1001, 2020.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.2.2.1" class="ltx_text" style="font-size:90%;">[17]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.4.1" class="ltx_text" style="font-size:90%;">
Andreas Geiger, Philip Lenz, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.5.1" class="ltx_text" style="font-size:90%;">Are We Ready for Autonomous Driving? The KITTI Vision Benchmark
Suite.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib17.8.3" class="ltx_text" style="font-size:90%;">, 2012.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.2.2.1" class="ltx_text" style="font-size:90%;">[18]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.4.1" class="ltx_text" style="font-size:90%;">
Tong He and Stefano Soatto.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.5.1" class="ltx_text" style="font-size:90%;">Mono3D++: Monocular 3D Vehicle Detection with Two-Scale 3D
Hypotheses and Task Priors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial
Intelligence</span><span id="bib.bib18.8.3" class="ltx_text" style="font-size:90%;">, volume 33, pages 8409–8416, 2019.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.2.2.1" class="ltx_text" style="font-size:90%;">[19]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.4.1" class="ltx_text" style="font-size:90%;">
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.5.1" class="ltx_text" style="font-size:90%;">ImageNet Classification with Deep Convolutional Neural Networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Communications of the ACM</span><span id="bib.bib19.7.2" class="ltx_text" style="font-size:90%;">, 60(6):84–90, 2017.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.2.2.1" class="ltx_text" style="font-size:90%;">[20]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.4.1" class="ltx_text" style="font-size:90%;">
Abhijit Kundu, Yin Li, and James M Rehg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.5.1" class="ltx_text" style="font-size:90%;">3D-RCNN: Instance-Level 3D Object Reconstruction via
Render-and-Compare.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib20.8.3" class="ltx_text" style="font-size:90%;">, pages 3559–3568, 2018.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.2.2.1" class="ltx_text" style="font-size:90%;">[21]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.4.1" class="ltx_text" style="font-size:90%;">
Peiliang Li, Xiaozhi Chen, and Shaojie Shen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.5.1" class="ltx_text" style="font-size:90%;">Stereo R-CNN Based 3D Object Detection for Autonomous Driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib21.8.3" class="ltx_text" style="font-size:90%;">, pages 7644–7652, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.2.2.1" class="ltx_text" style="font-size:90%;">[22]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.4.1" class="ltx_text" style="font-size:90%;">
Peixuan Li, Huaici Zhao, Pengfei Liu, and Feidao Cao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.5.1" class="ltx_text" style="font-size:90%;">RTM3D: Real-time Monocular 3D Detection from Object Keypoints for
Autonomous Driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib22.8.3" class="ltx_text" style="font-size:90%;">, pages 644–660.
Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.2.2.1" class="ltx_text" style="font-size:90%;">[23]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.4.1" class="ltx_text" style="font-size:90%;">
Ming Liang, Bin Yang, Shenlong Wang, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.5.1" class="ltx_text" style="font-size:90%;">Deep Continuous Fusion for Multi-sensor 3D Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.6.1" class="ltx_text" style="font-size:90%;">In Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair
Weiss, editors, </span><span id="bib.bib23.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision – ECCV 2018</span><span id="bib.bib23.8.3" class="ltx_text" style="font-size:90%;">, Lecture Notes in
Computer Science, pages 663–678. Springer International Publishing,
2018.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.2.2.1" class="ltx_text" style="font-size:90%;">[24]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.4.1" class="ltx_text" style="font-size:90%;">
Lijie Liu, Jiwen Lu, Chunjing Xu, Qi Tian, and Jie Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.5.1" class="ltx_text" style="font-size:90%;">Deep Fitting Degree Scoring Network for Monocular 3D Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib24.8.3" class="ltx_text" style="font-size:90%;">, pages 1057–1066, 2019.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.2.2.1" class="ltx_text" style="font-size:90%;">[25]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.4.1" class="ltx_text" style="font-size:90%;">
Zechen Liu, Zizhang Wu, and Roland Tóth.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.5.1" class="ltx_text" style="font-size:90%;">SMOKE: Single-Stage Monocular 3D Object Detection via Keypoint
Estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition Workshops</span><span id="bib.bib25.8.3" class="ltx_text" style="font-size:90%;">, pages 996–997, 2020.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.2.2.1" class="ltx_text" style="font-size:90%;">[26]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.4.1" class="ltx_text" style="font-size:90%;">
Zongdai Liu, Dingfu Zhou, Feixiang Lu, Jin Fang, and Liangjun Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.5.1" class="ltx_text" style="font-size:90%;">AutoShape: Real-Time Shape-Aware Monocular 3D Object Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib26.8.3" class="ltx_text" style="font-size:90%;">, pages 15641–15650, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.2.2.1" class="ltx_text" style="font-size:90%;">[27]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.4.1" class="ltx_text" style="font-size:90%;">
Yan Lu, Xinzhu Ma, Lei Yang, Tianzhu Zhang, Yating Liu, Qi Chu, Junjie Yan, and
Wanli Ouyang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.5.1" class="ltx_text" style="font-size:90%;">Geometry Uncertainty Projection Network for Monocular 3D Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib27.8.3" class="ltx_text" style="font-size:90%;">, pages 3111–3121, 2021.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.2.2.1" class="ltx_text" style="font-size:90%;">[28]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.4.1" class="ltx_text" style="font-size:90%;">
Xinzhu Ma, Shinan Liu, Zhiyi Xia, Hongwen Zhang, Xingyu Zeng, and Wanli Ouyang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.5.1" class="ltx_text" style="font-size:90%;">Rethinking Pseudo-Lidar Representation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2008.04582</span><span id="bib.bib28.7.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.2.2.1" class="ltx_text" style="font-size:90%;">[29]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.4.1" class="ltx_text" style="font-size:90%;">
Xinzhu Ma, Zhihui Wang, Haojie Li, Pengbo Zhang, Wanli Ouyang, and Xin Fan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.5.1" class="ltx_text" style="font-size:90%;">Accurate Monocular 3D Object Detection via Color-Embedded 3D
Reconstruction for Autonomous Driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib29.8.3" class="ltx_text" style="font-size:90%;">,
October 2019.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.2.2.1" class="ltx_text" style="font-size:90%;">[30]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.4.1" class="ltx_text" style="font-size:90%;">
Fabian Manhardt, Wadim Kehl, and Adrien Gaidon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.5.1" class="ltx_text" style="font-size:90%;">ROI-10D: Monocular Lifting of 2D Detection to 6D Pose and Metric
Shape.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib30.8.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.2.2.1" class="ltx_text" style="font-size:90%;">[31]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.4.1" class="ltx_text" style="font-size:90%;">
Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei
Sun, and Jingdong Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.5.1" class="ltx_text" style="font-size:90%;">Conditional DETR for Fast Training Convergence.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib31.8.3" class="ltx_text" style="font-size:90%;">, pages 3651–3660, 2021.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.2.2.1" class="ltx_text" style="font-size:90%;">[32]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.4.1" class="ltx_text" style="font-size:90%;">
Ishan Misra, Rohit Girdhar, and Armand Joulin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.5.1" class="ltx_text" style="font-size:90%;">An End-to-End Transformer Model for 3D Object Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib32.8.3" class="ltx_text" style="font-size:90%;">, pages 2906–2917, 2021.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.2.2.1" class="ltx_text" style="font-size:90%;">[33]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.4.1" class="ltx_text" style="font-size:90%;">
Arsalan Mousavian, Dragomir Anguelov, John Flynn, and Jana Kosecka.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.5.1" class="ltx_text" style="font-size:90%;">3D Bounding Box Estimation Using Deep Learning and Geometry.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib33.8.3" class="ltx_text" style="font-size:90%;">, pages 7074–7082, 2017.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.2.2.1" class="ltx_text" style="font-size:90%;">[34]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.4.1" class="ltx_text" style="font-size:90%;">
J Krishna Murthy, GV Sai Krishna, Falak Chhaya, and K Madhava Krishna.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.5.1" class="ltx_text" style="font-size:90%;">Reconstructing Vehicles from a Single Image: Shape Priors for Road
Scene Understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE International Conference on Robotics and Automation
(ICRA)</span><span id="bib.bib34.8.3" class="ltx_text" style="font-size:90%;">, pages 724–731. IEEE, 2017.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.2.2.1" class="ltx_text" style="font-size:90%;">[35]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.4.1" class="ltx_text" style="font-size:90%;">
Cuong Cao Pham and Jae Wook Jeon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.5.1" class="ltx_text" style="font-size:90%;">Robust Object Proposals Re-ranking for Object Detection in
Autonomous Driving using Convolutional Neural Networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Signal Processing: Image Communication</span><span id="bib.bib35.7.2" class="ltx_text" style="font-size:90%;">, 53:110–122, Apr. 2017.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.2.2.1" class="ltx_text" style="font-size:90%;">[36]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.4.1" class="ltx_text" style="font-size:90%;">
Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, and Leonidas J Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.5.1" class="ltx_text" style="font-size:90%;">Frustum Pointnets for 3D Object Detection from RGB-D Data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib36.8.3" class="ltx_text" style="font-size:90%;">, pages 918–927, 2018.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.2.2.1" class="ltx_text" style="font-size:90%;">[37]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.4.1" class="ltx_text" style="font-size:90%;">
Zengyi Qin, Jinglu Wang, and Yan Lu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.5.1" class="ltx_text" style="font-size:90%;">MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object
Localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial
Intelligence</span><span id="bib.bib37.8.3" class="ltx_text" style="font-size:90%;">, volume 33, pages 8851–8858, 2019.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.2.2.1" class="ltx_text" style="font-size:90%;">[38]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.4.1" class="ltx_text" style="font-size:90%;">
Zengyi Qin, Jinglu Wang, and Yan Lu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.5.1" class="ltx_text" style="font-size:90%;">Triangulation Learning Network: From Monocular to Stereo 3D Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib38.8.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.2.2.1" class="ltx_text" style="font-size:90%;">[39]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.4.1" class="ltx_text" style="font-size:90%;">
Cody Reading, Ali Harakeh, Julia Chae, and Steven L Waslander.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.5.1" class="ltx_text" style="font-size:90%;">Categorical Depth Distribution Network for Monocular 3D Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib39.8.3" class="ltx_text" style="font-size:90%;">, pages 8555–8564, 2021.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.2.2.1" class="ltx_text" style="font-size:90%;">[40]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.4.1" class="ltx_text" style="font-size:90%;">
Joseph Redmon and Ali Farhadi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.5.1" class="ltx_text" style="font-size:90%;">Yolov3: An Incremental Improvement.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1804.02767</span><span id="bib.bib40.7.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.2.2.1" class="ltx_text" style="font-size:90%;">[41]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.4.1" class="ltx_text" style="font-size:90%;">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.5.1" class="ltx_text" style="font-size:90%;">Faster R-CNN: Towards Real-Time Object Detection with Region
Proposal Networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib41.7.2" class="ltx_text" style="font-size:90%;">, 28, 2015.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.2.2.1" class="ltx_text" style="font-size:90%;">[42]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.4.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.5.1" class="ltx_text" style="font-size:90%;">PointRCNN: 3D Object Proposal Generation and Detection from Point
Cloud.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib42.8.3" class="ltx_text" style="font-size:90%;">, pages 770–779, 2019.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.2.2.1" class="ltx_text" style="font-size:90%;">[43]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.4.1" class="ltx_text" style="font-size:90%;">
Kiwoo Shin, Youngwook Paul Kwon, and Masayoshi Tomizuka.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.5.1" class="ltx_text" style="font-size:90%;">RoarNet: A Robust 3D Object Detection Based on Region Approximation
Refinement.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE Intelligent Vehicles Symposium (IV)</span><span id="bib.bib43.8.3" class="ltx_text" style="font-size:90%;">, pages
2510–2515. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.2.2.1" class="ltx_text" style="font-size:90%;">[44]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.4.1" class="ltx_text" style="font-size:90%;">
Andrea Simonelli, Samuel Rota Bulo, Lorenzo Porzi, Manuel López-Antequera,
and Peter Kontschieder.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.5.1" class="ltx_text" style="font-size:90%;">Disentangling Monocular 3D Object Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib44.8.3" class="ltx_text" style="font-size:90%;">, pages 1991–1999, 2019.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.2.2.1" class="ltx_text" style="font-size:90%;">[45]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.4.1" class="ltx_text" style="font-size:90%;">
Zhi Tian, Chunhua Shen, Hao Chen, and Tong He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.5.1" class="ltx_text" style="font-size:90%;">FCOS: Fully Convolutional One-Stage Object Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on
computer vision</span><span id="bib.bib45.8.3" class="ltx_text" style="font-size:90%;">, pages 9627–9636, 2019.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.2.2.1" class="ltx_text" style="font-size:90%;">[46]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.4.1" class="ltx_text" style="font-size:90%;">
Arnav Varma, Hemang Chawla, Bahram Zonooz, and Elahe Arani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.5.1" class="ltx_text" style="font-size:90%;">Transformers in Self-Supervised Monocular Depth Estimation with
Unknown Camera Intrinsics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2202.03131</span><span id="bib.bib46.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.2.2.1" class="ltx_text" style="font-size:90%;">[47]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.4.1" class="ltx_text" style="font-size:90%;">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.5.1" class="ltx_text" style="font-size:90%;">Attention Is All You Need.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib47.7.2" class="ltx_text" style="font-size:90%;">, 30, 2017.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.2.2.1" class="ltx_text" style="font-size:90%;">[48]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.4.1" class="ltx_text" style="font-size:90%;">
Jean Marie Uwabeza Vianney, Shubhra Aich, and Bingbing Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.5.1" class="ltx_text" style="font-size:90%;">RefinedMPL: Refined Monocular PseudoLiDAR for 3D Object Detection in
Autonomous Driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1911.09712</span><span id="bib.bib48.7.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.2.2.1" class="ltx_text" style="font-size:90%;">[49]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.4.1" class="ltx_text" style="font-size:90%;">
Tai Wang, Xinge Zhu, Jiangmiao Pang, and Dahua Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.5.1" class="ltx_text" style="font-size:90%;">FCOS3D: Fully Convolutional One-Stage Monocular 3D Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib49.8.3" class="ltx_text" style="font-size:90%;">, pages 913–922, 2021.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.2.2.1" class="ltx_text" style="font-size:90%;">[50]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.4.1" class="ltx_text" style="font-size:90%;">
Yan Wang, Wei-Lun Chao, Divyansh Garg, Bharath Hariharan, Mark Campbell, and
Kilian Q Weinberger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.5.1" class="ltx_text" style="font-size:90%;">Pseudo-LiDAR From Visual Depth Estimation: Bridging the Gap in 3D
Object Detection for Autonomous Driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib50.8.3" class="ltx_text" style="font-size:90%;">, pages 8445–8453, 2019.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.2.2.1" class="ltx_text" style="font-size:90%;">[51]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.4.1" class="ltx_text" style="font-size:90%;">
Yingming Wang, Xiangyu Zhang, Tong Yang, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.5.1" class="ltx_text" style="font-size:90%;">Anchor DETR: Query Design for Transformer-Based Object Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2109.07107</span><span id="bib.bib51.7.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.2.2.1" class="ltx_text" style="font-size:90%;">[52]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.4.1" class="ltx_text" style="font-size:90%;">
Xinshuo Weng and Kris Kitani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.5.1" class="ltx_text" style="font-size:90%;">Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib52.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision Workshops</span><span id="bib.bib52.8.3" class="ltx_text" style="font-size:90%;">, pages 0–0, 2019.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.2.2.1" class="ltx_text" style="font-size:90%;">[53]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.4.1" class="ltx_text" style="font-size:90%;">
Yu Xiang, Wongun Choi, Yuanqing Lin, and Silvio Savarese.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.5.1" class="ltx_text" style="font-size:90%;">Subcategory-Aware Convolutional Neural Networks for Object
Proposals and Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv:1604.04693 [cs]</span><span id="bib.bib53.7.2" class="ltx_text" style="font-size:90%;">, Mar. 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.8.1" class="ltx_text" style="font-size:90%;">arXiv: 1604.04693.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.2.2.1" class="ltx_text" style="font-size:90%;">[54]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.4.1" class="ltx_text" style="font-size:90%;">
Bin Xu and Zhenzhong Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.5.1" class="ltx_text" style="font-size:90%;">Multi-level Fusion Based 3D Object Detection from
Monocular Images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib54.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib54.8.3" class="ltx_text" style="font-size:90%;">, pages 2345–2353, Salt Lake City, UT, USA, June
2018. IEEE.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.2.2.1" class="ltx_text" style="font-size:90%;">[55]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.4.1" class="ltx_text" style="font-size:90%;">
Guanglei Yang, Hao Tang, Mingli Ding, Nicu Sebe, and Elisa Ricci.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.5.1" class="ltx_text" style="font-size:90%;">Transformer-Based Attention Networks for Continuous Pixel-Wise
Prediction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib55.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib55.8.3" class="ltx_text" style="font-size:90%;">, pages 16269–16279, 2021.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.2.2.1" class="ltx_text" style="font-size:90%;">[56]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.4.1" class="ltx_text" style="font-size:90%;">
Guanglei Yang, Hao Tang, Mingli Ding, Nicu Sebe, and Elisa Ricci.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.5.1" class="ltx_text" style="font-size:90%;">Transformers Solve Limited Receptive Field for Monocular Depth
Prediction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv e-prints</span><span id="bib.bib56.7.2" class="ltx_text" style="font-size:90%;">, pages arXiv–2103, 2021.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.2.2.1" class="ltx_text" style="font-size:90%;">[57]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.4.1" class="ltx_text" style="font-size:90%;">
Zhuyu Yao, Jiangbo Ai, Boxun Li, and Chi Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.5.1" class="ltx_text" style="font-size:90%;">Efficient DETR: Improving End-to-End Object Detector with Dense
Prior.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.01318</span><span id="bib.bib57.7.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.2.2.1" class="ltx_text" style="font-size:90%;">[58]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.4.1" class="ltx_text" style="font-size:90%;">
Fisher Yu, Dequan Wang, Evan Shelhamer, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.5.1" class="ltx_text" style="font-size:90%;">Deep Layer Aggregation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib58.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib58.8.3" class="ltx_text" style="font-size:90%;">, pages 2403–2412, 2018.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.2.2.1" class="ltx_text" style="font-size:90%;">[59]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.4.1" class="ltx_text" style="font-size:90%;">
Renrui Zhang, Han Qiu, Tai Wang, Xuanzhuo Xu, Ziyu Guo, Yu Qiao, Peng Gao, and
Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.5.1" class="ltx_text" style="font-size:90%;">MonoDETR: Depth-Aware Transformer for Monocular 3D Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2203.13310</span><span id="bib.bib59.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.2.2.1" class="ltx_text" style="font-size:90%;">[60]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.4.1" class="ltx_text" style="font-size:90%;">
Yunpeng Zhang, Jiwen Lu, and Jie Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.5.1" class="ltx_text" style="font-size:90%;">Objects Are Different: Flexible Monocular 3D Object Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib60.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib60.8.3" class="ltx_text" style="font-size:90%;">, pages 3289–3298, 2021.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.2.2.1" class="ltx_text" style="font-size:90%;">[61]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.4.1" class="ltx_text" style="font-size:90%;">
Xingyi Zhou, Dequan Wang, and Philipp Krähenbühl.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.5.1" class="ltx_text" style="font-size:90%;">Objects As Points.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv:1904.07850 [cs]</span><span id="bib.bib61.7.2" class="ltx_text" style="font-size:90%;">, Apr. 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.8.1" class="ltx_text" style="font-size:90%;">arXiv: 1904.07850.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib62.2.2.1" class="ltx_text" style="font-size:90%;">[62]</span></span>
<span class="ltx_bibblock"><span id="bib.bib62.4.1" class="ltx_text" style="font-size:90%;">
Yunsong Zhou, Yuan He, Hongzi Zhu, Cheng Wang, Hongyang Li, and Qinhong Jiang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.5.1" class="ltx_text" style="font-size:90%;">Monocular 3D Object Detection: An Extrinsic Parameter Free
Approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib62.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib62.8.3" class="ltx_text" style="font-size:90%;">, pages 7556–7566, 2021.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib63.2.2.1" class="ltx_text" style="font-size:90%;">[63]</span></span>
<span class="ltx_bibblock"><span id="bib.bib63.4.1" class="ltx_text" style="font-size:90%;">
Yin Zhou and Oncel Tuzel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.5.1" class="ltx_text" style="font-size:90%;">VoxelNet: End-to-End Learning for Point Cloud Based 3D Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib63.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib63.8.3" class="ltx_text" style="font-size:90%;">, pages 4490–4499, 2018.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib64.2.2.1" class="ltx_text" style="font-size:90%;">[64]</span></span>
<span class="ltx_bibblock"><span id="bib.bib64.4.1" class="ltx_text" style="font-size:90%;">
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.5.1" class="ltx_text" style="font-size:90%;">Deformable DETR: Deformable Transformers for End-to-End Object
Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2010.04159</span><span id="bib.bib64.7.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
</ul>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Checklist</h2>

<div id="Sx2.p1" class="ltx_para">
<ol id="Sx2.I1" class="ltx_enumerate">
<li id="Sx2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="Sx2.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i1.p1.1" class="ltx_p">For all authors…</p>
<ol id="Sx2.I1.i1.I1" class="ltx_enumerate">
<li id="Sx2.I1.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx2.I1.i1.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i1.I1.i1.p1.1" class="ltx_p">Do the main claims made in the abstract and introduction accurately reflect the paper’s contributions and scope?
<span id="Sx2.I1.i1.I1.i1.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx2.I1.i1.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i1.I1.i2.p1.1" class="ltx_p">Did you describe the limitations of your work?
<span id="Sx2.I1.i1.I1.i2.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.i1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="Sx2.I1.i1.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i1.I1.i3.p1.1" class="ltx_p">Did you discuss any potential negative societal impacts of your work?
<span id="Sx2.I1.i1.I1.i3.p1.1.1" class="ltx_text" style="color:#808080;">[N/A] </span></p>
</div>
</li>
<li id="Sx2.I1.i1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(d)</span> 
<div id="Sx2.I1.i1.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.i1.I1.i4.p1.1" class="ltx_p">Have you read the ethics review guidelines and ensured that your paper conforms to them?
<span id="Sx2.I1.i1.I1.i4.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
</ol>
</div>
</li>
<li id="Sx2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="Sx2.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i2.p1.1" class="ltx_p">If you are including theoretical results…</p>
<ol id="Sx2.I1.i2.I1" class="ltx_enumerate">
<li id="Sx2.I1.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx2.I1.i2.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i2.I1.i1.p1.1" class="ltx_p">Did you state the full set of assumptions of all theoretical results?
<span id="Sx2.I1.i2.I1.i1.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx2.I1.i2.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i2.I1.i2.p1.1" class="ltx_p">Did you include complete proofs of all theoretical results?
<span id="Sx2.I1.i2.I1.i2.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
</ol>
</div>
</li>
<li id="Sx2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="Sx2.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i3.p1.1" class="ltx_p">If you ran experiments…</p>
<ol id="Sx2.I1.i3.I1" class="ltx_enumerate">
<li id="Sx2.I1.i3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx2.I1.i3.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i3.I1.i1.p1.1" class="ltx_p">Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)?
<span id="Sx2.I1.i3.I1.i1.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.i3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx2.I1.i3.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i3.I1.i2.p1.1" class="ltx_p">Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?
<span id="Sx2.I1.i3.I1.i2.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span>See appendix.</p>
</div>
</li>
<li id="Sx2.I1.i3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="Sx2.I1.i3.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i3.I1.i3.p1.1" class="ltx_p">Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?
<span id="Sx2.I1.i3.I1.i3.p1.1.1" class="ltx_text" style="color:#FF8000;">[No] </span></p>
</div>
</li>
<li id="Sx2.I1.i3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(d)</span> 
<div id="Sx2.I1.i3.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.i3.I1.i4.p1.1" class="ltx_p">Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?
<span id="Sx2.I1.i3.I1.i4.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span>See appendix.</p>
</div>
</li>
</ol>
</div>
</li>
<li id="Sx2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="Sx2.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.i4.p1.1" class="ltx_p">If you are using existing assets (e.g., code, data, models) or curating/releasing new assets…</p>
<ol id="Sx2.I1.i4.I1" class="ltx_enumerate">
<li id="Sx2.I1.i4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx2.I1.i4.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i4.I1.i1.p1.1" class="ltx_p">If your work uses existing assets, did you cite the creators?
<span id="Sx2.I1.i4.I1.i1.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.i4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx2.I1.i4.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i4.I1.i2.p1.1" class="ltx_p">Did you mention the license of the assets?
<span id="Sx2.I1.i4.I1.i2.p1.1.1" class="ltx_text" style="color:#FF8000;">[No] </span></p>
</div>
</li>
<li id="Sx2.I1.i4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="Sx2.I1.i4.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i4.I1.i3.p1.1" class="ltx_p">Did you include any new assets either in the supplemental material or as a URL?
<span id="Sx2.I1.i4.I1.i3.p1.1.1" class="ltx_text" style="color:#FF8000;">[No] </span></p>
</div>
</li>
<li id="Sx2.I1.i4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(d)</span> 
<div id="Sx2.I1.i4.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.i4.I1.i4.p1.1" class="ltx_p">Did you discuss whether and how consent was obtained from people whose data you’re using/curating?
<span id="Sx2.I1.i4.I1.i4.p1.1.1" class="ltx_text" style="color:#FF8000;">[No] </span></p>
</div>
</li>
<li id="Sx2.I1.i4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(e)</span> 
<div id="Sx2.I1.i4.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.i4.I1.i5.p1.1" class="ltx_p">Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content?
<span id="Sx2.I1.i4.I1.i5.p1.1.1" class="ltx_text" style="color:#FF8000;">[No] </span></p>
</div>
</li>
</ol>
</div>
</li>
<li id="Sx2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="Sx2.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.i5.p1.1" class="ltx_p">If you used crowdsourcing or conducted research with human subjects…</p>
<ol id="Sx2.I1.i5.I1" class="ltx_enumerate">
<li id="Sx2.I1.i5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx2.I1.i5.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i5.I1.i1.p1.1" class="ltx_p">Did you include the full text of instructions given to participants and screenshots, if applicable?
<span id="Sx2.I1.i5.I1.i1.p1.1.1" class="ltx_text" style="color:#808080;">[N/A] </span></p>
</div>
</li>
<li id="Sx2.I1.i5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx2.I1.i5.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i5.I1.i2.p1.1" class="ltx_p">Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable?
<span id="Sx2.I1.i5.I1.i2.p1.1.1" class="ltx_text" style="color:#808080;">[N/A] </span></p>
</div>
</li>
<li id="Sx2.I1.i5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="Sx2.I1.i5.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i5.I1.i3.p1.1" class="ltx_p">Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?
<span id="Sx2.I1.i5.I1.i3.p1.1.1" class="ltx_text" style="color:#808080;">[N/A] </span></p>
</div>
</li>
</ol>
</div>
</li>
</ol>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2303.13560" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2303.13561" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2303.13561">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.13561" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2303.13562" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 18:29:03 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
