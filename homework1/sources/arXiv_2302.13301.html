<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2302.13301] Pillar R-CNN for Point Cloud 3D Object Detection</title><meta property="og:description" content="The performance of point cloud 3D object detection hinges on effectively representing raw points, grid-based voxels or pillars.
Recent two-stage 3D detectors typically take the point-voxel-based R-CNN paradigm, i.e., t…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pillar R-CNN for Point Cloud 3D Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Pillar R-CNN for Point Cloud 3D Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2302.13301">

<!--Generated on Thu Feb 29 23:17:38 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Pillar R-CNN for Point Cloud 3D Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Guangsheng Shi
<br class="ltx_break">Harbin Institute of Technology
<br class="ltx_break"><span id="id3.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">sgsadvance@163.com</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ruifeng Li <math id="id1.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="id1.1.m1.1a"><mo id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><ci id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\star</annotation></semantics></math>
<br class="ltx_break">Harbin Institute of Technology
<br class="ltx_break"><span id="id4.2.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">lrf100@hit.edu.cn</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chao Ma <math id="id2.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="id2.1.m1.1a"><mo id="id2.1.m1.1.1" xref="id2.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="id2.1.m1.1b"><ci id="id2.1.m1.1.1.cmml" xref="id2.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="id2.1.m1.1c">\star</annotation></semantics></math>
<br class="ltx_break">Shanghai Jiao Tong University
<br class="ltx_break"><span id="id5.2.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">chaoma@sjtu.edu.cn</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">The performance of point cloud 3D object detection hinges on effectively representing raw points, grid-based voxels or pillars.
Recent two-stage 3D detectors typically take the point-voxel-based R-CNN paradigm, i.e., the first stage resorts to the 3D voxel-based backbone for 3D proposal generation on bird-eye-view (BEV) representation and the second stage refines them via the intermediate point representation.
Their primary mechanisms involve the utilization of intermediary keypoints to restore the substantial 3D structure context from the converted BEV representation.
The skilled point-voxel feature interaction, however, makes the entire detection pipeline more complex and compute-intensive.
In this paper, we take a different viewpoint – the pillar-based BEV representation owns sufficient capacity to preserve the 3D structure.
In light of the latest advances in BEV-based perception, we devise a conceptually simple yet effective two-stage 3D detection architecture, named Pillar R-CNN.
On top of densified BEV feature maps, Pillar R-CNN can easily introduce the feature pyramid architecture to generate 3D proposals at various scales and take the simple 2D R-CNN style detect head for box refinement.
Our Pillar R-CNN performs favorably against state-of-the-art 3D detectors on the large-scale Waymo Open Dataset but at a small extra cost.
It should be highlighted that further exploration into BEV perception for applications involving autonomous driving is now possible thanks to the effective and elegant Pillar R-CNN architecture.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Point cloud 3D object detection plays a crucial role in 3D scene understanding for robotics and autonomous driving.
However, compared with well-developed image-based 2D detection,
LiDAR-based 3D detection still struggles to cope with the sparse and irregular nature of point clouds.
In this paper, we propose Pillar R-CNN, a Faster R-CNN-like architecture on pillar-based point cloud representation that can profit from the advances of the 2D detection field.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The performance of LiDAR-based 3D detection hinges on representation learning on point clouds.
Deep convolutional feature backbones include the point-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> or grid-based (<span id="S1.p2.1.2" class="ltx_text ltx_font_italic">e.g.</span>, 3D voxel-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> and 2D pillar-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>) representations.
Current state-of-the-art approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> mainly apply one-stage detectors to produce class-specific proposals and require abstracted point-wise features to make further box refinement.
Typically, PV-RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> extends SECOND <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> by introducing the precisely positioned keypoints from raw points to preserve the significant 3D structure information. Voxel Set Abstraction (VSA) is introduced to enrich each keypoints with the multi-scale 3D voxel feature context.
Each 3D RoI feature is further extracted from keypoints through RoI-grid pooling for box refinement.
Despite the decent detection accuracy, the unordered storage of keypoints leads to costly computation overheads.
Voxel R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> argues that coarse 3D voxels can also offer sufficient detection accuracy. Voxel RoI Pooling extracts 3D RoI features from the 3D sparse feature volumes. The regularity of 3D voxels facilitates the search for nearby voxel features while its coarse granularity sacrifices the detection accuracy especially for small objects.
Besides, Part-<span id="S1.p2.1.1" class="ltx_text ltx_font_italic">A<sup id="S1.p2.1.1.1" class="ltx_sup"><span id="S1.p2.1.1.1.1" class="ltx_text ltx_font_upright">2</span></sup></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> takes the upsampled 3D voxel points as transitional keypoints to alleviate the issue of overly coarse voxel granularity.
Moreover, most recent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> propose the variants of the RoI-grid pooling module to handle the issues of sparsity and point density variation of intermediary keypoints.
In a nutshell, top-performing two-stage 3D detection frameworks heavily depend on the 3D voxel-based backbone for BEV-based 3D proposal generation, and then restore the 3D structure context to make further box refinement based on the point-level features.
Nevertheless, the point-voxel-based detection paradigm and its associated point-based set operations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> complicate the entire 3D detection pipeline and require extra efforts for boosting efficiency.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The latest progress on BEV-based perception <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> demonstrates the potential of BEV representation for high-performance 3D object detection.
Pillar, as a typical phenotype of BEV representation on point clouds, might supply sufficient 3D structure information and can easily integrate the advances of mature 2D detection fields.
In this work, towards this objective, we take solely on pillar-based point cloud representation and try to boost its accuracy.
We first argue that pillars with proper granularity can also offer the significant 3D structure for box refinement.
As such, we propose a surprisingly flexible and effective two-stage framework, named <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">Pillar R-CNN</span>, that integrates FPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> with region proposal network (RPN) for class-specific 3D proposal generation at various scales and then crop the 2D dense pooling feature maps for further box refinement at a single manageable scale.
Specifically, we use a pillar-based feature backbone with a hybrid of sparse and dense convolutions to compute hierarchical feature maps in one forward pass.
To counteract the degraded accuracy on small objects, we devise a lateral connection layer to build a pillar-based pyramidal backbone like FPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> by densifying sparse pillar volumes.
However, this is too difficult and complex to be utilized on the 3D voxel-based feature backbone <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.
<a href="#S5.T3" title="In 5.2 Ablation Studies ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a> shows that incorporating FPN into RPN produces better class-specific proposals for small objects, just like its 2D counterpart <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
Moreover, we follow the RoIAlign <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> to crop the dense pooling maps to refine 3D proposals. Here, the pooling maps are built by another lateral connection layer over the feature hierarchies with manageable resolution.
Besides, the single-scale pooling maps are class-agnostic and robust to object scale variation.
This slightly differs from the commonly used FPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> on Faster R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Despite refining 3D proposals on a <math id="S1.p4.1.m1.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S1.p4.1.m1.1a"><mrow id="S1.p4.1.m1.1b"><mn id="S1.p4.1.m1.1.1">4</mn><mo lspace="0.222em" id="S1.p4.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">4\times</annotation></semantics></math> downsampled 2D feature map (<span id="S1.p4.1.1" class="ltx_text ltx_font_italic">i.e.</span>, pillar size of 0.4m), as shown in <a href="#S5.T2" title="In Training and inference details. ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, the proposed Pillar R-CNN achieves comparable detection accuracy with previous state-of-the-art two-stage methods on the large-scale Waymo Open Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The main contribution of this work stems from the conceptually simple yet effective design of Pillar R-CNN, which demonstrates the powerful modeling capability of pillar-based BEV representation on point clouds.
The impressive experiment results of Pillar R-CNN also confirm our viewpoint: intermediate point-level representation in a two-stage approach is not crucial for high-performance 3D object detection and BEV representation with proper pillar granularity can also afford sufficient 3D structure for this task.
Without bells and whistles, Pillar R-CNN bridges the domain gap between LiDAR-based 3D detection and image-based 2D detection by means of pillar-based BEV representation.
Despite only demonstrating BEV representation with Pillar R-CNN on point clouds, we believe the findings presented are equally applicable to the BEV-based detectors.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Two-stage 2D image object detection.</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">Representative two-stage 2D object detection methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> take a conceptually simple yet effective paradigm.
The first stage, called the region proposal network (RPN), generates an axis-aligned Region of Interest (RoI) by sliding windows over all locations in a class-agnostic manner.
The second stage crops the RoI feature by RoIPool <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> or RoIAlign <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, and then conducts proposal-specific classification and bounding-box regression.
The feature pyramid network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, as a basic component recognition system, can build pyramidal multi-level feature maps that hold high-level semantic features at all scales.
Our proposed 3D detection method shares the same spirit of FPN and RoI pooling but utilizes domain-specific techniques to address the issues of sparse and irregular point clouds on 2D BEV space.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Single-stage point cloud 3D object detection.</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">Single-stage 3D detection methods can be mainly divided into three streams, <span id="S2.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">i.e.,</span> point-based, voxel-based and pillar-based.
Point-based single-stage detectors directly learn point-wise features from raw point clouds, where set abstraction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> enables flexible receptive fields by setting different search radii.
3DSSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> introduces F-FPS for point downsampling and first performs 3D detection only using an encoder network.
Point-based methods straightforwardly consume point clouds, however, insufficient learning capacity and unordered storage become the main bottleneck.
Voxel-based single-stage detectors usually first rasterize point clouds into 3D voxel grids to be processed by 3D dense <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> or sparse convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> for geometry feature learning.
Those voxel-based methods can offer superior detection performance while the computational/memory overheads grow cubically with the used voxelization resolution.
Pillar-based single-stage detectors further simplify 3D voxels to 2D pillars to be processed by 2D convolutions, paving the way for embedded deployments.
PointPillars <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> first encodes the input point clouds into regular pillars and utilizes a simple top-down network for final 3D object detection.
The latest PillarNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> deeply the huge performance gap of voxel- and pillar-based methods in terms of the architecture components and proposes the “encoder-neck-head” pipeline for a better accuracy/speed trade-off.
Moreover, we deeply dive into the pillar-based point cloud representation for better detection accuracy on PillarNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Two-stage point cloud 3D object detection.</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">Two-stage 3D detection methods typically build on top of single-stage methods for generating class-specific 3D proposals, but focus on the proposal-specific feature extraction for box refinement based on costly point set abstraction operation.
PointRCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> first applies PointNet++ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> as the feature backbone for bottom-up 3D proposal generation and proposes a novel point cloud region pooling for 3D box refinement.
Similarly, STD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> generates point-based proposals from raw point clouds, but proposes a new PointsPool layer to introduce volumetric representation for compact RoI feature extraction.
Fast Point R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> introduces the voxel-based backbone for producing high-quality 3D proposals and applies an attention-based PointNet pooling module for box refinement.
PV-RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> firstly integrates the point- and voxel-based feature learning schemes, where a small set of raw points as intermediate keypoints are enriched with multi-scale 3D voxel features and the 3D RoI features are extracted through RoI-grid pooling for box refinement.
Incrementally, Voxel R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> substitutes the precise keypoints with coarse voxel center points with better memory locality to facilitate the search for nearby voxel features.
Part-<span id="S2.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">A<sup id="S2.SS0.SSS0.Px3.p1.1.1.1" class="ltx_sup"><span id="S2.SS0.SSS0.Px3.p1.1.1.1.1" class="ltx_text ltx_font_upright">2</span></sup></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> utilizes a UNet-like <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> backbone for both 3D proposal generation and intra-object part location prediction, and then designs a novel RoI-aware point cloud pooling module for exact box refinement without ambiguity.
The most recent Pyramid R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> and PDV <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> design the variants of RoI-grid pooling to resolve the sparsity and non-uniform distribution of point clouds for better detection accuracy.
Top-performing point-voxel-based 3D detectors rely on the voxel-based backbone for BEV-based 3D proposal generation but resort to intermediate point-level representation for further refinement.
Differently, we convert point clouds to regular pillars and conduct 3D proposal generation and box refinement soly on the BEV representation without using intermediate keypoints.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2302.13301/assets/x1.png" id="S2.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="189" height="63" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S2.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Point-Voxel-based 3D R-CNN</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2302.13301/assets/x2.png" id="S2.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="189" height="63" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S2.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Our Pillar R-CNN</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Compared with prior best-performing point-voxel-based 3D detection paradigms, our proposed Pillar R-CNN directly refines 3D RoI on the 2D BEV space as Faster R-CNN without the necessity of intermediary keypoint-wise features.</span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Preliminary</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we first revisit best-performing two-stage 3D detectors and then reflect on the performance bottleneck of point cloud 3D detection referring to image-based 2D detection.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Revisiting</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Current state-of-the-art two-stage 3D object detection approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, as in <a href="#S2.F1" title="In Two-stage point cloud 3D object detection. ‣ 2 Related Work ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>, typically employ the point-voxel-based feature learning scheme for the BEV-based 3D proposal generation and then conduct point-level box refinement in the 3D space.
In both of these two stages, effective keypoint representation plays the primary role.
The pioneering PV-RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> sub-samples raw point clouds via Farthest Point Sampling (FPS) as intermediate keypoints and take point-based set operations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> for point-voxel interaction.
Despite the impressive detection accuracy, PV-RCNN suffers from the time-consuming procedures of point sampling and neighbor searching.
Incrementally, Voxel R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> argues that the coarse 3D voxels instead of precise positioning of raw points are sufficient for accurate localization on large objects.
Voxel R-CNN treats sparse but regular 3D volumes as a set of non-empty voxel center points and utilizes an accelerated PointNet module for a new balance between accuracy and efficiency.
Part-<span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">A<sup id="S3.SS1.p1.1.1.1" class="ltx_sup"><span id="S3.SS1.p1.1.1.1.1" class="ltx_text ltx_font_upright">2</span></sup></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> adopts a UNet-like architecture for finer voxel points and gains further profits for small objects.
Most recent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> attempt to tackle the issues of sparsity and point density variation of intermediary keypoints for improving detection accuracy.
In summary, typical point-voxel-based 3D detectors convert point clouds to regular grids for BEV-based 3D proposal generation and hinge on the granularity of keypoints for further box refinement. This inevitably exacerbates the complexity of the detection system and also struggles with more efficient local aggregation operations like <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">From the perspective of BEV-based perception, we expect to design a compact R-CNN head on fine pillars for box refinement.
By taking a close at the 3D voxel-based detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, we observe the fact that they convert 3D feature volumes into BEV representations for the dense detect head.
We conjecture that the merely bird-eye-view (BEV) representation can still offer sufficient 3D structure information.
To confirm our viewpoint, we construct the reasonable pooling feature map with a manageable granularity and crop this 2D dense map for each 3D proposal for 3D RoI refinement.
Also, the encouraging results convince us that BEV representation can carry sufficient 3D structure information without the need to restore this context via point-level representation.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Domain Gap between Two-Stage 2D and 3D Detection</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Unlike the well-studied 2D community where the input image is a 2D densely packed array, the inherent sparsity and irregularity of point clouds make it divert from the 2D detection field in methodology.
The main gap may be the 3D point/voxel-based point cloud representation and transitional keypoints in the two-stage frameworks.
Due to this gap, the latest progress in 2D detection cannot be easily applied to LiDAR-based 3D detection.
For example, the feature pyramid network (FPN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, as a basic component in 2D detection, has not yet been successfully used by current LiDAR-based 3D detection.
The latest advance in pillar-based 3D detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> partially bridges this gap by introducing the well-developed backbones, such as VGGNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, in 2D detection to 3D object detection with demonstrated success.
Along this research direction, we aim to narrow the domain gap by developing a 2D R-CNN style detector as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> for Lidar-based 3D detection.
The proposed Pillar R-CNN integrates the basic FPN with RPN properly for small object detection and crops the 2D dense pooling feature map like RoIPool <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> or RoIAlign <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> for further box refinement without the usage of transitional keypoint representation.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2302.13301/assets/x3.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="381" height="103" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Overall architecture of our proposed Pillar R-CNN.
The pillar-based backbone establishes a feature hierarchy in one forward pass, resulting in multi-level feature maps.
The in-network feature pyramid of RPN creates feature maps at different spatial resolutions that have rich semantics at all class-related scales.
RPN attaches the same detect head to each pyramid level to take class-specific detection.
R-CNN refines 3D RoI proposals at a manageable resolution by creating class-agnostic 2D dense pooling feature maps via the novel lateral connection.
The dashed arrow indicates the detachable auxiliary segmentation branch.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Pillar R-CNN</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">As shown in <a href="#S3.F2" title="In 3.2 Domain Gap between Two-Stage 2D and 3D Detection ‣ 3 Preliminary ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, our proposed Pillar R-CNN is conceptually simple, including two stages: the first stage (RPN) produces 3D proposals along with its classification at all class-related scales; the second stage (R-CNN) refines 3D boxes on the BEV plane at a manageable resolution.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Pillar-based Backbone</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.2" class="ltx_p">The most recent pillar-based 3D detector, PillarNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, converts point clouds to regular pillars and handles the sparse 2D volumes hierarchically in a bottom-up pathway.
PillarNet takes the advantage of 2D object detection with ConvNets such as VGGNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and computes the feature hierarchy in one forward pass.
It creates a set of low-level sparse 2D pillar volumes and high-level dense feature maps via the hybrid of 2D sparse and dense convolutions in a bottom-up manner.
We denote the resulting multi-level feature volumes or maps from different pyramid levels by <math id="S4.SS1.p1.1.m1.5" class="ltx_Math" alttext="\{C_{1},C_{2},C_{3},C_{4},C_{5}\}" display="inline"><semantics id="S4.SS1.p1.1.m1.5a"><mrow id="S4.SS1.p1.1.m1.5.5.5" xref="S4.SS1.p1.1.m1.5.5.6.cmml"><mo stretchy="false" id="S4.SS1.p1.1.m1.5.5.5.6" xref="S4.SS1.p1.1.m1.5.5.6.cmml">{</mo><msub id="S4.SS1.p1.1.m1.1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.1.1.2.cmml">C</mi><mn id="S4.SS1.p1.1.m1.1.1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.p1.1.m1.5.5.5.7" xref="S4.SS1.p1.1.m1.5.5.6.cmml">,</mo><msub id="S4.SS1.p1.1.m1.2.2.2.2" xref="S4.SS1.p1.1.m1.2.2.2.2.cmml"><mi id="S4.SS1.p1.1.m1.2.2.2.2.2" xref="S4.SS1.p1.1.m1.2.2.2.2.2.cmml">C</mi><mn id="S4.SS1.p1.1.m1.2.2.2.2.3" xref="S4.SS1.p1.1.m1.2.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS1.p1.1.m1.5.5.5.8" xref="S4.SS1.p1.1.m1.5.5.6.cmml">,</mo><msub id="S4.SS1.p1.1.m1.3.3.3.3" xref="S4.SS1.p1.1.m1.3.3.3.3.cmml"><mi id="S4.SS1.p1.1.m1.3.3.3.3.2" xref="S4.SS1.p1.1.m1.3.3.3.3.2.cmml">C</mi><mn id="S4.SS1.p1.1.m1.3.3.3.3.3" xref="S4.SS1.p1.1.m1.3.3.3.3.3.cmml">3</mn></msub><mo id="S4.SS1.p1.1.m1.5.5.5.9" xref="S4.SS1.p1.1.m1.5.5.6.cmml">,</mo><msub id="S4.SS1.p1.1.m1.4.4.4.4" xref="S4.SS1.p1.1.m1.4.4.4.4.cmml"><mi id="S4.SS1.p1.1.m1.4.4.4.4.2" xref="S4.SS1.p1.1.m1.4.4.4.4.2.cmml">C</mi><mn id="S4.SS1.p1.1.m1.4.4.4.4.3" xref="S4.SS1.p1.1.m1.4.4.4.4.3.cmml">4</mn></msub><mo id="S4.SS1.p1.1.m1.5.5.5.10" xref="S4.SS1.p1.1.m1.5.5.6.cmml">,</mo><msub id="S4.SS1.p1.1.m1.5.5.5.5" xref="S4.SS1.p1.1.m1.5.5.5.5.cmml"><mi id="S4.SS1.p1.1.m1.5.5.5.5.2" xref="S4.SS1.p1.1.m1.5.5.5.5.2.cmml">C</mi><mn id="S4.SS1.p1.1.m1.5.5.5.5.3" xref="S4.SS1.p1.1.m1.5.5.5.5.3.cmml">5</mn></msub><mo stretchy="false" id="S4.SS1.p1.1.m1.5.5.5.11" xref="S4.SS1.p1.1.m1.5.5.6.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.5b"><set id="S4.SS1.p1.1.m1.5.5.6.cmml" xref="S4.SS1.p1.1.m1.5.5.5"><apply id="S4.SS1.p1.1.m1.1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.2">𝐶</ci><cn type="integer" id="S4.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.3">1</cn></apply><apply id="S4.SS1.p1.1.m1.2.2.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p1.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2">𝐶</ci><cn type="integer" id="S4.SS1.p1.1.m1.2.2.2.2.3.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.3">2</cn></apply><apply id="S4.SS1.p1.1.m1.3.3.3.3.cmml" xref="S4.SS1.p1.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.3.3.3.3.1.cmml" xref="S4.SS1.p1.1.m1.3.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.1.m1.3.3.3.3.2.cmml" xref="S4.SS1.p1.1.m1.3.3.3.3.2">𝐶</ci><cn type="integer" id="S4.SS1.p1.1.m1.3.3.3.3.3.cmml" xref="S4.SS1.p1.1.m1.3.3.3.3.3">3</cn></apply><apply id="S4.SS1.p1.1.m1.4.4.4.4.cmml" xref="S4.SS1.p1.1.m1.4.4.4.4"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.4.4.4.4.1.cmml" xref="S4.SS1.p1.1.m1.4.4.4.4">subscript</csymbol><ci id="S4.SS1.p1.1.m1.4.4.4.4.2.cmml" xref="S4.SS1.p1.1.m1.4.4.4.4.2">𝐶</ci><cn type="integer" id="S4.SS1.p1.1.m1.4.4.4.4.3.cmml" xref="S4.SS1.p1.1.m1.4.4.4.4.3">4</cn></apply><apply id="S4.SS1.p1.1.m1.5.5.5.5.cmml" xref="S4.SS1.p1.1.m1.5.5.5.5"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.5.5.5.5.1.cmml" xref="S4.SS1.p1.1.m1.5.5.5.5">subscript</csymbol><ci id="S4.SS1.p1.1.m1.5.5.5.5.2.cmml" xref="S4.SS1.p1.1.m1.5.5.5.5.2">𝐶</ci><cn type="integer" id="S4.SS1.p1.1.m1.5.5.5.5.3.cmml" xref="S4.SS1.p1.1.m1.5.5.5.5.3">5</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.5c">\{C_{1},C_{2},C_{3},C_{4},C_{5}\}</annotation></semantics></math> with strides <math id="S4.SS1.p1.2.m2.5" class="ltx_Math" alttext="\{1,2,4,8,16\}" display="inline"><semantics id="S4.SS1.p1.2.m2.5a"><mrow id="S4.SS1.p1.2.m2.5.6.2" xref="S4.SS1.p1.2.m2.5.6.1.cmml"><mo stretchy="false" id="S4.SS1.p1.2.m2.5.6.2.1" xref="S4.SS1.p1.2.m2.5.6.1.cmml">{</mo><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">1</mn><mo id="S4.SS1.p1.2.m2.5.6.2.2" xref="S4.SS1.p1.2.m2.5.6.1.cmml">,</mo><mn id="S4.SS1.p1.2.m2.2.2" xref="S4.SS1.p1.2.m2.2.2.cmml">2</mn><mo id="S4.SS1.p1.2.m2.5.6.2.3" xref="S4.SS1.p1.2.m2.5.6.1.cmml">,</mo><mn id="S4.SS1.p1.2.m2.3.3" xref="S4.SS1.p1.2.m2.3.3.cmml">4</mn><mo id="S4.SS1.p1.2.m2.5.6.2.4" xref="S4.SS1.p1.2.m2.5.6.1.cmml">,</mo><mn id="S4.SS1.p1.2.m2.4.4" xref="S4.SS1.p1.2.m2.4.4.cmml">8</mn><mo id="S4.SS1.p1.2.m2.5.6.2.5" xref="S4.SS1.p1.2.m2.5.6.1.cmml">,</mo><mn id="S4.SS1.p1.2.m2.5.5" xref="S4.SS1.p1.2.m2.5.5.cmml">16</mn><mo stretchy="false" id="S4.SS1.p1.2.m2.5.6.2.6" xref="S4.SS1.p1.2.m2.5.6.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.5b"><set id="S4.SS1.p1.2.m2.5.6.1.cmml" xref="S4.SS1.p1.2.m2.5.6.2"><cn type="integer" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">1</cn><cn type="integer" id="S4.SS1.p1.2.m2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2">2</cn><cn type="integer" id="S4.SS1.p1.2.m2.3.3.cmml" xref="S4.SS1.p1.2.m2.3.3">4</cn><cn type="integer" id="S4.SS1.p1.2.m2.4.4.cmml" xref="S4.SS1.p1.2.m2.4.4">8</cn><cn type="integer" id="S4.SS1.p1.2.m2.5.5.cmml" xref="S4.SS1.p1.2.m2.5.5">16</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.5c">\{1,2,4,8,16\}</annotation></semantics></math> of pillar scales.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Pyramidal Region Proposal Network</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.3" class="ltx_p">Similar to the basic FPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, we construct a pyramidal region proposal network to improve the detection accuracy of small objects like pedestrians.
To build high-level semantic feature maps at all class-related scales, we modify the lateral connection layer to effectively merge the top-down dense maps and bottom-up sparse volumes.
Each lateral connection merges the sparse feature volumes and dense feature maps of the same spatial size from the bottom-up pathway and the top-down pathway.
Specifically, the top-down pathway hallucinates higher resolution features by upsampling semantically stronger dense feature maps from higher pyramid levels with a stride 2 de-convolution layer.
The upsampled dense map is then merged with the corresponding densified bottom-up map from its sparse volumes by the simple concatenation.
This process is iterated until the required multi-scale feature maps are ready.
Finally, we append a <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">3</cn><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">3\times 3</annotation></semantics></math> convolutional layer on each merged map to alleviate the aliasing effect of upsampling and reduce the channel dimensions.
Here, the final set of feature maps with high-level rich semantics called <math id="S4.SS2.p1.2.m2.2" class="ltx_Math" alttext="\{P_{3},P_{4}\}" display="inline"><semantics id="S4.SS2.p1.2.m2.2a"><mrow id="S4.SS2.p1.2.m2.2.2.2" xref="S4.SS2.p1.2.m2.2.2.3.cmml"><mo stretchy="false" id="S4.SS2.p1.2.m2.2.2.2.3" xref="S4.SS2.p1.2.m2.2.2.3.cmml">{</mo><msub id="S4.SS2.p1.2.m2.1.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.1.1.2" xref="S4.SS2.p1.2.m2.1.1.1.1.2.cmml">P</mi><mn id="S4.SS2.p1.2.m2.1.1.1.1.3" xref="S4.SS2.p1.2.m2.1.1.1.1.3.cmml">3</mn></msub><mo id="S4.SS2.p1.2.m2.2.2.2.4" xref="S4.SS2.p1.2.m2.2.2.3.cmml">,</mo><msub id="S4.SS2.p1.2.m2.2.2.2.2" xref="S4.SS2.p1.2.m2.2.2.2.2.cmml"><mi id="S4.SS2.p1.2.m2.2.2.2.2.2" xref="S4.SS2.p1.2.m2.2.2.2.2.2.cmml">P</mi><mn id="S4.SS2.p1.2.m2.2.2.2.2.3" xref="S4.SS2.p1.2.m2.2.2.2.2.3.cmml">4</mn></msub><mo stretchy="false" id="S4.SS2.p1.2.m2.2.2.2.5" xref="S4.SS2.p1.2.m2.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.2b"><set id="S4.SS2.p1.2.m2.2.2.3.cmml" xref="S4.SS2.p1.2.m2.2.2.2"><apply id="S4.SS2.p1.2.m2.1.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1.2">𝑃</ci><cn type="integer" id="S4.SS2.p1.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1.3">3</cn></apply><apply id="S4.SS2.p1.2.m2.2.2.2.2.cmml" xref="S4.SS2.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.2.2.2.2.1.cmml" xref="S4.SS2.p1.2.m2.2.2.2.2">subscript</csymbol><ci id="S4.SS2.p1.2.m2.2.2.2.2.2.cmml" xref="S4.SS2.p1.2.m2.2.2.2.2.2">𝑃</ci><cn type="integer" id="S4.SS2.p1.2.m2.2.2.2.2.3.cmml" xref="S4.SS2.p1.2.m2.2.2.2.2.3">4</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.2c">\{P_{3},P_{4}\}</annotation></semantics></math>, correspond to <math id="S4.SS2.p1.3.m3.2" class="ltx_Math" alttext="\{C_{3},C_{4}\}" display="inline"><semantics id="S4.SS2.p1.3.m3.2a"><mrow id="S4.SS2.p1.3.m3.2.2.2" xref="S4.SS2.p1.3.m3.2.2.3.cmml"><mo stretchy="false" id="S4.SS2.p1.3.m3.2.2.2.3" xref="S4.SS2.p1.3.m3.2.2.3.cmml">{</mo><msub id="S4.SS2.p1.3.m3.1.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.1.1.2" xref="S4.SS2.p1.3.m3.1.1.1.1.2.cmml">C</mi><mn id="S4.SS2.p1.3.m3.1.1.1.1.3" xref="S4.SS2.p1.3.m3.1.1.1.1.3.cmml">3</mn></msub><mo id="S4.SS2.p1.3.m3.2.2.2.4" xref="S4.SS2.p1.3.m3.2.2.3.cmml">,</mo><msub id="S4.SS2.p1.3.m3.2.2.2.2" xref="S4.SS2.p1.3.m3.2.2.2.2.cmml"><mi id="S4.SS2.p1.3.m3.2.2.2.2.2" xref="S4.SS2.p1.3.m3.2.2.2.2.2.cmml">C</mi><mn id="S4.SS2.p1.3.m3.2.2.2.2.3" xref="S4.SS2.p1.3.m3.2.2.2.2.3.cmml">4</mn></msub><mo stretchy="false" id="S4.SS2.p1.3.m3.2.2.2.5" xref="S4.SS2.p1.3.m3.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.2b"><set id="S4.SS2.p1.3.m3.2.2.3.cmml" xref="S4.SS2.p1.3.m3.2.2.2"><apply id="S4.SS2.p1.3.m3.1.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p1.3.m3.1.1.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.2">𝐶</ci><cn type="integer" id="S4.SS2.p1.3.m3.1.1.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.3">3</cn></apply><apply id="S4.SS2.p1.3.m3.2.2.2.2.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.2.2.2.2.1.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S4.SS2.p1.3.m3.2.2.2.2.2.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2">𝐶</ci><cn type="integer" id="S4.SS2.p1.3.m3.2.2.2.2.3.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.3">4</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.2c">\{C_{3},C_{4}\}</annotation></semantics></math> respectively in terms of the spatial size.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">We attach the commonly used center detect head <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> to each level of in-network feature pyramid <math id="S4.SS2.p2.1.m1.2" class="ltx_Math" alttext="\{P_{3},P_{4}\}" display="inline"><semantics id="S4.SS2.p2.1.m1.2a"><mrow id="S4.SS2.p2.1.m1.2.2.2" xref="S4.SS2.p2.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.SS2.p2.1.m1.2.2.2.3" xref="S4.SS2.p2.1.m1.2.2.3.cmml">{</mo><msub id="S4.SS2.p2.1.m1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.1.1.2.cmml">P</mi><mn id="S4.SS2.p2.1.m1.1.1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.1.1.3.cmml">3</mn></msub><mo id="S4.SS2.p2.1.m1.2.2.2.4" xref="S4.SS2.p2.1.m1.2.2.3.cmml">,</mo><msub id="S4.SS2.p2.1.m1.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.cmml"><mi id="S4.SS2.p2.1.m1.2.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.2.cmml">P</mi><mn id="S4.SS2.p2.1.m1.2.2.2.2.3" xref="S4.SS2.p2.1.m1.2.2.2.2.3.cmml">4</mn></msub><mo stretchy="false" id="S4.SS2.p2.1.m1.2.2.2.5" xref="S4.SS2.p2.1.m1.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.2b"><set id="S4.SS2.p2.1.m1.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2"><apply id="S4.SS2.p2.1.m1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2">𝑃</ci><cn type="integer" id="S4.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.3">3</cn></apply><apply id="S4.SS2.p2.1.m1.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.2.2.2.2.1.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2">𝑃</ci><cn type="integer" id="S4.SS2.p2.1.m1.2.2.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.3">4</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.2c">\{P_{3},P_{4}\}</annotation></semantics></math>, on which class-specific object predictions are respectively made.
Although better lateral connection designs are more helpful, we stick to the simplest design as described above.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>R-CNN via 2D RoI Pooling on BEV Plane</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">To justify the BEV representation preserves the crucial 3D structure information, we construct the dense pooling feature maps at a manageable scale via our plainly designed lateral connection layer.
Then, we make further 3D box refinement by using a Faster R-CNN-like RoI pooling module on the BEV plane.
We additionally supervise the grid points of each 3D proposal with semantical supervision to further examine the 3D structural capability of BEV representation, aligning the extra keypoint segmentation supervision branch used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2302.13301/assets/x4.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="232" height="231" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.4.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.5.2" class="ltx_text" style="font-size:90%;">Pooling points (brown) feature extraction on the pooling map (dashed grid) from nearby grid points using bilinear interpolation.
<span id="S4.F3.5.2.1" class="ltx_text" style="color:#0000FF;">Blue box</span>: 3D RoI. <span id="S4.F3.5.2.2" class="ltx_text" style="color:#00FF00;">Green box</span>: ground truth.</span></figcaption>
</figure>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Lateral connection layer.</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.2" class="ltx_p">The aim of the lateral connection layer for building pooling maps is to integrate the low-level sparse pillar feature volumes and high-level dense semantic feature maps into the dense pooling maps at a manageable resolution.
Specifically, the 2D sparse convolution layer is used to downsample the selected low-level pillar volumes from the bottom-up pathway to the desired spatial resolution.
Then, the stride <math id="S4.SS3.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.1.m1.1a"><mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.m1.1c">2</annotation></semantics></math> de-convolution layer upsamples the dense semantic feature maps from the pyramidal neck module in a top-down manner.
Finally, the dense pooling maps are constructed by merging the semantically stronger dense maps and spatially more precise sparse volumes with the same spatial resolution via a <math id="S4.SS3.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.2.m2.1a"><mrow id="S4.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml"><mn id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.1" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml">×</mo><mn id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.3" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1"><times id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.1"></times><cn type="integer" id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2">3</cn><cn type="integer" id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.2.m2.1c">3\times 3</annotation></semantics></math> convolutional layer.
Our designed lateral connection layer slightly deviates from the element-wise addition way in the original FPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, in that the sparse volumes could be extremely sparse with mostly empty points.
To confront the issue of the center feature missing induced by the sparse features, we simply apply the concatenation and standard convolution operations to blend the densified maps from the bottom-up pathway and dense maps from the top-down pathway.
In this way, our lateral connection design can provide critical semantic coverage onto the spatially accurate yet sparse bottom-up pillar volumes.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Auxiliary segmentation supervision.</h4>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.1" class="ltx_p">We attach the detachable auxiliary segmentation supervision of grid points in each 3D proposal to promote the 3D structural capability of the BEV-based pooling maps, which is inspired by the extra segmentation supervision of keypoint with 3D voxel-based structure context in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.
We attach the detachable auxiliary segmentation supervision of grid points in each 3D proposal to promote the 3D structural capability of the BEV-based pooling maps, which is inspired by the extra segmentation supervision of keypoint with 3D voxel-based structure context in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.
Specifically, we employ a 2-layer MLP with the sigmoid function to predict the foreground/background score of each grid point in each projected 2D rotated RoI.
The segmentation layers can be directly produced from the 3D box annotations by identifying whether each grid point is inside or outside of a projected ground-truth rotated box in <a href="#S4.F3" title="In 4.3 R-CNN via 2D RoI Pooling on BEV Plane ‣ 4 Pillar R-CNN ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, since the 3D objects do not overlap on the BEV plane.
Additionally, the auxiliary segmentation supervision branch is only employed during training, so there is no additional computational overhead for inference.</p>
</div>
<div id="S4.SS3.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p2.3" class="ltx_p">Similar to the RoI pooling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> and RoI Align <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, we crop the dense pooling maps using the projected 2D rotated RoI in order to extract the 3D RoI feature on the BEV plane.
Specifically, we simply utilize bilinear interpolation operation to sample evenly distributed <math id="S4.SS3.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="G\times G" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.1.m1.1a"><mrow id="S4.SS3.SSS0.Px2.p2.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2.cmml">G</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.1" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.1.cmml">×</mo><mi id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3.cmml">G</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1"><times id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.1"></times><ci id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2">𝐺</ci><ci id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.1.m1.1c">G\times G</annotation></semantics></math> grid points in each projected 3D RoI in <a href="#S4.F3" title="In 4.3 R-CNN via 2D RoI Pooling on BEV Plane ‣ 4 Pillar R-CNN ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>.
Then we collapse the sampled grid point features <math id="S4.SS3.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{R}^{G\times G\times C}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.2.m2.1a"><msup id="S4.SS3.SSS0.Px2.p2.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.cmml">ℛ</mi><mrow id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.cmml"><mi id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.2" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.2.cmml">G</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">×</mo><mi id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.3" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.3.cmml">G</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1a" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">×</mo><mi id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.4" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.4.cmml">C</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1">superscript</csymbol><ci id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2">ℛ</ci><apply id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3"><times id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1"></times><ci id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.2">𝐺</ci><ci id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.3">𝐺</ci><ci id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.4.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.4">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.2.m2.1c">\mathcal{R}^{G\times G\times C}</annotation></semantics></math> per RoI into a vector <math id="S4.SS3.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{R}^{256}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.3.m3.1a"><msup id="S4.SS3.SSS0.Px2.p2.3.m3.1.1" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.2" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.2.cmml">ℛ</mi><mn id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.3" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.3.cmml">256</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.3.m3.1b"><apply id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1">superscript</csymbol><ci id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.2">ℛ</ci><cn type="integer" id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.3.m3.1c">\mathcal{R}^{256}</annotation></semantics></math> by two hidden 256-<span id="S4.SS3.SSS0.Px2.p2.3.1" class="ltx_text ltx_font_italic">D</span> fully-connected (<span id="S4.SS3.SSS0.Px2.p2.3.2" class="ltx_text ltx_font_italic">fc</span>) layers, as the common practice in previous two-stage 3D detection methods.
As a result, Our Faster R-CNN-like 2D RoI pooling module transforms each 3D RoI feature with objects of various sizes into a fixed spatial extent for 3D proposal refinement and confidence prediction.
It is worth noting that our second R-CNN stage slightly differs from Faster R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> in that it requires the pooling maps at the manageable scale with the amply fused semantic-spatial features via the lateral connection layer.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Training Losses</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.3" class="ltx_p">The proposed Pillar R-CNN framework is trained end-to-end with the region proposal loss <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{rpn}" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><msub id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml">ℒ</mi><mrow id="S4.SS4.p1.1.m1.1.1.3" xref="S4.SS4.p1.1.m1.1.1.3.cmml"><mi id="S4.SS4.p1.1.m1.1.1.3.2" xref="S4.SS4.p1.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.3.1" xref="S4.SS4.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS4.p1.1.m1.1.1.3.3" xref="S4.SS4.p1.1.m1.1.1.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.1.m1.1.1.3.1a" xref="S4.SS4.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS4.p1.1.m1.1.1.3.4" xref="S4.SS4.p1.1.m1.1.1.3.4.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">ℒ</ci><apply id="S4.SS4.p1.1.m1.1.1.3.cmml" xref="S4.SS4.p1.1.m1.1.1.3"><times id="S4.SS4.p1.1.m1.1.1.3.1.cmml" xref="S4.SS4.p1.1.m1.1.1.3.1"></times><ci id="S4.SS4.p1.1.m1.1.1.3.2.cmml" xref="S4.SS4.p1.1.m1.1.1.3.2">𝑟</ci><ci id="S4.SS4.p1.1.m1.1.1.3.3.cmml" xref="S4.SS4.p1.1.m1.1.1.3.3">𝑝</ci><ci id="S4.SS4.p1.1.m1.1.1.3.4.cmml" xref="S4.SS4.p1.1.m1.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\mathcal{L}_{rpn}</annotation></semantics></math>, the proposal refinement loss <math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{rcnn}" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><msub id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.2.m2.1.1.2" xref="S4.SS4.p1.2.m2.1.1.2.cmml">ℒ</mi><mrow id="S4.SS4.p1.2.m2.1.1.3" xref="S4.SS4.p1.2.m2.1.1.3.cmml"><mi id="S4.SS4.p1.2.m2.1.1.3.2" xref="S4.SS4.p1.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.2.m2.1.1.3.1" xref="S4.SS4.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS4.p1.2.m2.1.1.3.3" xref="S4.SS4.p1.2.m2.1.1.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.2.m2.1.1.3.1a" xref="S4.SS4.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS4.p1.2.m2.1.1.3.4" xref="S4.SS4.p1.2.m2.1.1.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.2.m2.1.1.3.1b" xref="S4.SS4.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS4.p1.2.m2.1.1.3.5" xref="S4.SS4.p1.2.m2.1.1.3.5.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><apply id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.1.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.p1.2.m2.1.1.2.cmml" xref="S4.SS4.p1.2.m2.1.1.2">ℒ</ci><apply id="S4.SS4.p1.2.m2.1.1.3.cmml" xref="S4.SS4.p1.2.m2.1.1.3"><times id="S4.SS4.p1.2.m2.1.1.3.1.cmml" xref="S4.SS4.p1.2.m2.1.1.3.1"></times><ci id="S4.SS4.p1.2.m2.1.1.3.2.cmml" xref="S4.SS4.p1.2.m2.1.1.3.2">𝑟</ci><ci id="S4.SS4.p1.2.m2.1.1.3.3.cmml" xref="S4.SS4.p1.2.m2.1.1.3.3">𝑐</ci><ci id="S4.SS4.p1.2.m2.1.1.3.4.cmml" xref="S4.SS4.p1.2.m2.1.1.3.4">𝑛</ci><ci id="S4.SS4.p1.2.m2.1.1.3.5.cmml" xref="S4.SS4.p1.2.m2.1.1.3.5">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">\mathcal{L}_{rcnn}</annotation></semantics></math>, and the auxiliary segmentation loss <math id="S4.SS4.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{seg}" display="inline"><semantics id="S4.SS4.p1.3.m3.1a"><msub id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.3.m3.1.1.2" xref="S4.SS4.p1.3.m3.1.1.2.cmml">ℒ</mi><mrow id="S4.SS4.p1.3.m3.1.1.3" xref="S4.SS4.p1.3.m3.1.1.3.cmml"><mi id="S4.SS4.p1.3.m3.1.1.3.2" xref="S4.SS4.p1.3.m3.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.3.m3.1.1.3.1" xref="S4.SS4.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S4.SS4.p1.3.m3.1.1.3.3" xref="S4.SS4.p1.3.m3.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.3.m3.1.1.3.1a" xref="S4.SS4.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S4.SS4.p1.3.m3.1.1.3.4" xref="S4.SS4.p1.3.m3.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><apply id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.3.m3.1.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS4.p1.3.m3.1.1.2.cmml" xref="S4.SS4.p1.3.m3.1.1.2">ℒ</ci><apply id="S4.SS4.p1.3.m3.1.1.3.cmml" xref="S4.SS4.p1.3.m3.1.1.3"><times id="S4.SS4.p1.3.m3.1.1.3.1.cmml" xref="S4.SS4.p1.3.m3.1.1.3.1"></times><ci id="S4.SS4.p1.3.m3.1.1.3.2.cmml" xref="S4.SS4.p1.3.m3.1.1.3.2">𝑠</ci><ci id="S4.SS4.p1.3.m3.1.1.3.3.cmml" xref="S4.SS4.p1.3.m3.1.1.3.3">𝑒</ci><ci id="S4.SS4.p1.3.m3.1.1.3.4.cmml" xref="S4.SS4.p1.3.m3.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">\mathcal{L}_{seg}</annotation></semantics></math>.
We adopt the same region proposal loss in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> for used pyramid scales.
We follow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and use the same proposal refinement loss for class-agnostic confidence prediction and box regression.
The auxiliary segmentation is simply supervised using a binary cross-entropy loss, with each grid point’s classification label determined by its projected location relative to the corresponding ground-truth bounding box.
The overall training loss is the sum of these three losses with equal weights:</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.1" class="ltx_Math" alttext="\centering\mathcal{L}_{total}=\sum_{s}{\mathcal{L}_{rpn}^{s}}+\mathcal{L}_{rcnn}+\mathcal{L}_{seg}\@add@centering" display="block"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml"><msub id="S4.E1.m1.1.1.2" xref="S4.E1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.2.2" xref="S4.E1.m1.1.1.2.2.cmml">ℒ</mi><mrow id="S4.E1.m1.1.1.2.3" xref="S4.E1.m1.1.1.2.3.cmml"><mi id="S4.E1.m1.1.1.2.3.2" xref="S4.E1.m1.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2.3.1" xref="S4.E1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.2.3.3" xref="S4.E1.m1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2.3.1a" xref="S4.E1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.2.3.4" xref="S4.E1.m1.1.1.2.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2.3.1b" xref="S4.E1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.2.3.5" xref="S4.E1.m1.1.1.2.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2.3.1c" xref="S4.E1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.2.3.6" xref="S4.E1.m1.1.1.2.3.6.cmml">l</mi></mrow></msub><mo rspace="0.111em" id="S4.E1.m1.1.1.1" xref="S4.E1.m1.1.1.1.cmml">=</mo><mrow id="S4.E1.m1.1.1.3" xref="S4.E1.m1.1.1.3.cmml"><mrow id="S4.E1.m1.1.1.3.2" xref="S4.E1.m1.1.1.3.2.cmml"><munder id="S4.E1.m1.1.1.3.2.1" xref="S4.E1.m1.1.1.3.2.1.cmml"><mo movablelimits="false" id="S4.E1.m1.1.1.3.2.1.2" xref="S4.E1.m1.1.1.3.2.1.2.cmml">∑</mo><mi id="S4.E1.m1.1.1.3.2.1.3" xref="S4.E1.m1.1.1.3.2.1.3.cmml">s</mi></munder><msubsup id="S4.E1.m1.1.1.3.2.2" xref="S4.E1.m1.1.1.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.3.2.2.2.2" xref="S4.E1.m1.1.1.3.2.2.2.2.cmml">ℒ</mi><mrow id="S4.E1.m1.1.1.3.2.2.2.3" xref="S4.E1.m1.1.1.3.2.2.2.3.cmml"><mi id="S4.E1.m1.1.1.3.2.2.2.3.2" xref="S4.E1.m1.1.1.3.2.2.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.3.2.2.2.3.1" xref="S4.E1.m1.1.1.3.2.2.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.3.2.2.2.3.3" xref="S4.E1.m1.1.1.3.2.2.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.3.2.2.2.3.1a" xref="S4.E1.m1.1.1.3.2.2.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.3.2.2.2.3.4" xref="S4.E1.m1.1.1.3.2.2.2.3.4.cmml">n</mi></mrow><mi id="S4.E1.m1.1.1.3.2.2.3" xref="S4.E1.m1.1.1.3.2.2.3.cmml">s</mi></msubsup></mrow><mo id="S4.E1.m1.1.1.3.1" xref="S4.E1.m1.1.1.3.1.cmml">+</mo><msub id="S4.E1.m1.1.1.3.3" xref="S4.E1.m1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.3.3.2" xref="S4.E1.m1.1.1.3.3.2.cmml">ℒ</mi><mrow id="S4.E1.m1.1.1.3.3.3" xref="S4.E1.m1.1.1.3.3.3.cmml"><mi id="S4.E1.m1.1.1.3.3.3.2" xref="S4.E1.m1.1.1.3.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.3.3.3.1" xref="S4.E1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.3.3.3.3" xref="S4.E1.m1.1.1.3.3.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.3.3.3.1a" xref="S4.E1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.3.3.3.4" xref="S4.E1.m1.1.1.3.3.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.3.3.3.1b" xref="S4.E1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.3.3.3.5" xref="S4.E1.m1.1.1.3.3.3.5.cmml">n</mi></mrow></msub><mo id="S4.E1.m1.1.1.3.1a" xref="S4.E1.m1.1.1.3.1.cmml">+</mo><msub id="S4.E1.m1.1.1.3.4" xref="S4.E1.m1.1.1.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.3.4.2" xref="S4.E1.m1.1.1.3.4.2.cmml">ℒ</mi><mrow id="S4.E1.m1.1.1.3.4.3" xref="S4.E1.m1.1.1.3.4.3.cmml"><mi id="S4.E1.m1.1.1.3.4.3.2" xref="S4.E1.m1.1.1.3.4.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.3.4.3.1" xref="S4.E1.m1.1.1.3.4.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.3.4.3.3" xref="S4.E1.m1.1.1.3.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.3.4.3.1a" xref="S4.E1.m1.1.1.3.4.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.3.4.3.4" xref="S4.E1.m1.1.1.3.4.3.4.cmml">g</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1"><eq id="S4.E1.m1.1.1.1.cmml" xref="S4.E1.m1.1.1.1"></eq><apply id="S4.E1.m1.1.1.2.cmml" xref="S4.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.2">subscript</csymbol><ci id="S4.E1.m1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.2.2">ℒ</ci><apply id="S4.E1.m1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.2.3"><times id="S4.E1.m1.1.1.2.3.1.cmml" xref="S4.E1.m1.1.1.2.3.1"></times><ci id="S4.E1.m1.1.1.2.3.2.cmml" xref="S4.E1.m1.1.1.2.3.2">𝑡</ci><ci id="S4.E1.m1.1.1.2.3.3.cmml" xref="S4.E1.m1.1.1.2.3.3">𝑜</ci><ci id="S4.E1.m1.1.1.2.3.4.cmml" xref="S4.E1.m1.1.1.2.3.4">𝑡</ci><ci id="S4.E1.m1.1.1.2.3.5.cmml" xref="S4.E1.m1.1.1.2.3.5">𝑎</ci><ci id="S4.E1.m1.1.1.2.3.6.cmml" xref="S4.E1.m1.1.1.2.3.6">𝑙</ci></apply></apply><apply id="S4.E1.m1.1.1.3.cmml" xref="S4.E1.m1.1.1.3"><plus id="S4.E1.m1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.3.1"></plus><apply id="S4.E1.m1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.3.2"><apply id="S4.E1.m1.1.1.3.2.1.cmml" xref="S4.E1.m1.1.1.3.2.1"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.3.2.1.1.cmml" xref="S4.E1.m1.1.1.3.2.1">subscript</csymbol><sum id="S4.E1.m1.1.1.3.2.1.2.cmml" xref="S4.E1.m1.1.1.3.2.1.2"></sum><ci id="S4.E1.m1.1.1.3.2.1.3.cmml" xref="S4.E1.m1.1.1.3.2.1.3">𝑠</ci></apply><apply id="S4.E1.m1.1.1.3.2.2.cmml" xref="S4.E1.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.3.2.2.1.cmml" xref="S4.E1.m1.1.1.3.2.2">superscript</csymbol><apply id="S4.E1.m1.1.1.3.2.2.2.cmml" xref="S4.E1.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.3.2.2.2.1.cmml" xref="S4.E1.m1.1.1.3.2.2">subscript</csymbol><ci id="S4.E1.m1.1.1.3.2.2.2.2.cmml" xref="S4.E1.m1.1.1.3.2.2.2.2">ℒ</ci><apply id="S4.E1.m1.1.1.3.2.2.2.3.cmml" xref="S4.E1.m1.1.1.3.2.2.2.3"><times id="S4.E1.m1.1.1.3.2.2.2.3.1.cmml" xref="S4.E1.m1.1.1.3.2.2.2.3.1"></times><ci id="S4.E1.m1.1.1.3.2.2.2.3.2.cmml" xref="S4.E1.m1.1.1.3.2.2.2.3.2">𝑟</ci><ci id="S4.E1.m1.1.1.3.2.2.2.3.3.cmml" xref="S4.E1.m1.1.1.3.2.2.2.3.3">𝑝</ci><ci id="S4.E1.m1.1.1.3.2.2.2.3.4.cmml" xref="S4.E1.m1.1.1.3.2.2.2.3.4">𝑛</ci></apply></apply><ci id="S4.E1.m1.1.1.3.2.2.3.cmml" xref="S4.E1.m1.1.1.3.2.2.3">𝑠</ci></apply></apply><apply id="S4.E1.m1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.3.3.1.cmml" xref="S4.E1.m1.1.1.3.3">subscript</csymbol><ci id="S4.E1.m1.1.1.3.3.2.cmml" xref="S4.E1.m1.1.1.3.3.2">ℒ</ci><apply id="S4.E1.m1.1.1.3.3.3.cmml" xref="S4.E1.m1.1.1.3.3.3"><times id="S4.E1.m1.1.1.3.3.3.1.cmml" xref="S4.E1.m1.1.1.3.3.3.1"></times><ci id="S4.E1.m1.1.1.3.3.3.2.cmml" xref="S4.E1.m1.1.1.3.3.3.2">𝑟</ci><ci id="S4.E1.m1.1.1.3.3.3.3.cmml" xref="S4.E1.m1.1.1.3.3.3.3">𝑐</ci><ci id="S4.E1.m1.1.1.3.3.3.4.cmml" xref="S4.E1.m1.1.1.3.3.3.4">𝑛</ci><ci id="S4.E1.m1.1.1.3.3.3.5.cmml" xref="S4.E1.m1.1.1.3.3.3.5">𝑛</ci></apply></apply><apply id="S4.E1.m1.1.1.3.4.cmml" xref="S4.E1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.3.4.1.cmml" xref="S4.E1.m1.1.1.3.4">subscript</csymbol><ci id="S4.E1.m1.1.1.3.4.2.cmml" xref="S4.E1.m1.1.1.3.4.2">ℒ</ci><apply id="S4.E1.m1.1.1.3.4.3.cmml" xref="S4.E1.m1.1.1.3.4.3"><times id="S4.E1.m1.1.1.3.4.3.1.cmml" xref="S4.E1.m1.1.1.3.4.3.1"></times><ci id="S4.E1.m1.1.1.3.4.3.2.cmml" xref="S4.E1.m1.1.1.3.4.3.2">𝑠</ci><ci id="S4.E1.m1.1.1.3.4.3.3.cmml" xref="S4.E1.m1.1.1.3.4.3.3">𝑒</ci><ci id="S4.E1.m1.1.1.3.4.3.4.cmml" xref="S4.E1.m1.1.1.3.4.3.4">𝑔</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">\centering\mathcal{L}_{total}=\sum_{s}{\mathcal{L}_{rpn}^{s}}+\mathcal{L}_{rcnn}+\mathcal{L}_{seg}\@add@centering</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We evaluate our Pillar R-CNN on the public Waymo Open Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, a large-scale 3D object detection dataset for autonomous driving research.
The whole dataset is composed of 798 training sequences (158,361 point cloud samples) and 202 validation sequences (40,077 point cloud samples).
The evaluation metrics used are 3D mean Average Precision (mAP) and mAP weighted by heading accuracy (mAPH).
The mAP and mAPH are based on an IoU threshold of 0.7 for vehicle and 0.5 for pedestrian and cyclist.
Two difficulty levels, LEVEL_1 (boxes with more than five LiDAR points) LEVEL_2 APH (boxes with at least one LiDAR point) are considered.
We highlight LEVEL_2 APH in tables since it is the main metric for ranking in the Waymo Challenge Leaderboard.</p>
</div>
<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Implementation details.</h4>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.7" class="ltx_p">The architecture of the pillar-based backbone follows the design of PillarNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, which includes the first four stages with sparse convolution for processing sparse pillar volumes and the last stage with standard convolution for densified feature maps on the BEV plane.
Based on the inherent feature hierarchy of pillar-based backbone, we simply introduce FPN into RPN by detecting large object detection (<span id="S5.SS0.SSS0.Px1.p1.7.1" class="ltx_text ltx_font_italic">e.g.</span>, vehicle) on <math id="S5.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_math_unparsed" alttext="8\times" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.1.m1.1a"><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.1b"><mn id="S5.SS0.SSS0.Px1.p1.1.m1.1.1">8</mn><mo lspace="0.222em" id="S5.SS0.SSS0.Px1.p1.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.1.m1.1c">8\times</annotation></semantics></math> stridden maps and small objects (<span id="S5.SS0.SSS0.Px1.p1.7.2" class="ltx_text ltx_font_italic">e.g.</span>, pedestrian) on <math id="S5.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.2.m2.1a"><mrow id="S5.SS0.SSS0.Px1.p1.2.m2.1b"><mn id="S5.SS0.SSS0.Px1.p1.2.m2.1.1">4</mn><mo lspace="0.222em" id="S5.SS0.SSS0.Px1.p1.2.m2.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.2.m2.1c">4\times</annotation></semantics></math> stridden maps.
The second stage constructs the pooling maps at a manageable resolution and channel dimension via a <math id="S5.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.3.m3.1a"><mrow id="S5.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.cmml"><mn id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.2" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.1" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml">×</mo><mn id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.3" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.3.m3.1b"><apply id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1"><times id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.1"></times><cn type="integer" id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.2">3</cn><cn type="integer" id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.3.m3.1c">3\times 3</annotation></semantics></math> convolutional layer. We only conduct experiments on the pooling resolutions of <math id="S5.SS0.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="P_{2}" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.4.m4.1a"><msub id="S5.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S5.SS0.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S5.SS0.SSS0.Px1.p1.4.m4.1.1.2" xref="S5.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml">P</mi><mn id="S5.SS0.SSS0.Px1.p1.4.m4.1.1.3" xref="S5.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.4.m4.1b"><apply id="S5.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S5.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.4.m4.1.1.2">𝑃</ci><cn type="integer" id="S5.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.4.m4.1c">P_{2}</annotation></semantics></math> and <math id="S5.SS0.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="P_{3}" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.5.m5.1a"><msub id="S5.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S5.SS0.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S5.SS0.SSS0.Px1.p1.5.m5.1.1.2" xref="S5.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml">P</mi><mn id="S5.SS0.SSS0.Px1.p1.5.m5.1.1.3" xref="S5.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.5.m5.1b"><apply id="S5.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S5.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.5.m5.1.1.2">𝑃</ci><cn type="integer" id="S5.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p1.5.m5.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.5.m5.1c">P_{3}</annotation></semantics></math>, but not using <math id="S5.SS0.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="P_{1}" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.6.m6.1a"><msub id="S5.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S5.SS0.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S5.SS0.SSS0.Px1.p1.6.m6.1.1.2" xref="S5.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml">P</mi><mn id="S5.SS0.SSS0.Px1.p1.6.m6.1.1.3" xref="S5.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.6.m6.1b"><apply id="S5.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S5.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.6.m6.1.1.2">𝑃</ci><cn type="integer" id="S5.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.6.m6.1c">P_{1}</annotation></semantics></math> due to its large memory footprint.
Unless mentioned, we employ the <math id="S5.SS0.SSS0.Px1.p1.7.m7.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.7.m7.1a"><mrow id="S5.SS0.SSS0.Px1.p1.7.m7.1b"><mn id="S5.SS0.SSS0.Px1.p1.7.m7.1.1">4</mn><mo lspace="0.222em" id="S5.SS0.SSS0.Px1.p1.7.m7.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.7.m7.1c">4\times</annotation></semantics></math> stridden pooling maps of the pillar size 0.4m, because it offers a good trade-off between localization performance and computation costs.</p>
</div>
<div id="S5.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p2.1" class="ltx_p">Following the settings of the baseline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, the detection range is [-75.2m, 75.2m] for the X and Y axis, and [-2m, 4m] for the Z axis. We also set the initial pillar size to (0.1m, 0.1m).</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Training and inference details.</h4>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p1.1" class="ltx_p">Following CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, our Pillar R-CNN framework is trained from scratch in an end-to-end manner with the AdamW optimizer, batch size 16 and learning rate 0.01 for 36 epochs on 4 RTX 3090 GPUs on the Waymo Open Dataset.
We report inference latency on a single 3090 GPU with batch size 1 following the way in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> without any test-time optimization.
We randomly sample 128 proposals with 1:1 ratio as the training samples for the proposal refinement stage, where the positive proposals have at least 0.55 3D IoU with the corresponding ground-truth boxes.
The data augmentation strategies during training are kept the same as PV-RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> for a fair comparison.</p>
</div>
<div id="S5.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p2.1" class="ltx_p">During inference, we keep the top (200, 150, 150) proposals generated by RPN for the vehicle, pedestrian, and cyclist with class-specific NMS, where the used 3D IoU thresholds are set to be 0.8, 0.55 and 0.55 for vehicle, pedestrian and cyclist, respectively.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<div id="S5.T1.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:120pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-175.3pt,48.3pt) scale(0.55287005771944,0.55287005771944) ;">
<table id="S5.T1.2.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T1.2.1.1.1" class="ltx_tr">
<td id="S5.T1.2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T1.2.1.1.1.1.1" class="ltx_text">Methods</span></td>
<td id="S5.T1.2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T1.2.1.1.1.2.1" class="ltx_text">Stages</span></td>
<td id="S5.T1.2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T1.2.1.1.1.3.1" class="ltx_text">Sensors</span></td>
<td id="S5.T1.2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">ALL (3D AP/APH)</td>
<td id="S5.T1.2.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Veh. (3D AP/APH)</td>
<td id="S5.T1.2.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Ped. (3D AP/APH)</td>
<td id="S5.T1.2.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Cyc. (3D AP/APH)</td>
</tr>
<tr id="S5.T1.2.1.2.2" class="ltx_tr">
<td id="S5.T1.2.1.2.2.1" class="ltx_td ltx_align_center">L1</td>
<td id="S5.T1.2.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S5.T1.2.1.2.2.3" class="ltx_td ltx_align_center">L1</td>
<td id="S5.T1.2.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S5.T1.2.1.2.2.5" class="ltx_td ltx_align_center">L1</td>
<td id="S5.T1.2.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S5.T1.2.1.2.2.7" class="ltx_td ltx_align_center">L1</td>
<td id="S5.T1.2.1.2.2.8" class="ltx_td ltx_align_center">L2</td>
</tr>
<tr id="S5.T1.2.1.3.3" class="ltx_tr">
<td id="S5.T1.2.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">StarNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S5.T1.2.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Two</td>
<td id="S5.T1.2.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T1.2.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T1.2.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T1.2.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">61.50/61.00</td>
<td id="S5.T1.2.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">54.90/54.50</td>
<td id="S5.T1.2.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">67.80/59.90</td>
<td id="S5.T1.2.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.10/54.00</td>
<td id="S5.T1.2.1.3.3.10" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T1.2.1.3.3.11" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S5.T1.2.1.4.4" class="ltx_tr">
<td id="S5.T1.2.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r">RCD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
</td>
<td id="S5.T1.2.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">Two</td>
<td id="S5.T1.2.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T1.2.1.4.4.4" class="ltx_td ltx_align_center">-</td>
<td id="S5.T1.2.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T1.2.1.4.4.6" class="ltx_td ltx_align_center">71.97/71.59</td>
<td id="S5.T1.2.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r">65.06/64.70</td>
<td id="S5.T1.2.1.4.4.8" class="ltx_td ltx_align_center">-</td>
<td id="S5.T1.2.1.4.4.9" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T1.2.1.4.4.10" class="ltx_td ltx_align_center">-</td>
<td id="S5.T1.2.1.4.4.11" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T1.2.1.5.5" class="ltx_tr">
<td id="S5.T1.2.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r">Light-FMFNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>
</td>
<td id="S5.T1.2.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">One</td>
<td id="S5.T1.2.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">L</td>
<td id="S5.T1.2.1.5.5.4" class="ltx_td ltx_align_center">71.24/67.26</td>
<td id="S5.T1.2.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r">65.88/62.18</td>
<td id="S5.T1.2.1.5.5.6" class="ltx_td ltx_align_center">77.85/77.30</td>
<td id="S5.T1.2.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r">70.16/69.65</td>
<td id="S5.T1.2.1.5.5.8" class="ltx_td ltx_align_center">69.52/59.78</td>
<td id="S5.T1.2.1.5.5.9" class="ltx_td ltx_align_center ltx_border_r">63.62/54.61</td>
<td id="S5.T1.2.1.5.5.10" class="ltx_td ltx_align_center">66.34/64.69</td>
<td id="S5.T1.2.1.5.5.11" class="ltx_td ltx_align_center">63.87/62.28</td>
</tr>
<tr id="S5.T1.2.1.6.6" class="ltx_tr">
<td id="S5.T1.2.1.6.6.1" class="ltx_td ltx_align_center ltx_border_r">HIKVISION_LiDAR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>
</td>
<td id="S5.T1.2.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">Two</td>
<td id="S5.T1.2.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r">L</td>
<td id="S5.T1.2.1.6.6.4" class="ltx_td ltx_align_center">75.19/72.58</td>
<td id="S5.T1.2.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r">69.74/67.29</td>
<td id="S5.T1.2.1.6.6.6" class="ltx_td ltx_align_center">78.63/78.14</td>
<td id="S5.T1.2.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r">71.06/70.60</td>
<td id="S5.T1.2.1.6.6.8" class="ltx_td ltx_align_center">76.00/69.90</td>
<td id="S5.T1.2.1.6.6.9" class="ltx_td ltx_align_center ltx_border_r">69.82/64.11</td>
<td id="S5.T1.2.1.6.6.10" class="ltx_td ltx_align_center">70.94/69.70</td>
<td id="S5.T1.2.1.6.6.11" class="ltx_td ltx_align_center">68.35/67.15</td>
</tr>
<tr id="S5.T1.2.1.7.7" class="ltx_tr">
<td id="S5.T1.2.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r">CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="S5.T1.2.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r">Two</td>
<td id="S5.T1.2.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r">LT</td>
<td id="S5.T1.2.1.7.7.4" class="ltx_td ltx_align_center">-</td>
<td id="S5.T1.2.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T1.2.1.7.7.6" class="ltx_td ltx_align_center">80.20/79.70</td>
<td id="S5.T1.2.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r">72.20/71.80</td>
<td id="S5.T1.2.1.7.7.8" class="ltx_td ltx_align_center">78.30/72.10</td>
<td id="S5.T1.2.1.7.7.9" class="ltx_td ltx_align_center ltx_border_r">72.20/66.40</td>
<td id="S5.T1.2.1.7.7.10" class="ltx_td ltx_align_center">-</td>
<td id="S5.T1.2.1.7.7.11" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T1.2.1.8.8" class="ltx_tr">
<td id="S5.T1.2.1.8.8.1" class="ltx_td ltx_align_center ltx_border_r">AFDetV2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</td>
<td id="S5.T1.2.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r">One</td>
<td id="S5.T1.2.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r">LT</td>
<td id="S5.T1.2.1.8.8.4" class="ltx_td ltx_align_center">77.56/75.20</td>
<td id="S5.T1.2.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r">72.18/69.95</td>
<td id="S5.T1.2.1.8.8.6" class="ltx_td ltx_align_center">80.49/80.43</td>
<td id="S5.T1.2.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r">72.98/72.55</td>
<td id="S5.T1.2.1.8.8.8" class="ltx_td ltx_align_center">79.76/74.35</td>
<td id="S5.T1.2.1.8.8.9" class="ltx_td ltx_align_center ltx_border_r">73.71/68.61</td>
<td id="S5.T1.2.1.8.8.10" class="ltx_td ltx_align_center"><span id="S5.T1.2.1.8.8.10.1" class="ltx_text ltx_font_bold">72.43/71.23</span></td>
<td id="S5.T1.2.1.8.8.11" class="ltx_td ltx_align_center"><span id="S5.T1.2.1.8.8.11.1" class="ltx_text ltx_font_bold">69.84/68.67</span></td>
</tr>
<tr id="S5.T1.2.1.9.9" class="ltx_tr">
<td id="S5.T1.2.1.9.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">PillarNet-18</td>
<td id="S5.T1.2.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">One</td>
<td id="S5.T1.2.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">LT</td>
<td id="S5.T1.2.1.9.9.4" class="ltx_td ltx_align_center ltx_border_t">76.60/73.62</td>
<td id="S5.T1.2.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.30/68.49</td>
<td id="S5.T1.2.1.9.9.6" class="ltx_td ltx_align_center ltx_border_t">81.85/81.40</td>
<td id="S5.T1.2.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.46/74.03</td>
<td id="S5.T1.2.1.9.9.8" class="ltx_td ltx_align_center ltx_border_t">79.97/72.68</td>
<td id="S5.T1.2.1.9.9.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.95/67.09</td>
<td id="S5.T1.2.1.9.9.10" class="ltx_td ltx_align_center ltx_border_t">67.98/66.80</td>
<td id="S5.T1.2.1.9.9.11" class="ltx_td ltx_align_center ltx_border_t">65.50/64.36</td>
</tr>
<tr id="S5.T1.2.1.10.10" class="ltx_tr">
<td id="S5.T1.2.1.10.10.1" class="ltx_td ltx_align_center ltx_border_r">PillarNet-34</td>
<td id="S5.T1.2.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r">One</td>
<td id="S5.T1.2.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r">LT</td>
<td id="S5.T1.2.1.10.10.4" class="ltx_td ltx_align_center">77.46/74.69</td>
<td id="S5.T1.2.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r">72.17/69.55</td>
<td id="S5.T1.2.1.10.10.6" class="ltx_td ltx_align_center">82.47/82.03</td>
<td id="S5.T1.2.1.10.10.7" class="ltx_td ltx_align_center ltx_border_r">75.07/74.65</td>
<td id="S5.T1.2.1.10.10.8" class="ltx_td ltx_align_center">80.82/74.13</td>
<td id="S5.T1.2.1.10.10.9" class="ltx_td ltx_align_center ltx_border_r">74.83/68.54</td>
<td id="S5.T1.2.1.10.10.10" class="ltx_td ltx_align_center">69.08/67.91</td>
<td id="S5.T1.2.1.10.10.11" class="ltx_td ltx_align_center">66.60/65.47</td>
</tr>
<tr id="S5.T1.2.1.11.11" class="ltx_tr">
<td id="S5.T1.2.1.11.11.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Pillar R-CNN-18</td>
<td id="S5.T1.2.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Two</td>
<td id="S5.T1.2.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">LT</td>
<td id="S5.T1.2.1.11.11.4" class="ltx_td ltx_align_center ltx_border_t">77.80/74.64</td>
<td id="S5.T1.2.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">72.56/69.55</td>
<td id="S5.T1.2.1.11.11.6" class="ltx_td ltx_align_center ltx_border_t">81.89/81.40</td>
<td id="S5.T1.2.1.11.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.52/74.07</td>
<td id="S5.T1.2.1.11.11.8" class="ltx_td ltx_align_center ltx_border_t">82.08/74.29</td>
<td id="S5.T1.2.1.11.11.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.23/68.84</td>
<td id="S5.T1.2.1.11.11.10" class="ltx_td ltx_align_center ltx_border_t">69.44/68.24</td>
<td id="S5.T1.2.1.11.11.11" class="ltx_td ltx_align_center ltx_border_t">66.92/65.75</td>
</tr>
<tr id="S5.T1.2.1.12.12" class="ltx_tr">
<td id="S5.T1.2.1.12.12.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">Pillar R-CNN-34</td>
<td id="S5.T1.2.1.12.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">Two</td>
<td id="S5.T1.2.1.12.12.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">LT</td>
<td id="S5.T1.2.1.12.12.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.2.1.12.12.4.1" class="ltx_text ltx_font_bold">78.29/75.28</span></td>
<td id="S5.T1.2.1.12.12.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T1.2.1.12.12.5.1" class="ltx_text ltx_font_bold">73.05/70.18</span></td>
<td id="S5.T1.2.1.12.12.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.2.1.12.12.6.1" class="ltx_text ltx_font_bold">82.53/82.10</span></td>
<td id="S5.T1.2.1.12.12.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T1.2.1.12.12.7.1" class="ltx_text ltx_font_bold">75.16/74.75</span></td>
<td id="S5.T1.2.1.12.12.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.2.1.12.12.8.1" class="ltx_text ltx_font_bold">82.90/75.50</span></td>
<td id="S5.T1.2.1.12.12.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T1.2.1.12.12.9.1" class="ltx_text ltx_font_bold">77.04/70.00</span></td>
<td id="S5.T1.2.1.12.12.10" class="ltx_td ltx_align_center ltx_border_bb">69.43/68.25</td>
<td id="S5.T1.2.1.12.12.11" class="ltx_td ltx_align_center ltx_border_bb">66.94/65.79</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.4.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S5.T1.5.2" class="ltx_text" style="font-size:90%;">Single-frame LiDAR-only non-ensemble performance comparison on the Waymo Open Dataset <span id="S5.T1.5.2.1" class="ltx_text ltx_font_italic">test</span> set.
“L” and “LT” mean “all LiDARS” and “top-LiDAR only”, respectively.
The table is sorted by ALL APH/L2 which is the official ranking metric. The proposed Pillar R-CNN models set new state-of-the-art results.
</span></figcaption>
</figure>
<figure id="S5.T2" class="ltx_table">
<div id="S5.T2.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:263.9pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-153.8pt,93.4pt) scale(0.585027388045606,0.585027388045606) ;">
<table id="S5.T2.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T2.3.3.4.1" class="ltx_tr">
<th id="S5.T2.3.3.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T2.3.3.4.1.1.1" class="ltx_text">Methods</span></th>
<th id="S5.T2.3.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T2.3.3.4.1.2.1" class="ltx_text">Stages</span></th>
<td id="S5.T2.3.3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">ALL (3D mAP/mAPH)</td>
<td id="S5.T2.3.3.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Veh. (3D mAP/mAPH)</td>
<td id="S5.T2.3.3.4.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Ped. (3D mAP/mAPH)</td>
<td id="S5.T2.3.3.4.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Cyc. (3D mAP/mAPH)</td>
</tr>
<tr id="S5.T2.3.3.5.2" class="ltx_tr">
<td id="S5.T2.3.3.5.2.1" class="ltx_td ltx_align_center">L1</td>
<td id="S5.T2.3.3.5.2.2" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S5.T2.3.3.5.2.3" class="ltx_td ltx_align_center">L1</td>
<td id="S5.T2.3.3.5.2.4" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S5.T2.3.3.5.2.5" class="ltx_td ltx_align_center">L1</td>
<td id="S5.T2.3.3.5.2.6" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S5.T2.3.3.5.2.7" class="ltx_td ltx_align_center">L1</td>
<td id="S5.T2.3.3.5.2.8" class="ltx_td ltx_align_center">L2</td>
</tr>
<tr id="S5.T2.3.3.6.3" class="ltx_tr">
<th id="S5.T2.3.3.6.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">StarNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</th>
<th id="S5.T2.3.3.6.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Two</th>
<td id="S5.T2.3.3.6.3.3" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T2.3.3.6.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.3.3.6.3.5" class="ltx_td ltx_align_center ltx_border_t">53.70/-</td>
<td id="S5.T2.3.3.6.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.3.3.6.3.7" class="ltx_td ltx_align_center ltx_border_t">66.80/-</td>
<td id="S5.T2.3.3.6.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.3.3.6.3.9" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T2.3.3.6.3.10" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S5.T2.3.3.7.4" class="ltx_tr">
<th id="S5.T2.3.3.7.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3D-MAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>
</th>
<th id="S5.T2.3.3.7.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Multi</th>
<td id="S5.T2.3.3.7.4.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.7.4.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.7.4.5" class="ltx_td ltx_align_center">69.03/68.52</td>
<td id="S5.T2.3.3.7.4.6" class="ltx_td ltx_align_center ltx_border_r">60.16/59.71</td>
<td id="S5.T2.3.3.7.4.7" class="ltx_td ltx_align_center">71.71/67.74</td>
<td id="S5.T2.3.3.7.4.8" class="ltx_td ltx_align_center ltx_border_r">62.58/ 59.04</td>
<td id="S5.T2.3.3.7.4.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.7.4.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.3.3.8.5" class="ltx_tr">
<th id="S5.T2.3.3.8.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">RCD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
</th>
<th id="S5.T2.3.3.8.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.8.5.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.8.5.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.8.5.5" class="ltx_td ltx_align_center">69.59/69.16</td>
<td id="S5.T2.3.3.8.5.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.8.5.7" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.8.5.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.8.5.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.8.5.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<math id="S5.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S5.T2.1.1.1.1.m1.1a"><mo id="S5.T2.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.m1.1c">\dagger</annotation></semantics></math>SECOND <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">One</th>
<td id="S5.T2.1.1.1.3" class="ltx_td ltx_align_center">67.20/63.05</td>
<td id="S5.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r">60.97/57.23</td>
<td id="S5.T2.1.1.1.5" class="ltx_td ltx_align_center">72.27/71.69</td>
<td id="S5.T2.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r">63.85/63.33</td>
<td id="S5.T2.1.1.1.7" class="ltx_td ltx_align_center">68.70/58.18</td>
<td id="S5.T2.1.1.1.8" class="ltx_td ltx_align_center ltx_border_r">60.72/51.31</td>
<td id="S5.T2.1.1.1.9" class="ltx_td ltx_align_center">60.62/59.28</td>
<td id="S5.T2.1.1.1.10" class="ltx_td ltx_align_center">58.34/57.05</td>
</tr>
<tr id="S5.T2.2.2.2" class="ltx_tr">
<th id="S5.T2.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<math id="S5.T2.2.2.2.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S5.T2.2.2.2.1.m1.1a"><mo id="S5.T2.2.2.2.1.m1.1.1" xref="S5.T2.2.2.2.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.1.m1.1b"><ci id="S5.T2.2.2.2.1.m1.1.1.cmml" xref="S5.T2.2.2.2.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.1.m1.1c">\dagger</annotation></semantics></math>PointPillar <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</th>
<th id="S5.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">One</th>
<td id="S5.T2.2.2.2.3" class="ltx_td ltx_align_center">68.87/63.33</td>
<td id="S5.T2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r">62.63/57.53</td>
<td id="S5.T2.2.2.2.5" class="ltx_td ltx_align_center">71.60/71.00</td>
<td id="S5.T2.2.2.2.6" class="ltx_td ltx_align_center ltx_border_r">63.10/62.50</td>
<td id="S5.T2.2.2.2.7" class="ltx_td ltx_align_center">70.60/56.70</td>
<td id="S5.T2.2.2.2.8" class="ltx_td ltx_align_center ltx_border_r">62.90/50.20</td>
<td id="S5.T2.2.2.2.9" class="ltx_td ltx_align_center">64.40/62.30</td>
<td id="S5.T2.2.2.2.10" class="ltx_td ltx_align_center">61.90/59.90</td>
</tr>
<tr id="S5.T2.3.3.9.6" class="ltx_tr">
<th id="S5.T2.3.3.9.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">IA-SSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</th>
<th id="S5.T2.3.3.9.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">One</th>
<td id="S5.T2.3.3.9.6.3" class="ltx_td ltx_align_center">69.19/64.48</td>
<td id="S5.T2.3.3.9.6.4" class="ltx_td ltx_align_center ltx_border_r">62.28/58.08</td>
<td id="S5.T2.3.3.9.6.5" class="ltx_td ltx_align_center">70.53/69.67</td>
<td id="S5.T2.3.3.9.6.6" class="ltx_td ltx_align_center ltx_border_r">61.55/60.80</td>
<td id="S5.T2.3.3.9.6.7" class="ltx_td ltx_align_center">69.38/58.47</td>
<td id="S5.T2.3.3.9.6.8" class="ltx_td ltx_align_center ltx_border_r">60.30/50.73</td>
<td id="S5.T2.3.3.9.6.9" class="ltx_td ltx_align_center">67.67/65.30</td>
<td id="S5.T2.3.3.9.6.10" class="ltx_td ltx_align_center">64.98/62.71</td>
</tr>
<tr id="S5.T2.3.3.10.7" class="ltx_tr">
<th id="S5.T2.3.3.10.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">LiDAR R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>
</th>
<th id="S5.T2.3.3.10.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.10.7.3" class="ltx_td ltx_align_center">71.10/66.20</td>
<td id="S5.T2.3.3.10.7.4" class="ltx_td ltx_align_center ltx_border_r">64.63/60.10</td>
<td id="S5.T2.3.3.10.7.5" class="ltx_td ltx_align_center">73.50/73.00</td>
<td id="S5.T2.3.3.10.7.6" class="ltx_td ltx_align_center ltx_border_r">64.70/64.20</td>
<td id="S5.T2.3.3.10.7.7" class="ltx_td ltx_align_center">71.20/58.70</td>
<td id="S5.T2.3.3.10.7.8" class="ltx_td ltx_align_center ltx_border_r">63.10/51.70</td>
<td id="S5.T2.3.3.10.7.9" class="ltx_td ltx_align_center">68.60/66.90</td>
<td id="S5.T2.3.3.10.7.10" class="ltx_td ltx_align_center">66.10/64.40</td>
</tr>
<tr id="S5.T2.3.3.11.8" class="ltx_tr">
<th id="S5.T2.3.3.11.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">MVF++ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</th>
<th id="S5.T2.3.3.11.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">One</th>
<td id="S5.T2.3.3.11.8.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.11.8.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.11.8.5" class="ltx_td ltx_align_center">74.64/-</td>
<td id="S5.T2.3.3.11.8.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.11.8.7" class="ltx_td ltx_align_center">78.01/-</td>
<td id="S5.T2.3.3.11.8.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.11.8.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.11.8.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.3.3.12.9" class="ltx_tr">
<th id="S5.T2.3.3.12.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">RSN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>
</th>
<th id="S5.T2.3.3.12.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.12.9.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.12.9.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.12.9.5" class="ltx_td ltx_align_center">75.10/74.60</td>
<td id="S5.T2.3.3.12.9.6" class="ltx_td ltx_align_center ltx_border_r">66.00/65.50</td>
<td id="S5.T2.3.3.12.9.7" class="ltx_td ltx_align_center">77.80/72.70</td>
<td id="S5.T2.3.3.12.9.8" class="ltx_td ltx_align_center ltx_border_r">68.30/63.70</td>
<td id="S5.T2.3.3.12.9.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.12.9.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.3.3.13.10" class="ltx_tr">
<th id="S5.T2.3.3.13.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Voxel R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
</th>
<th id="S5.T2.3.3.13.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.13.10.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.13.10.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.13.10.5" class="ltx_td ltx_align_center">75.59/-</td>
<td id="S5.T2.3.3.13.10.6" class="ltx_td ltx_align_center ltx_border_r">66.59/-</td>
<td id="S5.T2.3.3.13.10.7" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.13.10.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.13.10.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.13.10.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.3.3.14.11" class="ltx_tr">
<th id="S5.T2.3.3.14.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Pyramid R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
</th>
<th id="S5.T2.3.3.14.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.14.11.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.14.11.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.14.11.5" class="ltx_td ltx_align_center">76.30/75.68</td>
<td id="S5.T2.3.3.14.11.6" class="ltx_td ltx_align_center ltx_border_r">67.23/66.68</td>
<td id="S5.T2.3.3.14.11.7" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.14.11.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.14.11.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.14.11.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.3.3.15.12" class="ltx_tr">
<th id="S5.T2.3.3.15.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</th>
<th id="S5.T2.3.3.15.12.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.15.12.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.15.12.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.3.3.15.12.5" class="ltx_td ltx_align_center">76.70/76.20</td>
<td id="S5.T2.3.3.15.12.6" class="ltx_td ltx_align_center ltx_border_r">68.80/68.30</td>
<td id="S5.T2.3.3.15.12.7" class="ltx_td ltx_align_center">79.00/72.90</td>
<td id="S5.T2.3.3.15.12.8" class="ltx_td ltx_align_center ltx_border_r">71.00/65.30</td>
<td id="S5.T2.3.3.15.12.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T2.3.3.15.12.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.3.3.16.13" class="ltx_tr">
<th id="S5.T2.3.3.16.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">PV-RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>
</th>
<th id="S5.T2.3.3.16.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.16.13.3" class="ltx_td ltx_align_center">73.44/69.63</td>
<td id="S5.T2.3.3.16.13.4" class="ltx_td ltx_align_center ltx_border_r">66.80/63.33</td>
<td id="S5.T2.3.3.16.13.5" class="ltx_td ltx_align_center">77.51/76.89</td>
<td id="S5.T2.3.3.16.13.6" class="ltx_td ltx_align_center ltx_border_r">68.98/68.41</td>
<td id="S5.T2.3.3.16.13.7" class="ltx_td ltx_align_center">75.01/65.65</td>
<td id="S5.T2.3.3.16.13.8" class="ltx_td ltx_align_center ltx_border_r">66.04/57.61</td>
<td id="S5.T2.3.3.16.13.9" class="ltx_td ltx_align_center">67.81/66.35</td>
<td id="S5.T2.3.3.16.13.10" class="ltx_td ltx_align_center">65.39/63.98</td>
</tr>
<tr id="S5.T2.3.3.3" class="ltx_tr">
<th id="S5.T2.3.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Part-A<sup id="S5.T2.3.3.3.1.1" class="ltx_sup">2</sup> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>
</th>
<th id="S5.T2.3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.3.3" class="ltx_td ltx_align_center">73.63/70.25</td>
<td id="S5.T2.3.3.3.4" class="ltx_td ltx_align_center ltx_border_r">66.93/63.85</td>
<td id="S5.T2.3.3.3.5" class="ltx_td ltx_align_center">77.05/76.51</td>
<td id="S5.T2.3.3.3.6" class="ltx_td ltx_align_center ltx_border_r">68.47/67.97</td>
<td id="S5.T2.3.3.3.7" class="ltx_td ltx_align_center">75.24/66.87</td>
<td id="S5.T2.3.3.3.8" class="ltx_td ltx_align_center ltx_border_r">66.18/58.62</td>
<td id="S5.T2.3.3.3.9" class="ltx_td ltx_align_center">68.60/67.36</td>
<td id="S5.T2.3.3.3.10" class="ltx_td ltx_align_center">66.13/64.93</td>
</tr>
<tr id="S5.T2.3.3.17.14" class="ltx_tr">
<th id="S5.T2.3.3.17.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">PDV <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>
</th>
<th id="S5.T2.3.3.17.14.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.17.14.3" class="ltx_td ltx_align_center">73.25/69.95</td>
<td id="S5.T2.3.3.17.14.4" class="ltx_td ltx_align_center ltx_border_r">67.21/64.15</td>
<td id="S5.T2.3.3.17.14.5" class="ltx_td ltx_align_center">76.85/76.33</td>
<td id="S5.T2.3.3.17.14.6" class="ltx_td ltx_align_center ltx_border_r">69.30/68.81</td>
<td id="S5.T2.3.3.17.14.7" class="ltx_td ltx_align_center">74.19/65.96</td>
<td id="S5.T2.3.3.17.14.8" class="ltx_td ltx_align_center ltx_border_r">65.85/58.28</td>
<td id="S5.T2.3.3.17.14.9" class="ltx_td ltx_align_center">68.71/67.55</td>
<td id="S5.T2.3.3.17.14.10" class="ltx_td ltx_align_center">66.49/65.36</td>
</tr>
<tr id="S5.T2.3.3.18.15" class="ltx_tr">
<th id="S5.T2.3.3.18.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">AFDetV2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</th>
<th id="S5.T2.3.3.18.15.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">One</th>
<td id="S5.T2.3.3.18.15.3" class="ltx_td ltx_align_center">77.18/74.83</td>
<td id="S5.T2.3.3.18.15.4" class="ltx_td ltx_align_center ltx_border_r">70.97/68.77</td>
<td id="S5.T2.3.3.18.15.5" class="ltx_td ltx_align_center">77.64/77.14</td>
<td id="S5.T2.3.3.18.15.6" class="ltx_td ltx_align_center ltx_border_r">69.68//69.22</td>
<td id="S5.T2.3.3.18.15.7" class="ltx_td ltx_align_center">80.19/74.62</td>
<td id="S5.T2.3.3.18.15.8" class="ltx_td ltx_align_center ltx_border_r">72.16/66.95</td>
<td id="S5.T2.3.3.18.15.9" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.18.15.9.1" class="ltx_text ltx_font_bold">73.72/72.74</span></td>
<td id="S5.T2.3.3.18.15.10" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.18.15.10.1" class="ltx_text ltx_font_bold">71.06/70.12</span></td>
</tr>
<tr id="S5.T2.3.3.19.16" class="ltx_tr">
<th id="S5.T2.3.3.19.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">CenterFormer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>
</th>
<th id="S5.T2.3.3.19.16.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">One</th>
<td id="S5.T2.3.3.19.16.3" class="ltx_td ltx_align_center">75.37/73.00</td>
<td id="S5.T2.3.3.19.16.4" class="ltx_td ltx_align_center ltx_border_r">71.2/68.93</td>
<td id="S5.T2.3.3.19.16.5" class="ltx_td ltx_align_center">75.2/74.7</td>
<td id="S5.T2.3.3.19.16.6" class="ltx_td ltx_align_center ltx_border_r">70.2/69.7</td>
<td id="S5.T2.3.3.19.16.7" class="ltx_td ltx_align_center">78.6/73.0</td>
<td id="S5.T2.3.3.19.16.8" class="ltx_td ltx_align_center ltx_border_r">73.6/68.3</td>
<td id="S5.T2.3.3.19.16.9" class="ltx_td ltx_align_center">72.3/71.3</td>
<td id="S5.T2.3.3.19.16.10" class="ltx_td ltx_align_center">69.8/68.8</td>
</tr>
<tr id="S5.T2.3.3.20.17" class="ltx_tr">
<th id="S5.T2.3.3.20.17.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">PillarNet-18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</th>
<th id="S5.T2.3.3.20.17.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">One</th>
<td id="S5.T2.3.3.20.17.3" class="ltx_td ltx_align_center ltx_border_t">76.15/73.20</td>
<td id="S5.T2.3.3.20.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.91/67.17</td>
<td id="S5.T2.3.3.20.17.5" class="ltx_td ltx_align_center ltx_border_t">78.24/77.73</td>
<td id="S5.T2.3.3.20.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.40/69.92</td>
<td id="S5.T2.3.3.20.17.7" class="ltx_td ltx_align_center ltx_border_t">79.80/72.59</td>
<td id="S5.T2.3.3.20.17.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.57/64.90</td>
<td id="S5.T2.3.3.20.17.9" class="ltx_td ltx_align_center ltx_border_t">70.40/69.29</td>
<td id="S5.T2.3.3.20.17.10" class="ltx_td ltx_align_center ltx_border_t">67.75/66.68</td>
</tr>
<tr id="S5.T2.3.3.21.18" class="ltx_tr">
<th id="S5.T2.3.3.21.18.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">PillarNet-34 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</th>
<th id="S5.T2.3.3.21.18.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">One</th>
<td id="S5.T2.3.3.21.18.3" class="ltx_td ltx_align_center">77.32/74.60</td>
<td id="S5.T2.3.3.21.18.4" class="ltx_td ltx_align_center ltx_border_r">70.97/68.43</td>
<td id="S5.T2.3.3.21.18.5" class="ltx_td ltx_align_center">79.09/78.59</td>
<td id="S5.T2.3.3.21.18.6" class="ltx_td ltx_align_center ltx_border_r">70.92/70.46</td>
<td id="S5.T2.3.3.21.18.7" class="ltx_td ltx_align_center">80.59/74.01</td>
<td id="S5.T2.3.3.21.18.8" class="ltx_td ltx_align_center ltx_border_r">72.28/66.17</td>
<td id="S5.T2.3.3.21.18.9" class="ltx_td ltx_align_center">72.29/71.21</td>
<td id="S5.T2.3.3.21.18.10" class="ltx_td ltx_align_center">69.72/68.67</td>
</tr>
<tr id="S5.T2.3.3.22.19" class="ltx_tr">
<th id="S5.T2.3.3.22.19.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Pillar R-CNN-18</th>
<th id="S5.T2.3.3.22.19.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Two</th>
<td id="S5.T2.3.3.22.19.3" class="ltx_td ltx_align_center ltx_border_t">77.31/74.11</td>
<td id="S5.T2.3.3.22.19.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.27/68.24</td>
<td id="S5.T2.3.3.22.19.5" class="ltx_td ltx_align_center ltx_border_t">78.70/78.19</td>
<td id="S5.T2.3.3.22.19.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.53/70.06</td>
<td id="S5.T2.3.3.22.19.7" class="ltx_td ltx_align_center ltx_border_t">82.15/74.24</td>
<td id="S5.T2.3.3.22.19.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.78/67.27</td>
<td id="S5.T2.3.3.22.19.9" class="ltx_td ltx_align_center ltx_border_t">71.07/69.91</td>
<td id="S5.T2.3.3.22.19.10" class="ltx_td ltx_align_center ltx_border_t">68.50/67.38</td>
</tr>
<tr id="S5.T2.3.3.23.20" class="ltx_tr">
<th id="S5.T2.3.3.23.20.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Pillar R-CNN-34</th>
<th id="S5.T2.3.3.23.20.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Two</th>
<td id="S5.T2.3.3.23.20.3" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.23.20.3.1" class="ltx_text ltx_font_bold">78.12/75.02</span></td>
<td id="S5.T2.3.3.23.20.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.3.3.23.20.4.1" class="ltx_text ltx_font_bold">72.07/69.11</span></td>
<td id="S5.T2.3.3.23.20.5" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.23.20.5.1" class="ltx_text ltx_font_bold">79.47/78.98</span></td>
<td id="S5.T2.3.3.23.20.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.3.3.23.20.6.1" class="ltx_text ltx_font_bold">71.29/70.84</span></td>
<td id="S5.T2.3.3.23.20.7" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.23.20.7.1" class="ltx_text ltx_font_bold">82.67/75.06</span></td>
<td id="S5.T2.3.3.23.20.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.3.3.23.20.8.1" class="ltx_text ltx_font_bold">75.29/68.35</span></td>
<td id="S5.T2.3.3.23.20.9" class="ltx_td ltx_align_center">72.21/71.01</td>
<td id="S5.T2.3.3.23.20.10" class="ltx_td ltx_align_center">69.62/68.45</td>
</tr>
<tr id="S5.T2.3.3.24.21" class="ltx_tr">
<th id="S5.T2.3.3.24.21.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Pillar R-CNN-18 (6 epoch)</th>
<th id="S5.T2.3.3.24.21.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Two</th>
<td id="S5.T2.3.3.24.21.3" class="ltx_td ltx_align_center ltx_border_t">76.87/73.62</td>
<td id="S5.T2.3.3.24.21.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.82/67.74</td>
<td id="S5.T2.3.3.24.21.5" class="ltx_td ltx_align_center ltx_border_t">78.07/77.52</td>
<td id="S5.T2.3.3.24.21.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.09/69.58</td>
<td id="S5.T2.3.3.24.21.7" class="ltx_td ltx_align_center ltx_border_t">81.31/73.27</td>
<td id="S5.T2.3.3.24.21.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.79/66.18</td>
<td id="S5.T2.3.3.24.21.9" class="ltx_td ltx_align_center ltx_border_t">71.22/70.07</td>
<td id="S5.T2.3.3.24.21.10" class="ltx_td ltx_align_center ltx_border_t">68.57/67.47</td>
</tr>
<tr id="S5.T2.3.3.25.22" class="ltx_tr">
<th id="S5.T2.3.3.25.22.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">Pillar R-CNN-18 (12 epoch)</th>
<th id="S5.T2.3.3.25.22.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">Two</th>
<td id="S5.T2.3.3.25.22.3" class="ltx_td ltx_align_center ltx_border_bb">76.83/73.59</td>
<td id="S5.T2.3.3.25.22.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">70.74/67.67</td>
<td id="S5.T2.3.3.25.22.5" class="ltx_td ltx_align_center ltx_border_bb">77.96/77.40</td>
<td id="S5.T2.3.3.25.22.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">69.95/69.43</td>
<td id="S5.T2.3.3.25.22.7" class="ltx_td ltx_align_center ltx_border_bb">81.17/73.14</td>
<td id="S5.T2.3.3.25.22.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">73.53/65.95</td>
<td id="S5.T2.3.3.25.22.9" class="ltx_td ltx_align_center ltx_border_bb">71.37/70.22</td>
<td id="S5.T2.3.3.25.22.10" class="ltx_td ltx_align_center ltx_border_bb">68.73/67.63</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.7.2.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.5.1" class="ltx_text" style="font-size:90%;">Single-frame LiDAR-only non-ensemble 3D AP/APH performance comparison on the Waymo validation set.
The table is sorted by ALL APH/L2, which is the official leaderboard ranking metric.
The proposed Pillar R-CNN demonstrates superiority over the state-of-the-art one-stage and two-stage approaches. <math id="S5.T2.5.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S5.T2.5.1.m1.1b"><mo id="S5.T2.5.1.m1.1.1" xref="S5.T2.5.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.1.m1.1c"><ci id="S5.T2.5.1.m1.1.1.cmml" xref="S5.T2.5.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.1.m1.1d">\dagger</annotation></semantics></math>: reported by LiDAR R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. </span></figcaption>
</figure>
</section>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Comparison with State-of-the-Arts</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">To validate the effectiveness of our proposed Pillar R-CNN, we fairly compare with state-of-the-art methods on the Waymo Open Dataset.</p>
</div>
<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Evaluation on the Waymo validation set.</h4>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p1.1" class="ltx_p">We compare our Pillar R-CNN with all published single-frame LiDAR-only non-ensemble methods on the Waymo validation set.
As shown in <a href="#S5.T2" title="In Training and inference details. ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, Pillar R-CNN achieves competitive performance for vehicle and pedestrian detection.
By introducing FPN, our Pillar R-CNN achieves remarkably better AP/APH on all difficulty levels for the detection of small objects.
To be specific, our Pillar R-CNN with heavy PillarNet-34 backbone achieves 68.05 APH/L2 for pedestrian detection, surpassing the state-of-the-art AFDetV2 by +1.1%.
The cyclist accuracy is hampered by the unbalanced object distribution as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, which dynamic label assignment techniques such as SimOTA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> can solve.
It is noteworthy that our Pillar R-CNN confirms the BEV representation can supply sufficient 3D structual information for superior detection accuracy.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Evaluation on the Waymo test set.</h4>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p1.1" class="ltx_p">We evaluate the performance of our Pillar R-CNN with its model variants on the Waymo Open Dataset <span id="S5.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">test</span> set.
As shown in <a href="#S5.T1" title="In Training and inference details. ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a>, our Pillar R-CNN-34 outperforms all the previous single-frame LiDAR-only non-ensemble detectors, especially for vehicle and pedestrian detection. Our Pillar R-CNN-18/34 consistently surpass their one-stage counterparts PillarNet-18/34.
It is worth noting that the reported results of Pillar R-CNN apply <math id="S5.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.1.m1.1a"><mrow id="S5.SS1.SSS0.Px2.p1.1.m1.1b"><mn id="S5.SS1.SSS0.Px2.p1.1.m1.1.1">4</mn><mo lspace="0.222em" id="S5.SS1.SSS0.Px2.p1.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.1.m1.1c">4\times</annotation></semantics></math> stridden pooling map for refining 3D proposals on all three classes.</p>
</div>
<div id="S5.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p2.1" class="ltx_p"><span id="S5.SS1.SSS0.Px2.p2.1.1" class="ltx_text ltx_font_bold">Better results of integrating latest advances of 2D detection field will be provided later.</span></p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Ablation Studies</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We investigate the individual components of our proposed Pillar R-CNN framework with extensive ablation experiments.
For efficiency, we uniformly sub-sample 25% of the training sequences and evaluate the full validation sequences.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.2.1.1" class="ltx_tr">
<td id="S5.T3.2.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T3.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Methods</span></td>
<td id="S5.T3.2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T3.2.1.1.2.1" class="ltx_text" style="font-size:90%;">FPN</span></td>
<td id="S5.T3.2.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T3.2.1.1.3.1" class="ltx_text" style="font-size:90%;">Aux.</span></td>
<td id="S5.T3.2.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T3.2.1.1.4.1" class="ltx_text" style="font-size:90%;">Veh. (APH)</span></td>
<td id="S5.T3.2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T3.2.1.1.5.1" class="ltx_text" style="font-size:90%;">Ped. (APH)</span></td>
</tr>
<tr id="S5.T3.2.2.2" class="ltx_tr">
<td id="S5.T3.2.2.2.1" class="ltx_td ltx_align_center"><span id="S5.T3.2.2.2.1.1" class="ltx_text" style="font-size:90%;">L1</span></td>
<td id="S5.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.2.2.2.1" class="ltx_text" style="font-size:90%;">L2</span></td>
<td id="S5.T3.2.2.2.3" class="ltx_td ltx_align_center"><span id="S5.T3.2.2.2.3.1" class="ltx_text" style="font-size:90%;">L1</span></td>
<td id="S5.T3.2.2.2.4" class="ltx_td ltx_align_center"><span id="S5.T3.2.2.2.4.1" class="ltx_text" style="font-size:90%;">L2</span></td>
</tr>
<tr id="S5.T3.2.3.3" class="ltx_tr">
<td id="S5.T3.2.3.3.1" class="ltx_td ltx_align_left ltx_border_t" colspan="5"><span id="S5.T3.2.3.3.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">PillarNet-18 Backbone</span></td>
<td id="S5.T3.2.3.3.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.2.3.3.3" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S5.T3.2.4.4" class="ltx_tr">
<td id="S5.T3.2.4.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T3.2.4.4.1.1" class="ltx_text" style="font-size:90%;">RPN</span></td>
<td id="S5.T3.2.4.4.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T3.2.4.4.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T3.2.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.2.4.4.4.1" class="ltx_text" style="font-size:90%;">74.55</span></td>
<td id="S5.T3.2.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.2.4.4.5.1" class="ltx_text" style="font-size:90%;">66.84</span></td>
<td id="S5.T3.2.4.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.2.4.4.6.1" class="ltx_text" style="font-size:90%;">64.75</span></td>
<td id="S5.T3.2.4.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.2.4.4.7.1" class="ltx_text" style="font-size:90%;">57.85</span></td>
</tr>
<tr id="S5.T3.2.5.5" class="ltx_tr">
<td id="S5.T3.2.5.5.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.5.5.1.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T3.2.5.5.2" class="ltx_td ltx_border_r"></td>
<td id="S5.T3.2.5.5.3" class="ltx_td ltx_align_center"><span id="S5.T3.2.5.5.3.1" class="ltx_text" style="font-size:90%;">74.54</span></td>
<td id="S5.T3.2.5.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.5.5.4.1" class="ltx_text" style="font-size:90%;">66.86</span></td>
<td id="S5.T3.2.5.5.5" class="ltx_td ltx_align_center"><span id="S5.T3.2.5.5.5.1" class="ltx_text" style="font-size:90%;">70.04</span></td>
<td id="S5.T3.2.5.5.6" class="ltx_td ltx_align_center"><span id="S5.T3.2.5.5.6.1" class="ltx_text" style="font-size:90%;">63.25</span></td>
</tr>
<tr id="S5.T3.2.6.6" class="ltx_tr">
<td id="S5.T3.2.6.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="4"><span id="S5.T3.2.6.6.1.1" class="ltx_text" style="font-size:90%;">R-CNN</span></td>
<td id="S5.T3.2.6.6.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T3.2.6.6.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T3.2.6.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.2.6.6.4.1" class="ltx_text" style="font-size:90%;">76.32</span></td>
<td id="S5.T3.2.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.2.6.6.5.1" class="ltx_text" style="font-size:90%;">68.53</span></td>
<td id="S5.T3.2.6.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.2.6.6.6.1" class="ltx_text" style="font-size:90%;">70.11</span></td>
<td id="S5.T3.2.6.6.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.2.6.6.7.1" class="ltx_text" style="font-size:90%;">62.26</span></td>
</tr>
<tr id="S5.T3.2.7.7" class="ltx_tr">
<td id="S5.T3.2.7.7.1" class="ltx_td ltx_border_r"></td>
<td id="S5.T3.2.7.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.7.7.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T3.2.7.7.3" class="ltx_td ltx_align_center"><span id="S5.T3.2.7.7.3.1" class="ltx_text" style="font-size:90%;">76.55</span></td>
<td id="S5.T3.2.7.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.7.7.4.1" class="ltx_text" style="font-size:90%;">68.64</span></td>
<td id="S5.T3.2.7.7.5" class="ltx_td ltx_align_center"><span id="S5.T3.2.7.7.5.1" class="ltx_text" style="font-size:90%;">70.21</span></td>
<td id="S5.T3.2.7.7.6" class="ltx_td ltx_align_center"><span id="S5.T3.2.7.7.6.1" class="ltx_text" style="font-size:90%;">62.46</span></td>
</tr>
<tr id="S5.T3.2.8.8" class="ltx_tr">
<td id="S5.T3.2.8.8.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.8.8.1.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T3.2.8.8.2" class="ltx_td ltx_border_r"></td>
<td id="S5.T3.2.8.8.3" class="ltx_td ltx_align_center"><span id="S5.T3.2.8.8.3.1" class="ltx_text" style="font-size:90%;">76.22</span></td>
<td id="S5.T3.2.8.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.8.8.4.1" class="ltx_text" style="font-size:90%;">68.17</span></td>
<td id="S5.T3.2.8.8.5" class="ltx_td ltx_align_center"><span id="S5.T3.2.8.8.5.1" class="ltx_text" style="font-size:90%;">72.27</span></td>
<td id="S5.T3.2.8.8.6" class="ltx_td ltx_align_center"><span id="S5.T3.2.8.8.6.1" class="ltx_text" style="font-size:90%;">65.16</span></td>
</tr>
<tr id="S5.T3.2.9.9" class="ltx_tr">
<td id="S5.T3.2.9.9.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.9.9.1.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T3.2.9.9.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.9.9.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T3.2.9.9.3" class="ltx_td ltx_align_center"><span id="S5.T3.2.9.9.3.1" class="ltx_text" style="font-size:90%;">76.30</span></td>
<td id="S5.T3.2.9.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.2.9.9.4.1" class="ltx_text" style="font-size:90%;">68.40</span></td>
<td id="S5.T3.2.9.9.5" class="ltx_td ltx_align_center"><span id="S5.T3.2.9.9.5.1" class="ltx_text" style="font-size:90%;">72.47</span></td>
<td id="S5.T3.2.9.9.6" class="ltx_td ltx_align_center"><span id="S5.T3.2.9.9.6.1" class="ltx_text" style="font-size:90%;">65.38</span></td>
</tr>
<tr id="S5.T3.2.10.10" class="ltx_tr">
<td id="S5.T3.2.10.10.1" class="ltx_td ltx_align_left ltx_border_t" colspan="5"><span id="S5.T3.2.10.10.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">PillarNet-34 Backbone</span></td>
<td id="S5.T3.2.10.10.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.2.10.10.3" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S5.T3.2.11.11" class="ltx_tr">
<td id="S5.T3.2.11.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T3.2.11.11.1.1" class="ltx_text" style="font-size:90%;">RPN</span></td>
<td id="S5.T3.2.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.2.11.11.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T3.2.11.11.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T3.2.11.11.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.2.11.11.4.1" class="ltx_text" style="font-size:90%;">75.64</span></td>
<td id="S5.T3.2.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.2.11.11.5.1" class="ltx_text" style="font-size:90%;">67.93</span></td>
<td id="S5.T3.2.11.11.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.2.11.11.6.1" class="ltx_text" style="font-size:90%;">70.76</span></td>
<td id="S5.T3.2.11.11.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.2.11.11.7.1" class="ltx_text" style="font-size:90%;">64.11</span></td>
</tr>
<tr id="S5.T3.2.12.12" class="ltx_tr">
<td id="S5.T3.2.12.12.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T3.2.12.12.1.1" class="ltx_text" style="font-size:90%;">R-CNN</span></td>
<td id="S5.T3.2.12.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T3.2.12.12.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T3.2.12.12.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T3.2.12.12.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T3.2.12.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T3.2.12.12.4.1" class="ltx_text" style="font-size:90%;">76.99</span></td>
<td id="S5.T3.2.12.12.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T3.2.12.12.5.1" class="ltx_text" style="font-size:90%;">69.07</span></td>
<td id="S5.T3.2.12.12.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T3.2.12.12.6.1" class="ltx_text" style="font-size:90%;">73.18</span></td>
<td id="S5.T3.2.12.12.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T3.2.12.12.7.1" class="ltx_text" style="font-size:90%;">66.07</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Effects of each component in our Pillar R-CNN framework on Waymo validation set.
</figcaption>
</figure>
<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Effects of Pillar R-CNN components.</h4>

<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p1.5" class="ltx_p"><a href="#S5.T3" title="In 5.2 Ablation Studies ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a> details how each proposed component influences the accuracy of our Pillar R-CNN on various pillar-based backbones.
Based on the PillarNet-18 backbone, the <math id="S5.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="1^{st}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.1.m1.1a"><msup id="S5.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mn id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">1</mn><mrow id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.2" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.1" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.3" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.2">1</cn><apply id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3"><times id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.2">𝑠</ci><ci id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.1.m1.1c">1^{st}</annotation></semantics></math> and <math id="S5.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="3^{rd}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.2.m2.1a"><msup id="S5.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mn id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">3</mn><mrow id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.1" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.2">3</cn><apply id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3"><times id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.2">𝑟</ci><ci id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.2.m2.1c">3^{rd}</annotation></semantics></math> rows show that compared with the RPN, the RoI refinement stage increases significantly by +1.69% APH/L2 for vehicle detection and +4.41% for pedestrian detection.
The auxiliary supervision on grid points per RoI brings marginal gains shown in <math id="S5.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="4^{th}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.3.m3.1a"><msup id="S5.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mn id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml">4</mn><mrow id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.2" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.1" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.3" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.2">4</cn><apply id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3"><times id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.2">𝑡</ci><ci id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.3.m3.1c">4^{th}</annotation></semantics></math> row while this branch is disabled in inference.
Moreover, introducing FPN into RPN in the <math id="S5.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="2^{nd}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.4.m4.1a"><msup id="S5.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.cmml"><mn id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.2" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml">2</mn><mrow id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.2" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.1" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.3" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.4.m4.1b"><apply id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.2">2</cn><apply id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3"><times id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.2">𝑛</ci><ci id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.4.m4.1c">2^{nd}</annotation></semantics></math> row achieves a large gain of +5.4% APH/L2 on small object detection like pedestrian.
With the proposals computed by RPN with FPN, shown in the <math id="S5.SS2.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="6^{th}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.5.m5.1a"><msup id="S5.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.cmml"><mn id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.2" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml">6</mn><mrow id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.2" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.1" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.3" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.5.m5.1b"><apply id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.2">6</cn><apply id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3"><times id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.2">𝑡</ci><ci id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.5.m5.1c">6^{th}</annotation></semantics></math> row, our Pillar R-CNN achieves a further gain of +2.13% APH/L2 on pedestrian.
In addition, by using the heavy yet powerful PillarNet-34 backbone, the performance of Pillar R-CNN can be further boosted overall categories.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<table id="S5.T4.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.2.1.1" class="ltx_tr">
<th id="S5.T4.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T4.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Stride</span></th>
<th id="S5.T4.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T4.2.1.1.2.1" class="ltx_text" style="font-size:90%;">LC</span></th>
<th id="S5.T4.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T4.2.1.1.3.1" class="ltx_text" style="font-size:90%;">Veh. (APH)</span></th>
<th id="S5.T4.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S5.T4.2.1.1.4.1" class="ltx_text" style="font-size:90%;">Ped. (APH)</span></th>
</tr>
<tr id="S5.T4.2.2.2" class="ltx_tr">
<th id="S5.T4.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T4.2.2.2.1.1" class="ltx_text" style="font-size:90%;">L1</span></th>
<th id="S5.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S5.T4.2.2.2.2.1" class="ltx_text" style="font-size:90%;">L2</span></th>
<th id="S5.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T4.2.2.2.3.1" class="ltx_text" style="font-size:90%;">L1</span></th>
<th id="S5.T4.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T4.2.2.2.4.1" class="ltx_text" style="font-size:90%;">L2</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.2.3.1" class="ltx_tr">
<th id="S5.T4.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T4.2.3.1.1.1" class="ltx_text" style="font-size:90%;">8</span></th>
<th id="S5.T4.2.3.1.2" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<td id="S5.T4.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.3.1.3.1" class="ltx_text" style="font-size:90%;">75.88</span></td>
<td id="S5.T4.2.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.2.3.1.4.1" class="ltx_text" style="font-size:90%;">67.96</span></td>
<td id="S5.T4.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.3.1.5.1" class="ltx_text" style="font-size:90%;">68.93</span></td>
<td id="S5.T4.2.3.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.3.1.6.1" class="ltx_text" style="font-size:90%;">61.44</span></td>
</tr>
<tr id="S5.T4.2.4.2" class="ltx_tr">
<th id="S5.T4.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.2.4.2.1.1" class="ltx_text" style="font-size:90%;">8</span></th>
<th id="S5.T4.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.2.4.2.2.1" class="ltx_text" style="font-size:90%;">✓</span></th>
<td id="S5.T4.2.4.2.3" class="ltx_td ltx_align_center"><span id="S5.T4.2.4.2.3.1" class="ltx_text" style="font-size:90%;">75.96</span></td>
<td id="S5.T4.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.2.4.2.4.1" class="ltx_text" style="font-size:90%;">68.08</span></td>
<td id="S5.T4.2.4.2.5" class="ltx_td ltx_align_center"><span id="S5.T4.2.4.2.5.1" class="ltx_text" style="font-size:90%;">68.97</span></td>
<td id="S5.T4.2.4.2.6" class="ltx_td ltx_align_center"><span id="S5.T4.2.4.2.6.1" class="ltx_text" style="font-size:90%;">61.48</span></td>
</tr>
<tr id="S5.T4.2.5.3" class="ltx_tr">
<th id="S5.T4.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.2.5.3.1.1" class="ltx_text" style="font-size:90%;">4</span></th>
<th id="S5.T4.2.5.3.2" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S5.T4.2.5.3.3" class="ltx_td ltx_align_center"><span id="S5.T4.2.5.3.3.1" class="ltx_text" style="font-size:90%;">75.77</span></td>
<td id="S5.T4.2.5.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.2.5.3.4.1" class="ltx_text" style="font-size:90%;">67.89</span></td>
<td id="S5.T4.2.5.3.5" class="ltx_td ltx_align_center"><span id="S5.T4.2.5.3.5.1" class="ltx_text" style="font-size:90%;">68.85</span></td>
<td id="S5.T4.2.5.3.6" class="ltx_td ltx_align_center"><span id="S5.T4.2.5.3.6.1" class="ltx_text" style="font-size:90%;">61.32</span></td>
</tr>
<tr id="S5.T4.2.6.4" class="ltx_tr">
<th id="S5.T4.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.2.6.4.1.1" class="ltx_text" style="font-size:90%;">4</span></th>
<th id="S5.T4.2.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.2.6.4.2.1" class="ltx_text" style="font-size:90%;">✓</span></th>
<td id="S5.T4.2.6.4.3" class="ltx_td ltx_align_center"><span id="S5.T4.2.6.4.3.1" class="ltx_text" style="font-size:90%;">76.55</span></td>
<td id="S5.T4.2.6.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.2.6.4.4.1" class="ltx_text" style="font-size:90%;">68.64</span></td>
<td id="S5.T4.2.6.4.5" class="ltx_td ltx_align_center"><span id="S5.T4.2.6.4.5.1" class="ltx_text" style="font-size:90%;">70.21</span></td>
<td id="S5.T4.2.6.4.6" class="ltx_td ltx_align_center"><span id="S5.T4.2.6.4.6.1" class="ltx_text" style="font-size:90%;">62.46</span></td>
</tr>
<tr id="S5.T4.2.7.5" class="ltx_tr">
<th id="S5.T4.2.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T4.2.7.5.1.1" class="ltx_text" style="font-size:90%;">2</span></th>
<th id="S5.T4.2.7.5.2" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S5.T4.2.7.5.3" class="ltx_td ltx_align_center"><span id="S5.T4.2.7.5.3.1" class="ltx_text" style="font-size:90%;">76.16</span></td>
<td id="S5.T4.2.7.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.2.7.5.4.1" class="ltx_text" style="font-size:90%;">68.30</span></td>
<td id="S5.T4.2.7.5.5" class="ltx_td ltx_align_center"><span id="S5.T4.2.7.5.5.1" class="ltx_text" style="font-size:90%;">69.97</span></td>
<td id="S5.T4.2.7.5.6" class="ltx_td ltx_align_center"><span id="S5.T4.2.7.5.6.1" class="ltx_text" style="font-size:90%;">62.16</span></td>
</tr>
<tr id="S5.T4.2.8.6" class="ltx_tr">
<th id="S5.T4.2.8.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r"><span id="S5.T4.2.8.6.1.1" class="ltx_text" style="font-size:90%;">2</span></th>
<th id="S5.T4.2.8.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r"><span id="S5.T4.2.8.6.2.1" class="ltx_text" style="font-size:90%;">✓</span></th>
<td id="S5.T4.2.8.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.2.8.6.3.1" class="ltx_text" style="font-size:90%;">76.49</span></td>
<td id="S5.T4.2.8.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T4.2.8.6.4.1" class="ltx_text" style="font-size:90%;">68.55</span></td>
<td id="S5.T4.2.8.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.2.8.6.5.1" class="ltx_text" style="font-size:90%;">70.82</span></td>
<td id="S5.T4.2.8.6.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.2.8.6.6.1" class="ltx_text" style="font-size:90%;">63.13</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Effects of the used pooling map resolutions and lateral connection layer in our Pillar R-CNN framework on Waymo validation set.</figcaption>
</figure>
<figure id="S5.T5" class="ltx_table">
<table id="S5.T5.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T5.6.7.1" class="ltx_tr">
<th id="S5.T5.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T5.6.7.1.1.1" class="ltx_text" style="font-size:90%;">Grid size</span></th>
<th id="S5.T5.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T5.6.7.1.2.1" class="ltx_text" style="font-size:90%;">Veh. (APH)</span></th>
<th id="S5.T5.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S5.T5.6.7.1.3.1" class="ltx_text" style="font-size:90%;">Ped. (APH)</span></th>
</tr>
<tr id="S5.T5.6.8.2" class="ltx_tr">
<th id="S5.T5.6.8.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T5.6.8.2.1.1" class="ltx_text" style="font-size:90%;">L1</span></th>
<th id="S5.T5.6.8.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S5.T5.6.8.2.2.1" class="ltx_text" style="font-size:90%;">L2</span></th>
<th id="S5.T5.6.8.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T5.6.8.2.3.1" class="ltx_text" style="font-size:90%;">L1</span></th>
<th id="S5.T5.6.8.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T5.6.8.2.4.1" class="ltx_text" style="font-size:90%;">L2</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T5.1.1" class="ltx_tr">
<th id="S5.T5.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><math id="S5.T5.1.1.1.m1.1" class="ltx_Math" alttext="4\times 4" display="inline"><semantics id="S5.T5.1.1.1.m1.1a"><mrow id="S5.T5.1.1.1.m1.1.1" xref="S5.T5.1.1.1.m1.1.1.cmml"><mn mathsize="90%" id="S5.T5.1.1.1.m1.1.1.2" xref="S5.T5.1.1.1.m1.1.1.2.cmml">4</mn><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S5.T5.1.1.1.m1.1.1.1" xref="S5.T5.1.1.1.m1.1.1.1.cmml">×</mo><mn mathsize="90%" id="S5.T5.1.1.1.m1.1.1.3" xref="S5.T5.1.1.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.m1.1b"><apply id="S5.T5.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.m1.1.1"><times id="S5.T5.1.1.1.m1.1.1.1.cmml" xref="S5.T5.1.1.1.m1.1.1.1"></times><cn type="integer" id="S5.T5.1.1.1.m1.1.1.2.cmml" xref="S5.T5.1.1.1.m1.1.1.2">4</cn><cn type="integer" id="S5.T5.1.1.1.m1.1.1.3.cmml" xref="S5.T5.1.1.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.1.1.1.m1.1c">4\times 4</annotation></semantics></math></th>
<td id="S5.T5.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.1.2.1" class="ltx_text" style="font-size:90%;">75.58</span></td>
<td id="S5.T5.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T5.1.1.3.1" class="ltx_text" style="font-size:90%;">67.63</span></td>
<td id="S5.T5.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.1.4.1" class="ltx_text" style="font-size:90%;">69.14</span></td>
<td id="S5.T5.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.1.5.1" class="ltx_text" style="font-size:90%;">61.67</span></td>
</tr>
<tr id="S5.T5.2.2" class="ltx_tr">
<th id="S5.T5.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><math id="S5.T5.2.2.1.m1.1" class="ltx_Math" alttext="5\times 5" display="inline"><semantics id="S5.T5.2.2.1.m1.1a"><mrow id="S5.T5.2.2.1.m1.1.1" xref="S5.T5.2.2.1.m1.1.1.cmml"><mn mathsize="90%" id="S5.T5.2.2.1.m1.1.1.2" xref="S5.T5.2.2.1.m1.1.1.2.cmml">5</mn><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S5.T5.2.2.1.m1.1.1.1" xref="S5.T5.2.2.1.m1.1.1.1.cmml">×</mo><mn mathsize="90%" id="S5.T5.2.2.1.m1.1.1.3" xref="S5.T5.2.2.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.2.2.1.m1.1b"><apply id="S5.T5.2.2.1.m1.1.1.cmml" xref="S5.T5.2.2.1.m1.1.1"><times id="S5.T5.2.2.1.m1.1.1.1.cmml" xref="S5.T5.2.2.1.m1.1.1.1"></times><cn type="integer" id="S5.T5.2.2.1.m1.1.1.2.cmml" xref="S5.T5.2.2.1.m1.1.1.2">5</cn><cn type="integer" id="S5.T5.2.2.1.m1.1.1.3.cmml" xref="S5.T5.2.2.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.2.1.m1.1c">5\times 5</annotation></semantics></math></th>
<td id="S5.T5.2.2.2" class="ltx_td ltx_align_center"><span id="S5.T5.2.2.2.1" class="ltx_text" style="font-size:90%;">76.11</span></td>
<td id="S5.T5.2.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.2.2.3.1" class="ltx_text" style="font-size:90%;">68.19</span></td>
<td id="S5.T5.2.2.4" class="ltx_td ltx_align_center"><span id="S5.T5.2.2.4.1" class="ltx_text" style="font-size:90%;">69.77</span></td>
<td id="S5.T5.2.2.5" class="ltx_td ltx_align_center"><span id="S5.T5.2.2.5.1" class="ltx_text" style="font-size:90%;">62.17</span></td>
</tr>
<tr id="S5.T5.3.3" class="ltx_tr">
<th id="S5.T5.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><math id="S5.T5.3.3.1.m1.1" class="ltx_Math" alttext="6\times 6" display="inline"><semantics id="S5.T5.3.3.1.m1.1a"><mrow id="S5.T5.3.3.1.m1.1.1" xref="S5.T5.3.3.1.m1.1.1.cmml"><mn mathsize="90%" id="S5.T5.3.3.1.m1.1.1.2" xref="S5.T5.3.3.1.m1.1.1.2.cmml">6</mn><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S5.T5.3.3.1.m1.1.1.1" xref="S5.T5.3.3.1.m1.1.1.1.cmml">×</mo><mn mathsize="90%" id="S5.T5.3.3.1.m1.1.1.3" xref="S5.T5.3.3.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.3.3.1.m1.1b"><apply id="S5.T5.3.3.1.m1.1.1.cmml" xref="S5.T5.3.3.1.m1.1.1"><times id="S5.T5.3.3.1.m1.1.1.1.cmml" xref="S5.T5.3.3.1.m1.1.1.1"></times><cn type="integer" id="S5.T5.3.3.1.m1.1.1.2.cmml" xref="S5.T5.3.3.1.m1.1.1.2">6</cn><cn type="integer" id="S5.T5.3.3.1.m1.1.1.3.cmml" xref="S5.T5.3.3.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.3.1.m1.1c">6\times 6</annotation></semantics></math></th>
<td id="S5.T5.3.3.2" class="ltx_td ltx_align_center"><span id="S5.T5.3.3.2.1" class="ltx_text" style="font-size:90%;">76.32</span></td>
<td id="S5.T5.3.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.3.3.3.1" class="ltx_text" style="font-size:90%;">68.37</span></td>
<td id="S5.T5.3.3.4" class="ltx_td ltx_align_center"><span id="S5.T5.3.3.4.1" class="ltx_text" style="font-size:90%;">70.11</span></td>
<td id="S5.T5.3.3.5" class="ltx_td ltx_align_center"><span id="S5.T5.3.3.5.1" class="ltx_text" style="font-size:90%;">62.40</span></td>
</tr>
<tr id="S5.T5.4.4" class="ltx_tr">
<th id="S5.T5.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><math id="S5.T5.4.4.1.m1.1" class="ltx_Math" alttext="7\times 7" display="inline"><semantics id="S5.T5.4.4.1.m1.1a"><mrow id="S5.T5.4.4.1.m1.1.1" xref="S5.T5.4.4.1.m1.1.1.cmml"><mn mathsize="90%" id="S5.T5.4.4.1.m1.1.1.2" xref="S5.T5.4.4.1.m1.1.1.2.cmml">7</mn><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S5.T5.4.4.1.m1.1.1.1" xref="S5.T5.4.4.1.m1.1.1.1.cmml">×</mo><mn mathsize="90%" id="S5.T5.4.4.1.m1.1.1.3" xref="S5.T5.4.4.1.m1.1.1.3.cmml">7</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.4.4.1.m1.1b"><apply id="S5.T5.4.4.1.m1.1.1.cmml" xref="S5.T5.4.4.1.m1.1.1"><times id="S5.T5.4.4.1.m1.1.1.1.cmml" xref="S5.T5.4.4.1.m1.1.1.1"></times><cn type="integer" id="S5.T5.4.4.1.m1.1.1.2.cmml" xref="S5.T5.4.4.1.m1.1.1.2">7</cn><cn type="integer" id="S5.T5.4.4.1.m1.1.1.3.cmml" xref="S5.T5.4.4.1.m1.1.1.3">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.4.1.m1.1c">7\times 7</annotation></semantics></math></th>
<td id="S5.T5.4.4.2" class="ltx_td ltx_align_center"><span id="S5.T5.4.4.2.1" class="ltx_text" style="font-size:90%;">76.55</span></td>
<td id="S5.T5.4.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.4.4.3.1" class="ltx_text" style="font-size:90%;">68.64</span></td>
<td id="S5.T5.4.4.4" class="ltx_td ltx_align_center"><span id="S5.T5.4.4.4.1" class="ltx_text" style="font-size:90%;">70.21</span></td>
<td id="S5.T5.4.4.5" class="ltx_td ltx_align_center"><span id="S5.T5.4.4.5.1" class="ltx_text" style="font-size:90%;">62.46</span></td>
</tr>
<tr id="S5.T5.5.5" class="ltx_tr">
<th id="S5.T5.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><math id="S5.T5.5.5.1.m1.1" class="ltx_Math" alttext="8\times 8" display="inline"><semantics id="S5.T5.5.5.1.m1.1a"><mrow id="S5.T5.5.5.1.m1.1.1" xref="S5.T5.5.5.1.m1.1.1.cmml"><mn mathsize="90%" id="S5.T5.5.5.1.m1.1.1.2" xref="S5.T5.5.5.1.m1.1.1.2.cmml">8</mn><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S5.T5.5.5.1.m1.1.1.1" xref="S5.T5.5.5.1.m1.1.1.1.cmml">×</mo><mn mathsize="90%" id="S5.T5.5.5.1.m1.1.1.3" xref="S5.T5.5.5.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.5.5.1.m1.1b"><apply id="S5.T5.5.5.1.m1.1.1.cmml" xref="S5.T5.5.5.1.m1.1.1"><times id="S5.T5.5.5.1.m1.1.1.1.cmml" xref="S5.T5.5.5.1.m1.1.1.1"></times><cn type="integer" id="S5.T5.5.5.1.m1.1.1.2.cmml" xref="S5.T5.5.5.1.m1.1.1.2">8</cn><cn type="integer" id="S5.T5.5.5.1.m1.1.1.3.cmml" xref="S5.T5.5.5.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.5.5.1.m1.1c">8\times 8</annotation></semantics></math></th>
<td id="S5.T5.5.5.2" class="ltx_td ltx_align_center"><span id="S5.T5.5.5.2.1" class="ltx_text" style="font-size:90%;">76.90</span></td>
<td id="S5.T5.5.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.5.5.3.1" class="ltx_text" style="font-size:90%;">68.96</span></td>
<td id="S5.T5.5.5.4" class="ltx_td ltx_align_center"><span id="S5.T5.5.5.4.1" class="ltx_text" style="font-size:90%;">70.29</span></td>
<td id="S5.T5.5.5.5" class="ltx_td ltx_align_center"><span id="S5.T5.5.5.5.1" class="ltx_text" style="font-size:90%;">62.69</span></td>
</tr>
<tr id="S5.T5.6.6" class="ltx_tr">
<th id="S5.T5.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r"><math id="S5.T5.6.6.1.m1.1" class="ltx_Math" alttext="9\times 9" display="inline"><semantics id="S5.T5.6.6.1.m1.1a"><mrow id="S5.T5.6.6.1.m1.1.1" xref="S5.T5.6.6.1.m1.1.1.cmml"><mn mathsize="90%" id="S5.T5.6.6.1.m1.1.1.2" xref="S5.T5.6.6.1.m1.1.1.2.cmml">9</mn><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S5.T5.6.6.1.m1.1.1.1" xref="S5.T5.6.6.1.m1.1.1.1.cmml">×</mo><mn mathsize="90%" id="S5.T5.6.6.1.m1.1.1.3" xref="S5.T5.6.6.1.m1.1.1.3.cmml">9</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.6.6.1.m1.1b"><apply id="S5.T5.6.6.1.m1.1.1.cmml" xref="S5.T5.6.6.1.m1.1.1"><times id="S5.T5.6.6.1.m1.1.1.1.cmml" xref="S5.T5.6.6.1.m1.1.1.1"></times><cn type="integer" id="S5.T5.6.6.1.m1.1.1.2.cmml" xref="S5.T5.6.6.1.m1.1.1.2">9</cn><cn type="integer" id="S5.T5.6.6.1.m1.1.1.3.cmml" xref="S5.T5.6.6.1.m1.1.1.3">9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.6.6.1.m1.1c">9\times 9</annotation></semantics></math></th>
<td id="S5.T5.6.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T5.6.6.2.1" class="ltx_text" style="font-size:90%;">76.70</span></td>
<td id="S5.T5.6.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T5.6.6.3.1" class="ltx_text" style="font-size:90%;">68.78</span></td>
<td id="S5.T5.6.6.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T5.6.6.4.1" class="ltx_text" style="font-size:90%;">70.11</span></td>
<td id="S5.T5.6.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T5.6.6.5.1" class="ltx_text" style="font-size:90%;">62.47</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Effects of the different grid sizes in our proposed RoI-grid pooling module on Waymo validation set.</figcaption>
</figure>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Effects of lateral connection layer.</h4>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p1.6" class="ltx_p">In <a href="#S5.T4" title="In Effects of Pillar R-CNN components. ‣ 5.2 Ablation Studies ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, we investigate the effects of the lateral connection layer used to build the pooling map.
The <math id="S5.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="1^{st}" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.1.m1.1a"><msup id="S5.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">1</mn><mrow id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.1" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.2">1</cn><apply id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3"><times id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.2">𝑠</ci><ci id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.1.m1.1c">1^{st}</annotation></semantics></math>, <math id="S5.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="3^{rd}" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.2.m2.1a"><msup id="S5.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mn id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">3</mn><mrow id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.2" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.1" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.3" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.2">3</cn><apply id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3"><times id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.2">𝑟</ci><ci id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.2.m2.1c">3^{rd}</annotation></semantics></math> and <math id="S5.SS2.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="5^{th}" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.3.m3.1a"><msup id="S5.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.cmml"><mn id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.2" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml">5</mn><mrow id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.2" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.1" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.3.m3.1b"><apply id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.2">5</cn><apply id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3"><times id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.2">𝑡</ci><ci id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.3.m3.1c">5^{th}</annotation></semantics></math> rows of <a href="#S5.T4" title="In Effects of Pillar R-CNN components. ‣ 5.2 Ablation Studies ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a> show that pooling at fine resolutions alone does not improve performance.
It is because the upsampled top-down map has rich semantics but lacks precise spatial information.
The <math id="S5.SS2.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="2^{nd}" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.4.m4.1a"><msup id="S5.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.cmml"><mn id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.2" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.2.cmml">2</mn><mrow id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.2" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.1" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.3" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.4.m4.1b"><apply id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.2">2</cn><apply id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3"><times id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.2">𝑛</ci><ci id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.4.m4.1c">2^{nd}</annotation></semantics></math>, <math id="S5.SS2.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="4^{th}" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.5.m5.1a"><msup id="S5.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.cmml"><mn id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.cmml">4</mn><mrow id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.1" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.3" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.5.m5.1b"><apply id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2">4</cn><apply id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3"><times id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.2">𝑡</ci><ci id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.5.m5.1c">4^{th}</annotation></semantics></math> and <math id="S5.SS2.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="6^{th}" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.6.m6.1a"><msup id="S5.SS2.SSS0.Px2.p1.6.m6.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.cmml"><mn id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml">6</mn><mrow id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.6.m6.1b"><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2">6</cn><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3"><times id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.2">𝑡</ci><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.6.m6.1c">6^{th}</annotation></semantics></math> rows of <a href="#S5.T4" title="In Effects of Pillar R-CNN components. ‣ 5.2 Ablation Studies ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a> reveal that the designed lateral connection layer can encode high-level semantic and low-level geometry at various scales for boosting 3D detection performance.
Though simple, the lateral connection layer provides good semantic coverage on the sparse bottom-up map with mostly zeros.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Effects of pooling map resolution.</h4>

<div id="S5.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px3.p1.5" class="ltx_p"><a href="#S5.T4" title="In Effects of Pillar R-CNN components. ‣ 5.2 Ablation Studies ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a> illustrates the effects of the pooling map resolution with different spatial sizes constructed by our lateral connection module.
The <math id="S5.SS2.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="2^{nd}" display="inline"><semantics id="S5.SS2.SSS0.Px3.p1.1.m1.1a"><msup id="S5.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><mn id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml">2</mn><mrow id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.2" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.1" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.2">2</cn><apply id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3"><times id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.2">𝑛</ci><ci id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px3.p1.1.m1.1c">2^{nd}</annotation></semantics></math>, <math id="S5.SS2.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="4^{th}" display="inline"><semantics id="S5.SS2.SSS0.Px3.p1.2.m2.1a"><msup id="S5.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.cmml"><mn id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.2" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml">4</mn><mrow id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.2" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.1" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.3" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px3.p1.2.m2.1b"><apply id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.2">4</cn><apply id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3"><times id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.2">𝑡</ci><ci id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px3.p1.2.m2.1c">4^{th}</annotation></semantics></math> and <math id="S5.SS2.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="6^{th}" display="inline"><semantics id="S5.SS2.SSS0.Px3.p1.3.m3.1a"><msup id="S5.SS2.SSS0.Px3.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.cmml"><mn id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.2" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.2.cmml">6</mn><mrow id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.2" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.1" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px3.p1.3.m3.1b"><apply id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.2">6</cn><apply id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3"><times id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.2">𝑡</ci><ci id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px3.p1.3.m3.1c">6^{th}</annotation></semantics></math> rows of <a href="#S5.T4" title="In Effects of Pillar R-CNN components. ‣ 5.2 Ablation Studies ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a> show that the finer resolution of the pooling map achieves better performance, especially for small objects.
However, a finer pooling map takes more additional memory/computation costs.
Therefore, we use the <math id="S5.SS2.SSS0.Px3.p1.4.m4.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S5.SS2.SSS0.Px3.p1.4.m4.1a"><mrow id="S5.SS2.SSS0.Px3.p1.4.m4.1b"><mn id="S5.SS2.SSS0.Px3.p1.4.m4.1.1">4</mn><mo lspace="0.222em" id="S5.SS2.SSS0.Px3.p1.4.m4.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px3.p1.4.m4.1c">4\times</annotation></semantics></math> stridden pooling map as a trade-off throughout experiments, because <math id="S5.SS2.SSS0.Px3.p1.5.m5.1" class="ltx_math_unparsed" alttext="2\times" display="inline"><semantics id="S5.SS2.SSS0.Px3.p1.5.m5.1a"><mrow id="S5.SS2.SSS0.Px3.p1.5.m5.1b"><mn id="S5.SS2.SSS0.Px3.p1.5.m5.1.1">2</mn><mo lspace="0.222em" id="S5.SS2.SSS0.Px3.p1.5.m5.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px3.p1.5.m5.1c">2\times</annotation></semantics></math> or finer pooling maps consume too much memory with marginal benefits.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Effects of grid size per RoI.</h4>

<div id="S5.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px4.p1.3" class="ltx_p"><a href="#S5.T5" title="In Effects of Pillar R-CNN components. ‣ 5.2 Ablation Studies ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a> shows the impact of different grid sizes within RoI-grid pooling module on detection performance. We can see that the accuracy consistently increases as the grid sizes from <math id="S5.SS2.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="4\times 4" display="inline"><semantics id="S5.SS2.SSS0.Px4.p1.1.m1.1a"><mrow id="S5.SS2.SSS0.Px4.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1.cmml"><mn id="S5.SS2.SSS0.Px4.p1.1.m1.1.1.2" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1.2.cmml">4</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.SSS0.Px4.p1.1.m1.1.1.1" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS2.SSS0.Px4.p1.1.m1.1.1.3" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.1.m1.1b"><apply id="S5.SS2.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1"><times id="S5.SS2.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS2.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1.2">4</cn><cn type="integer" id="S5.SS2.SSS0.Px4.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS0.Px4.p1.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.1.m1.1c">4\times 4</annotation></semantics></math> to <math id="S5.SS2.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="8\times 8" display="inline"><semantics id="S5.SS2.SSS0.Px4.p1.2.m2.1a"><mrow id="S5.SS2.SSS0.Px4.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1.cmml"><mn id="S5.SS2.SSS0.Px4.p1.2.m2.1.1.2" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1.2.cmml">8</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.SSS0.Px4.p1.2.m2.1.1.1" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS2.SSS0.Px4.p1.2.m2.1.1.3" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.2.m2.1b"><apply id="S5.SS2.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1"><times id="S5.SS2.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1.1"></times><cn type="integer" id="S5.SS2.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1.2">8</cn><cn type="integer" id="S5.SS2.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS0.Px4.p1.2.m2.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.2.m2.1c">8\times 8</annotation></semantics></math>, but a larger grid size degrades performance slightly.
The reason can be explained by that R-CNN with larger grid sizes has more learnable parameters in the first fully-connected layer and thus easily over-fits the training set.
Here, we adopt the grid size of <math id="S5.SS2.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="7\times 7" display="inline"><semantics id="S5.SS2.SSS0.Px4.p1.3.m3.1a"><mrow id="S5.SS2.SSS0.Px4.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1.cmml"><mn id="S5.SS2.SSS0.Px4.p1.3.m3.1.1.2" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1.2.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.SSS0.Px4.p1.3.m3.1.1.1" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1.1.cmml">×</mo><mn id="S5.SS2.SSS0.Px4.p1.3.m3.1.1.3" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1.3.cmml">7</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px4.p1.3.m3.1b"><apply id="S5.SS2.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1"><times id="S5.SS2.SSS0.Px4.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1.1"></times><cn type="integer" id="S5.SS2.SSS0.Px4.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1.2">7</cn><cn type="integer" id="S5.SS2.SSS0.Px4.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS0.Px4.p1.3.m3.1.1.3">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px4.p1.3.m3.1c">7\times 7</annotation></semantics></math> to keep the same setting with its 2D counterparts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<table id="S5.T6.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T6.4.5.1" class="ltx_tr">
<th id="S5.T6.4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" colspan="4"><span id="S5.T6.4.5.1.1.1" class="ltx_text" style="font-size:90%;">Bottom-up features</span></th>
<td id="S5.T6.4.5.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T6.4.5.1.2.1" class="ltx_text" style="font-size:90%;">Veh. (APH)</span></td>
<td id="S5.T6.4.5.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T6.4.5.1.3.1" class="ltx_text" style="font-size:90%;">Ped. (APH)</span></td>
</tr>
<tr id="S5.T6.4.4" class="ltx_tr">
<th id="S5.T6.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S5.T6.1.1.1.m1.1" class="ltx_Math" alttext="C_{1}" display="inline"><semantics id="S5.T6.1.1.1.m1.1a"><msub id="S5.T6.1.1.1.m1.1.1" xref="S5.T6.1.1.1.m1.1.1.cmml"><mi mathsize="90%" id="S5.T6.1.1.1.m1.1.1.2" xref="S5.T6.1.1.1.m1.1.1.2.cmml">C</mi><mn mathsize="90%" id="S5.T6.1.1.1.m1.1.1.3" xref="S5.T6.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T6.1.1.1.m1.1b"><apply id="S5.T6.1.1.1.m1.1.1.cmml" xref="S5.T6.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T6.1.1.1.m1.1.1.1.cmml" xref="S5.T6.1.1.1.m1.1.1">subscript</csymbol><ci id="S5.T6.1.1.1.m1.1.1.2.cmml" xref="S5.T6.1.1.1.m1.1.1.2">𝐶</ci><cn type="integer" id="S5.T6.1.1.1.m1.1.1.3.cmml" xref="S5.T6.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.1.1.1.m1.1c">C_{1}</annotation></semantics></math></th>
<th id="S5.T6.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S5.T6.2.2.2.m1.1" class="ltx_Math" alttext="C_{2}" display="inline"><semantics id="S5.T6.2.2.2.m1.1a"><msub id="S5.T6.2.2.2.m1.1.1" xref="S5.T6.2.2.2.m1.1.1.cmml"><mi mathsize="90%" id="S5.T6.2.2.2.m1.1.1.2" xref="S5.T6.2.2.2.m1.1.1.2.cmml">C</mi><mn mathsize="90%" id="S5.T6.2.2.2.m1.1.1.3" xref="S5.T6.2.2.2.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T6.2.2.2.m1.1b"><apply id="S5.T6.2.2.2.m1.1.1.cmml" xref="S5.T6.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S5.T6.2.2.2.m1.1.1.1.cmml" xref="S5.T6.2.2.2.m1.1.1">subscript</csymbol><ci id="S5.T6.2.2.2.m1.1.1.2.cmml" xref="S5.T6.2.2.2.m1.1.1.2">𝐶</ci><cn type="integer" id="S5.T6.2.2.2.m1.1.1.3.cmml" xref="S5.T6.2.2.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.2.2.m1.1c">C_{2}</annotation></semantics></math></th>
<td id="S5.T6.3.3.3" class="ltx_td ltx_align_center"><math id="S5.T6.3.3.3.m1.1" class="ltx_Math" alttext="C_{3}" display="inline"><semantics id="S5.T6.3.3.3.m1.1a"><msub id="S5.T6.3.3.3.m1.1.1" xref="S5.T6.3.3.3.m1.1.1.cmml"><mi mathsize="90%" id="S5.T6.3.3.3.m1.1.1.2" xref="S5.T6.3.3.3.m1.1.1.2.cmml">C</mi><mn mathsize="90%" id="S5.T6.3.3.3.m1.1.1.3" xref="S5.T6.3.3.3.m1.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T6.3.3.3.m1.1b"><apply id="S5.T6.3.3.3.m1.1.1.cmml" xref="S5.T6.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S5.T6.3.3.3.m1.1.1.1.cmml" xref="S5.T6.3.3.3.m1.1.1">subscript</csymbol><ci id="S5.T6.3.3.3.m1.1.1.2.cmml" xref="S5.T6.3.3.3.m1.1.1.2">𝐶</ci><cn type="integer" id="S5.T6.3.3.3.m1.1.1.3.cmml" xref="S5.T6.3.3.3.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.3.3.3.m1.1c">C_{3}</annotation></semantics></math></td>
<td id="S5.T6.4.4.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T6.4.4.4.m1.1" class="ltx_Math" alttext="C_{4}" display="inline"><semantics id="S5.T6.4.4.4.m1.1a"><msub id="S5.T6.4.4.4.m1.1.1" xref="S5.T6.4.4.4.m1.1.1.cmml"><mi mathsize="90%" id="S5.T6.4.4.4.m1.1.1.2" xref="S5.T6.4.4.4.m1.1.1.2.cmml">C</mi><mn mathsize="90%" id="S5.T6.4.4.4.m1.1.1.3" xref="S5.T6.4.4.4.m1.1.1.3.cmml">4</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T6.4.4.4.m1.1b"><apply id="S5.T6.4.4.4.m1.1.1.cmml" xref="S5.T6.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S5.T6.4.4.4.m1.1.1.1.cmml" xref="S5.T6.4.4.4.m1.1.1">subscript</csymbol><ci id="S5.T6.4.4.4.m1.1.1.2.cmml" xref="S5.T6.4.4.4.m1.1.1.2">𝐶</ci><cn type="integer" id="S5.T6.4.4.4.m1.1.1.3.cmml" xref="S5.T6.4.4.4.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.4.4.4.m1.1c">C_{4}</annotation></semantics></math></td>
<td id="S5.T6.4.4.5" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.5.1" class="ltx_text" style="font-size:90%;">L1</span></td>
<td id="S5.T6.4.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.4.4.6.1" class="ltx_text" style="font-size:90%;">L2</span></td>
<td id="S5.T6.4.4.7" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.7.1" class="ltx_text" style="font-size:90%;">L1</span></td>
<td id="S5.T6.4.4.8" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.8.1" class="ltx_text" style="font-size:90%;">L2</span></td>
</tr>
<tr id="S5.T6.4.6.2" class="ltx_tr">
<th id="S5.T6.4.6.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S5.T6.4.6.2.2" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<td id="S5.T6.4.6.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.4.6.2.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T6.4.6.2.4" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T6.4.6.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.4.6.2.5.1" class="ltx_text" style="font-size:90%;">76.55</span></td>
<td id="S5.T6.4.6.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.6.2.6.1" class="ltx_text" style="font-size:90%;">68.64</span></td>
<td id="S5.T6.4.6.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.4.6.2.7.1" class="ltx_text" style="font-size:90%;">70.21</span></td>
<td id="S5.T6.4.6.2.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.4.6.2.8.1" class="ltx_text" style="font-size:90%;">62.46</span></td>
</tr>
<tr id="S5.T6.4.7.3" class="ltx_tr">
<th id="S5.T6.4.7.3.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S5.T6.4.7.3.2" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S5.T6.4.7.3.3" class="ltx_td ltx_align_center"><span id="S5.T6.4.7.3.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T6.4.7.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.4.7.3.4.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T6.4.7.3.5" class="ltx_td ltx_align_center"><span id="S5.T6.4.7.3.5.1" class="ltx_text" style="font-size:90%;">76.34</span></td>
<td id="S5.T6.4.7.3.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.4.7.3.6.1" class="ltx_text" style="font-size:90%;">68.45</span></td>
<td id="S5.T6.4.7.3.7" class="ltx_td ltx_align_center"><span id="S5.T6.4.7.3.7.1" class="ltx_text" style="font-size:90%;">70.15</span></td>
<td id="S5.T6.4.7.3.8" class="ltx_td ltx_align_center"><span id="S5.T6.4.7.3.8.1" class="ltx_text" style="font-size:90%;">62.39</span></td>
</tr>
<tr id="S5.T6.4.8.4" class="ltx_tr">
<th id="S5.T6.4.8.4.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S5.T6.4.8.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T6.4.8.4.2.1" class="ltx_text" style="font-size:90%;">✓</span></th>
<td id="S5.T6.4.8.4.3" class="ltx_td ltx_align_center"><span id="S5.T6.4.8.4.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T6.4.8.4.4" class="ltx_td ltx_border_r"></td>
<td id="S5.T6.4.8.4.5" class="ltx_td ltx_align_center"><span id="S5.T6.4.8.4.5.1" class="ltx_text" style="font-size:90%;">76.75</span></td>
<td id="S5.T6.4.8.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.4.8.4.6.1" class="ltx_text" style="font-size:90%;">68.82</span></td>
<td id="S5.T6.4.8.4.7" class="ltx_td ltx_align_center"><span id="S5.T6.4.8.4.7.1" class="ltx_text" style="font-size:90%;">70.41</span></td>
<td id="S5.T6.4.8.4.8" class="ltx_td ltx_align_center"><span id="S5.T6.4.8.4.8.1" class="ltx_text" style="font-size:90%;">62.65</span></td>
</tr>
<tr id="S5.T6.4.9.5" class="ltx_tr">
<th id="S5.T6.4.9.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb"><span id="S5.T6.4.9.5.1.1" class="ltx_text" style="font-size:90%;">✓</span></th>
<th id="S5.T6.4.9.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb"><span id="S5.T6.4.9.5.2.1" class="ltx_text" style="font-size:90%;">✓</span></th>
<td id="S5.T6.4.9.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.4.9.5.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T6.4.9.5.4" class="ltx_td ltx_border_bb ltx_border_r"></td>
<td id="S5.T6.4.9.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.4.9.5.5.1" class="ltx_text" style="font-size:90%;">76.48</span></td>
<td id="S5.T6.4.9.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T6.4.9.5.6.1" class="ltx_text" style="font-size:90%;">68.54</span></td>
<td id="S5.T6.4.9.5.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.4.9.5.7.1" class="ltx_text" style="font-size:90%;">70.36</span></td>
<td id="S5.T6.4.9.5.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.4.9.5.8.1" class="ltx_text" style="font-size:90%;">62.60</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>Effects of additional bottom-up features for constructing <math id="S5.T6.6.m1.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S5.T6.6.m1.1b"><mrow id="S5.T6.6.m1.1c"><mn id="S5.T6.6.m1.1.1">4</mn><mo lspace="0.222em" id="S5.T6.6.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S5.T6.6.m1.1d">4\times</annotation></semantics></math> stridden pooling map on Waymo validation set.</figcaption>
</figure>
</section>
<section id="S5.SS2.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Effects of additional bottom-up features for pooling.</h4>

<div id="S5.SS2.SSS0.Px5.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px5.p1.5" class="ltx_p">Through our designed lateral connection, the built pooling map can integrate additional multi-scale features from the bottom-up pathway.
The <math id="S5.SS2.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="2^{nd}" display="inline"><semantics id="S5.SS2.SSS0.Px5.p1.1.m1.1a"><msup id="S5.SS2.SSS0.Px5.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.cmml"><mn id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.2" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.2.cmml">2</mn><mrow id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.2" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.1" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.3" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px5.p1.1.m1.1b"><apply id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.2">2</cn><apply id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3"><times id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.2">𝑛</ci><ci id="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px5.p1.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px5.p1.1.m1.1c">2^{nd}</annotation></semantics></math> row of <a href="#S5.T6" title="In Effects of grid size per RoI. ‣ 5.2 Ablation Studies ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">6</span></a> shows that combining coarser <math id="S5.SS2.SSS0.Px5.p1.2.m2.1" class="ltx_Math" alttext="C_{4}" display="inline"><semantics id="S5.SS2.SSS0.Px5.p1.2.m2.1a"><msub id="S5.SS2.SSS0.Px5.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px5.p1.2.m2.1.1.cmml"><mi id="S5.SS2.SSS0.Px5.p1.2.m2.1.1.2" xref="S5.SS2.SSS0.Px5.p1.2.m2.1.1.2.cmml">C</mi><mn id="S5.SS2.SSS0.Px5.p1.2.m2.1.1.3" xref="S5.SS2.SSS0.Px5.p1.2.m2.1.1.3.cmml">4</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px5.p1.2.m2.1b"><apply id="S5.SS2.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px5.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS0.Px5.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS0.Px5.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS0.Px5.p1.2.m2.1.1.2">𝐶</ci><cn type="integer" id="S5.SS2.SSS0.Px5.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS0.Px5.p1.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px5.p1.2.m2.1c">C_{4}</annotation></semantics></math> map slightly drops detection accuracy.
While the use of lower-level features in the <math id="S5.SS2.SSS0.Px5.p1.3.m3.1" class="ltx_Math" alttext="3^{rd}" display="inline"><semantics id="S5.SS2.SSS0.Px5.p1.3.m3.1a"><msup id="S5.SS2.SSS0.Px5.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.cmml"><mn id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.2" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.2.cmml">3</mn><mrow id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.2" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.1" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.3" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px5.p1.3.m3.1b"><apply id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.2">3</cn><apply id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3"><times id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.2">𝑟</ci><ci id="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px5.p1.3.m3.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px5.p1.3.m3.1c">3^{rd}</annotation></semantics></math> and <math id="S5.SS2.SSS0.Px5.p1.4.m4.1" class="ltx_Math" alttext="4^{th}" display="inline"><semantics id="S5.SS2.SSS0.Px5.p1.4.m4.1a"><msup id="S5.SS2.SSS0.Px5.p1.4.m4.1.1" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.cmml"><mn id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.2" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.2.cmml">4</mn><mrow id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.cmml"><mi id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.2" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.1" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.3" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px5.p1.4.m4.1b"><apply id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.1.cmml" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.2.cmml" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.2">4</cn><apply id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.cmml" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3"><times id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.1"></times><ci id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.2">𝑡</ci><ci id="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px5.p1.4.m4.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px5.p1.4.m4.1c">4^{th}</annotation></semantics></math> rows yields negligible performance gains at an extra cost.
Hence, solely using its corresponding <math id="S5.SS2.SSS0.Px5.p1.5.m5.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S5.SS2.SSS0.Px5.p1.5.m5.1a"><mrow id="S5.SS2.SSS0.Px5.p1.5.m5.1b"><mn id="S5.SS2.SSS0.Px5.p1.5.m5.1.1">4</mn><mo lspace="0.222em" id="S5.SS2.SSS0.Px5.p1.5.m5.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px5.p1.5.m5.1c">4\times</annotation></semantics></math> stridden bottom-up map achieves satisfying accuracy.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Different Training Schemes</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We compare different two-stage training schemes, <span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, end-to-end training schedule and separate training of the RPN and R-CNN.
Our Pillar R-CNN adopts the typical end-to-end training schedule for 36 epochs as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
This differs from our used codebase <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, where the RPN and R-CNN are separately trained with 36 epochs and 6 epochs respectively.
We provide more experimental results of the separate training scheme, in which the RPN is first trained to generate region proposals and then frozen to train the R-CNN module.
As shown in <a href="#S5.T2" title="In Training and inference details. ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, the 6-epoch schedule of Pillar R-CNN-18 results in slightly degraded detection performance, and a longer 12-epoch schedule may trap the R-CNN model in over-fitting.
In contrast, for Pillar R-CNN, it is easy to build a unified network in which the RPN and R-CNN are trained at once with favorable performance.</p>
</div>
<figure id="S5.T7" class="ltx_table">
<div id="S5.T7.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:429.3pt;height:359.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(96.5pt,-80.9pt) scale(1.81669672894864,1.81669672894864) ;">
<table id="S5.T7.2.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T7.2.1.1.1" class="ltx_tr">
<td id="S5.T7.2.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T7.2.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Methods</span></td>
<td id="S5.T7.2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T7.2.1.1.1.2.1" class="ltx_text" style="font-size:90%;">FPN</span></td>
<td id="S5.T7.2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T7.2.1.1.1.3.1" class="ltx_text" style="font-size:90%;">IoU</span></td>
<td id="S5.T7.2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T7.2.1.1.1.4.1" class="ltx_text" style="font-size:90%;">Veh. (APH)</span></td>
<td id="S5.T7.2.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T7.2.1.1.1.5.1" class="ltx_text" style="font-size:90%;">Ped. (APH)</span></td>
</tr>
<tr id="S5.T7.2.1.2.2" class="ltx_tr">
<td id="S5.T7.2.1.2.2.1" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">L1</span></td>
<td id="S5.T7.2.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.1.2.2.2.1" class="ltx_text" style="font-size:90%;">L2</span></td>
<td id="S5.T7.2.1.2.2.3" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.2.2.3.1" class="ltx_text" style="font-size:90%;">L1</span></td>
<td id="S5.T7.2.1.2.2.4" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.2.2.4.1" class="ltx_text" style="font-size:90%;">L2</span></td>
</tr>
<tr id="S5.T7.2.1.3.3" class="ltx_tr">
<td id="S5.T7.2.1.3.3.1" class="ltx_td ltx_align_left ltx_border_t" colspan="5"><span id="S5.T7.2.1.3.3.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">PillarNet-18 Backbone</span></td>
<td id="S5.T7.2.1.3.3.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T7.2.1.3.3.3" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S5.T7.2.1.4.4" class="ltx_tr">
<td id="S5.T7.2.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T7.2.1.4.4.1.1" class="ltx_text" style="font-size:90%;">RPN</span></td>
<td id="S5.T7.2.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.1.4.4.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T7.2.1.4.4.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T7.2.1.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.2.1.4.4.4.1" class="ltx_text" style="font-size:90%;">74.54</span></td>
<td id="S5.T7.2.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.1.4.4.5.1" class="ltx_text" style="font-size:90%;">66.86</span></td>
<td id="S5.T7.2.1.4.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.2.1.4.4.6.1" class="ltx_text" style="font-size:90%;">70.04</span></td>
<td id="S5.T7.2.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.2.1.4.4.7.1" class="ltx_text" style="font-size:90%;">63.25</span></td>
</tr>
<tr id="S5.T7.2.1.5.5" class="ltx_tr">
<td id="S5.T7.2.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.1.5.5.1.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T7.2.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.1.5.5.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T7.2.1.5.5.3" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.5.5.3.1" class="ltx_text" style="font-size:90%;">76.40</span></td>
<td id="S5.T7.2.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.1.5.5.4.1" class="ltx_text" style="font-size:90%;">68.22</span></td>
<td id="S5.T7.2.1.5.5.5" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.5.5.5.1" class="ltx_text" style="font-size:90%;">71.85</span></td>
<td id="S5.T7.2.1.5.5.6" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.5.5.6.1" class="ltx_text" style="font-size:90%;">64.54</span></td>
</tr>
<tr id="S5.T7.2.1.6.6" class="ltx_tr">
<td id="S5.T7.2.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T7.2.1.6.6.1.1" class="ltx_text" style="font-size:90%;">R-CNN</span></td>
<td id="S5.T7.2.1.6.6.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T7.2.1.6.6.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T7.2.1.6.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.2.1.6.6.4.1" class="ltx_text" style="font-size:90%;">76.55</span></td>
<td id="S5.T7.2.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.1.6.6.5.1" class="ltx_text" style="font-size:90%;">68.64</span></td>
<td id="S5.T7.2.1.6.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.2.1.6.6.6.1" class="ltx_text" style="font-size:90%;">70.21</span></td>
<td id="S5.T7.2.1.6.6.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.2.1.6.6.7.1" class="ltx_text" style="font-size:90%;">62.46</span></td>
</tr>
<tr id="S5.T7.2.1.7.7" class="ltx_tr">
<td id="S5.T7.2.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.1.7.7.1.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T7.2.1.7.7.2" class="ltx_td ltx_border_r"></td>
<td id="S5.T7.2.1.7.7.3" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.7.7.3.1" class="ltx_text" style="font-size:90%;">76.30</span></td>
<td id="S5.T7.2.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.1.7.7.4.1" class="ltx_text" style="font-size:90%;">68.40</span></td>
<td id="S5.T7.2.1.7.7.5" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.7.7.5.1" class="ltx_text" style="font-size:90%;">72.47</span></td>
<td id="S5.T7.2.1.7.7.6" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.7.7.6.1" class="ltx_text" style="font-size:90%;">65.38</span></td>
</tr>
<tr id="S5.T7.2.1.8.8" class="ltx_tr">
<td id="S5.T7.2.1.8.8.1" class="ltx_td ltx_align_left ltx_border_t" colspan="5"><span id="S5.T7.2.1.8.8.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">PillarNet-34 Backbone</span></td>
<td id="S5.T7.2.1.8.8.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T7.2.1.8.8.3" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S5.T7.2.1.9.9" class="ltx_tr">
<td id="S5.T7.2.1.9.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T7.2.1.9.9.1.1" class="ltx_text" style="font-size:90%;">RPN</span></td>
<td id="S5.T7.2.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.1.9.9.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T7.2.1.9.9.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T7.2.1.9.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.2.1.9.9.4.1" class="ltx_text" style="font-size:90%;">75.64</span></td>
<td id="S5.T7.2.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.1.9.9.5.1" class="ltx_text" style="font-size:90%;">67.93</span></td>
<td id="S5.T7.2.1.9.9.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.2.1.9.9.6.1" class="ltx_text" style="font-size:90%;">70.76</span></td>
<td id="S5.T7.2.1.9.9.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.2.1.9.9.7.1" class="ltx_text" style="font-size:90%;">64.11</span></td>
</tr>
<tr id="S5.T7.2.1.10.10" class="ltx_tr">
<td id="S5.T7.2.1.10.10.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.1.10.10.1.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T7.2.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.1.10.10.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T7.2.1.10.10.3" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.10.10.3.1" class="ltx_text" style="font-size:90%;">77.30</span></td>
<td id="S5.T7.2.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.1.10.10.4.1" class="ltx_text" style="font-size:90%;">69.16</span></td>
<td id="S5.T7.2.1.10.10.5" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.10.10.5.1" class="ltx_text" style="font-size:90%;">73.38</span></td>
<td id="S5.T7.2.1.10.10.6" class="ltx_td ltx_align_center"><span id="S5.T7.2.1.10.10.6.1" class="ltx_text" style="font-size:90%;">66.23</span></td>
</tr>
<tr id="S5.T7.2.1.11.11" class="ltx_tr">
<td id="S5.T7.2.1.11.11.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T7.2.1.11.11.1.1" class="ltx_text" style="font-size:90%;">R-CNN</span></td>
<td id="S5.T7.2.1.11.11.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T7.2.1.11.11.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S5.T7.2.1.11.11.3" class="ltx_td ltx_border_bb ltx_border_r ltx_border_t"></td>
<td id="S5.T7.2.1.11.11.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.2.1.11.11.4.1" class="ltx_text" style="font-size:90%;">76.99</span></td>
<td id="S5.T7.2.1.11.11.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T7.2.1.11.11.5.1" class="ltx_text" style="font-size:90%;">69.07</span></td>
<td id="S5.T7.2.1.11.11.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.2.1.11.11.6.1" class="ltx_text" style="font-size:90%;">73.18</span></td>
<td id="S5.T7.2.1.11.11.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.2.1.11.11.7.1" class="ltx_text" style="font-size:90%;">66.07</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 7: </span>Effects of IoU-aware confidence rectification for our pyramidal region proposal network.</figcaption>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>IoU-aware Confidence Rectification</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.4" class="ltx_p">The IoU-aware confidence rectification is commonly used to cope with the misalignment issue for 2D detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> and 3D detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> between localization accuracy and classification score.
The IoU-aware rectification function <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> at the post-processing stage can be formulated as:</p>
<table id="S5.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E2.m1.1" class="ltx_Math" alttext="\centering\hat{S}=S^{1-\beta}*W_{\rm{IoU}}^{\beta}\@add@centering" display="block"><semantics id="S5.E2.m1.1a"><mrow id="S5.E2.m1.1.1" xref="S5.E2.m1.1.1.cmml"><mover accent="true" id="S5.E2.m1.1.1.2" xref="S5.E2.m1.1.1.2.cmml"><mi id="S5.E2.m1.1.1.2.2" xref="S5.E2.m1.1.1.2.2.cmml">S</mi><mo id="S5.E2.m1.1.1.2.1" xref="S5.E2.m1.1.1.2.1.cmml">^</mo></mover><mo id="S5.E2.m1.1.1.1" xref="S5.E2.m1.1.1.1.cmml">=</mo><mrow id="S5.E2.m1.1.1.3" xref="S5.E2.m1.1.1.3.cmml"><msup id="S5.E2.m1.1.1.3.2" xref="S5.E2.m1.1.1.3.2.cmml"><mi id="S5.E2.m1.1.1.3.2.2" xref="S5.E2.m1.1.1.3.2.2.cmml">S</mi><mrow id="S5.E2.m1.1.1.3.2.3" xref="S5.E2.m1.1.1.3.2.3.cmml"><mn id="S5.E2.m1.1.1.3.2.3.2" xref="S5.E2.m1.1.1.3.2.3.2.cmml">1</mn><mo id="S5.E2.m1.1.1.3.2.3.1" xref="S5.E2.m1.1.1.3.2.3.1.cmml">−</mo><mi id="S5.E2.m1.1.1.3.2.3.3" xref="S5.E2.m1.1.1.3.2.3.3.cmml">β</mi></mrow></msup><mo lspace="0.222em" rspace="0.222em" id="S5.E2.m1.1.1.3.1" xref="S5.E2.m1.1.1.3.1.cmml">∗</mo><msubsup id="S5.E2.m1.1.1.3.3" xref="S5.E2.m1.1.1.3.3.cmml"><mi id="S5.E2.m1.1.1.3.3.2.2" xref="S5.E2.m1.1.1.3.3.2.2.cmml">W</mi><mi id="S5.E2.m1.1.1.3.3.2.3" xref="S5.E2.m1.1.1.3.3.2.3.cmml">IoU</mi><mi id="S5.E2.m1.1.1.3.3.3" xref="S5.E2.m1.1.1.3.3.3.cmml">β</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E2.m1.1b"><apply id="S5.E2.m1.1.1.cmml" xref="S5.E2.m1.1.1"><eq id="S5.E2.m1.1.1.1.cmml" xref="S5.E2.m1.1.1.1"></eq><apply id="S5.E2.m1.1.1.2.cmml" xref="S5.E2.m1.1.1.2"><ci id="S5.E2.m1.1.1.2.1.cmml" xref="S5.E2.m1.1.1.2.1">^</ci><ci id="S5.E2.m1.1.1.2.2.cmml" xref="S5.E2.m1.1.1.2.2">𝑆</ci></apply><apply id="S5.E2.m1.1.1.3.cmml" xref="S5.E2.m1.1.1.3"><times id="S5.E2.m1.1.1.3.1.cmml" xref="S5.E2.m1.1.1.3.1"></times><apply id="S5.E2.m1.1.1.3.2.cmml" xref="S5.E2.m1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.3.2.1.cmml" xref="S5.E2.m1.1.1.3.2">superscript</csymbol><ci id="S5.E2.m1.1.1.3.2.2.cmml" xref="S5.E2.m1.1.1.3.2.2">𝑆</ci><apply id="S5.E2.m1.1.1.3.2.3.cmml" xref="S5.E2.m1.1.1.3.2.3"><minus id="S5.E2.m1.1.1.3.2.3.1.cmml" xref="S5.E2.m1.1.1.3.2.3.1"></minus><cn type="integer" id="S5.E2.m1.1.1.3.2.3.2.cmml" xref="S5.E2.m1.1.1.3.2.3.2">1</cn><ci id="S5.E2.m1.1.1.3.2.3.3.cmml" xref="S5.E2.m1.1.1.3.2.3.3">𝛽</ci></apply></apply><apply id="S5.E2.m1.1.1.3.3.cmml" xref="S5.E2.m1.1.1.3.3"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.3.3.1.cmml" xref="S5.E2.m1.1.1.3.3">superscript</csymbol><apply id="S5.E2.m1.1.1.3.3.2.cmml" xref="S5.E2.m1.1.1.3.3"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.3.3.2.1.cmml" xref="S5.E2.m1.1.1.3.3">subscript</csymbol><ci id="S5.E2.m1.1.1.3.3.2.2.cmml" xref="S5.E2.m1.1.1.3.3.2.2">𝑊</ci><ci id="S5.E2.m1.1.1.3.3.2.3.cmml" xref="S5.E2.m1.1.1.3.3.2.3">IoU</ci></apply><ci id="S5.E2.m1.1.1.3.3.3.cmml" xref="S5.E2.m1.1.1.3.3.3">𝛽</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E2.m1.1c">\centering\hat{S}=S^{1-\beta}*W_{\rm{IoU}}^{\beta}\@add@centering</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S5.SS4.p1.3" class="ltx_p">where <math id="S5.SS4.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S5.SS4.p1.1.m1.1a"><mi id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><ci id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">S</annotation></semantics></math> indicates the classification score and <math id="S5.SS4.p1.2.m2.1" class="ltx_Math" alttext="W_{\rm{IoU}}" display="inline"><semantics id="S5.SS4.p1.2.m2.1a"><msub id="S5.SS4.p1.2.m2.1.1" xref="S5.SS4.p1.2.m2.1.1.cmml"><mi id="S5.SS4.p1.2.m2.1.1.2" xref="S5.SS4.p1.2.m2.1.1.2.cmml">W</mi><mi id="S5.SS4.p1.2.m2.1.1.3" xref="S5.SS4.p1.2.m2.1.1.3.cmml">IoU</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.2.m2.1b"><apply id="S5.SS4.p1.2.m2.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.2.m2.1.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS4.p1.2.m2.1.1.2.cmml" xref="S5.SS4.p1.2.m2.1.1.2">𝑊</ci><ci id="S5.SS4.p1.2.m2.1.1.3.cmml" xref="S5.SS4.p1.2.m2.1.1.3">IoU</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.2.m2.1c">W_{\rm{IoU}}</annotation></semantics></math> is the IoU score. <math id="S5.SS4.p1.3.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS4.p1.3.m3.1a"><mi id="S5.SS4.p1.3.m3.1.1" xref="S5.SS4.p1.3.m3.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.3.m3.1b"><ci id="S5.SS4.p1.3.m3.1.1.cmml" xref="S5.SS4.p1.3.m3.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.3.m3.1c">\beta</annotation></semantics></math> is a hyper-parameter.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">To verify its effect on our proposed pyramidal region proposal network, we follow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> and conduct experiments for single-stage object detection.
From the results of RPN in <a href="#S5.T7" title="In 5.3 Different Training Schemes ‣ 5 Experiments ‣ Pillar R-CNN for Point Cloud 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">7</span></a>, we can see that IoU-aware confidence rectification can achieve huge performance improvement on our pyramidal region proposal network.
After restoring using carefully tuned rectification factor <math id="S5.SS4.p2.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS4.p2.1.m1.1a"><mi id="S5.SS4.p2.1.m1.1.1" xref="S5.SS4.p2.1.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.m1.1b"><ci id="S5.SS4.p2.1.m1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.1.m1.1c">\beta</annotation></semantics></math> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, the RPN achieves comparable performance with its R-CNN counterparts.
That is, the IoU-aware confidence rectification module benefits the ranking-based metrics such as Average Precision.
In contrast, the R-CNN module mainly rescores boxes adaptively such that the boxes with better localization can be selected.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This paper presents a conceptually simple Faster R-CNN-like 3D detector, named Pillar R-CNN, for accurate 3D object detection solely on pillar-based point cloud representation.
The key insight lies in the pillar-based representation can offer crucial 3D structural information for accurate 3D detection. It differs from previous point-voxel-based two-stage methods that require abstracted intermediary keypoints for precise 3D box refinement.
From this standpoint, we introduce FPN into RPN for better proposal generation on small objects and design a simple yet effective lateral connection layer to merge the low-level sparse pillar volumes and high-level dense semantic maps for the second 3D RoI refinement.
Moreover, Our Pillar R-CNN also takes into account the domain gap between image and point clouds for object detection, and attempts to design a novel two-stage detection paradigm to bridge this gap.
As a result, our Pillar R-CNN builds a promising pathway for incorporating the advances from the well-developed 2D detection domain for accurate 3D detection based on pillar-based feature representation.
Extensive experimental results on the large-scale Waymo Open Dataset demonstrate that BEV representation on point clouds can preserve sufficient 3D structural information to facilitate the research of BEV perception.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Alex Bewley, Pei Sun, Thomas Mensink, Dragomir Anguelov, and Cristian
Sminchisescu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Range conditioned dilated convolutions for scale invariant 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Conference on Robot Learning</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Yilun Chen, Shu Liu, Xiaoyong Shen, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Fast point r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 9775–9784, 2019.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Jiajun Deng, Shaoshuai Shi, Peiwei Li, Wengang Zhou, Yanyong Zhang, and
Houqiang Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Voxel r-cnn: Towards high performance voxel-based 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial
Intelligence</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Zheng Ge, Songtao Liu, Feng Wang, Zeming Li, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Yolox: Exceeding yolo series in 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2107.08430</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Fast r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, pages 1440–1448, 2015.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Benjamin Graham, Martin Engelcke, and Laurens Van Der Maaten.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">3d semantic segmentation with submanifold sparse convolutional
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 9224–9232, 2018.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Mask r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 2961–2969, 2017.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, pages 770–778, 2016.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Jordan SK Hu, Tianshu Kuai, and Steven L Waslander.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Point density-aware voxels for lidar 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">2022.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Yihan Hu, Zhuangzhuang Ding, Runzhou Ge, Wenxin Shao, Li Huang, Kun Li, and
Qiang Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Afdetv2: Rethinking the necessity of the second stage for object
detection from point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">2021.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Junjie Huang, Guan Huang, Zheng Zhu, and Dalong Du.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Bevdet: High-performance multi-camera 3d object detection in
bird-eye-view.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2112.11790</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Borui Jiang, Ruixuan Luo, Jiayuan Mao, Tete Xiao, and Yuning Jiang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Acquisition of localization confidence for accurate object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European conference on computer vision
(ECCV)</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages 784–799, 2018.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar
Beijbom.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Pointpillars: Fast encoders for object detection from point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 12697–12705, 2019.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Zhichao Li, Feng Wang, and Naiyan Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Lidar r-cnn: An efficient and universal 3d object detector.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 7546–7555, 2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan,
and Serge Belongie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Feature pyramid networks for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, pages 2117–2125, 2017.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Yuexin Ma, Tai Wang, Xuyang Bai, Huitong Yang, Yuenan Hou, Yaming Wang, Yu
Qiao, Ruigang Yang, Dinesh Manocha, and Xinge Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Vision-centric bev perception: A survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2208.02797</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Jiageng Mao, Minzhe Niu, Haoyue Bai, Xiaodan Liang, Hang Xu, and Chunjing Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Pyramid r-cnn: Towards better performance and adaptability for 3d
object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 2723–2732, 2021.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Jiageng Mao, Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">3d object detection for autonomous driving: a review and new
outlooks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2206.09474</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Youshaa Murhij and Dmitry Yudin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Real-time 3d object detection using feature map flow.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.14101</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Jiquan Ngiam, Benjamin Caine, Wei Han, Brandon Yang, Yuning Chai, Pei Sun, Yin
Zhou, Xi Yi, Ouais Alsharif, Patrick Nguyen, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Starnet: Targeted computation for object detection in point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1908.11069</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Pointnet: Deep learning on point sets for 3d classification and
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 652–660, 2017.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Pointnet++: Deep hierarchical feature learning on point sets in a
metric space.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, 30, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Charles R Qi, Yin Zhou, Mahyar Najibi, Pei Sun, Khoa Vo, Boyang Deng, and
Dragomir Anguelov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Offboard 3d object detection from point cloud sequences.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 6134–6144, 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Faster r-cnn: Towards real-time object detection with region proposal
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 28, 2015.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">U-net: Convolutional networks for biomedical image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Medical image computing and
computer-assisted intervention</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 234–241. Springer, 2015.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
guangsheng Shi, Ruifeng Li, and chao Ma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Pillarnet: Real-time and high-performance pillar-based 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 35–52.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and
Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Pv-rcnn: Point-voxel feature set abstraction for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, pages 10529–10538, 2020.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Pointrcnn: 3d object proposal generation and detection from point
cloud.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, pages 770–779, 2019.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Zhe Wang, Jianping Shi, Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">From points to parts: 3d object detection from point cloud with
part-aware and part-aggregation network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine intelligence</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">,
43(8):2647–2664, 2020.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Karen Simonyan and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Very deep convolutional networks for large-scale image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1409.1556</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai
Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Scalability in perception for autonomous driving: Waymo open dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, pages 2446–2454, 2020.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Pei Sun, Weiyue Wang, Yuning Chai, Gamaleldin Elsayed, Alex Bewley, Xiao Zhang,
Cristian Sminchisescu, and Dragomir Anguelov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Rsn: Range sparse net for efficient, accurate lidar 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, pages 5725–5734, 2021.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Shengkai Wu, Xiaoping Li, and Xinggang Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Iou-aware single-stage object detector for accurate localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Image and Vision Computing</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:90%;">, 97:103911, 2020.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Jianyun Xu, Xin Tang, Jian Dou, Xu Shu, and Yushi Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Centeratt: Fast 2-stage center attention network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.10493</span><span id="bib.bib34.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Yan Yan, Yuxing Mao, and Bo Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Second: Sparsely embedded convolutional detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Sensors</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">, 18(10):3337, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Zetong Yang, Yanan Sun, Shu Liu, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">3dssd: Point-based 3d single stage object detector.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, pages 11040–11048, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Zetong Yang, Yanan Sun, Shu Liu, Xiaoyong Shen, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Std: Sparse-to-dense 3d object detector for point cloud.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, pages 1951–1960, 2019.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Zetong Yang, Yin Zhou, Zhifeng Chen, and Jiquan Ngiam.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">3d-man: 3d multi-frame attention network for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, pages 1863–1872, 2021.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Center-based 3d object detection and tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, pages 11784–11793, 2021.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Yifan Zhang, Qingyong Hu, Guoquan Xu, Yanxin Ma, Jianwei Wan, and Yulan Guo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Not all points are equal: Learning highly efficient point-based
detectors for 3d lidar point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Wu Zheng, Weiliang Tang, Sijin Chen, Li Jiang, and Chi-Wing Fu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Cia-ssd: Confident iou-aware single-stage object detector from point
cloud.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI conference on artificial
intelligence</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, volume 35, pages 3555–3562, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Yin Zhou and Oncel Tuzel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Voxelnet: End-to-end learning for point cloud based 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:90%;">, pages 4490–4499, 2018.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Zixiang Zhou, Xiangchen Zhao, Yu Wang, Panqu Wang, and Hassan Foroosh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Centerformer: Center-based transformer for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">, pages 496–513.
Springer, 2022.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2302.13299" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2302.13301" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2302.13301">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2302.13301" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2302.13302" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 23:17:38 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
