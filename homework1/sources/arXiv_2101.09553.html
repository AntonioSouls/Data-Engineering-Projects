<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2101.09553] REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY</title><meta property="og:description" content="A key requirement for autonomous on-orbit proximity operations is the estimation of a target spacecraft’s relative pose (position and orientation). It is desirable to employ monocular cameras for this problem due to th…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2101.09553">

<!--Generated on Sat Mar  9 04:35:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\PaperNumber</span>
<p id="p1.2" class="ltx_p">21-283
</p>
</div>
<h1 class="ltx_title ltx_title_document">REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kevin Black
</span><span class="ltx_author_notes">Undergraduate Researcher, Texas Spacecraft Laboratory, The University of Texas at Austin</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Shrivu Shankar<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Daniel Fonseka<span id="footnotex2" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Jacob Deutsch<span id="footnotex3" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Abhimanyu Dhir<span id="footnotex4" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> and Maruthi R. Akella
</span><span class="ltx_author_notes">Ashley H. Priddy Centennial Professorship in Engineering, Department of Aerospace Engineering and Engineering Mechanics, The University of Texas at
Austin, AAS Fellow, Email: makella@mail.utexas.edu</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">A key requirement for autonomous on-orbit proximity operations is the estimation of a target spacecraft’s relative pose (position and orientation). It is desirable to employ monocular cameras for this problem due to their low cost, weight, and power requirements. This work presents a novel convolutional neural network (CNN)-based monocular pose estimation system that achieves state-of-the-art accuracy with low computational demand. In combination with a Blender-based synthetic data generation scheme, the system demonstrates the ability to generalize from purely synthetic training data to real in-space imagery of the Northrop Grumman Enhanced Cygnus spacecraft. Additionally, the system achieves real-time performance on low-power flight-like hardware.</p>
</div>
<section id="S1" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Frequent proximity operations between spacecraft in orbit are a key requirement for current and future activities such as formation flying, debris removal<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, and on-orbit servicing<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Automation of these operations is crucial to their long-term value and viability. A fundamental requirement for autonomous proximity operations is the automatic detection of a target spacecraft’s relative position and attitude, often referred to as pose estimation. Oftentimes, as in the case of debris removal, the target is non-cooperative: it does not employ any active communications or special markings to assist the sensing spacecraft. Furthermore, many of these missions utilize only small spacecraft with strict power and mass requirements. Monocular cameras — which are small in size, ubiquitous in nature, and consume little power compared to other sensors such as stereo cameras or LIDAR — are an ideal sensor for low-power non-cooperative pose estimation.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The problem of pose estimation from monocular imagery has been studied for many years. Early techniques focused on hand-engineered feature matching<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, but have been known to exhibit to poor robustness and generalization capabilities. This is particularly true in the space environment, which presents unique challenges such as low signal-to-noise ratio, harsh and varied lighting conditions, and a dynamic Earth background. However, over the past decade, nearly all computer vision tasks such as monocular pose estimation have become increasingly dominated by deep convolutional neural networks (CNNs). Compared to prior techniques, CNNs have been shown to be more resilient to noise and better able to generalize to previously unseen scenarios. It is no surprise that CNNs are now being applied for in-space monocular pose estimation. The 2019 Satellite Pose Estimation Challenge (SPEC)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, hosted by Stanford University and the European Space Agency (ESA), saw all of its top-performing submissions employ CNN-based deep learning models.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, deep neural networks suffer from two major disadvantages: they require large amounts of labeled data to train and are computationally expensive to run. Due to the scarcity of labeled real images of spacecraft in orbit, most work on in-space monocular pose estimation has focused on synthetic or mockup-based imagery for both training and evaluation. For example, the dataset provided for the SPEC competition was the Spacecraft Pose Estimation Dataset (SPEED)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, which consists of black-and-white synthetic images of the ESA Tango spacecraft as well as limited real images of a mockup. Models that perform well on a limited variety of artificial images will not necessarily transfer effectively to the real environment. There has also been relatively little discussion about the feasibility of running these models on flight-like hardware. Most CNNs require expensive computations that are optimized for a Graphics Processing Unit (GPU); however, the application of GPUs in the space domain is still a nascent field of study due to radiation exposure considerations<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. While traditional processors are still capable of running CNNs, many spacecraft, especially smaller satellites such as CubeSats, only have low-power processors that are incapable of running large, state-of-the-art CNN models in real-time.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">This work presents a monocular pose estimation system that addresses many of the challenges described above. The core of the system is a novel CNN-based pose estimation architecture that is computationally inexpensive, yet maintains state-of-the-art accuracy. Similar to some prior works<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, this architecture is a 3-step process consisting of an object detection CNN, a keypoint regression CNN, and an off-the-shelf perspective-n-point (PnP) solver. It also includes a final error prediction step which identifies bad pose estimates and replaces them with “non-detections”. Furthermore, the entire architecture is trained using a novel synthetic data generation scheme that produces photorealistic images with many of the degradations present in real space imagery. Synthetic images are generated using Cycles, a physically-based, ray-tracing, production rendering engine packaged with the open-source 3D graphics software Blender<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Our aim is to present a nearly flight-ready system. As discussed above, real image performance, along with feasibility of using flight-like hardware, is essential for flight readiness. In contrast to most prior work, we analyze the ability of the pose estimation system to generalize to real images. These real images exhibit a wide range of poses, backgrounds, and the aforementioned degradations. In addition, we present a thorough benchmark of the system’s performance on an Intel Joule 570x single-board computer, the same type which flew on the NASA Johnson Space Center (JSC) Seeker CubeSat mission in September 2019<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">We first provide a survey of related work. Then, we describe the details of our pose estimation architecture, as well as our synthetic data generation scheme using the Northrop Grumman Enhanced Cygnus vehicle as our target spacecraft. We next present results including the performance of our architecture on the SPEED dataset, the performance of our system on both synthetic and real images of Cygnus, and the hardware performance of our system on the Intel Joule 570x single-board computer.</p>
</div>
</section>
<section id="S2" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">There is much pre-existing work in the context of spacecraft monocular pose estimation, including a recently published overview of methods in the field by Cassinis et al. (2019)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Early methods of pose estimation relied on classical, non-learning methods such as Hough line detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and Canny edge detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> for producing raw image features. However, pivotal papers such as Krizhevsky et al. (2012)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> show that learned feature detection through the use of CNNs is both more accurate and robust for computer vision tasks.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In some cases, this has gone as far as solving for pose as the direct output of a CNN. Su et al. (2016) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> show that by discretizing the viewpoint space, a CNN can be used to classify an input image directly into a binned pose. Kehlet et. al. (2017) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> expand on this to add refinement and verification methods after the pose classification. Rather than modeling the problem as a classification task, Mahendran et al. (2017) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> show that directly regressing a quaternion representation of pose is a viable method where minimal, if any, post-processing is required. In this case, the task of pose estimation can be completely learned by an end-to-end CNN. Although more and more computer vision applications now rely on end-to-end CNNs, based on the results of the Satellite Pose Estimation Challenge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, the best performing pose estimation models in the space domain still use classical pose solvers such as POSIT<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> or Perspective-n-Point (PnP)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> attached to the output of a CNN-based keypoint detector. Much recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> has shown such a keypoints-based pipeline to be one of the most viable methods for the specific task of monocular satellite pose estimation. Furthermore, all of these recent works first use an object detection step to crop to the region of interest in order to provide scale invariance to the keypoint model.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">To compensate for uncertainties in keypoint predictions, Cassinis et al. (2020)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> show the problem can be modeled as predicting a heatmap (where peaks represent high-confidence locations of a given keypoint in the input image) for each keypoint as opposed to regressing coordinates directly. This provides some interpretability as each prediction can be visualized as a feature-heatmap when juxtaposed with the original image, and the 2D output allows for richer keypoint features to be fed to the accompanying pose solver. By instead encoding the heatmap as a pixel-level displacement field, pose estimation accuracy can further be improved as in Hou et. al.’s MobilePose<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">While these architectural advances are shown to improve pose accuracy in aggregate, deployed pose applications also require additional guarantees on worst-case predictions. For spacecraft, Kalman filters are often applied to a stream of pose model predictions and sensor data to validate the likelihood of the estimated poses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. In CullNet<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, Gupta et al. also show that bad pose estimates can be culled with the use of an additional error-predicting CNN. They use each candidate pose estimate to produce a corresponding 2D mask of the target object, then feed this mask along with the original image into a CNN which attempts to predict the accuracy of the pose estimate.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">As discussed above, another common challenge of extra-terrestrial pose estimation is the scarcity of real data. This drives many methods (especially those that utilize CNNs) to employ transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. In some cases, this requires initially training the keypoint model on a completely separate domain to learn key CNN filters that are still generalizable to the target domain of space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Other work attempts to use visual simulations to generate artificial training data. Notably, this includes the OpenGL-rendered SPEED dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, as well as the Unreal Engine-based simulator presented in Proenca and Gao (2019)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Generative Adversarial Networks (GANs) have also been employed in similar contexts to improve the realism of artificial training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.</p>
</div>
</section>
<section id="S3" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The proposed pose estimation architecture is composed of a 3-step process. An object detection network first determines the 2D bounding box of the target spacecraft, and then feeds a cropped region of interest (RoI) to a separate keypoint regression network. The keypoint regression network regresses the 2D locations of predetermined 3D surface keypoints on the spacecraft model, from which the full pose is obtained using an off-the-shelf Perspective-n-Point (PnP) solver. This overall architecture was chosen because prior works<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, as well as our own experiments, have found that such 3-step processes tend to outperform other techniques such as direct pose regression or classification. The final error prediction step predicts the approximate error of a given pose estimate. These error predictions can then be used to reject bad pose estimates and produce “non-detections” instead.</p>
</div>
<section id="S3.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Keypoint Selection</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We utilize surface keypoints for pose estimation rather than the corners of the 3D bounding box. The bounding box corners are often used in systems that need to handle multiple objects; however, as we only need to consider a single known object, we use surface keypoints due to their stronger correspondence with local image features.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.2" class="ltx_p">To select keypoints, we exploit our access to the 3D mesh model of the Cygnus spacecraft that is used for synthetic image generation. A user-specified number of keypoints (<math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">n</annotation></semantics></math>) are generated randomly using a sample elimination algorithm<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> that produces Poisson disk sample sets. The result is that the generated points are approximately “evenly spread out” in 3D space, serving well for the task of pose estimation for any given number of points. We find that using <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="n=20" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">n</mi><mo id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><eq id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1"></eq><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝑛</ci><cn type="integer" id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">n=20</annotation></semantics></math> keypoints produces good results, and use that value for all experiments.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">For evaluation on the SPEED dataset, we use the same 11 surface keypoints as in Park et. al. (2019)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and Chen et. al. (2019)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Object Detection</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">For the object detection network, we use off-the-shelf models from the TensorFlow Object Detection API <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. These are easy to train and include access to weights pretrained on the COCO 2017 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. We select the SSD MobileNetv2 architecture<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> with an input resolution of <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="320\times 320" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mn id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">320</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">320</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><times id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">320</cn><cn type="integer" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">320</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">320\times 320</annotation></semantics></math>, as it provides adequate accuracy while being the least computationally expensive architecture with an available pretrained checkpoint.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We operate in the context of a guaranteed single spacecraft in every image, so we always take the top bounding box detection regardless of confidence. To produce the final RoI, the detected bounding box is made square by setting the length of its shorter side to that of its longer side and then expanded by 25% to ensure that the entire spacecraft lies inside.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Keypoint Regression</h3>

<figure id="S3.F1" class="ltx_figure"><img src="/html/2101.09553/assets/Figures/krn_diagram.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="213" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.4.2.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.2.1" class="ltx_text" style="font-size:90%;">Layer diagram for the keypoint regression network. Blue rectangles are convolutional layers, purple are transposed convolutional layers, orange are inverted residual blocks, and green is the output <math id="S3.F1.2.1.m1.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S3.F1.2.1.m1.1b"><mrow id="S3.F1.2.1.m1.1.1" xref="S3.F1.2.1.m1.1.1.cmml"><mn id="S3.F1.2.1.m1.1.1.2" xref="S3.F1.2.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.F1.2.1.m1.1.1.1" xref="S3.F1.2.1.m1.1.1.1.cmml">×</mo><mn id="S3.F1.2.1.m1.1.1.3" xref="S3.F1.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F1.2.1.m1.1c"><apply id="S3.F1.2.1.m1.1.1.cmml" xref="S3.F1.2.1.m1.1.1"><times id="S3.F1.2.1.m1.1.1.1.cmml" xref="S3.F1.2.1.m1.1.1.1"></times><cn type="integer" id="S3.F1.2.1.m1.1.1.2.cmml" xref="S3.F1.2.1.m1.1.1.2">1</cn><cn type="integer" id="S3.F1.2.1.m1.1.1.3.cmml" xref="S3.F1.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.2.1.m1.1d">1\times 1</annotation></semantics></math> convolution.</span></figcaption>
</figure>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/keypoints.jpg" id="S3.F2.1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/cutout.png" id="S3.F2.2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.4.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.5.2" class="ltx_text" style="font-size:90%;">Left: an example output of the keypoint regression network. Each same-colored cluster of points is the 196 predictions for each keypoint. Right: an example of a mask cutout fed to the error prediction network. The background has been filled with a checkered pattern for illustration purposes; however, in practice those pixels would all be set to black.</span></figcaption>
</figure>
<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">After bounding box detection, the image is cropped to the RoI and rescaled to a resolution of <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mn id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><times id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">224</cn><cn type="integer" id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">224\times 224</annotation></semantics></math>. The resulting image is then fed to the keypoint regression network.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.6" class="ltx_p">The keypoint regression network (Figure <a href="#S3.F1" title="Figure 1 ‣ 3.3 Keypoint Regression ‣ 3 Methods ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) is based on a MobileNetv2<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> backbone and follows the general architecture of MobilePose<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Unlike MobilePose, we keep the original MobileNetv2 network and cut it off before its final convolutional layer, producing a <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="7\times 7\times 320" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mrow id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mn id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.1.m1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.1.m1.1.1.1a" xref="S3.SS3.p2.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS3.p2.1.m1.1.1.4" xref="S3.SS3.p2.1.m1.1.1.4.cmml">320</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><times id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1"></times><cn type="integer" id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">7</cn><cn type="integer" id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">7</cn><cn type="integer" id="S3.SS3.p2.1.m1.1.1.4.cmml" xref="S3.SS3.p2.1.m1.1.1.4">320</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">7\times 7\times 320</annotation></semantics></math> feature map. The feature map is upsampled back to <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="14\times 14" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mrow id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mn id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.2.m2.1.1.1" xref="S3.SS3.p2.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><times id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1.1"></times><cn type="integer" id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">14</cn><cn type="integer" id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">14\times 14</annotation></semantics></math> with a transposed convolutional layer, followed by a skip connection via concatenation to the last layer in MobileNetv2 with the same <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="14\times 14" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mrow id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mn id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.3.m3.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.cmml">×</mo><mn id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><times id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1"></times><cn type="integer" id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">14</cn><cn type="integer" id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">14\times 14</annotation></semantics></math> scale. This is followed by two more of MobileNetv2’s inverted residual blocks, and then a final <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mrow id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mn id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.4.m4.1.1.1" xref="S3.SS3.p2.4.m4.1.1.1.cmml">×</mo><mn id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><times id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1.1"></times><cn type="integer" id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">1</cn><cn type="integer" id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">1\times 1</annotation></semantics></math> convolution to produce an output tensor with dimension <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="14\times 14\times 2n" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mrow id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mrow id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml"><mn id="S3.SS3.p2.5.m5.1.1.2.2" xref="S3.SS3.p2.5.m5.1.1.2.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.5.m5.1.1.2.1" xref="S3.SS3.p2.5.m5.1.1.2.1.cmml">×</mo><mn id="S3.SS3.p2.5.m5.1.1.2.3" xref="S3.SS3.p2.5.m5.1.1.2.3.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.5.m5.1.1.2.1a" xref="S3.SS3.p2.5.m5.1.1.2.1.cmml">×</mo><mn id="S3.SS3.p2.5.m5.1.1.2.4" xref="S3.SS3.p2.5.m5.1.1.2.4.cmml">2</mn></mrow><mo lspace="0em" rspace="0em" id="S3.SS3.p2.5.m5.1.1.1" xref="S3.SS3.p2.5.m5.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><times id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1.1"></times><apply id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2"><times id="S3.SS3.p2.5.m5.1.1.2.1.cmml" xref="S3.SS3.p2.5.m5.1.1.2.1"></times><cn type="integer" id="S3.SS3.p2.5.m5.1.1.2.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2.2">14</cn><cn type="integer" id="S3.SS3.p2.5.m5.1.1.2.3.cmml" xref="S3.SS3.p2.5.m5.1.1.2.3">14</cn><cn type="integer" id="S3.SS3.p2.5.m5.1.1.2.4.cmml" xref="S3.SS3.p2.5.m5.1.1.2.4">2</cn></apply><ci id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">14\times 14\times 2n</annotation></semantics></math>, where <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><mi id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><ci id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">n</annotation></semantics></math> is the number of keypoints.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.3" class="ltx_p">Each of the <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="14\times 14" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mn id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.1.m1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><times id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1"></times><cn type="integer" id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">14</cn><cn type="integer" id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">14\times 14</annotation></semantics></math> entries in the output tensor make a prediction for the 2D locations of all <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><mi id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">n</annotation></semantics></math> keypoints, meaning each keypoint has 196 predictions. As in MobilePose, the network does not predict the keypoints’ 2D locations directly, but rather each of the <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="14\times 14" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mn id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.3.m3.1.1.1" xref="S3.SS3.p3.3.m3.1.1.1.cmml">×</mo><mn id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><times id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1.1"></times><cn type="integer" id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">14</cn><cn type="integer" id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">14\times 14</annotation></semantics></math> output locations predict an offset from their corresponding location in the image to each of the keypoint’s 2D locations. The network is trained with L1 (mean absolute error) loss as to be more lenient to outliers, since not every output location may be able to accurately predict the location of every keypoint.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">The goal of the downsampling-upsampling architecture is to combine both global and local image features to obtain more accurate keypoint predictions. As with the object detection network, the depthwise separable convolutions of MobileNetv2 drastically reduce the number of computations compared to typical CNNs and allow real-time inference on low-power devices.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Pose Estimation</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.3" class="ltx_p">The keypoint regression network produces <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="14\times 14=196" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mrow id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mrow id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml"><mn id="S3.SS4.p1.1.m1.1.1.2.2" xref="S3.SS4.p1.1.m1.1.1.2.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p1.1.m1.1.1.2.1" xref="S3.SS4.p1.1.m1.1.1.2.1.cmml">×</mo><mn id="S3.SS4.p1.1.m1.1.1.2.3" xref="S3.SS4.p1.1.m1.1.1.2.3.cmml">14</mn></mrow><mo id="S3.SS4.p1.1.m1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">196</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><eq id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1"></eq><apply id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2"><times id="S3.SS4.p1.1.m1.1.1.2.1.cmml" xref="S3.SS4.p1.1.m1.1.1.2.1"></times><cn type="integer" id="S3.SS4.p1.1.m1.1.1.2.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2.2">14</cn><cn type="integer" id="S3.SS4.p1.1.m1.1.1.2.3.cmml" xref="S3.SS4.p1.1.m1.1.1.2.3">14</cn></apply><cn type="integer" id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">196</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">14\times 14=196</annotation></semantics></math> predictions for each of <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mi id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><ci id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">n</annotation></semantics></math> keypoints, resulting in <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="196n" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mrow id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml"><mn id="S3.SS4.p1.3.m3.1.1.2" xref="S3.SS4.p1.3.m3.1.1.2.cmml">196</mn><mo lspace="0em" rspace="0em" id="S3.SS4.p1.3.m3.1.1.1" xref="S3.SS4.p1.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS4.p1.3.m3.1.1.3" xref="S3.SS4.p1.3.m3.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><apply id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1"><times id="S3.SS4.p1.3.m3.1.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1.1"></times><cn type="integer" id="S3.SS4.p1.3.m3.1.1.2.cmml" xref="S3.SS4.p1.3.m3.1.1.2">196</cn><ci id="S3.SS4.p1.3.m3.1.1.3.cmml" xref="S3.SS4.p1.3.m3.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">196n</annotation></semantics></math> total correspondences between 3D keypoints and their 2D locations in the image. The spacecraft pose can then be obtained using off-the-shelf PnP solver software. However, the keypoint regression is deliberately designed to be lenient to outliers, so random sample consensus (RANSAC)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> is also necessary to make the solution more robust. We use the <span id="S3.SS4.p1.3.1" class="ltx_text ltx_font_italic">solvePnPRansac</span> function from the open-source OpenCV <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> library configured to use the EPnP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> algorithm, which was found to provide the best balance of speed and accuracy.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Error Prediction</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Similar to CullNet<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, a 2D binary mask of the target spacecraft is first created using the estimated pose. This is done quickly using OpenGL. However, rather than concatenating the mask with the original image, the mask is instead used to “cut out” the shape of the target spacecraft; i.e., inside the mask, the original image is kept and outside the mask, every pixel is set to zero. All of these operations occur within the <math id="S3.SS5.p1.1.m1.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S3.SS5.p1.1.m1.1a"><mrow id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml"><mn id="S3.SS5.p1.1.m1.1.1.2" xref="S3.SS5.p1.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS5.p1.1.m1.1.1.1" xref="S3.SS5.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS5.p1.1.m1.1.1.3" xref="S3.SS5.p1.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><apply id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1"><times id="S3.SS5.p1.1.m1.1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS5.p1.1.m1.1.1.2.cmml" xref="S3.SS5.p1.1.m1.1.1.2">224</cn><cn type="integer" id="S3.SS5.p1.1.m1.1.1.3.cmml" xref="S3.SS5.p1.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">224\times 224</annotation></semantics></math> cropped RoI. The resulting cutout is used as the input to the error prediction network.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.8" class="ltx_p">Rather than trying to predict an error derived from the final pose solution, we found it more accurate to instead predict an error derived from the output of the keypoint regression network. The error metric we use is the mean Euclidean distance between all 2D keypoint estimates and their corresponding ground truth locations:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="E_{k}=\frac{1}{196n}\sum_{i=0}^{n}{\sum_{j=0}^{196}{||\bm{k_{i}-\bm{\hat{k}_{i,j}}}||}}" display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><msub id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml"><mi id="S3.E1.m1.3.3.3.2" xref="S3.E1.m1.3.3.3.2.cmml">E</mi><mi id="S3.E1.m1.3.3.3.3" xref="S3.E1.m1.3.3.3.3.cmml">k</mi></msub><mo id="S3.E1.m1.3.3.2" xref="S3.E1.m1.3.3.2.cmml">=</mo><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.cmml"><mfrac id="S3.E1.m1.3.3.1.3" xref="S3.E1.m1.3.3.1.3.cmml"><mn id="S3.E1.m1.3.3.1.3.2" xref="S3.E1.m1.3.3.1.3.2.cmml">1</mn><mrow id="S3.E1.m1.3.3.1.3.3" xref="S3.E1.m1.3.3.1.3.3.cmml"><mn id="S3.E1.m1.3.3.1.3.3.2" xref="S3.E1.m1.3.3.1.3.3.2.cmml">196</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.3.3.1" xref="S3.E1.m1.3.3.1.3.3.1.cmml">​</mo><mi id="S3.E1.m1.3.3.1.3.3.3" xref="S3.E1.m1.3.3.1.3.3.3.cmml">n</mi></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.2.cmml">​</mo><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><munderover id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E1.m1.3.3.1.1.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E1.m1.3.3.1.1.2.2.3" xref="S3.E1.m1.3.3.1.1.2.2.3.cmml"><mi id="S3.E1.m1.3.3.1.1.2.2.3.2" xref="S3.E1.m1.3.3.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E1.m1.3.3.1.1.2.2.3.1" xref="S3.E1.m1.3.3.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.3.3.1.1.2.2.3.3" xref="S3.E1.m1.3.3.1.1.2.2.3.3.cmml">0</mn></mrow><mi id="S3.E1.m1.3.3.1.1.2.3" xref="S3.E1.m1.3.3.1.1.2.3.cmml">n</mi></munderover><mrow id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.cmml"><munderover id="S3.E1.m1.3.3.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E1.m1.3.3.1.1.1.2.2.2" xref="S3.E1.m1.3.3.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E1.m1.3.3.1.1.1.2.2.3" xref="S3.E1.m1.3.3.1.1.1.2.2.3.cmml"><mi id="S3.E1.m1.3.3.1.1.1.2.2.3.2" xref="S3.E1.m1.3.3.1.1.1.2.2.3.2.cmml">j</mi><mo id="S3.E1.m1.3.3.1.1.1.2.2.3.1" xref="S3.E1.m1.3.3.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.3.3.1.1.1.2.2.3.3" xref="S3.E1.m1.3.3.1.1.1.2.2.3.3.cmml">0</mn></mrow><mn id="S3.E1.m1.3.3.1.1.1.2.3" xref="S3.E1.m1.3.3.1.1.1.2.3.cmml">196</mn></munderover><mrow id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.3.3.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.2.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2.2.cmml">𝒌</mi><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.2.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2.3.cmml">𝒊</mi></msub><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S3.E1.m1.3.3.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E1.m1.3.3.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.3.3.1.1.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.2.cmml">𝒌</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mrow id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">𝒊</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S3.E1.m1.2.2.2.4.1" xref="S3.E1.m1.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">𝒋</mi></mrow></msub></mrow><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><eq id="S3.E1.m1.3.3.2.cmml" xref="S3.E1.m1.3.3.2"></eq><apply id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.1.cmml" xref="S3.E1.m1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.3.3.3.2.cmml" xref="S3.E1.m1.3.3.3.2">𝐸</ci><ci id="S3.E1.m1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3">𝑘</ci></apply><apply id="S3.E1.m1.3.3.1.cmml" xref="S3.E1.m1.3.3.1"><times id="S3.E1.m1.3.3.1.2.cmml" xref="S3.E1.m1.3.3.1.2"></times><apply id="S3.E1.m1.3.3.1.3.cmml" xref="S3.E1.m1.3.3.1.3"><divide id="S3.E1.m1.3.3.1.3.1.cmml" xref="S3.E1.m1.3.3.1.3"></divide><cn type="integer" id="S3.E1.m1.3.3.1.3.2.cmml" xref="S3.E1.m1.3.3.1.3.2">1</cn><apply id="S3.E1.m1.3.3.1.3.3.cmml" xref="S3.E1.m1.3.3.1.3.3"><times id="S3.E1.m1.3.3.1.3.3.1.cmml" xref="S3.E1.m1.3.3.1.3.3.1"></times><cn type="integer" id="S3.E1.m1.3.3.1.3.3.2.cmml" xref="S3.E1.m1.3.3.1.3.3.2">196</cn><ci id="S3.E1.m1.3.3.1.3.3.3.cmml" xref="S3.E1.m1.3.3.1.3.3.3">𝑛</ci></apply></apply><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1"><apply id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.2.1.cmml" xref="S3.E1.m1.3.3.1.1.2">superscript</csymbol><apply id="S3.E1.m1.3.3.1.1.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.2">subscript</csymbol><sum id="S3.E1.m1.3.3.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2"></sum><apply id="S3.E1.m1.3.3.1.1.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2.3"><eq id="S3.E1.m1.3.3.1.1.2.2.3.1.cmml" xref="S3.E1.m1.3.3.1.1.2.2.3.1"></eq><ci id="S3.E1.m1.3.3.1.1.2.2.3.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S3.E1.m1.3.3.1.1.2.2.3.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2.3.3">0</cn></apply></apply><ci id="S3.E1.m1.3.3.1.1.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.3">𝑛</ci></apply><apply id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"><apply id="S3.E1.m1.3.3.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.2">superscript</csymbol><apply id="S3.E1.m1.3.3.1.1.1.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.2">subscript</csymbol><sum id="S3.E1.m1.3.3.1.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.2.2.2"></sum><apply id="S3.E1.m1.3.3.1.1.1.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.2.2.3"><eq id="S3.E1.m1.3.3.1.1.1.2.2.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.2.2.3.1"></eq><ci id="S3.E1.m1.3.3.1.1.1.2.2.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.2.2.3.2">𝑗</ci><cn type="integer" id="S3.E1.m1.3.3.1.1.1.2.2.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.2.2.3.3">0</cn></apply></apply><cn type="integer" id="S3.E1.m1.3.3.1.1.1.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.2.3">196</cn></apply><apply id="S3.E1.m1.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2">norm</csymbol><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1"><minus id="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1"></minus><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2.2">𝒌</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2.3">𝒊</ci></apply><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.2"><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.1">bold-^</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.2">𝒌</ci></apply><list id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">𝒊</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">𝒋</ci></list></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">E_{k}=\frac{1}{196n}\sum_{i=0}^{n}{\sum_{j=0}^{196}{||\bm{k_{i}-\bm{\hat{k}_{i,j}}}||}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS5.p2.7" class="ltx_p">where <math id="S3.SS5.p2.1.m1.1" class="ltx_Math" alttext="\bm{k_{i}}" display="inline"><semantics id="S3.SS5.p2.1.m1.1a"><msub id="S3.SS5.p2.1.m1.1.1" xref="S3.SS5.p2.1.m1.1.1.cmml"><mi id="S3.SS5.p2.1.m1.1.1.2" xref="S3.SS5.p2.1.m1.1.1.2.cmml">𝒌</mi><mi id="S3.SS5.p2.1.m1.1.1.3" xref="S3.SS5.p2.1.m1.1.1.3.cmml">𝒊</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.1.m1.1b"><apply id="S3.SS5.p2.1.m1.1.1.cmml" xref="S3.SS5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.1.m1.1.1.1.cmml" xref="S3.SS5.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.p2.1.m1.1.1.2.cmml" xref="S3.SS5.p2.1.m1.1.1.2">𝒌</ci><ci id="S3.SS5.p2.1.m1.1.1.3.cmml" xref="S3.SS5.p2.1.m1.1.1.3">𝒊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.1.m1.1c">\bm{k_{i}}</annotation></semantics></math> is the ground truth location of the <math id="S3.SS5.p2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS5.p2.2.m2.1a"><mi id="S3.SS5.p2.2.m2.1.1" xref="S3.SS5.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.2.m2.1b"><ci id="S3.SS5.p2.2.m2.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.2.m2.1c">i</annotation></semantics></math>th keypoint, and <math id="S3.SS5.p2.3.m3.2" class="ltx_Math" alttext="\bm{\hat{k}_{i,j}}" display="inline"><semantics id="S3.SS5.p2.3.m3.2a"><msub id="S3.SS5.p2.3.m3.2.3" xref="S3.SS5.p2.3.m3.2.3.cmml"><mover accent="true" id="S3.SS5.p2.3.m3.2.3.2" xref="S3.SS5.p2.3.m3.2.3.2.cmml"><mi id="S3.SS5.p2.3.m3.2.3.2.2" xref="S3.SS5.p2.3.m3.2.3.2.2.cmml">𝒌</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S3.SS5.p2.3.m3.2.3.2.1" xref="S3.SS5.p2.3.m3.2.3.2.1.cmml">^</mo></mover><mrow id="S3.SS5.p2.3.m3.2.2.2.4" xref="S3.SS5.p2.3.m3.2.2.2.3.cmml"><mi id="S3.SS5.p2.3.m3.1.1.1.1" xref="S3.SS5.p2.3.m3.1.1.1.1.cmml">𝒊</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S3.SS5.p2.3.m3.2.2.2.4.1" xref="S3.SS5.p2.3.m3.2.2.2.3.cmml">,</mo><mi id="S3.SS5.p2.3.m3.2.2.2.2" xref="S3.SS5.p2.3.m3.2.2.2.2.cmml">𝒋</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.3.m3.2b"><apply id="S3.SS5.p2.3.m3.2.3.cmml" xref="S3.SS5.p2.3.m3.2.3"><csymbol cd="ambiguous" id="S3.SS5.p2.3.m3.2.3.1.cmml" xref="S3.SS5.p2.3.m3.2.3">subscript</csymbol><apply id="S3.SS5.p2.3.m3.2.3.2.cmml" xref="S3.SS5.p2.3.m3.2.3.2"><ci id="S3.SS5.p2.3.m3.2.3.2.1.cmml" xref="S3.SS5.p2.3.m3.2.3.2.1">bold-^</ci><ci id="S3.SS5.p2.3.m3.2.3.2.2.cmml" xref="S3.SS5.p2.3.m3.2.3.2.2">𝒌</ci></apply><list id="S3.SS5.p2.3.m3.2.2.2.3.cmml" xref="S3.SS5.p2.3.m3.2.2.2.4"><ci id="S3.SS5.p2.3.m3.1.1.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1.1.1">𝒊</ci><ci id="S3.SS5.p2.3.m3.2.2.2.2.cmml" xref="S3.SS5.p2.3.m3.2.2.2.2">𝒋</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.3.m3.2c">\bm{\hat{k}_{i,j}}</annotation></semantics></math> is the <math id="S3.SS5.p2.4.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS5.p2.4.m4.1a"><mi id="S3.SS5.p2.4.m4.1.1" xref="S3.SS5.p2.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.4.m4.1b"><ci id="S3.SS5.p2.4.m4.1.1.cmml" xref="S3.SS5.p2.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.4.m4.1c">j</annotation></semantics></math>th estimate for the <math id="S3.SS5.p2.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS5.p2.5.m5.1a"><mi id="S3.SS5.p2.5.m5.1.1" xref="S3.SS5.p2.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.5.m5.1b"><ci id="S3.SS5.p2.5.m5.1.1.cmml" xref="S3.SS5.p2.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.5.m5.1c">i</annotation></semantics></math>th keypoint from the keypoint regression network. Keypoint locations are expressed as 2D pixel coordinates within the <math id="S3.SS5.p2.6.m6.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S3.SS5.p2.6.m6.1a"><mrow id="S3.SS5.p2.6.m6.1.1" xref="S3.SS5.p2.6.m6.1.1.cmml"><mn id="S3.SS5.p2.6.m6.1.1.2" xref="S3.SS5.p2.6.m6.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS5.p2.6.m6.1.1.1" xref="S3.SS5.p2.6.m6.1.1.1.cmml">×</mo><mn id="S3.SS5.p2.6.m6.1.1.3" xref="S3.SS5.p2.6.m6.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.6.m6.1b"><apply id="S3.SS5.p2.6.m6.1.1.cmml" xref="S3.SS5.p2.6.m6.1.1"><times id="S3.SS5.p2.6.m6.1.1.1.cmml" xref="S3.SS5.p2.6.m6.1.1.1"></times><cn type="integer" id="S3.SS5.p2.6.m6.1.1.2.cmml" xref="S3.SS5.p2.6.m6.1.1.2">224</cn><cn type="integer" id="S3.SS5.p2.6.m6.1.1.3.cmml" xref="S3.SS5.p2.6.m6.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.6.m6.1c">224\times 224</annotation></semantics></math> cropped RoI. The task of the error prediction network is thus to take a cutout as the input and regress <math id="S3.SS5.p2.7.m7.1" class="ltx_Math" alttext="E_{k}" display="inline"><semantics id="S3.SS5.p2.7.m7.1a"><msub id="S3.SS5.p2.7.m7.1.1" xref="S3.SS5.p2.7.m7.1.1.cmml"><mi id="S3.SS5.p2.7.m7.1.1.2" xref="S3.SS5.p2.7.m7.1.1.2.cmml">E</mi><mi id="S3.SS5.p2.7.m7.1.1.3" xref="S3.SS5.p2.7.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.7.m7.1b"><apply id="S3.SS5.p2.7.m7.1.1.cmml" xref="S3.SS5.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.7.m7.1.1.1.cmml" xref="S3.SS5.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS5.p2.7.m7.1.1.2.cmml" xref="S3.SS5.p2.7.m7.1.1.2">𝐸</ci><ci id="S3.SS5.p2.7.m7.1.1.3.cmml" xref="S3.SS5.p2.7.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.7.m7.1c">E_{k}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p id="S3.SS5.p3.1" class="ltx_p">The cutout method allows the error prediction network to reuse nearly the full architecture and weights of the keypoint regression network, with only the final <math id="S3.SS5.p3.1.m1.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S3.SS5.p3.1.m1.1a"><mrow id="S3.SS5.p3.1.m1.1.1" xref="S3.SS5.p3.1.m1.1.1.cmml"><mn id="S3.SS5.p3.1.m1.1.1.2" xref="S3.SS5.p3.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS5.p3.1.m1.1.1.1" xref="S3.SS5.p3.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS5.p3.1.m1.1.1.3" xref="S3.SS5.p3.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.1.m1.1b"><apply id="S3.SS5.p3.1.m1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1"><times id="S3.SS5.p3.1.m1.1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1.1"></times><cn type="integer" id="S3.SS5.p3.1.m1.1.1.2.cmml" xref="S3.SS5.p3.1.m1.1.1.2">1</cn><cn type="integer" id="S3.SS5.p3.1.m1.1.1.3.cmml" xref="S3.SS5.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.1.m1.1c">1\times 1</annotation></semantics></math> convolution replaced with a fully connected layer. We found the ability to initialize the error prediction network with the weights of the keypoint regression network to significantly aid training.</p>
</div>
<div id="S3.SS5.p4" class="ltx_para">
<p id="S3.SS5.p4.1" class="ltx_p">Once the network produces a prediction for the keypoint error, <math id="S3.SS5.p4.1.m1.1" class="ltx_Math" alttext="\hat{E_{k}}" display="inline"><semantics id="S3.SS5.p4.1.m1.1a"><mover accent="true" id="S3.SS5.p4.1.m1.1.1" xref="S3.SS5.p4.1.m1.1.1.cmml"><msub id="S3.SS5.p4.1.m1.1.1.2" xref="S3.SS5.p4.1.m1.1.1.2.cmml"><mi id="S3.SS5.p4.1.m1.1.1.2.2" xref="S3.SS5.p4.1.m1.1.1.2.2.cmml">E</mi><mi id="S3.SS5.p4.1.m1.1.1.2.3" xref="S3.SS5.p4.1.m1.1.1.2.3.cmml">k</mi></msub><mo id="S3.SS5.p4.1.m1.1.1.1" xref="S3.SS5.p4.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS5.p4.1.m1.1b"><apply id="S3.SS5.p4.1.m1.1.1.cmml" xref="S3.SS5.p4.1.m1.1.1"><ci id="S3.SS5.p4.1.m1.1.1.1.cmml" xref="S3.SS5.p4.1.m1.1.1.1">^</ci><apply id="S3.SS5.p4.1.m1.1.1.2.cmml" xref="S3.SS5.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS5.p4.1.m1.1.1.2.1.cmml" xref="S3.SS5.p4.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS5.p4.1.m1.1.1.2.2.cmml" xref="S3.SS5.p4.1.m1.1.1.2.2">𝐸</ci><ci id="S3.SS5.p4.1.m1.1.1.2.3.cmml" xref="S3.SS5.p4.1.m1.1.1.2.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p4.1.m1.1c">\hat{E_{k}}</annotation></semantics></math>, a threshold must be chosen above which pose estimates are rejected. Using the synthetic test set, we choose 20 pixels as a good balance between rejecting bad estimates and keeping good ones.</p>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Synthetic Data Generation</h3>

<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/cyg_re.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">Cygnus with no augmentations in front of a real Earth background</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/cyg_drb.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">Cygnus in front of a randomized background</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/cyg_blur.png" id="S3.F3.sf3.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F3.sf3.3.2" class="ltx_text" style="font-size:90%;">Cygnus with a blur effect</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/cyg_lensflare.png" id="S3.F3.sf4.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F3.sf4.3.2" class="ltx_text" style="font-size:90%;">Cygnus with a lens flare effect</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/cyg_fogglow.png" id="S3.F3.sf5.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S3.F3.sf5.3.2" class="ltx_text" style="font-size:90%;">Cygnus with a “fog glow” effect</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/cyg_simplestar.png" id="S3.F3.sf6.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf6.2.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><span id="S3.F3.sf6.3.2" class="ltx_text" style="font-size:90%;">Cygnus with a “simple star” effect</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Example synthetic images with and without augmentations. The bottom row all falls under the category of “glare and lens flares”.</span></figcaption>
</figure>
<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.1" class="ltx_p">Due to the scarcity of labeled real images, we generate synthetic images for our experiments with the Northrop Grumman Enhanced Cygnus spacecraft. Images are generated using Blender <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, an open-source 3D modeling suite, and its Cycles<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.cycles-renderer.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.cycles-renderer.org/</a></span></span></span> rendering engine. Cycles is a physically-based, ray-tracing, production-quality rendering engine. In comparison to prior work which has used OpenGL shaders<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> or Unreal Engine<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, we use Cycles to better mimic real camera parameters and produce more photorealistic images. We obtain our model of the Cygnus spacecraft from an open-source GitHub repository<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/brickmack/Blender-Spaceflight-Models" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/brickmack/Blender-Spaceflight-Models</a></span></span></span>.</p>
</div>
<div id="S3.SS6.p2" class="ltx_para">
<p id="S3.SS6.p2.1" class="ltx_p">Blender’s powerful Python API also allows easy configuration of the camera position, lighting angle, and spacecraft pose. We use a custom-built library<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://autognc-starfish.readthedocs.io" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://autognc-starfish.readthedocs.io</a></span></span></span> to leverage this API and enable flexible, automated generation of labeled synthetic images.</p>
</div>
<div id="S3.SS6.p3" class="ltx_para">
<p id="S3.SS6.p3.1" class="ltx_p">To better simulate images taken in the true space environment, we additionally use Blender to add custom augmentations to the synthetic data. These augmentations include various types of randomized glare, lens flares, blur, and background images. Two types of background images are used. The first is real satellite photos of Earth, intended to further improve realism. The second is completely randomized non-realistic background images, intended to reduce overfitting during training and improve generalization to the variance present in real images. These augmentations to the training data have led to a marked increase in the performance of the pose estimation system on real images.</p>
</div>
</section>
<section id="S3.SS7" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.7 </span>Training Details</h3>

<div id="S3.SS7.p1" class="ltx_para">
<p id="S3.SS7.p1.1" class="ltx_p">The object detection network is initialized with weights pre-trained on the COCO 2017 dataset<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. It is trained for 40,000 steps using the Adam optimizer with a batch size of 10 and an initial learning rate of 0.001 that decays to 0.0001 at 20,000 steps and 0.00001 at 30,000 steps. Random flips, 90° rotations, and crops are applied.</p>
</div>
<div id="S3.SS7.p2" class="ltx_para">
<p id="S3.SS7.p2.1" class="ltx_p">The MobileNetv2 portion of the keypoint regression network is initialized with weights pre-trained on the ImageNet dataset<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. The entire network is then trained for 300 epochs using the Adam optimizer with a batch size of 60 and an initial learning rate of 0.001 that decays to 0.0001 at 100 epochs and begins decaying exponentially after 200 epochs as <math id="S3.SS7.p2.1.m1.1" class="ltx_Math" alttext="0.001e^{-0.05(\text{epoch}-200)}" display="inline"><semantics id="S3.SS7.p2.1.m1.1a"><mrow id="S3.SS7.p2.1.m1.1.2" xref="S3.SS7.p2.1.m1.1.2.cmml"><mn id="S3.SS7.p2.1.m1.1.2.2" xref="S3.SS7.p2.1.m1.1.2.2.cmml">0.001</mn><mo lspace="0em" rspace="0em" id="S3.SS7.p2.1.m1.1.2.1" xref="S3.SS7.p2.1.m1.1.2.1.cmml">​</mo><msup id="S3.SS7.p2.1.m1.1.2.3" xref="S3.SS7.p2.1.m1.1.2.3.cmml"><mi id="S3.SS7.p2.1.m1.1.2.3.2" xref="S3.SS7.p2.1.m1.1.2.3.2.cmml">e</mi><mrow id="S3.SS7.p2.1.m1.1.1.1" xref="S3.SS7.p2.1.m1.1.1.1.cmml"><mo id="S3.SS7.p2.1.m1.1.1.1a" xref="S3.SS7.p2.1.m1.1.1.1.cmml">−</mo><mrow id="S3.SS7.p2.1.m1.1.1.1.1" xref="S3.SS7.p2.1.m1.1.1.1.1.cmml"><mn id="S3.SS7.p2.1.m1.1.1.1.1.3" xref="S3.SS7.p2.1.m1.1.1.1.1.3.cmml">0.05</mn><mo lspace="0em" rspace="0em" id="S3.SS7.p2.1.m1.1.1.1.1.2" xref="S3.SS7.p2.1.m1.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS7.p2.1.m1.1.1.1.1.1.1" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS7.p2.1.m1.1.1.1.1.1.1.2" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS7.p2.1.m1.1.1.1.1.1.1.1" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.cmml"><mtext id="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.2" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.2a.cmml">epoch</mtext><mo id="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.1" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.3" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.3.cmml">200</mn></mrow><mo stretchy="false" id="S3.SS7.p2.1.m1.1.1.1.1.1.1.3" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS7.p2.1.m1.1b"><apply id="S3.SS7.p2.1.m1.1.2.cmml" xref="S3.SS7.p2.1.m1.1.2"><times id="S3.SS7.p2.1.m1.1.2.1.cmml" xref="S3.SS7.p2.1.m1.1.2.1"></times><cn type="float" id="S3.SS7.p2.1.m1.1.2.2.cmml" xref="S3.SS7.p2.1.m1.1.2.2">0.001</cn><apply id="S3.SS7.p2.1.m1.1.2.3.cmml" xref="S3.SS7.p2.1.m1.1.2.3"><csymbol cd="ambiguous" id="S3.SS7.p2.1.m1.1.2.3.1.cmml" xref="S3.SS7.p2.1.m1.1.2.3">superscript</csymbol><ci id="S3.SS7.p2.1.m1.1.2.3.2.cmml" xref="S3.SS7.p2.1.m1.1.2.3.2">𝑒</ci><apply id="S3.SS7.p2.1.m1.1.1.1.cmml" xref="S3.SS7.p2.1.m1.1.1.1"><minus id="S3.SS7.p2.1.m1.1.1.1.2.cmml" xref="S3.SS7.p2.1.m1.1.1.1"></minus><apply id="S3.SS7.p2.1.m1.1.1.1.1.cmml" xref="S3.SS7.p2.1.m1.1.1.1.1"><times id="S3.SS7.p2.1.m1.1.1.1.1.2.cmml" xref="S3.SS7.p2.1.m1.1.1.1.1.2"></times><cn type="float" id="S3.SS7.p2.1.m1.1.1.1.1.3.cmml" xref="S3.SS7.p2.1.m1.1.1.1.1.3">0.05</cn><apply id="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1"><minus id="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.1"></minus><ci id="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.2a.cmml" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.2"><mtext mathsize="70%" id="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.2">epoch</mtext></ci><cn type="integer" id="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS7.p2.1.m1.1.1.1.1.1.1.1.3">200</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS7.p2.1.m1.1c">0.001e^{-0.05(\text{epoch}-200)}</annotation></semantics></math>. The RoIs used for training are derived from the ground-truth bounding box labels with random translations and expansions applied. Random flips, 90° rotations, brightness, contrast, and saturation augmentations are also applied.</p>
</div>
<div id="S3.SS7.p3" class="ltx_para">
<p id="S3.SS7.p3.1" class="ltx_p">The error prediction network is initialized with weights from the fully trained keypoint regression network. The training data is a holdout test set consisting of synthetic images never seen by the object detection or keypoint regression networks. The network is trained for 50 epochs using the Adam optimizer with a batch size of 64 and a learning rate of 0.001.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<section id="S4.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Evaluation Metrics</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">For evaluating the object detection network individually, we use the standard intersection-over-union (IoU) of the detected and ground-truth bounding boxes. We also report an additional metric we call RoI accuracy, which is the proportion of images in which the final region of interest (the detected bounding box squared and expanded by 25%) contains the entire ground-truth bounding box.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.6" class="ltx_p">Pose is represented as a pair <math id="S4.SS1.p2.1.m1.2" class="ltx_Math" alttext="(\bm{q,t})" display="inline"><semantics id="S4.SS1.p2.1.m1.2a"><mrow id="S4.SS1.p2.1.m1.2.3.2" xref="S4.SS1.p2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.SS1.p2.1.m1.2.3.2.1" xref="S4.SS1.p2.1.m1.2.3.1.cmml">(</mo><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">𝒒</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.SS1.p2.1.m1.2.3.2.2" xref="S4.SS1.p2.1.m1.2.3.1.cmml">,</mo><mi id="S4.SS1.p2.1.m1.2.2" xref="S4.SS1.p2.1.m1.2.2.cmml">𝒕</mi><mo stretchy="false" id="S4.SS1.p2.1.m1.2.3.2.3" xref="S4.SS1.p2.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.2b"><interval closure="open" id="S4.SS1.p2.1.m1.2.3.1.cmml" xref="S4.SS1.p2.1.m1.2.3.2"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝒒</ci><ci id="S4.SS1.p2.1.m1.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2">𝒕</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.2c">(\bm{q,t})</annotation></semantics></math> where <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mi id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">𝒒</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">𝒒</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\bm{q}</annotation></semantics></math> is a rotation represented as a quaternion and <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="\bm{t}" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mi id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">𝒕</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><ci id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">𝒕</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\bm{t}</annotation></semantics></math> is a 3-dimensional translation vector. Applied together, <math id="S4.SS1.p2.4.m4.2" class="ltx_Math" alttext="(\bm{q,t})" display="inline"><semantics id="S4.SS1.p2.4.m4.2a"><mrow id="S4.SS1.p2.4.m4.2.3.2" xref="S4.SS1.p2.4.m4.2.3.1.cmml"><mo stretchy="false" id="S4.SS1.p2.4.m4.2.3.2.1" xref="S4.SS1.p2.4.m4.2.3.1.cmml">(</mo><mi id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml">𝒒</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.SS1.p2.4.m4.2.3.2.2" xref="S4.SS1.p2.4.m4.2.3.1.cmml">,</mo><mi id="S4.SS1.p2.4.m4.2.2" xref="S4.SS1.p2.4.m4.2.2.cmml">𝒕</mi><mo stretchy="false" id="S4.SS1.p2.4.m4.2.3.2.3" xref="S4.SS1.p2.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.2b"><interval closure="open" id="S4.SS1.p2.4.m4.2.3.1.cmml" xref="S4.SS1.p2.4.m4.2.3.2"><ci id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">𝒒</ci><ci id="S4.SS1.p2.4.m4.2.2.cmml" xref="S4.SS1.p2.4.m4.2.2">𝒕</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.2c">(\bm{q,t})</annotation></semantics></math> align the camera reference frame with the target reference frame. 4 metrics will be used to measure the error between a ground-truth pose <math id="S4.SS1.p2.5.m5.2" class="ltx_Math" alttext="(\bm{q,t})" display="inline"><semantics id="S4.SS1.p2.5.m5.2a"><mrow id="S4.SS1.p2.5.m5.2.3.2" xref="S4.SS1.p2.5.m5.2.3.1.cmml"><mo stretchy="false" id="S4.SS1.p2.5.m5.2.3.2.1" xref="S4.SS1.p2.5.m5.2.3.1.cmml">(</mo><mi id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml">𝒒</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.SS1.p2.5.m5.2.3.2.2" xref="S4.SS1.p2.5.m5.2.3.1.cmml">,</mo><mi id="S4.SS1.p2.5.m5.2.2" xref="S4.SS1.p2.5.m5.2.2.cmml">𝒕</mi><mo stretchy="false" id="S4.SS1.p2.5.m5.2.3.2.3" xref="S4.SS1.p2.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.2b"><interval closure="open" id="S4.SS1.p2.5.m5.2.3.1.cmml" xref="S4.SS1.p2.5.m5.2.3.2"><ci id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">𝒒</ci><ci id="S4.SS1.p2.5.m5.2.2.cmml" xref="S4.SS1.p2.5.m5.2.2">𝒕</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.2c">(\bm{q,t})</annotation></semantics></math> and predicted pose <math id="S4.SS1.p2.6.m6.2" class="ltx_Math" alttext="(\bm{\hat{q},\hat{t}})" display="inline"><semantics id="S4.SS1.p2.6.m6.2a"><mrow id="S4.SS1.p2.6.m6.2.3.2" xref="S4.SS1.p2.6.m6.2.3.1.cmml"><mo stretchy="false" id="S4.SS1.p2.6.m6.2.3.2.1" xref="S4.SS1.p2.6.m6.2.3.1.cmml">(</mo><mover accent="true" id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml"><mi id="S4.SS1.p2.6.m6.1.1.2" xref="S4.SS1.p2.6.m6.1.1.2.cmml">𝒒</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.SS1.p2.6.m6.1.1.1" xref="S4.SS1.p2.6.m6.1.1.1.cmml">^</mo></mover><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.SS1.p2.6.m6.2.3.2.2" xref="S4.SS1.p2.6.m6.2.3.1.cmml">,</mo><mover accent="true" id="S4.SS1.p2.6.m6.2.2" xref="S4.SS1.p2.6.m6.2.2.cmml"><mi id="S4.SS1.p2.6.m6.2.2.2" xref="S4.SS1.p2.6.m6.2.2.2.cmml">𝒕</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.SS1.p2.6.m6.2.2.1" xref="S4.SS1.p2.6.m6.2.2.1.cmml">^</mo></mover><mo stretchy="false" id="S4.SS1.p2.6.m6.2.3.2.3" xref="S4.SS1.p2.6.m6.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.2b"><interval closure="open" id="S4.SS1.p2.6.m6.2.3.1.cmml" xref="S4.SS1.p2.6.m6.2.3.2"><apply id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1"><ci id="S4.SS1.p2.6.m6.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1">bold-^</ci><ci id="S4.SS1.p2.6.m6.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.2">𝒒</ci></apply><apply id="S4.SS1.p2.6.m6.2.2.cmml" xref="S4.SS1.p2.6.m6.2.2"><ci id="S4.SS1.p2.6.m6.2.2.1.cmml" xref="S4.SS1.p2.6.m6.2.2.1">bold-^</ci><ci id="S4.SS1.p2.6.m6.2.2.2.cmml" xref="S4.SS1.p2.6.m6.2.2.2">𝒕</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.2c">(\bm{\hat{q},\hat{t}})</annotation></semantics></math>. The first metric measures the rotation error, computed as:</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.1" class="ltx_Math" alttext="E_{R}=2\arccos{|\bm{q}\cdot\bm{\hat{q}}|}" display="block"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><msub id="S4.E2.m1.1.1.3" xref="S4.E2.m1.1.1.3.cmml"><mi id="S4.E2.m1.1.1.3.2" xref="S4.E2.m1.1.1.3.2.cmml">E</mi><mi id="S4.E2.m1.1.1.3.3" xref="S4.E2.m1.1.1.3.3.cmml">R</mi></msub><mo id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml">=</mo><mrow id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.cmml"><mn id="S4.E2.m1.1.1.1.3" xref="S4.E2.m1.1.1.1.3.cmml">2</mn><mo lspace="0.167em" rspace="0em" id="S4.E2.m1.1.1.1.2" xref="S4.E2.m1.1.1.1.2.cmml">​</mo><mrow id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.2.cmml">arccos</mi><mo id="S4.E2.m1.1.1.1.1a" xref="S4.E2.m1.1.1.1.1.cmml">⁡</mo><mrow id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.1.2.cmml">𝒒</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E2.m1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.1.cmml">⋅</mo><mover accent="true" id="S4.E2.m1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.1.1.1.1.3.2.cmml">𝒒</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.E2.m1.1.1.1.1.1.1.1.3.1" xref="S4.E2.m1.1.1.1.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1"><eq id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2"></eq><apply id="S4.E2.m1.1.1.3.cmml" xref="S4.E2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.3">subscript</csymbol><ci id="S4.E2.m1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.3.2">𝐸</ci><ci id="S4.E2.m1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.3.3">𝑅</ci></apply><apply id="S4.E2.m1.1.1.1.cmml" xref="S4.E2.m1.1.1.1"><times id="S4.E2.m1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.2"></times><cn type="integer" id="S4.E2.m1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.3">2</cn><apply id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1"><arccos id="S4.E2.m1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.2"></arccos><apply id="S4.E2.m1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1"><abs id="S4.E2.m1.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2"></abs><apply id="S4.E2.m1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1"><ci id="S4.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1">⋅</ci><ci id="S4.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.2">𝒒</ci><apply id="S4.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.3"><ci id="S4.E2.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.3.1">bold-^</ci><ci id="S4.E2.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.3.2">𝒒</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">E_{R}=2\arccos{|\bm{q}\cdot\bm{\hat{q}}|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p2.10" class="ltx_p">where <math id="S4.SS1.p2.7.m1.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="S4.SS1.p2.7.m1.1a"><mo id="S4.SS1.p2.7.m1.1.1" xref="S4.SS1.p2.7.m1.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m1.1b"><ci id="S4.SS1.p2.7.m1.1.1.cmml" xref="S4.SS1.p2.7.m1.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m1.1c">\cdot</annotation></semantics></math> is the vector dot product. <math id="S4.SS1.p2.8.m2.1" class="ltx_Math" alttext="E_{R}" display="inline"><semantics id="S4.SS1.p2.8.m2.1a"><msub id="S4.SS1.p2.8.m2.1.1" xref="S4.SS1.p2.8.m2.1.1.cmml"><mi id="S4.SS1.p2.8.m2.1.1.2" xref="S4.SS1.p2.8.m2.1.1.2.cmml">E</mi><mi id="S4.SS1.p2.8.m2.1.1.3" xref="S4.SS1.p2.8.m2.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m2.1b"><apply id="S4.SS1.p2.8.m2.1.1.cmml" xref="S4.SS1.p2.8.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.8.m2.1.1.1.cmml" xref="S4.SS1.p2.8.m2.1.1">subscript</csymbol><ci id="S4.SS1.p2.8.m2.1.1.2.cmml" xref="S4.SS1.p2.8.m2.1.1.2">𝐸</ci><ci id="S4.SS1.p2.8.m2.1.1.3.cmml" xref="S4.SS1.p2.8.m2.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m2.1c">E_{R}</annotation></semantics></math> corresponds to the angle of the smallest rotation that aligns <math id="S4.SS1.p2.9.m3.1" class="ltx_Math" alttext="\bm{\hat{q}}" display="inline"><semantics id="S4.SS1.p2.9.m3.1a"><mover accent="true" id="S4.SS1.p2.9.m3.1.1" xref="S4.SS1.p2.9.m3.1.1.cmml"><mi id="S4.SS1.p2.9.m3.1.1.2" xref="S4.SS1.p2.9.m3.1.1.2.cmml">𝒒</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.SS1.p2.9.m3.1.1.1" xref="S4.SS1.p2.9.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.9.m3.1b"><apply id="S4.SS1.p2.9.m3.1.1.cmml" xref="S4.SS1.p2.9.m3.1.1"><ci id="S4.SS1.p2.9.m3.1.1.1.cmml" xref="S4.SS1.p2.9.m3.1.1.1">bold-^</ci><ci id="S4.SS1.p2.9.m3.1.1.2.cmml" xref="S4.SS1.p2.9.m3.1.1.2">𝒒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.9.m3.1c">\bm{\hat{q}}</annotation></semantics></math> and <math id="S4.SS1.p2.10.m4.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S4.SS1.p2.10.m4.1a"><mi id="S4.SS1.p2.10.m4.1.1" xref="S4.SS1.p2.10.m4.1.1.cmml">𝒒</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.10.m4.1b"><ci id="S4.SS1.p2.10.m4.1.1.cmml" xref="S4.SS1.p2.10.m4.1.1">𝒒</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.10.m4.1c">\bm{q}</annotation></semantics></math>. Another two metrics measure the translation error:</p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.1" class="ltx_Math" alttext="E_{T}=||\bm{t}-\bm{\hat{t}}||" display="block"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml"><msub id="S4.E3.m1.1.1.3" xref="S4.E3.m1.1.1.3.cmml"><mi id="S4.E3.m1.1.1.3.2" xref="S4.E3.m1.1.1.3.2.cmml">E</mi><mi id="S4.E3.m1.1.1.3.3" xref="S4.E3.m1.1.1.3.3.cmml">T</mi></msub><mo id="S4.E3.m1.1.1.2" xref="S4.E3.m1.1.1.2.cmml">=</mo><mrow id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E3.m1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.2.1.cmml">‖</mo><mrow id="S4.E3.m1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.cmml"><mi id="S4.E3.m1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.2.cmml">𝒕</mi><mo id="S4.E3.m1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S4.E3.m1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.3.cmml"><mi id="S4.E3.m1.1.1.1.1.1.3.2" xref="S4.E3.m1.1.1.1.1.1.3.2.cmml">𝒕</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.E3.m1.1.1.1.1.1.3.1" xref="S4.E3.m1.1.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S4.E3.m1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.2.1.cmml">‖</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1"><eq id="S4.E3.m1.1.1.2.cmml" xref="S4.E3.m1.1.1.2"></eq><apply id="S4.E3.m1.1.1.3.cmml" xref="S4.E3.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.3">subscript</csymbol><ci id="S4.E3.m1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.3.2">𝐸</ci><ci id="S4.E3.m1.1.1.3.3.cmml" xref="S4.E3.m1.1.1.3.3">𝑇</ci></apply><apply id="S4.E3.m1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1"><csymbol cd="latexml" id="S4.E3.m1.1.1.1.2.1.cmml" xref="S4.E3.m1.1.1.1.1.2">norm</csymbol><apply id="S4.E3.m1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1"><minus id="S4.E3.m1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1"></minus><ci id="S4.E3.m1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.2">𝒕</ci><apply id="S4.E3.m1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.3"><ci id="S4.E3.m1.1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.1.1.1.3.1">bold-^</ci><ci id="S4.E3.m1.1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.1.1.1.3.2">𝒕</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">E_{T}=||\bm{t}-\bm{\hat{t}}||</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.2" class="ltx_Math" alttext="E_{TN}=\frac{||\bm{t}-\bm{\hat{t}}||}{||\bm{t}||}" display="block"><semantics id="S4.E4.m1.2a"><mrow id="S4.E4.m1.2.3" xref="S4.E4.m1.2.3.cmml"><msub id="S4.E4.m1.2.3.2" xref="S4.E4.m1.2.3.2.cmml"><mi id="S4.E4.m1.2.3.2.2" xref="S4.E4.m1.2.3.2.2.cmml">E</mi><mrow id="S4.E4.m1.2.3.2.3" xref="S4.E4.m1.2.3.2.3.cmml"><mi id="S4.E4.m1.2.3.2.3.2" xref="S4.E4.m1.2.3.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.3.2.3.1" xref="S4.E4.m1.2.3.2.3.1.cmml">​</mo><mi id="S4.E4.m1.2.3.2.3.3" xref="S4.E4.m1.2.3.2.3.3.cmml">N</mi></mrow></msub><mo id="S4.E4.m1.2.3.1" xref="S4.E4.m1.2.3.1.cmml">=</mo><mfrac id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml"><mrow id="S4.E4.m1.1.1.1.1" xref="S4.E4.m1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E4.m1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.2.1.cmml">‖</mo><mrow id="S4.E4.m1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.2.cmml">𝒕</mi><mo id="S4.E4.m1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S4.E4.m1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.1.1.1.1.1.3.2" xref="S4.E4.m1.1.1.1.1.1.3.2.cmml">𝒕</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S4.E4.m1.1.1.1.1.1.3.1" xref="S4.E4.m1.1.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S4.E4.m1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.2.1.cmml">‖</mo></mrow><mrow id="S4.E4.m1.2.2.2.3" xref="S4.E4.m1.2.2.2.2.cmml"><mo stretchy="false" id="S4.E4.m1.2.2.2.3.1" xref="S4.E4.m1.2.2.2.2.1.cmml">‖</mo><mi id="S4.E4.m1.2.2.2.1" xref="S4.E4.m1.2.2.2.1.cmml">𝒕</mi><mo stretchy="false" id="S4.E4.m1.2.2.2.3.2" xref="S4.E4.m1.2.2.2.2.1.cmml">‖</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.2b"><apply id="S4.E4.m1.2.3.cmml" xref="S4.E4.m1.2.3"><eq id="S4.E4.m1.2.3.1.cmml" xref="S4.E4.m1.2.3.1"></eq><apply id="S4.E4.m1.2.3.2.cmml" xref="S4.E4.m1.2.3.2"><csymbol cd="ambiguous" id="S4.E4.m1.2.3.2.1.cmml" xref="S4.E4.m1.2.3.2">subscript</csymbol><ci id="S4.E4.m1.2.3.2.2.cmml" xref="S4.E4.m1.2.3.2.2">𝐸</ci><apply id="S4.E4.m1.2.3.2.3.cmml" xref="S4.E4.m1.2.3.2.3"><times id="S4.E4.m1.2.3.2.3.1.cmml" xref="S4.E4.m1.2.3.2.3.1"></times><ci id="S4.E4.m1.2.3.2.3.2.cmml" xref="S4.E4.m1.2.3.2.3.2">𝑇</ci><ci id="S4.E4.m1.2.3.2.3.3.cmml" xref="S4.E4.m1.2.3.2.3.3">𝑁</ci></apply></apply><apply id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2"><divide id="S4.E4.m1.2.2.3.cmml" xref="S4.E4.m1.2.2"></divide><apply id="S4.E4.m1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1"><csymbol cd="latexml" id="S4.E4.m1.1.1.1.2.1.cmml" xref="S4.E4.m1.1.1.1.1.2">norm</csymbol><apply id="S4.E4.m1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1"><minus id="S4.E4.m1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1"></minus><ci id="S4.E4.m1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.2">𝒕</ci><apply id="S4.E4.m1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.3"><ci id="S4.E4.m1.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.1.1.3.1">bold-^</ci><ci id="S4.E4.m1.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.1.3.2">𝒕</ci></apply></apply></apply><apply id="S4.E4.m1.2.2.2.2.cmml" xref="S4.E4.m1.2.2.2.3"><csymbol cd="latexml" id="S4.E4.m1.2.2.2.2.1.cmml" xref="S4.E4.m1.2.2.2.3.1">norm</csymbol><ci id="S4.E4.m1.2.2.2.1.cmml" xref="S4.E4.m1.2.2.2.1">𝒕</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.2c">E_{TN}=\frac{||\bm{t}-\bm{\hat{t}}||}{||\bm{t}||}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p2.12" class="ltx_p"><math id="S4.SS1.p2.11.m1.1" class="ltx_Math" alttext="E_{T}" display="inline"><semantics id="S4.SS1.p2.11.m1.1a"><msub id="S4.SS1.p2.11.m1.1.1" xref="S4.SS1.p2.11.m1.1.1.cmml"><mi id="S4.SS1.p2.11.m1.1.1.2" xref="S4.SS1.p2.11.m1.1.1.2.cmml">E</mi><mi id="S4.SS1.p2.11.m1.1.1.3" xref="S4.SS1.p2.11.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.11.m1.1b"><apply id="S4.SS1.p2.11.m1.1.1.cmml" xref="S4.SS1.p2.11.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.11.m1.1.1.1.cmml" xref="S4.SS1.p2.11.m1.1.1">subscript</csymbol><ci id="S4.SS1.p2.11.m1.1.1.2.cmml" xref="S4.SS1.p2.11.m1.1.1.2">𝐸</ci><ci id="S4.SS1.p2.11.m1.1.1.3.cmml" xref="S4.SS1.p2.11.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.11.m1.1c">E_{T}</annotation></semantics></math> is the distance between the ground truth and predicted translations in a real unit, such as meters; <math id="S4.SS1.p2.12.m2.1" class="ltx_Math" alttext="E_{TN}" display="inline"><semantics id="S4.SS1.p2.12.m2.1a"><msub id="S4.SS1.p2.12.m2.1.1" xref="S4.SS1.p2.12.m2.1.1.cmml"><mi id="S4.SS1.p2.12.m2.1.1.2" xref="S4.SS1.p2.12.m2.1.1.2.cmml">E</mi><mrow id="S4.SS1.p2.12.m2.1.1.3" xref="S4.SS1.p2.12.m2.1.1.3.cmml"><mi id="S4.SS1.p2.12.m2.1.1.3.2" xref="S4.SS1.p2.12.m2.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.12.m2.1.1.3.1" xref="S4.SS1.p2.12.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS1.p2.12.m2.1.1.3.3" xref="S4.SS1.p2.12.m2.1.1.3.3.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.12.m2.1b"><apply id="S4.SS1.p2.12.m2.1.1.cmml" xref="S4.SS1.p2.12.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.12.m2.1.1.1.cmml" xref="S4.SS1.p2.12.m2.1.1">subscript</csymbol><ci id="S4.SS1.p2.12.m2.1.1.2.cmml" xref="S4.SS1.p2.12.m2.1.1.2">𝐸</ci><apply id="S4.SS1.p2.12.m2.1.1.3.cmml" xref="S4.SS1.p2.12.m2.1.1.3"><times id="S4.SS1.p2.12.m2.1.1.3.1.cmml" xref="S4.SS1.p2.12.m2.1.1.3.1"></times><ci id="S4.SS1.p2.12.m2.1.1.3.2.cmml" xref="S4.SS1.p2.12.m2.1.1.3.2">𝑇</ci><ci id="S4.SS1.p2.12.m2.1.1.3.3.cmml" xref="S4.SS1.p2.12.m2.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.12.m2.1c">E_{TN}</annotation></semantics></math> is this distance normalized by the ground truth distance between the target and the camera. A final metric combines the two errors:</p>
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E5.m1.1" class="ltx_Math" alttext="E_{C}=E_{R}+E_{TN}" display="block"><semantics id="S4.E5.m1.1a"><mrow id="S4.E5.m1.1.1" xref="S4.E5.m1.1.1.cmml"><msub id="S4.E5.m1.1.1.2" xref="S4.E5.m1.1.1.2.cmml"><mi id="S4.E5.m1.1.1.2.2" xref="S4.E5.m1.1.1.2.2.cmml">E</mi><mi id="S4.E5.m1.1.1.2.3" xref="S4.E5.m1.1.1.2.3.cmml">C</mi></msub><mo id="S4.E5.m1.1.1.1" xref="S4.E5.m1.1.1.1.cmml">=</mo><mrow id="S4.E5.m1.1.1.3" xref="S4.E5.m1.1.1.3.cmml"><msub id="S4.E5.m1.1.1.3.2" xref="S4.E5.m1.1.1.3.2.cmml"><mi id="S4.E5.m1.1.1.3.2.2" xref="S4.E5.m1.1.1.3.2.2.cmml">E</mi><mi id="S4.E5.m1.1.1.3.2.3" xref="S4.E5.m1.1.1.3.2.3.cmml">R</mi></msub><mo id="S4.E5.m1.1.1.3.1" xref="S4.E5.m1.1.1.3.1.cmml">+</mo><msub id="S4.E5.m1.1.1.3.3" xref="S4.E5.m1.1.1.3.3.cmml"><mi id="S4.E5.m1.1.1.3.3.2" xref="S4.E5.m1.1.1.3.3.2.cmml">E</mi><mrow id="S4.E5.m1.1.1.3.3.3" xref="S4.E5.m1.1.1.3.3.3.cmml"><mi id="S4.E5.m1.1.1.3.3.3.2" xref="S4.E5.m1.1.1.3.3.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.1.1.3.3.3.1" xref="S4.E5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.E5.m1.1.1.3.3.3.3" xref="S4.E5.m1.1.1.3.3.3.3.cmml">N</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.1b"><apply id="S4.E5.m1.1.1.cmml" xref="S4.E5.m1.1.1"><eq id="S4.E5.m1.1.1.1.cmml" xref="S4.E5.m1.1.1.1"></eq><apply id="S4.E5.m1.1.1.2.cmml" xref="S4.E5.m1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.2.1.cmml" xref="S4.E5.m1.1.1.2">subscript</csymbol><ci id="S4.E5.m1.1.1.2.2.cmml" xref="S4.E5.m1.1.1.2.2">𝐸</ci><ci id="S4.E5.m1.1.1.2.3.cmml" xref="S4.E5.m1.1.1.2.3">𝐶</ci></apply><apply id="S4.E5.m1.1.1.3.cmml" xref="S4.E5.m1.1.1.3"><plus id="S4.E5.m1.1.1.3.1.cmml" xref="S4.E5.m1.1.1.3.1"></plus><apply id="S4.E5.m1.1.1.3.2.cmml" xref="S4.E5.m1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.3.2.1.cmml" xref="S4.E5.m1.1.1.3.2">subscript</csymbol><ci id="S4.E5.m1.1.1.3.2.2.cmml" xref="S4.E5.m1.1.1.3.2.2">𝐸</ci><ci id="S4.E5.m1.1.1.3.2.3.cmml" xref="S4.E5.m1.1.1.3.2.3">𝑅</ci></apply><apply id="S4.E5.m1.1.1.3.3.cmml" xref="S4.E5.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.3.3.1.cmml" xref="S4.E5.m1.1.1.3.3">subscript</csymbol><ci id="S4.E5.m1.1.1.3.3.2.cmml" xref="S4.E5.m1.1.1.3.3.2">𝐸</ci><apply id="S4.E5.m1.1.1.3.3.3.cmml" xref="S4.E5.m1.1.1.3.3.3"><times id="S4.E5.m1.1.1.3.3.3.1.cmml" xref="S4.E5.m1.1.1.3.3.3.1"></times><ci id="S4.E5.m1.1.1.3.3.3.2.cmml" xref="S4.E5.m1.1.1.3.3.3.2">𝑇</ci><ci id="S4.E5.m1.1.1.3.3.3.3.cmml" xref="S4.E5.m1.1.1.3.3.3.3">𝑁</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.1c">E_{C}=E_{R}+E_{TN}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">For experiments with Cygnus, these pose metrics will be reported twice: once for the full dataset, and once with rejected pose estimates removed using the error prediction network. The proportion of pose estimates that were rejected will also be reported.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>SPEED Dataset</h3>

<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/speedsynthetic.jpg" id="S4.F4.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="374" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/speedreal.jpg" id="S4.F4.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="374" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.4.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.5.2" class="ltx_text" style="font-size:90%;">A synthetic image (left) and real image of a mockup (right) from the SPEED dataset</span></figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">First, our pose estimation system is evaluated on the SPEED dataset<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> in order to provide a comparison to the top submissions in the Satellite Pose Estimation Challenge (SPEC)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. The SPEED dataset consists of 12,000 training images and 2,998 test images of the ESA Tango spacecraft, all grayscale and synthetic. 300 real grayscale images of a Tango mockup are also included. The images have a resolution of <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="1900\times 1200" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">1900</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">1200</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">1900</cn><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">1200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">1900\times 1200</annotation></semantics></math> and a horizontal field of view of 35.1°. The distance of Tango from the camera ranges from 3 to 40.5 meters, with bounding box side length ranging from 27 pixels to 1432 pixels with a mean of 371 pixels.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.4.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.5.2" class="ltx_text" style="font-size:90%;">Satellite Pose Estimation Challenge Comparison</span></figcaption>
<table id="S4.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.2.2" class="ltx_tr">
<th id="S4.T1.2.2.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">SPEC Rank</th>
<th id="S4.T1.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Name</th>
<th id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Mean <math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><msub id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml"><mi id="S4.T1.1.1.1.m1.1.1.2" xref="S4.T1.1.1.1.m1.1.1.2.cmml">E</mi><mi id="S4.T1.1.1.1.m1.1.1.3" xref="S4.T1.1.1.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T1.1.1.1.m1.1.1.2.cmml" xref="S4.T1.1.1.1.m1.1.1.2">𝐸</ci><ci id="S4.T1.1.1.1.m1.1.1.3.cmml" xref="S4.T1.1.1.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">E_{C}</annotation></semantics></math> (synthetic)</th>
<th id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Mean <math id="S4.T1.2.2.2.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><msub id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml"><mi id="S4.T1.2.2.2.m1.1.1.2" xref="S4.T1.2.2.2.m1.1.1.2.cmml">E</mi><mi id="S4.T1.2.2.2.m1.1.1.3" xref="S4.T1.2.2.2.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><apply id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.2.2.2.m1.1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">subscript</csymbol><ci id="S4.T1.2.2.2.m1.1.1.2.cmml" xref="S4.T1.2.2.2.m1.1.1.2">𝐸</ci><ci id="S4.T1.2.2.2.m1.1.1.3.cmml" xref="S4.T1.2.2.2.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">E_{C}</annotation></semantics></math> (real)</th>
<th id="S4.T1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"># parameters (millions)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.2.3.1" class="ltx_tr">
<th id="S4.T1.2.3.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t">1</th>
<th id="S4.T1.2.3.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T1.2.3.1.2.1" class="ltx_text ltx_font_typewriter">UniAdelaide<cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.2.3.1.2.1.1.1" class="ltx_text ltx_font_serif">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S4.T1.2.3.1.2.1.2.2" class="ltx_text ltx_font_serif">]</span></cite></span></th>
<td id="S4.T1.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0094</td>
<td id="S4.T1.2.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.3752</td>
<td id="S4.T1.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">60+</td>
</tr>
<tr id="S4.T1.2.4.2" class="ltx_tr">
<th id="S4.T1.2.4.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">2</th>
<th id="S4.T1.2.4.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.2.4.2.2.1" class="ltx_text ltx_font_typewriter">EPFL_cvlab<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_serif">4</span></span><a target="_blank" href="https://indico.esa.int/event/319/attachments/3561/4754/pose_gerard_segmentation.pdf" title="" class="ltx_ref ltx_url">https://indico.esa.int/event/319/attachments/3561/4754/pose_gerard_segmentation.pdf</a></span></span></span></span></th>
<td id="S4.T1.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r">0.0215</td>
<td id="S4.T1.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r">0.1140</td>
<td id="S4.T1.2.4.2.5" class="ltx_td ltx_align_center">60+</td>
</tr>
<tr id="S4.T1.2.5.3" class="ltx_tr">
<th id="S4.T1.2.5.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<th id="S4.T1.2.5.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.2.5.3.2.1" class="ltx_text ltx_font_bold">Ours</span></th>
<td id="S4.T1.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.2.5.3.3.1" class="ltx_text ltx_font_bold">0.0409</span></td>
<td id="S4.T1.2.5.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.2.5.3.4.1" class="ltx_text ltx_font_bold">0.2918</span></td>
<td id="S4.T1.2.5.3.5" class="ltx_td ltx_align_center"><span id="S4.T1.2.5.3.5.1" class="ltx_text ltx_font_bold">6.9</span></td>
</tr>
<tr id="S4.T1.2.6.4" class="ltx_tr">
<th id="S4.T1.2.6.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">3</th>
<th id="S4.T1.2.6.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.2.6.4.2.1" class="ltx_text ltx_font_typewriter">pedro_fairspace<cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.2.6.4.2.1.1.1" class="ltx_text ltx_font_serif">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S4.T1.2.6.4.2.1.2.2" class="ltx_text ltx_font_serif">]</span></cite></span></th>
<td id="S4.T1.2.6.4.3" class="ltx_td ltx_align_center ltx_border_r">0.0570</td>
<td id="S4.T1.2.6.4.4" class="ltx_td ltx_align_center ltx_border_r">0.1555</td>
<td id="S4.T1.2.6.4.5" class="ltx_td ltx_align_center">60+</td>
</tr>
<tr id="S4.T1.2.7.5" class="ltx_tr">
<th id="S4.T1.2.7.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">4</th>
<th id="S4.T1.2.7.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.2.7.5.2.1" class="ltx_text ltx_font_typewriter">stanford_slab<cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.2.7.5.2.1.1.1" class="ltx_text ltx_font_serif">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S4.T1.2.7.5.2.1.2.2" class="ltx_text ltx_font_serif">]</span></cite></span></th>
<td id="S4.T1.2.7.5.3" class="ltx_td ltx_align_center ltx_border_r">0.0626</td>
<td id="S4.T1.2.7.5.4" class="ltx_td ltx_align_center ltx_border_r">0.3951</td>
<td id="S4.T1.2.7.5.5" class="ltx_td ltx_align_center">11.2</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.2" class="ltx_p">Table <a href="#S4.T1" title="Table 1 ‣ 4.2 SPEED Dataset ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows our system ranked alongside the top 4 submissions to the SPEC competition. The labels for the SPEED test set have not been released publicly, so we are only able to report the <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msub id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">E</mi><mi id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">𝐸</ci><ci id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">E_{C}</annotation></semantics></math> scores obtained from the SPEC post-mortem scoring server<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://kelvins.esa.int/pose-estimation-challenge-post-mortem/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://kelvins.esa.int/pose-estimation-challenge-post-mortem/</a></span></span></span>. We are also not able to test the error prediction step, since a pose estimate must be returned for every image. The competition ranks submissions based on the synthetic mean <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><msub id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">E</mi><mi id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">𝐸</ci><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">E_{C}</annotation></semantics></math> score only. The parameter counts are obtained from the publications corresponding to each of the submissions, and roughly correspond to a network’s computational needs.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Our pose estimation system achieves competitive accuracy, placing 3rd in both synthetic and real image score while having the fewest parameters. The only other top submission with a comparable network size is that of <span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_typewriter">stanford_slab</span>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S4.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Cygnus: Synthetic Data</h3>

<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.3.2" class="ltx_text" style="font-size:90%;">Dataset Breakdown</span></figcaption>
<table id="S4.T2.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.4.1.1" class="ltx_tr">
<th id="S4.T2.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Description</th>
<th id="S4.T2.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Number of Images</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.4.2.1" class="ltx_tr">
<td id="S4.T2.4.2.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">No augmentations</td>
<td id="S4.T2.4.2.1.2" class="ltx_td ltx_align_left ltx_border_t">3,000</td>
</tr>
<tr id="S4.T2.4.3.2" class="ltx_tr">
<td id="S4.T2.4.3.2.1" class="ltx_td ltx_align_left ltx_border_r">Glare and lens flares</td>
<td id="S4.T2.4.3.2.2" class="ltx_td ltx_align_left">3,000</td>
</tr>
<tr id="S4.T2.4.4.3" class="ltx_tr">
<td id="S4.T2.4.4.3.1" class="ltx_td ltx_align_left ltx_border_r">Blur</td>
<td id="S4.T2.4.4.3.2" class="ltx_td ltx_align_left">3,000</td>
</tr>
<tr id="S4.T2.4.5.4" class="ltx_tr">
<td id="S4.T2.4.5.4.1" class="ltx_td ltx_align_left ltx_border_r">Spacecraft partially out-of-frame</td>
<td id="S4.T2.4.5.4.2" class="ltx_td ltx_align_left">3,000</td>
</tr>
<tr id="S4.T2.4.6.5" class="ltx_tr">
<td id="S4.T2.4.6.5.1" class="ltx_td ltx_align_left ltx_border_r">No augmentations, real Earth background</td>
<td id="S4.T2.4.6.5.2" class="ltx_td ltx_align_left">2,000</td>
</tr>
<tr id="S4.T2.4.7.6" class="ltx_tr">
<td id="S4.T2.4.7.6.1" class="ltx_td ltx_align_left ltx_border_r">Glare and lens flares, real Earth background</td>
<td id="S4.T2.4.7.6.2" class="ltx_td ltx_align_left">2,000</td>
</tr>
<tr id="S4.T2.4.8.7" class="ltx_tr">
<td id="S4.T2.4.8.7.1" class="ltx_td ltx_align_left ltx_border_r">Blur, real Earth background</td>
<td id="S4.T2.4.8.7.2" class="ltx_td ltx_align_left">2,000</td>
</tr>
<tr id="S4.T2.4.9.8" class="ltx_tr">
<td id="S4.T2.4.9.8.1" class="ltx_td ltx_align_left ltx_border_r">No augmentations, randomized background</td>
<td id="S4.T2.4.9.8.2" class="ltx_td ltx_align_left">2,000</td>
</tr>
<tr id="S4.T2.4.10.9" class="ltx_tr">
<td id="S4.T2.4.10.9.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.4.10.9.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S4.T2.4.10.9.2" class="ltx_td ltx_align_left"><span id="S4.T2.4.10.9.2.1" class="ltx_text ltx_font_bold">20,000</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Table <a href="#S4.T2" title="Table 2 ‣ 4.3 Cygnus: Synthetic Data ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the composition of the synthetic dataset we use for all experiments with the Cygnus spacecraft. All images have resolution <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="1024\times 1024" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mn id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">1024</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><times id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">1024</cn><cn type="integer" id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">1024\times 1024</annotation></semantics></math> with a field of view of 39.6°. Position, orientation, and lighting angle are all randomized. Target distance from the camera is randomized from 35 to 75 meters. Not accounting for images with Cygnus partially out of frame, bounding box side length ranges from 76 to 459 pixels, with a mean of 232 pixels. The dataset is split into 64% training, 16% validation, and a 20% holdout test images.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.11.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.12.2" class="ltx_text" style="font-size:90%;">Synthetic Dataset Performance</span></figcaption>
<table id="S4.T3.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.9.10.1" class="ltx_tr">
<th id="S4.T3.9.10.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S4.T3.9.10.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Metric</td>
<td id="S4.T3.9.10.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Median</td>
<td id="S4.T3.9.10.1.4" class="ltx_td ltx_align_left ltx_border_t">Mean</td>
</tr>
<tr id="S4.T3.9.11.2" class="ltx_tr">
<th id="S4.T3.9.11.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.9.11.2.1.1" class="ltx_text">Object Detection Metrics</span></th>
<td id="S4.T3.9.11.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">RoI Accuracy</td>
<td id="S4.T3.9.11.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S4.T3.9.11.2.4" class="ltx_td ltx_align_left ltx_border_t">0.98</td>
</tr>
<tr id="S4.T3.9.12.3" class="ltx_tr">
<td id="S4.T3.9.12.3.1" class="ltx_td ltx_align_left ltx_border_r">IoU</td>
<td id="S4.T3.9.12.3.2" class="ltx_td ltx_align_left ltx_border_r">0.95</td>
<td id="S4.T3.9.12.3.3" class="ltx_td ltx_align_left">0.92</td>
</tr>
<tr id="S4.T3.1.1" class="ltx_tr">
<th id="S4.T3.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T3.1.1.2.1" class="ltx_text">Pose Metrics</span></th>
<td id="S4.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<math id="S4.T3.1.1.1.m1.1" class="ltx_Math" alttext="E_{R}" display="inline"><semantics id="S4.T3.1.1.1.m1.1a"><msub id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml"><mi id="S4.T3.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.m1.1.1.2.cmml">E</mi><mi id="S4.T3.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T3.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.m1.1.1.2">𝐸</ci><ci id="S4.T3.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.m1.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">E_{R}</annotation></semantics></math> (deg)</td>
<td id="S4.T3.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3.22</td>
<td id="S4.T3.1.1.4" class="ltx_td ltx_align_left ltx_border_t">25.96</td>
</tr>
<tr id="S4.T3.2.2" class="ltx_tr">
<td id="S4.T3.2.2.1" class="ltx_td ltx_align_left ltx_border_r">
<math id="S4.T3.2.2.1.m1.1" class="ltx_Math" alttext="E_{T}" display="inline"><semantics id="S4.T3.2.2.1.m1.1a"><msub id="S4.T3.2.2.1.m1.1.1" xref="S4.T3.2.2.1.m1.1.1.cmml"><mi id="S4.T3.2.2.1.m1.1.1.2" xref="S4.T3.2.2.1.m1.1.1.2.cmml">E</mi><mi id="S4.T3.2.2.1.m1.1.1.3" xref="S4.T3.2.2.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.1b"><apply id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.2.2.1.m1.1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1">subscript</csymbol><ci id="S4.T3.2.2.1.m1.1.1.2.cmml" xref="S4.T3.2.2.1.m1.1.1.2">𝐸</ci><ci id="S4.T3.2.2.1.m1.1.1.3.cmml" xref="S4.T3.2.2.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.1c">E_{T}</annotation></semantics></math> (meters)</td>
<td id="S4.T3.2.2.2" class="ltx_td ltx_align_left ltx_border_r">0.93</td>
<td id="S4.T3.2.2.3" class="ltx_td ltx_align_left">85.49</td>
</tr>
<tr id="S4.T3.3.3" class="ltx_tr">
<td id="S4.T3.3.3.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T3.3.3.1.m1.1" class="ltx_Math" alttext="E_{TN}" display="inline"><semantics id="S4.T3.3.3.1.m1.1a"><msub id="S4.T3.3.3.1.m1.1.1" xref="S4.T3.3.3.1.m1.1.1.cmml"><mi id="S4.T3.3.3.1.m1.1.1.2" xref="S4.T3.3.3.1.m1.1.1.2.cmml">E</mi><mrow id="S4.T3.3.3.1.m1.1.1.3" xref="S4.T3.3.3.1.m1.1.1.3.cmml"><mi id="S4.T3.3.3.1.m1.1.1.3.2" xref="S4.T3.3.3.1.m1.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.T3.3.3.1.m1.1.1.3.1" xref="S4.T3.3.3.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T3.3.3.1.m1.1.1.3.3" xref="S4.T3.3.3.1.m1.1.1.3.3.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.1.m1.1b"><apply id="S4.T3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.3.3.1.m1.1.1.1.cmml" xref="S4.T3.3.3.1.m1.1.1">subscript</csymbol><ci id="S4.T3.3.3.1.m1.1.1.2.cmml" xref="S4.T3.3.3.1.m1.1.1.2">𝐸</ci><apply id="S4.T3.3.3.1.m1.1.1.3.cmml" xref="S4.T3.3.3.1.m1.1.1.3"><times id="S4.T3.3.3.1.m1.1.1.3.1.cmml" xref="S4.T3.3.3.1.m1.1.1.3.1"></times><ci id="S4.T3.3.3.1.m1.1.1.3.2.cmml" xref="S4.T3.3.3.1.m1.1.1.3.2">𝑇</ci><ci id="S4.T3.3.3.1.m1.1.1.3.3.cmml" xref="S4.T3.3.3.1.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.1.m1.1c">E_{TN}</annotation></semantics></math></td>
<td id="S4.T3.3.3.2" class="ltx_td ltx_align_left ltx_border_r">0.017</td>
<td id="S4.T3.3.3.3" class="ltx_td ltx_align_left">1.565</td>
</tr>
<tr id="S4.T3.4.4" class="ltx_tr">
<td id="S4.T3.4.4.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T3.4.4.1.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.T3.4.4.1.m1.1a"><msub id="S4.T3.4.4.1.m1.1.1" xref="S4.T3.4.4.1.m1.1.1.cmml"><mi id="S4.T3.4.4.1.m1.1.1.2" xref="S4.T3.4.4.1.m1.1.1.2.cmml">E</mi><mi id="S4.T3.4.4.1.m1.1.1.3" xref="S4.T3.4.4.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.1.m1.1b"><apply id="S4.T3.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.4.4.1.m1.1.1.1.cmml" xref="S4.T3.4.4.1.m1.1.1">subscript</csymbol><ci id="S4.T3.4.4.1.m1.1.1.2.cmml" xref="S4.T3.4.4.1.m1.1.1.2">𝐸</ci><ci id="S4.T3.4.4.1.m1.1.1.3.cmml" xref="S4.T3.4.4.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.1.m1.1c">E_{C}</annotation></semantics></math></td>
<td id="S4.T3.4.4.2" class="ltx_td ltx_align_left ltx_border_r">0.074</td>
<td id="S4.T3.4.4.3" class="ltx_td ltx_align_left">2.018</td>
</tr>
<tr id="S4.T3.5.5" class="ltx_tr">
<th id="S4.T3.5.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="5"><span id="S4.T3.5.5.1.1" class="ltx_text">
<span id="S4.T3.5.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.1.1.1.2" class="ltx_tr">
<span id="S4.T3.5.5.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_right">Rejected Estimates</span></span>
<span id="S4.T3.5.5.1.1.1.1" class="ltx_tr">
<span id="S4.T3.5.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_right">(<math id="S4.T3.5.5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\hat{E_{k}}&gt;20" display="inline"><semantics id="S4.T3.5.5.1.1.1.1.1.m1.1a"><mrow id="S4.T3.5.5.1.1.1.1.1.m1.1.1" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.cmml"><mover accent="true" id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.cmml"><msub id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.cmml"><mi id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.2" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.2.cmml">E</mi><mi id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.3" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.3.cmml">k</mi></msub><mo id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.1" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.1.cmml">^</mo></mover><mo id="S4.T3.5.5.1.1.1.1.1.m1.1.1.1" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mn id="S4.T3.5.5.1.1.1.1.1.m1.1.1.3" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.1.1.1.1.1.m1.1b"><apply id="S4.T3.5.5.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1"><gt id="S4.T3.5.5.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.1"></gt><apply id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2"><ci id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.1.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.1">^</ci><apply id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2"><csymbol cd="ambiguous" id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.1.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2">subscript</csymbol><ci id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.2.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.2">𝐸</ci><ci id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.3.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.2.3">𝑘</ci></apply></apply><cn type="integer" id="S4.T3.5.5.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.1.1.1.1.1.m1.1c">\hat{E_{k}}&gt;20</annotation></semantics></math>) Removed</span></span>
</span></span></th>
<td id="S4.T3.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Proportion Rejected</td>
<td id="S4.T3.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S4.T3.5.5.4" class="ltx_td ltx_align_left ltx_border_t">0.18</td>
</tr>
<tr id="S4.T3.6.6" class="ltx_tr">
<td id="S4.T3.6.6.1" class="ltx_td ltx_align_left ltx_border_r">
<math id="S4.T3.6.6.1.m1.1" class="ltx_Math" alttext="E_{R}" display="inline"><semantics id="S4.T3.6.6.1.m1.1a"><msub id="S4.T3.6.6.1.m1.1.1" xref="S4.T3.6.6.1.m1.1.1.cmml"><mi id="S4.T3.6.6.1.m1.1.1.2" xref="S4.T3.6.6.1.m1.1.1.2.cmml">E</mi><mi id="S4.T3.6.6.1.m1.1.1.3" xref="S4.T3.6.6.1.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.1.m1.1b"><apply id="S4.T3.6.6.1.m1.1.1.cmml" xref="S4.T3.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.6.6.1.m1.1.1.1.cmml" xref="S4.T3.6.6.1.m1.1.1">subscript</csymbol><ci id="S4.T3.6.6.1.m1.1.1.2.cmml" xref="S4.T3.6.6.1.m1.1.1.2">𝐸</ci><ci id="S4.T3.6.6.1.m1.1.1.3.cmml" xref="S4.T3.6.6.1.m1.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.1.m1.1c">E_{R}</annotation></semantics></math> (deg)</td>
<td id="S4.T3.6.6.2" class="ltx_td ltx_align_left ltx_border_r">2.64</td>
<td id="S4.T3.6.6.3" class="ltx_td ltx_align_left">6.45</td>
</tr>
<tr id="S4.T3.7.7" class="ltx_tr">
<td id="S4.T3.7.7.1" class="ltx_td ltx_align_left ltx_border_r">
<math id="S4.T3.7.7.1.m1.1" class="ltx_Math" alttext="E_{T}" display="inline"><semantics id="S4.T3.7.7.1.m1.1a"><msub id="S4.T3.7.7.1.m1.1.1" xref="S4.T3.7.7.1.m1.1.1.cmml"><mi id="S4.T3.7.7.1.m1.1.1.2" xref="S4.T3.7.7.1.m1.1.1.2.cmml">E</mi><mi id="S4.T3.7.7.1.m1.1.1.3" xref="S4.T3.7.7.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.1.m1.1b"><apply id="S4.T3.7.7.1.m1.1.1.cmml" xref="S4.T3.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.7.7.1.m1.1.1.1.cmml" xref="S4.T3.7.7.1.m1.1.1">subscript</csymbol><ci id="S4.T3.7.7.1.m1.1.1.2.cmml" xref="S4.T3.7.7.1.m1.1.1.2">𝐸</ci><ci id="S4.T3.7.7.1.m1.1.1.3.cmml" xref="S4.T3.7.7.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.1.m1.1c">E_{T}</annotation></semantics></math> (meters)</td>
<td id="S4.T3.7.7.2" class="ltx_td ltx_align_left ltx_border_r">0.71</td>
<td id="S4.T3.7.7.3" class="ltx_td ltx_align_left">1.08</td>
</tr>
<tr id="S4.T3.8.8" class="ltx_tr">
<td id="S4.T3.8.8.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T3.8.8.1.m1.1" class="ltx_Math" alttext="E_{TN}" display="inline"><semantics id="S4.T3.8.8.1.m1.1a"><msub id="S4.T3.8.8.1.m1.1.1" xref="S4.T3.8.8.1.m1.1.1.cmml"><mi id="S4.T3.8.8.1.m1.1.1.2" xref="S4.T3.8.8.1.m1.1.1.2.cmml">E</mi><mrow id="S4.T3.8.8.1.m1.1.1.3" xref="S4.T3.8.8.1.m1.1.1.3.cmml"><mi id="S4.T3.8.8.1.m1.1.1.3.2" xref="S4.T3.8.8.1.m1.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.T3.8.8.1.m1.1.1.3.1" xref="S4.T3.8.8.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T3.8.8.1.m1.1.1.3.3" xref="S4.T3.8.8.1.m1.1.1.3.3.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.1.m1.1b"><apply id="S4.T3.8.8.1.m1.1.1.cmml" xref="S4.T3.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.8.8.1.m1.1.1.1.cmml" xref="S4.T3.8.8.1.m1.1.1">subscript</csymbol><ci id="S4.T3.8.8.1.m1.1.1.2.cmml" xref="S4.T3.8.8.1.m1.1.1.2">𝐸</ci><apply id="S4.T3.8.8.1.m1.1.1.3.cmml" xref="S4.T3.8.8.1.m1.1.1.3"><times id="S4.T3.8.8.1.m1.1.1.3.1.cmml" xref="S4.T3.8.8.1.m1.1.1.3.1"></times><ci id="S4.T3.8.8.1.m1.1.1.3.2.cmml" xref="S4.T3.8.8.1.m1.1.1.3.2">𝑇</ci><ci id="S4.T3.8.8.1.m1.1.1.3.3.cmml" xref="S4.T3.8.8.1.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.1.m1.1c">E_{TN}</annotation></semantics></math></td>
<td id="S4.T3.8.8.2" class="ltx_td ltx_align_left ltx_border_r">0.013</td>
<td id="S4.T3.8.8.3" class="ltx_td ltx_align_left">0.019</td>
</tr>
<tr id="S4.T3.9.9" class="ltx_tr">
<td id="S4.T3.9.9.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T3.9.9.1.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.T3.9.9.1.m1.1a"><msub id="S4.T3.9.9.1.m1.1.1" xref="S4.T3.9.9.1.m1.1.1.cmml"><mi id="S4.T3.9.9.1.m1.1.1.2" xref="S4.T3.9.9.1.m1.1.1.2.cmml">E</mi><mi id="S4.T3.9.9.1.m1.1.1.3" xref="S4.T3.9.9.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.1.m1.1b"><apply id="S4.T3.9.9.1.m1.1.1.cmml" xref="S4.T3.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.9.9.1.m1.1.1.1.cmml" xref="S4.T3.9.9.1.m1.1.1">subscript</csymbol><ci id="S4.T3.9.9.1.m1.1.1.2.cmml" xref="S4.T3.9.9.1.m1.1.1.2">𝐸</ci><ci id="S4.T3.9.9.1.m1.1.1.3.cmml" xref="S4.T3.9.9.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.1.m1.1c">E_{C}</annotation></semantics></math></td>
<td id="S4.T3.9.9.2" class="ltx_td ltx_align_left ltx_border_r">0.062</td>
<td id="S4.T3.9.9.3" class="ltx_td ltx_align_left">0.132</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Table <a href="#S4.T3" title="Table 3 ‣ 4.3 Cygnus: Synthetic Data ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the performance of the pose estimation system on the aforementioned holdout set. The object detection network performs very well: the resulting RoI includes the entire spacecraft in 98% of images. The pose errors, on the other hand, are characterized by extreme outliers: due to the various augmentations, the system produces a few “bad estimates” on the most difficult images. (This includes, of course, the 2% of images where the initial RoI is inaccurate.) In particular, the translation errors are unbounded, and so a few extreme outliers can severely inflate the mean. However, the error prediction network easily detects these extreme outliers. As mentioned before, the <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="\hat{E_{k}}" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mover accent="true" id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><msub id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2.2" xref="S4.SS3.p2.1.m1.1.1.2.2.cmml">E</mi><mi id="S4.SS3.p2.1.m1.1.1.2.3" xref="S4.SS3.p2.1.m1.1.1.2.3.cmml">k</mi></msub><mo id="S4.SS3.p2.1.m1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><ci id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1">^</ci><apply id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.2.1.cmml" xref="S4.SS3.p2.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2.2">𝐸</ci><ci id="S4.SS3.p2.1.m1.1.1.2.3.cmml" xref="S4.SS3.p2.1.m1.1.1.2.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\hat{E_{k}}</annotation></semantics></math> threshold is chosen using this synthetic dataset to provide a good balance between rejecting bad estimates and keeping good ones. The chosen threshold of 20 pixels results in 18% of estimates being rejected while bringing down the mean errors to reasonable values.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Overall, as with the SPEED dataset, it is expected that the system will perform well on the same type of synthetic data it is trained on. The synthetic image error provides a rough lower bound on the achievable real image error.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Cygnus: Real Data</h3>

<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_105.jpg" id="S4.F5.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_399.jpg" id="S4.F5.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_620.jpg" id="S4.F5.3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_057.jpg" id="S4.F5.4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_549.jpg" id="S4.F5.5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_612.jpg" id="S4.F5.6.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.8.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.9.2" class="ltx_text" style="font-size:90%;">Examples of real images</span></figcaption>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">The real dataset consists of 540 photos of the Cygnus spacecraft taken in orbit. The photos are obtained from NASA<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://images.nasa.gov/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://images.nasa.gov/</a></span></span></span>. They cover a variety of poses and lighting conditions, and include degradations such as glare and motion blur. The field of view varies from 1.8° to 86.9°, and bounding box side length varies from 54 pixels to 744 pixels with a mean of 231 pixels.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.6.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.7.2" class="ltx_text" style="font-size:90%;">Human Labeling Error</span></figcaption>
<table id="S4.T4.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.4.5.1" class="ltx_tr">
<th id="S4.T4.4.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Metric</th>
<th id="S4.T4.4.5.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Median</th>
<th id="S4.T4.4.5.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Mean</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<math id="S4.T4.1.1.1.m1.1" class="ltx_Math" alttext="E_{R}" display="inline"><semantics id="S4.T4.1.1.1.m1.1a"><msub id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml"><mi id="S4.T4.1.1.1.m1.1.1.2" xref="S4.T4.1.1.1.m1.1.1.2.cmml">E</mi><mi id="S4.T4.1.1.1.m1.1.1.3" xref="S4.T4.1.1.1.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T4.1.1.1.m1.1.1.2.cmml" xref="S4.T4.1.1.1.m1.1.1.2">𝐸</ci><ci id="S4.T4.1.1.1.m1.1.1.3.cmml" xref="S4.T4.1.1.1.m1.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">E_{R}</annotation></semantics></math> (deg)</th>
<td id="S4.T4.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.71</td>
<td id="S4.T4.1.1.3" class="ltx_td ltx_align_left ltx_border_t">2.11</td>
</tr>
<tr id="S4.T4.2.2" class="ltx_tr">
<th id="S4.T4.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<math id="S4.T4.2.2.1.m1.1" class="ltx_Math" alttext="E_{T}" display="inline"><semantics id="S4.T4.2.2.1.m1.1a"><msub id="S4.T4.2.2.1.m1.1.1" xref="S4.T4.2.2.1.m1.1.1.cmml"><mi id="S4.T4.2.2.1.m1.1.1.2" xref="S4.T4.2.2.1.m1.1.1.2.cmml">E</mi><mi id="S4.T4.2.2.1.m1.1.1.3" xref="S4.T4.2.2.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.1.m1.1b"><apply id="S4.T4.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.2.2.1.m1.1.1.1.cmml" xref="S4.T4.2.2.1.m1.1.1">subscript</csymbol><ci id="S4.T4.2.2.1.m1.1.1.2.cmml" xref="S4.T4.2.2.1.m1.1.1.2">𝐸</ci><ci id="S4.T4.2.2.1.m1.1.1.3.cmml" xref="S4.T4.2.2.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.1.m1.1c">E_{T}</annotation></semantics></math> (meters)</th>
<td id="S4.T4.2.2.2" class="ltx_td ltx_align_left ltx_border_r">1.91</td>
<td id="S4.T4.2.2.3" class="ltx_td ltx_align_left">3.66</td>
</tr>
<tr id="S4.T4.3.3" class="ltx_tr">
<th id="S4.T4.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><math id="S4.T4.3.3.1.m1.1" class="ltx_Math" alttext="E_{TN}" display="inline"><semantics id="S4.T4.3.3.1.m1.1a"><msub id="S4.T4.3.3.1.m1.1.1" xref="S4.T4.3.3.1.m1.1.1.cmml"><mi id="S4.T4.3.3.1.m1.1.1.2" xref="S4.T4.3.3.1.m1.1.1.2.cmml">E</mi><mrow id="S4.T4.3.3.1.m1.1.1.3" xref="S4.T4.3.3.1.m1.1.1.3.cmml"><mi id="S4.T4.3.3.1.m1.1.1.3.2" xref="S4.T4.3.3.1.m1.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.T4.3.3.1.m1.1.1.3.1" xref="S4.T4.3.3.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T4.3.3.1.m1.1.1.3.3" xref="S4.T4.3.3.1.m1.1.1.3.3.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.1.m1.1b"><apply id="S4.T4.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.3.3.1.m1.1.1.1.cmml" xref="S4.T4.3.3.1.m1.1.1">subscript</csymbol><ci id="S4.T4.3.3.1.m1.1.1.2.cmml" xref="S4.T4.3.3.1.m1.1.1.2">𝐸</ci><apply id="S4.T4.3.3.1.m1.1.1.3.cmml" xref="S4.T4.3.3.1.m1.1.1.3"><times id="S4.T4.3.3.1.m1.1.1.3.1.cmml" xref="S4.T4.3.3.1.m1.1.1.3.1"></times><ci id="S4.T4.3.3.1.m1.1.1.3.2.cmml" xref="S4.T4.3.3.1.m1.1.1.3.2">𝑇</ci><ci id="S4.T4.3.3.1.m1.1.1.3.3.cmml" xref="S4.T4.3.3.1.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.1.m1.1c">E_{TN}</annotation></semantics></math></th>
<td id="S4.T4.3.3.2" class="ltx_td ltx_align_left ltx_border_r">0.011</td>
<td id="S4.T4.3.3.3" class="ltx_td ltx_align_left">0.020</td>
</tr>
<tr id="S4.T4.4.4" class="ltx_tr">
<th id="S4.T4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><math id="S4.T4.4.4.1.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.T4.4.4.1.m1.1a"><msub id="S4.T4.4.4.1.m1.1.1" xref="S4.T4.4.4.1.m1.1.1.cmml"><mi id="S4.T4.4.4.1.m1.1.1.2" xref="S4.T4.4.4.1.m1.1.1.2.cmml">E</mi><mi id="S4.T4.4.4.1.m1.1.1.3" xref="S4.T4.4.4.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.1.m1.1b"><apply id="S4.T4.4.4.1.m1.1.1.cmml" xref="S4.T4.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.4.4.1.m1.1.1.1.cmml" xref="S4.T4.4.4.1.m1.1.1">subscript</csymbol><ci id="S4.T4.4.4.1.m1.1.1.2.cmml" xref="S4.T4.4.4.1.m1.1.1.2">𝐸</ci><ci id="S4.T4.4.4.1.m1.1.1.3.cmml" xref="S4.T4.4.4.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.1.m1.1c">E_{C}</annotation></semantics></math></th>
<td id="S4.T4.4.4.2" class="ltx_td ltx_align_left ltx_border_r">0.045</td>
<td id="S4.T4.4.4.3" class="ltx_td ltx_align_left">0.056</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">The images are hand-labeled with pose information using a custom-built tool<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://github.com/autognc/opat-js" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/autognc/opat-js</a></span></span></span> that overlays a 3D model of the spacecraft on top of each image and allows the user to line it up with the real spacecraft. We also estimate the human error associated with this labeling tool by creating a synthetic dataset with the same number of images and similar poses as the real image dataset. This gives access to known ground-truth poses so that the human labeling error can be measured. The results are presented in Table <a href="#S4.T4" title="Table 4 ‣ 4.4 Cygnus: Real Data ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We find that the human labeling error is small enough to still conduct a robust analysis of the pose estimation system’s error.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.11.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.12.2" class="ltx_text" style="font-size:90%;">Real Dataset Performance</span></figcaption>
<table id="S4.T5.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.9.10.1" class="ltx_tr">
<th id="S4.T5.9.10.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S4.T5.9.10.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Metric</td>
<td id="S4.T5.9.10.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Median</td>
<td id="S4.T5.9.10.1.4" class="ltx_td ltx_align_left ltx_border_t">Mean</td>
</tr>
<tr id="S4.T5.9.11.2" class="ltx_tr">
<th id="S4.T5.9.11.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T5.9.11.2.1.1" class="ltx_text">Object Detection Metrics</span></th>
<td id="S4.T5.9.11.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">RoI Accuracy</td>
<td id="S4.T5.9.11.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S4.T5.9.11.2.4" class="ltx_td ltx_align_left ltx_border_t">0.95</td>
</tr>
<tr id="S4.T5.9.12.3" class="ltx_tr">
<td id="S4.T5.9.12.3.1" class="ltx_td ltx_align_left ltx_border_r">IoU</td>
<td id="S4.T5.9.12.3.2" class="ltx_td ltx_align_left ltx_border_r">0.90</td>
<td id="S4.T5.9.12.3.3" class="ltx_td ltx_align_left">0.85</td>
</tr>
<tr id="S4.T5.1.1" class="ltx_tr">
<th id="S4.T5.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T5.1.1.2.1" class="ltx_text">Pose Metrics</span></th>
<td id="S4.T5.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<math id="S4.T5.1.1.1.m1.1" class="ltx_Math" alttext="E_{R}" display="inline"><semantics id="S4.T5.1.1.1.m1.1a"><msub id="S4.T5.1.1.1.m1.1.1" xref="S4.T5.1.1.1.m1.1.1.cmml"><mi id="S4.T5.1.1.1.m1.1.1.2" xref="S4.T5.1.1.1.m1.1.1.2.cmml">E</mi><mi id="S4.T5.1.1.1.m1.1.1.3" xref="S4.T5.1.1.1.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.m1.1b"><apply id="S4.T5.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.1.1.1.m1.1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T5.1.1.1.m1.1.1.2.cmml" xref="S4.T5.1.1.1.m1.1.1.2">𝐸</ci><ci id="S4.T5.1.1.1.m1.1.1.3.cmml" xref="S4.T5.1.1.1.m1.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.m1.1c">E_{R}</annotation></semantics></math> (deg)</td>
<td id="S4.T5.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7.33</td>
<td id="S4.T5.1.1.4" class="ltx_td ltx_align_left ltx_border_t">35.26</td>
</tr>
<tr id="S4.T5.2.2" class="ltx_tr">
<td id="S4.T5.2.2.1" class="ltx_td ltx_align_left ltx_border_r">
<math id="S4.T5.2.2.1.m1.1" class="ltx_Math" alttext="E_{T}" display="inline"><semantics id="S4.T5.2.2.1.m1.1a"><msub id="S4.T5.2.2.1.m1.1.1" xref="S4.T5.2.2.1.m1.1.1.cmml"><mi id="S4.T5.2.2.1.m1.1.1.2" xref="S4.T5.2.2.1.m1.1.1.2.cmml">E</mi><mi id="S4.T5.2.2.1.m1.1.1.3" xref="S4.T5.2.2.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.1.m1.1b"><apply id="S4.T5.2.2.1.m1.1.1.cmml" xref="S4.T5.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.2.2.1.m1.1.1.1.cmml" xref="S4.T5.2.2.1.m1.1.1">subscript</csymbol><ci id="S4.T5.2.2.1.m1.1.1.2.cmml" xref="S4.T5.2.2.1.m1.1.1.2">𝐸</ci><ci id="S4.T5.2.2.1.m1.1.1.3.cmml" xref="S4.T5.2.2.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.1.m1.1c">E_{T}</annotation></semantics></math> (meters)</td>
<td id="S4.T5.2.2.2" class="ltx_td ltx_align_left ltx_border_r">7.36</td>
<td id="S4.T5.2.2.3" class="ltx_td ltx_align_left">112.83</td>
</tr>
<tr id="S4.T5.3.3" class="ltx_tr">
<td id="S4.T5.3.3.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T5.3.3.1.m1.1" class="ltx_Math" alttext="E_{TN}" display="inline"><semantics id="S4.T5.3.3.1.m1.1a"><msub id="S4.T5.3.3.1.m1.1.1" xref="S4.T5.3.3.1.m1.1.1.cmml"><mi id="S4.T5.3.3.1.m1.1.1.2" xref="S4.T5.3.3.1.m1.1.1.2.cmml">E</mi><mrow id="S4.T5.3.3.1.m1.1.1.3" xref="S4.T5.3.3.1.m1.1.1.3.cmml"><mi id="S4.T5.3.3.1.m1.1.1.3.2" xref="S4.T5.3.3.1.m1.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.T5.3.3.1.m1.1.1.3.1" xref="S4.T5.3.3.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.3.3.1.m1.1.1.3.3" xref="S4.T5.3.3.1.m1.1.1.3.3.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.1.m1.1b"><apply id="S4.T5.3.3.1.m1.1.1.cmml" xref="S4.T5.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.3.3.1.m1.1.1.1.cmml" xref="S4.T5.3.3.1.m1.1.1">subscript</csymbol><ci id="S4.T5.3.3.1.m1.1.1.2.cmml" xref="S4.T5.3.3.1.m1.1.1.2">𝐸</ci><apply id="S4.T5.3.3.1.m1.1.1.3.cmml" xref="S4.T5.3.3.1.m1.1.1.3"><times id="S4.T5.3.3.1.m1.1.1.3.1.cmml" xref="S4.T5.3.3.1.m1.1.1.3.1"></times><ci id="S4.T5.3.3.1.m1.1.1.3.2.cmml" xref="S4.T5.3.3.1.m1.1.1.3.2">𝑇</ci><ci id="S4.T5.3.3.1.m1.1.1.3.3.cmml" xref="S4.T5.3.3.1.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.1.m1.1c">E_{TN}</annotation></semantics></math></td>
<td id="S4.T5.3.3.2" class="ltx_td ltx_align_left ltx_border_r">0.032</td>
<td id="S4.T5.3.3.3" class="ltx_td ltx_align_left">0.317</td>
</tr>
<tr id="S4.T5.4.4" class="ltx_tr">
<td id="S4.T5.4.4.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T5.4.4.1.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.T5.4.4.1.m1.1a"><msub id="S4.T5.4.4.1.m1.1.1" xref="S4.T5.4.4.1.m1.1.1.cmml"><mi id="S4.T5.4.4.1.m1.1.1.2" xref="S4.T5.4.4.1.m1.1.1.2.cmml">E</mi><mi id="S4.T5.4.4.1.m1.1.1.3" xref="S4.T5.4.4.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.1.m1.1b"><apply id="S4.T5.4.4.1.m1.1.1.cmml" xref="S4.T5.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.4.4.1.m1.1.1.1.cmml" xref="S4.T5.4.4.1.m1.1.1">subscript</csymbol><ci id="S4.T5.4.4.1.m1.1.1.2.cmml" xref="S4.T5.4.4.1.m1.1.1.2">𝐸</ci><ci id="S4.T5.4.4.1.m1.1.1.3.cmml" xref="S4.T5.4.4.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.1.m1.1c">E_{C}</annotation></semantics></math></td>
<td id="S4.T5.4.4.2" class="ltx_td ltx_align_left ltx_border_r">0.170</td>
<td id="S4.T5.4.4.3" class="ltx_td ltx_align_left">0.932</td>
</tr>
<tr id="S4.T5.5.5" class="ltx_tr">
<th id="S4.T5.5.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="5"><span id="S4.T5.5.5.1.1" class="ltx_text">
<span id="S4.T5.5.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T5.5.5.1.1.1.2" class="ltx_tr">
<span id="S4.T5.5.5.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_right">Rejected Estimates</span></span>
<span id="S4.T5.5.5.1.1.1.1" class="ltx_tr">
<span id="S4.T5.5.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_right">(<math id="S4.T5.5.5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\hat{E_{k}}&gt;20" display="inline"><semantics id="S4.T5.5.5.1.1.1.1.1.m1.1a"><mrow id="S4.T5.5.5.1.1.1.1.1.m1.1.1" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.cmml"><mover accent="true" id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.cmml"><msub id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.cmml"><mi id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.2" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.2.cmml">E</mi><mi id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.3" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.3.cmml">k</mi></msub><mo id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.1" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.1.cmml">^</mo></mover><mo id="S4.T5.5.5.1.1.1.1.1.m1.1.1.1" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mn id="S4.T5.5.5.1.1.1.1.1.m1.1.1.3" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.5.5.1.1.1.1.1.m1.1b"><apply id="S4.T5.5.5.1.1.1.1.1.m1.1.1.cmml" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1"><gt id="S4.T5.5.5.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.1"></gt><apply id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2"><ci id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.1.cmml" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.1">^</ci><apply id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.cmml" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2"><csymbol cd="ambiguous" id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.1.cmml" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2">subscript</csymbol><ci id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.2.cmml" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.2">𝐸</ci><ci id="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.3.cmml" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.2.2.3">𝑘</ci></apply></apply><cn type="integer" id="S4.T5.5.5.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T5.5.5.1.1.1.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.5.1.1.1.1.1.m1.1c">\hat{E_{k}}&gt;20</annotation></semantics></math>) Removed</span></span>
</span></span></th>
<td id="S4.T5.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Proportion Rejected</td>
<td id="S4.T5.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S4.T5.5.5.4" class="ltx_td ltx_align_left ltx_border_t">0.16</td>
</tr>
<tr id="S4.T5.6.6" class="ltx_tr">
<td id="S4.T5.6.6.1" class="ltx_td ltx_align_left ltx_border_r">
<math id="S4.T5.6.6.1.m1.1" class="ltx_Math" alttext="E_{R}" display="inline"><semantics id="S4.T5.6.6.1.m1.1a"><msub id="S4.T5.6.6.1.m1.1.1" xref="S4.T5.6.6.1.m1.1.1.cmml"><mi id="S4.T5.6.6.1.m1.1.1.2" xref="S4.T5.6.6.1.m1.1.1.2.cmml">E</mi><mi id="S4.T5.6.6.1.m1.1.1.3" xref="S4.T5.6.6.1.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.6.6.1.m1.1b"><apply id="S4.T5.6.6.1.m1.1.1.cmml" xref="S4.T5.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.6.6.1.m1.1.1.1.cmml" xref="S4.T5.6.6.1.m1.1.1">subscript</csymbol><ci id="S4.T5.6.6.1.m1.1.1.2.cmml" xref="S4.T5.6.6.1.m1.1.1.2">𝐸</ci><ci id="S4.T5.6.6.1.m1.1.1.3.cmml" xref="S4.T5.6.6.1.m1.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.6.1.m1.1c">E_{R}</annotation></semantics></math> (deg)</td>
<td id="S4.T5.6.6.2" class="ltx_td ltx_align_left ltx_border_r">6.48</td>
<td id="S4.T5.6.6.3" class="ltx_td ltx_align_left">29.88</td>
</tr>
<tr id="S4.T5.7.7" class="ltx_tr">
<td id="S4.T5.7.7.1" class="ltx_td ltx_align_left ltx_border_r">
<math id="S4.T5.7.7.1.m1.1" class="ltx_Math" alttext="E_{T}" display="inline"><semantics id="S4.T5.7.7.1.m1.1a"><msub id="S4.T5.7.7.1.m1.1.1" xref="S4.T5.7.7.1.m1.1.1.cmml"><mi id="S4.T5.7.7.1.m1.1.1.2" xref="S4.T5.7.7.1.m1.1.1.2.cmml">E</mi><mi id="S4.T5.7.7.1.m1.1.1.3" xref="S4.T5.7.7.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.7.7.1.m1.1b"><apply id="S4.T5.7.7.1.m1.1.1.cmml" xref="S4.T5.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.7.7.1.m1.1.1.1.cmml" xref="S4.T5.7.7.1.m1.1.1">subscript</csymbol><ci id="S4.T5.7.7.1.m1.1.1.2.cmml" xref="S4.T5.7.7.1.m1.1.1.2">𝐸</ci><ci id="S4.T5.7.7.1.m1.1.1.3.cmml" xref="S4.T5.7.7.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.7.1.m1.1c">E_{T}</annotation></semantics></math> (meters)</td>
<td id="S4.T5.7.7.2" class="ltx_td ltx_align_left ltx_border_r">6.19</td>
<td id="S4.T5.7.7.3" class="ltx_td ltx_align_left">10.94</td>
</tr>
<tr id="S4.T5.8.8" class="ltx_tr">
<td id="S4.T5.8.8.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T5.8.8.1.m1.1" class="ltx_Math" alttext="E_{TN}" display="inline"><semantics id="S4.T5.8.8.1.m1.1a"><msub id="S4.T5.8.8.1.m1.1.1" xref="S4.T5.8.8.1.m1.1.1.cmml"><mi id="S4.T5.8.8.1.m1.1.1.2" xref="S4.T5.8.8.1.m1.1.1.2.cmml">E</mi><mrow id="S4.T5.8.8.1.m1.1.1.3" xref="S4.T5.8.8.1.m1.1.1.3.cmml"><mi id="S4.T5.8.8.1.m1.1.1.3.2" xref="S4.T5.8.8.1.m1.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.T5.8.8.1.m1.1.1.3.1" xref="S4.T5.8.8.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.8.8.1.m1.1.1.3.3" xref="S4.T5.8.8.1.m1.1.1.3.3.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.8.8.1.m1.1b"><apply id="S4.T5.8.8.1.m1.1.1.cmml" xref="S4.T5.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.8.8.1.m1.1.1.1.cmml" xref="S4.T5.8.8.1.m1.1.1">subscript</csymbol><ci id="S4.T5.8.8.1.m1.1.1.2.cmml" xref="S4.T5.8.8.1.m1.1.1.2">𝐸</ci><apply id="S4.T5.8.8.1.m1.1.1.3.cmml" xref="S4.T5.8.8.1.m1.1.1.3"><times id="S4.T5.8.8.1.m1.1.1.3.1.cmml" xref="S4.T5.8.8.1.m1.1.1.3.1"></times><ci id="S4.T5.8.8.1.m1.1.1.3.2.cmml" xref="S4.T5.8.8.1.m1.1.1.3.2">𝑇</ci><ci id="S4.T5.8.8.1.m1.1.1.3.3.cmml" xref="S4.T5.8.8.1.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.8.1.m1.1c">E_{TN}</annotation></semantics></math></td>
<td id="S4.T5.8.8.2" class="ltx_td ltx_align_left ltx_border_r">0.026</td>
<td id="S4.T5.8.8.3" class="ltx_td ltx_align_left">0.040</td>
</tr>
<tr id="S4.T5.9.9" class="ltx_tr">
<td id="S4.T5.9.9.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T5.9.9.1.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.T5.9.9.1.m1.1a"><msub id="S4.T5.9.9.1.m1.1.1" xref="S4.T5.9.9.1.m1.1.1.cmml"><mi id="S4.T5.9.9.1.m1.1.1.2" xref="S4.T5.9.9.1.m1.1.1.2.cmml">E</mi><mi id="S4.T5.9.9.1.m1.1.1.3" xref="S4.T5.9.9.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.9.9.1.m1.1b"><apply id="S4.T5.9.9.1.m1.1.1.cmml" xref="S4.T5.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.9.9.1.m1.1.1.1.cmml" xref="S4.T5.9.9.1.m1.1.1">subscript</csymbol><ci id="S4.T5.9.9.1.m1.1.1.2.cmml" xref="S4.T5.9.9.1.m1.1.1.2">𝐸</ci><ci id="S4.T5.9.9.1.m1.1.1.3.cmml" xref="S4.T5.9.9.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.9.1.m1.1c">E_{C}</annotation></semantics></math></td>
<td id="S4.T5.9.9.2" class="ltx_td ltx_align_left ltx_border_r">0.156</td>
<td id="S4.T5.9.9.3" class="ltx_td ltx_align_left">0.561</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">Table <a href="#S4.T5" title="Table 5 ‣ 4.4 Cygnus: Real Data ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the performance of the pose estimation system on the real images. The object detection network still performs quite well. The pose errors once again contain some “bad estimates” on the more difficult images. Keeping the same <math id="S4.SS4.p3.1.m1.1" class="ltx_Math" alttext="\hat{E_{k}}" display="inline"><semantics id="S4.SS4.p3.1.m1.1a"><mover accent="true" id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml"><msub id="S4.SS4.p3.1.m1.1.1.2" xref="S4.SS4.p3.1.m1.1.1.2.cmml"><mi id="S4.SS4.p3.1.m1.1.1.2.2" xref="S4.SS4.p3.1.m1.1.1.2.2.cmml">E</mi><mi id="S4.SS4.p3.1.m1.1.1.2.3" xref="S4.SS4.p3.1.m1.1.1.2.3.cmml">k</mi></msub><mo id="S4.SS4.p3.1.m1.1.1.1" xref="S4.SS4.p3.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><apply id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1"><ci id="S4.SS4.p3.1.m1.1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1.1">^</ci><apply id="S4.SS4.p3.1.m1.1.1.2.cmml" xref="S4.SS4.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.p3.1.m1.1.1.2.1.cmml" xref="S4.SS4.p3.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS4.p3.1.m1.1.1.2.2.cmml" xref="S4.SS4.p3.1.m1.1.1.2.2">𝐸</ci><ci id="S4.SS4.p3.1.m1.1.1.2.3.cmml" xref="S4.SS4.p3.1.m1.1.1.2.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">\hat{E_{k}}</annotation></semantics></math> threshold of 20 pixels, the error prediction network rejects 16% of the estimates and easily recognizes all of the most extreme outliers. Overall, considering the relative difficulty of the real image test set, the system generalizes well.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">However, the error prediction network notably does not help very much with the mean rotation error compared to the mean translation error. This is because the Cygnus spacecraft has a major symmetry: namely, a 180° rotation around the barrel is difficult to distinguish, indicated primarily by the presence or absence of two logos. This poses an especially challenging obstacle to the keypoint regression network when generalizing to real data. In some images, the network misses the subtle features necessary to determine the correct orientation, due to the fact that it was trained using an imperfect synthetic model. This particular type of mistake produces a confident estimate that is unlikely to be rejected by the error prediction network, yet has near 180° rotation error (see Figure <a href="#S4.F7" title="Figure 7 ‣ 4.4 Cygnus: Real Data ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (d) and (e) for examples).</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.7.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.8.2" class="ltx_text" style="font-size:90%;">Rotation Error Allowing Symmetrical Orientations</span></figcaption>
<table id="S4.T6.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.5.6.1" class="ltx_tr">
<th id="S4.T6.5.6.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S4.T6.5.6.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Metric</th>
<th id="S4.T6.5.6.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Median</th>
<th id="S4.T6.5.6.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Mean</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.1.1" class="ltx_tr">
<th id="S4.T6.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T6.1.1.2.1" class="ltx_text">Pose Metrics</span></th>
<th id="S4.T6.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<math id="S4.T6.1.1.1.m1.1" class="ltx_Math" alttext="E_{R}" display="inline"><semantics id="S4.T6.1.1.1.m1.1a"><msub id="S4.T6.1.1.1.m1.1.1" xref="S4.T6.1.1.1.m1.1.1.cmml"><mi id="S4.T6.1.1.1.m1.1.1.2" xref="S4.T6.1.1.1.m1.1.1.2.cmml">E</mi><mi id="S4.T6.1.1.1.m1.1.1.3" xref="S4.T6.1.1.1.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.m1.1b"><apply id="S4.T6.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.1.1.1.m1.1.1.1.cmml" xref="S4.T6.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T6.1.1.1.m1.1.1.2.cmml" xref="S4.T6.1.1.1.m1.1.1.2">𝐸</ci><ci id="S4.T6.1.1.1.m1.1.1.3.cmml" xref="S4.T6.1.1.1.m1.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.m1.1c">E_{R}</annotation></semantics></math> (deg)</th>
<td id="S4.T6.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6.20</td>
<td id="S4.T6.1.1.4" class="ltx_td ltx_align_left ltx_border_t">11.97</td>
</tr>
<tr id="S4.T6.2.2" class="ltx_tr">
<th id="S4.T6.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><math id="S4.T6.2.2.1.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.T6.2.2.1.m1.1a"><msub id="S4.T6.2.2.1.m1.1.1" xref="S4.T6.2.2.1.m1.1.1.cmml"><mi id="S4.T6.2.2.1.m1.1.1.2" xref="S4.T6.2.2.1.m1.1.1.2.cmml">E</mi><mi id="S4.T6.2.2.1.m1.1.1.3" xref="S4.T6.2.2.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.1.m1.1b"><apply id="S4.T6.2.2.1.m1.1.1.cmml" xref="S4.T6.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.2.2.1.m1.1.1.1.cmml" xref="S4.T6.2.2.1.m1.1.1">subscript</csymbol><ci id="S4.T6.2.2.1.m1.1.1.2.cmml" xref="S4.T6.2.2.1.m1.1.1.2">𝐸</ci><ci id="S4.T6.2.2.1.m1.1.1.3.cmml" xref="S4.T6.2.2.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.1.m1.1c">E_{C}</annotation></semantics></math></th>
<td id="S4.T6.2.2.2" class="ltx_td ltx_align_left ltx_border_r">0.154</td>
<td id="S4.T6.2.2.3" class="ltx_td ltx_align_left">0.526</td>
</tr>
<tr id="S4.T6.4.4" class="ltx_tr">
<th id="S4.T6.3.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T6.3.3.1.1" class="ltx_text">
<span id="S4.T6.3.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T6.3.3.1.1.1.2" class="ltx_tr">
<span id="S4.T6.3.3.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_right">Rejected Estimates</span></span>
<span id="S4.T6.3.3.1.1.1.1" class="ltx_tr">
<span id="S4.T6.3.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_right">(<math id="S4.T6.3.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\hat{E_{k}}&gt;20" display="inline"><semantics id="S4.T6.3.3.1.1.1.1.1.m1.1a"><mrow id="S4.T6.3.3.1.1.1.1.1.m1.1.1" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.cmml"><mover accent="true" id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.cmml"><msub id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.cmml"><mi id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.2" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.2.cmml">E</mi><mi id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.3" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.3.cmml">k</mi></msub><mo id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.1" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.1.cmml">^</mo></mover><mo id="S4.T6.3.3.1.1.1.1.1.m1.1.1.1" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mn id="S4.T6.3.3.1.1.1.1.1.m1.1.1.3" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.3.3.1.1.1.1.1.m1.1b"><apply id="S4.T6.3.3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1"><gt id="S4.T6.3.3.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.1"></gt><apply id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2"><ci id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.1.cmml" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.1">^</ci><apply id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.cmml" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2"><csymbol cd="ambiguous" id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.1.cmml" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2">subscript</csymbol><ci id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.2.cmml" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.2">𝐸</ci><ci id="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.3.cmml" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.2.2.3">𝑘</ci></apply></apply><cn type="integer" id="S4.T6.3.3.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T6.3.3.1.1.1.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.3.1.1.1.1.1.m1.1c">\hat{E_{k}}&gt;20</annotation></semantics></math>) Removed</span></span>
</span></span></th>
<th id="S4.T6.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<math id="S4.T6.4.4.2.m1.1" class="ltx_Math" alttext="E_{R}" display="inline"><semantics id="S4.T6.4.4.2.m1.1a"><msub id="S4.T6.4.4.2.m1.1.1" xref="S4.T6.4.4.2.m1.1.1.cmml"><mi id="S4.T6.4.4.2.m1.1.1.2" xref="S4.T6.4.4.2.m1.1.1.2.cmml">E</mi><mi id="S4.T6.4.4.2.m1.1.1.3" xref="S4.T6.4.4.2.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T6.4.4.2.m1.1b"><apply id="S4.T6.4.4.2.m1.1.1.cmml" xref="S4.T6.4.4.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.4.4.2.m1.1.1.1.cmml" xref="S4.T6.4.4.2.m1.1.1">subscript</csymbol><ci id="S4.T6.4.4.2.m1.1.1.2.cmml" xref="S4.T6.4.4.2.m1.1.1.2">𝐸</ci><ci id="S4.T6.4.4.2.m1.1.1.3.cmml" xref="S4.T6.4.4.2.m1.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.4.2.m1.1c">E_{R}</annotation></semantics></math> (deg)</th>
<td id="S4.T6.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">5.38</td>
<td id="S4.T6.4.4.4" class="ltx_td ltx_align_left ltx_border_t">8.37</td>
</tr>
<tr id="S4.T6.5.5" class="ltx_tr">
<th id="S4.T6.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><math id="S4.T6.5.5.1.m1.1" class="ltx_Math" alttext="E_{C}" display="inline"><semantics id="S4.T6.5.5.1.m1.1a"><msub id="S4.T6.5.5.1.m1.1.1" xref="S4.T6.5.5.1.m1.1.1.cmml"><mi id="S4.T6.5.5.1.m1.1.1.2" xref="S4.T6.5.5.1.m1.1.1.2.cmml">E</mi><mi id="S4.T6.5.5.1.m1.1.1.3" xref="S4.T6.5.5.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T6.5.5.1.m1.1b"><apply id="S4.T6.5.5.1.m1.1.1.cmml" xref="S4.T6.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.5.5.1.m1.1.1.1.cmml" xref="S4.T6.5.5.1.m1.1.1">subscript</csymbol><ci id="S4.T6.5.5.1.m1.1.1.2.cmml" xref="S4.T6.5.5.1.m1.1.1.2">𝐸</ci><ci id="S4.T6.5.5.1.m1.1.1.3.cmml" xref="S4.T6.5.5.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.5.5.1.m1.1c">E_{C}</annotation></semantics></math></th>
<td id="S4.T6.5.5.2" class="ltx_td ltx_align_left ltx_border_r">0.136</td>
<td id="S4.T6.5.5.3" class="ltx_td ltx_align_left">0.186</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.1" class="ltx_p">Table <a href="#S4.T6" title="Table 6 ‣ 4.4 Cygnus: Real Data ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> presents updated rotation and combined error values if the issue of symmetry is ignored; i.e., the rotation error is computed as the smallest angle rotation that aligns the estimated pose with either of the two ambiguous orientations. These values correspond to the feasible mission scenario where the orientation of Cygnus about this axis of symmetry is not important, only the orientation of its overall shape and major features. Without the 180° outliers, the pose estimation system achieves a rotation error within 10° and a combined error lower than it does on the much easier SPEED real image test set.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/pos_hist.png" id="S4.F6.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/rot_hist.png" id="S4.F6.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.4.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.5.2" class="ltx_text" style="font-size:90%;">Histogram of translation error (left) and rotation error (right) that also shows images rejected by the error prediction network. The error prediction step helps immensely with translation error, rejecting nearly all of the outliers. However, it is much less effective for rotation error, due to the rotational symmetry. All of the outliers near 180° are otherwise “good estimates” with the incorrect orientation (e.g. Figure <a href="#S4.F7" title="Figure 7 ‣ 4.4 Cygnus: Real Data ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (d) and (e)).</span></figcaption>
</figure>
<figure id="S4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_det_105.jpg" id="S4.F7.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf1.6.2.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><math id="S4.F7.sf1.3.m1.1" class="ltx_Math" alttext="E_{R}=4.22\degree" display="inline"><semantics id="S4.F7.sf1.3.m1.1b"><mrow id="S4.F7.sf1.3.m1.1.1" xref="S4.F7.sf1.3.m1.1.1.cmml"><msub id="S4.F7.sf1.3.m1.1.1.2" xref="S4.F7.sf1.3.m1.1.1.2.cmml"><mi mathsize="90%" id="S4.F7.sf1.3.m1.1.1.2.2" xref="S4.F7.sf1.3.m1.1.1.2.2.cmml">E</mi><mi mathsize="90%" id="S4.F7.sf1.3.m1.1.1.2.3" xref="S4.F7.sf1.3.m1.1.1.2.3.cmml">R</mi></msub><mo mathsize="90%" id="S4.F7.sf1.3.m1.1.1.1" xref="S4.F7.sf1.3.m1.1.1.1.cmml">=</mo><mrow id="S4.F7.sf1.3.m1.1.1.3" xref="S4.F7.sf1.3.m1.1.1.3.cmml"><mn mathsize="90%" id="S4.F7.sf1.3.m1.1.1.3.2" xref="S4.F7.sf1.3.m1.1.1.3.2.cmml">4.22</mn><mo lspace="0em" rspace="0em" id="S4.F7.sf1.3.m1.1.1.3.1" xref="S4.F7.sf1.3.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" mathvariant="normal" id="S4.F7.sf1.3.m1.1.1.3.3" xref="S4.F7.sf1.3.m1.1.1.3.3.cmml">°</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf1.3.m1.1c"><apply id="S4.F7.sf1.3.m1.1.1.cmml" xref="S4.F7.sf1.3.m1.1.1"><eq id="S4.F7.sf1.3.m1.1.1.1.cmml" xref="S4.F7.sf1.3.m1.1.1.1"></eq><apply id="S4.F7.sf1.3.m1.1.1.2.cmml" xref="S4.F7.sf1.3.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf1.3.m1.1.1.2.1.cmml" xref="S4.F7.sf1.3.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf1.3.m1.1.1.2.2.cmml" xref="S4.F7.sf1.3.m1.1.1.2.2">𝐸</ci><ci id="S4.F7.sf1.3.m1.1.1.2.3.cmml" xref="S4.F7.sf1.3.m1.1.1.2.3">𝑅</ci></apply><apply id="S4.F7.sf1.3.m1.1.1.3.cmml" xref="S4.F7.sf1.3.m1.1.1.3"><times id="S4.F7.sf1.3.m1.1.1.3.1.cmml" xref="S4.F7.sf1.3.m1.1.1.3.1"></times><cn type="float" id="S4.F7.sf1.3.m1.1.1.3.2.cmml" xref="S4.F7.sf1.3.m1.1.1.3.2">4.22</cn><ci id="S4.F7.sf1.3.m1.1.1.3.3.cmml" xref="S4.F7.sf1.3.m1.1.1.3.3">°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf1.3.m1.1d">E_{R}=4.22\degree</annotation></semantics></math><span id="S4.F7.sf1.4.1" class="ltx_text" style="font-size:90%;">, <math id="S4.F7.sf1.4.1.m1.1" class="ltx_Math" alttext="E_{TN}=0.013" display="inline"><semantics id="S4.F7.sf1.4.1.m1.1b"><mrow id="S4.F7.sf1.4.1.m1.1.1" xref="S4.F7.sf1.4.1.m1.1.1.cmml"><msub id="S4.F7.sf1.4.1.m1.1.1.2" xref="S4.F7.sf1.4.1.m1.1.1.2.cmml"><mi id="S4.F7.sf1.4.1.m1.1.1.2.2" xref="S4.F7.sf1.4.1.m1.1.1.2.2.cmml">E</mi><mrow id="S4.F7.sf1.4.1.m1.1.1.2.3" xref="S4.F7.sf1.4.1.m1.1.1.2.3.cmml"><mi id="S4.F7.sf1.4.1.m1.1.1.2.3.2" xref="S4.F7.sf1.4.1.m1.1.1.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.F7.sf1.4.1.m1.1.1.2.3.1" xref="S4.F7.sf1.4.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.F7.sf1.4.1.m1.1.1.2.3.3" xref="S4.F7.sf1.4.1.m1.1.1.2.3.3.cmml">N</mi></mrow></msub><mo id="S4.F7.sf1.4.1.m1.1.1.1" xref="S4.F7.sf1.4.1.m1.1.1.1.cmml">=</mo><mn id="S4.F7.sf1.4.1.m1.1.1.3" xref="S4.F7.sf1.4.1.m1.1.1.3.cmml">0.013</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf1.4.1.m1.1c"><apply id="S4.F7.sf1.4.1.m1.1.1.cmml" xref="S4.F7.sf1.4.1.m1.1.1"><eq id="S4.F7.sf1.4.1.m1.1.1.1.cmml" xref="S4.F7.sf1.4.1.m1.1.1.1"></eq><apply id="S4.F7.sf1.4.1.m1.1.1.2.cmml" xref="S4.F7.sf1.4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf1.4.1.m1.1.1.2.1.cmml" xref="S4.F7.sf1.4.1.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf1.4.1.m1.1.1.2.2.cmml" xref="S4.F7.sf1.4.1.m1.1.1.2.2">𝐸</ci><apply id="S4.F7.sf1.4.1.m1.1.1.2.3.cmml" xref="S4.F7.sf1.4.1.m1.1.1.2.3"><times id="S4.F7.sf1.4.1.m1.1.1.2.3.1.cmml" xref="S4.F7.sf1.4.1.m1.1.1.2.3.1"></times><ci id="S4.F7.sf1.4.1.m1.1.1.2.3.2.cmml" xref="S4.F7.sf1.4.1.m1.1.1.2.3.2">𝑇</ci><ci id="S4.F7.sf1.4.1.m1.1.1.2.3.3.cmml" xref="S4.F7.sf1.4.1.m1.1.1.2.3.3">𝑁</ci></apply></apply><cn type="float" id="S4.F7.sf1.4.1.m1.1.1.3.cmml" xref="S4.F7.sf1.4.1.m1.1.1.3">0.013</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf1.4.1.m1.1d">E_{TN}=0.013</annotation></semantics></math> 
<br class="ltx_break">Noisy keypoint estimates can still produce a good pose estimate by using RANSAC.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_det_399.jpg" id="S4.F7.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf2.6.2.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><math id="S4.F7.sf2.3.m1.1" class="ltx_Math" alttext="E_{R}=2.72\degree" display="inline"><semantics id="S4.F7.sf2.3.m1.1b"><mrow id="S4.F7.sf2.3.m1.1.1" xref="S4.F7.sf2.3.m1.1.1.cmml"><msub id="S4.F7.sf2.3.m1.1.1.2" xref="S4.F7.sf2.3.m1.1.1.2.cmml"><mi mathsize="90%" id="S4.F7.sf2.3.m1.1.1.2.2" xref="S4.F7.sf2.3.m1.1.1.2.2.cmml">E</mi><mi mathsize="90%" id="S4.F7.sf2.3.m1.1.1.2.3" xref="S4.F7.sf2.3.m1.1.1.2.3.cmml">R</mi></msub><mo mathsize="90%" id="S4.F7.sf2.3.m1.1.1.1" xref="S4.F7.sf2.3.m1.1.1.1.cmml">=</mo><mrow id="S4.F7.sf2.3.m1.1.1.3" xref="S4.F7.sf2.3.m1.1.1.3.cmml"><mn mathsize="90%" id="S4.F7.sf2.3.m1.1.1.3.2" xref="S4.F7.sf2.3.m1.1.1.3.2.cmml">2.72</mn><mo lspace="0em" rspace="0em" id="S4.F7.sf2.3.m1.1.1.3.1" xref="S4.F7.sf2.3.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" mathvariant="normal" id="S4.F7.sf2.3.m1.1.1.3.3" xref="S4.F7.sf2.3.m1.1.1.3.3.cmml">°</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf2.3.m1.1c"><apply id="S4.F7.sf2.3.m1.1.1.cmml" xref="S4.F7.sf2.3.m1.1.1"><eq id="S4.F7.sf2.3.m1.1.1.1.cmml" xref="S4.F7.sf2.3.m1.1.1.1"></eq><apply id="S4.F7.sf2.3.m1.1.1.2.cmml" xref="S4.F7.sf2.3.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf2.3.m1.1.1.2.1.cmml" xref="S4.F7.sf2.3.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf2.3.m1.1.1.2.2.cmml" xref="S4.F7.sf2.3.m1.1.1.2.2">𝐸</ci><ci id="S4.F7.sf2.3.m1.1.1.2.3.cmml" xref="S4.F7.sf2.3.m1.1.1.2.3">𝑅</ci></apply><apply id="S4.F7.sf2.3.m1.1.1.3.cmml" xref="S4.F7.sf2.3.m1.1.1.3"><times id="S4.F7.sf2.3.m1.1.1.3.1.cmml" xref="S4.F7.sf2.3.m1.1.1.3.1"></times><cn type="float" id="S4.F7.sf2.3.m1.1.1.3.2.cmml" xref="S4.F7.sf2.3.m1.1.1.3.2">2.72</cn><ci id="S4.F7.sf2.3.m1.1.1.3.3.cmml" xref="S4.F7.sf2.3.m1.1.1.3.3">°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf2.3.m1.1d">E_{R}=2.72\degree</annotation></semantics></math><span id="S4.F7.sf2.4.1" class="ltx_text" style="font-size:90%;">, <math id="S4.F7.sf2.4.1.m1.1" class="ltx_Math" alttext="E_{TN}=0.034" display="inline"><semantics id="S4.F7.sf2.4.1.m1.1b"><mrow id="S4.F7.sf2.4.1.m1.1.1" xref="S4.F7.sf2.4.1.m1.1.1.cmml"><msub id="S4.F7.sf2.4.1.m1.1.1.2" xref="S4.F7.sf2.4.1.m1.1.1.2.cmml"><mi id="S4.F7.sf2.4.1.m1.1.1.2.2" xref="S4.F7.sf2.4.1.m1.1.1.2.2.cmml">E</mi><mrow id="S4.F7.sf2.4.1.m1.1.1.2.3" xref="S4.F7.sf2.4.1.m1.1.1.2.3.cmml"><mi id="S4.F7.sf2.4.1.m1.1.1.2.3.2" xref="S4.F7.sf2.4.1.m1.1.1.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.F7.sf2.4.1.m1.1.1.2.3.1" xref="S4.F7.sf2.4.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.F7.sf2.4.1.m1.1.1.2.3.3" xref="S4.F7.sf2.4.1.m1.1.1.2.3.3.cmml">N</mi></mrow></msub><mo id="S4.F7.sf2.4.1.m1.1.1.1" xref="S4.F7.sf2.4.1.m1.1.1.1.cmml">=</mo><mn id="S4.F7.sf2.4.1.m1.1.1.3" xref="S4.F7.sf2.4.1.m1.1.1.3.cmml">0.034</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf2.4.1.m1.1c"><apply id="S4.F7.sf2.4.1.m1.1.1.cmml" xref="S4.F7.sf2.4.1.m1.1.1"><eq id="S4.F7.sf2.4.1.m1.1.1.1.cmml" xref="S4.F7.sf2.4.1.m1.1.1.1"></eq><apply id="S4.F7.sf2.4.1.m1.1.1.2.cmml" xref="S4.F7.sf2.4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf2.4.1.m1.1.1.2.1.cmml" xref="S4.F7.sf2.4.1.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf2.4.1.m1.1.1.2.2.cmml" xref="S4.F7.sf2.4.1.m1.1.1.2.2">𝐸</ci><apply id="S4.F7.sf2.4.1.m1.1.1.2.3.cmml" xref="S4.F7.sf2.4.1.m1.1.1.2.3"><times id="S4.F7.sf2.4.1.m1.1.1.2.3.1.cmml" xref="S4.F7.sf2.4.1.m1.1.1.2.3.1"></times><ci id="S4.F7.sf2.4.1.m1.1.1.2.3.2.cmml" xref="S4.F7.sf2.4.1.m1.1.1.2.3.2">𝑇</ci><ci id="S4.F7.sf2.4.1.m1.1.1.2.3.3.cmml" xref="S4.F7.sf2.4.1.m1.1.1.2.3.3">𝑁</ci></apply></apply><cn type="float" id="S4.F7.sf2.4.1.m1.1.1.3.cmml" xref="S4.F7.sf2.4.1.m1.1.1.3">0.034</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf2.4.1.m1.1d">E_{TN}=0.034</annotation></semantics></math> 
<br class="ltx_break">The object detection network performs well at multiple scales.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_det_620.jpg" id="S4.F7.sf3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf3.6.2.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><math id="S4.F7.sf3.3.m1.1" class="ltx_Math" alttext="E_{R}=6.34\degree" display="inline"><semantics id="S4.F7.sf3.3.m1.1b"><mrow id="S4.F7.sf3.3.m1.1.1" xref="S4.F7.sf3.3.m1.1.1.cmml"><msub id="S4.F7.sf3.3.m1.1.1.2" xref="S4.F7.sf3.3.m1.1.1.2.cmml"><mi mathsize="90%" id="S4.F7.sf3.3.m1.1.1.2.2" xref="S4.F7.sf3.3.m1.1.1.2.2.cmml">E</mi><mi mathsize="90%" id="S4.F7.sf3.3.m1.1.1.2.3" xref="S4.F7.sf3.3.m1.1.1.2.3.cmml">R</mi></msub><mo mathsize="90%" id="S4.F7.sf3.3.m1.1.1.1" xref="S4.F7.sf3.3.m1.1.1.1.cmml">=</mo><mrow id="S4.F7.sf3.3.m1.1.1.3" xref="S4.F7.sf3.3.m1.1.1.3.cmml"><mn mathsize="90%" id="S4.F7.sf3.3.m1.1.1.3.2" xref="S4.F7.sf3.3.m1.1.1.3.2.cmml">6.34</mn><mo lspace="0em" rspace="0em" id="S4.F7.sf3.3.m1.1.1.3.1" xref="S4.F7.sf3.3.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" mathvariant="normal" id="S4.F7.sf3.3.m1.1.1.3.3" xref="S4.F7.sf3.3.m1.1.1.3.3.cmml">°</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf3.3.m1.1c"><apply id="S4.F7.sf3.3.m1.1.1.cmml" xref="S4.F7.sf3.3.m1.1.1"><eq id="S4.F7.sf3.3.m1.1.1.1.cmml" xref="S4.F7.sf3.3.m1.1.1.1"></eq><apply id="S4.F7.sf3.3.m1.1.1.2.cmml" xref="S4.F7.sf3.3.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf3.3.m1.1.1.2.1.cmml" xref="S4.F7.sf3.3.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf3.3.m1.1.1.2.2.cmml" xref="S4.F7.sf3.3.m1.1.1.2.2">𝐸</ci><ci id="S4.F7.sf3.3.m1.1.1.2.3.cmml" xref="S4.F7.sf3.3.m1.1.1.2.3">𝑅</ci></apply><apply id="S4.F7.sf3.3.m1.1.1.3.cmml" xref="S4.F7.sf3.3.m1.1.1.3"><times id="S4.F7.sf3.3.m1.1.1.3.1.cmml" xref="S4.F7.sf3.3.m1.1.1.3.1"></times><cn type="float" id="S4.F7.sf3.3.m1.1.1.3.2.cmml" xref="S4.F7.sf3.3.m1.1.1.3.2">6.34</cn><ci id="S4.F7.sf3.3.m1.1.1.3.3.cmml" xref="S4.F7.sf3.3.m1.1.1.3.3">°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf3.3.m1.1d">E_{R}=6.34\degree</annotation></semantics></math><span id="S4.F7.sf3.4.1" class="ltx_text" style="font-size:90%;">, <math id="S4.F7.sf3.4.1.m1.1" class="ltx_Math" alttext="E_{TN}=0.045" display="inline"><semantics id="S4.F7.sf3.4.1.m1.1b"><mrow id="S4.F7.sf3.4.1.m1.1.1" xref="S4.F7.sf3.4.1.m1.1.1.cmml"><msub id="S4.F7.sf3.4.1.m1.1.1.2" xref="S4.F7.sf3.4.1.m1.1.1.2.cmml"><mi id="S4.F7.sf3.4.1.m1.1.1.2.2" xref="S4.F7.sf3.4.1.m1.1.1.2.2.cmml">E</mi><mrow id="S4.F7.sf3.4.1.m1.1.1.2.3" xref="S4.F7.sf3.4.1.m1.1.1.2.3.cmml"><mi id="S4.F7.sf3.4.1.m1.1.1.2.3.2" xref="S4.F7.sf3.4.1.m1.1.1.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.F7.sf3.4.1.m1.1.1.2.3.1" xref="S4.F7.sf3.4.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.F7.sf3.4.1.m1.1.1.2.3.3" xref="S4.F7.sf3.4.1.m1.1.1.2.3.3.cmml">N</mi></mrow></msub><mo id="S4.F7.sf3.4.1.m1.1.1.1" xref="S4.F7.sf3.4.1.m1.1.1.1.cmml">=</mo><mn id="S4.F7.sf3.4.1.m1.1.1.3" xref="S4.F7.sf3.4.1.m1.1.1.3.cmml">0.045</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf3.4.1.m1.1c"><apply id="S4.F7.sf3.4.1.m1.1.1.cmml" xref="S4.F7.sf3.4.1.m1.1.1"><eq id="S4.F7.sf3.4.1.m1.1.1.1.cmml" xref="S4.F7.sf3.4.1.m1.1.1.1"></eq><apply id="S4.F7.sf3.4.1.m1.1.1.2.cmml" xref="S4.F7.sf3.4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf3.4.1.m1.1.1.2.1.cmml" xref="S4.F7.sf3.4.1.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf3.4.1.m1.1.1.2.2.cmml" xref="S4.F7.sf3.4.1.m1.1.1.2.2">𝐸</ci><apply id="S4.F7.sf3.4.1.m1.1.1.2.3.cmml" xref="S4.F7.sf3.4.1.m1.1.1.2.3"><times id="S4.F7.sf3.4.1.m1.1.1.2.3.1.cmml" xref="S4.F7.sf3.4.1.m1.1.1.2.3.1"></times><ci id="S4.F7.sf3.4.1.m1.1.1.2.3.2.cmml" xref="S4.F7.sf3.4.1.m1.1.1.2.3.2">𝑇</ci><ci id="S4.F7.sf3.4.1.m1.1.1.2.3.3.cmml" xref="S4.F7.sf3.4.1.m1.1.1.2.3.3">𝑁</ci></apply></apply><cn type="float" id="S4.F7.sf3.4.1.m1.1.1.3.cmml" xref="S4.F7.sf3.4.1.m1.1.1.3">0.045</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf3.4.1.m1.1d">E_{TN}=0.045</annotation></semantics></math> 
<br class="ltx_break">The system performs well even with an object slightly occluding Cygnus, which does not appear at all in the training data.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_det_057.jpg" id="S4.F7.sf4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf4.6.2.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><math id="S4.F7.sf4.3.m1.1" class="ltx_Math" alttext="E_{R}=177.6\degree" display="inline"><semantics id="S4.F7.sf4.3.m1.1b"><mrow id="S4.F7.sf4.3.m1.1.1" xref="S4.F7.sf4.3.m1.1.1.cmml"><msub id="S4.F7.sf4.3.m1.1.1.2" xref="S4.F7.sf4.3.m1.1.1.2.cmml"><mi mathsize="90%" id="S4.F7.sf4.3.m1.1.1.2.2" xref="S4.F7.sf4.3.m1.1.1.2.2.cmml">E</mi><mi mathsize="90%" id="S4.F7.sf4.3.m1.1.1.2.3" xref="S4.F7.sf4.3.m1.1.1.2.3.cmml">R</mi></msub><mo mathsize="90%" id="S4.F7.sf4.3.m1.1.1.1" xref="S4.F7.sf4.3.m1.1.1.1.cmml">=</mo><mrow id="S4.F7.sf4.3.m1.1.1.3" xref="S4.F7.sf4.3.m1.1.1.3.cmml"><mn mathsize="90%" id="S4.F7.sf4.3.m1.1.1.3.2" xref="S4.F7.sf4.3.m1.1.1.3.2.cmml">177.6</mn><mo lspace="0em" rspace="0em" id="S4.F7.sf4.3.m1.1.1.3.1" xref="S4.F7.sf4.3.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" mathvariant="normal" id="S4.F7.sf4.3.m1.1.1.3.3" xref="S4.F7.sf4.3.m1.1.1.3.3.cmml">°</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf4.3.m1.1c"><apply id="S4.F7.sf4.3.m1.1.1.cmml" xref="S4.F7.sf4.3.m1.1.1"><eq id="S4.F7.sf4.3.m1.1.1.1.cmml" xref="S4.F7.sf4.3.m1.1.1.1"></eq><apply id="S4.F7.sf4.3.m1.1.1.2.cmml" xref="S4.F7.sf4.3.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf4.3.m1.1.1.2.1.cmml" xref="S4.F7.sf4.3.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf4.3.m1.1.1.2.2.cmml" xref="S4.F7.sf4.3.m1.1.1.2.2">𝐸</ci><ci id="S4.F7.sf4.3.m1.1.1.2.3.cmml" xref="S4.F7.sf4.3.m1.1.1.2.3">𝑅</ci></apply><apply id="S4.F7.sf4.3.m1.1.1.3.cmml" xref="S4.F7.sf4.3.m1.1.1.3"><times id="S4.F7.sf4.3.m1.1.1.3.1.cmml" xref="S4.F7.sf4.3.m1.1.1.3.1"></times><cn type="float" id="S4.F7.sf4.3.m1.1.1.3.2.cmml" xref="S4.F7.sf4.3.m1.1.1.3.2">177.6</cn><ci id="S4.F7.sf4.3.m1.1.1.3.3.cmml" xref="S4.F7.sf4.3.m1.1.1.3.3">°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf4.3.m1.1d">E_{R}=177.6\degree</annotation></semantics></math><span id="S4.F7.sf4.4.1" class="ltx_text" style="font-size:90%;">, <math id="S4.F7.sf4.4.1.m1.1" class="ltx_Math" alttext="E_{TN}=0.025" display="inline"><semantics id="S4.F7.sf4.4.1.m1.1b"><mrow id="S4.F7.sf4.4.1.m1.1.1" xref="S4.F7.sf4.4.1.m1.1.1.cmml"><msub id="S4.F7.sf4.4.1.m1.1.1.2" xref="S4.F7.sf4.4.1.m1.1.1.2.cmml"><mi id="S4.F7.sf4.4.1.m1.1.1.2.2" xref="S4.F7.sf4.4.1.m1.1.1.2.2.cmml">E</mi><mrow id="S4.F7.sf4.4.1.m1.1.1.2.3" xref="S4.F7.sf4.4.1.m1.1.1.2.3.cmml"><mi id="S4.F7.sf4.4.1.m1.1.1.2.3.2" xref="S4.F7.sf4.4.1.m1.1.1.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.F7.sf4.4.1.m1.1.1.2.3.1" xref="S4.F7.sf4.4.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.F7.sf4.4.1.m1.1.1.2.3.3" xref="S4.F7.sf4.4.1.m1.1.1.2.3.3.cmml">N</mi></mrow></msub><mo id="S4.F7.sf4.4.1.m1.1.1.1" xref="S4.F7.sf4.4.1.m1.1.1.1.cmml">=</mo><mn id="S4.F7.sf4.4.1.m1.1.1.3" xref="S4.F7.sf4.4.1.m1.1.1.3.cmml">0.025</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf4.4.1.m1.1c"><apply id="S4.F7.sf4.4.1.m1.1.1.cmml" xref="S4.F7.sf4.4.1.m1.1.1"><eq id="S4.F7.sf4.4.1.m1.1.1.1.cmml" xref="S4.F7.sf4.4.1.m1.1.1.1"></eq><apply id="S4.F7.sf4.4.1.m1.1.1.2.cmml" xref="S4.F7.sf4.4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf4.4.1.m1.1.1.2.1.cmml" xref="S4.F7.sf4.4.1.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf4.4.1.m1.1.1.2.2.cmml" xref="S4.F7.sf4.4.1.m1.1.1.2.2">𝐸</ci><apply id="S4.F7.sf4.4.1.m1.1.1.2.3.cmml" xref="S4.F7.sf4.4.1.m1.1.1.2.3"><times id="S4.F7.sf4.4.1.m1.1.1.2.3.1.cmml" xref="S4.F7.sf4.4.1.m1.1.1.2.3.1"></times><ci id="S4.F7.sf4.4.1.m1.1.1.2.3.2.cmml" xref="S4.F7.sf4.4.1.m1.1.1.2.3.2">𝑇</ci><ci id="S4.F7.sf4.4.1.m1.1.1.2.3.3.cmml" xref="S4.F7.sf4.4.1.m1.1.1.2.3.3">𝑁</ci></apply></apply><cn type="float" id="S4.F7.sf4.4.1.m1.1.1.3.cmml" xref="S4.F7.sf4.4.1.m1.1.1.3">0.025</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf4.4.1.m1.1d">E_{TN}=0.025</annotation></semantics></math> 
<br class="ltx_break">In dark lighting, the network cannot see the logos and guesses the incorrect orientation around the barrel.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_det_549.jpg" id="S4.F7.sf5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf5.6.2.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><math id="S4.F7.sf5.3.m1.1" class="ltx_Math" alttext="E_{R}=179.5\degree" display="inline"><semantics id="S4.F7.sf5.3.m1.1b"><mrow id="S4.F7.sf5.3.m1.1.1" xref="S4.F7.sf5.3.m1.1.1.cmml"><msub id="S4.F7.sf5.3.m1.1.1.2" xref="S4.F7.sf5.3.m1.1.1.2.cmml"><mi mathsize="90%" id="S4.F7.sf5.3.m1.1.1.2.2" xref="S4.F7.sf5.3.m1.1.1.2.2.cmml">E</mi><mi mathsize="90%" id="S4.F7.sf5.3.m1.1.1.2.3" xref="S4.F7.sf5.3.m1.1.1.2.3.cmml">R</mi></msub><mo mathsize="90%" id="S4.F7.sf5.3.m1.1.1.1" xref="S4.F7.sf5.3.m1.1.1.1.cmml">=</mo><mrow id="S4.F7.sf5.3.m1.1.1.3" xref="S4.F7.sf5.3.m1.1.1.3.cmml"><mn mathsize="90%" id="S4.F7.sf5.3.m1.1.1.3.2" xref="S4.F7.sf5.3.m1.1.1.3.2.cmml">179.5</mn><mo lspace="0em" rspace="0em" id="S4.F7.sf5.3.m1.1.1.3.1" xref="S4.F7.sf5.3.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" mathvariant="normal" id="S4.F7.sf5.3.m1.1.1.3.3" xref="S4.F7.sf5.3.m1.1.1.3.3.cmml">°</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf5.3.m1.1c"><apply id="S4.F7.sf5.3.m1.1.1.cmml" xref="S4.F7.sf5.3.m1.1.1"><eq id="S4.F7.sf5.3.m1.1.1.1.cmml" xref="S4.F7.sf5.3.m1.1.1.1"></eq><apply id="S4.F7.sf5.3.m1.1.1.2.cmml" xref="S4.F7.sf5.3.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf5.3.m1.1.1.2.1.cmml" xref="S4.F7.sf5.3.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf5.3.m1.1.1.2.2.cmml" xref="S4.F7.sf5.3.m1.1.1.2.2">𝐸</ci><ci id="S4.F7.sf5.3.m1.1.1.2.3.cmml" xref="S4.F7.sf5.3.m1.1.1.2.3">𝑅</ci></apply><apply id="S4.F7.sf5.3.m1.1.1.3.cmml" xref="S4.F7.sf5.3.m1.1.1.3"><times id="S4.F7.sf5.3.m1.1.1.3.1.cmml" xref="S4.F7.sf5.3.m1.1.1.3.1"></times><cn type="float" id="S4.F7.sf5.3.m1.1.1.3.2.cmml" xref="S4.F7.sf5.3.m1.1.1.3.2">179.5</cn><ci id="S4.F7.sf5.3.m1.1.1.3.3.cmml" xref="S4.F7.sf5.3.m1.1.1.3.3">°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf5.3.m1.1d">E_{R}=179.5\degree</annotation></semantics></math><span id="S4.F7.sf5.4.1" class="ltx_text" style="font-size:90%;">, <math id="S4.F7.sf5.4.1.m1.1" class="ltx_Math" alttext="E_{TN}=0.009" display="inline"><semantics id="S4.F7.sf5.4.1.m1.1b"><mrow id="S4.F7.sf5.4.1.m1.1.1" xref="S4.F7.sf5.4.1.m1.1.1.cmml"><msub id="S4.F7.sf5.4.1.m1.1.1.2" xref="S4.F7.sf5.4.1.m1.1.1.2.cmml"><mi id="S4.F7.sf5.4.1.m1.1.1.2.2" xref="S4.F7.sf5.4.1.m1.1.1.2.2.cmml">E</mi><mrow id="S4.F7.sf5.4.1.m1.1.1.2.3" xref="S4.F7.sf5.4.1.m1.1.1.2.3.cmml"><mi id="S4.F7.sf5.4.1.m1.1.1.2.3.2" xref="S4.F7.sf5.4.1.m1.1.1.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.F7.sf5.4.1.m1.1.1.2.3.1" xref="S4.F7.sf5.4.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.F7.sf5.4.1.m1.1.1.2.3.3" xref="S4.F7.sf5.4.1.m1.1.1.2.3.3.cmml">N</mi></mrow></msub><mo id="S4.F7.sf5.4.1.m1.1.1.1" xref="S4.F7.sf5.4.1.m1.1.1.1.cmml">=</mo><mn id="S4.F7.sf5.4.1.m1.1.1.3" xref="S4.F7.sf5.4.1.m1.1.1.3.cmml">0.009</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf5.4.1.m1.1c"><apply id="S4.F7.sf5.4.1.m1.1.1.cmml" xref="S4.F7.sf5.4.1.m1.1.1"><eq id="S4.F7.sf5.4.1.m1.1.1.1.cmml" xref="S4.F7.sf5.4.1.m1.1.1.1"></eq><apply id="S4.F7.sf5.4.1.m1.1.1.2.cmml" xref="S4.F7.sf5.4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf5.4.1.m1.1.1.2.1.cmml" xref="S4.F7.sf5.4.1.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf5.4.1.m1.1.1.2.2.cmml" xref="S4.F7.sf5.4.1.m1.1.1.2.2">𝐸</ci><apply id="S4.F7.sf5.4.1.m1.1.1.2.3.cmml" xref="S4.F7.sf5.4.1.m1.1.1.2.3"><times id="S4.F7.sf5.4.1.m1.1.1.2.3.1.cmml" xref="S4.F7.sf5.4.1.m1.1.1.2.3.1"></times><ci id="S4.F7.sf5.4.1.m1.1.1.2.3.2.cmml" xref="S4.F7.sf5.4.1.m1.1.1.2.3.2">𝑇</ci><ci id="S4.F7.sf5.4.1.m1.1.1.2.3.3.cmml" xref="S4.F7.sf5.4.1.m1.1.1.2.3.3">𝑁</ci></apply></apply><cn type="float" id="S4.F7.sf5.4.1.m1.1.1.3.cmml" xref="S4.F7.sf5.4.1.m1.1.1.3">0.009</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf5.4.1.m1.1d">E_{TN}=0.009</annotation></semantics></math> 
<br class="ltx_break">This viewing angle obscures the logos, again making it very difficult for the network to determine the correct orientation.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2101.09553/assets/Figures/image_det_612.jpg" id="S4.F7.sf6.g1" class="ltx_graphics ltx_img_landscape" width="598" height="398" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf6.8.3.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><math id="S4.F7.sf6.4.m1.1" class="ltx_Math" alttext="E_{R}=17.50\degree" display="inline"><semantics id="S4.F7.sf6.4.m1.1b"><mrow id="S4.F7.sf6.4.m1.1.1" xref="S4.F7.sf6.4.m1.1.1.cmml"><msub id="S4.F7.sf6.4.m1.1.1.2" xref="S4.F7.sf6.4.m1.1.1.2.cmml"><mi mathsize="90%" id="S4.F7.sf6.4.m1.1.1.2.2" xref="S4.F7.sf6.4.m1.1.1.2.2.cmml">E</mi><mi mathsize="90%" id="S4.F7.sf6.4.m1.1.1.2.3" xref="S4.F7.sf6.4.m1.1.1.2.3.cmml">R</mi></msub><mo mathsize="90%" id="S4.F7.sf6.4.m1.1.1.1" xref="S4.F7.sf6.4.m1.1.1.1.cmml">=</mo><mrow id="S4.F7.sf6.4.m1.1.1.3" xref="S4.F7.sf6.4.m1.1.1.3.cmml"><mn mathsize="90%" id="S4.F7.sf6.4.m1.1.1.3.2" xref="S4.F7.sf6.4.m1.1.1.3.2.cmml">17.50</mn><mo lspace="0em" rspace="0em" id="S4.F7.sf6.4.m1.1.1.3.1" xref="S4.F7.sf6.4.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" mathvariant="normal" id="S4.F7.sf6.4.m1.1.1.3.3" xref="S4.F7.sf6.4.m1.1.1.3.3.cmml">°</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf6.4.m1.1c"><apply id="S4.F7.sf6.4.m1.1.1.cmml" xref="S4.F7.sf6.4.m1.1.1"><eq id="S4.F7.sf6.4.m1.1.1.1.cmml" xref="S4.F7.sf6.4.m1.1.1.1"></eq><apply id="S4.F7.sf6.4.m1.1.1.2.cmml" xref="S4.F7.sf6.4.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf6.4.m1.1.1.2.1.cmml" xref="S4.F7.sf6.4.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf6.4.m1.1.1.2.2.cmml" xref="S4.F7.sf6.4.m1.1.1.2.2">𝐸</ci><ci id="S4.F7.sf6.4.m1.1.1.2.3.cmml" xref="S4.F7.sf6.4.m1.1.1.2.3">𝑅</ci></apply><apply id="S4.F7.sf6.4.m1.1.1.3.cmml" xref="S4.F7.sf6.4.m1.1.1.3"><times id="S4.F7.sf6.4.m1.1.1.3.1.cmml" xref="S4.F7.sf6.4.m1.1.1.3.1"></times><cn type="float" id="S4.F7.sf6.4.m1.1.1.3.2.cmml" xref="S4.F7.sf6.4.m1.1.1.3.2">17.50</cn><ci id="S4.F7.sf6.4.m1.1.1.3.3.cmml" xref="S4.F7.sf6.4.m1.1.1.3.3">°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf6.4.m1.1d">E_{R}=17.50\degree</annotation></semantics></math><span id="S4.F7.sf6.6.2" class="ltx_text" style="font-size:90%;">, <math id="S4.F7.sf6.5.1.m1.1" class="ltx_Math" alttext="E_{TN}=0.105" display="inline"><semantics id="S4.F7.sf6.5.1.m1.1b"><mrow id="S4.F7.sf6.5.1.m1.1.1" xref="S4.F7.sf6.5.1.m1.1.1.cmml"><msub id="S4.F7.sf6.5.1.m1.1.1.2" xref="S4.F7.sf6.5.1.m1.1.1.2.cmml"><mi id="S4.F7.sf6.5.1.m1.1.1.2.2" xref="S4.F7.sf6.5.1.m1.1.1.2.2.cmml">E</mi><mrow id="S4.F7.sf6.5.1.m1.1.1.2.3" xref="S4.F7.sf6.5.1.m1.1.1.2.3.cmml"><mi id="S4.F7.sf6.5.1.m1.1.1.2.3.2" xref="S4.F7.sf6.5.1.m1.1.1.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S4.F7.sf6.5.1.m1.1.1.2.3.1" xref="S4.F7.sf6.5.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.F7.sf6.5.1.m1.1.1.2.3.3" xref="S4.F7.sf6.5.1.m1.1.1.2.3.3.cmml">N</mi></mrow></msub><mo id="S4.F7.sf6.5.1.m1.1.1.1" xref="S4.F7.sf6.5.1.m1.1.1.1.cmml">=</mo><mn id="S4.F7.sf6.5.1.m1.1.1.3" xref="S4.F7.sf6.5.1.m1.1.1.3.cmml">0.105</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf6.5.1.m1.1c"><apply id="S4.F7.sf6.5.1.m1.1.1.cmml" xref="S4.F7.sf6.5.1.m1.1.1"><eq id="S4.F7.sf6.5.1.m1.1.1.1.cmml" xref="S4.F7.sf6.5.1.m1.1.1.1"></eq><apply id="S4.F7.sf6.5.1.m1.1.1.2.cmml" xref="S4.F7.sf6.5.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F7.sf6.5.1.m1.1.1.2.1.cmml" xref="S4.F7.sf6.5.1.m1.1.1.2">subscript</csymbol><ci id="S4.F7.sf6.5.1.m1.1.1.2.2.cmml" xref="S4.F7.sf6.5.1.m1.1.1.2.2">𝐸</ci><apply id="S4.F7.sf6.5.1.m1.1.1.2.3.cmml" xref="S4.F7.sf6.5.1.m1.1.1.2.3"><times id="S4.F7.sf6.5.1.m1.1.1.2.3.1.cmml" xref="S4.F7.sf6.5.1.m1.1.1.2.3.1"></times><ci id="S4.F7.sf6.5.1.m1.1.1.2.3.2.cmml" xref="S4.F7.sf6.5.1.m1.1.1.2.3.2">𝑇</ci><ci id="S4.F7.sf6.5.1.m1.1.1.2.3.3.cmml" xref="S4.F7.sf6.5.1.m1.1.1.2.3.3">𝑁</ci></apply></apply><cn type="float" id="S4.F7.sf6.5.1.m1.1.1.3.cmml" xref="S4.F7.sf6.5.1.m1.1.1.3">0.105</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf6.5.1.m1.1d">E_{TN}=0.105</annotation></semantics></math> 
<br class="ltx_break">This is an obvious failure case, which is rejected easily by the error prediction network (<math id="S4.F7.sf6.6.2.m2.1" class="ltx_Math" alttext="\hat{E_{k}}=86" display="inline"><semantics id="S4.F7.sf6.6.2.m2.1b"><mrow id="S4.F7.sf6.6.2.m2.1.1" xref="S4.F7.sf6.6.2.m2.1.1.cmml"><mover accent="true" id="S4.F7.sf6.6.2.m2.1.1.2" xref="S4.F7.sf6.6.2.m2.1.1.2.cmml"><msub id="S4.F7.sf6.6.2.m2.1.1.2.2" xref="S4.F7.sf6.6.2.m2.1.1.2.2.cmml"><mi id="S4.F7.sf6.6.2.m2.1.1.2.2.2" xref="S4.F7.sf6.6.2.m2.1.1.2.2.2.cmml">E</mi><mi id="S4.F7.sf6.6.2.m2.1.1.2.2.3" xref="S4.F7.sf6.6.2.m2.1.1.2.2.3.cmml">k</mi></msub><mo id="S4.F7.sf6.6.2.m2.1.1.2.1" xref="S4.F7.sf6.6.2.m2.1.1.2.1.cmml">^</mo></mover><mo id="S4.F7.sf6.6.2.m2.1.1.1" xref="S4.F7.sf6.6.2.m2.1.1.1.cmml">=</mo><mn id="S4.F7.sf6.6.2.m2.1.1.3" xref="S4.F7.sf6.6.2.m2.1.1.3.cmml">86</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.sf6.6.2.m2.1c"><apply id="S4.F7.sf6.6.2.m2.1.1.cmml" xref="S4.F7.sf6.6.2.m2.1.1"><eq id="S4.F7.sf6.6.2.m2.1.1.1.cmml" xref="S4.F7.sf6.6.2.m2.1.1.1"></eq><apply id="S4.F7.sf6.6.2.m2.1.1.2.cmml" xref="S4.F7.sf6.6.2.m2.1.1.2"><ci id="S4.F7.sf6.6.2.m2.1.1.2.1.cmml" xref="S4.F7.sf6.6.2.m2.1.1.2.1">^</ci><apply id="S4.F7.sf6.6.2.m2.1.1.2.2.cmml" xref="S4.F7.sf6.6.2.m2.1.1.2.2"><csymbol cd="ambiguous" id="S4.F7.sf6.6.2.m2.1.1.2.2.1.cmml" xref="S4.F7.sf6.6.2.m2.1.1.2.2">subscript</csymbol><ci id="S4.F7.sf6.6.2.m2.1.1.2.2.2.cmml" xref="S4.F7.sf6.6.2.m2.1.1.2.2.2">𝐸</ci><ci id="S4.F7.sf6.6.2.m2.1.1.2.2.3.cmml" xref="S4.F7.sf6.6.2.m2.1.1.2.2.3">𝑘</ci></apply></apply><cn type="integer" id="S4.F7.sf6.6.2.m2.1.1.3.cmml" xref="S4.F7.sf6.6.2.m2.1.1.3">86</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.sf6.6.2.m2.1d">\hat{E_{k}}=86</annotation></semantics></math>).</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">The pose estimation system applied to the 6 real images from Figure <a href="#S4.F5" title="Figure 5 ‣ 4.4 Cygnus: Real Data ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The green box is the RoI from the object detection network, and the colored dots are the output from the keypoint detection network same as in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.3 Keypoint Regression ‣ 3 Methods ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</span></figcaption>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Hardware Performance</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">To benchmark the pose estimation model, we use the Intel Joule 570x single-board computer. It has been used previously in a CNN-based visual navigation system onboard a 3U CubeSat<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, establishing its viability as flight-ready commercial off-the-shelf (COTS) hardware. The computational capabilities of the Joule are severely limited in comparison to typical ground-based hardware such as a laptop or smartphone. Achieving real-time performance on the device demonstrates the suitability of our system for nearly any realistic mission hardware.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">The Joule contains a 1.7GHz Intel Atom processor, 4 GB of RAM, and no dedicated graphics card. With these specifications, the pose estimation model runs at approximately 0.56 Hz using TensorFlow<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. However, a default TensorFlow installation is not optimized for inference on low-power devices. Proper optimization for low-power devices is known to increase speed by 10-20 times. The most common toolkit for such optimization is TensorFlow Lite<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>; however, TensorFlow Lite is optimized for the ARM architecture that is dominant among mobile devices. The analogous toolkit for x86 Intel processors is OpenVINO<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html</a></span></span></span>. By converting the pose estimation system into the OpenVINO format, inference speed increased to 6.6 Hz without a reduction in model accuracy.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T7.2.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S4.T7.3.2" class="ltx_text" style="font-size:90%;">Inference Speed Comparison (ms)</span></figcaption>
<table id="S4.T7.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T7.4.1.1" class="ltx_tr">
<th id="S4.T7.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Tool</th>
<th id="S4.T7.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Object Detection</th>
<th id="S4.T7.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Keypoint Regression</th>
<th id="S4.T7.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">PnP Solver</th>
<th id="S4.T7.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Error Prediction</th>
<th id="S4.T7.4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T7.4.1.1.6.1" class="ltx_text ltx_font_bold">Combined</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T7.4.2.1" class="ltx_tr">
<th id="S4.T7.4.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">TensorFlow</th>
<td id="S4.T7.4.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">710</td>
<td id="S4.T7.4.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">434</td>
<td id="S4.T7.4.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</td>
<td id="S4.T7.4.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">621</td>
<td id="S4.T7.4.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.4.2.1.6.1" class="ltx_text ltx_font_bold">1777</span></td>
</tr>
<tr id="S4.T7.4.3.2" class="ltx_tr">
<th id="S4.T7.4.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">OpenVINO</th>
<td id="S4.T7.4.3.2.2" class="ltx_td ltx_align_center ltx_border_r">68</td>
<td id="S4.T7.4.3.2.3" class="ltx_td ltx_align_center ltx_border_r">31</td>
<td id="S4.T7.4.3.2.4" class="ltx_td ltx_align_center ltx_border_r">10</td>
<td id="S4.T7.4.3.2.5" class="ltx_td ltx_align_center ltx_border_r">41</td>
<td id="S4.T7.4.3.2.6" class="ltx_td ltx_align_center"><span id="S4.T7.4.3.2.6.1" class="ltx_text ltx_font_bold">152</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.1" class="ltx_p">Table <a href="#S4.T7" title="Table 7 ‣ 4.5 Hardware Performance ‣ 4 Results ‣ REAL-TIME, FLIGHT-READY, NON-COOPERATIVE SPACECRAFT POSE ESTIMATION USING MONOCULAR IMAGERY" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> presents inference times for each component of the system. Timing data was collected by measuring the average inference time over over a period of 10 minutes, allowing the Joule reach thermal equilibrium. Once at thermal equilibrium, the power consumption for all models averaged 3.7 Watts.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The presented pose estimation system achieves state-of-the-art accuracy on the Spacecraft Pose Estimation Dataset (SPEED). At the same time, it runs at 6.6 Hz — fast enough to be considered real-time for most applications — on low-power commercial-off-the-shelf (COTS) hardware suitable for small satellites. Most importantly, given a complete lack of real training data, the system is still able to perform accurately on real images with difficult and diverse conditions. In the case of particularly difficult images or random failures, the error prediction network is able to automatically filter out bad estimates.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">As such, the presented work comprises a nearly flight-ready pose estimation system. It is suitable to run in real-time on a small satellite with limited power requirements and a single monocular camera. The synthetic image generation and training techniques are easily applicable to any spacecraft. Overall, the system’s real image performance is good enough to be useful for many applications in autonomous proximity operations; examples include formation flying, debris removal, and on-orbit inspection or servicing.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Future work will focus on integrating the pose estimation system with the other components of a fully flight-ready system. Primarily, this includes applying a dynamics-aware filtering algorithm (such as a Kalman filter) to the produced pose estimates. However, properly evaluating such a fully integrated system requires labeled time-series data from real proximity operations, which is even more difficult to obtain than ordinary real images. Another avenue of future work is to further address the issue of rotational symmetry, which is the biggest weakness of the presented pose estimation system. There exists prior work that aims to solve the specific problem of rotational symmetry in pose estimation, which could possibly be applied to this work.</p>
</div>
</section>
<section id="S6" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We would like to thank Siddarth Kaki for his support and feedback on a variety of research topics. We also thank Evan Wilde for his aid with Blender modeling. Finally, we thank the NASA Johnson Space Center, in particular Sam Pedrotty, which provided funding that contributed to this work.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. Forshaw, G. Aglietti, N. Navarathinam, H. Kadhem, T. Salmon, A. Pisseloup,
E. Joffre, T. Chabot, I. Retat, R. Axthelm, S. Barraclough, A. Ratcliffe,
C. Bernal, F. Chaumette, A. Pollini, and W. Steyn, “RemoveDEBRIS: An
in-orbit active debris removal demonstration mission,” <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Acta
Astronautica</span>, Vol. 127, 06 2016, 10.1016/j.actaastro.2016.06.018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
B. Sullivan, D. Barnhart, L. Hill, P. Oppenheimer, B. L. Benedict, G. V.
Ommering, L. Chappell, J. Ratti, and P. Will, <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">DARPA Phoenix Payload
Orbital Delivery System (PODs): “FedEx to GEO”</span>, 10.2514/6.2013-5484.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
B. B. Reed, R. C. Smith, B. J. Naasz, J. F. Pellegrino, and C. E. Bacon, <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">The Restore-L Servicing Mission</span>, 10.2514/6.2016-5478.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Cropp, <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Pose estimation and relative orbit determination of a nearby
target microsatellite using passive imagery.</span>

</span>
<span class="ltx_bibblock">PhD thesis, University of Surrey (United Kingdom)., 2001.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
X. Du, B. Liang, W. Xu, and Y. Qiu, “Pose measurement of large non-cooperative
satellite based on collaborative cameras,” <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Acta Astronautica</span>,
Vol. 68, No. 11, 2011, pp. 2047 – 2065,
https://doi.org/10.1016/j.actaastro.2010.10.021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
M. Kisantal, S. Sharma, T. H. Park, D. Izzo, M. Märtens, and
S. D’Amico, “Satellite Pose Estimation Challenge: Dataset, Competition
Design, and Results,” <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Aerospace and Electronic
Systems</span>, Vol. 56, No. 5, 2020, pp. 4083–4098, 10.1109/TAES.2020.2989063.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
S. Sharma, C. Beierle, and S. D’Amico, “Pose estimation for
non-cooperative spacecraft rendezvous using convolutional neural networks,”
<span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">2018 IEEE Aerospace Conference</span>, 2018, pp. 1–12.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S. Sharma, T. H. Park, and S. D’Amico, “Spacecraft Pose Estimation Dataset
(SPEED),” Stanford Digital Repository. Available at:
https://doi.org/10.25740/dz692fn7184, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
L. Kosmidis, J. Lachaize, J. Abella, O. Notebaert, F. J. Cazorla, and
D. Steenari, “GPU4S: Embedded GPUs in Space,” <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">2019 22nd Euromicro
Conference on Digital System Design (DSD)</span>, 2019, pp. 399–405.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
T. H. Park, S. Sharma, and S. D’Amico, “Towards Robust Learning-Based Pose
Estimation of Noncooperative Spacecraft,” <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">2019 AAS/AIAA Astrodynamics
Specialist Conference, Portland, Maine</span>, August 11-15 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
B. Chen, J. Cao, A. Parra, and T. Chin, “Satellite Pose Estimation
with Deep Landmark Regression and Nonlinear Pose Refinement,” <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">2019
IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)</span>, 2019,
pp. 2816–2824.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
B. O. Community, <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Blender - a 3D modelling and rendering package</span>.

</span>
<span class="ltx_bibblock">Blender Foundation, Stichting Blender Foundation, Amsterdam, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
N. Dhamani, G. Martin, C. Schubert, P. Singh, N. Hatten, and M. R. Akella, <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Applications of Machine Learning and Monocular Vision for Autonomous On-Orbit
Proximity Operations</span>, 10.2514/6.2020-1376.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
L. Pasqualetto Cassinis, R. Fonod, and E. Gill, “Review of the robustness
and applicability of monocular pose estimation systems for relative
navigation with an uncooperative spacecraft,” <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Progress in Aerospace
Sciences</span>, Vol. 110, 2019, p. 100548,
https://doi.org/10.1016/j.paerosci.2019.05.008.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet Classification with
Deep Convolutional Neural Networks,” <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information
Processing Systems 25</span> (F. Pereira, C. J. C. Burges, L. Bottou, and K. Q.
Weinberger, eds.), pp. 1097–1105, Curran Associates, Inc., 2012.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
H. Su, C. Ruizhongtai Qi, Y. Li, and L. Guibas, “Render for CNN: Viewpoint
Estimation in Images Using CNNs Trained with Rendered 3D Model Views,” 05
2015, 10.1109/ICCV.2015.308.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
W. Kehl, F. Manhardt, F. Tombari, S. Ilic, and N. Navab, “SSD-6D: Making
RGB-based 3D detection and 6D pose estimation great again,” <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">CoRR</span>,
Vol. abs/1711.10006, 2017.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S. Mahendran, H. Ali, and R. Vidal, “3D Pose Regression Using
Convolutional Neural Networks,” <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">2017 IEEE Conference on Computer
Vision and Pattern Recognition Workshops (CVPRW)</span>, 2017, pp. 494–495,
10.1109/CVPRW.2017.73.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
D. DeMenthon and L. Davis, “Model-Based Object Pose in 25 Lines of Code,”
Vol. 15, 02 1998, 10.1007/3-540-55426-2_38.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M. A. Fischler and R. C. Bolles, “Random Sample Consensus: A Paradigm for
Model Fitting with Applications to Image Analysis and Automated
Cartography,” <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Readings in Computer Vision</span> (M. A. Fischler and
O. Firschein, eds.), pp. 726 – 740, San Francisco (CA): Morgan Kaufmann,
1987, https://doi.org/10.1016/B978-0-08-051581-6.50070-2.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
L. P. Cassinis, R. Fonod, E. Gill, I. Ahrns, and J. G. Fernandez, <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">CNN-Based Pose Estimation System for Close-Proximity Operations Around
Uncooperative Spacecraft</span>, 10.2514/6.2020-1457.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
T. Hou, A. Ahmadyan, L. Zhang, J. Wei, and M. Grundmann, “MobilePose:
Real-Time Pose Estimation for Unseen Objects with Weak Shape Supervision,”
2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
L. Zhang, H. Yang, H. Cai, and S. Qian, “Kalman Filtering for Relative
Spacecraft Attitude and Position Estimation: A Revisit,” <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Journal of
Guidance, Control, and Dynamics</span>, Vol. 37, 09 2014, pp. 1706–1711,
10.2514/1.G000204.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
K. Gupta, L. Petersson, and R. Hartley, “CullNet: Calibrated and Pose Aware
Confidence Scores for Object Pose Estimation,” <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">2019 IEEE/CVF
International Conference on Computer Vision Workshop (ICCVW)</span>, 2019,
pp. 2758–2766.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
J.-F. Shi, S. Ulrich, and S. Ruel, “CubeSat Simulation and Detection using
Monocular Camera Images and Convolutional Neural Networks,” 01 2018,
10.2514/6.2018-1604.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
P. F. Proença and Y. Gao, “Deep Learning for Spacecraft Pose Estimation from
Photorealistic Rendering,” <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">2020 IEEE International Conference on
Robotics and Automation (ICRA)</span>, 2020, pp. 6007–6013.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
B. Joshi, M. Modasshir, T. Manderson, H. Damron, M. Xanthidis, A. Quattrini Li,
I. Rekleitis, and G. Dudek, “DeepURL: Deep Pose Estimation Framework for
Underwater Relative Localization,” <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">IEEE/RSJ International Conference
on Intelligent Robots and Systems (IROS)</span>, Las Vegas, NV, 2020, p. accepted.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
C. Yuksel, “Sample Elimination for Generating Poisson Disk Sample Sets,”
<span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Comput. Graph. Forum</span>, Vol. 34, May 2015, p. 25–32, 10.1111/cgf.12538.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
J. Huang, V. Rathod, C. Sun, M. Zhu, A. Korattikara, A. Fathi,
I. Fischer, Z. Wojna, Y. Song, S. Guadarrama, and K. Murphy,
“Speed/Accuracy Trade-Offs for Modern Convolutional Object Detectors,”
<span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
2017, pp. 3296–3297.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,
P. Dollár, and C. L. Zitnick, “Microsoft COCO: Common objects in
context,” <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">European conference on computer vision</span>, Springer, 2014,
pp. 740–755.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L. Chen,
“MobileNetV2: Inverted Residuals and Linear Bottlenecks,” <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">2018
IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, 2018,
pp. 4510–4520.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
G. Bradski, “The OpenCV Library,” <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Dr. Dobb’s Journal of Software
Tools</span>, 2000.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
V. Lepetit, F. Moreno-Noguer, and P. Fua, “EPnP: An accurate O(n) solution to
the PnP problem,” <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">International Journal of Computer Vision</span>, Vol. 81,
02 2009, 10.1007/s11263-008-0152-6.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
J. Deng, W. Dong, R. Socher, L. Li, Kai Li, and Li Fei-Fei,
“ImageNet: A large-scale hierarchical image database,” <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">2009 IEEE
Conference on Computer Vision and Pattern Recognition</span>, 2009, pp. 248–255.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado,
A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving,
M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg,
D. Mané, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens,
B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan,
F. Viégas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and
X. Zheng, “TensorFlow: Large-Scale Machine Learning on Heterogeneous
Systems,” 2015.

</span>
<span class="ltx_bibblock">Software available from tensorflow.org.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2101.09552" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2101.09553" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2101.09553">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2101.09553" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2101.09554" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  9 04:35:59 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
