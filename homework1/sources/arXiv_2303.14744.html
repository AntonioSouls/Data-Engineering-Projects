<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.14744] Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection</title><meta property="og:description" content="Building object detectors that are robust to domain shifts is critical for real-world applications. Prior approaches fine-tune a pre-trained backbone and risk overfitting it to in-distribution (ID) data and distorting …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.14744">

<!--Generated on Thu Feb 29 17:35:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Mind the Backbone: Minimizing Backbone Distortion for
<br class="ltx_break">Robust Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kuniaki Saito<sup id="id9.9.id1" class="ltx_sup"><span id="id9.9.id1.1" class="ltx_text ltx_font_italic">1</span></sup>, Donghyun Kim<sup id="id10.10.id2" class="ltx_sup"><span id="id10.10.id2.1" class="ltx_text ltx_font_italic">2</span></sup>, Piotr Teterwak<sup id="id11.11.id3" class="ltx_sup"><span id="id11.11.id3.1" class="ltx_text ltx_font_italic">1</span></sup>, Rogerio Feris<sup id="id12.12.id4" class="ltx_sup"><span id="id12.12.id4.1" class="ltx_text ltx_font_italic">2</span></sup>, Kate Saenko<sup id="id13.13.id5" class="ltx_sup"><span id="id13.13.id5.1" class="ltx_text ltx_font_italic">1,3</span></sup> 
<br class="ltx_break"><sup id="id14.14.id6" class="ltx_sup"><span id="id14.14.id6.1" class="ltx_text ltx_font_italic">1</span></sup>Boston University, <sup id="id15.15.id7" class="ltx_sup"><span id="id15.15.id7.1" class="ltx_text ltx_font_italic">2</span></sup>MIT-IBM Watson AI Lab , <sup id="id16.16.id8" class="ltx_sup"><span id="id16.16.id8.1" class="ltx_text ltx_font_italic">3</span></sup>Meta AI
<br class="ltx_break"><span id="id17.17.id9" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{keisaito, piotrt, saenko}@bu.edu, dkim@ibm.com, rsferis@us.ibm.com
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id18.id1" class="ltx_p">Building object detectors that are robust to domain shifts is critical for real-world applications. Prior approaches fine-tune a pre-trained backbone and risk overfitting it to in-distribution (ID) data and distorting features useful for out-of-distribution (OOD) generalization. We propose to use Relative Gradient Norm (RGN) as a way to measure the vulnerability of a backbone to feature distortion, and show that high RGN is indeed correlated with lower OOD performance. Our analysis of RGN yields interesting findings: some backbones lose OOD robustness during fine-tuning, but others gain robustness because their architecture prevents the parameters from changing too much from the initial model.
Given these findings, we present recipes to boost OOD robustness for both types of backbones. Specifically, we investigate regularization and architectural choices for minimizing gradient updates so as to prevent the tuned backbone from losing generalizable features. Our proposed techniques complement each other and show substantial improvements over baselines on diverse architectures and datasets.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Fine-tuning a large-scale pre-trained vision model has become the defacto transfer learning paradigm that significantly improves performance on diverse downstream tasks compared to training from scratch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. Although naive fine-tuning performs well on the downstream task’s training distribution (in-distribution; ID), it has subpar performance on data unseen during training (out-of-distribution; OOD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
Kumar <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S1.p1.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> suggest that fine-tuning without unnecessarily distorting the pre-trained backbone is the key to achieving high performance in both ID and OOD. They show that “linear warm-up” training, <em id="S1.p1.1.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.p1.1.4" class="ltx_text"></span> training a linear head first while freezing the backbone before fine-tuning all layers, is effective for robust image classification.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2303.14744/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="398" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.9.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.10.2" class="ltx_text" style="font-size:90%;">Top: The standard fine-tuning approach in object detection can cause overfitting to ID and hurt the performance on OOD data (<span id="S1.F1.10.2.1" class="ltx_text" style="color:#FF8000;">Orange</span> dot with <span id="S1.F1.10.2.2" class="ltx_text ltx_font_bold">Plain Tuning</span>) or achieve minimal improvements (<span id="S1.F1.10.2.3" class="ltx_text" style="color:#0000FF;">Blue</span> dot with <span id="S1.F1.10.2.4" class="ltx_text ltx_font_bold">Plain Tuning</span>) depending on the network architecture. Based on a thorough analysis, we propose a new fine-tuning recipe that can achieve good performance on both ID and OOD performance for diverse pre-trained backbones (<span id="S1.F1.10.2.5" class="ltx_text" style="color:#0000FF;">Blue</span> and <span id="S1.F1.10.2.6" class="ltx_text" style="color:#FF8000;">Orange</span> dots with <span id="S1.F1.10.2.7" class="ltx_text ltx_font_bold">Our Tuning</span>). Results are on Pascal <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, see Table <a href="#S5.T4" title="Table 4 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Bottom: We visualize detected results in Foggy Cityscape.
</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Inspired by this, we explore the effect of backbone distortion during fine-tuning in object detection. Although there exist generalizable detection approaches that use data augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, feature augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, or advanced objectives <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, our work is the first to ask whether biasing toward the initial model is effective for this task.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">We study an equivalent of “linear warm-up” training for object detection. Specifically, we first train the decoder (all detector modules except for the backbone) while keeping the backbone frozen, which we refer to as <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">Decoder-Probing (DP)</span>. After DP, we perform full fine-tuning of the detector (including the backbone), which we call <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">Decoder-Probing Fine-Tuning (DP-FT)</span>. Surprisingly, we observe that the improvement in OOD performance of DP-FT over DP depends on the architecture of the backbone.
To analyze this phenomenon, we investigate the relationship between performance improvement from fine-tuning and the amount of gradient in each parameter. Specifically, two detectors are compared for each backbone to compute the performance change after tuning the backbone: (1) a DP model and (2) fine-tuning all modules (FT). We then compute the ratio of gradient norm to parameter norm, i.e., <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">Relative Gradient Norm (RGN)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, calculated on the training (in-distribution) data using DP. Intuitively, RGN indicates how much updating feature extractors require to fit ID data. We measure RGN’s correlation with the performance improvement on OOD relative to that on ID.
Our novel findings are three-fold: (1) a model with small RGN is more likely to improve performance on both OOD and ID data after fine-tuning, (2) RGN depends on the network architecture, (3) in particular, some modules such as squeeze excitation (SE) blocks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> can reduce the gradient, thus lowering RGN and improving both OOD and ID performance after fine-tuning.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Based on these findings, we explore two techniques to preserve the generalizability of a diverse set of pre-trained models (see Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
The first is a regularizer that minimizes the distance from the initial model in the parameter space to prevent feature distortion. The backbone is constrained to find a point performing well on ID, yet not too far away from the initial model. This simple regularization effectively boosts OOD performance for diverse architectures, yet is overlooked in generalizable object detection. Second, we study the effect of the decoder’s architecture and training iterations on decreasing the RGN of the backbone. A decoder producing a lower RGN tends to train a detector more generalizable to OOD. Specifically, inserting an SE-Block into the backbone significantly decreases RGN.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Our contributions can be summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We reveal a novel finding that some backbones lose more OOD robustness after fine-tuning than others. At the same time, some backbones can significantly increase robustness due to an architecture that prevents the parameters from being too far away from the initial model, such as having an SE-Block.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We present methods to boost OOD robustness for both types of backbones. Specifically, weight regularization and decoder design are investigated, and the two techniques are shown to complement each other.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Our methods show substantial improvements over baselines when evaluating on diverse architectures and object detection datasets.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Domain Generalization in Image classification.</span>
Robust fine-tuning, namely, adapting a pre-trained model to a downstream task without losing generalization to unseen domains, has been popular in recent work. Gulrajani <em id="S2.p1.1.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p1.1.3" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> find that simple ERM, <em id="S2.p1.1.4" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S2.p1.1.5" class="ltx_text"></span> fine-tuning on source with well-tuned hyperparameters, shows strong generalization. Kim <em id="S2.p1.1.6" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p1.1.7" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and Angarano <em id="S2.p1.1.8" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p1.1.9" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> show that larger models have stronger OOD performance. Kumar <em id="S2.p1.1.10" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p1.1.11" class="ltx_text"></span> propose warm-up with a linear head <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, while Wortsman <em id="S2.p1.1.12" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p1.1.13" class="ltx_text"></span> propose to interpolate the weights of a fine-tuned and a zero-shot model to produce a single robust model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. This technique is extended to ensemble diverse models trained from the same initialization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, and to ensemble several checkpoints from one training trajectory <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Regularizing the change w.r.t the pre-trained model’s features is another promising way to tackle the problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
Surgical fine-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> changes only a subset of layers to adapt a model to a downstream task. Their goal is to improve the performance on the downstream task given a small number of training data. They find that tuning a block with a large RGN achieves high performance on the downstream task. In contrast, our findings suggest that large RGN can indicate the risk of overfitting the training data.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<div id="S2.T1.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:518.3pt;height:177.4pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-5.3pt,1.8pt) scale(0.98,0.98) ;">
<table id="S2.T1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.2.1.1" class="ltx_tr">
<td id="S2.T1.2.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Backbone</td>
<td id="S2.T1.2.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Tuning</td>
<td id="S2.T1.2.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Comic</td>
<td id="S2.T1.2.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Water</td>
<td id="S2.T1.2.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Clipart</td>
<td id="S2.T1.2.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">ID: Pascal</td>
</tr>
<tr id="S2.T1.2.1.2" class="ltx_tr">
<td id="S2.T1.2.1.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="3"><span id="S2.T1.2.1.2.1.1" class="ltx_text">ResNet50 Instagram <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span></td>
<td id="S2.T1.2.1.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">DP</td>
<td id="S2.T1.2.1.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15.7</td>
<td id="S2.T1.2.1.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.2</td>
<td id="S2.T1.2.1.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15.3</td>
<td id="S2.T1.2.1.2.6" class="ltx_td ltx_align_left ltx_border_t">44.6</td>
</tr>
<tr id="S2.T1.2.1.3" class="ltx_tr">
<td id="S2.T1.2.1.3.1" class="ltx_td ltx_align_left ltx_border_r">FT</td>
<td id="S2.T1.2.1.3.2" class="ltx_td ltx_align_left ltx_border_r">7.5 (<span id="S2.T1.2.1.3.2.1" class="ltx_text" style="color:#FF0000;">-8.2</span>)</td>
<td id="S2.T1.2.1.3.3" class="ltx_td ltx_align_left ltx_border_r">19.4 (<span id="S2.T1.2.1.3.3.1" class="ltx_text" style="color:#FF0000;">-1.8</span>)</td>
<td id="S2.T1.2.1.3.4" class="ltx_td ltx_align_left ltx_border_r">11.4 (<span id="S2.T1.2.1.3.4.1" class="ltx_text" style="color:#FF0000;">-3.9</span>)</td>
<td id="S2.T1.2.1.3.5" class="ltx_td ltx_align_left">50.4 (<span id="S2.T1.2.1.3.5.1" class="ltx_text" style="color:#0000FF;">+5.8</span>)</td>
</tr>
<tr id="S2.T1.2.1.4" class="ltx_tr">
<td id="S2.T1.2.1.4.1" class="ltx_td ltx_align_left ltx_border_r">DP-FT</td>
<td id="S2.T1.2.1.4.2" class="ltx_td ltx_align_left ltx_border_r">9.1 (<span id="S2.T1.2.1.4.2.1" class="ltx_text" style="color:#FF0000;">-6.6</span>)</td>
<td id="S2.T1.2.1.4.3" class="ltx_td ltx_align_left ltx_border_r">21.0 (<span id="S2.T1.2.1.4.3.1" class="ltx_text" style="color:#FF0000;">-0.2</span>)</td>
<td id="S2.T1.2.1.4.4" class="ltx_td ltx_align_left ltx_border_r">12.9 (<span id="S2.T1.2.1.4.4.1" class="ltx_text" style="color:#FF0000;">-2.4</span>)</td>
<td id="S2.T1.2.1.4.5" class="ltx_td ltx_align_left">52.6 (<span id="S2.T1.2.1.4.5.1" class="ltx_text" style="color:#0000FF;">+8.0</span>)</td>
</tr>
<tr id="S2.T1.2.1.5" class="ltx_tr">
<td id="S2.T1.2.1.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="3"><span id="S2.T1.2.1.5.1.1" class="ltx_text">EfficientNet-B2 JFT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite></span></td>
<td id="S2.T1.2.1.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">DP</td>
<td id="S2.T1.2.1.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12.6</td>
<td id="S2.T1.2.1.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20.4</td>
<td id="S2.T1.2.1.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15.1</td>
<td id="S2.T1.2.1.5.6" class="ltx_td ltx_align_left ltx_border_t">40.2</td>
</tr>
<tr id="S2.T1.2.1.6" class="ltx_tr">
<td id="S2.T1.2.1.6.1" class="ltx_td ltx_align_left ltx_border_r">FT</td>
<td id="S2.T1.2.1.6.2" class="ltx_td ltx_align_left ltx_border_r">17.1 (<span id="S2.T1.2.1.6.2.1" class="ltx_text" style="color:#0000FF;">+4.5</span>)</td>
<td id="S2.T1.2.1.6.3" class="ltx_td ltx_align_left ltx_border_r">27.2 (<span id="S2.T1.2.1.6.3.1" class="ltx_text" style="color:#0000FF;">+6.8</span>)</td>
<td id="S2.T1.2.1.6.4" class="ltx_td ltx_align_left ltx_border_r">18.0 (<span id="S2.T1.2.1.6.4.1" class="ltx_text" style="color:#0000FF;">+2.9</span>)</td>
<td id="S2.T1.2.1.6.5" class="ltx_td ltx_align_left">53.4 (<span id="S2.T1.2.1.6.5.1" class="ltx_text" style="color:#0000FF;">+13.2</span>)</td>
</tr>
<tr id="S2.T1.2.1.7" class="ltx_tr">
<td id="S2.T1.2.1.7.1" class="ltx_td ltx_align_left ltx_border_r">DP-FT</td>
<td id="S2.T1.2.1.7.2" class="ltx_td ltx_align_left ltx_border_r">17.4 (<span id="S2.T1.2.1.7.2.1" class="ltx_text" style="color:#0000FF;">+4.7</span>))</td>
<td id="S2.T1.2.1.7.3" class="ltx_td ltx_align_left ltx_border_r">29.4 (<span id="S2.T1.2.1.7.3.1" class="ltx_text" style="color:#0000FF;">+9.0</span>)</td>
<td id="S2.T1.2.1.7.4" class="ltx_td ltx_align_left ltx_border_r">20.7 (<span id="S2.T1.2.1.7.4.1" class="ltx_text" style="color:#0000FF;">+5.6</span>)</td>
<td id="S2.T1.2.1.7.5" class="ltx_td ltx_align_left">55.3 (<span id="S2.T1.2.1.7.5.1" class="ltx_text" style="color:#0000FF;">+15.1</span>)</td>
</tr>
<tr id="S2.T1.2.1.8" class="ltx_tr">
<td id="S2.T1.2.1.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" rowspan="3"><span id="S2.T1.2.1.8.1.1" class="ltx_text">ConvNeXt Base IN21K <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite></span></td>
<td id="S2.T1.2.1.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">DP</td>
<td id="S2.T1.2.1.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">11.7</td>
<td id="S2.T1.2.1.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">17.3</td>
<td id="S2.T1.2.1.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">14.0</td>
<td id="S2.T1.2.1.8.6" class="ltx_td ltx_align_left ltx_border_t">39.7</td>
</tr>
<tr id="S2.T1.2.1.9" class="ltx_tr">
<td id="S2.T1.2.1.9.1" class="ltx_td ltx_align_left ltx_border_r">FT</td>
<td id="S2.T1.2.1.9.2" class="ltx_td ltx_align_left ltx_border_r">11.5 (<span id="S2.T1.2.1.9.2.1" class="ltx_text" style="color:#FF0000;">-0.2</span>)</td>
<td id="S2.T1.2.1.9.3" class="ltx_td ltx_align_left ltx_border_r">22.9 (<span id="S2.T1.2.1.9.3.1" class="ltx_text" style="color:#0000FF;">+5.6</span>)</td>
<td id="S2.T1.2.1.9.4" class="ltx_td ltx_align_left ltx_border_r">16.8 (<span id="S2.T1.2.1.9.4.1" class="ltx_text" style="color:#0000FF;">+2.8</span>)</td>
<td id="S2.T1.2.1.9.5" class="ltx_td ltx_align_left">60.6 (<span id="S2.T1.2.1.9.5.1" class="ltx_text" style="color:#0000FF;">+20.9</span>)</td>
</tr>
<tr id="S2.T1.2.1.10" class="ltx_tr">
<td id="S2.T1.2.1.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">DP-FT</td>
<td id="S2.T1.2.1.10.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">13.6 (<span id="S2.T1.2.1.10.2.1" class="ltx_text" style="color:#0000FF;">+2.9</span>)</td>
<td id="S2.T1.2.1.10.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">24.7 (<span id="S2.T1.2.1.10.3.1" class="ltx_text" style="color:#0000FF;">+7.4</span>)</td>
<td id="S2.T1.2.1.10.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">19.1 (<span id="S2.T1.2.1.10.4.1" class="ltx_text" style="color:#0000FF;">+5.1</span>)</td>
<td id="S2.T1.2.1.10.5" class="ltx_td ltx_align_left ltx_border_bb">62.3 (<span id="S2.T1.2.1.10.5.1" class="ltx_text" style="color:#0000FF;">+22.6</span>)</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.4.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.5.2" class="ltx_text" style="font-size:90%;">Analysis of DP (Detector Probing, <em id="S2.T1.5.2.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S2.T1.5.2.2" class="ltx_text"></span> tuning only the decoder, freezing backbone), FT (Fine-Tuning all modules), and DP-FT (tuning all layers after DP training) on the three OOD domains and ID (training) domain. Interestingly, EfficientNet-B2 FT improves OOD performance over DP while ResNet50 FT degrades OOD performance. Overall, DP-FT improves performance over FT. </span></figcaption>
</figure>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Data Augmentation.</span>
Data augmentation effectively expands the training domain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> <em id="S2.p2.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S2.p2.1.3" class="ltx_text"></span>, Augmix <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> exploits diverse synthetic data augmentation, and augmentation with style transfer can further diversify training images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. Our experiments show that the backbone can lose generalization even with augmentation, needing regularization to maintain OOD robustness.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Domain Generalization in Object detection.</span>
Wang <em id="S2.p3.1.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p3.1.3" class="ltx_text"></span> employ temporal frames to ensure the consistency of features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Normalization perturbation (NP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, concurrent with our work, uses style randomization in feature space. Det-AdvProp <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> combines adversarial and clean examples to train a model. The settings of NP and Det-AdvProp are comparable to ours, but we do not compare against their approaches since they do not publish code to train models. Instead, we show the compatibility of our approach with data augmentation. This indicates the potential compatibility with their methods, which use data augmentation for training.
There exist multiple source generalizable object detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, but we tackle a single-source scenario with no domain labels. Vasconcelos <em id="S2.p3.1.4" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p3.1.5" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> demonstrate that training only a strong decoder on top of a frozen backbone can improve detection models. They focus on evaluating the model on ID, but we inspect the effectiveness of OOD generalization and fine-tuning the backbone.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Continual Learning.</span>
Our study connects with early work on continual learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> in considering the distance from a pre-trained model in weight space. They find that elastic weight consolidation (EWC), which accounts for the importance of each weight on the older task, is useful for maintaining performance on older tasks. Mirzadeh <em id="S2.p4.1.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p4.1.3" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> show that wider neural networks forget less and have sparser gradient updates.
Xuhong <em id="S2.p4.1.4" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p4.1.5" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> inspect fine-tuning for retaining the features learned on the source task, compare several regularization methods including EWC, and observe that a simple L2 penalty on the pre-trained model mitigates overfitting well, which we also observe in experiments (see appendix for more details).
Wortsman <em id="S2.p4.1.6" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p4.1.7" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> also use the L2 penalty as a baseline in an image classification task but the penalty is not explored in object detection. We highlight that we are the first to show that weight regularization is an overlooked, yet powerful tool for keeping OOD performance in object detection.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2303.14744/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="242" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">RGN of three DP models on Pascal.<span id="S2.F2.4.2.1" class="ltx_text ltx_font_medium"> The depth is normalized by the total number of layers. Interestingly, RGN values differ a lot by models (legend shows RGN averaged over layers). ResNet50 has a large RGN in all layers, while EfficientNet has a very small RGN in all layers, which seems to support the generalization in OOD.</span></span></figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Analysis of Feature Distortion</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we aim to answer three questions; (1) how the model’s distortion can be quantified, (2) the correlation between OOD performance and the distortion, and (3) whether the distortion depends on the backbone architecture.
We start by analyzing three tuning strategies; (1) a decoder-probing (DP) model, which freezes the feature extractor while training the remaining detector modules, <em id="S3.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.p1.1.2" class="ltx_text"></span>, decoder, (2) fine-tuning (FT) model, which tunes both the extractor and detector, (3) a decoder-probing before fine-tuning (DP-FT), which applies DP training before FT.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Set-up.</span>
We use the Faster R-CNN model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> with a feature pyramid network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> as our detector since it is the typical detector architecture. We regard the pyramid modules and detector head as the decoder, wherein only the decoder is trained for a DP model. We follow the protocol of detectron2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> for hyper-parameter selection, <em id="S3.p2.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.p2.1.3" class="ltx_text"></span>, the shallow CNN layers (stages 1 and 2) and all BatchNorm parameters are frozen by the default setting of the library. DP and FT train for the same number of iterations, DP-FT initializes the decoder with the DP model and trains both decoder and backbone as in FT training.
Backbones are chosen mainly from models pre-trained with large-scale data such as Instagram <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, JFT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, and ImageNet21K <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> (IN21K) since our primary goal is the investigation of robust models.
We utilize Pascal <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> (16,551 training images) or Cityscapes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> (2,965 training images) as training data. We employ watercolor, comic, and clipart <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> as OOD in Pascal, FoggyCityscapes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> and BDD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> as OOD in Cityscapes.
We focus on the setting where the training data is not very large as this is the case in many applications.
We employ the mean Average Precision (mAP) used in COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> as the evaluation metric.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.14744/assets/x3.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">Comic: -0.78 (mAP 10.3)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.14744/assets/x4.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">Clipart: -0.48 (mAP 14.8)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.14744/assets/x5.png" id="S3.F3.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F3.sf3.3.2" class="ltx_text" style="font-size:90%;">Watercolor: -0.23 (mAP 22.0)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.14744/assets/x6.png" id="S3.F3.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F3.sf4.3.2" class="ltx_text" style="font-size:90%;">BDD: -0.73 (mAP 5.9)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F3.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.14744/assets/x7.png" id="S3.F3.sf5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S3.F3.sf5.3.2" class="ltx_text" style="font-size:90%;">Foggy: -0.60 (mAP 10.9)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F3.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.14744/assets/x8.png" id="S3.F3.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="191" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text" style="font-size:90%;">A negative correlation exists between RGN and performance improvement in OOD over ID by fine-tuning. RGN (x-axis) indicates whether the network will degrade performance on OOD by fine-tuning. Y-axis indicates the ratio of mAP improvement in OOD to the improvement in ID by fine-tuning.</span></figcaption>
</figure>
<div id="S3.p3" class="ltx_para ltx_noindent">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">The performance improvement by DP-FT depends on the architecture.</span>
First, we conduct experiments to see the effect of DP-FT in Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Work ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Interestingly, the performance improvement over DP depends on the pre-trained models. EfficientNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> improves both OOD and ID performance by fine-tuning feature extractor, but ResNet50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> significantly degrades OOD performance. Also, DP-FT improves performance compared to FT but still underperforms DP in OOD for ResNet50. Overall, ConvNeXt improves OOD performance, but the gain is marginal, considering its high performance on ID. Prior work on image classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> only reports that naive fine-tuning tends to decrease OOD generalization. Our novel finding is that the performance decrease or increase depends on the architecture of the pre-trained models.</p>
</div>
<div id="S3.p4" class="ltx_para ltx_noindent">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">Relative Gradient Norm differs by architectures.</span>
The analysis above motivates us to study the factors that improve OOD performance with simple fine-tuning.
From the insight on linear-warm-up training for image classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, if the amount of updates, <em id="S3.p4.1.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.p4.1.3" class="ltx_text"></span>, model distortion, by fine-tuning is large, the model will likely lose generalization on OOD. To quantify the model distortion, we compute the variant of the ratio of gradient norm to parameter norm (RGN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.7" class="ltx_p">Let <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="\mathbf{W}\in\mathbb{R}^{C_{i}\times C_{o}\times F}" display="inline"><semantics id="S3.p5.1.m1.1a"><mrow id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml"><mi id="S3.p5.1.m1.1.1.2" xref="S3.p5.1.m1.1.1.2.cmml">𝐖</mi><mo id="S3.p5.1.m1.1.1.1" xref="S3.p5.1.m1.1.1.1.cmml">∈</mo><msup id="S3.p5.1.m1.1.1.3" xref="S3.p5.1.m1.1.1.3.cmml"><mi id="S3.p5.1.m1.1.1.3.2" xref="S3.p5.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.p5.1.m1.1.1.3.3" xref="S3.p5.1.m1.1.1.3.3.cmml"><msub id="S3.p5.1.m1.1.1.3.3.2" xref="S3.p5.1.m1.1.1.3.3.2.cmml"><mi id="S3.p5.1.m1.1.1.3.3.2.2" xref="S3.p5.1.m1.1.1.3.3.2.2.cmml">C</mi><mi id="S3.p5.1.m1.1.1.3.3.2.3" xref="S3.p5.1.m1.1.1.3.3.2.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.p5.1.m1.1.1.3.3.1" xref="S3.p5.1.m1.1.1.3.3.1.cmml">×</mo><msub id="S3.p5.1.m1.1.1.3.3.3" xref="S3.p5.1.m1.1.1.3.3.3.cmml"><mi id="S3.p5.1.m1.1.1.3.3.3.2" xref="S3.p5.1.m1.1.1.3.3.3.2.cmml">C</mi><mi id="S3.p5.1.m1.1.1.3.3.3.3" xref="S3.p5.1.m1.1.1.3.3.3.3.cmml">o</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.p5.1.m1.1.1.3.3.1a" xref="S3.p5.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.p5.1.m1.1.1.3.3.4" xref="S3.p5.1.m1.1.1.3.3.4.cmml">F</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><apply id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1"><in id="S3.p5.1.m1.1.1.1.cmml" xref="S3.p5.1.m1.1.1.1"></in><ci id="S3.p5.1.m1.1.1.2.cmml" xref="S3.p5.1.m1.1.1.2">𝐖</ci><apply id="S3.p5.1.m1.1.1.3.cmml" xref="S3.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p5.1.m1.1.1.3.1.cmml" xref="S3.p5.1.m1.1.1.3">superscript</csymbol><ci id="S3.p5.1.m1.1.1.3.2.cmml" xref="S3.p5.1.m1.1.1.3.2">ℝ</ci><apply id="S3.p5.1.m1.1.1.3.3.cmml" xref="S3.p5.1.m1.1.1.3.3"><times id="S3.p5.1.m1.1.1.3.3.1.cmml" xref="S3.p5.1.m1.1.1.3.3.1"></times><apply id="S3.p5.1.m1.1.1.3.3.2.cmml" xref="S3.p5.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.p5.1.m1.1.1.3.3.2.1.cmml" xref="S3.p5.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.p5.1.m1.1.1.3.3.2.2.cmml" xref="S3.p5.1.m1.1.1.3.3.2.2">𝐶</ci><ci id="S3.p5.1.m1.1.1.3.3.2.3.cmml" xref="S3.p5.1.m1.1.1.3.3.2.3">𝑖</ci></apply><apply id="S3.p5.1.m1.1.1.3.3.3.cmml" xref="S3.p5.1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.p5.1.m1.1.1.3.3.3.1.cmml" xref="S3.p5.1.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.p5.1.m1.1.1.3.3.3.2.cmml" xref="S3.p5.1.m1.1.1.3.3.3.2">𝐶</ci><ci id="S3.p5.1.m1.1.1.3.3.3.3.cmml" xref="S3.p5.1.m1.1.1.3.3.3.3">𝑜</ci></apply><ci id="S3.p5.1.m1.1.1.3.3.4.cmml" xref="S3.p5.1.m1.1.1.3.3.4">𝐹</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">\mathbf{W}\in\mathbb{R}^{C_{i}\times C_{o}\times F}</annotation></semantics></math> denote a weight parameter in a convolution layer, where <math id="S3.p5.2.m2.3" class="ltx_Math" alttext="C_{i},C_{o},F" display="inline"><semantics id="S3.p5.2.m2.3a"><mrow id="S3.p5.2.m2.3.3.2" xref="S3.p5.2.m2.3.3.3.cmml"><msub id="S3.p5.2.m2.2.2.1.1" xref="S3.p5.2.m2.2.2.1.1.cmml"><mi id="S3.p5.2.m2.2.2.1.1.2" xref="S3.p5.2.m2.2.2.1.1.2.cmml">C</mi><mi id="S3.p5.2.m2.2.2.1.1.3" xref="S3.p5.2.m2.2.2.1.1.3.cmml">i</mi></msub><mo id="S3.p5.2.m2.3.3.2.3" xref="S3.p5.2.m2.3.3.3.cmml">,</mo><msub id="S3.p5.2.m2.3.3.2.2" xref="S3.p5.2.m2.3.3.2.2.cmml"><mi id="S3.p5.2.m2.3.3.2.2.2" xref="S3.p5.2.m2.3.3.2.2.2.cmml">C</mi><mi id="S3.p5.2.m2.3.3.2.2.3" xref="S3.p5.2.m2.3.3.2.2.3.cmml">o</mi></msub><mo id="S3.p5.2.m2.3.3.2.4" xref="S3.p5.2.m2.3.3.3.cmml">,</mo><mi id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml">F</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.3b"><list id="S3.p5.2.m2.3.3.3.cmml" xref="S3.p5.2.m2.3.3.2"><apply id="S3.p5.2.m2.2.2.1.1.cmml" xref="S3.p5.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.p5.2.m2.2.2.1.1.1.cmml" xref="S3.p5.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.p5.2.m2.2.2.1.1.2.cmml" xref="S3.p5.2.m2.2.2.1.1.2">𝐶</ci><ci id="S3.p5.2.m2.2.2.1.1.3.cmml" xref="S3.p5.2.m2.2.2.1.1.3">𝑖</ci></apply><apply id="S3.p5.2.m2.3.3.2.2.cmml" xref="S3.p5.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.p5.2.m2.3.3.2.2.1.cmml" xref="S3.p5.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.p5.2.m2.3.3.2.2.2.cmml" xref="S3.p5.2.m2.3.3.2.2.2">𝐶</ci><ci id="S3.p5.2.m2.3.3.2.2.3.cmml" xref="S3.p5.2.m2.3.3.2.2.3">𝑜</ci></apply><ci id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1">𝐹</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.3c">C_{i},C_{o},F</annotation></semantics></math> denote input, output channel size, and the kernel size of filters.
Since we are interested in the scale of updates per each filter, we take summation within each filter to compute RGN in layer <math id="S3.p5.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.p5.3.m3.1a"><mi id="S3.p5.3.m3.1.1" xref="S3.p5.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.p5.3.m3.1b"><ci id="S3.p5.3.m3.1.1.cmml" xref="S3.p5.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.3.m3.1c">L</annotation></semantics></math>, <math id="S3.p5.4.m4.2" class="ltx_Math" alttext="\mathbf{RGN}^{L}_{ij}=\frac{\sum_{k}|\nabla{\mathbf{W}_{ijk}}|}{\sum_{k}|\mathbf{W}_{ijk}|}" display="inline"><semantics id="S3.p5.4.m4.2a"><mrow id="S3.p5.4.m4.2.3" xref="S3.p5.4.m4.2.3.cmml"><msubsup id="S3.p5.4.m4.2.3.2" xref="S3.p5.4.m4.2.3.2.cmml"><mi id="S3.p5.4.m4.2.3.2.2.2" xref="S3.p5.4.m4.2.3.2.2.2.cmml">𝐑𝐆𝐍</mi><mrow id="S3.p5.4.m4.2.3.2.3" xref="S3.p5.4.m4.2.3.2.3.cmml"><mi id="S3.p5.4.m4.2.3.2.3.2" xref="S3.p5.4.m4.2.3.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p5.4.m4.2.3.2.3.1" xref="S3.p5.4.m4.2.3.2.3.1.cmml">​</mo><mi id="S3.p5.4.m4.2.3.2.3.3" xref="S3.p5.4.m4.2.3.2.3.3.cmml">j</mi></mrow><mi id="S3.p5.4.m4.2.3.2.2.3" xref="S3.p5.4.m4.2.3.2.2.3.cmml">L</mi></msubsup><mo id="S3.p5.4.m4.2.3.1" xref="S3.p5.4.m4.2.3.1.cmml">=</mo><mfrac id="S3.p5.4.m4.2.2" xref="S3.p5.4.m4.2.2.cmml"><mrow id="S3.p5.4.m4.1.1.1" xref="S3.p5.4.m4.1.1.1.cmml"><mstyle displaystyle="false" id="S3.p5.4.m4.1.1.1.2" xref="S3.p5.4.m4.1.1.1.2.cmml"><msub id="S3.p5.4.m4.1.1.1.2a" xref="S3.p5.4.m4.1.1.1.2.cmml"><mo id="S3.p5.4.m4.1.1.1.2.2" xref="S3.p5.4.m4.1.1.1.2.2.cmml">∑</mo><mi id="S3.p5.4.m4.1.1.1.2.3" xref="S3.p5.4.m4.1.1.1.2.3.cmml">k</mi></msub></mstyle><mrow id="S3.p5.4.m4.1.1.1.1.1" xref="S3.p5.4.m4.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p5.4.m4.1.1.1.1.1.2" xref="S3.p5.4.m4.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.p5.4.m4.1.1.1.1.1.1" xref="S3.p5.4.m4.1.1.1.1.1.1.cmml"><mo rspace="0.167em" id="S3.p5.4.m4.1.1.1.1.1.1.1" xref="S3.p5.4.m4.1.1.1.1.1.1.1.cmml">∇</mo><msub id="S3.p5.4.m4.1.1.1.1.1.1.2" xref="S3.p5.4.m4.1.1.1.1.1.1.2.cmml"><mi id="S3.p5.4.m4.1.1.1.1.1.1.2.2" xref="S3.p5.4.m4.1.1.1.1.1.1.2.2.cmml">𝐖</mi><mrow id="S3.p5.4.m4.1.1.1.1.1.1.2.3" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.cmml"><mi id="S3.p5.4.m4.1.1.1.1.1.1.2.3.2" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p5.4.m4.1.1.1.1.1.1.2.3.1" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.p5.4.m4.1.1.1.1.1.1.2.3.3" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.3.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.p5.4.m4.1.1.1.1.1.1.2.3.1a" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.p5.4.m4.1.1.1.1.1.1.2.3.4" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.4.cmml">k</mi></mrow></msub></mrow><mo stretchy="false" id="S3.p5.4.m4.1.1.1.1.1.3" xref="S3.p5.4.m4.1.1.1.1.2.1.cmml">|</mo></mrow></mrow><mrow id="S3.p5.4.m4.2.2.2" xref="S3.p5.4.m4.2.2.2.cmml"><mstyle displaystyle="false" id="S3.p5.4.m4.2.2.2.2" xref="S3.p5.4.m4.2.2.2.2.cmml"><msub id="S3.p5.4.m4.2.2.2.2a" xref="S3.p5.4.m4.2.2.2.2.cmml"><mo id="S3.p5.4.m4.2.2.2.2.2" xref="S3.p5.4.m4.2.2.2.2.2.cmml">∑</mo><mi id="S3.p5.4.m4.2.2.2.2.3" xref="S3.p5.4.m4.2.2.2.2.3.cmml">k</mi></msub></mstyle><mrow id="S3.p5.4.m4.2.2.2.1.1" xref="S3.p5.4.m4.2.2.2.1.2.cmml"><mo stretchy="false" id="S3.p5.4.m4.2.2.2.1.1.2" xref="S3.p5.4.m4.2.2.2.1.2.1.cmml">|</mo><msub id="S3.p5.4.m4.2.2.2.1.1.1" xref="S3.p5.4.m4.2.2.2.1.1.1.cmml"><mi id="S3.p5.4.m4.2.2.2.1.1.1.2" xref="S3.p5.4.m4.2.2.2.1.1.1.2.cmml">𝐖</mi><mrow id="S3.p5.4.m4.2.2.2.1.1.1.3" xref="S3.p5.4.m4.2.2.2.1.1.1.3.cmml"><mi id="S3.p5.4.m4.2.2.2.1.1.1.3.2" xref="S3.p5.4.m4.2.2.2.1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p5.4.m4.2.2.2.1.1.1.3.1" xref="S3.p5.4.m4.2.2.2.1.1.1.3.1.cmml">​</mo><mi id="S3.p5.4.m4.2.2.2.1.1.1.3.3" xref="S3.p5.4.m4.2.2.2.1.1.1.3.3.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.p5.4.m4.2.2.2.1.1.1.3.1a" xref="S3.p5.4.m4.2.2.2.1.1.1.3.1.cmml">​</mo><mi id="S3.p5.4.m4.2.2.2.1.1.1.3.4" xref="S3.p5.4.m4.2.2.2.1.1.1.3.4.cmml">k</mi></mrow></msub><mo stretchy="false" id="S3.p5.4.m4.2.2.2.1.1.3" xref="S3.p5.4.m4.2.2.2.1.2.1.cmml">|</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.4.m4.2b"><apply id="S3.p5.4.m4.2.3.cmml" xref="S3.p5.4.m4.2.3"><eq id="S3.p5.4.m4.2.3.1.cmml" xref="S3.p5.4.m4.2.3.1"></eq><apply id="S3.p5.4.m4.2.3.2.cmml" xref="S3.p5.4.m4.2.3.2"><csymbol cd="ambiguous" id="S3.p5.4.m4.2.3.2.1.cmml" xref="S3.p5.4.m4.2.3.2">subscript</csymbol><apply id="S3.p5.4.m4.2.3.2.2.cmml" xref="S3.p5.4.m4.2.3.2"><csymbol cd="ambiguous" id="S3.p5.4.m4.2.3.2.2.1.cmml" xref="S3.p5.4.m4.2.3.2">superscript</csymbol><ci id="S3.p5.4.m4.2.3.2.2.2.cmml" xref="S3.p5.4.m4.2.3.2.2.2">𝐑𝐆𝐍</ci><ci id="S3.p5.4.m4.2.3.2.2.3.cmml" xref="S3.p5.4.m4.2.3.2.2.3">𝐿</ci></apply><apply id="S3.p5.4.m4.2.3.2.3.cmml" xref="S3.p5.4.m4.2.3.2.3"><times id="S3.p5.4.m4.2.3.2.3.1.cmml" xref="S3.p5.4.m4.2.3.2.3.1"></times><ci id="S3.p5.4.m4.2.3.2.3.2.cmml" xref="S3.p5.4.m4.2.3.2.3.2">𝑖</ci><ci id="S3.p5.4.m4.2.3.2.3.3.cmml" xref="S3.p5.4.m4.2.3.2.3.3">𝑗</ci></apply></apply><apply id="S3.p5.4.m4.2.2.cmml" xref="S3.p5.4.m4.2.2"><divide id="S3.p5.4.m4.2.2.3.cmml" xref="S3.p5.4.m4.2.2"></divide><apply id="S3.p5.4.m4.1.1.1.cmml" xref="S3.p5.4.m4.1.1.1"><apply id="S3.p5.4.m4.1.1.1.2.cmml" xref="S3.p5.4.m4.1.1.1.2"><csymbol cd="ambiguous" id="S3.p5.4.m4.1.1.1.2.1.cmml" xref="S3.p5.4.m4.1.1.1.2">subscript</csymbol><sum id="S3.p5.4.m4.1.1.1.2.2.cmml" xref="S3.p5.4.m4.1.1.1.2.2"></sum><ci id="S3.p5.4.m4.1.1.1.2.3.cmml" xref="S3.p5.4.m4.1.1.1.2.3">𝑘</ci></apply><apply id="S3.p5.4.m4.1.1.1.1.2.cmml" xref="S3.p5.4.m4.1.1.1.1.1"><abs id="S3.p5.4.m4.1.1.1.1.2.1.cmml" xref="S3.p5.4.m4.1.1.1.1.1.2"></abs><apply id="S3.p5.4.m4.1.1.1.1.1.1.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1"><ci id="S3.p5.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1.1">∇</ci><apply id="S3.p5.4.m4.1.1.1.1.1.1.2.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.p5.4.m4.1.1.1.1.1.1.2.1.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.p5.4.m4.1.1.1.1.1.1.2.2.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1.2.2">𝐖</ci><apply id="S3.p5.4.m4.1.1.1.1.1.1.2.3.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3"><times id="S3.p5.4.m4.1.1.1.1.1.1.2.3.1.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.1"></times><ci id="S3.p5.4.m4.1.1.1.1.1.1.2.3.2.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.2">𝑖</ci><ci id="S3.p5.4.m4.1.1.1.1.1.1.2.3.3.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.3">𝑗</ci><ci id="S3.p5.4.m4.1.1.1.1.1.1.2.3.4.cmml" xref="S3.p5.4.m4.1.1.1.1.1.1.2.3.4">𝑘</ci></apply></apply></apply></apply></apply><apply id="S3.p5.4.m4.2.2.2.cmml" xref="S3.p5.4.m4.2.2.2"><apply id="S3.p5.4.m4.2.2.2.2.cmml" xref="S3.p5.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.p5.4.m4.2.2.2.2.1.cmml" xref="S3.p5.4.m4.2.2.2.2">subscript</csymbol><sum id="S3.p5.4.m4.2.2.2.2.2.cmml" xref="S3.p5.4.m4.2.2.2.2.2"></sum><ci id="S3.p5.4.m4.2.2.2.2.3.cmml" xref="S3.p5.4.m4.2.2.2.2.3">𝑘</ci></apply><apply id="S3.p5.4.m4.2.2.2.1.2.cmml" xref="S3.p5.4.m4.2.2.2.1.1"><abs id="S3.p5.4.m4.2.2.2.1.2.1.cmml" xref="S3.p5.4.m4.2.2.2.1.1.2"></abs><apply id="S3.p5.4.m4.2.2.2.1.1.1.cmml" xref="S3.p5.4.m4.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p5.4.m4.2.2.2.1.1.1.1.cmml" xref="S3.p5.4.m4.2.2.2.1.1.1">subscript</csymbol><ci id="S3.p5.4.m4.2.2.2.1.1.1.2.cmml" xref="S3.p5.4.m4.2.2.2.1.1.1.2">𝐖</ci><apply id="S3.p5.4.m4.2.2.2.1.1.1.3.cmml" xref="S3.p5.4.m4.2.2.2.1.1.1.3"><times id="S3.p5.4.m4.2.2.2.1.1.1.3.1.cmml" xref="S3.p5.4.m4.2.2.2.1.1.1.3.1"></times><ci id="S3.p5.4.m4.2.2.2.1.1.1.3.2.cmml" xref="S3.p5.4.m4.2.2.2.1.1.1.3.2">𝑖</ci><ci id="S3.p5.4.m4.2.2.2.1.1.1.3.3.cmml" xref="S3.p5.4.m4.2.2.2.1.1.1.3.3">𝑗</ci><ci id="S3.p5.4.m4.2.2.2.1.1.1.3.4.cmml" xref="S3.p5.4.m4.2.2.2.1.1.1.3.4">𝑘</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.4.m4.2c">\mathbf{RGN}^{L}_{ij}=\frac{\sum_{k}|\nabla{\mathbf{W}_{ijk}}|}{\sum_{k}|\mathbf{W}_{ijk}|}</annotation></semantics></math>. Then, <math id="S3.p5.5.m5.2" class="ltx_Math" alttext="\mathbf{RGN}^{L}=\frac{1}{C_{i}C_{o}}\sum_{i,j}\mathbf{RGN}^{L}_{ij}" display="inline"><semantics id="S3.p5.5.m5.2a"><mrow id="S3.p5.5.m5.2.3" xref="S3.p5.5.m5.2.3.cmml"><msup id="S3.p5.5.m5.2.3.2" xref="S3.p5.5.m5.2.3.2.cmml"><mi id="S3.p5.5.m5.2.3.2.2" xref="S3.p5.5.m5.2.3.2.2.cmml">𝐑𝐆𝐍</mi><mi id="S3.p5.5.m5.2.3.2.3" xref="S3.p5.5.m5.2.3.2.3.cmml">L</mi></msup><mo id="S3.p5.5.m5.2.3.1" xref="S3.p5.5.m5.2.3.1.cmml">=</mo><mrow id="S3.p5.5.m5.2.3.3" xref="S3.p5.5.m5.2.3.3.cmml"><mfrac id="S3.p5.5.m5.2.3.3.2" xref="S3.p5.5.m5.2.3.3.2.cmml"><mn id="S3.p5.5.m5.2.3.3.2.2" xref="S3.p5.5.m5.2.3.3.2.2.cmml">1</mn><mrow id="S3.p5.5.m5.2.3.3.2.3" xref="S3.p5.5.m5.2.3.3.2.3.cmml"><msub id="S3.p5.5.m5.2.3.3.2.3.2" xref="S3.p5.5.m5.2.3.3.2.3.2.cmml"><mi id="S3.p5.5.m5.2.3.3.2.3.2.2" xref="S3.p5.5.m5.2.3.3.2.3.2.2.cmml">C</mi><mi id="S3.p5.5.m5.2.3.3.2.3.2.3" xref="S3.p5.5.m5.2.3.3.2.3.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.p5.5.m5.2.3.3.2.3.1" xref="S3.p5.5.m5.2.3.3.2.3.1.cmml">​</mo><msub id="S3.p5.5.m5.2.3.3.2.3.3" xref="S3.p5.5.m5.2.3.3.2.3.3.cmml"><mi id="S3.p5.5.m5.2.3.3.2.3.3.2" xref="S3.p5.5.m5.2.3.3.2.3.3.2.cmml">C</mi><mi id="S3.p5.5.m5.2.3.3.2.3.3.3" xref="S3.p5.5.m5.2.3.3.2.3.3.3.cmml">o</mi></msub></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.p5.5.m5.2.3.3.1" xref="S3.p5.5.m5.2.3.3.1.cmml">​</mo><mrow id="S3.p5.5.m5.2.3.3.3" xref="S3.p5.5.m5.2.3.3.3.cmml"><msub id="S3.p5.5.m5.2.3.3.3.1" xref="S3.p5.5.m5.2.3.3.3.1.cmml"><mo id="S3.p5.5.m5.2.3.3.3.1.2" xref="S3.p5.5.m5.2.3.3.3.1.2.cmml">∑</mo><mrow id="S3.p5.5.m5.2.2.2.4" xref="S3.p5.5.m5.2.2.2.3.cmml"><mi id="S3.p5.5.m5.1.1.1.1" xref="S3.p5.5.m5.1.1.1.1.cmml">i</mi><mo id="S3.p5.5.m5.2.2.2.4.1" xref="S3.p5.5.m5.2.2.2.3.cmml">,</mo><mi id="S3.p5.5.m5.2.2.2.2" xref="S3.p5.5.m5.2.2.2.2.cmml">j</mi></mrow></msub><msubsup id="S3.p5.5.m5.2.3.3.3.2" xref="S3.p5.5.m5.2.3.3.3.2.cmml"><mi id="S3.p5.5.m5.2.3.3.3.2.2.2" xref="S3.p5.5.m5.2.3.3.3.2.2.2.cmml">𝐑𝐆𝐍</mi><mrow id="S3.p5.5.m5.2.3.3.3.2.3" xref="S3.p5.5.m5.2.3.3.3.2.3.cmml"><mi id="S3.p5.5.m5.2.3.3.3.2.3.2" xref="S3.p5.5.m5.2.3.3.3.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p5.5.m5.2.3.3.3.2.3.1" xref="S3.p5.5.m5.2.3.3.3.2.3.1.cmml">​</mo><mi id="S3.p5.5.m5.2.3.3.3.2.3.3" xref="S3.p5.5.m5.2.3.3.3.2.3.3.cmml">j</mi></mrow><mi id="S3.p5.5.m5.2.3.3.3.2.2.3" xref="S3.p5.5.m5.2.3.3.3.2.2.3.cmml">L</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.5.m5.2b"><apply id="S3.p5.5.m5.2.3.cmml" xref="S3.p5.5.m5.2.3"><eq id="S3.p5.5.m5.2.3.1.cmml" xref="S3.p5.5.m5.2.3.1"></eq><apply id="S3.p5.5.m5.2.3.2.cmml" xref="S3.p5.5.m5.2.3.2"><csymbol cd="ambiguous" id="S3.p5.5.m5.2.3.2.1.cmml" xref="S3.p5.5.m5.2.3.2">superscript</csymbol><ci id="S3.p5.5.m5.2.3.2.2.cmml" xref="S3.p5.5.m5.2.3.2.2">𝐑𝐆𝐍</ci><ci id="S3.p5.5.m5.2.3.2.3.cmml" xref="S3.p5.5.m5.2.3.2.3">𝐿</ci></apply><apply id="S3.p5.5.m5.2.3.3.cmml" xref="S3.p5.5.m5.2.3.3"><times id="S3.p5.5.m5.2.3.3.1.cmml" xref="S3.p5.5.m5.2.3.3.1"></times><apply id="S3.p5.5.m5.2.3.3.2.cmml" xref="S3.p5.5.m5.2.3.3.2"><divide id="S3.p5.5.m5.2.3.3.2.1.cmml" xref="S3.p5.5.m5.2.3.3.2"></divide><cn type="integer" id="S3.p5.5.m5.2.3.3.2.2.cmml" xref="S3.p5.5.m5.2.3.3.2.2">1</cn><apply id="S3.p5.5.m5.2.3.3.2.3.cmml" xref="S3.p5.5.m5.2.3.3.2.3"><times id="S3.p5.5.m5.2.3.3.2.3.1.cmml" xref="S3.p5.5.m5.2.3.3.2.3.1"></times><apply id="S3.p5.5.m5.2.3.3.2.3.2.cmml" xref="S3.p5.5.m5.2.3.3.2.3.2"><csymbol cd="ambiguous" id="S3.p5.5.m5.2.3.3.2.3.2.1.cmml" xref="S3.p5.5.m5.2.3.3.2.3.2">subscript</csymbol><ci id="S3.p5.5.m5.2.3.3.2.3.2.2.cmml" xref="S3.p5.5.m5.2.3.3.2.3.2.2">𝐶</ci><ci id="S3.p5.5.m5.2.3.3.2.3.2.3.cmml" xref="S3.p5.5.m5.2.3.3.2.3.2.3">𝑖</ci></apply><apply id="S3.p5.5.m5.2.3.3.2.3.3.cmml" xref="S3.p5.5.m5.2.3.3.2.3.3"><csymbol cd="ambiguous" id="S3.p5.5.m5.2.3.3.2.3.3.1.cmml" xref="S3.p5.5.m5.2.3.3.2.3.3">subscript</csymbol><ci id="S3.p5.5.m5.2.3.3.2.3.3.2.cmml" xref="S3.p5.5.m5.2.3.3.2.3.3.2">𝐶</ci><ci id="S3.p5.5.m5.2.3.3.2.3.3.3.cmml" xref="S3.p5.5.m5.2.3.3.2.3.3.3">𝑜</ci></apply></apply></apply><apply id="S3.p5.5.m5.2.3.3.3.cmml" xref="S3.p5.5.m5.2.3.3.3"><apply id="S3.p5.5.m5.2.3.3.3.1.cmml" xref="S3.p5.5.m5.2.3.3.3.1"><csymbol cd="ambiguous" id="S3.p5.5.m5.2.3.3.3.1.1.cmml" xref="S3.p5.5.m5.2.3.3.3.1">subscript</csymbol><sum id="S3.p5.5.m5.2.3.3.3.1.2.cmml" xref="S3.p5.5.m5.2.3.3.3.1.2"></sum><list id="S3.p5.5.m5.2.2.2.3.cmml" xref="S3.p5.5.m5.2.2.2.4"><ci id="S3.p5.5.m5.1.1.1.1.cmml" xref="S3.p5.5.m5.1.1.1.1">𝑖</ci><ci id="S3.p5.5.m5.2.2.2.2.cmml" xref="S3.p5.5.m5.2.2.2.2">𝑗</ci></list></apply><apply id="S3.p5.5.m5.2.3.3.3.2.cmml" xref="S3.p5.5.m5.2.3.3.3.2"><csymbol cd="ambiguous" id="S3.p5.5.m5.2.3.3.3.2.1.cmml" xref="S3.p5.5.m5.2.3.3.3.2">subscript</csymbol><apply id="S3.p5.5.m5.2.3.3.3.2.2.cmml" xref="S3.p5.5.m5.2.3.3.3.2"><csymbol cd="ambiguous" id="S3.p5.5.m5.2.3.3.3.2.2.1.cmml" xref="S3.p5.5.m5.2.3.3.3.2">superscript</csymbol><ci id="S3.p5.5.m5.2.3.3.3.2.2.2.cmml" xref="S3.p5.5.m5.2.3.3.3.2.2.2">𝐑𝐆𝐍</ci><ci id="S3.p5.5.m5.2.3.3.3.2.2.3.cmml" xref="S3.p5.5.m5.2.3.3.3.2.2.3">𝐿</ci></apply><apply id="S3.p5.5.m5.2.3.3.3.2.3.cmml" xref="S3.p5.5.m5.2.3.3.3.2.3"><times id="S3.p5.5.m5.2.3.3.3.2.3.1.cmml" xref="S3.p5.5.m5.2.3.3.3.2.3.1"></times><ci id="S3.p5.5.m5.2.3.3.3.2.3.2.cmml" xref="S3.p5.5.m5.2.3.3.3.2.3.2">𝑖</ci><ci id="S3.p5.5.m5.2.3.3.3.2.3.3.cmml" xref="S3.p5.5.m5.2.3.3.3.2.3.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.5.m5.2c">\mathbf{RGN}^{L}=\frac{1}{C_{i}C_{o}}\sum_{i,j}\mathbf{RGN}^{L}_{ij}</annotation></semantics></math>. To get the RGN value for one model, we take the average over layers, <math id="S3.p5.6.m6.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.p5.6.m6.1a"><mi id="S3.p5.6.m6.1.1" xref="S3.p5.6.m6.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.p5.6.m6.1b"><ci id="S3.p5.6.m6.1.1.cmml" xref="S3.p5.6.m6.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.6.m6.1c">L</annotation></semantics></math>.
We utilize the DP model to compute the gradient of detection loss; thus, RGN indicates how aggressively <math id="S3.p5.7.m7.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.p5.7.m7.1a"><mi id="S3.p5.7.m7.1.1" xref="S3.p5.7.m7.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.p5.7.m7.1b"><ci id="S3.p5.7.m7.1.1.cmml" xref="S3.p5.7.m7.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.7.m7.1c">W</annotation></semantics></math> will be updated by fine-tuning. RGN is averaged over training images. Note that since we do not update the DP model during this computation. RGN shows the expected update at the starting point of DP-FT.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">Fig. <a href="#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> plots RGN values for the three models on Pascal, with different layers, used in Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Work ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. RGN differs significantly by model; EfficientNet has a small RGN in most layers, ConvNeXt has a large RGN in the first few layers, and ResNet50 has large RGN across all layers. Also, note that ResNet50 loses OOD generalization by fine-tuning while the other two networks improve it in Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Work ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The RGN averaged over all layers are 1.34 (ResNet50), 0.13 (ConvNeXt), and 0.06 (EfficientNet), respectively.
This observation is consistent with previous findings, <em id="S3.p6.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.p6.1.2" class="ltx_text"></span>, the performance on OOD will be high if a pre-trained model does not have to aggressively update parameters to fit a downstream task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
However, our novel finding is that the model distortion is specific to each pre-trained model. Next, we conduct a more extensive study to investigate whether the difference stems from architecture or the dataset used to train the model.</p>
</div>
<div id="S3.p7" class="ltx_para ltx_noindent">
<p id="S3.p7.3" class="ltx_p"><span id="S3.p7.3.1" class="ltx_text ltx_font_bold">Relative Gradient Norm (RGN) has a negative correlation with performance improvement in OOD.</span>
In Fig. <a href="#S3.F3" title="Figure 3 ‣ 3 Analysis of Feature Distortion ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we investigate the relationship between RGN and the ratio of improvement on OOD to improvement on ID, <em id="S3.p7.3.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.p7.3.3" class="ltx_text"></span> <math id="S3.p7.1.m1.1" class="ltx_math_unparsed" alttext="\frac{(\rm{OOD_{FT}}-OOD\rm{{}_{DP}})}{(\rm{ID_{FT}}-ID_{DP})}" display="inline"><semantics id="S3.p7.1.m1.1a"><mfrac id="S3.p7.1.m1.1.1"><mrow id="S3.p7.1.m1.1.1.3"><mo stretchy="false" id="S3.p7.1.m1.1.1.3.1">(</mo><msub id="S3.p7.1.m1.1.1.3.2"><mi id="S3.p7.1.m1.1.1.3.2.2">OOD</mi><mi id="S3.p7.1.m1.1.1.3.2.3">FT</mi></msub><mo id="S3.p7.1.m1.1.1.3.3">−</mo><mi id="S3.p7.1.m1.1.1.3.4">OOD</mi><mmultiscripts id="S3.p7.1.m1.1.1.3.5"><mo stretchy="false" id="S3.p7.1.m1.1.1.3.5.2">)</mo><mprescripts id="S3.p7.1.m1.1.1.3.5a"></mprescripts><mi id="S3.p7.1.m1.1.1.3.5.3">DP</mi><mrow id="S3.p7.1.m1.1.1.3.5b"></mrow></mmultiscripts></mrow><mrow id="S3.p7.1.m1.1.1.1.1"><mo stretchy="false" id="S3.p7.1.m1.1.1.1.1.2">(</mo><mrow id="S3.p7.1.m1.1.1.1.1.1"><msub id="S3.p7.1.m1.1.1.1.1.1.2"><mi id="S3.p7.1.m1.1.1.1.1.1.2.2">ID</mi><mi id="S3.p7.1.m1.1.1.1.1.1.2.3">FT</mi></msub><mo id="S3.p7.1.m1.1.1.1.1.1.1">−</mo><msub id="S3.p7.1.m1.1.1.1.1.1.3"><mi id="S3.p7.1.m1.1.1.1.1.1.3.2">ID</mi><mi id="S3.p7.1.m1.1.1.1.1.1.3.3">DP</mi></msub></mrow><mo stretchy="false" id="S3.p7.1.m1.1.1.1.1.3">)</mo></mrow></mfrac><annotation encoding="application/x-tex" id="S3.p7.1.m1.1b">\frac{(\rm{OOD_{FT}}-OOD\rm{{}_{DP}})}{(\rm{ID_{FT}}-ID_{DP})}</annotation></semantics></math>, where <math id="S3.p7.2.m2.1" class="ltx_Math" alttext="\rm{OOD}" display="inline"><semantics id="S3.p7.2.m2.1a"><mi id="S3.p7.2.m2.1.1" xref="S3.p7.2.m2.1.1.cmml">OOD</mi><annotation-xml encoding="MathML-Content" id="S3.p7.2.m2.1b"><ci id="S3.p7.2.m2.1.1.cmml" xref="S3.p7.2.m2.1.1">OOD</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.2.m2.1c">\rm{OOD}</annotation></semantics></math> and <math id="S3.p7.3.m3.1" class="ltx_Math" alttext="\rm{ID}" display="inline"><semantics id="S3.p7.3.m3.1a"><mi id="S3.p7.3.m3.1.1" xref="S3.p7.3.m3.1.1.cmml">ID</mi><annotation-xml encoding="MathML-Content" id="S3.p7.3.m3.1b"><ci id="S3.p7.3.m3.1.1.cmml" xref="S3.p7.3.m3.1.1">ID</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.3.m3.1c">\rm{ID}</annotation></semantics></math> denote the mAP on OOD and ID respectively. We employ 14 models with diverse architectures and different pre-training datasets, <em id="S3.p7.3.4" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.p7.3.5" class="ltx_text"></span>, ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, SeNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, EfficientNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, ConvNeXt <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, MobileNetV2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.
We observe that RGN and relative improvement has a negative correlation, indicating that RGN is a good measurement of the performance improvement on OOD gained by fine-tuning on ID. Intuitively, the target domain with low mAP is far from the ID. Then, the correlation becomes more evident in these plots as OOD gets farther away from ID. For example, the correlation is more evident in Comic (mAP: 10.3) while it is not evident in Watercolor (map: 22.0).</p>
</div>
<figure id="S3.T2" class="ltx_table">
<div id="S3.T2.2" class="ltx_inline-block ltx_transformed_outer" style="width:237.2pt;height:81pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-13.2pt,4.5pt) scale(0.9,0.9) ;">
<table id="S3.T2.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.2.2.2" class="ltx_tr">
<td id="S3.T2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_tt">Backbone</td>
<td id="S3.T2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_tt">Dataset</td>
<td id="S3.T2.2.2.2.5" class="ltx_td ltx_align_center ltx_border_tt">SE</td>
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">RGN<sub id="S3.T2.1.1.1.1.1" class="ltx_sub">pascal</sub>
</td>
<td id="S3.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt">RGN<sub id="S3.T2.2.2.2.2.1" class="ltx_sub">city</sub>
</td>
</tr>
<tr id="S3.T2.2.2.3" class="ltx_tr">
<td id="S3.T2.2.2.3.1" class="ltx_td ltx_align_center ltx_border_t">ResNet50</td>
<td id="S3.T2.2.2.3.2" class="ltx_td ltx_align_center ltx_border_t">IN1K</td>
<td id="S3.T2.2.2.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.2.2.3.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S3.T2.2.2.3.4" class="ltx_td ltx_align_center ltx_border_t">0.31</td>
<td id="S3.T2.2.2.3.5" class="ltx_td ltx_align_center ltx_border_t">0.53</td>
</tr>
<tr id="S3.T2.2.2.4" class="ltx_tr">
<td id="S3.T2.2.2.4.1" class="ltx_td ltx_align_center">ResNet50</td>
<td id="S3.T2.2.2.4.2" class="ltx_td ltx_align_center">IN1K + Augmix</td>
<td id="S3.T2.2.2.4.3" class="ltx_td ltx_align_center"><span id="S3.T2.2.2.4.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S3.T2.2.2.4.4" class="ltx_td ltx_align_center">0.57</td>
<td id="S3.T2.2.2.4.5" class="ltx_td ltx_align_center">0.48</td>
</tr>
<tr id="S3.T2.2.2.5" class="ltx_tr">
<td id="S3.T2.2.2.5.1" class="ltx_td ltx_align_center">ResNet50</td>
<td id="S3.T2.2.2.5.2" class="ltx_td ltx_align_center">IN1K + Insta</td>
<td id="S3.T2.2.2.5.3" class="ltx_td ltx_align_center"><span id="S3.T2.2.2.5.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S3.T2.2.2.5.4" class="ltx_td ltx_align_center">1.34</td>
<td id="S3.T2.2.2.5.5" class="ltx_td ltx_align_center">0.89</td>
</tr>
<tr id="S3.T2.2.2.6" class="ltx_tr">
<td id="S3.T2.2.2.6.1" class="ltx_td ltx_align_center ltx_border_bb">SeNet50</td>
<td id="S3.T2.2.2.6.2" class="ltx_td ltx_align_center ltx_border_bb">IN1K</td>
<td id="S3.T2.2.2.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.2.2.6.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S3.T2.2.2.6.4" class="ltx_td ltx_align_center ltx_border_bb">0.05</td>
<td id="S3.T2.2.2.6.5" class="ltx_td ltx_align_center ltx_border_bb">0.04</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.4.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.5.2" class="ltx_text" style="font-size:90%;">Relationship among RGN and architecture and dataset used to train the model. RGN of SeNet is much smaller than that of ResNet. Note that the difference between SeNet50 and ResNet50 is whether SE-Block is plugged into the model. Also, RGN is calculated except for SE-Block for a fair comparison.</span></figcaption>
</figure>
<div id="S3.p8" class="ltx_para ltx_noindent">
<p id="S3.p8.1" class="ltx_p"><span id="S3.p8.1.1" class="ltx_text ltx_font_bold">Pre-training dataset and SE-Block affect RGN.</span>
In Table <a href="#S3.T2" title="Table 2 ‣ 3 Analysis of Feature Distortion ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we pick ResNet50 trained with different datasets and SeNet50 to show their RGN. First, surprisingly, using more data tends to increase RGN, as shown in the results of ResNet50. If a model is trained on diverse data, it may need to lose much representation to be specific to the downstream task. Second, SeNet has a much smaller RGN than ResNet50 does. The only difference between SeNet and ResNet50 is the existence of SE-Block. Therefore, we conjecture that one of the keys to reducing RGN is in SE-Block and investigate it in the next paragraph.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2303.14744/assets/x9.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">Visualization of SE-Block activations. Note that most values are close to either zero or one, which works to suppress gradients from the upper layer.</span></figcaption>
</figure>
<div id="S3.p9" class="ltx_para ltx_noindent">
<p id="S3.p9.6" class="ltx_p"><span id="S3.p9.6.1" class="ltx_text ltx_font_bold">Analysis of SE-Block.</span>
Squeeze-and-excitation block performs channel-wise attention in the residual block as follows:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="\hat{\mathbf{X}}=\mathbf{X}+\sigma(S(R(\mathbf{X})))\circ R(\mathbf{X})," display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mover accent="true" id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml"><mi id="S3.E1.m1.3.3.1.1.3.2" xref="S3.E1.m1.3.3.1.1.3.2.cmml">𝐗</mi><mo id="S3.E1.m1.3.3.1.1.3.1" xref="S3.E1.m1.3.3.1.1.3.1.cmml">^</mo></mover><mo id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.3.cmml">𝐗</mi><mo id="S3.E1.m1.3.3.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.2.cmml">+</mo><mrow id="S3.E1.m1.3.3.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">𝐗</mi><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.055em" stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E1.m1.3.3.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.2.cmml">∘</mo><mi id="S3.E1.m1.3.3.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.3.cmml">R</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.3.2.1" xref="S3.E1.m1.3.3.1.1.1.1.cmml">(</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">𝐗</mi><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.3.2.2" xref="S3.E1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><eq id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2"></eq><apply id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.3"><ci id="S3.E1.m1.3.3.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3.1">^</ci><ci id="S3.E1.m1.3.3.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2">𝐗</ci></apply><apply id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"><plus id="S3.E1.m1.3.3.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.2"></plus><ci id="S3.E1.m1.3.3.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.3">𝐗</ci><apply id="S3.E1.m1.3.3.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2"></times><apply id="S3.E1.m1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"><compose id="S3.E1.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2"></compose><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3">𝜎</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.3">𝑆</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑅</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝐗</ci></apply></apply></apply><ci id="S3.E1.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.3">𝑅</ci></apply><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">𝐗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\hat{\mathbf{X}}=\mathbf{X}+\sigma(S(R(\mathbf{X})))\circ R(\mathbf{X}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.p9.5" class="ltx_p">where <math id="S3.p9.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.p9.1.m1.1a"><mi id="S3.p9.1.m1.1.1" xref="S3.p9.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.p9.1.m1.1b"><ci id="S3.p9.1.m1.1.1.cmml" xref="S3.p9.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.1.m1.1c">\sigma</annotation></semantics></math>, <math id="S3.p9.2.m2.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.p9.2.m2.1a"><mi id="S3.p9.2.m2.1.1" xref="S3.p9.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.p9.2.m2.1b"><ci id="S3.p9.2.m2.1.1.cmml" xref="S3.p9.2.m2.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.2.m2.1c">S</annotation></semantics></math>, <math id="S3.p9.3.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.p9.3.m3.1a"><mi id="S3.p9.3.m3.1.1" xref="S3.p9.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.p9.3.m3.1b"><ci id="S3.p9.3.m3.1.1.cmml" xref="S3.p9.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.3.m3.1c">R</annotation></semantics></math>, and <math id="S3.p9.4.m4.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S3.p9.4.m4.1a"><mo id="S3.p9.4.m4.1.1" xref="S3.p9.4.m4.1.1.cmml">∘</mo><annotation-xml encoding="MathML-Content" id="S3.p9.4.m4.1b"><compose id="S3.p9.4.m4.1.1.cmml" xref="S3.p9.4.m4.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.4.m4.1c">\circ</annotation></semantics></math> denote sigmoid activation, multi-layer perceptron after average pooling, convolution layers, and channel-wise attention, respectively. This block applies sigmoid activation to scale outputs from 0 to 1. Therefore, the block masks several outputs from <math id="S3.p9.5.m5.1" class="ltx_Math" alttext="R(X)" display="inline"><semantics id="S3.p9.5.m5.1a"><mrow id="S3.p9.5.m5.1.2" xref="S3.p9.5.m5.1.2.cmml"><mi id="S3.p9.5.m5.1.2.2" xref="S3.p9.5.m5.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.p9.5.m5.1.2.1" xref="S3.p9.5.m5.1.2.1.cmml">​</mo><mrow id="S3.p9.5.m5.1.2.3.2" xref="S3.p9.5.m5.1.2.cmml"><mo stretchy="false" id="S3.p9.5.m5.1.2.3.2.1" xref="S3.p9.5.m5.1.2.cmml">(</mo><mi id="S3.p9.5.m5.1.1" xref="S3.p9.5.m5.1.1.cmml">X</mi><mo stretchy="false" id="S3.p9.5.m5.1.2.3.2.2" xref="S3.p9.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.5.m5.1b"><apply id="S3.p9.5.m5.1.2.cmml" xref="S3.p9.5.m5.1.2"><times id="S3.p9.5.m5.1.2.1.cmml" xref="S3.p9.5.m5.1.2.1"></times><ci id="S3.p9.5.m5.1.2.2.cmml" xref="S3.p9.5.m5.1.2.2">𝑅</ci><ci id="S3.p9.5.m5.1.1.cmml" xref="S3.p9.5.m5.1.1">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.5.m5.1c">R(X)</annotation></semantics></math> resulting in a sparse activation pattern. In Fig. <a href="#S3.F4" title="Figure 4 ‣ 3 Analysis of Feature Distortion ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we visualize the histogram of the activation from four SE-Blocks, computed on the SeNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> pre-trained on ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. We observe that many units are close to either zero or one.</p>
</div>
<div id="S3.p10" class="ltx_para">
<p id="S3.p10.2" class="ltx_p">For simplicity, let <math id="S3.p10.1.m1.1" class="ltx_Math" alttext="M(\mathbf{X})" display="inline"><semantics id="S3.p10.1.m1.1a"><mrow id="S3.p10.1.m1.1.2" xref="S3.p10.1.m1.1.2.cmml"><mi id="S3.p10.1.m1.1.2.2" xref="S3.p10.1.m1.1.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.p10.1.m1.1.2.1" xref="S3.p10.1.m1.1.2.1.cmml">​</mo><mrow id="S3.p10.1.m1.1.2.3.2" xref="S3.p10.1.m1.1.2.cmml"><mo stretchy="false" id="S3.p10.1.m1.1.2.3.2.1" xref="S3.p10.1.m1.1.2.cmml">(</mo><mi id="S3.p10.1.m1.1.1" xref="S3.p10.1.m1.1.1.cmml">𝐗</mi><mo stretchy="false" id="S3.p10.1.m1.1.2.3.2.2" xref="S3.p10.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p10.1.m1.1b"><apply id="S3.p10.1.m1.1.2.cmml" xref="S3.p10.1.m1.1.2"><times id="S3.p10.1.m1.1.2.1.cmml" xref="S3.p10.1.m1.1.2.1"></times><ci id="S3.p10.1.m1.1.2.2.cmml" xref="S3.p10.1.m1.1.2.2">𝑀</ci><ci id="S3.p10.1.m1.1.1.cmml" xref="S3.p10.1.m1.1.1">𝐗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.1.m1.1c">M(\mathbf{X})</annotation></semantics></math> denote <math id="S3.p10.2.m2.2" class="ltx_Math" alttext="S(R(\mathbf{X}))" display="inline"><semantics id="S3.p10.2.m2.2a"><mrow id="S3.p10.2.m2.2.2" xref="S3.p10.2.m2.2.2.cmml"><mi id="S3.p10.2.m2.2.2.3" xref="S3.p10.2.m2.2.2.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.p10.2.m2.2.2.2" xref="S3.p10.2.m2.2.2.2.cmml">​</mo><mrow id="S3.p10.2.m2.2.2.1.1" xref="S3.p10.2.m2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.p10.2.m2.2.2.1.1.2" xref="S3.p10.2.m2.2.2.1.1.1.cmml">(</mo><mrow id="S3.p10.2.m2.2.2.1.1.1" xref="S3.p10.2.m2.2.2.1.1.1.cmml"><mi id="S3.p10.2.m2.2.2.1.1.1.2" xref="S3.p10.2.m2.2.2.1.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.p10.2.m2.2.2.1.1.1.1" xref="S3.p10.2.m2.2.2.1.1.1.1.cmml">​</mo><mrow id="S3.p10.2.m2.2.2.1.1.1.3.2" xref="S3.p10.2.m2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.p10.2.m2.2.2.1.1.1.3.2.1" xref="S3.p10.2.m2.2.2.1.1.1.cmml">(</mo><mi id="S3.p10.2.m2.1.1" xref="S3.p10.2.m2.1.1.cmml">𝐗</mi><mo stretchy="false" id="S3.p10.2.m2.2.2.1.1.1.3.2.2" xref="S3.p10.2.m2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.p10.2.m2.2.2.1.1.3" xref="S3.p10.2.m2.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p10.2.m2.2b"><apply id="S3.p10.2.m2.2.2.cmml" xref="S3.p10.2.m2.2.2"><times id="S3.p10.2.m2.2.2.2.cmml" xref="S3.p10.2.m2.2.2.2"></times><ci id="S3.p10.2.m2.2.2.3.cmml" xref="S3.p10.2.m2.2.2.3">𝑆</ci><apply id="S3.p10.2.m2.2.2.1.1.1.cmml" xref="S3.p10.2.m2.2.2.1.1"><times id="S3.p10.2.m2.2.2.1.1.1.1.cmml" xref="S3.p10.2.m2.2.2.1.1.1.1"></times><ci id="S3.p10.2.m2.2.2.1.1.1.2.cmml" xref="S3.p10.2.m2.2.2.1.1.1.2">𝑅</ci><ci id="S3.p10.2.m2.1.1.cmml" xref="S3.p10.2.m2.1.1">𝐗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.2.m2.2c">S(R(\mathbf{X}))</annotation></semantics></math>. Then, we can calculate the derivative as follows:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.5" class="ltx_Math" alttext="\diffp{\hat{\mathbf{X}}}{\mathbf{X}}=I+\diffp{\sigma(M(\mathbf{X}))}{\mathbf{X}}\circ R(\mathbf{X})+\sigma(M(\mathbf{X}))\circ\diffp{R(\mathbf{X})}{\mathbf{X}}." display="block"><semantics id="S3.E2.m1.5a"><mrow id="S3.E2.m1.5.5.1" xref="S3.E2.m1.5.5.1.1.cmml"><mrow id="S3.E2.m1.5.5.1.1" xref="S3.E2.m1.5.5.1.1.cmml"><mrow id="S3.E2.m1.5.5.1.1.4" xref="S3.E2.m1.5.5.1.1.4.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.E2.m1.5.5.1.1.4.2" xref="S3.E2.m1.5.5.1.1.4.2b.cmml"><mtext id="S3.E2.m1.5.5.1.1.4.2a" xref="S3.E2.m1.5.5.1.1.4.2b.cmml">\diffp</mtext></merror><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.4.1" xref="S3.E2.m1.5.5.1.1.4.1.cmml">​</mo><mover accent="true" id="S3.E2.m1.5.5.1.1.4.3" xref="S3.E2.m1.5.5.1.1.4.3.cmml"><mi id="S3.E2.m1.5.5.1.1.4.3.2" xref="S3.E2.m1.5.5.1.1.4.3.2.cmml">𝐗</mi><mo id="S3.E2.m1.5.5.1.1.4.3.1" xref="S3.E2.m1.5.5.1.1.4.3.1.cmml">^</mo></mover><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.4.1a" xref="S3.E2.m1.5.5.1.1.4.1.cmml">​</mo><mi id="S3.E2.m1.5.5.1.1.4.4" xref="S3.E2.m1.5.5.1.1.4.4.cmml">𝐗</mi></mrow><mo id="S3.E2.m1.5.5.1.1.3" xref="S3.E2.m1.5.5.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.5.5.1.1.2" xref="S3.E2.m1.5.5.1.1.2.cmml"><mi id="S3.E2.m1.5.5.1.1.2.4" xref="S3.E2.m1.5.5.1.1.2.4.cmml">I</mi><mo id="S3.E2.m1.5.5.1.1.2.3" xref="S3.E2.m1.5.5.1.1.2.3.cmml">+</mo><mrow id="S3.E2.m1.5.5.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.cmml"><mrow id="S3.E2.m1.5.5.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.5.5.1.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.E2.m1.5.5.1.1.1.1.1.1.3" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3b.cmml"><mtext id="S3.E2.m1.5.5.1.1.1.1.1.1.3a" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3b.cmml">\diffp</mtext></merror><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.1.1.1.1.2" xref="S3.E2.m1.5.5.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E2.m1.5.5.1.1.1.1.1.1.4" xref="S3.E2.m1.5.5.1.1.1.1.1.1.4.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.1.1.1.1.2a" xref="S3.E2.m1.5.5.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">𝐗</mi><mo stretchy="false" id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.1.1.1.1.2b" xref="S3.E2.m1.5.5.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E2.m1.5.5.1.1.1.1.1.1.5" xref="S3.E2.m1.5.5.1.1.1.1.1.1.5.cmml">𝐗</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.5.5.1.1.1.1.1.2" xref="S3.E2.m1.5.5.1.1.1.1.1.2.cmml">∘</mo><mi id="S3.E2.m1.5.5.1.1.1.1.1.3" xref="S3.E2.m1.5.5.1.1.1.1.1.3.cmml">R</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.1.1.2" xref="S3.E2.m1.5.5.1.1.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.5.5.1.1.1.1.3.2" xref="S3.E2.m1.5.5.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.1.1.1.1.3.2.1" xref="S3.E2.m1.5.5.1.1.1.1.cmml">(</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">𝐗</mi><mo stretchy="false" id="S3.E2.m1.5.5.1.1.1.1.3.2.2" xref="S3.E2.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.5.5.1.1.2.3a" xref="S3.E2.m1.5.5.1.1.2.3.cmml">+</mo><mrow id="S3.E2.m1.5.5.1.1.2.2" xref="S3.E2.m1.5.5.1.1.2.2.cmml"><mrow id="S3.E2.m1.5.5.1.1.2.2.1" xref="S3.E2.m1.5.5.1.1.2.2.1.cmml"><mrow id="S3.E2.m1.5.5.1.1.2.2.1.1" xref="S3.E2.m1.5.5.1.1.2.2.1.1.cmml"><mi id="S3.E2.m1.5.5.1.1.2.2.1.1.3" xref="S3.E2.m1.5.5.1.1.2.2.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.2.2.1.1.2" xref="S3.E2.m1.5.5.1.1.2.2.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.2" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.cmml"><mi id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.2" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.3.2" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.3.2.1" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.cmml">(</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">𝐗</mi><mo stretchy="false" id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.3.2.2" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.055em" stretchy="false" id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.3" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E2.m1.5.5.1.1.2.2.1.2" xref="S3.E2.m1.5.5.1.1.2.2.1.2.cmml">∘</mo><merror class="ltx_ERROR undefined undefined" id="S3.E2.m1.5.5.1.1.2.2.1.3" xref="S3.E2.m1.5.5.1.1.2.2.1.3b.cmml"><mtext id="S3.E2.m1.5.5.1.1.2.2.1.3a" xref="S3.E2.m1.5.5.1.1.2.2.1.3b.cmml">\diffp</mtext></merror></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.2.2.2" xref="S3.E2.m1.5.5.1.1.2.2.2.cmml">​</mo><mi id="S3.E2.m1.5.5.1.1.2.2.3" xref="S3.E2.m1.5.5.1.1.2.2.3.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.2.2.2a" xref="S3.E2.m1.5.5.1.1.2.2.2.cmml">​</mo><mrow id="S3.E2.m1.5.5.1.1.2.2.4.2" xref="S3.E2.m1.5.5.1.1.2.2.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.1.1.2.2.4.2.1" xref="S3.E2.m1.5.5.1.1.2.2.cmml">(</mo><mi id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml">𝐗</mi><mo stretchy="false" id="S3.E2.m1.5.5.1.1.2.2.4.2.2" xref="S3.E2.m1.5.5.1.1.2.2.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.1.1.2.2.2b" xref="S3.E2.m1.5.5.1.1.2.2.2.cmml">​</mo><mi id="S3.E2.m1.5.5.1.1.2.2.5" xref="S3.E2.m1.5.5.1.1.2.2.5.cmml">𝐗</mi></mrow></mrow></mrow><mo lspace="0em" id="S3.E2.m1.5.5.1.2" xref="S3.E2.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.5b"><apply id="S3.E2.m1.5.5.1.1.cmml" xref="S3.E2.m1.5.5.1"><eq id="S3.E2.m1.5.5.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.3"></eq><apply id="S3.E2.m1.5.5.1.1.4.cmml" xref="S3.E2.m1.5.5.1.1.4"><times id="S3.E2.m1.5.5.1.1.4.1.cmml" xref="S3.E2.m1.5.5.1.1.4.1"></times><ci id="S3.E2.m1.5.5.1.1.4.2b.cmml" xref="S3.E2.m1.5.5.1.1.4.2"><merror class="ltx_ERROR undefined undefined" id="S3.E2.m1.5.5.1.1.4.2.cmml" xref="S3.E2.m1.5.5.1.1.4.2"><mtext id="S3.E2.m1.5.5.1.1.4.2a.cmml" xref="S3.E2.m1.5.5.1.1.4.2">\diffp</mtext></merror></ci><apply id="S3.E2.m1.5.5.1.1.4.3.cmml" xref="S3.E2.m1.5.5.1.1.4.3"><ci id="S3.E2.m1.5.5.1.1.4.3.1.cmml" xref="S3.E2.m1.5.5.1.1.4.3.1">^</ci><ci id="S3.E2.m1.5.5.1.1.4.3.2.cmml" xref="S3.E2.m1.5.5.1.1.4.3.2">𝐗</ci></apply><ci id="S3.E2.m1.5.5.1.1.4.4.cmml" xref="S3.E2.m1.5.5.1.1.4.4">𝐗</ci></apply><apply id="S3.E2.m1.5.5.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.2"><plus id="S3.E2.m1.5.5.1.1.2.3.cmml" xref="S3.E2.m1.5.5.1.1.2.3"></plus><ci id="S3.E2.m1.5.5.1.1.2.4.cmml" xref="S3.E2.m1.5.5.1.1.2.4">𝐼</ci><apply id="S3.E2.m1.5.5.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1"><times id="S3.E2.m1.5.5.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.1.1.2"></times><apply id="S3.E2.m1.5.5.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1"><compose id="S3.E2.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.2"></compose><apply id="S3.E2.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1"><times id="S3.E2.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.2"></times><ci id="S3.E2.m1.5.5.1.1.1.1.1.1.3b.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3"><merror class="ltx_ERROR undefined undefined" id="S3.E2.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3"><mtext id="S3.E2.m1.5.5.1.1.1.1.1.1.3a.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3">\diffp</mtext></merror></ci><ci id="S3.E2.m1.5.5.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.4">𝜎</ci><apply id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.1.1.1.2">𝑀</ci><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝐗</ci></apply><ci id="S3.E2.m1.5.5.1.1.1.1.1.1.5.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.5">𝐗</ci></apply><ci id="S3.E2.m1.5.5.1.1.1.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.3">𝑅</ci></apply><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝐗</ci></apply><apply id="S3.E2.m1.5.5.1.1.2.2.cmml" xref="S3.E2.m1.5.5.1.1.2.2"><times id="S3.E2.m1.5.5.1.1.2.2.2.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2"></times><apply id="S3.E2.m1.5.5.1.1.2.2.1.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1"><compose id="S3.E2.m1.5.5.1.1.2.2.1.2.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.2"></compose><apply id="S3.E2.m1.5.5.1.1.2.2.1.1.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.1"><times id="S3.E2.m1.5.5.1.1.2.2.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.1.2"></times><ci id="S3.E2.m1.5.5.1.1.2.2.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.1.3">𝜎</ci><apply id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1"><times id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.1"></times><ci id="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.1.1.1.1.2">𝑀</ci><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝐗</ci></apply></apply><ci id="S3.E2.m1.5.5.1.1.2.2.1.3b.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.3"><merror class="ltx_ERROR undefined undefined" id="S3.E2.m1.5.5.1.1.2.2.1.3.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.3"><mtext id="S3.E2.m1.5.5.1.1.2.2.1.3a.cmml" xref="S3.E2.m1.5.5.1.1.2.2.1.3">\diffp</mtext></merror></ci></apply><ci id="S3.E2.m1.5.5.1.1.2.2.3.cmml" xref="S3.E2.m1.5.5.1.1.2.2.3">𝑅</ci><ci id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4">𝐗</ci><ci id="S3.E2.m1.5.5.1.1.2.2.5.cmml" xref="S3.E2.m1.5.5.1.1.2.2.5">𝐗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.5c">\diffp{\hat{\mathbf{X}}}{\mathbf{X}}=I+\diffp{\sigma(M(\mathbf{X}))}{\mathbf{X}}\circ R(\mathbf{X})+\sigma(M(\mathbf{X}))\circ\diffp{R(\mathbf{X})}{\mathbf{X}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.p11" class="ltx_para">
<p id="S3.p11.3" class="ltx_p">Note that the second term includes a derivative of the sigmoid activation, which is nearly zero if the activation is close to one or zero:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.5" class="ltx_Math" alttext="\diffp{\sigma(M(\mathbf{X}))}{\mathbf{X}}=(I-\sigma(M(\mathbf{X})))\sigma(M(\mathbf{X}))\diffp{M(\mathbf{X})}{\mathbf{X}}." display="block"><semantics id="S3.E3.m1.5a"><mrow id="S3.E3.m1.5.5.1" xref="S3.E3.m1.5.5.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1" xref="S3.E3.m1.5.5.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1.1" xref="S3.E3.m1.5.5.1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.E3.m1.5.5.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.3b.cmml"><mtext id="S3.E3.m1.5.5.1.1.1.3a" xref="S3.E3.m1.5.5.1.1.1.3b.cmml">\diffp</mtext></merror><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.2.cmml">​</mo><mi id="S3.E3.m1.5.5.1.1.1.4" xref="S3.E3.m1.5.5.1.1.1.4.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.2a" xref="S3.E3.m1.5.5.1.1.1.2.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">𝐗</mi><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.2b" xref="S3.E3.m1.5.5.1.1.1.2.cmml">​</mo><mi id="S3.E3.m1.5.5.1.1.1.5" xref="S3.E3.m1.5.5.1.1.1.5.cmml">𝐗</mi></mrow><mo id="S3.E3.m1.5.5.1.1.4" xref="S3.E3.m1.5.5.1.1.4.cmml">=</mo><mrow id="S3.E3.m1.5.5.1.1.3" xref="S3.E3.m1.5.5.1.1.3.cmml"><mrow id="S3.E3.m1.5.5.1.1.2.1.1" xref="S3.E3.m1.5.5.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.2.1.1.2" xref="S3.E3.m1.5.5.1.1.2.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.2.1.1.1" xref="S3.E3.m1.5.5.1.1.2.1.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.2.1.1.1.3" xref="S3.E3.m1.5.5.1.1.2.1.1.1.3.cmml">I</mi><mo id="S3.E3.m1.5.5.1.1.2.1.1.1.2" xref="S3.E3.m1.5.5.1.1.2.1.1.1.2.cmml">−</mo><mrow id="S3.E3.m1.5.5.1.1.2.1.1.1.1" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.2.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.2.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.2.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.3.2.1" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">𝐗</mi><mo stretchy="false" id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E3.m1.5.5.1.1.2.1.1.3" xref="S3.E3.m1.5.5.1.1.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.3.3" xref="S3.E3.m1.5.5.1.1.3.3.cmml">​</mo><mi id="S3.E3.m1.5.5.1.1.3.4" xref="S3.E3.m1.5.5.1.1.3.4.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.3.3a" xref="S3.E3.m1.5.5.1.1.3.3.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.3.2.1" xref="S3.E3.m1.5.5.1.1.3.2.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.3.2.1.2" xref="S3.E3.m1.5.5.1.1.3.2.1.1.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.3.2.1.1" xref="S3.E3.m1.5.5.1.1.3.2.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.3.2.1.1.2" xref="S3.E3.m1.5.5.1.1.3.2.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.3.2.1.1.1" xref="S3.E3.m1.5.5.1.1.3.2.1.1.1.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.3.2.1.1.3.2" xref="S3.E3.m1.5.5.1.1.3.2.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.3.2.1.1.3.2.1" xref="S3.E3.m1.5.5.1.1.3.2.1.1.cmml">(</mo><mi id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">𝐗</mi><mo stretchy="false" id="S3.E3.m1.5.5.1.1.3.2.1.1.3.2.2" xref="S3.E3.m1.5.5.1.1.3.2.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.5.5.1.1.3.2.1.3" xref="S3.E3.m1.5.5.1.1.3.2.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.3.3b" xref="S3.E3.m1.5.5.1.1.3.3.cmml">​</mo><merror class="ltx_ERROR undefined undefined" id="S3.E3.m1.5.5.1.1.3.5" xref="S3.E3.m1.5.5.1.1.3.5b.cmml"><mtext id="S3.E3.m1.5.5.1.1.3.5a" xref="S3.E3.m1.5.5.1.1.3.5b.cmml">\diffp</mtext></merror><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.3.3c" xref="S3.E3.m1.5.5.1.1.3.3.cmml">​</mo><mi id="S3.E3.m1.5.5.1.1.3.6" xref="S3.E3.m1.5.5.1.1.3.6.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.3.3d" xref="S3.E3.m1.5.5.1.1.3.3.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.3.7.2" xref="S3.E3.m1.5.5.1.1.3.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.3.7.2.1" xref="S3.E3.m1.5.5.1.1.3.cmml">(</mo><mi id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml">𝐗</mi><mo stretchy="false" id="S3.E3.m1.5.5.1.1.3.7.2.2" xref="S3.E3.m1.5.5.1.1.3.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.3.3e" xref="S3.E3.m1.5.5.1.1.3.3.cmml">​</mo><mi id="S3.E3.m1.5.5.1.1.3.8" xref="S3.E3.m1.5.5.1.1.3.8.cmml">𝐗</mi></mrow></mrow><mo lspace="0em" id="S3.E3.m1.5.5.1.2" xref="S3.E3.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.5b"><apply id="S3.E3.m1.5.5.1.1.cmml" xref="S3.E3.m1.5.5.1"><eq id="S3.E3.m1.5.5.1.1.4.cmml" xref="S3.E3.m1.5.5.1.1.4"></eq><apply id="S3.E3.m1.5.5.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1"><times id="S3.E3.m1.5.5.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.2"></times><ci id="S3.E3.m1.5.5.1.1.1.3b.cmml" xref="S3.E3.m1.5.5.1.1.1.3"><merror class="ltx_ERROR undefined undefined" id="S3.E3.m1.5.5.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.3"><mtext id="S3.E3.m1.5.5.1.1.1.3a.cmml" xref="S3.E3.m1.5.5.1.1.1.3">\diffp</mtext></merror></ci><ci id="S3.E3.m1.5.5.1.1.1.4.cmml" xref="S3.E3.m1.5.5.1.1.1.4">𝜎</ci><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1"><times id="S3.E3.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2">𝑀</ci><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝐗</ci></apply><ci id="S3.E3.m1.5.5.1.1.1.5.cmml" xref="S3.E3.m1.5.5.1.1.1.5">𝐗</ci></apply><apply id="S3.E3.m1.5.5.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.3"><times id="S3.E3.m1.5.5.1.1.3.3.cmml" xref="S3.E3.m1.5.5.1.1.3.3"></times><apply id="S3.E3.m1.5.5.1.1.2.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.2.1.1"><minus id="S3.E3.m1.5.5.1.1.2.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.2.1.1.1.2"></minus><ci id="S3.E3.m1.5.5.1.1.2.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.2.1.1.1.3">𝐼</ci><apply id="S3.E3.m1.5.5.1.1.2.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1"><times id="S3.E3.m1.5.5.1.1.2.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.2"></times><ci id="S3.E3.m1.5.5.1.1.2.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.3">𝜎</ci><apply id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1"><times id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.2.1.1.1.1.1.1.1.2">𝑀</ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝐗</ci></apply></apply></apply><ci id="S3.E3.m1.5.5.1.1.3.4.cmml" xref="S3.E3.m1.5.5.1.1.3.4">𝜎</ci><apply id="S3.E3.m1.5.5.1.1.3.2.1.1.cmml" xref="S3.E3.m1.5.5.1.1.3.2.1"><times id="S3.E3.m1.5.5.1.1.3.2.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.3.2.1.1.1"></times><ci id="S3.E3.m1.5.5.1.1.3.2.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.3.2.1.1.2">𝑀</ci><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">𝐗</ci></apply><ci id="S3.E3.m1.5.5.1.1.3.5b.cmml" xref="S3.E3.m1.5.5.1.1.3.5"><merror class="ltx_ERROR undefined undefined" id="S3.E3.m1.5.5.1.1.3.5.cmml" xref="S3.E3.m1.5.5.1.1.3.5"><mtext id="S3.E3.m1.5.5.1.1.3.5a.cmml" xref="S3.E3.m1.5.5.1.1.3.5">\diffp</mtext></merror></ci><ci id="S3.E3.m1.5.5.1.1.3.6.cmml" xref="S3.E3.m1.5.5.1.1.3.6">𝑀</ci><ci id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4">𝐗</ci><ci id="S3.E3.m1.5.5.1.1.3.8.cmml" xref="S3.E3.m1.5.5.1.1.3.8">𝐗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.5c">\diffp{\sigma(M(\mathbf{X}))}{\mathbf{X}}=(I-\sigma(M(\mathbf{X})))\sigma(M(\mathbf{X}))\diffp{M(\mathbf{X})}{\mathbf{X}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.p11.2" class="ltx_p">Also, <math id="S3.p11.1.m1.1" class="ltx_math_unparsed" alttext="\sigma(M(\mathbf{X})))" display="inline"><semantics id="S3.p11.1.m1.1a"><mrow id="S3.p11.1.m1.1b"><mi id="S3.p11.1.m1.1.2">σ</mi><mrow id="S3.p11.1.m1.1.3"><mo stretchy="false" id="S3.p11.1.m1.1.3.1">(</mo><mi id="S3.p11.1.m1.1.3.2">M</mi><mrow id="S3.p11.1.m1.1.3.3"><mo stretchy="false" id="S3.p11.1.m1.1.3.3.1">(</mo><mi id="S3.p11.1.m1.1.1">𝐗</mi><mo stretchy="false" id="S3.p11.1.m1.1.3.3.2">)</mo></mrow><mo stretchy="false" id="S3.p11.1.m1.1.3.4">)</mo></mrow><mo stretchy="false" id="S3.p11.1.m1.1.4">)</mo></mrow><annotation encoding="application/x-tex" id="S3.p11.1.m1.1c">\sigma(M(\mathbf{X})))</annotation></semantics></math> in the third term of Eq.  <a href="#S3.E2" title="In 3 Analysis of Feature Distortion ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> can mask the derivative from <math id="S3.p11.2.m2.1" class="ltx_Math" alttext="R(\mathbf{X})" display="inline"><semantics id="S3.p11.2.m2.1a"><mrow id="S3.p11.2.m2.1.2" xref="S3.p11.2.m2.1.2.cmml"><mi id="S3.p11.2.m2.1.2.2" xref="S3.p11.2.m2.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.p11.2.m2.1.2.1" xref="S3.p11.2.m2.1.2.1.cmml">​</mo><mrow id="S3.p11.2.m2.1.2.3.2" xref="S3.p11.2.m2.1.2.cmml"><mo stretchy="false" id="S3.p11.2.m2.1.2.3.2.1" xref="S3.p11.2.m2.1.2.cmml">(</mo><mi id="S3.p11.2.m2.1.1" xref="S3.p11.2.m2.1.1.cmml">𝐗</mi><mo stretchy="false" id="S3.p11.2.m2.1.2.3.2.2" xref="S3.p11.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p11.2.m2.1b"><apply id="S3.p11.2.m2.1.2.cmml" xref="S3.p11.2.m2.1.2"><times id="S3.p11.2.m2.1.2.1.cmml" xref="S3.p11.2.m2.1.2.1"></times><ci id="S3.p11.2.m2.1.2.2.cmml" xref="S3.p11.2.m2.1.2.2">𝑅</ci><ci id="S3.p11.2.m2.1.1.cmml" xref="S3.p11.2.m2.1.1">𝐗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p11.2.m2.1c">R(\mathbf{X})</annotation></semantics></math>. From this analysis and empirical findings, we hypothesize that SE-Block is masking gradient from upper layers and promotes robust fine-tuning.</p>
</div>
<div id="S3.p12" class="ltx_para">
<p id="S3.p12.1" class="ltx_p">In summary, in this analysis, we introduce RGN to measure the distortion of the model by fine-tuning, revealing that the large distortion is correlated with lower OOD performance. Also, some backbones lose OOD robustness during fine-tuning, but others gain robustness because their architecture prevents distortion.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Regularization for Robust Fine-tuning</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Given the findings in the previous section, we aim to find a fine-tuning recipe for achieving a robust object detector.
In the previous section, we have seen that large RGN distorts features of the pre-trained model, and SE-Block can effectively reduce the amount of gradient. In addition, DP-FT boosts OOD performance compared to FT.
We build two techniques inspired by these observations on top of DP-FT.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2303.14744/assets/x10.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="225" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Illustration of decoder-probing with SE-Block and (left) and its fine-tuning (right).</span></figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T3.2.1" class="ltx_tr">
<td id="S4.T3.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T3.2.1.1.1" class="ltx_text">Backbone</span></td>
<td id="S4.T3.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T3.2.1.2.1" class="ltx_text">Method</span></td>
<td id="S4.T3.2.1.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="4">ID: Pascal</td>
<td id="S4.T3.2.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">ID: Cityscapes</td>
</tr>
<tr id="S4.T3.2.2" class="ltx_tr">
<td id="S4.T3.2.2.1" class="ltx_td ltx_align_center ltx_border_r">Comic</td>
<td id="S4.T3.2.2.2" class="ltx_td ltx_align_center ltx_border_r">Watercolor</td>
<td id="S4.T3.2.2.3" class="ltx_td ltx_align_center ltx_border_r">Clipart</td>
<td id="S4.T3.2.2.4" class="ltx_td ltx_align_center ltx_border_rr">ID</td>
<td id="S4.T3.2.2.5" class="ltx_td ltx_align_center ltx_border_r">Foggy</td>
<td id="S4.T3.2.2.6" class="ltx_td ltx_align_center ltx_border_r">BDD</td>
<td id="S4.T3.2.2.7" class="ltx_td ltx_align_center">ID</td>
</tr>
<tr id="S4.T3.2.3" class="ltx_tr">
<td id="S4.T3.2.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T3.2.3.1.1" class="ltx_text">ResNet50 Instagram <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span></td>
<td id="S4.T3.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DP</td>
<td id="S4.T3.2.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.7</td>
<td id="S4.T3.2.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">21.2</td>
<td id="S4.T3.2.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.3</td>
<td id="S4.T3.2.3.6" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">44.6</td>
<td id="S4.T3.2.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13.9</td>
<td id="S4.T3.2.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">7.7</td>
<td id="S4.T3.2.3.9" class="ltx_td ltx_align_center ltx_border_t">28.3</td>
</tr>
<tr id="S4.T3.2.4" class="ltx_tr">
<td id="S4.T3.2.4.1" class="ltx_td ltx_align_center ltx_border_r">FT</td>
<td id="S4.T3.2.4.2" class="ltx_td ltx_align_center ltx_border_r">7.5</td>
<td id="S4.T3.2.4.3" class="ltx_td ltx_align_center ltx_border_r">19.4</td>
<td id="S4.T3.2.4.4" class="ltx_td ltx_align_center ltx_border_r">11.4</td>
<td id="S4.T3.2.4.5" class="ltx_td ltx_align_center ltx_border_rr">50.4</td>
<td id="S4.T3.2.4.6" class="ltx_td ltx_align_center ltx_border_r">12.8</td>
<td id="S4.T3.2.4.7" class="ltx_td ltx_align_center ltx_border_r">5.1</td>
<td id="S4.T3.2.4.8" class="ltx_td ltx_align_center">33.5</td>
</tr>
<tr id="S4.T3.2.5" class="ltx_tr">
<td id="S4.T3.2.5.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.5.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT</span></td>
<td id="S4.T3.2.5.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.5.2.1" class="ltx_text" style="background-color:#F2F2F2;">9.1</span></td>
<td id="S4.T3.2.5.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.5.3.1" class="ltx_text" style="background-color:#F2F2F2;">21.0</span></td>
<td id="S4.T3.2.5.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.5.4.1" class="ltx_text" style="background-color:#F2F2F2;">12.9</span></td>
<td id="S4.T3.2.5.5" class="ltx_td ltx_align_center ltx_border_rr" style="background-color:#F2F2F2;"><span id="S4.T3.2.5.5.1" class="ltx_text" style="background-color:#F2F2F2;">52.6</span></td>
<td id="S4.T3.2.5.6" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.5.6.1" class="ltx_text" style="background-color:#F2F2F2;">14.8</span></td>
<td id="S4.T3.2.5.7" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.5.7.1" class="ltx_text" style="background-color:#F2F2F2;">5.5</span></td>
<td id="S4.T3.2.5.8" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T3.2.5.8.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">34.7</span></td>
</tr>
<tr id="S4.T3.2.6" class="ltx_tr">
<td id="S4.T3.2.6.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.6.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT + WR</span></td>
<td id="S4.T3.2.6.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.6.2.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">16.8</span></td>
<td id="S4.T3.2.6.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.6.3.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">26.5</span></td>
<td id="S4.T3.2.6.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.6.4.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">17.6</span></td>
<td id="S4.T3.2.6.5" class="ltx_td ltx_align_center ltx_border_rr" style="background-color:#F2F2F2;"><span id="S4.T3.2.6.5.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">52.9</span></td>
<td id="S4.T3.2.6.6" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.6.6.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">19.3</span></td>
<td id="S4.T3.2.6.7" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.6.7.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">9.6</span></td>
<td id="S4.T3.2.6.8" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T3.2.6.8.1" class="ltx_text" style="background-color:#F2F2F2;">34.5</span></td>
</tr>
<tr id="S4.T3.2.7" class="ltx_tr">
<td id="S4.T3.2.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T3.2.7.1.1" class="ltx_text">ConvNeXt IN21K <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite></span></td>
<td id="S4.T3.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DP</td>
<td id="S4.T3.2.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.7</td>
<td id="S4.T3.2.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17.3</td>
<td id="S4.T3.2.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14.0</td>
<td id="S4.T3.2.7.6" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">39.7</td>
<td id="S4.T3.2.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14.7</td>
<td id="S4.T3.2.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">7.8</td>
<td id="S4.T3.2.7.9" class="ltx_td ltx_align_center ltx_border_t">31.1</td>
</tr>
<tr id="S4.T3.2.8" class="ltx_tr">
<td id="S4.T3.2.8.1" class="ltx_td ltx_align_center ltx_border_r">FT</td>
<td id="S4.T3.2.8.2" class="ltx_td ltx_align_center ltx_border_r">11.5</td>
<td id="S4.T3.2.8.3" class="ltx_td ltx_align_center ltx_border_r">22.9</td>
<td id="S4.T3.2.8.4" class="ltx_td ltx_align_center ltx_border_r">16.8</td>
<td id="S4.T3.2.8.5" class="ltx_td ltx_align_center ltx_border_rr">60.6</td>
<td id="S4.T3.2.8.6" class="ltx_td ltx_align_center ltx_border_r">18.1</td>
<td id="S4.T3.2.8.7" class="ltx_td ltx_align_center ltx_border_r">9.7</td>
<td id="S4.T3.2.8.8" class="ltx_td ltx_align_center">35.8</td>
</tr>
<tr id="S4.T3.2.9" class="ltx_tr">
<td id="S4.T3.2.9.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.9.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT</span></td>
<td id="S4.T3.2.9.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.9.2.1" class="ltx_text" style="background-color:#F2F2F2;">13.6</span></td>
<td id="S4.T3.2.9.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.9.3.1" class="ltx_text" style="background-color:#F2F2F2;">24.7</span></td>
<td id="S4.T3.2.9.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.9.4.1" class="ltx_text" style="background-color:#F2F2F2;">19.1</span></td>
<td id="S4.T3.2.9.5" class="ltx_td ltx_align_center ltx_border_rr" style="background-color:#F2F2F2;"><span id="S4.T3.2.9.5.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">62.3</span></td>
<td id="S4.T3.2.9.6" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.9.6.1" class="ltx_text" style="background-color:#F2F2F2;">20.5</span></td>
<td id="S4.T3.2.9.7" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.9.7.1" class="ltx_text" style="background-color:#F2F2F2;">11.5</span></td>
<td id="S4.T3.2.9.8" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T3.2.9.8.1" class="ltx_text" style="background-color:#F2F2F2;">37.1</span></td>
</tr>
<tr id="S4.T3.2.10" class="ltx_tr">
<td id="S4.T3.2.10.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.10.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT + WR</span></td>
<td id="S4.T3.2.10.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.10.2.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">14.6</span></td>
<td id="S4.T3.2.10.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.10.3.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">27.8</span></td>
<td id="S4.T3.2.10.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.10.4.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">19.7</span></td>
<td id="S4.T3.2.10.5" class="ltx_td ltx_align_center ltx_border_rr" style="background-color:#F2F2F2;"><span id="S4.T3.2.10.5.1" class="ltx_text" style="background-color:#F2F2F2;">61.4</span></td>
<td id="S4.T3.2.10.6" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.10.6.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">21.1</span></td>
<td id="S4.T3.2.10.7" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.10.7.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">11.7</span></td>
<td id="S4.T3.2.10.8" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T3.2.10.8.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">37.2</span></td>
</tr>
<tr id="S4.T3.2.11" class="ltx_tr">
<td id="S4.T3.2.11.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T3.2.11.1.1" class="ltx_text">Eff-B2 JFT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite></span></td>
<td id="S4.T3.2.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DP</td>
<td id="S4.T3.2.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">12.6</td>
<td id="S4.T3.2.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.4</td>
<td id="S4.T3.2.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.1</td>
<td id="S4.T3.2.11.6" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">40.2</td>
<td id="S4.T3.2.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.1</td>
<td id="S4.T3.2.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.9</td>
<td id="S4.T3.2.11.9" class="ltx_td ltx_align_center ltx_border_t">25.2</td>
</tr>
<tr id="S4.T3.2.12" class="ltx_tr">
<td id="S4.T3.2.12.1" class="ltx_td ltx_align_center ltx_border_r">FT</td>
<td id="S4.T3.2.12.2" class="ltx_td ltx_align_center ltx_border_r">17.1</td>
<td id="S4.T3.2.12.3" class="ltx_td ltx_align_center ltx_border_r">27.2</td>
<td id="S4.T3.2.12.4" class="ltx_td ltx_align_center ltx_border_r">18.0</td>
<td id="S4.T3.2.12.5" class="ltx_td ltx_align_center ltx_border_rr">53.4</td>
<td id="S4.T3.2.12.6" class="ltx_td ltx_align_center ltx_border_r">10.7</td>
<td id="S4.T3.2.12.7" class="ltx_td ltx_align_center ltx_border_r">5.1</td>
<td id="S4.T3.2.12.8" class="ltx_td ltx_align_center">31.5</td>
</tr>
<tr id="S4.T3.2.13" class="ltx_tr">
<td id="S4.T3.2.13.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.13.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT</span></td>
<td id="S4.T3.2.13.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.13.2.1" class="ltx_text" style="background-color:#F2F2F2;">17.4</span></td>
<td id="S4.T3.2.13.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.13.3.1" class="ltx_text" style="background-color:#F2F2F2;">29.4</span></td>
<td id="S4.T3.2.13.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.13.4.1" class="ltx_text" style="background-color:#F2F2F2;">20.7</span></td>
<td id="S4.T3.2.13.5" class="ltx_td ltx_align_center ltx_border_rr" style="background-color:#F2F2F2;"><span id="S4.T3.2.13.5.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">55.3</span></td>
<td id="S4.T3.2.13.6" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.13.6.1" class="ltx_text" style="background-color:#F2F2F2;">12.9</span></td>
<td id="S4.T3.2.13.7" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.13.7.1" class="ltx_text" style="background-color:#F2F2F2;">7.3</span></td>
<td id="S4.T3.2.13.8" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T3.2.13.8.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">32.9</span></td>
</tr>
<tr id="S4.T3.2.14" class="ltx_tr">
<td id="S4.T3.2.14.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.14.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT + WR</span></td>
<td id="S4.T3.2.14.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.14.2.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">19.5</span></td>
<td id="S4.T3.2.14.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.14.3.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">30.0</span></td>
<td id="S4.T3.2.14.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.14.4.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">22.0</span></td>
<td id="S4.T3.2.14.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr" style="background-color:#F2F2F2;"><span id="S4.T3.2.14.5.1" class="ltx_text" style="background-color:#F2F2F2;">54.2</span></td>
<td id="S4.T3.2.14.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.14.6.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">13.5</span></td>
<td id="S4.T3.2.14.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.2.14.7.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">7.6</span></td>
<td id="S4.T3.2.14.8" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F2F2F2;"><span id="S4.T3.2.14.8.1" class="ltx_text" style="background-color:#F2F2F2;">32.5</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.3.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.4.2" class="ltx_text" style="font-size:90%;">Effect of weight regularization. DP, FT, and WR denote decoder-probing, fine-tuning, and weight regularization.</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Weight Regularization</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Our analysis shows that RGN is a key factor in losing generalizability. To reduce RGN and incorporate an explicit inductive bias of a pre-trained model, we investigate the effect of introducing the distance from the initial value as a regularizer, which we denote <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\Omega(w)" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.2" xref="S4.SS1.p1.1.m1.1.2.cmml"><mi mathvariant="normal" id="S4.SS1.p1.1.m1.1.2.2" xref="S4.SS1.p1.1.m1.1.2.2.cmml">Ω</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.1.2.1" xref="S4.SS1.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S4.SS1.p1.1.m1.1.2.3.2" xref="S4.SS1.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S4.SS1.p1.1.m1.1.2.3.2.1" xref="S4.SS1.p1.1.m1.1.2.cmml">(</mo><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S4.SS1.p1.1.m1.1.2.3.2.2" xref="S4.SS1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.2"><times id="S4.SS1.p1.1.m1.1.2.1.cmml" xref="S4.SS1.p1.1.m1.1.2.1"></times><ci id="S4.SS1.p1.1.m1.1.2.2.cmml" xref="S4.SS1.p1.1.m1.1.2.2">Ω</ci><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\Omega(w)</annotation></semantics></math>, and optimize it with detection loss as follows:</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.4" class="ltx_Math" alttext="L(w)=L_{det}(w)+\lambda\Omega(w)," display="block"><semantics id="S4.E4.m1.4a"><mrow id="S4.E4.m1.4.4.1" xref="S4.E4.m1.4.4.1.1.cmml"><mrow id="S4.E4.m1.4.4.1.1" xref="S4.E4.m1.4.4.1.1.cmml"><mrow id="S4.E4.m1.4.4.1.1.2" xref="S4.E4.m1.4.4.1.1.2.cmml"><mi id="S4.E4.m1.4.4.1.1.2.2" xref="S4.E4.m1.4.4.1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.1.1.2.1" xref="S4.E4.m1.4.4.1.1.2.1.cmml">​</mo><mrow id="S4.E4.m1.4.4.1.1.2.3.2" xref="S4.E4.m1.4.4.1.1.2.cmml"><mo stretchy="false" id="S4.E4.m1.4.4.1.1.2.3.2.1" xref="S4.E4.m1.4.4.1.1.2.cmml">(</mo><mi id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml">w</mi><mo stretchy="false" id="S4.E4.m1.4.4.1.1.2.3.2.2" xref="S4.E4.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.4.4.1.1.1" xref="S4.E4.m1.4.4.1.1.1.cmml">=</mo><mrow id="S4.E4.m1.4.4.1.1.3" xref="S4.E4.m1.4.4.1.1.3.cmml"><mrow id="S4.E4.m1.4.4.1.1.3.2" xref="S4.E4.m1.4.4.1.1.3.2.cmml"><msub id="S4.E4.m1.4.4.1.1.3.2.2" xref="S4.E4.m1.4.4.1.1.3.2.2.cmml"><mi id="S4.E4.m1.4.4.1.1.3.2.2.2" xref="S4.E4.m1.4.4.1.1.3.2.2.2.cmml">L</mi><mrow id="S4.E4.m1.4.4.1.1.3.2.2.3" xref="S4.E4.m1.4.4.1.1.3.2.2.3.cmml"><mi id="S4.E4.m1.4.4.1.1.3.2.2.3.2" xref="S4.E4.m1.4.4.1.1.3.2.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.1.1.3.2.2.3.1" xref="S4.E4.m1.4.4.1.1.3.2.2.3.1.cmml">​</mo><mi id="S4.E4.m1.4.4.1.1.3.2.2.3.3" xref="S4.E4.m1.4.4.1.1.3.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.1.1.3.2.2.3.1a" xref="S4.E4.m1.4.4.1.1.3.2.2.3.1.cmml">​</mo><mi id="S4.E4.m1.4.4.1.1.3.2.2.3.4" xref="S4.E4.m1.4.4.1.1.3.2.2.3.4.cmml">t</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.1.1.3.2.1" xref="S4.E4.m1.4.4.1.1.3.2.1.cmml">​</mo><mrow id="S4.E4.m1.4.4.1.1.3.2.3.2" xref="S4.E4.m1.4.4.1.1.3.2.cmml"><mo stretchy="false" id="S4.E4.m1.4.4.1.1.3.2.3.2.1" xref="S4.E4.m1.4.4.1.1.3.2.cmml">(</mo><mi id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml">w</mi><mo stretchy="false" id="S4.E4.m1.4.4.1.1.3.2.3.2.2" xref="S4.E4.m1.4.4.1.1.3.2.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.4.4.1.1.3.1" xref="S4.E4.m1.4.4.1.1.3.1.cmml">+</mo><mrow id="S4.E4.m1.4.4.1.1.3.3" xref="S4.E4.m1.4.4.1.1.3.3.cmml"><mi id="S4.E4.m1.4.4.1.1.3.3.2" xref="S4.E4.m1.4.4.1.1.3.3.2.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.1.1.3.3.1" xref="S4.E4.m1.4.4.1.1.3.3.1.cmml">​</mo><mi mathvariant="normal" id="S4.E4.m1.4.4.1.1.3.3.3" xref="S4.E4.m1.4.4.1.1.3.3.3.cmml">Ω</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.1.1.3.3.1a" xref="S4.E4.m1.4.4.1.1.3.3.1.cmml">​</mo><mrow id="S4.E4.m1.4.4.1.1.3.3.4.2" xref="S4.E4.m1.4.4.1.1.3.3.cmml"><mo stretchy="false" id="S4.E4.m1.4.4.1.1.3.3.4.2.1" xref="S4.E4.m1.4.4.1.1.3.3.cmml">(</mo><mi id="S4.E4.m1.3.3" xref="S4.E4.m1.3.3.cmml">w</mi><mo stretchy="false" id="S4.E4.m1.4.4.1.1.3.3.4.2.2" xref="S4.E4.m1.4.4.1.1.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E4.m1.4.4.1.2" xref="S4.E4.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.4b"><apply id="S4.E4.m1.4.4.1.1.cmml" xref="S4.E4.m1.4.4.1"><eq id="S4.E4.m1.4.4.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.1"></eq><apply id="S4.E4.m1.4.4.1.1.2.cmml" xref="S4.E4.m1.4.4.1.1.2"><times id="S4.E4.m1.4.4.1.1.2.1.cmml" xref="S4.E4.m1.4.4.1.1.2.1"></times><ci id="S4.E4.m1.4.4.1.1.2.2.cmml" xref="S4.E4.m1.4.4.1.1.2.2">𝐿</ci><ci id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1">𝑤</ci></apply><apply id="S4.E4.m1.4.4.1.1.3.cmml" xref="S4.E4.m1.4.4.1.1.3"><plus id="S4.E4.m1.4.4.1.1.3.1.cmml" xref="S4.E4.m1.4.4.1.1.3.1"></plus><apply id="S4.E4.m1.4.4.1.1.3.2.cmml" xref="S4.E4.m1.4.4.1.1.3.2"><times id="S4.E4.m1.4.4.1.1.3.2.1.cmml" xref="S4.E4.m1.4.4.1.1.3.2.1"></times><apply id="S4.E4.m1.4.4.1.1.3.2.2.cmml" xref="S4.E4.m1.4.4.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.1.1.3.2.2.1.cmml" xref="S4.E4.m1.4.4.1.1.3.2.2">subscript</csymbol><ci id="S4.E4.m1.4.4.1.1.3.2.2.2.cmml" xref="S4.E4.m1.4.4.1.1.3.2.2.2">𝐿</ci><apply id="S4.E4.m1.4.4.1.1.3.2.2.3.cmml" xref="S4.E4.m1.4.4.1.1.3.2.2.3"><times id="S4.E4.m1.4.4.1.1.3.2.2.3.1.cmml" xref="S4.E4.m1.4.4.1.1.3.2.2.3.1"></times><ci id="S4.E4.m1.4.4.1.1.3.2.2.3.2.cmml" xref="S4.E4.m1.4.4.1.1.3.2.2.3.2">𝑑</ci><ci id="S4.E4.m1.4.4.1.1.3.2.2.3.3.cmml" xref="S4.E4.m1.4.4.1.1.3.2.2.3.3">𝑒</ci><ci id="S4.E4.m1.4.4.1.1.3.2.2.3.4.cmml" xref="S4.E4.m1.4.4.1.1.3.2.2.3.4">𝑡</ci></apply></apply><ci id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2">𝑤</ci></apply><apply id="S4.E4.m1.4.4.1.1.3.3.cmml" xref="S4.E4.m1.4.4.1.1.3.3"><times id="S4.E4.m1.4.4.1.1.3.3.1.cmml" xref="S4.E4.m1.4.4.1.1.3.3.1"></times><ci id="S4.E4.m1.4.4.1.1.3.3.2.cmml" xref="S4.E4.m1.4.4.1.1.3.3.2">𝜆</ci><ci id="S4.E4.m1.4.4.1.1.3.3.3.cmml" xref="S4.E4.m1.4.4.1.1.3.3.3">Ω</ci><ci id="S4.E4.m1.3.3.cmml" xref="S4.E4.m1.3.3">𝑤</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.4c">L(w)=L_{det}(w)+\lambda\Omega(w),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p2.2" class="ltx_p">where <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="L_{det}(w)" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.2" xref="S4.SS1.p2.1.m1.1.2.cmml"><msub id="S4.SS1.p2.1.m1.1.2.2" xref="S4.SS1.p2.1.m1.1.2.2.cmml"><mi id="S4.SS1.p2.1.m1.1.2.2.2" xref="S4.SS1.p2.1.m1.1.2.2.2.cmml">L</mi><mrow id="S4.SS1.p2.1.m1.1.2.2.3" xref="S4.SS1.p2.1.m1.1.2.2.3.cmml"><mi id="S4.SS1.p2.1.m1.1.2.2.3.2" xref="S4.SS1.p2.1.m1.1.2.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.2.2.3.1" xref="S4.SS1.p2.1.m1.1.2.2.3.1.cmml">​</mo><mi id="S4.SS1.p2.1.m1.1.2.2.3.3" xref="S4.SS1.p2.1.m1.1.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.2.2.3.1a" xref="S4.SS1.p2.1.m1.1.2.2.3.1.cmml">​</mo><mi id="S4.SS1.p2.1.m1.1.2.2.3.4" xref="S4.SS1.p2.1.m1.1.2.2.3.4.cmml">t</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.2.1" xref="S4.SS1.p2.1.m1.1.2.1.cmml">​</mo><mrow id="S4.SS1.p2.1.m1.1.2.3.2" xref="S4.SS1.p2.1.m1.1.2.cmml"><mo stretchy="false" id="S4.SS1.p2.1.m1.1.2.3.2.1" xref="S4.SS1.p2.1.m1.1.2.cmml">(</mo><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S4.SS1.p2.1.m1.1.2.3.2.2" xref="S4.SS1.p2.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.2"><times id="S4.SS1.p2.1.m1.1.2.1.cmml" xref="S4.SS1.p2.1.m1.1.2.1"></times><apply id="S4.SS1.p2.1.m1.1.2.2.cmml" xref="S4.SS1.p2.1.m1.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.2.2.1.cmml" xref="S4.SS1.p2.1.m1.1.2.2">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.2.2.2.cmml" xref="S4.SS1.p2.1.m1.1.2.2.2">𝐿</ci><apply id="S4.SS1.p2.1.m1.1.2.2.3.cmml" xref="S4.SS1.p2.1.m1.1.2.2.3"><times id="S4.SS1.p2.1.m1.1.2.2.3.1.cmml" xref="S4.SS1.p2.1.m1.1.2.2.3.1"></times><ci id="S4.SS1.p2.1.m1.1.2.2.3.2.cmml" xref="S4.SS1.p2.1.m1.1.2.2.3.2">𝑑</ci><ci id="S4.SS1.p2.1.m1.1.2.2.3.3.cmml" xref="S4.SS1.p2.1.m1.1.2.2.3.3">𝑒</ci><ci id="S4.SS1.p2.1.m1.1.2.2.3.4.cmml" xref="S4.SS1.p2.1.m1.1.2.2.3.4">𝑡</ci></apply></apply><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">L_{det}(w)</annotation></semantics></math> denotes the loss of object detection. Note that the decoder modules are trained without regularization.
There are several options for <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\Omega(w)" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.2" xref="S4.SS1.p2.2.m2.1.2.cmml"><mi mathvariant="normal" id="S4.SS1.p2.2.m2.1.2.2" xref="S4.SS1.p2.2.m2.1.2.2.cmml">Ω</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.2.1" xref="S4.SS1.p2.2.m2.1.2.1.cmml">​</mo><mrow id="S4.SS1.p2.2.m2.1.2.3.2" xref="S4.SS1.p2.2.m2.1.2.cmml"><mo stretchy="false" id="S4.SS1.p2.2.m2.1.2.3.2.1" xref="S4.SS1.p2.2.m2.1.2.cmml">(</mo><mi id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">w</mi><mo stretchy="false" id="S4.SS1.p2.2.m2.1.2.3.2.2" xref="S4.SS1.p2.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.2.cmml" xref="S4.SS1.p2.2.m2.1.2"><times id="S4.SS1.p2.2.m2.1.2.1.cmml" xref="S4.SS1.p2.2.m2.1.2.1"></times><ci id="S4.SS1.p2.2.m2.1.2.2.cmml" xref="S4.SS1.p2.2.m2.1.2.2">Ω</ci><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\Omega(w)</annotation></semantics></math> as indicated by previous work on transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="L^{2}" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><msup id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mi id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">L</mi><mn id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S4.SS1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">L^{2}</annotation></semantics></math><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold"> penalty.</span>
One simple option for the distance function is the L2 distance,</p>
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E5.m1.2" class="ltx_Math" alttext="\Omega(w)=\sum_{i}\lVert w_{i}-{w_{i}}^{pre}\rVert^{2}." display="block"><semantics id="S4.E5.m1.2a"><mrow id="S4.E5.m1.2.2.1" xref="S4.E5.m1.2.2.1.1.cmml"><mrow id="S4.E5.m1.2.2.1.1" xref="S4.E5.m1.2.2.1.1.cmml"><mrow id="S4.E5.m1.2.2.1.1.3" xref="S4.E5.m1.2.2.1.1.3.cmml"><mi mathvariant="normal" id="S4.E5.m1.2.2.1.1.3.2" xref="S4.E5.m1.2.2.1.1.3.2.cmml">Ω</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.3.1" xref="S4.E5.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S4.E5.m1.2.2.1.1.3.3.2" xref="S4.E5.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S4.E5.m1.2.2.1.1.3.3.2.1" xref="S4.E5.m1.2.2.1.1.3.cmml">(</mo><mi id="S4.E5.m1.1.1" xref="S4.E5.m1.1.1.cmml">w</mi><mo stretchy="false" id="S4.E5.m1.2.2.1.1.3.3.2.2" xref="S4.E5.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S4.E5.m1.2.2.1.1.2" xref="S4.E5.m1.2.2.1.1.2.cmml">=</mo><mrow id="S4.E5.m1.2.2.1.1.1" xref="S4.E5.m1.2.2.1.1.1.cmml"><munder id="S4.E5.m1.2.2.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S4.E5.m1.2.2.1.1.1.2.2" xref="S4.E5.m1.2.2.1.1.1.2.2.cmml">∑</mo><mi id="S4.E5.m1.2.2.1.1.1.2.3" xref="S4.E5.m1.2.2.1.1.1.2.3.cmml">i</mi></munder><msup id="S4.E5.m1.2.2.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.cmml"><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.1.2.cmml"><mo fence="true" lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.1.1.2.1.cmml">∥</mo><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S4.E5.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">w</mi><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml">−</mo><mmultiscripts id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.2" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.2.cmml">w</mi><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.3.cmml">i</mi><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3a" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml"></mrow><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3b" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml"></mrow><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.2" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.1" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.1a" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.4" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.4.cmml">e</mi></mrow></mmultiscripts></mrow><mo fence="true" lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.3" xref="S4.E5.m1.2.2.1.1.1.1.1.2.1.cmml">∥</mo></mrow><mn id="S4.E5.m1.2.2.1.1.1.1.3" xref="S4.E5.m1.2.2.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow><mo lspace="0em" id="S4.E5.m1.2.2.1.2" xref="S4.E5.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.2b"><apply id="S4.E5.m1.2.2.1.1.cmml" xref="S4.E5.m1.2.2.1"><eq id="S4.E5.m1.2.2.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.2"></eq><apply id="S4.E5.m1.2.2.1.1.3.cmml" xref="S4.E5.m1.2.2.1.1.3"><times id="S4.E5.m1.2.2.1.1.3.1.cmml" xref="S4.E5.m1.2.2.1.1.3.1"></times><ci id="S4.E5.m1.2.2.1.1.3.2.cmml" xref="S4.E5.m1.2.2.1.1.3.2">Ω</ci><ci id="S4.E5.m1.1.1.cmml" xref="S4.E5.m1.1.1">𝑤</ci></apply><apply id="S4.E5.m1.2.2.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1"><apply id="S4.E5.m1.2.2.1.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.1.2.1.cmml" xref="S4.E5.m1.2.2.1.1.1.2">subscript</csymbol><sum id="S4.E5.m1.2.2.1.1.1.2.2.cmml" xref="S4.E5.m1.2.2.1.1.1.2.2"></sum><ci id="S4.E5.m1.2.2.1.1.1.2.3.cmml" xref="S4.E5.m1.2.2.1.1.1.2.3">𝑖</ci></apply><apply id="S4.E5.m1.2.2.1.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1">superscript</csymbol><apply id="S4.E5.m1.2.2.1.1.1.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E5.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.2">delimited-∥∥</csymbol><apply id="S4.E5.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1"><minus id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1"></minus><apply id="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.2">𝑤</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.2">𝑤</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply><apply id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3"><times id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.1"></times><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.2">𝑝</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.3">𝑟</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.4.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.3.4">𝑒</ci></apply></apply></apply></apply><cn type="integer" id="S4.E5.m1.2.2.1.1.1.1.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.2c">\Omega(w)=\sum_{i}\lVert w_{i}-{w_{i}}^{pre}\rVert^{2}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p3.2" class="ltx_p">The distance looks naive, yet it empirically works well to preserve robustness to OOD.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.2" class="ltx_p"><math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="L^{2}" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><msup id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml"><mi id="S4.SS1.p4.1.m1.1.1.2" xref="S4.SS1.p4.1.m1.1.1.2.cmml">L</mi><mn id="S4.SS1.p4.1.m1.1.1.3" xref="S4.SS1.p4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><apply id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.1.m1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p4.1.m1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S4.SS1.p4.1.m1.1.1.3.cmml" xref="S4.SS1.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">L^{2}</annotation></semantics></math><span id="S4.SS1.p4.2.1" class="ltx_text ltx_font_bold"> penalty weighted by RGN.</span>
We also study weighting the <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="L^{2}" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><msup id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml"><mi id="S4.SS1.p4.2.m2.1.1.2" xref="S4.SS1.p4.2.m2.1.1.2.cmml">L</mi><mn id="S4.SS1.p4.2.m2.1.1.3" xref="S4.SS1.p4.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><apply id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.2.m2.1.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.p4.2.m2.1.1.2.cmml" xref="S4.SS1.p4.2.m2.1.1.2">𝐿</ci><cn type="integer" id="S4.SS1.p4.2.m2.1.1.3.cmml" xref="S4.SS1.p4.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">L^{2}</annotation></semantics></math> penalty by RGN:</p>
<table id="S4.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E6.m1.2" class="ltx_Math" alttext="\Omega(w)=\sum_{i}{{\mathbf{RGN}}_{i}}\lVert w_{i}-{w_{i}}^{pre}\rVert^{2}," display="block"><semantics id="S4.E6.m1.2a"><mrow id="S4.E6.m1.2.2.1" xref="S4.E6.m1.2.2.1.1.cmml"><mrow id="S4.E6.m1.2.2.1.1" xref="S4.E6.m1.2.2.1.1.cmml"><mrow id="S4.E6.m1.2.2.1.1.3" xref="S4.E6.m1.2.2.1.1.3.cmml"><mi mathvariant="normal" id="S4.E6.m1.2.2.1.1.3.2" xref="S4.E6.m1.2.2.1.1.3.2.cmml">Ω</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.2.2.1.1.3.1" xref="S4.E6.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S4.E6.m1.2.2.1.1.3.3.2" xref="S4.E6.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S4.E6.m1.2.2.1.1.3.3.2.1" xref="S4.E6.m1.2.2.1.1.3.cmml">(</mo><mi id="S4.E6.m1.1.1" xref="S4.E6.m1.1.1.cmml">w</mi><mo stretchy="false" id="S4.E6.m1.2.2.1.1.3.3.2.2" xref="S4.E6.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S4.E6.m1.2.2.1.1.2" xref="S4.E6.m1.2.2.1.1.2.cmml">=</mo><mrow id="S4.E6.m1.2.2.1.1.1" xref="S4.E6.m1.2.2.1.1.1.cmml"><munder id="S4.E6.m1.2.2.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.2.cmml"><mo movablelimits="false" id="S4.E6.m1.2.2.1.1.1.2.2" xref="S4.E6.m1.2.2.1.1.1.2.2.cmml">∑</mo><mi id="S4.E6.m1.2.2.1.1.1.2.3" xref="S4.E6.m1.2.2.1.1.1.2.3.cmml">i</mi></munder><mrow id="S4.E6.m1.2.2.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.cmml"><msub id="S4.E6.m1.2.2.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.3.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.3.2" xref="S4.E6.m1.2.2.1.1.1.1.3.2.cmml">𝐑𝐆𝐍</mi><mi id="S4.E6.m1.2.2.1.1.1.1.3.3" xref="S4.E6.m1.2.2.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.E6.m1.2.2.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.2.cmml">​</mo><msup id="S4.E6.m1.2.2.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.cmml"><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.2.cmml"><mo fence="true" rspace="0em" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.2.1.cmml">∥</mo><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml">w</mi><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.cmml">−</mo><mmultiscripts id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml">w</mi><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml">i</mi><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3a" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"></mrow><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3b" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"></mrow><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.1a" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.4" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.4.cmml">e</mi></mrow></mmultiscripts></mrow><mo fence="true" lspace="0em" rspace="0em" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.2.1.cmml">∥</mo></mrow><mn id="S4.E6.m1.2.2.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><mo id="S4.E6.m1.2.2.1.2" xref="S4.E6.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.2b"><apply id="S4.E6.m1.2.2.1.1.cmml" xref="S4.E6.m1.2.2.1"><eq id="S4.E6.m1.2.2.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.2"></eq><apply id="S4.E6.m1.2.2.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.3"><times id="S4.E6.m1.2.2.1.1.3.1.cmml" xref="S4.E6.m1.2.2.1.1.3.1"></times><ci id="S4.E6.m1.2.2.1.1.3.2.cmml" xref="S4.E6.m1.2.2.1.1.3.2">Ω</ci><ci id="S4.E6.m1.1.1.cmml" xref="S4.E6.m1.1.1">𝑤</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1"><apply id="S4.E6.m1.2.2.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.2.1.cmml" xref="S4.E6.m1.2.2.1.1.1.2">subscript</csymbol><sum id="S4.E6.m1.2.2.1.1.1.2.2.cmml" xref="S4.E6.m1.2.2.1.1.1.2.2"></sum><ci id="S4.E6.m1.2.2.1.1.1.2.3.cmml" xref="S4.E6.m1.2.2.1.1.1.2.3">𝑖</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1"><times id="S4.E6.m1.2.2.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.2"></times><apply id="S4.E6.m1.2.2.1.1.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.1.3.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S4.E6.m1.2.2.1.1.1.1.3.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.3.2">𝐑𝐆𝐍</ci><ci id="S4.E6.m1.2.2.1.1.1.1.3.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.3.3">𝑖</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1">superscript</csymbol><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E6.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.2">delimited-∥∥</csymbol><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1"><minus id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.2">𝑤</ci><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.2">𝑤</ci><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3"><times id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.2">𝑝</ci><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.3">𝑟</ci><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.3.4">𝑒</ci></apply></apply></apply></apply><cn type="integer" id="S4.E6.m1.2.2.1.1.1.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.2c">\Omega(w)=\sum_{i}{{\mathbf{RGN}}_{i}}\lVert w_{i}-{w_{i}}^{pre}\rVert^{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p4.4" class="ltx_p">where <math id="S4.SS1.p4.3.m1.1" class="ltx_Math" alttext="\mathbf{RGN}_{i}" display="inline"><semantics id="S4.SS1.p4.3.m1.1a"><msub id="S4.SS1.p4.3.m1.1.1" xref="S4.SS1.p4.3.m1.1.1.cmml"><mi id="S4.SS1.p4.3.m1.1.1.2" xref="S4.SS1.p4.3.m1.1.1.2.cmml">𝐑𝐆𝐍</mi><mi id="S4.SS1.p4.3.m1.1.1.3" xref="S4.SS1.p4.3.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m1.1b"><apply id="S4.SS1.p4.3.m1.1.1.cmml" xref="S4.SS1.p4.3.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.3.m1.1.1.1.cmml" xref="S4.SS1.p4.3.m1.1.1">subscript</csymbol><ci id="S4.SS1.p4.3.m1.1.1.2.cmml" xref="S4.SS1.p4.3.m1.1.1.2">𝐑𝐆𝐍</ci><ci id="S4.SS1.p4.3.m1.1.1.3.cmml" xref="S4.SS1.p4.3.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m1.1c">\mathbf{RGN}_{i}</annotation></semantics></math> denotes RGN value for the parameter <math id="S4.SS1.p4.4.m2.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="S4.SS1.p4.4.m2.1a"><msub id="S4.SS1.p4.4.m2.1.1" xref="S4.SS1.p4.4.m2.1.1.cmml"><mi id="S4.SS1.p4.4.m2.1.1.2" xref="S4.SS1.p4.4.m2.1.1.2.cmml">w</mi><mi id="S4.SS1.p4.4.m2.1.1.3" xref="S4.SS1.p4.4.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.4.m2.1b"><apply id="S4.SS1.p4.4.m2.1.1.cmml" xref="S4.SS1.p4.4.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.4.m2.1.1.1.cmml" xref="S4.SS1.p4.4.m2.1.1">subscript</csymbol><ci id="S4.SS1.p4.4.m2.1.1.2.cmml" xref="S4.SS1.p4.4.m2.1.1.2">𝑤</ci><ci id="S4.SS1.p4.4.m2.1.1.3.cmml" xref="S4.SS1.p4.4.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.4.m2.1c">w_{i}</annotation></semantics></math>. The RGN value needs to be computed after DP training.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS1.p5.4" class="ltx_p"><span id="S4.SS1.p5.4.1" class="ltx_text ltx_font_bold">Elastic weight consolidation (EWC).</span>
EWC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> utilizes a fisher-information matrix to weight the regularizer,</p>
<table id="S4.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E7.m1.2" class="ltx_Math" alttext="\Omega(w)=\sum_{i}{{F}_{i}}\lVert w_{i}-{w_{i}}^{pre}\rVert^{2}," display="block"><semantics id="S4.E7.m1.2a"><mrow id="S4.E7.m1.2.2.1" xref="S4.E7.m1.2.2.1.1.cmml"><mrow id="S4.E7.m1.2.2.1.1" xref="S4.E7.m1.2.2.1.1.cmml"><mrow id="S4.E7.m1.2.2.1.1.3" xref="S4.E7.m1.2.2.1.1.3.cmml"><mi mathvariant="normal" id="S4.E7.m1.2.2.1.1.3.2" xref="S4.E7.m1.2.2.1.1.3.2.cmml">Ω</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.2.2.1.1.3.1" xref="S4.E7.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S4.E7.m1.2.2.1.1.3.3.2" xref="S4.E7.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S4.E7.m1.2.2.1.1.3.3.2.1" xref="S4.E7.m1.2.2.1.1.3.cmml">(</mo><mi id="S4.E7.m1.1.1" xref="S4.E7.m1.1.1.cmml">w</mi><mo stretchy="false" id="S4.E7.m1.2.2.1.1.3.3.2.2" xref="S4.E7.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S4.E7.m1.2.2.1.1.2" xref="S4.E7.m1.2.2.1.1.2.cmml">=</mo><mrow id="S4.E7.m1.2.2.1.1.1" xref="S4.E7.m1.2.2.1.1.1.cmml"><munder id="S4.E7.m1.2.2.1.1.1.2" xref="S4.E7.m1.2.2.1.1.1.2.cmml"><mo movablelimits="false" id="S4.E7.m1.2.2.1.1.1.2.2" xref="S4.E7.m1.2.2.1.1.1.2.2.cmml">∑</mo><mi id="S4.E7.m1.2.2.1.1.1.2.3" xref="S4.E7.m1.2.2.1.1.1.2.3.cmml">i</mi></munder><mrow id="S4.E7.m1.2.2.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.cmml"><msub id="S4.E7.m1.2.2.1.1.1.1.3" xref="S4.E7.m1.2.2.1.1.1.1.3.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.3.2" xref="S4.E7.m1.2.2.1.1.1.1.3.2.cmml">F</mi><mi id="S4.E7.m1.2.2.1.1.1.1.3.3" xref="S4.E7.m1.2.2.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.E7.m1.2.2.1.1.1.1.2" xref="S4.E7.m1.2.2.1.1.1.1.2.cmml">​</mo><msup id="S4.E7.m1.2.2.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.1.cmml"><mrow id="S4.E7.m1.2.2.1.1.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.2.cmml"><mo fence="true" rspace="0em" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.2.1.cmml">∥</mo><mrow id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml">w</mi><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.cmml">−</mo><mmultiscripts id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml">w</mi><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml">i</mi><mrow id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3a" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"></mrow><mrow id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3b" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"></mrow><mrow id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.1a" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.4" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.4.cmml">e</mi></mrow></mmultiscripts></mrow><mo fence="true" lspace="0em" rspace="0em" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.2.1.cmml">∥</mo></mrow><mn id="S4.E7.m1.2.2.1.1.1.1.1.3" xref="S4.E7.m1.2.2.1.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><mo id="S4.E7.m1.2.2.1.2" xref="S4.E7.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.2b"><apply id="S4.E7.m1.2.2.1.1.cmml" xref="S4.E7.m1.2.2.1"><eq id="S4.E7.m1.2.2.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.2"></eq><apply id="S4.E7.m1.2.2.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.3"><times id="S4.E7.m1.2.2.1.1.3.1.cmml" xref="S4.E7.m1.2.2.1.1.3.1"></times><ci id="S4.E7.m1.2.2.1.1.3.2.cmml" xref="S4.E7.m1.2.2.1.1.3.2">Ω</ci><ci id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1">𝑤</ci></apply><apply id="S4.E7.m1.2.2.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1"><apply id="S4.E7.m1.2.2.1.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.2.1.cmml" xref="S4.E7.m1.2.2.1.1.1.2">subscript</csymbol><sum id="S4.E7.m1.2.2.1.1.1.2.2.cmml" xref="S4.E7.m1.2.2.1.1.1.2.2"></sum><ci id="S4.E7.m1.2.2.1.1.1.2.3.cmml" xref="S4.E7.m1.2.2.1.1.1.2.3">𝑖</ci></apply><apply id="S4.E7.m1.2.2.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1"><times id="S4.E7.m1.2.2.1.1.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.2"></times><apply id="S4.E7.m1.2.2.1.1.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.1.3.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S4.E7.m1.2.2.1.1.1.1.3.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.3.2">𝐹</ci><ci id="S4.E7.m1.2.2.1.1.1.1.3.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.3.3">𝑖</ci></apply><apply id="S4.E7.m1.2.2.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1">superscript</csymbol><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E7.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.2">delimited-∥∥</csymbol><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1"><minus id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.2">𝑤</ci><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.2">𝑤</ci><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3"><times id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2">𝑝</ci><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.3">𝑟</ci><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.4">𝑒</ci></apply></apply></apply></apply><cn type="integer" id="S4.E7.m1.2.2.1.1.1.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.2c">\Omega(w)=\sum_{i}{{F}_{i}}\lVert w_{i}-{w_{i}}^{pre}\rVert^{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p5.3" class="ltx_p">where <math id="S4.SS1.p5.1.m1.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S4.SS1.p5.1.m1.1a"><mi id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><ci id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">F</annotation></semantics></math> denotes the fisher matrix. Since Kirkpatrick <em id="S4.SS1.p5.3.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S4.SS1.p5.3.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> employ diagonal approximation to compute the Fisher matrix, the biggest difference between the penalty with RGN and this penalty is in the normalization by the norm of the parameter.
Empirically, we find that these techniques are almost equally effective in boosting the performance of OOD, that is, by choosing proper <math id="S4.SS1.p5.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS1.p5.2.m2.1a"><mi id="S4.SS1.p5.2.m2.1.1" xref="S4.SS1.p5.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.2.m2.1b"><ci id="S4.SS1.p5.2.m2.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.2.m2.1c">\lambda</annotation></semantics></math>, they show comparable performance in both OOD and ID.
But, the regularization with RGN excels at transferring <math id="S4.SS1.p5.3.m3.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS1.p5.3.m3.1a"><mi id="S4.SS1.p5.3.m3.1.1" xref="S4.SS1.p5.3.m3.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.3.m3.1b"><ci id="S4.SS1.p5.3.m3.1.1.cmml" xref="S4.SS1.p5.3.m3.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.3.m3.1c">\lambda</annotation></semantics></math> across different pre-trained models probably because RGN considers the scale of gradient and weights, making regularization’s strength consistent across different architectures. In experiments, we employ the regularization with RGN and leave the comparison among regularizers in the appendix.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Regularization by Decoder Design</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">Decoder-Probing with SE-Block.</span>
Although the SE-Block effectively avoids distorting features, not all pre-trained models are built with it. Thus, we study inserting SE-Blocks into several layers of pre-trained models and perform decoder-probing fine-tuning. By default, ResNet-like architectures split the network into four stages. We insert the block at the end of each stage, as shown in Fig. <a href="#S4.F5" title="Figure 5 ‣ 4 Regularization for Robust Fine-tuning ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We tune the decoder and SE-Block during decoder-probing training, then tune all modules during fine-tuning. The block is expected to filter the gradient from the upper layers, thus leading to better OOD performance. Additionally, since the block is a lightweight plug-in module, the parameter and running time increase during inference is very small.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Stronger decoder.</span>
One simple way to reduce the gradient updates to the backbone model is to use a strong decoder in decoder-probing training, then fine-tune the whole network. If the strong decoder decreases the loss, the backbone will not be significantly updated. In experiments, we investigate increasing training iterations in decoder-probing and decoder architecture.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.2" class="ltx_p">In this section, we first study the effect of weight regularization and SE-Block. After that, we analyze the combination of the two techniques and other regularization, such as data augmentation. We follow the experimental protocol presented in Sec. <a href="#S3" title="3 Analysis of Feature Distortion ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We set <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.p1.1.m1.1a"><mi id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">\lambda</annotation></semantics></math> in Eq. <a href="#S4.E4" title="In 4.1 Weight Regularization ‣ 4 Regularization for Robust Fine-tuning ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> as 0.1 based on the performance on Pascal to Watercolor using ResNet50, and apply the same value to all other settings with weight regularization. We analyze the sensitivity to <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.p1.2.m2.1a"><mi id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><ci id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">\lambda</annotation></semantics></math> in the appendix.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.2" class="ltx_p"><span id="S5.p2.2.1" class="ltx_text ltx_font_bold">Effect of weight regularization.</span>
Table <a href="#S4.T3" title="Table 3 ‣ 4 Regularization for Robust Fine-tuning ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows results with three pre-trained models. The results show the effectiveness of using weight regularization for all architectures. This means that even for the architecture with a robust structure, <em id="S5.p2.2.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S5.p2.2.3" class="ltx_text"></span>, EfficientNet, adapting to downstream tasks without losing generalization is not trivial, thus, regularization is useful. Large <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.p2.1.m1.1a"><mi id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\lambda</annotation></semantics></math> values in Eq. <a href="#S4.E4" title="In 4.1 Weight Regularization ‣ 4 Regularization for Robust Fine-tuning ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> impose strong regularization on the training, that is, larger <math id="S5.p2.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.p2.2.m2.1a"><mi id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><ci id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">\lambda</annotation></semantics></math> should improve OOD generalization while limiting the improvements on ID performance. We obtain empirical results consistent with this intuition in the appendix.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<div id="S5.T4.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:259.3pt;height:194.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.4pt,10.8pt) scale(0.9,0.9) ;">
<table id="S5.T4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T4.2.1.1" class="ltx_tr">
<td id="S5.T4.2.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T4.2.1.1.1.1" class="ltx_text">Backbone</span></td>
<td id="S5.T4.2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T4.2.1.1.2.1" class="ltx_text">Method</span></td>
<td id="S5.T4.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="4">ID: Pascal</td>
</tr>
<tr id="S5.T4.2.1.2" class="ltx_tr">
<td id="S5.T4.2.1.2.1" class="ltx_td ltx_align_center ltx_border_r">Comic</td>
<td id="S5.T4.2.1.2.2" class="ltx_td ltx_align_center ltx_border_r">Water</td>
<td id="S5.T4.2.1.2.3" class="ltx_td ltx_align_center ltx_border_r">Clipart</td>
<td id="S5.T4.2.1.2.4" class="ltx_td ltx_align_center">ID</td>
</tr>
<tr id="S5.T4.2.1.3" class="ltx_tr">
<td id="S5.T4.2.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="5"><span id="S5.T4.2.1.3.1.1" class="ltx_text"><span id="S5.T4.2.1.3.1.1.1" class="ltx_text"></span> <span id="S5.T4.2.1.3.1.1.2" class="ltx_text">
<span id="S5.T4.2.1.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T4.2.1.3.1.1.2.1.1" class="ltx_tr">
<span id="S5.T4.2.1.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">ResNet50</span></span>
<span id="S5.T4.2.1.3.1.1.2.1.2" class="ltx_tr">
<span id="S5.T4.2.1.3.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Instagram</span></span>
</span></span> <span id="S5.T4.2.1.3.1.1.3" class="ltx_text"></span></span></td>
<td id="S5.T4.2.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DP</td>
<td id="S5.T4.2.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.7</td>
<td id="S5.T4.2.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">21.2</td>
<td id="S5.T4.2.1.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.3</td>
<td id="S5.T4.2.1.3.6" class="ltx_td ltx_align_center ltx_border_t">44.6</td>
</tr>
<tr id="S5.T4.2.1.4" class="ltx_tr">
<td id="S5.T4.2.1.4.1" class="ltx_td ltx_align_center ltx_border_r">FT</td>
<td id="S5.T4.2.1.4.2" class="ltx_td ltx_align_center ltx_border_r">7.5</td>
<td id="S5.T4.2.1.4.3" class="ltx_td ltx_align_center ltx_border_r">19.4</td>
<td id="S5.T4.2.1.4.4" class="ltx_td ltx_align_center ltx_border_r">11.4</td>
<td id="S5.T4.2.1.4.5" class="ltx_td ltx_align_center">50.4</td>
</tr>
<tr id="S5.T4.2.1.5" class="ltx_tr">
<td id="S5.T4.2.1.5.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.5.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT</span></td>
<td id="S5.T4.2.1.5.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.5.2.1" class="ltx_text" style="background-color:#F2F2F2;">9.1</span></td>
<td id="S5.T4.2.1.5.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.5.3.1" class="ltx_text" style="background-color:#F2F2F2;">21.0</span></td>
<td id="S5.T4.2.1.5.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.5.4.1" class="ltx_text" style="background-color:#F2F2F2;">12.9</span></td>
<td id="S5.T4.2.1.5.5" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.5.5.1" class="ltx_text" style="background-color:#F2F2F2;">52.6</span></td>
</tr>
<tr id="S5.T4.2.1.6" class="ltx_tr">
<td id="S5.T4.2.1.6.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.6.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-SE-FT</span></td>
<td id="S5.T4.2.1.6.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.6.2.1" class="ltx_text" style="background-color:#F2F2F2;">10.2</span></td>
<td id="S5.T4.2.1.6.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.6.3.1" class="ltx_text" style="background-color:#F2F2F2;">22.5</span></td>
<td id="S5.T4.2.1.6.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.6.4.1" class="ltx_text" style="background-color:#F2F2F2;">15.1</span></td>
<td id="S5.T4.2.1.6.5" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.6.5.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">53.4</span></td>
</tr>
<tr id="S5.T4.2.1.7" class="ltx_tr">
<td id="S5.T4.2.1.7.1" class="ltx_td ltx_align_center ltx_border_r">+ WR</td>
<td id="S5.T4.2.1.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.2.1.7.2.1" class="ltx_text ltx_font_bold">18.9</span></td>
<td id="S5.T4.2.1.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.2.1.7.3.1" class="ltx_text ltx_font_bold">27.5</span></td>
<td id="S5.T4.2.1.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.2.1.7.4.1" class="ltx_text ltx_font_bold">21.4</span></td>
<td id="S5.T4.2.1.7.5" class="ltx_td ltx_align_center">52.2</td>
</tr>
<tr id="S5.T4.2.1.8" class="ltx_tr">
<td id="S5.T4.2.1.8.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="5"><span id="S5.T4.2.1.8.1.1" class="ltx_text"><span id="S5.T4.2.1.8.1.1.1" class="ltx_text"></span> <span id="S5.T4.2.1.8.1.1.2" class="ltx_text">
<span id="S5.T4.2.1.8.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T4.2.1.8.1.1.2.1.1" class="ltx_tr">
<span id="S5.T4.2.1.8.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">ConvNeXt</span></span>
<span id="S5.T4.2.1.8.1.1.2.1.2" class="ltx_tr">
<span id="S5.T4.2.1.8.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">IN21K</span></span>
</span></span> <span id="S5.T4.2.1.8.1.1.3" class="ltx_text"></span></span></td>
<td id="S5.T4.2.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DP</td>
<td id="S5.T4.2.1.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.7</td>
<td id="S5.T4.2.1.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17.3</td>
<td id="S5.T4.2.1.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14.0</td>
<td id="S5.T4.2.1.8.6" class="ltx_td ltx_align_center ltx_border_t">39.7</td>
</tr>
<tr id="S5.T4.2.1.9" class="ltx_tr">
<td id="S5.T4.2.1.9.1" class="ltx_td ltx_align_center ltx_border_r">FT</td>
<td id="S5.T4.2.1.9.2" class="ltx_td ltx_align_center ltx_border_r">11.5</td>
<td id="S5.T4.2.1.9.3" class="ltx_td ltx_align_center ltx_border_r">22.9</td>
<td id="S5.T4.2.1.9.4" class="ltx_td ltx_align_center ltx_border_r">16.8</td>
<td id="S5.T4.2.1.9.5" class="ltx_td ltx_align_center">60.6</td>
</tr>
<tr id="S5.T4.2.1.10" class="ltx_tr">
<td id="S5.T4.2.1.10.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.10.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT</span></td>
<td id="S5.T4.2.1.10.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.10.2.1" class="ltx_text" style="background-color:#F2F2F2;">13.6</span></td>
<td id="S5.T4.2.1.10.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.10.3.1" class="ltx_text" style="background-color:#F2F2F2;">24.7</span></td>
<td id="S5.T4.2.1.10.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.10.4.1" class="ltx_text" style="background-color:#F2F2F2;">19.1</span></td>
<td id="S5.T4.2.1.10.5" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.10.5.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">62.3</span></td>
</tr>
<tr id="S5.T4.2.1.11" class="ltx_tr">
<td id="S5.T4.2.1.11.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.11.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-SE-FT</span></td>
<td id="S5.T4.2.1.11.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.11.2.1" class="ltx_text" style="background-color:#F2F2F2;">15.4</span></td>
<td id="S5.T4.2.1.11.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.11.3.1" class="ltx_text" style="background-color:#F2F2F2;">27.5</span></td>
<td id="S5.T4.2.1.11.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.11.4.1" class="ltx_text" style="background-color:#F2F2F2;">20.9</span></td>
<td id="S5.T4.2.1.11.5" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S5.T4.2.1.11.5.1" class="ltx_text" style="background-color:#F2F2F2;">61.6</span></td>
</tr>
<tr id="S5.T4.2.1.12" class="ltx_tr">
<td id="S5.T4.2.1.12.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">+ WR</td>
<td id="S5.T4.2.1.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T4.2.1.12.2.1" class="ltx_text ltx_font_bold">17.8</span></td>
<td id="S5.T4.2.1.12.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T4.2.1.12.3.1" class="ltx_text ltx_font_bold">29.3</span></td>
<td id="S5.T4.2.1.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T4.2.1.12.4.1" class="ltx_text ltx_font_bold">23.8</span></td>
<td id="S5.T4.2.1.12.5" class="ltx_td ltx_align_center ltx_border_bb">61.0</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T4.3.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S5.T4.4.2" class="ltx_text" style="font-size:90%;">Effect of inserting SE-Block (SE). SE-Block improves generalization and combining it with weight regularization (WR) in fine-tuning further increases performance. </span></figcaption>
</figure>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Inserting SE-Block into the backbone.</span>
Table <a href="#S5.T4" title="Table 4 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> investigates the effectiveness of inserting SE-Block into the pre-trained model following Sec. <a href="#S4.SS2" title="4.2 Regularization by Decoder Design ‣ 4 Regularization for Robust Fine-tuning ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>. Although it does not necessarily outperform the DP model in OOD, it consistently improves FT and DP-FT, showing that SE-Block improves generalization. Additionally, combining the technique with weight regularization (see +WR) significantly improves performance, showing the compatibility of the two techniques.
Table <a href="#S5.T5" title="Table 5 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> compares DP and DP-SE models in terms of RGN and the detection loss computed on the checkpoints.
The decrease in loss can reduce the RGN value, but even when the loss value increases a little (see ConvNeXt), DP-SE substantially reduces RGN value. This indicates that SE-Block is important in preventing large gradients from passing to lower layers.</p>
</div>
<div id="S5.p4" class="ltx_para ltx_noindent">
<p id="S5.p4.1" class="ltx_p"><span id="S5.p4.1.1" class="ltx_text ltx_font_bold">Distance from the pre-trained model.</span>
Table <a href="#S5.T6" title="Table 6 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the distance between fine-tuned (DP-FT) models and an initial model. Since weight regularization uses the distance as a penalty, the fine-tuned model gets closer to the initial one. Also, SE-Block, the architecture level regularization, reduces the distance. Although the plain training renders the model far from the initial one, its performance on ID is worse than in some regularized models. Overfitting can cause performance degradation even ID.</p>
</div>
<figure id="S5.T5" class="ltx_table">
<table id="S5.T5.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T5.2.1" class="ltx_tr">
<td id="S5.T5.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Backbone</td>
<td id="S5.T5.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">Method</td>
<td id="S5.T5.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">RGN</td>
<td id="S5.T5.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">Loss</td>
</tr>
<tr id="S5.T5.2.2" class="ltx_tr">
<td id="S5.T5.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T5.2.2.1.1" class="ltx_text"><span id="S5.T5.2.2.1.1.1" class="ltx_text"></span> <span id="S5.T5.2.2.1.1.2" class="ltx_text">
<span id="S5.T5.2.2.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T5.2.2.1.1.2.1.1" class="ltx_tr">
<span id="S5.T5.2.2.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">ResNet50</span></span>
<span id="S5.T5.2.2.1.1.2.1.2" class="ltx_tr">
<span id="S5.T5.2.2.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Instagram</span></span>
</span></span> <span id="S5.T5.2.2.1.1.3" class="ltx_text"></span></span></td>
<td id="S5.T5.2.2.2" class="ltx_td ltx_align_center ltx_border_t">DP</td>
<td id="S5.T5.2.2.3" class="ltx_td ltx_align_center ltx_border_t">1.34</td>
<td id="S5.T5.2.2.4" class="ltx_td ltx_align_center ltx_border_t">0.34</td>
</tr>
<tr id="S5.T5.2.3" class="ltx_tr">
<td id="S5.T5.2.3.1" class="ltx_td ltx_align_center">DP-SE</td>
<td id="S5.T5.2.3.2" class="ltx_td ltx_align_center">0.36</td>
<td id="S5.T5.2.3.3" class="ltx_td ltx_align_center">0.27</td>
</tr>
<tr id="S5.T5.2.4" class="ltx_tr">
<td id="S5.T5.2.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T5.2.4.1.1" class="ltx_text"><span id="S5.T5.2.4.1.1.1" class="ltx_text"></span> <span id="S5.T5.2.4.1.1.2" class="ltx_text">
<span id="S5.T5.2.4.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T5.2.4.1.1.2.1.1" class="ltx_tr">
<span id="S5.T5.2.4.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">ConvNeXt</span></span>
<span id="S5.T5.2.4.1.1.2.1.2" class="ltx_tr">
<span id="S5.T5.2.4.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">IN21K</span></span>
</span></span> <span id="S5.T5.2.4.1.1.3" class="ltx_text"></span></span></td>
<td id="S5.T5.2.4.2" class="ltx_td ltx_align_center ltx_border_t">DP</td>
<td id="S5.T5.2.4.3" class="ltx_td ltx_align_center ltx_border_t">0.13</td>
<td id="S5.T5.2.4.4" class="ltx_td ltx_align_center ltx_border_t">0.35</td>
</tr>
<tr id="S5.T5.2.5" class="ltx_tr">
<td id="S5.T5.2.5.1" class="ltx_td ltx_align_center ltx_border_bb">DP-SE</td>
<td id="S5.T5.2.5.2" class="ltx_td ltx_align_center ltx_border_bb">0.04</td>
<td id="S5.T5.2.5.3" class="ltx_td ltx_align_center ltx_border_bb">0.36</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S5.T5.4.2" class="ltx_text" style="font-size:90%;">Comparison between DP and DP-SE (decoder-probing inserting SE-Block) in terms of RGN.</span></figcaption>
</figure>
<figure id="S5.T6" class="ltx_table">
<div id="S5.T6.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:236.2pt;height:81pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-13.1pt,4.5pt) scale(0.9,0.9) ;">
<table id="S5.T6.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T6.2.1.1" class="ltx_tr">
<td id="S5.T6.2.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">SE</td>
<td id="S5.T6.2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">WR</td>
<td id="S5.T6.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Distance from Init</td>
<td id="S5.T6.2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">AP (OOD)</td>
<td id="S5.T6.2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">AP (ID)</td>
</tr>
<tr id="S5.T6.2.1.2" class="ltx_tr">
<td id="S5.T6.2.1.2.1" class="ltx_td ltx_border_t"></td>
<td id="S5.T6.2.1.2.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T6.2.1.2.3" class="ltx_td ltx_align_center ltx_border_t">7.91</td>
<td id="S5.T6.2.1.2.4" class="ltx_td ltx_align_center ltx_border_t">14.3</td>
<td id="S5.T6.2.1.2.5" class="ltx_td ltx_align_center ltx_border_t">52.6</td>
</tr>
<tr id="S5.T6.2.1.3" class="ltx_tr">
<td id="S5.T6.2.1.3.1" class="ltx_td ltx_align_center"><span id="S5.T6.2.1.3.1.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T6.2.1.3.2" class="ltx_td ltx_border_r"></td>
<td id="S5.T6.2.1.3.3" class="ltx_td ltx_align_center">6.41</td>
<td id="S5.T6.2.1.3.4" class="ltx_td ltx_align_center">15.9</td>
<td id="S5.T6.2.1.3.5" class="ltx_td ltx_align_center">53.4</td>
</tr>
<tr id="S5.T6.2.1.4" class="ltx_tr">
<td id="S5.T6.2.1.4.1" class="ltx_td"></td>
<td id="S5.T6.2.1.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.2.1.4.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T6.2.1.4.3" class="ltx_td ltx_align_center">0.34</td>
<td id="S5.T6.2.1.4.4" class="ltx_td ltx_align_center">19.9</td>
<td id="S5.T6.2.1.4.5" class="ltx_td ltx_align_center">52.9</td>
</tr>
<tr id="S5.T6.2.1.5" class="ltx_tr">
<td id="S5.T6.2.1.5.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.2.1.5.1.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T6.2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T6.2.1.5.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T6.2.1.5.3" class="ltx_td ltx_align_center ltx_border_bb">0.04</td>
<td id="S5.T6.2.1.5.4" class="ltx_td ltx_align_center ltx_border_bb">22.6</td>
<td id="S5.T6.2.1.5.5" class="ltx_td ltx_align_center ltx_border_bb">52.2</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T6.3.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S5.T6.4.2" class="ltx_text" style="font-size:90%;">Distance from pre-trained models for DP-FT models. We use ResNet50 and Pascal. Both SE-Block and weight regularization decrease the distance from the initial model, improving the generalization in OOD.</span></figcaption>
</figure>
<figure id="S5.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F6.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2303.14744/assets/x11.png" id="S5.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="581" height="436" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">Longer DP training.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F6.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2303.14744/assets/x12.png" id="S5.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="581" height="387" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">Stronger decoder.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S5.F6.3.2" class="ltx_text" style="font-size:90%;">Analysis of the decoder design. Left: longer DP training increases OOD performance. Right: Investigation on the stronger decoder (NAS-FPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>). RGN value is shown next to each plot of DP. Strong decoder model increases RGN, which causes significant decrease in OOD performance in fine-tuning. </span></figcaption>
</figure>
<figure id="S5.T7" class="ltx_table">
<table id="S5.T7.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T7.2.1" class="ltx_tr">
<td id="S5.T7.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T7.2.1.1.1" class="ltx_text">Method</span></td>
<td id="S5.T7.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T7.2.1.2.1" class="ltx_text">DP-FT</span></td>
<td id="S5.T7.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T7.2.1.3.1" class="ltx_text">Augmix</span></td>
<td id="S5.T7.2.1.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="4">ID: Pascal</td>
<td id="S5.T7.2.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">ID: Cityscape</td>
</tr>
<tr id="S5.T7.2.2" class="ltx_tr">
<td id="S5.T7.2.2.1" class="ltx_td ltx_align_center ltx_border_r">Comic</td>
<td id="S5.T7.2.2.2" class="ltx_td ltx_align_center ltx_border_r">Watercolor</td>
<td id="S5.T7.2.2.3" class="ltx_td ltx_align_center ltx_border_r">Clipart</td>
<td id="S5.T7.2.2.4" class="ltx_td ltx_align_center ltx_border_rr">ID</td>
<td id="S5.T7.2.2.5" class="ltx_td ltx_align_center ltx_border_r">Foggy</td>
<td id="S5.T7.2.2.6" class="ltx_td ltx_align_center ltx_border_r">BDD</td>
<td id="S5.T7.2.2.7" class="ltx_td ltx_align_center">ID</td>
</tr>
<tr id="S5.T7.2.3" class="ltx_tr">
<td id="S5.T7.2.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FT</td>
<td id="S5.T7.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.3.2.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T7.2.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.3.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T7.2.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.5</td>
<td id="S5.T7.2.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22.9</td>
<td id="S5.T7.2.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16.8</td>
<td id="S5.T7.2.3.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">60.6</td>
<td id="S5.T7.2.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">18.1</td>
<td id="S5.T7.2.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">9.7</td>
<td id="S5.T7.2.3.10" class="ltx_td ltx_align_center ltx_border_t">35.8</td>
</tr>
<tr id="S5.T7.2.4" class="ltx_tr">
<td id="S5.T7.2.4.1" class="ltx_td ltx_align_center ltx_border_r">FT</td>
<td id="S5.T7.2.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.4.2.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T7.2.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.4.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T7.2.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.4.4.1" class="ltx_text ltx_font_bold">15.5</span></td>
<td id="S5.T7.2.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.4.5.1" class="ltx_text ltx_font_bold">28.6</span></td>
<td id="S5.T7.2.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.4.6.1" class="ltx_text ltx_font_bold">20.7</span></td>
<td id="S5.T7.2.4.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T7.2.4.7.1" class="ltx_text ltx_font_bold">61.4</span></td>
<td id="S5.T7.2.4.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.4.8.1" class="ltx_text ltx_font_bold">25.4</span></td>
<td id="S5.T7.2.4.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.4.9.1" class="ltx_text ltx_font_bold">14.5</span></td>
<td id="S5.T7.2.4.10" class="ltx_td ltx_align_center"><span id="S5.T7.2.4.10.1" class="ltx_text ltx_font_bold">37.6</span></td>
</tr>
<tr id="S5.T7.2.5" class="ltx_tr">
<td id="S5.T7.2.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CR</td>
<td id="S5.T7.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.5.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T7.2.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.5.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T7.2.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17.5</td>
<td id="S5.T7.2.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">31.1</td>
<td id="S5.T7.2.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">23.3</td>
<td id="S5.T7.2.5.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S5.T7.2.5.7.1" class="ltx_text ltx_font_bold">59.9</span></td>
<td id="S5.T7.2.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.9</td>
<td id="S5.T7.2.5.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14.3</td>
<td id="S5.T7.2.5.10" class="ltx_td ltx_align_center ltx_border_t">38.5</td>
</tr>
<tr id="S5.T7.2.6" class="ltx_tr">
<td id="S5.T7.2.6.1" class="ltx_td ltx_align_center ltx_border_r">CR + WR</td>
<td id="S5.T7.2.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.6.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T7.2.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.6.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T7.2.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.6.4.1" class="ltx_text ltx_font_bold">19.1</span></td>
<td id="S5.T7.2.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.6.5.1" class="ltx_text ltx_font_bold">32.2</span></td>
<td id="S5.T7.2.6.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.6.6.1" class="ltx_text ltx_font_bold">24.7</span></td>
<td id="S5.T7.2.6.7" class="ltx_td ltx_align_center ltx_border_rr">58.6</td>
<td id="S5.T7.2.6.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.6.8.1" class="ltx_text ltx_font_bold">27.8</span></td>
<td id="S5.T7.2.6.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.2.6.9.1" class="ltx_text ltx_font_bold">14.9</span></td>
<td id="S5.T7.2.6.10" class="ltx_td ltx_align_center"><span id="S5.T7.2.6.10.1" class="ltx_text ltx_font_bold">39.2</span></td>
</tr>
<tr id="S5.T7.2.7" class="ltx_tr">
<td id="S5.T7.2.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">WR + SE</td>
<td id="S5.T7.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.7.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T7.2.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.2.7.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T7.2.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17.8</td>
<td id="S5.T7.2.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">29.3</td>
<td id="S5.T7.2.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">23.8</td>
<td id="S5.T7.2.7.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">61.0</td>
<td id="S5.T7.2.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">21.5</td>
<td id="S5.T7.2.7.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">12.0</td>
<td id="S5.T7.2.7.10" class="ltx_td ltx_align_center ltx_border_t">37.6</td>
</tr>
<tr id="S5.T7.2.8" class="ltx_tr">
<td id="S5.T7.2.8.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">WR + SE</td>
<td id="S5.T7.2.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T7.2.8.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T7.2.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T7.2.8.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T7.2.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T7.2.8.4.1" class="ltx_text ltx_font_bold">20.0</span></td>
<td id="S5.T7.2.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T7.2.8.5.1" class="ltx_text ltx_font_bold">32.9</span></td>
<td id="S5.T7.2.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T7.2.8.6.1" class="ltx_text ltx_font_bold">25.4</span></td>
<td id="S5.T7.2.8.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr"><span id="S5.T7.2.8.7.1" class="ltx_text ltx_font_bold">61.3</span></td>
<td id="S5.T7.2.8.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T7.2.8.8.1" class="ltx_text ltx_font_bold">27.1</span></td>
<td id="S5.T7.2.8.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T7.2.8.9.1" class="ltx_text ltx_font_bold">14.8</span></td>
<td id="S5.T7.2.8.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T7.2.8.10.1" class="ltx_text ltx_font_bold">38.8</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T7.3.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S5.T7.4.2" class="ltx_text" style="font-size:90%;">Compatibility of our weight regularization (WR) and SE-Block training (SE) techniques with other domain generalization techniques using ConvNeXt. CR: contrastive regularization, Augmix: data augmentation.</span></figcaption>
</figure>
<div id="S5.p5" class="ltx_para ltx_noindent">
<p id="S5.p5.1" class="ltx_p"><span id="S5.p5.1.1" class="ltx_text ltx_font_bold">Decoder producing small RGN helps OOD generalization.</span>
Fig. <a href="#S5.F6.sf1" title="In Figure 6 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a> compares DP, DP-FT, and DP-FT plus weight regularization by increasing the number of training iterations in the DP stage. We conduct training on Pascal with the ResNet50 model and report the performance averaged over the three OOD domains.
We have two findings; (1) longer training in DP reduces RGN and improves OOD generalization in all approaches, yet, (2) the backbone still loses generalization by fine-tuning (DP vs. DP-FT), and (3) weight regularization is helpful to maintain the generalization. Fig. <a href="#S5.F6.sf2" title="In Figure 6 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a> further investigates the capacity of the decoder model using NAS-FPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, by increasing the stack of feature pyramid modules. Stacking more modules increases the generalization on OOD (NAS-FPN DP), but fine-tuning from such decoders significantly reduces generalization (NAS-FPN DP-FT). The decoder with more FPN stacks has a larger RGN, reducing generalization by fine-tuning. These models underperform a plain decoder with DP-FT trained with weight regularization (from Fig.  <a href="#S5.F6.sf1" title="In Figure 6 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>), showing that a stronger decoder does not necessarily produce a generalizable detector. We also try longer DP training for this strong decoder but do not see improvements in OOD performance because the strong decoder easily overfits the ID data. These observations suggest that training a lightweight decoder longer in the DP stage and applying weight regularization during fine-tuning is the best recipe to achieve an OOD robust detector.</p>
</div>
<div id="S5.p6" class="ltx_para ltx_noindent">
<p id="S5.p6.1" class="ltx_p"><span id="S5.p6.1.1" class="ltx_text ltx_font_bold">Compatibility with other DG approaches.</span>
Since the prior work on single-domain generalization for object detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, comparable to our setting, does not publish training code, we develop several DG approaches inspired by DG image classification to see the compatibility with our techniques in Table <a href="#S5.T7" title="Table 7 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
First, to see the compatibility with data augmentation, we study the Augmix data augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Comparing the second row (FT) and the last row (WR+SE), our approach and data augmentation have an orthogonal effect; data augmentation expands the training domain while our approach retains the knowledge of the pre-trained model. From this result, we conjecture that our approach is compatible with other augmentation, such as adversarial augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
Second, to ensure consistency with a pre-trained model, we introduce a model regularized with feature consistency loss. Specifically, given the DP model, this approach minimizes detection loss and contrastive loss between region-wise features from the DP and the tuned model, wherein Augmix <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> is employed as data augmentation. Although the contrastive loss to ensure consistency with the pre-trained model is explored in image classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, our work is the first to test in object detection. The regularization approach, CR, outperforms FT trained with Augmix. Note that, thanks to the simplicity of weight regularization, it is easy to plug in, computationally efficient, and consistently improves the performance of CR (CR+WR). These results indicate that our proposed recipes are compatible with other generalization techniques.</p>
</div>
<figure id="S5.T8" class="ltx_table">
<div id="S5.T8.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:236.9pt;height:119.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-6.2pt,3.1pt) scale(0.95,0.95) ;">
<table id="S5.T8.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.2.1.1" class="ltx_tr">
<td id="S5.T8.2.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T8.2.1.1.1.1" class="ltx_text">Method</span></td>
<td id="S5.T8.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="4">ID: Pascal</td>
</tr>
<tr id="S5.T8.2.1.2" class="ltx_tr">
<td id="S5.T8.2.1.2.1" class="ltx_td ltx_align_center ltx_border_r">Comic</td>
<td id="S5.T8.2.1.2.2" class="ltx_td ltx_align_center ltx_border_r">Water</td>
<td id="S5.T8.2.1.2.3" class="ltx_td ltx_align_center ltx_border_r">Clipart</td>
<td id="S5.T8.2.1.2.4" class="ltx_td ltx_align_center">ID</td>
</tr>
<tr id="S5.T8.2.1.3" class="ltx_tr">
<td id="S5.T8.2.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DP</td>
<td id="S5.T8.2.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17.9</td>
<td id="S5.T8.2.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">27.2</td>
<td id="S5.T8.2.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22.6</td>
<td id="S5.T8.2.1.3.5" class="ltx_td ltx_align_center ltx_border_t">49.5</td>
</tr>
<tr id="S5.T8.2.1.4" class="ltx_tr">
<td id="S5.T8.2.1.4.1" class="ltx_td ltx_align_center ltx_border_r">FT</td>
<td id="S5.T8.2.1.4.2" class="ltx_td ltx_align_center ltx_border_r">13.7</td>
<td id="S5.T8.2.1.4.3" class="ltx_td ltx_align_center ltx_border_r">29.0</td>
<td id="S5.T8.2.1.4.4" class="ltx_td ltx_align_center ltx_border_r">23.1</td>
<td id="S5.T8.2.1.4.5" class="ltx_td ltx_align_center">62.3</td>
</tr>
<tr id="S5.T8.2.1.5" class="ltx_tr">
<td id="S5.T8.2.1.5.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.5.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT</span></td>
<td id="S5.T8.2.1.5.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.5.2.1" class="ltx_text" style="background-color:#F2F2F2;">15.4</span></td>
<td id="S5.T8.2.1.5.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.5.3.1" class="ltx_text" style="background-color:#F2F2F2;">30.7</span></td>
<td id="S5.T8.2.1.5.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.5.4.1" class="ltx_text" style="background-color:#F2F2F2;">23.2</span></td>
<td id="S5.T8.2.1.5.5" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.5.5.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">62.8</span></td>
</tr>
<tr id="S5.T8.2.1.6" class="ltx_tr">
<td id="S5.T8.2.1.6.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.6.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT + WR</span></td>
<td id="S5.T8.2.1.6.2" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.6.2.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">19.5</span></td>
<td id="S5.T8.2.1.6.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.6.3.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">33.7</span></td>
<td id="S5.T8.2.1.6.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.6.4.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">26.3</span></td>
<td id="S5.T8.2.1.6.5" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.6.5.1" class="ltx_text" style="background-color:#F2F2F2;">61.9</span></td>
</tr>
<tr id="S5.T8.2.1.7" class="ltx_tr">
<td id="S5.T8.2.1.7.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.7.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-SE-FT + WR</span></td>
<td id="S5.T8.2.1.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.7.2.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">19.8</span></td>
<td id="S5.T8.2.1.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.7.3.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">33.1</span></td>
<td id="S5.T8.2.1.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.7.4.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">26.8</span></td>
<td id="S5.T8.2.1.7.5" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F2F2F2;"><span id="S5.T8.2.1.7.5.1" class="ltx_text" style="background-color:#F2F2F2;">60.6</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T8.3.1.1" class="ltx_text" style="font-size:90%;">Table 8</span>: </span><span id="S5.T8.4.2" class="ltx_text" style="font-size:90%;">Results on Swin Transformer. </span></figcaption>
</figure>
<div id="S5.p7" class="ltx_para ltx_noindent">
<p id="S5.p7.1" class="ltx_p"><span id="S5.p7.1.1" class="ltx_text ltx_font_bold">Transformer.</span>
We further investigate the effectiveness of the regularization in Swin-Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. We employ Swin-B pre-trained with ImageNet-21K in Table <a href="#S5.T8" title="Table 8 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. While both FT and DP-FT decrease performance on OOD or the improvements are marginal, adding the weight regularization remarkably improves OOD generalization with a small decrease in ID performance. The advantage of using SE-Block is not evident in this experiment. Further exploration of gradient-preserving layers in transformers is part of future work.</p>
</div>
<figure id="S5.T9" class="ltx_table">
<div id="S5.T9.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:223.3pt;height:81pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.4pt,4.5pt) scale(0.9,0.9) ;">
<table id="S5.T9.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T9.2.1.1" class="ltx_tr">
<td id="S5.T9.2.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">DP-FT</td>
<td id="S5.T9.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">WR</td>
<td id="S5.T9.2.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">SE</td>
<td id="S5.T9.2.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">COCO</td>
<td id="S5.T9.2.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">COCO-C</td>
<td id="S5.T9.2.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">rPC (%)</td>
</tr>
<tr id="S5.T9.2.1.2" class="ltx_tr">
<td id="S5.T9.2.1.2.1" class="ltx_td ltx_border_t"></td>
<td id="S5.T9.2.1.2.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T9.2.1.2.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S5.T9.2.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.5</td>
<td id="S5.T9.2.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.2</td>
<td id="S5.T9.2.1.2.6" class="ltx_td ltx_align_center ltx_border_t">55.3</td>
</tr>
<tr id="S5.T9.2.1.3" class="ltx_tr">
<td id="S5.T9.2.1.3.1" class="ltx_td ltx_align_center"><span id="S5.T9.2.1.3.1.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.2.1.3.2" class="ltx_td"></td>
<td id="S5.T9.2.1.3.3" class="ltx_td ltx_border_r"></td>
<td id="S5.T9.2.1.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T9.2.1.3.4.1" class="ltx_text ltx_font_bold">38.5</span></td>
<td id="S5.T9.2.1.3.5" class="ltx_td ltx_align_center ltx_border_r">22.7</td>
<td id="S5.T9.2.1.3.6" class="ltx_td ltx_align_center">58.9</td>
</tr>
<tr id="S5.T9.2.1.4" class="ltx_tr">
<td id="S5.T9.2.1.4.1" class="ltx_td ltx_align_center"><span id="S5.T9.2.1.4.1.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.2.1.4.2" class="ltx_td ltx_align_center"><span id="S5.T9.2.1.4.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.2.1.4.3" class="ltx_td ltx_border_r"></td>
<td id="S5.T9.2.1.4.4" class="ltx_td ltx_align_center ltx_border_r">37.7</td>
<td id="S5.T9.2.1.4.5" class="ltx_td ltx_align_center ltx_border_r">25.1</td>
<td id="S5.T9.2.1.4.6" class="ltx_td ltx_align_center">66.5</td>
</tr>
<tr id="S5.T9.2.1.5" class="ltx_tr">
<td id="S5.T9.2.1.5.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T9.2.1.5.1.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T9.2.1.5.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.2.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T9.2.1.5.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.2.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">37.2</td>
<td id="S5.T9.2.1.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T9.2.1.5.5.1" class="ltx_text ltx_font_bold">25.7</span></td>
<td id="S5.T9.2.1.5.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T9.2.1.5.6.1" class="ltx_text ltx_font_bold">69.0</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T9.3.1.1" class="ltx_text" style="font-size:90%;">Table 9</span>: </span><span id="S5.T9.4.2" class="ltx_text" style="font-size:90%;">Results of ResNet50 trained on COCO (AP). rPC denotes the
relative performance under corruption. Introducing weight regularization and SE-Block substantially improves robustness over FT (the first row).</span></figcaption>
</figure>
<div id="S5.p8" class="ltx_para ltx_noindent">
<p id="S5.p8.1" class="ltx_p"><span id="S5.p8.1.1" class="ltx_text ltx_font_bold">Experiments on COCO.</span>
We evaluate our approach using COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and COCO-C <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> containing images with diverse types and severity of image corruptions. Table <a href="#S5.T9" title="Table 9 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows that regularization boosts robustness to corruptions by more than five points over the plain fine-tuning (FT).</p>
</div>
<figure id="S5.T10" class="ltx_table">
<div id="S5.T10.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:258.7pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-32.3pt,9.0pt) scale(0.8,0.8) ;">
<table id="S5.T10.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T10.2.1.1" class="ltx_tr">
<td id="S5.T10.2.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T10.2.1.1.1.1" class="ltx_text">Method</span></td>
<td id="S5.T10.2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4">Bbox</td>
<td id="S5.T10.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="4">Seg</td>
</tr>
<tr id="S5.T10.2.1.2" class="ltx_tr">
<td id="S5.T10.2.1.2.1" class="ltx_td ltx_align_center">AP</td>
<td id="S5.T10.2.1.2.2" class="ltx_td ltx_align_center">APr</td>
<td id="S5.T10.2.1.2.3" class="ltx_td ltx_align_center">APc</td>
<td id="S5.T10.2.1.2.4" class="ltx_td ltx_align_center ltx_border_r">APf</td>
<td id="S5.T10.2.1.2.5" class="ltx_td ltx_align_center">AP</td>
<td id="S5.T10.2.1.2.6" class="ltx_td ltx_align_center">APr</td>
<td id="S5.T10.2.1.2.7" class="ltx_td ltx_align_center">APc</td>
<td id="S5.T10.2.1.2.8" class="ltx_td ltx_align_center">APf</td>
</tr>
<tr id="S5.T10.2.1.3" class="ltx_tr">
<td id="S5.T10.2.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DP</td>
<td id="S5.T10.2.1.3.2" class="ltx_td ltx_align_center ltx_border_t">20.1</td>
<td id="S5.T10.2.1.3.3" class="ltx_td ltx_align_center ltx_border_t">10.2</td>
<td id="S5.T10.2.1.3.4" class="ltx_td ltx_align_center ltx_border_t">19.2</td>
<td id="S5.T10.2.1.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">25.5</td>
<td id="S5.T10.2.1.3.6" class="ltx_td ltx_align_center ltx_border_t">20.9</td>
<td id="S5.T10.2.1.3.7" class="ltx_td ltx_align_center ltx_border_t">11.8</td>
<td id="S5.T10.2.1.3.8" class="ltx_td ltx_align_center ltx_border_t">20.4</td>
<td id="S5.T10.2.1.3.9" class="ltx_td ltx_align_center ltx_border_t">25.5</td>
</tr>
<tr id="S5.T10.2.1.4" class="ltx_tr">
<td id="S5.T10.2.1.4.1" class="ltx_td ltx_align_center ltx_border_r">DP-FT</td>
<td id="S5.T10.2.1.4.2" class="ltx_td ltx_align_center">22.1</td>
<td id="S5.T10.2.1.4.3" class="ltx_td ltx_align_center">9.9</td>
<td id="S5.T10.2.1.4.4" class="ltx_td ltx_align_center">20.3</td>
<td id="S5.T10.2.1.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T10.2.1.4.5.1" class="ltx_text ltx_font_bold">29.5</span></td>
<td id="S5.T10.2.1.4.6" class="ltx_td ltx_align_center">22.2</td>
<td id="S5.T10.2.1.4.7" class="ltx_td ltx_align_center">11.4</td>
<td id="S5.T10.2.1.4.8" class="ltx_td ltx_align_center">20.9</td>
<td id="S5.T10.2.1.4.9" class="ltx_td ltx_align_center">28.4</td>
</tr>
<tr id="S5.T10.2.1.5" class="ltx_tr">
<td id="S5.T10.2.1.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">DP-FT + WR</td>
<td id="S5.T10.2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T10.2.1.5.2.1" class="ltx_text ltx_font_bold">22.4</span></td>
<td id="S5.T10.2.1.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T10.2.1.5.3.1" class="ltx_text ltx_font_bold">10.7</span></td>
<td id="S5.T10.2.1.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T10.2.1.5.4.1" class="ltx_text ltx_font_bold">21.1</span></td>
<td id="S5.T10.2.1.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">29.0</td>
<td id="S5.T10.2.1.5.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T10.2.1.5.6.1" class="ltx_text ltx_font_bold">22.9</span></td>
<td id="S5.T10.2.1.5.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T10.2.1.5.7.1" class="ltx_text ltx_font_bold">11.9</span></td>
<td id="S5.T10.2.1.5.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T10.2.1.5.8.1" class="ltx_text ltx_font_bold">22.3</span></td>
<td id="S5.T10.2.1.5.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T10.2.1.5.9.1" class="ltx_text ltx_font_bold">28.5</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T10.3.1.1" class="ltx_text" style="font-size:90%;">Table 10</span>: </span><span id="S5.T10.4.2" class="ltx_text" style="font-size:90%;">Results on long-tailed instance segmentation using Lvis v1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. </span></figcaption>
</figure>
<div id="S5.p9" class="ltx_para">
<p id="S5.p9.1" class="ltx_p"><span id="S5.p9.1.1" class="ltx_text ltx_font_bold">Analysis on the long-tailed instance segmentation.</span>
Although we focus on the input-level distribution shift in evaluation, one of the important shifts is in label distribution. Especially, long-tailed recognition aims to train a model which generalizes well on diverse categories from data with imbalanced label distribution.
We hypothesize that the large-scale pre-trained backbone has representations effective at recognizing diverse categories, but it can lose the representations if trained on the imbalanced data; thus, the regularization on a backbone can be effective. Then, we conduct experiments on Lvis v1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> in Table <a href="#S5.T10" title="Table 10 ‣ 5 Experiments ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.
We see that DP-FT degrades performance on rare categories (APr) compared to DP, while weight regularization improves the performance on all types of categories. This analysis indicates the effectiveness of a large-scale pre-trained model for long-tailed recognition.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We study ways of achieving a robust object detector by fine-tuning from a robust pre-trained model.
We explore warmup fine-tuning in object detection, i.e., decoder-probing followed by full fine-tuning, and find that it gives architecture-specific improvements. Given this, we explore two complementary techniques to preserve generalizable representations: weight regularization to preserve backbone features, and the design of the decoder. These techniques prove useful for diverse architectures and datasets. We believe they will be good baselines for generalizable object detection.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgement</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This work was supported by DARPA LwLL.</p>
</div>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Experimental Details</h2>

<div id="A1.p1" class="ltx_para ltx_noindent">
<p id="A1.p1.1" class="ltx_p"><span id="A1.p1.1.1" class="ltx_text ltx_font_bold">Datasets.</span>
The number of test images used for evaluation is listed in Table <a href="#A1.T1" title="Table A ‣ Appendix A Experimental Details ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. For experiments on COCO, we use the validation split for evaluation.</p>
</div>
<figure id="A1.T1" class="ltx_table">
<table id="A1.T1.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T1.2.1" class="ltx_tr">
<td id="A1.T1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4">ID: Pascal</td>
<td id="A1.T1.2.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">ID: Cityscape</td>
</tr>
<tr id="A1.T1.2.2" class="ltx_tr">
<td id="A1.T1.2.2.1" class="ltx_td ltx_align_center ltx_border_r">Comic</td>
<td id="A1.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_r">Water</td>
<td id="A1.T1.2.2.3" class="ltx_td ltx_align_center ltx_border_r">Clipart</td>
<td id="A1.T1.2.2.4" class="ltx_td ltx_align_center ltx_border_r">ID</td>
<td id="A1.T1.2.2.5" class="ltx_td ltx_align_center ltx_border_r">Foggy</td>
<td id="A1.T1.2.2.6" class="ltx_td ltx_align_center ltx_border_r">BDD</td>
<td id="A1.T1.2.2.7" class="ltx_td ltx_align_center">ID</td>
</tr>
<tr id="A1.T1.2.3" class="ltx_tr">
<td id="A1.T1.2.3.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">1,000</td>
<td id="A1.T1.2.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">1,000</td>
<td id="A1.T1.2.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">500</td>
<td id="A1.T1.2.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">1,999</td>
<td id="A1.T1.2.3.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">500</td>
<td id="A1.T1.2.3.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">5,346</td>
<td id="A1.T1.2.3.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">500</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table A</span>: </span><span id="A1.T1.4.2" class="ltx_text" style="font-size:90%;">Number of test images.</span></figcaption>
</figure>
<div id="A1.p2" class="ltx_para ltx_noindent">
<p id="A1.p2.1" class="ltx_p"><span id="A1.p2.1.1" class="ltx_text ltx_font_bold">Training Details.</span>
We set up the hyper-parameters following the instructions provided by detectron2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, <em id="A1.p2.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A1.p2.1.3" class="ltx_text"></span>, we train the model for 80,000 iterations with a batch size of 2 in Pascal and 24,000 iterations with a batch size of 8 in Cityscape. In Cityscape, MaskRCNN is trained and evaluation is done on the instance segmentation task.
For other architectural choices <em id="A1.p2.1.4" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A1.p2.1.5" class="ltx_text"></span>, the architecture of the feature pyramid and detector head, we employ the default configuration.
One exception is in the training of ConvNeXt <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, where we use the group normalization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> in the feature pyramid module to stabilize the training.
For pre-trained models, we employ weights available in PyTorch Image Models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>.
We will publish the code used for training, including each configuration, upon acceptance.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Additional Results</h2>

<figure id="A2.T2" class="ltx_table">
<table id="A2.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T2.2.1" class="ltx_tr">
<td id="A2.T2.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Method</td>
<td id="A2.T2.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">Foggy</td>
<td id="A2.T2.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">BDD</td>
<td id="A2.T2.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">Cityscape</td>
</tr>
<tr id="A2.T2.2.2" class="ltx_tr">
<td id="A2.T2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DP</td>
<td id="A2.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">14.7</td>
<td id="A2.T2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">7.8</td>
<td id="A2.T2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">31.1</td>
</tr>
<tr id="A2.T2.2.3" class="ltx_tr">
<td id="A2.T2.2.3.1" class="ltx_td ltx_align_center ltx_border_r">FT</td>
<td id="A2.T2.2.3.2" class="ltx_td ltx_align_center">18.1</td>
<td id="A2.T2.2.3.3" class="ltx_td ltx_align_center">9.7</td>
<td id="A2.T2.2.3.4" class="ltx_td ltx_align_center">35.8</td>
</tr>
<tr id="A2.T2.2.4" class="ltx_tr">
<td id="A2.T2.2.4.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="A2.T2.2.4.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT</span></td>
<td id="A2.T2.2.4.2" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="A2.T2.2.4.2.1" class="ltx_text" style="background-color:#F2F2F2;">20.5</span></td>
<td id="A2.T2.2.4.3" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="A2.T2.2.4.3.1" class="ltx_text" style="background-color:#F2F2F2;">11.5</span></td>
<td id="A2.T2.2.4.4" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="A2.T2.2.4.4.1" class="ltx_text" style="background-color:#F2F2F2;">37.1</span></td>
</tr>
<tr id="A2.T2.2.5" class="ltx_tr">
<td id="A2.T2.2.5.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="A2.T2.2.5.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-SE-FT</span></td>
<td id="A2.T2.2.5.2" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="A2.T2.2.5.2.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">22.0</span></td>
<td id="A2.T2.2.5.3" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="A2.T2.2.5.3.1" class="ltx_text" style="background-color:#F2F2F2;">11.3</span></td>
<td id="A2.T2.2.5.4" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="A2.T2.2.5.4.1" class="ltx_text" style="background-color:#F2F2F2;">36.6</span></td>
</tr>
<tr id="A2.T2.2.6" class="ltx_tr">
<td id="A2.T2.2.6.1" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F2F2F2;"><span id="A2.T2.2.6.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-FT + WR</span></td>
<td id="A2.T2.2.6.2" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="A2.T2.2.6.2.1" class="ltx_text" style="background-color:#F2F2F2;">21.1</span></td>
<td id="A2.T2.2.6.3" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="A2.T2.2.6.3.1" class="ltx_text" style="background-color:#F2F2F2;">11.7</span></td>
<td id="A2.T2.2.6.4" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="A2.T2.2.6.4.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">37.2</span></td>
</tr>
<tr id="A2.T2.2.7" class="ltx_tr">
<td id="A2.T2.2.7.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="A2.T2.2.7.1.1" class="ltx_text" style="background-color:#F2F2F2;">DP-SE-FT + WR</span></td>
<td id="A2.T2.2.7.2" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F2F2F2;"><span id="A2.T2.2.7.2.1" class="ltx_text" style="background-color:#F2F2F2;">21.7</span></td>
<td id="A2.T2.2.7.3" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F2F2F2;"><span id="A2.T2.2.7.3.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">11.8</span></td>
<td id="A2.T2.2.7.4" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F2F2F2;"><span id="A2.T2.2.7.4.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">37.2</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A2.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table B</span>: </span><span id="A2.T2.4.2" class="ltx_text" style="font-size:90%;">Results on Cityscapes using Convnext.</span></figcaption>
</figure>
<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p"><span id="A2.p1.1.1" class="ltx_text ltx_font_bold">Results on Cityscape.</span>
Table <a href="#A2.T2" title="Table B ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a> shows the full ablation study on Cityscape using ConvNeXt. Overall, combining all modules performs well in many domains.</p>
</div>
<figure id="A2.T3" class="ltx_table">
<table id="A2.T3.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T3.2.1" class="ltx_tr">
<td id="A2.T3.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="A2.T3.2.1.1.1" class="ltx_text">Data</span></td>
<td id="A2.T3.2.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">ID: Pascal</td>
</tr>
<tr id="A2.T3.2.2" class="ltx_tr">
<td id="A2.T3.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Comic</td>
<td id="A2.T3.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Water</td>
<td id="A2.T3.2.2.3" class="ltx_td ltx_align_center ltx_border_t">Cart</td>
</tr>
<tr id="A2.T3.2.3" class="ltx_tr">
<td id="A2.T3.2.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IN1K</td>
<td id="A2.T3.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.9 (<span id="A2.T3.2.3.2.1" class="ltx_text" style="color:#0000FF;">+3.6</span>)</td>
<td id="A2.T3.2.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22.5 (<span id="A2.T3.2.3.3.1" class="ltx_text" style="color:#0000FF;">+2.1</span>)</td>
<td id="A2.T3.2.3.4" class="ltx_td ltx_align_center ltx_border_t">16.5 (<span id="A2.T3.2.3.4.1" class="ltx_text" style="color:#0000FF;">+4.7</span>)</td>
</tr>
<tr id="A2.T3.2.4" class="ltx_tr">
<td id="A2.T3.2.4.1" class="ltx_td ltx_align_center ltx_border_r">IN1K+Augmix</td>
<td id="A2.T3.2.4.2" class="ltx_td ltx_align_center ltx_border_r">12.7 (<span id="A2.T3.2.4.2.1" class="ltx_text" style="color:#0000FF;">+3.1</span>)</td>
<td id="A2.T3.2.4.3" class="ltx_td ltx_align_center ltx_border_r">25.7 (<span id="A2.T3.2.4.3.1" class="ltx_text" style="color:#0000FF;">+2.6</span>)</td>
<td id="A2.T3.2.4.4" class="ltx_td ltx_align_center">17.3 (<span id="A2.T3.2.4.4.1" class="ltx_text" style="color:#0000FF;">+2.5</span>)</td>
</tr>
<tr id="A2.T3.2.5" class="ltx_tr">
<td id="A2.T3.2.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">Instagram</td>
<td id="A2.T3.2.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">16.8 (<span id="A2.T3.2.5.2.1" class="ltx_text" style="color:#0000FF;">+9.3</span>)</td>
<td id="A2.T3.2.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">26.5 (<span id="A2.T3.2.5.3.1" class="ltx_text" style="color:#0000FF;">+7.1</span>)</td>
<td id="A2.T3.2.5.4" class="ltx_td ltx_align_center ltx_border_bb">17.6 (<span id="A2.T3.2.5.4.1" class="ltx_text" style="color:#0000FF;">+6.2</span>)</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A2.T3.3.1.1" class="ltx_text" style="font-size:90%;">Table C</span>: </span><span id="A2.T3.4.2" class="ltx_text" style="font-size:90%;">Results of ResNet50 pre-trained with different datasets or augmentation. We show the results with DP-FT + WR and improvement over FT baseline with blue numbers.</span></figcaption>
</figure>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p"><span id="A2.p2.1.1" class="ltx_text ltx_font_bold">Analysis of the dataset used for pre-training.</span>
Table <a href="#A2.T3" title="Table C ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a> describes the performance of ResNet50 models pre-trained with different datasets or data augmentation, where we apply weight regularization to train these models. Generally, pre-training on diverse data makes the model generalize well on OOD datasets. Also, improvements over the FT baseline by the regularization get more significant in the pre-training. In other words, pre-trained on diverse data, the model will likely forget the learned representations with standard training.</p>
</div>
<figure id="A2.F1" class="ltx_figure"><img src="/html/2303.14744/assets/x13.png" id="A2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure A</span>: </span><span id="A2.F1.3.2" class="ltx_text" style="font-size:90%;">Sensitivity to the hyper-parameter.</span></figcaption>
</figure>
<figure id="A2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A2.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.14744/assets/x14.png" id="A2.F2.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="352" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A2.F2.sf1.3.2" class="ltx_text" style="font-size:90%;">RGN weighted regularization</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A2.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.14744/assets/x15.png" id="A2.F2.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="352" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F2.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A2.F2.sf2.3.2" class="ltx_text" style="font-size:90%;">EWC</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A2.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.14744/assets/x16.png" id="A2.F2.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="352" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F2.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="A2.F2.sf3.3.2" class="ltx_text" style="font-size:90%;">L2 distance</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure B</span>: </span><span id="A2.F2.3.2" class="ltx_text" style="font-size:90%;">Comparison among difference regularization. (a): RGN weighted regularization. (b): EWC. (c): Plain weight regularization. X-axis varies the coefficient for regularization. Y-axis denotes the MAP on the training domain (Pascal) with each coefficient over the MAP of the DP-FT model. Intuitively, Y-axis denotes the strongness of the regularization.</span></figcaption>
</figure>
<figure id="A2.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A2.F3.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2303.14744/assets/x17.png" id="A2.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="581" height="387" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A2.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">MAP on ID (Pascal).</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A2.F3.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2303.14744/assets/x18.png" id="A2.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="581" height="387" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A2.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">MAP on OOD.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A2.F3.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2303.14744/assets/x19.png" id="A2.F3.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="581" height="387" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="A2.F3.sf3.3.2" class="ltx_text" style="font-size:90%;">MAP on ID (Pascal).</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A2.F3.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2303.14744/assets/x20.png" id="A2.F3.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="581" height="387" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F3.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="A2.F3.sf4.3.2" class="ltx_text" style="font-size:90%;">MAP on OOD.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A2.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure C</span>: </span><span id="A2.F3.3.2" class="ltx_text" style="font-size:90%;">Effect of longer training in DP with NAS-FPN (a)(b) and the default FPN (c)(d).</span></figcaption>
</figure>
<div id="A2.p3" class="ltx_para">
<p id="A2.p3.2" class="ltx_p"><span id="A2.p3.2.1" class="ltx_text ltx_font_bold">ID-OOD Trade-off by the coefficient.</span>
Fig. <a href="#A2.F1" title="Figure A ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> shows a trade-off in ID-and-OOD performance controlled by the regularization coefficient, <math id="A2.p3.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.p3.1.m1.1a"><mi id="A2.p3.1.m1.1.1" xref="A2.p3.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A2.p3.1.m1.1b"><ci id="A2.p3.1.m1.1.1.cmml" xref="A2.p3.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.1.m1.1c">\lambda</annotation></semantics></math> in Eq. 4, which is measured using Pascal with ResNet50-Instagram. Increasing <math id="A2.p3.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.p3.2.m2.1a"><mi id="A2.p3.2.m2.1.1" xref="A2.p3.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A2.p3.2.m2.1b"><ci id="A2.p3.2.m2.1.1.cmml" xref="A2.p3.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.2.m2.1c">\lambda</annotation></semantics></math> adds more regularization to keep the parameter near the initial model, reflected as the performance decrease in ID (Pascal). Clipart and Comic increase the performance with more regularization, while Watercolor peaks near 0.1. The peak of OOD performance should differ by the similarity with ID dataset.</p>
</div>
<figure id="A2.T4" class="ltx_table">
<table id="A2.T4.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T4.2.1" class="ltx_tr">
<td id="A2.T4.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;" rowspan="2"><span id="A2.T4.2.1.1.1" class="ltx_text">Data</span></td>
<td id="A2.T4.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="2">EfficientNet</td>
<td id="A2.T4.2.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="2">ResNet50</td>
</tr>
<tr id="A2.T4.2.2" class="ltx_tr">
<td id="A2.T4.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">OOD</td>
<td id="A2.T4.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">ID</td>
<td id="A2.T4.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">OOD</td>
<td id="A2.T4.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">ID</td>
</tr>
<tr id="A2.T4.2.3" class="ltx_tr">
<td id="A2.T4.2.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">L2-penalty</td>
<td id="A2.T4.2.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">22.3</td>
<td id="A2.T4.2.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">50.5</td>
<td id="A2.T4.2.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">20.5</td>
<td id="A2.T4.2.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">52.6</td>
</tr>
<tr id="A2.T4.2.4" class="ltx_tr">
<td id="A2.T4.2.4.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">EWC</td>
<td id="A2.T4.2.4.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">23.3</td>
<td id="A2.T4.2.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">55.2</td>
<td id="A2.T4.2.4.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">21.0</td>
<td id="A2.T4.2.4.5" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;">53.5</td>
</tr>
<tr id="A2.T4.2.5" class="ltx_tr">
<td id="A2.T4.2.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">RGN</td>
<td id="A2.T4.2.5.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">23.8</td>
<td id="A2.T4.2.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">54.3</td>
<td id="A2.T4.2.5.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">20.3</td>
<td id="A2.T4.2.5.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;">52.9</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A2.T4.3.1.1" class="ltx_text" style="font-size:90%;">Table D</span>: </span><span id="A2.T4.4.2" class="ltx_text" style="font-size:90%;">Performance comparison among different regularization.</span></figcaption>
</figure>
<div id="A2.p4" class="ltx_para">
<p id="A2.p4.4" class="ltx_p"><span id="A2.p4.4.1" class="ltx_text ltx_font_bold">Comparison among different regularizations.</span>
Table <a href="#A2.T4" title="Table D ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a> compares different regularization, <em id="A2.p4.4.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A2.p4.4.3" class="ltx_text"></span>, weight regularization with L2-distance, EWC, and RGN weighted regularization, using DP-FT.
We train models using Pascal and pick <math id="A2.p4.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.p4.1.m1.1a"><mi id="A2.p4.1.m1.1.1" xref="A2.p4.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A2.p4.1.m1.1b"><ci id="A2.p4.1.m1.1.1.cmml" xref="A2.p4.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p4.1.m1.1c">\lambda</annotation></semantics></math> based on the Watercolor domain and show the average over three domains as OOD. We do not see a significant difference among the three regularizations, in particular, in OOD performance. We further investigate the strength of the regularization on each <math id="A2.p4.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.p4.2.m2.1a"><mi id="A2.p4.2.m2.1.1" xref="A2.p4.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A2.p4.2.m2.1b"><ci id="A2.p4.2.m2.1.1.cmml" xref="A2.p4.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p4.2.m2.1c">\lambda</annotation></semantics></math> in Fig. <a href="#A2.F2" title="Figure B ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>. The Y-axis shows the MAP on Pascal with each coefficient over the MAP of the DP-FT model. With more regularization, the value decreases. Therefore, the value implies the strength of the regularization. Then, we see that the strength of the regularizer is similar across different architectures by RGN while the other two show different strengths. This indicates that RGN can add similar strength of the regularization on different architectures by the same <math id="A2.p4.3.m3.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.p4.3.m3.1a"><mi id="A2.p4.3.m3.1.1" xref="A2.p4.3.m3.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A2.p4.3.m3.1b"><ci id="A2.p4.3.m3.1.1.cmml" xref="A2.p4.3.m3.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p4.3.m3.1c">\lambda</annotation></semantics></math>. This is because the regularization is weighted by the relative gradient norm, which should adjust the strength of the regularization depending on the norm of the gradient and parameter. In short, L2-distance and EWC may require additional hyper-parameter <math id="A2.p4.4.m4.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A2.p4.4.m4.1a"><mi id="A2.p4.4.m4.1.1" xref="A2.p4.4.m4.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A2.p4.4.m4.1b"><ci id="A2.p4.4.m4.1.1.cmml" xref="A2.p4.4.m4.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p4.4.m4.1c">\lambda</annotation></semantics></math> tuning when the architecture is changed while RGN weighted regularization is less sensitive to the changes in the architecture.</p>
</div>
<figure id="A2.T5" class="ltx_table">
<table id="A2.T5.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T5.2.1" class="ltx_tr">
<td id="A2.T5.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;">DP-FT</td>
<td id="A2.T5.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;">WR</td>
<td id="A2.T5.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;">SE</td>
<td id="A2.T5.2.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;">Clean</td>
<td id="A2.T5.2.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.5.1" class="ltx_text" style="font-size:90%;">Gauss.</span></td>
<td id="A2.T5.2.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.6.1" class="ltx_text" style="font-size:90%;">Shot</span></td>
<td id="A2.T5.2.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.7.1" class="ltx_text" style="font-size:90%;">Impulse</span></td>
<td id="A2.T5.2.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.8.1" class="ltx_text" style="font-size:90%;">Defocus</span></td>
<td id="A2.T5.2.1.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.9.1" class="ltx_text" style="font-size:90%;">Glass</span></td>
<td id="A2.T5.2.1.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.10.1" class="ltx_text" style="font-size:90%;">Motion</span></td>
<td id="A2.T5.2.1.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.11.1" class="ltx_text" style="font-size:90%;">Zoom</span></td>
<td id="A2.T5.2.1.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.12.1" class="ltx_text" style="font-size:90%;">Snow</span></td>
<td id="A2.T5.2.1.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.13.1" class="ltx_text" style="font-size:90%;">Frost</span></td>
<td id="A2.T5.2.1.14" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.14.1" class="ltx_text" style="font-size:90%;">Fog</span></td>
<td id="A2.T5.2.1.15" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.15.1" class="ltx_text" style="font-size:90%;">Bright</span></td>
<td id="A2.T5.2.1.16" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.16.1" class="ltx_text" style="font-size:90%;">Contrast</span></td>
<td id="A2.T5.2.1.17" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.17.1" class="ltx_text" style="font-size:90%;">Elastic</span></td>
<td id="A2.T5.2.1.18" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.18.1" class="ltx_text" style="font-size:90%;">Pixel</span></td>
<td id="A2.T5.2.1.19" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.1.19.1" class="ltx_text" style="font-size:90%;">JPEG</span></td>
</tr>
<tr id="A2.T5.2.2" class="ltx_tr">
<td id="A2.T5.2.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;"></td>
<td id="A2.T5.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;"></td>
<td id="A2.T5.2.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_r ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;"></td>
<td id="A2.T5.2.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">36.5</td>
<td id="A2.T5.2.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">18.5</td>
<td id="A2.T5.2.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">19.2</td>
<td id="A2.T5.2.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">16.8</td>
<td id="A2.T5.2.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">24.9</td>
<td id="A2.T5.2.2.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">17.4</td>
<td id="A2.T5.2.2.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">21.2</td>
<td id="A2.T5.2.2.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">6.4</td>
<td id="A2.T5.2.2.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">12.8</td>
<td id="A2.T5.2.2.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">19.1</td>
<td id="A2.T5.2.2.14" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">20.8</td>
<td id="A2.T5.2.2.15" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">31.9</td>
<td id="A2.T5.2.2.16" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">21.1</td>
<td id="A2.T5.2.2.17" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">28.0</td>
<td id="A2.T5.2.2.18" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">23.6</td>
<td id="A2.T5.2.2.19" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">20.5</td>
</tr>
<tr id="A2.T5.2.3" class="ltx_tr">
<td id="A2.T5.2.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.3.1.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="A2.T5.2.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:1.5pt;padding-right:1.5pt;"></td>
<td id="A2.T5.2.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;"></td>
<td id="A2.T5.2.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.3.4.1" class="ltx_text ltx_font_bold">38.5</span></td>
<td id="A2.T5.2.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">21.0</td>
<td id="A2.T5.2.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">21.8</td>
<td id="A2.T5.2.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;">19.2</td>
<td id="A2.T5.2.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">26.9</td>
<td id="A2.T5.2.3.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">18.7</td>
<td id="A2.T5.2.3.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">22.7</td>
<td id="A2.T5.2.3.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;">6.7</td>
<td id="A2.T5.2.3.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">14.2</td>
<td id="A2.T5.2.3.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">21.7</td>
<td id="A2.T5.2.3.14" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">32.1</td>
<td id="A2.T5.2.3.15" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;">33.9</td>
<td id="A2.T5.2.3.16" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">23.7</td>
<td id="A2.T5.2.3.17" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">29.8</td>
<td id="A2.T5.2.3.18" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">26.0</td>
<td id="A2.T5.2.3.19" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">21.9</td>
</tr>
<tr id="A2.T5.2.4" class="ltx_tr">
<td id="A2.T5.2.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.4.1.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="A2.T5.2.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.4.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="A2.T5.2.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;"></td>
<td id="A2.T5.2.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;">37.7</td>
<td id="A2.T5.2.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.4.5.1" class="ltx_text ltx_font_bold">23.4</span></td>
<td id="A2.T5.2.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.4.6.1" class="ltx_text ltx_font_bold">23.8</span></td>
<td id="A2.T5.2.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.4.7.1" class="ltx_text ltx_font_bold">21.7</span></td>
<td id="A2.T5.2.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">27.1</td>
<td id="A2.T5.2.4.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">20.7</td>
<td id="A2.T5.2.4.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">24.2</td>
<td id="A2.T5.2.4.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;">7.9</td>
<td id="A2.T5.2.4.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">16.6</td>
<td id="A2.T5.2.4.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">23.0</td>
<td id="A2.T5.2.4.14" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">34.1</td>
<td id="A2.T5.2.4.15" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;">33.8</td>
<td id="A2.T5.2.4.16" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">27.8</td>
<td id="A2.T5.2.4.17" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">30.4</td>
<td id="A2.T5.2.4.18" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">32.8</td>
<td id="A2.T5.2.4.19" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.5pt;padding-right:1.5pt;">28.6</td>
</tr>
<tr id="A2.T5.2.5" class="ltx_tr">
<td id="A2.T5.2.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.1.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="A2.T5.2.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.2.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="A2.T5.2.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="A2.T5.2.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;">37.2</td>
<td id="A2.T5.2.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">22.7</td>
<td id="A2.T5.2.5.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">23.0</td>
<td id="A2.T5.2.5.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;">20.8</td>
<td id="A2.T5.2.5.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.8.1" class="ltx_text ltx_font_bold">28.6</span></td>
<td id="A2.T5.2.5.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.9.1" class="ltx_text ltx_font_bold">23.0</span></td>
<td id="A2.T5.2.5.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.10.1" class="ltx_text ltx_font_bold">25.4</span></td>
<td id="A2.T5.2.5.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.11.1" class="ltx_text ltx_font_bold">8.1</span></td>
<td id="A2.T5.2.5.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.12.1" class="ltx_text ltx_font_bold">17.4</span></td>
<td id="A2.T5.2.5.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.13.1" class="ltx_text ltx_font_bold">23.5</span></td>
<td id="A2.T5.2.5.14" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.14.1" class="ltx_text ltx_font_bold">34.5</span></td>
<td id="A2.T5.2.5.15" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.15.1" class="ltx_text ltx_font_bold">34.2</span></td>
<td id="A2.T5.2.5.16" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.16.1" class="ltx_text ltx_font_bold">28.7</span></td>
<td id="A2.T5.2.5.17" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.17.1" class="ltx_text ltx_font_bold">30.7</span></td>
<td id="A2.T5.2.5.18" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.18.1" class="ltx_text ltx_font_bold">33.2</span></td>
<td id="A2.T5.2.5.19" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="A2.T5.2.5.19.1" class="ltx_text ltx_font_bold">31.0</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A2.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table E</span>: </span><span id="A2.T5.4.2" class="ltx_text" style="font-size:90%;">Detailed results on the robustness evaluation using COCO.</span></figcaption>
</figure>
<div id="A2.p5" class="ltx_para">
<p id="A2.p5.1" class="ltx_p"><span id="A2.p5.1.1" class="ltx_text ltx_font_bold">Analysis on NAS-FPN.</span>
Fig. <a href="#A2.F3" title="Figure C ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a> shows the effect of training iterations for the DP model of NAS-FPN and FPN, where we set the number of stacks in NAS-FPN as 3. The NAS-FPN shows strong performance on ID by longer training but reduces the performance on OOD. By contrast, FPN improves the performance on both types of distribution through longer training. A strong decoder can easily overfit ID data; thus, OOD performance can decrease with longer training.</p>
</div>
<figure id="A2.F4" class="ltx_figure"><img src="/html/2303.14744/assets/x21.png" id="A2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="246" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure D</span>: </span><span id="A2.F4.3.2" class="ltx_text" style="font-size:90%;">Performance on each corruption severity.</span></figcaption>
</figure>
<div id="A2.p6" class="ltx_para">
<p id="A2.p6.1" class="ltx_p"><span id="A2.p6.1.1" class="ltx_text ltx_font_bold">Analysis on the robustness to image corruptions.</span>
Table <a href="#A2.T5" title="Table E ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a> shows the results on the robustness to image corruptions using COCO. Using our regularization, the trained detector improves the robustness to all types of corruption. Interestingly, the use of SE-Block decreases the robustness to the high-frequecy noise, <em id="A2.p6.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A2.p6.1.3" class="ltx_text"></span>, gaussian noise, while improving the robustness to the other types of corruptions. The architectural difference seems to cause this change.
Fig. <a href="#A2.F4" title="Figure D ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a> shows the performance on each severity of the corruptions. Trained with regularization (WR, SE), the detector performs better on the diverse level of severities than the model without regularization.</p>
</div>
<figure id="A2.F5" class="ltx_figure"><img src="/html/2303.14744/assets/x22.png" id="A2.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="392" height="357" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure E</span>: </span><span id="A2.F5.3.2" class="ltx_text" style="font-size:90%;">Detection results on Pascal.</span></figcaption>
</figure>
<figure id="A2.F6" class="ltx_figure"><img src="/html/2303.14744/assets/x23.png" id="A2.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="135" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure F</span>: </span><span id="A2.F6.3.2" class="ltx_text" style="font-size:90%;">Detection results on Cityscapes.</span></figcaption>
</figure>
<div id="A2.p7" class="ltx_para">
<p id="A2.p7.1" class="ltx_p"><span id="A2.p7.1.1" class="ltx_text ltx_font_bold">Qualitative Results.</span>
Fig. <a href="#A2.F5" title="Figure E ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a> and  <a href="#A2.F6" title="Figure F ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">F</span></a> show qualitative results on Pascal and Cityscape. Note that, using our regularization, more objects are detected, <em id="A2.p7.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A2.p7.1.3" class="ltx_text"></span>, middle in Fig. <a href="#A2.F5" title="Figure E ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a> and top right in Fig. <a href="#A2.F6" title="Figure F ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">F</span></a>, or correctly classified, <em id="A2.p7.1.4" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A2.p7.1.5" class="ltx_text"></span>, top left in Fig. <a href="#A2.F5" title="Figure E ‣ Appendix B Additional Results ‣ Mind the Backbone: Minimizing Backbone Distortion for Robust Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a>. Several objects are not localized by both models, which indicates the difficulty of this task.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Simone Angarano, Mauro Martini, Francesco Salvetti, Vittorio Mazzia, and
Marcello Chiaberge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Back-to-bones: Rediscovering the role of backbones in domain
generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2209.01121</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Junbum Cha, Sanghyuk Chun, Kyungjae Lee, Han-Cheol Cho, Seunghyun Park, Yunsung
Lee, and Sungrae Park.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Swad: Domain generalization by seeking flat minima.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">,
34:22405–22418, 2021.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Junbum Cha, Kyungjae Lee, Sungrae Park, and Sanghyuk Chun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Domain generalization by mutual-information regularization with
pre-trained models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision–ECCV 2022: 17th European Conference, Tel
Aviv, Israel, October 23–27, 2022, Proceedings, Part XXIII</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 440–457.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Wuyang Chen, Zhiding Yu, Shalini De Mello, Sifei Liu, Jose M Alvarez, Zhangyang
Wang, and Anima Anandkumar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Contrastive syn-to-real generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.02290</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Xiangning Chen, Cihang Xie, Mingxing Tan, Li Zhang, Cho-Jui Hsieh, and Boqing
Gong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Robust and accurate object detection via adversarial learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, pages 16622–16631, 2021.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Brian Chu, Vashisht Madhavan, Oscar Beijbom, Judy Hoffman, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Best practices for fine-tuning visual classifiers to new domains.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision–ECCV 2016 Workshops: Amsterdam, The
Netherlands, October 8-10 and 15-16, 2016, Proceedings, Part III 14</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages
435–442. Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler,
Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">The cityscapes dataset for semantic urban scene understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Imagenet: A large-scale hierarchical image database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2009 IEEE conference on computer vision and pattern
recognition</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, pages 248–255. Ieee, 2009.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew
Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">The pascal visual object classes (voc) challenge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IJCV</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 88(2):303–338, 2010.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Qi Fan, Mattia Segu, Yu-Wing Tai, Fisher Yu, Chi-Keung Tang, Bernt Schiele, and
Dengxin Dai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Normalization perturbation: A simple domain generalization method for
real-world domain shifts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2211.04393</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Golnaz Ghiasi, Tsung-Yi Lin, and Quoc V Le.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Nas-fpn: Learning scalable feature pyramid architecture for object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 7036–7045, 2019.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Rich feature hierarchies for accurate object detection and semantic
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages 580–587, 2014.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Ishaan Gulrajani and David Lopez-Paz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">In search of lost domain generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2007.01434</span><span id="bib.bib13.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Agrim Gupta, Piotr Dollar, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Lvis: A dataset for large vocabulary instance segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 5356–5364, 2019.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin Gilmer, and Balaji
Lakshminarayanan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Augmix: A simple data processing method to improve robustness and
uncertainty.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1912.02781</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Jie Hu, Li Shen, and Gang Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Squeeze-and-excitation networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 7132–7141, 2018.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Naoto Inoue, Ryosuke Furuta, Toshihiko Yamasaki, and Kiyoharu Aizawa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Cross-domain weakly-supervised object detection through progressive
domain adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Donghyun Kim, Kaihong Wang, Stan Sclaroff, and Kate Saenko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">A broad study of pre-training for domain generalization and
adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision–ECCV 2022: 17th European Conference, Tel
Aviv, Israel, October 23–27, 2022, Proceedings, Part XXXIII</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, pages
621–638. Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
Grabska-Barwinska, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Overcoming catastrophic forgetting in neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1612.00796</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Ananya Kumar, Aditi Raghunathan, Robbie Jones, Tengyu Ma, and Percy Liang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Fine-tuning can distort pretrained features and underperform
out-of-distribution.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2202.10054</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Yoonho Lee, Annie S Chen, Fahim Tajwar, Ananya Kumar, Huaxiu Yao, Percy Liang,
and Chelsea Finn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Surgical fine-tuning improves adaptation to distribution shifts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2210.11466</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Chuang Lin, Zehuan Yuan, Sicheng Zhao, Peize Sun, Changhu Wang, and Jianfei
Cai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Domain-invariant disentangled network for generalizable object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 8771–8780, 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan,
and Serge Belongie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Feature pyramid networks for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, pages 2117–2125, 2017.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr Dollár, and C Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
Baining Guo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Swin transformer: Hierarchical vision transformer using shifted
windows.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on
computer vision</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 10012–10022, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
and Saining Xie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">A convnet for the 2020s.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, pages 11976–11986, 2022.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Jonathan Long, Evan Shelhamer, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Fully convolutional networks for semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, pages 3431–3440, 2015.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri,
Yixuan Li, Ashwin Bharambe, and Laurens Van Der Maaten.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Exploring the limits of weakly supervised pretraining.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European conference on computer vision
(ECCV)</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, pages 181–196, 2018.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Claudio Michaelis, Benjamin Mitzkus, Robert Geirhos, Evgenia Rusak, Oliver
Bringmann, Alexander S Ecker, Matthias Bethge, and Wieland Brendel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Benchmarking robustness in object detection: Autonomous driving when
winter is coming.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1907.07484</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Seyed Iman Mirzadeh, Arslan Chaudhry, Dong Yin, Huiyi Hu, Razvan Pascanu, Dilan
Gorur, and Mehrdad Farajtabar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Wide neural networks forget less catastrophically.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, pages
15699–15717. PMLR, 2022.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Alexandre Rame, Matthieu Kirchmeyer, Thibaud Rahier, Alain Rakotomamonjy,
Patrick Gallinari, and Matthieu Cord.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Diverse weight averaging for out-of-distribution generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2205.09739</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Faster r-cnn: Towards real-time object detection with region proposal
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Christos Sakaridis, Dengxin Dai, and Luc Van Gool.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Semantic foggy scene understanding with synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IJCV</span><span id="bib.bib34.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh
Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Mobilenetv2: Inverted residuals and linear bottlenecks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 4510–4520, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Revisiting unreasonable effectiveness of data in deep learning era.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, pages 843–852, 2017.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Mingxing Tan and Quoc Le.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Efficientnet: Rethinking model scaling for convolutional neural
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International conference on machine learning</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, pages
6105–6114. PMLR, 2019.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Cristina Vasconcelos, Vighnesh Birodkar, and Vincent Dumoulin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Proper reuse of image classification features improves object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, pages 13628–13637, 2022.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Xudong Wang, Zhaowei Cai, Dashan Gao, and Nuno Vasconcelos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Towards universal object detection by domain attention.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, pages 7289–7298, 2019.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Xin Wang, Thomas E Huang, Benlin Liu, Fisher Yu, Xiaolong Wang, Joseph E
Gonzalez, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Robust object detection via instance-level temporal cycle confusion.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Computer Vision (ICCV)</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Ross Wightman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Pytorch image models.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/rwightman/pytorch-image-models" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/rwightman/pytorch-image-models</a><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Mitchell Wortsman, Gabriel Ilharco, Samir Ya Gadre, Rebecca Roelofs, Raphael
Gontijo-Lopes, Ari S Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon,
Simon Kornblith, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Model soups: averaging weights of multiple fine-tuned models improves
accuracy without increasing inference time.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:90%;">, pages
23965–23998. PMLR, 2022.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Mitchell Wortsman, Gabriel Ilharco, Jong Wook Kim, Mike Li, Simon Kornblith,
Rebecca Roelofs, Raphael Gontijo Lopes, Hannaneh Hajishirzi, Ali Farhadi,
Hongseok Namkoong, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Robust fine-tuning of zero-shot models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">, pages 7959–7971, 2022.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Yuxin Wu and Kaiming He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Group normalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European conference on computer vision
(ECCV)</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:90%;">, pages 3–19, 2018.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Detectron2.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/facebookresearch/detectron2" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/facebookresearch/detectron2</a><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Self-training with noisy student improves imagenet classification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib46.5.3" class="ltx_text" style="font-size:90%;">, pages 10687–10698, 2020.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Qinwei Xu, Ruipeng Zhang, Ya Zhang, Yanfeng Wang, and Qi Tian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">A fourier-based framework for domain generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib47.5.3" class="ltx_text" style="font-size:90%;">, pages 14383–14392, 2021.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
LI Xuhong, Yves Grandvalet, and Franck Davoine.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Explicit inductive bias for transfer learning with convolutional
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib48.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib48.5.3" class="ltx_text" style="font-size:90%;">, pages
2825–2834. PMLR, 2018.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">How transferable are features in deep neural networks?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib49.4.2" class="ltx_text" style="font-size:90%;">, 27, 2014.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu,
Vashisht Madhavan, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Bdd100k: A diverse driving dataset for heterogeneous multitask
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, pages 2636–2645, 2020.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Zhun Zhong, Yuyang Zhao, Gim Hee Lee, and Nicu Sebe.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Adversarial style augmentation for domain generalized urban-scene
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2207.04892</span><span id="bib.bib51.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Domain generalization with mixstyle.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.02008</span><span id="bib.bib52.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2303.14743" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2303.14744" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2303.14744">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.14744" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2303.14745" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 17:35:07 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
